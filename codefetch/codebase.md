docker-compose.yml
```
1 | # docker-compose.yml
2 | # Defines the services for the application.
3 | 
4 | services:
5 |   backend:
6 |     build:
7 |       context: ./backend
8 |     ports:
9 |       - "8000:8000"
10 |     volumes:
11 |       - ./backend:/app
12 |     # This allows the container to communicate with services running on the host machine.
13 |     # It's necessary for the Flask backend inside Docker to reach the Ollama API
14 |     # running on your host (localhost).
15 |     # For Linux: use "host.docker.internal:host-gateway"
16 |     # For Mac/Windows: "host.docker.internal" is automatically available.
17 |     extra_hosts:
18 |       - "host.docker.internal:host-gateway"
19 |     restart: unless-stopped
20 |     container_name: interpaws_backend
```

.venv/pyvenv.cfg
```
1 | home = /opt/homebrew/opt/python@3.13/bin
2 | include-system-site-packages = false
3 | version = 3.13.5
4 | executable = /opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/bin/python3.13
5 | command = /opt/homebrew/opt/python@3.13/bin/python3.13 -m venv /Users/amaribullard/Documents/GitHub/interpawsdemo/.venv
```

backend/Dockerfile
```
1 | # backend/Dockerfile
2 | # Specifies the environment for the backend service.
3 | 
4 | # STRATEGY CHANGE: Use the full python:3.11-bookworm image.
5 | # This image is larger but includes the build-essential tools
6 | # required by ortools, which avoids the failing apt-get command.
7 | FROM python:3.11-bookworm
8 | 
9 | # Set the working directory in the container
10 | WORKDIR /app
11 | 
12 | # Copy the requirements file into the container at /app
13 | COPY requirements.txt .
14 | 
15 | # Install any needed packages specified in requirements.txt
16 | RUN pip install --no-cache-dir -r requirements.txt
17 | 
18 | # Copy the rest of the application's code into the container
19 | COPY . .
20 | 
21 | # Command to run the application
22 | # 1. Run the seed script to ensure the database is initialized.
23 | # 2. Start the Flask application using Gunicorn.
24 | CMD ["sh", "-c", "python seed_demo.py && gunicorn --bind 0.0.0.0:8000 api:app"]
```

backend/api.py
```
1 | # backend/api.py
2 | import os
3 | import sqlite3
4 | from datetime import datetime, time, timedelta
5 | 
6 | from flask import Flask, jsonify, redirect, render_template, request, url_for
7 | from sqlalchemy import (create_engine, Column, Integer, String, Time, ForeignKey,
8 |                         Date)
9 | from sqlalchemy.orm import declarative_base, sessionmaker
10 | from sqlalchemy.exc import IntegrityError
11 | 
12 | from scheduler.solver import find_available_slots
13 | from scheduler.ranker import rank_slots_with_llm
14 | 
15 | # --- Configuration & Setup ---
16 | DATABASE_URL = "sqlite:///clinic.db"
17 | engine = create_engine(DATABASE_URL)
18 | Base = declarative_base()
19 | Session = sessionmaker(bind=engine)
20 | 
21 | _current_dir = os.path.dirname(os.path.abspath(__file__))
22 | _template_folder = os.path.join(_current_dir, 'templates')
23 | app = Flask(__name__, template_folder=_template_folder)
24 | 
25 | 
26 | # --- Database Models ---
27 | class Vet(Base):
28 |     __tablename__ = 'vets'
29 |     id = Column(Integer, primary_key=True)
30 |     name = Column(String, unique=True)
31 | 
32 | class Room(Base):
33 |     __tablename__ = 'rooms'
34 |     id = Column(Integer, primary_key=True)
35 |     name = Column(String, unique=True)
36 | 
37 | class Appointment(Base):
38 |     __tablename__ = 'appointments'
39 |     id = Column(Integer, primary_key=True)
40 |     pet_name = Column(String)
41 |     reason = Column(String)
42 |     date = Column(Date)
43 |     start_time = Column(Time)
44 |     end_time = Column(Time)
45 |     vet_id = Column(Integer, ForeignKey('vets.id'))
46 |     room_id = Column(Integer, ForeignKey('rooms.id'))
47 | 
48 | # --- App Routes ---
49 | 
50 | @app.route('/')
51 | def wizard():
52 |     """Serves the initial clinic setup wizard page."""
53 |     session = Session()
54 |     clinic_exists = session.query(Vet).first() is not None
55 |     session.close()
56 |     if clinic_exists:
57 |         return redirect(url_for('booking_form'))
58 |     return render_template('wizard.html')
59 | 
60 | @app.route('/setup-clinic', methods=['POST'])
61 | def setup_clinic():
62 |     """
63 |     Initializes the clinic with a number of vets and rooms.
64 |     This is a demo-only function to set up the resources.
65 |     """
66 |     session = Session()
67 |     try:
68 |         num_vets = int(request.form.get('vets', 5))
69 |         num_rooms = int(request.form.get('rooms', 5))
70 | 
71 |         # Clear existing data for a clean demo setup
72 |         session.query(Appointment).delete()
73 |         session.query(Vet).delete()
74 |         session.query(Room).delete()
75 | 
76 |         for i in range(1, num_vets + 1):
77 |             session.add(Vet(name=f"Dr. Pawson {i}"))
78 |         for i in range(1, num_rooms + 1):
79 |             session.add(Room(name=f"Exam Room {i}"))
80 |         
81 |         session.commit()
82 |     except Exception as e:
83 |         session.rollback()
84 |         app.logger.error(f"Error setting up clinic: {e}")
85 |     finally:
86 |         session.close()
87 |     
88 |     return redirect(url_for('booking_form'))
89 | 
90 | @app.route('/booking')
91 | def booking_form():
92 |     """Serves the main appointment booking page."""
93 |     return render_template('booking.html')
94 | 
95 | @app.route('/find-appointment', methods=['POST'])
96 | def find_appointment():
97 |     """
98 |     API endpoint to find and rank appointment slots.
99 |     This is called by the booking form via HTMX.
100 |     """
101 |     session = Session()
102 |     try:
103 |         # --- Get data from form ---
104 |         pet_name = request.form.get('pet_name')
105 |         reason = request.form.get('reason')
106 |         appointment_date_str = request.form.get('date')
107 |         appointment_date = datetime.strptime(appointment_date_str, '%Y-%m-%d').date()
108 | 
109 |         # --- Core Logic ---
110 |         # 1. Get resources and existing appointments from DB
111 |         vets = session.query(Vet).all()
112 |         rooms = session.query(Room).all()
113 |         existing_appointments = session.query(Appointment).filter_by(date=appointment_date).all()
114 | 
115 |         # 2. Use OR-Tools to find all feasible slots
116 |         feasible_slots = find_available_slots(
117 |             appointment_date, vets, rooms, existing_appointments
118 |         )
119 | 
120 |         if not feasible_slots:
121 |             return "<div>No available slots found for this date.</div>"
122 | 
123 |         # 3. Use LLM to rank the feasible slots
124 |         app.logger.info("Sending slots to AI ranker...")
125 |         ranked_slots = rank_slots_with_llm(feasible_slots, reason)
126 | 
127 |         # 4. Prepare top 3 slots for display
128 |         top_slots = ranked_slots[:3]
129 | 
130 |         return render_template('results.html', slots=top_slots, pet_name=pet_name, reason=reason, date=appointment_date_str)
131 | 
132 |     except Exception as e:
133 |         app.logger.error(f"Error finding appointment: {e}")
134 |         return f"<div class='text-red-500 p-4'>An error occurred: {e}</div>"
135 |     finally:
136 |         session.close()
137 | 
138 | @app.route('/book-appointment', methods=['POST'])
139 | def book_appointment():
140 |     """
141 |     Simulates booking an appointment and saves it to the database.
142 |     """
143 |     session = Session()
144 |     try:
145 |         pet_name = request.form.get('pet_name')
146 |         reason = request.form.get('reason')
147 |         date_str = request.form.get('date')
148 |         time_str = request.form.get('time')
149 |         vet_id = int(request.form.get('vet_id'))
150 |         room_id = int(request.form.get('room_id'))
151 | 
152 |         appointment_date = datetime.strptime(date_str, '%Y-%m-%d').date()
153 |         start_time_obj = datetime.strptime(time_str, '%H:%M').time()
154 |         
155 |         # Appointments are 30 minutes for this demo
156 |         end_time_obj = (datetime.combine(appointment_date, start_time_obj) + timedelta(minutes=30)).time()
157 | 
158 |         new_appointment = Appointment(
159 |             pet_name=pet_name,
160 |             reason=reason,
161 |             date=appointment_date,
162 |             start_time=start_time_obj,
163 |             end_time=end_time_obj,
164 |             vet_id=vet_id,
165 |             room_id=room_id
166 |         )
167 |         session.add(new_appointment)
168 |         session.commit()
169 |         
170 |         # In a real app, you'd return a confirmation page.
171 |         # For this demo, we just confirm it's "booked".
172 |         return f"Booked appointment for {pet_name} at {time_str} on {date_str}!"
173 | 
174 |     except IntegrityError:
175 |         session.rollback()
176 |         return "Error: This slot was just booked by someone else. Please try another."
177 |     except Exception as e:
178 |         session.rollback()
179 |         app.logger.error(f"Error booking appointment: {e}")
180 |         return f"An error occurred during booking: {e}"
181 |     finally:
182 |         session.close()
183 | 
184 | if __name__ == '__main__':
185 |     # This is for local development without Gunicorn
186 |     Base.metadata.create_all(engine)
187 |     app.run(host='0.0.0.0', port=8000, debug=True)
```

backend/requirements.txt
```
1 | Flask==3.0.3
2 | gunicorn==22.0.0
3 | ortools==9.9.3963
4 | requests==2.32.3
5 | SQLAlchemy==2.0.30
```

backend/seed_demo.py
```
1 | # backend/seed_demo.py
2 | import os
3 | from sqlalchemy import create_engine, inspect
4 | from sqlalchemy.orm import sessionmaker
5 | # The api module is now in the same directory, so the import path changes.
6 | from api import Base, Vet, Room, Appointment
7 | 
8 | # The DB file will be created in the current directory (/app in the container)
9 | DATABASE_FILE = "clinic.db"
10 | DATABASE_URL = f"sqlite:///{DATABASE_FILE}"
11 | 
12 | def seed_database():
13 |     """
14 |     Initializes the database with default data if it's empty.
15 |     This ensures the demo works out-of-the-box on first run.
16 |     """
17 |     engine = create_engine(DATABASE_URL)
18 |     
19 |     inspector = inspect(engine)
20 |     if inspector.has_table("vets"):
21 |         print("Database already seeded. Skipping initialization.")
22 |         return
23 | 
24 |     print("Database not found or empty. Initializing with demo data...")
25 |     
26 |     # Create all tables
27 |     Base.metadata.create_all(engine)
28 |     
29 |     Session = sessionmaker(bind=engine)
30 |     session = Session()
31 | 
32 |     try:
33 |         # --- Default Clinic Setup ---
34 |         num_vets = 5
35 |         num_rooms = 5
36 | 
37 |         # Add Vets
38 |         for i in range(1, num_vets + 1):
39 |             session.add(Vet(name=f"Dr. Pawson {i}"))
40 | 
41 |         # Add Rooms
42 |         for i in range(1, num_rooms + 1):
43 |             session.add(Room(name=f"Exam Room {i}"))
44 |         
45 |         session.commit()
46 |         print(f"Successfully created {num_vets} vets and {num_rooms} rooms.")
47 | 
48 |     except Exception as e:
49 |         print(f"An error occurred during seeding: {e}")
50 |         session.rollback()
51 |     finally:
52 |         session.close()
53 | 
54 | if __name__ == "__main__":
55 |     seed_database()
```

backend/scheduler/ranker.py
```
1 | # backend/scheduler/ranker.py
2 | import json
3 | import requests
4 | import logging
5 | 
6 | # Configure logging
7 | logging.basicConfig(level=logging.INFO)
8 | logger = logging.getLogger(__name__)
9 | 
10 | # The Ollama API endpoint. Assumes Ollama is running on the host machine.
11 | # 'host.docker.internal' is a special DNS name that resolves to the host's IP from within a Docker container.
12 | # FIX: The URL was previously formatted as a Markdown link, which is invalid.
13 | OLLAMA_API_URL = "http://host.docker.internal:11434/api/generate"
14 | 
15 | def rank_slots_with_llm(feasible_slots, reason_for_visit):
16 |     """
17 |     Ranks a list of feasible appointment slots using a local LLM.
18 | 
19 |     Args:
20 |         feasible_slots (list): A list of dictionaries, each representing a slot.
21 |         reason_for_visit (str): The user-provided reason for the visit.
22 | 
23 |     Returns:
24 |         list: A sorted list of the top-ranked slots. Returns the original
25 |               list if the LLM call fails.
26 |     """
27 |     if not feasible_slots:
28 |         return []
29 | 
30 |     # Create a simplified list of slots for the prompt
31 |     prompt_slots = [
32 |         f"Slot {i+1}: Time {slot['start_time']}"
33 |         for i, slot in enumerate(feasible_slots)
34 |     ]
35 |     
36 |     prompt = f"""
37 | You are an expert veterinary clinic scheduler. Your task is to select the three best appointment times from a list of available slots based on the patient's reason for visit.
38 | 
39 | **Reason for Visit:** "{reason_for_visit}"
40 | 
41 | **Available Slots:**
42 | {json.dumps(prompt_slots, indent=2)}
43 | 
44 | **Instructions:**
45 | 1.  Analyze the "Reason for Visit". Consider urgency, potential need for a quiet environment, or if it's a routine check-up.
46 |     - Urgent-sounding requests (e.g., "not eating", "limping", "sick") should be prioritized for earlier slots.
47 |     - Routine visits (e.g., "annual checkup", "vaccinations") can be scheduled later.
48 |     - Anxious pets (e.g., "anxious cat", "scared of other dogs") might benefit from the very first slot of the day or the first slot after lunch when the clinic is quieter.
49 | 2.  Based on your analysis, choose the top 3 most suitable slots from the list.
50 | 3.  Return your response as a JSON object containing a single key "top_3_indices" with a list of the integer indices (1-based from the list above) of your chosen slots, from best to worst.
51 | 
52 | **Example Response Format:**
53 | {{
54 |   "top_3_indices": [5, 2, 10]
55 | }}
56 | 
57 | Now, provide the JSON for the given reason and slots.
58 | """
59 | 
60 |     payload = {
61 |         "model": "qwen:7b",
62 |         "prompt": prompt,
63 |         "format": "json",
64 |         "stream": False
65 |     }
66 | 
67 |     logger.info(f"Sending request to Ollama at {OLLAMA_API_URL}...")
68 |     try:
69 |         response = requests.post(OLLAMA_API_URL, json=payload, timeout=60) # Increased timeout
70 |         response.raise_for_status()
71 | 
72 |         response_text = response.json().get('response', '{}')
73 |         logger.info(f"Ollama raw response: {response_text}")
74 | 
75 |         # The response from Ollama is a string containing JSON, so we parse it.
76 |         ranked_data = json.loads(response_text)
77 |         
78 |         top_indices = ranked_data.get("top_3_indices")
79 | 
80 |         if not top_indices or not isinstance(top_indices, list):
81 |             logger.warning("LLM did not return valid indices. Returning original slot order.")
82 |             return feasible_slots
83 | 
84 |         # Convert 1-based indices from LLM to 0-based list indices
85 |         ranked_slots = [feasible_slots[i-1] for i in top_indices if 0 < i <= len(feasible_slots)]
86 |         return ranked_slots
87 | 
88 |     except requests.exceptions.RequestException as e:
89 |         logger.error(f"Could not connect to Ollama API: {e}")
90 |         # Fallback: return the original list if the LLM is unavailable
91 |         return feasible_slots
92 |     except (json.JSONDecodeError, KeyError) as e:
93 |         logger.error(f"Error parsing LLM response: {e}")
94 |         # Fallback: return the original list on malformed response
95 |         return feasible_slots
```

backend/scheduler/solver.py
```
1 | # backend/scheduler/solver.py
2 | from ortools.sat.python import cp_model
3 | from datetime import time, timedelta, datetime
4 | 
5 | def find_available_slots(appointment_date, vets, rooms, existing_appointments):
6 |     """
7 |     Uses Google OR-Tools CP-SAT solver to find all available 30-minute
8 |     appointment slots for a given day.
9 | 
10 |     Args:
11 |         appointment_date (date): The date to search for slots.
12 |         vets (list): List of Vet objects.
13 |         rooms (list): List of Room objects.
14 |         existing_appointments (list): List of Appointment objects for the given date.
15 | 
16 |     Returns:
17 |         list: A list of dictionaries, where each dictionary represents a
18 |               feasible appointment slot with 'vet_id', 'room_id', 'start_time',
19 |               and 'end_time'.
20 |     """
21 |     model = cp_model.CpModel()
22 | 
23 |     # --- Constants ---
24 |     # Working hours: 9:00 AM to 5:00 PM (17:00)
25 |     # We represent time in minutes from midnight for easier calculations.
26 |     day_start_min = 9 * 60  # 9:00 AM
27 |     day_end_min = 17 * 60 # 5:00 PM
28 |     appointment_duration = 30 # minutes
29 | 
30 |     vet_ids = [v.id for v in vets]
31 |     room_ids = [r.id for r in rooms]
32 | 
33 |     # --- Create Interval Variables for Existing Appointments ---
34 |     # These are fixed intervals that potential new appointments cannot overlap with.
35 |     vet_intervals = {v_id: [] for v_id in vet_ids}
36 |     room_intervals = {r_id: [] for r_id in room_ids}
37 | 
38 |     for appt in existing_appointments:
39 |         start_min = appt.start_time.hour * 60 + appt.start_time.minute
40 |         end_min = appt.end_time.hour * 60 + appt.end_time.minute
41 |         duration = end_min - start_min
42 |         
43 |         # Create a fixed interval for the vet
44 |         # FIX: The correct method name is NewIntervalVar. This was the source of the error.
45 |         vet_interval = model.NewIntervalVar(start_min, duration, start_min + duration, f"vet_{appt.vet_id}_appt_{appt.id}")
46 |         vet_intervals[appt.vet_id].append(vet_interval)
47 | 
48 |         # Create a fixed interval for the room
49 |         # FIX: The correct method name is NewIntervalVar.
50 |         room_interval = model.NewIntervalVar(start_min, duration, start_min + duration, f"room_{appt.room_id}_appt_{appt.id}")
51 |         room_intervals[appt.room_id].append(room_interval)
52 | 
53 |     # --- Create Potential Appointment Slots ---
54 |     # We create a potential 30-minute slot for every vet/room combination at every possible start time.
55 |     # The solver will then tell us which of these are feasible.
56 |     
57 |     possible_starts = range(day_start_min, day_end_min - appointment_duration + 1, 15) # Check every 15 mins
58 |     
59 |     # This will hold our potential slots: (task_literal, vet_id, room_id, start_time_min)
60 |     potential_slots = []
61 | 
62 |     for start_min in possible_starts:
63 |         for v_id in vet_ids:
64 |             for r_id in room_ids:
65 |                 # A boolean variable that is true if this specific slot is selected
66 |                 literal = model.NewBoolVar(f"slot_v{v_id}_r{r_id}_t{start_min}")
67 |                 
68 |                 # The interval for this potential slot
69 |                 # FIX: The correct method name is NewOptionalIntervalVar.
70 |                 interval = model.NewOptionalIntervalVar(
71 |                     start_min,
72 |                     appointment_duration,
73 |                     start_min + appointment_duration,
74 |                     literal,
75 |                     f"interval_v{v_id}_r{r_id}_t{start_min}"
76 |                 )
77 |                 
78 |                 # Add this potential slot to the lists for constraints
79 |                 vet_intervals[v_id].append(interval)
80 |                 room_intervals[r_id].append(interval)
81 |                 
82 |                 potential_slots.append((literal, v_id, r_id, start_min))
83 | 
84 |     # --- Add Constraints ---
85 |     # 1. No overlapping appointments for each vet
86 |     for v_id in vet_ids:
87 |         model.AddNoOverlap(vet_intervals[v_id])
88 | 
89 |     # 2. No overlapping appointments for each room
90 |     for r_id in room_ids:
91 |         model.AddNoOverlap(room_intervals[r_id])
92 | 
93 |     # --- Solver and Solution Collection ---
94 |     solver = cp_model.CpSolver()
95 |     
96 |     # We need a solution callback to find ALL feasible solutions, not just one.
97 |     class AllSolutionsCallback(cp_model.CpSolverSolutionCallback):
98 |         def __init__(self, variables):
99 |             cp_model.CpSolverSolutionCallback.__init__(self)
100 |             self.__variables = variables
101 |             self.solutions = []
102 | 
103 |         def on_solution_callback(self):
104 |             for var, v_id, r_id, start_min in self.__variables:
105 |                 if self.Value(var):
106 |                     start_time_obj = time(hour=start_min // 60, minute=start_min % 60)
107 |                     end_time_obj = (datetime.combine(datetime.today(), start_time_obj) + timedelta(minutes=appointment_duration)).time()
108 |                     self.solutions.append({
109 |                         "vet_id": v_id,
110 |                         "vet_name": f"Dr. Pawson {v_id}", # Demo name
111 |                         "room_id": r_id,
112 |                         "room_name": f"Exam Room {r_id}", # Demo name
113 |                         "date": appointment_date.strftime('%Y-%m-%d'),
114 |                         "start_time": start_time_obj.strftime('%H:%M'),
115 |                         "end_time": end_time_obj.strftime('%H:%M'),
116 |                     })
117 | 
118 |     solution_callback = AllSolutionsCallback(potential_slots)
119 |     solver.parameters.enumerate_all_solutions = True
120 |     status = solver.Solve(model, solution_callback)
121 |     
122 |     # Remove duplicate slots (can happen if multiple rooms/vets are free)
123 |     unique_solutions = []
124 |     seen_slots = set()
125 |     for sol in solution_callback.solutions:
126 |         slot_key = (sol['start_time'], sol['end_time'])
127 |         if slot_key not in seen_slots:
128 |             unique_solutions.append(sol)
129 |             seen_slots.add(slot_key)
130 | 
131 |     # Sort solutions by time
132 |     unique_solutions.sort(key=lambda x: x['start_time'])
133 | 
134 |     return unique_solutions
```

backend/templates/booking.html
```
1 | <!-- templates/booking.html -->
2 | <!DOCTYPE html>
3 | <html lang="en">
4 | <head>
5 |     <meta charset="UTF-8">
6 |     <meta name="viewport" content="width=device-width, initial-scale=1.0">
7 |     <title>Book an Appointment - Interpaws</title>
8 |     <script src="https://cdn.tailwindcss.com"></script>
9 |     <script src="https://unpkg.com/htmx.org@1.9.12"></script>
10 |     <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
11 |     <style>
12 |         body { font-family: 'Inter', sans-serif; }
13 |         /* HTMX spinner indicator styles */
14 |         .htmx-indicator {
15 |             display: none;
16 |             opacity: 0;
17 |             transition: opacity 200ms ease-in;
18 |         }
19 |         .htmx-request .htmx-indicator {
20 |             display: inline-block;
21 |             opacity: 1;
22 |         }
23 |         .htmx-request.htmx-indicator {
24 |             display: inline-block;
25 |             opacity: 1;
26 |         }
27 |     </style>
28 | </head>
29 | <body class="bg-slate-50 text-slate-800">
30 |     <div class="min-h-screen flex flex-col items-center p-4 pt-8">
31 |         <div class="w-full max-w-2xl">
32 |             <!-- Header -->
33 |             <div class="text-center mb-8">
34 |                 <h1 class="text-3xl font-bold text-indigo-600">Book an Appointment</h1>
35 |                 <p class="text-slate-500 mt-2">Let our AI assistant find the perfect slot for you.</p>
36 |             </div>
37 | 
38 |             <!-- Booking Form -->
39 |             <div class="bg-white p-8 rounded-xl shadow-md">
40 |                 <form 
41 |                     hx-post="/find-appointment" 
42 |                     hx-target="#results-container" 
43 |                     hx-indicator="#spinner"
44 |                     hx-swap="innerHTML">
45 |                     <div class="grid grid-cols-1 md:grid-cols-2 gap-6">
46 |                         <div>
47 |                             <label for="pet_name" class="block text-sm font-medium text-slate-700">Pet's Name</label>
48 |                             <input type="text" name="pet_name" id="pet_name" required value="Buddy" class="mt-1 block w-full px-3 py-2 bg-slate-50 border border-slate-300 rounded-md shadow-sm focus:outline-none focus:ring-indigo-500 focus:border-indigo-500">
49 |                         </div>
50 |                         <div>
51 |                             <label for="date" class="block text-sm font-medium text-slate-700">Appointment Date</label>
52 |                             <input type="date" name="date" id="date" required class="mt-1 block w-full px-3 py-2 bg-slate-50 border border-slate-300 rounded-md shadow-sm focus:outline-none focus:ring-indigo-500 focus:border-indigo-500">
53 |                         </div>
54 |                         <div class="md:col-span-2">
55 |                             <label for="reason" class="block text-sm font-medium text-slate-700">Reason for Visit</label>
56 |                             <textarea name="reason" id="reason" rows="3" required class="mt-1 block w-full px-3 py-2 bg-slate-50 border border-slate-300 rounded-md shadow-sm focus:outline-none focus:ring-indigo-500 focus:border-indigo-500" placeholder="e.g., Annual checkup, not eating, limping, anxious cat needs vaccinations...">My puppy is sick and throwing up.</textarea>
57 |                             <p class="text-xs text-slate-400 mt-1">This text will be sent to the AI to help it choose the best time.</p>
58 |                         </div>
59 |                     </div>
60 | 
61 |                     <div class="mt-8">
62 |                         <button type="submit" class="w-full flex items-center justify-center py-3 px-4 border border-transparent rounded-md shadow-sm text-sm font-medium text-white bg-indigo-600 hover:bg-indigo-700 focus:outline-none focus:ring-2 focus:ring-offset-2 focus:ring-indigo-500">
63 |                             <svg id="spinner" class="htmx-indicator animate-spin -ml-1 mr-3 h-5 w-5 text-white" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24">
64 |                                 <circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle>
65 |                                 <path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path>
66 |                             </svg>
67 |                             Find Available Slots
68 |                         </button>
69 |                     </div>
70 |                 </form>
71 |             </div>
72 |             
73 |             <!-- Results container will be populated by HTMX -->
74 |             <div id="results-container" class="mt-8">
75 |                 <!-- AI-ranked results will appear here -->
76 |             </div>
77 |         </div>
78 |     </div>
79 |     <script>
80 |         // Set default date to today
81 |         document.getElementById('date').valueAsDate = new Date();
82 |     </script>
83 | </body>
84 | </html>
```

backend/templates/results.html
```
1 | <!-- templates/results.html -->
2 | <!-- This is a partial template rendered by the /find-appointment route and injected by HTMX -->
3 | 
4 | <div class="space-y-4">
5 |     <h2 class="text-xl font-semibold text-center text-slate-700">Top 3 AI-Recommended Slots</h2>
6 |     {% for slot in slots %}
7 |     <div class="bg-white p-5 rounded-lg shadow-sm border border-slate-200 flex items-center justify-between">
8 |         <div>
9 |             <p class="text-lg font-bold text-indigo-600">{{ slot.start_time }}</p>
10 |             <p class="text-sm text-slate-500">{{ slot.vet_name }} in {{ slot.room_name }}</p>
11 |         </div>
12 |         <div>
13 |             <!-- This form will replace its parent div with the confirmation message from the server -->
14 |             <form hx-post="/book-appointment" hx-target="closest div" hx-swap="outerHTML">
15 |                 <input type="hidden" name="pet_name" value="{{ pet_name }}">
16 |                 <input type="hidden" name="reason" value="{{ reason }}">
17 |                 <input type="hidden" name="date" value="{{ date }}">
18 |                 <input type="hidden" name="time" value="{{ slot.start_time }}">
19 |                 <input type="hidden" name="vet_id" value="{{ slot.vet_id }}">
20 |                 <input type="hidden" name="room_id" value="{{ slot.room_id }}">
21 |                 <button type="submit" class="px-4 py-2 bg-emerald-500 text-white text-sm font-medium rounded-md hover:bg-emerald-600 focus:outline-none focus:ring-2 focus:ring-offset-2 focus:ring-emerald-500">
22 |                     Book Appointment
23 |                 </button>
24 |             </form>
25 |         </div>
26 |     </div>
27 |     {% else %}
28 |     <div class="bg-white p-5 rounded-lg shadow-sm border border-slate-200 text-center">
29 |         <p class="text-slate-600">We couldn't find any suitable appointments based on the criteria. Please try another date.</p>
30 |     </div>
31 |     {% endfor %}
32 | </div>
```

backend/templates/wizard.html
```
1 | <!-- backend/templates/wizard.html -->
2 | <!DOCTYPE html>
3 | <html lang="en">
4 | <head>
5 |     <meta charset="UTF-8">
6 |     <meta name="viewport" content="width=device-width, initial-scale=1.0">
7 |     <title>Clinic Setup Wizard - Interpaws</title>
8 |     <script src="https://cdn.tailwindcss.com"></script>
9 |     <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
10 |     <style>
11 |         body { font-family: 'Inter', sans-serif; }
12 |     </style>
13 | </head>
14 | <body class="bg-slate-50 text-slate-800">
15 |     <div class="min-h-screen flex flex-col items-center justify-center p-4">
16 |         <div class="w-full max-w-md">
17 |             <!-- Header -->
18 |             <div class="text-center mb-8">
19 |                 <h1 class="text-3xl font-bold text-indigo-600">Interpaws Demo Setup</h1>
20 |                 <p class="text-slate-500 mt-2">Create your demo clinic resources.</p>
21 |             </div>
22 | 
23 |             <!-- Wizard Form -->
24 |             <div class="bg-white p-8 rounded-xl shadow-md">
25 |                 <form action="/setup-clinic" method="POST">
26 |                     <div class="space-y-6">
27 |                         <div>
28 |                             <label for="vets" class="block text-sm font-medium text-slate-700">Number of Veterinarians</label>
29 |                             <div class="mt-1">
30 |                                 <input type="number" name="vets" id="vets" value="5" class="block w-full px-3 py-2 bg-slate-50 border border-slate-300 rounded-md shadow-sm placeholder-slate-400 focus:outline-none focus:ring-indigo-500 focus:border-indigo-500 sm:text-sm">
31 |                             </div>
32 |                         </div>
33 | 
34 |                         <div>
35 |                             <label for="rooms" class="block text-sm font-medium text-slate-700">Number of Exam Rooms</label>
36 |                             <div class="mt-1">
37 |                                 <input type="number" name="rooms" id="rooms" value="5" class="block w-full px-3 py-2 bg-slate-50 border border-slate-300 rounded-md shadow-sm placeholder-slate-400 focus:outline-none focus:ring-indigo-500 focus:border-indigo-500 sm:text-sm">
38 |                             </div>
39 |                         </div>
40 |                     </div>
41 | 
42 |                     <div class="mt-8">
43 |                         <button type="submit" class="w-full flex justify-center py-3 px-4 border border-transparent rounded-md shadow-sm text-sm font-medium text-white bg-indigo-600 hover:bg-indigo-700 focus:outline-none focus:ring-2 focus:ring-offset-2 focus:ring-indigo-500">
44 |                             Create Clinic & Start Demo
45 |                         </button>
46 |                     </div>
47 |                 </form>
48 |             </div>
49 |             <p class="text-center text-xs text-slate-400 mt-4">This step seeds the database with the specified resources.</p>
50 |         </div>
51 |     </div>
52 | </body>
53 | </html>
```

.venv/bin/Activate.ps1
```
1 | <#
2 | .Synopsis
3 | Activate a Python virtual environment for the current PowerShell session.
4 | 
5 | .Description
6 | Pushes the python executable for a virtual environment to the front of the
7 | $Env:PATH environment variable and sets the prompt to signify that you are
8 | in a Python virtual environment. Makes use of the command line switches as
9 | well as the `pyvenv.cfg` file values present in the virtual environment.
10 | 
11 | .Parameter VenvDir
12 | Path to the directory that contains the virtual environment to activate. The
13 | default value for this is the parent of the directory that the Activate.ps1
14 | script is located within.
15 | 
16 | .Parameter Prompt
17 | The prompt prefix to display when this virtual environment is activated. By
18 | default, this prompt is the name of the virtual environment folder (VenvDir)
19 | surrounded by parentheses and followed by a single space (ie. '(.venv) ').
20 | 
21 | .Example
22 | Activate.ps1
23 | Activates the Python virtual environment that contains the Activate.ps1 script.
24 | 
25 | .Example
26 | Activate.ps1 -Verbose
27 | Activates the Python virtual environment that contains the Activate.ps1 script,
28 | and shows extra information about the activation as it executes.
29 | 
30 | .Example
31 | Activate.ps1 -VenvDir C:\Users\MyUser\Common\.venv
32 | Activates the Python virtual environment located in the specified location.
33 | 
34 | .Example
35 | Activate.ps1 -Prompt "MyPython"
36 | Activates the Python virtual environment that contains the Activate.ps1 script,
37 | and prefixes the current prompt with the specified string (surrounded in
38 | parentheses) while the virtual environment is active.
39 | 
40 | .Notes
41 | On Windows, it may be required to enable this Activate.ps1 script by setting the
42 | execution policy for the user. You can do this by issuing the following PowerShell
43 | command:
44 | 
45 | PS C:\> Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser
46 | 
47 | For more information on Execution Policies: 
48 | https://go.microsoft.com/fwlink/?LinkID=135170
49 | 
50 | #>
51 | Param(
52 |     [Parameter(Mandatory = $false)]
53 |     [String]
54 |     $VenvDir,
55 |     [Parameter(Mandatory = $false)]
56 |     [String]
57 |     $Prompt
58 | )
59 | 
60 | <# Function declarations --------------------------------------------------- #>
61 | 
62 | <#
63 | .Synopsis
64 | Remove all shell session elements added by the Activate script, including the
65 | addition of the virtual environment's Python executable from the beginning of
66 | the PATH variable.
67 | 
68 | .Parameter NonDestructive
69 | If present, do not remove this function from the global namespace for the
70 | session.
71 | 
72 | #>
73 | function global:deactivate ([switch]$NonDestructive) {
74 |     # Revert to original values
75 | 
76 |     # The prior prompt:
77 |     if (Test-Path -Path Function:_OLD_VIRTUAL_PROMPT) {
78 |         Copy-Item -Path Function:_OLD_VIRTUAL_PROMPT -Destination Function:prompt
79 |         Remove-Item -Path Function:_OLD_VIRTUAL_PROMPT
80 |     }
81 | 
82 |     # The prior PYTHONHOME:
83 |     if (Test-Path -Path Env:_OLD_VIRTUAL_PYTHONHOME) {
84 |         Copy-Item -Path Env:_OLD_VIRTUAL_PYTHONHOME -Destination Env:PYTHONHOME
85 |         Remove-Item -Path Env:_OLD_VIRTUAL_PYTHONHOME
86 |     }
87 | 
88 |     # The prior PATH:
89 |     if (Test-Path -Path Env:_OLD_VIRTUAL_PATH) {
90 |         Copy-Item -Path Env:_OLD_VIRTUAL_PATH -Destination Env:PATH
91 |         Remove-Item -Path Env:_OLD_VIRTUAL_PATH
92 |     }
93 | 
94 |     # Just remove the VIRTUAL_ENV altogether:
95 |     if (Test-Path -Path Env:VIRTUAL_ENV) {
96 |         Remove-Item -Path env:VIRTUAL_ENV
97 |     }
98 | 
99 |     # Just remove VIRTUAL_ENV_PROMPT altogether.
100 |     if (Test-Path -Path Env:VIRTUAL_ENV_PROMPT) {
101 |         Remove-Item -Path env:VIRTUAL_ENV_PROMPT
102 |     }
103 | 
104 |     # Just remove the _PYTHON_VENV_PROMPT_PREFIX altogether:
105 |     if (Get-Variable -Name "_PYTHON_VENV_PROMPT_PREFIX" -ErrorAction SilentlyContinue) {
106 |         Remove-Variable -Name _PYTHON_VENV_PROMPT_PREFIX -Scope Global -Force
107 |     }
108 | 
109 |     # Leave deactivate function in the global namespace if requested:
110 |     if (-not $NonDestructive) {
111 |         Remove-Item -Path function:deactivate
112 |     }
113 | }
114 | 
115 | <#
116 | .Description
117 | Get-PyVenvConfig parses the values from the pyvenv.cfg file located in the
118 | given folder, and returns them in a map.
119 | 
120 | For each line in the pyvenv.cfg file, if that line can be parsed into exactly
121 | two strings separated by `=` (with any amount of whitespace surrounding the =)
122 | then it is considered a `key = value` line. The left hand string is the key,
123 | the right hand is the value.
124 | 
125 | If the value starts with a `'` or a `"` then the first and last character is
126 | stripped from the value before being captured.
127 | 
128 | .Parameter ConfigDir
129 | Path to the directory that contains the `pyvenv.cfg` file.
130 | #>
131 | function Get-PyVenvConfig(
132 |     [String]
133 |     $ConfigDir
134 | ) {
135 |     Write-Verbose "Given ConfigDir=$ConfigDir, obtain values in pyvenv.cfg"
136 | 
137 |     # Ensure the file exists, and issue a warning if it doesn't (but still allow the function to continue).
138 |     $pyvenvConfigPath = Join-Path -Resolve -Path $ConfigDir -ChildPath 'pyvenv.cfg' -ErrorAction Continue
139 | 
140 |     # An empty map will be returned if no config file is found.
141 |     $pyvenvConfig = @{ }
142 | 
143 |     if ($pyvenvConfigPath) {
144 | 
145 |         Write-Verbose "File exists, parse `key = value` lines"
146 |         $pyvenvConfigContent = Get-Content -Path $pyvenvConfigPath
147 | 
148 |         $pyvenvConfigContent | ForEach-Object {
149 |             $keyval = $PSItem -split "\s*=\s*", 2
150 |             if ($keyval[0] -and $keyval[1]) {
151 |                 $val = $keyval[1]
152 | 
153 |                 # Remove extraneous quotations around a string value.
154 |                 if ("'""".Contains($val.Substring(0, 1))) {
155 |                     $val = $val.Substring(1, $val.Length - 2)
156 |                 }
157 | 
158 |                 $pyvenvConfig[$keyval[0]] = $val
159 |                 Write-Verbose "Adding Key: '$($keyval[0])'='$val'"
160 |             }
161 |         }
162 |     }
163 |     return $pyvenvConfig
164 | }
165 | 
166 | 
167 | <# Begin Activate script --------------------------------------------------- #>
168 | 
169 | # Determine the containing directory of this script
170 | $VenvExecPath = Split-Path -Parent $MyInvocation.MyCommand.Definition
171 | $VenvExecDir = Get-Item -Path $VenvExecPath
172 | 
173 | Write-Verbose "Activation script is located in path: '$VenvExecPath'"
174 | Write-Verbose "VenvExecDir Fullname: '$($VenvExecDir.FullName)"
175 | Write-Verbose "VenvExecDir Name: '$($VenvExecDir.Name)"
176 | 
177 | # Set values required in priority: CmdLine, ConfigFile, Default
178 | # First, get the location of the virtual environment, it might not be
179 | # VenvExecDir if specified on the command line.
180 | if ($VenvDir) {
181 |     Write-Verbose "VenvDir given as parameter, using '$VenvDir' to determine values"
182 | }
183 | else {
184 |     Write-Verbose "VenvDir not given as a parameter, using parent directory name as VenvDir."
185 |     $VenvDir = $VenvExecDir.Parent.FullName.TrimEnd("\\/")
186 |     Write-Verbose "VenvDir=$VenvDir"
187 | }
188 | 
189 | # Next, read the `pyvenv.cfg` file to determine any required value such
190 | # as `prompt`.
191 | $pyvenvCfg = Get-PyVenvConfig -ConfigDir $VenvDir
192 | 
193 | # Next, set the prompt from the command line, or the config file, or
194 | # just use the name of the virtual environment folder.
195 | if ($Prompt) {
196 |     Write-Verbose "Prompt specified as argument, using '$Prompt'"
197 | }
198 | else {
199 |     Write-Verbose "Prompt not specified as argument to script, checking pyvenv.cfg value"
200 |     if ($pyvenvCfg -and $pyvenvCfg['prompt']) {
201 |         Write-Verbose "  Setting based on value in pyvenv.cfg='$($pyvenvCfg['prompt'])'"
202 |         $Prompt = $pyvenvCfg['prompt'];
203 |     }
204 |     else {
205 |         Write-Verbose "  Setting prompt based on parent's directory's name. (Is the directory name passed to venv module when creating the virtual environment)"
206 |         Write-Verbose "  Got leaf-name of $VenvDir='$(Split-Path -Path $venvDir -Leaf)'"
207 |         $Prompt = Split-Path -Path $venvDir -Leaf
208 |     }
209 | }
210 | 
211 | Write-Verbose "Prompt = '$Prompt'"
212 | Write-Verbose "VenvDir='$VenvDir'"
213 | 
214 | # Deactivate any currently active virtual environment, but leave the
215 | # deactivate function in place.
216 | deactivate -nondestructive
217 | 
218 | # Now set the environment variable VIRTUAL_ENV, used by many tools to determine
219 | # that there is an activated venv.
220 | $env:VIRTUAL_ENV = $VenvDir
221 | 
222 | $env:VIRTUAL_ENV_PROMPT = $Prompt
223 | 
224 | if (-not $Env:VIRTUAL_ENV_DISABLE_PROMPT) {
225 | 
226 |     Write-Verbose "Setting prompt to '$Prompt'"
227 | 
228 |     # Set the prompt to include the env name
229 |     # Make sure _OLD_VIRTUAL_PROMPT is global
230 |     function global:_OLD_VIRTUAL_PROMPT { "" }
231 |     Copy-Item -Path function:prompt -Destination function:_OLD_VIRTUAL_PROMPT
232 |     New-Variable -Name _PYTHON_VENV_PROMPT_PREFIX -Description "Python virtual environment prompt prefix" -Scope Global -Option ReadOnly -Visibility Public -Value $Prompt
233 | 
234 |     function global:prompt {
235 |         Write-Host -NoNewline -ForegroundColor Green "($_PYTHON_VENV_PROMPT_PREFIX) "
236 |         _OLD_VIRTUAL_PROMPT
237 |     }
238 | }
239 | 
240 | # Clear PYTHONHOME
241 | if (Test-Path -Path Env:PYTHONHOME) {
242 |     Copy-Item -Path Env:PYTHONHOME -Destination Env:_OLD_VIRTUAL_PYTHONHOME
243 |     Remove-Item -Path Env:PYTHONHOME
244 | }
245 | 
246 | # Add the venv to the PATH
247 | Copy-Item -Path Env:PATH -Destination Env:_OLD_VIRTUAL_PATH
248 | $Env:PATH = "$VenvExecDir$([System.IO.Path]::PathSeparator)$Env:PATH"
```

.venv/bin/activate
```
1 | # This file must be used with "source bin/activate" *from bash*
2 | # You cannot run it directly
3 | 
4 | deactivate () {
5 |     # reset old environment variables
6 |     if [ -n "${_OLD_VIRTUAL_PATH:-}" ] ; then
7 |         PATH="${_OLD_VIRTUAL_PATH:-}"
8 |         export PATH
9 |         unset _OLD_VIRTUAL_PATH
10 |     fi
11 |     if [ -n "${_OLD_VIRTUAL_PYTHONHOME:-}" ] ; then
12 |         PYTHONHOME="${_OLD_VIRTUAL_PYTHONHOME:-}"
13 |         export PYTHONHOME
14 |         unset _OLD_VIRTUAL_PYTHONHOME
15 |     fi
16 | 
17 |     # Call hash to forget past locations. Without forgetting
18 |     # past locations the $PATH changes we made may not be respected.
19 |     # See "man bash" for more details. hash is usually a builtin of your shell
20 |     hash -r 2> /dev/null
21 | 
22 |     if [ -n "${_OLD_VIRTUAL_PS1:-}" ] ; then
23 |         PS1="${_OLD_VIRTUAL_PS1:-}"
24 |         export PS1
25 |         unset _OLD_VIRTUAL_PS1
26 |     fi
27 | 
28 |     unset VIRTUAL_ENV
29 |     unset VIRTUAL_ENV_PROMPT
30 |     if [ ! "${1:-}" = "nondestructive" ] ; then
31 |     # Self destruct!
32 |         unset -f deactivate
33 |     fi
34 | }
35 | 
36 | # unset irrelevant variables
37 | deactivate nondestructive
38 | 
39 | # on Windows, a path can contain colons and backslashes and has to be converted:
40 | case "$(uname)" in
41 |     CYGWIN*|MSYS*|MINGW*)
42 |         # transform D:\path\to\venv to /d/path/to/venv on MSYS and MINGW
43 |         # and to /cygdrive/d/path/to/venv on Cygwin
44 |         VIRTUAL_ENV=$(cygpath /Users/amaribullard/Documents/GitHub/interpawsdemo/.venv)
45 |         export VIRTUAL_ENV
46 |         ;;
47 |     *)
48 |         # use the path as-is
49 |         export VIRTUAL_ENV=/Users/amaribullard/Documents/GitHub/interpawsdemo/.venv
50 |         ;;
51 | esac
52 | 
53 | _OLD_VIRTUAL_PATH="$PATH"
54 | PATH="$VIRTUAL_ENV/"bin":$PATH"
55 | export PATH
56 | 
57 | VIRTUAL_ENV_PROMPT=.venv
58 | export VIRTUAL_ENV_PROMPT
59 | 
60 | # unset PYTHONHOME if set
61 | # this will fail if PYTHONHOME is set to the empty string (which is bad anyway)
62 | # could use `if (set -u; : $PYTHONHOME) ;` in bash
63 | if [ -n "${PYTHONHOME:-}" ] ; then
64 |     _OLD_VIRTUAL_PYTHONHOME="${PYTHONHOME:-}"
65 |     unset PYTHONHOME
66 | fi
67 | 
68 | if [ -z "${VIRTUAL_ENV_DISABLE_PROMPT:-}" ] ; then
69 |     _OLD_VIRTUAL_PS1="${PS1:-}"
70 |     PS1="(".venv") ${PS1:-}"
71 |     export PS1
72 | fi
73 | 
74 | # Call hash to forget past commands. Without forgetting
75 | # past commands the $PATH changes we made may not be respected
76 | hash -r 2> /dev/null
```

.venv/bin/activate.csh
```
1 | # This file must be used with "source bin/activate.csh" *from csh*.
2 | # You cannot run it directly.
3 | 
4 | # Created by Davide Di Blasi <davidedb@gmail.com>.
5 | # Ported to Python 3.3 venv by Andrew Svetlov <andrew.svetlov@gmail.com>
6 | 
7 | alias deactivate 'test $?_OLD_VIRTUAL_PATH != 0 && setenv PATH "$_OLD_VIRTUAL_PATH" && unset _OLD_VIRTUAL_PATH; rehash; test $?_OLD_VIRTUAL_PROMPT != 0 && set prompt="$_OLD_VIRTUAL_PROMPT" && unset _OLD_VIRTUAL_PROMPT; unsetenv VIRTUAL_ENV; unsetenv VIRTUAL_ENV_PROMPT; test "\!:*" != "nondestructive" && unalias deactivate'
8 | 
9 | # Unset irrelevant variables.
10 | deactivate nondestructive
11 | 
12 | setenv VIRTUAL_ENV /Users/amaribullard/Documents/GitHub/interpawsdemo/.venv
13 | 
14 | set _OLD_VIRTUAL_PATH="$PATH"
15 | setenv PATH "$VIRTUAL_ENV/"bin":$PATH"
16 | setenv VIRTUAL_ENV_PROMPT .venv
17 | 
18 | 
19 | set _OLD_VIRTUAL_PROMPT="$prompt"
20 | 
21 | if (! "$?VIRTUAL_ENV_DISABLE_PROMPT") then
22 |     set prompt = "(".venv") $prompt:q"
23 | endif
24 | 
25 | alias pydoc python -m pydoc
26 | 
27 | rehash
```

.venv/bin/activate.fish
```
1 | # This file must be used with "source <venv>/bin/activate.fish" *from fish*
2 | # (https://fishshell.com/). You cannot run it directly.
3 | 
4 | function deactivate  -d "Exit virtual environment and return to normal shell environment"
5 |     # reset old environment variables
6 |     if test -n "$_OLD_VIRTUAL_PATH"
7 |         set -gx PATH $_OLD_VIRTUAL_PATH
8 |         set -e _OLD_VIRTUAL_PATH
9 |     end
10 |     if test -n "$_OLD_VIRTUAL_PYTHONHOME"
11 |         set -gx PYTHONHOME $_OLD_VIRTUAL_PYTHONHOME
12 |         set -e _OLD_VIRTUAL_PYTHONHOME
13 |     end
14 | 
15 |     if test -n "$_OLD_FISH_PROMPT_OVERRIDE"
16 |         set -e _OLD_FISH_PROMPT_OVERRIDE
17 |         # prevents error when using nested fish instances (Issue #93858)
18 |         if functions -q _old_fish_prompt
19 |             functions -e fish_prompt
20 |             functions -c _old_fish_prompt fish_prompt
21 |             functions -e _old_fish_prompt
22 |         end
23 |     end
24 | 
25 |     set -e VIRTUAL_ENV
26 |     set -e VIRTUAL_ENV_PROMPT
27 |     if test "$argv[1]" != "nondestructive"
28 |         # Self-destruct!
29 |         functions -e deactivate
30 |     end
31 | end
32 | 
33 | # Unset irrelevant variables.
34 | deactivate nondestructive
35 | 
36 | set -gx VIRTUAL_ENV /Users/amaribullard/Documents/GitHub/interpawsdemo/.venv
37 | 
38 | set -gx _OLD_VIRTUAL_PATH $PATH
39 | set -gx PATH "$VIRTUAL_ENV/"bin $PATH
40 | set -gx VIRTUAL_ENV_PROMPT .venv
41 | 
42 | # Unset PYTHONHOME if set.
43 | if set -q PYTHONHOME
44 |     set -gx _OLD_VIRTUAL_PYTHONHOME $PYTHONHOME
45 |     set -e PYTHONHOME
46 | end
47 | 
48 | if test -z "$VIRTUAL_ENV_DISABLE_PROMPT"
49 |     # fish uses a function instead of an env var to generate the prompt.
50 | 
51 |     # Save the current fish_prompt function as the function _old_fish_prompt.
52 |     functions -c fish_prompt _old_fish_prompt
53 | 
54 |     # With the original prompt function renamed, we can override with our own.
55 |     function fish_prompt
56 |         # Save the return status of the last command.
57 |         set -l old_status $status
58 | 
59 |         # Output the venv prompt; color taken from the blue of the Python logo.
60 |         printf "%s(%s)%s " (set_color 4B8BBE) .venv (set_color normal)
61 | 
62 |         # Restore the return status of the previous command.
63 |         echo "exit $old_status" | .
64 |         # Output the original/"old" prompt.
65 |         _old_fish_prompt
66 |     end
67 | 
68 |     set -gx _OLD_FISH_PROMPT_OVERRIDE "$VIRTUAL_ENV"
69 | end
```

.venv/bin/pip
```
1 | #!/Users/amaribullard/Documents/GitHub/interpawsdemo/.venv/bin/python3.13
2 | # -*- coding: utf-8 -*-
3 | import re
4 | import sys
5 | from pip._internal.cli.main import main
6 | if __name__ == '__main__':
7 |     sys.argv[0] = re.sub(r'(-script\.pyw|\.exe)?$', '', sys.argv[0])
8 |     sys.exit(main())
```

.venv/bin/pip3
```
1 | #!/Users/amaribullard/Documents/GitHub/interpawsdemo/.venv/bin/python3.13
2 | # -*- coding: utf-8 -*-
3 | import re
4 | import sys
5 | from pip._internal.cli.main import main
6 | if __name__ == '__main__':
7 |     sys.argv[0] = re.sub(r'(-script\.pyw|\.exe)?$', '', sys.argv[0])
8 |     sys.exit(main())
```

.venv/bin/pip3.13
```
1 | #!/Users/amaribullard/Documents/GitHub/interpawsdemo/.venv/bin/python3.13
2 | # -*- coding: utf-8 -*-
3 | import re
4 | import sys
5 | from pip._internal.cli.main import main
6 | if __name__ == '__main__':
7 |     sys.argv[0] = re.sub(r'(-script\.pyw|\.exe)?$', '', sys.argv[0])
8 |     sys.exit(main())
```

.venv/bin/python
```
1 |             0            H   __PAGEZERO                                                          __TEXT                  @               @                   __text          __TEXT          P           P                           __stubs         __TEXT          H            H                         __cstring       __TEXT                                                   __unwind_info   __TEXT               h                                          __DATA_CONST     @      @       @       @                  __got           __DATA_CONST     @             @                                 __DATA                 @                                   __bss           __DATA                                                         H   __LINKEDIT                          M                    4          3       0                0     P                                              P  %                             /usr/lib/dyld             |;g[1n2                     *              (     P                 x             /opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/Python           8           G   /usr/lib/libSystem.B.dylib      &           )                     H                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  _WO{     @C   `  5    @                TJ_8	_ qAT	 *@8_ q	  )% @   < < R @     3     5U   R       A  !    @ @       ! R R~    T@        @9 9A  !      9@      R Ri    Tc  R     !P      A  !  " R{  t  C   (  @@C    _     !  RN   O{  W   =    4 5R r  # ! RN   1  T@  TRI   )    3 5{BOA _    (  @@    AR" R(    R#    {   !@ R  {   !8  R  {   !   R    @   
2 | @   @   @   @   "@   &@   *@   .@   2@   6@   :@   >@   B@   F@   J@   N@ realpath: %s . / __PYVENV_LAUNCHER__ posix_spawn: %s Resources/Python.app/Contents/MacOS/Python posix_spawnattr_int posix_spawnattr_setbinpref posix_spawnattr_setbinpref failed to copy
3 |  posix_spawnattr_setflags                         P  @   @   H      @                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     	     
4 |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            P                                              @  @                  L  ^  t                 0 n        _Py_Initialize __NSGetExecutablePath ___error ___stderrp ___strlcat_chk _dladdr _environ _err _exit _fwrite _malloc _posix_spawn _posix_spawnattr_init _posix_spawnattr_setbinpref_np _posix_spawnattr_setflags _realpath$DARWIN_EXTSN _setenv _strcpy _strlen _strrchr         __mh_execute_header         header 	main              <   BEa                            '             =             F             Q             `             h             q             v             |                                                                                                                                                        	   
5 |                                                          	   
6 |                                             __mh_execute_header _Py_Initialize __NSGetExecutablePath ___error ___stderrp ___strlcat_chk _dladdr _environ _err _exit _fwrite _malloc _posix_spawn _posix_spawnattr_init _posix_spawnattr_setbinpref_np _posix_spawnattr_setflags _realpath$DARWIN_EXTSN _setenv _strcpy _strlen _strrchr radr://5614542            !          $                       X      	                                           @        python3-555549447c3b67815ba7316ea1b1fcffedf7dbb8 y NeuxJRNj-7C                                qgcHo$kj\ ,RA]xwO"!"0eqG|XofkOX||zH,XofkOX||zH,$G:t"xF%),DXofkOX||zH,XofkOX||zH,XofkOX||zH,5\MeC[e.@,7                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         
```

.venv/bin/python3
```
1 |             0            H   __PAGEZERO                                                          __TEXT                  @               @                   __text          __TEXT          P           P                           __stubs         __TEXT          H            H                         __cstring       __TEXT                                                   __unwind_info   __TEXT               h                                          __DATA_CONST     @      @       @       @                  __got           __DATA_CONST     @             @                                 __DATA                 @                                   __bss           __DATA                                                         H   __LINKEDIT                          M                    4          3       0                0     P                                              P  %                             /usr/lib/dyld             |;g[1n2                     *              (     P                 x             /opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/Python           8           G   /usr/lib/libSystem.B.dylib      &           )                     H                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  _WO{     @C   `  5    @                TJ_8	_ qAT	 *@8_ q	  )% @   < < R @     3     5U   R       A  !    @ @       ! R R~    T@        @9 9A  !      9@      R Ri    Tc  R     !P      A  !  " R{  t  C   (  @@C    _     !  RN   O{  W   =    4 5R r  # ! RN   1  T@  TRI   )    3 5{BOA _    (  @@    AR" R(    R#    {   !@ R  {   !8  R  {   !   R    @   
2 | @   @   @   @   "@   &@   *@   .@   2@   6@   :@   >@   B@   F@   J@   N@ realpath: %s . / __PYVENV_LAUNCHER__ posix_spawn: %s Resources/Python.app/Contents/MacOS/Python posix_spawnattr_int posix_spawnattr_setbinpref posix_spawnattr_setbinpref failed to copy
3 |  posix_spawnattr_setflags                         P  @   @   H      @                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     	     
4 |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            P                                              @  @                  L  ^  t                 0 n        _Py_Initialize __NSGetExecutablePath ___error ___stderrp ___strlcat_chk _dladdr _environ _err _exit _fwrite _malloc _posix_spawn _posix_spawnattr_init _posix_spawnattr_setbinpref_np _posix_spawnattr_setflags _realpath$DARWIN_EXTSN _setenv _strcpy _strlen _strrchr         __mh_execute_header         header 	main              <   BEa                            '             =             F             Q             `             h             q             v             |                                                                                                                                                        	   
5 |                                                          	   
6 |                                             __mh_execute_header _Py_Initialize __NSGetExecutablePath ___error ___stderrp ___strlcat_chk _dladdr _environ _err _exit _fwrite _malloc _posix_spawn _posix_spawnattr_init _posix_spawnattr_setbinpref_np _posix_spawnattr_setflags _realpath$DARWIN_EXTSN _setenv _strcpy _strlen _strrchr radr://5614542            !          $                       X      	                                           @        python3-555549447c3b67815ba7316ea1b1fcffedf7dbb8 y NeuxJRNj-7C                                qgcHo$kj\ ,RA]xwO"!"0eqG|XofkOX||zH,XofkOX||zH,$G:t"xF%),DXofkOX||zH,XofkOX||zH,XofkOX||zH,5\MeC[e.@,7                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         
```

.venv/bin/python3.13
```
1 |             0            H   __PAGEZERO                                                          __TEXT                  @               @                   __text          __TEXT          P           P                           __stubs         __TEXT          H            H                         __cstring       __TEXT                                                   __unwind_info   __TEXT               h                                          __DATA_CONST     @      @       @       @                  __got           __DATA_CONST     @             @                                 __DATA                 @                                   __bss           __DATA                                                         H   __LINKEDIT                          M                    4          3       0                0     P                                              P  %                             /usr/lib/dyld             |;g[1n2                     *              (     P                 x             /opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/Python           8           G   /usr/lib/libSystem.B.dylib      &           )                     H                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  _WO{     @C   `  5    @                TJ_8	_ qAT	 *@8_ q	  )% @   < < R @     3     5U   R       A  !    @ @       ! R R~    T@        @9 9A  !      9@      R Ri    Tc  R     !P      A  !  " R{  t  C   (  @@C    _     !  RN   O{  W   =    4 5R r  # ! RN   1  T@  TRI   )    3 5{BOA _    (  @@    AR" R(    R#    {   !@ R  {   !8  R  {   !   R    @   
2 | @   @   @   @   "@   &@   *@   .@   2@   6@   :@   >@   B@   F@   J@   N@ realpath: %s . / __PYVENV_LAUNCHER__ posix_spawn: %s Resources/Python.app/Contents/MacOS/Python posix_spawnattr_int posix_spawnattr_setbinpref posix_spawnattr_setbinpref failed to copy
3 |  posix_spawnattr_setflags                         P  @   @   H      @                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     	     
4 |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            P                                              @  @                  L  ^  t                 0 n        _Py_Initialize __NSGetExecutablePath ___error ___stderrp ___strlcat_chk _dladdr _environ _err _exit _fwrite _malloc _posix_spawn _posix_spawnattr_init _posix_spawnattr_setbinpref_np _posix_spawnattr_setflags _realpath$DARWIN_EXTSN _setenv _strcpy _strlen _strrchr         __mh_execute_header         header 	main              <   BEa                            '             =             F             Q             `             h             q             v             |                                                                                                                                                        	   
5 |                                                          	   
6 |                                             __mh_execute_header _Py_Initialize __NSGetExecutablePath ___error ___stderrp ___strlcat_chk _dladdr _environ _err _exit _fwrite _malloc _posix_spawn _posix_spawnattr_init _posix_spawnattr_setbinpref_np _posix_spawnattr_setflags _realpath$DARWIN_EXTSN _setenv _strcpy _strlen _strrchr radr://5614542            !          $                       X      	                                           @        python3-555549447c3b67815ba7316ea1b1fcffedf7dbb8 y NeuxJRNj-7C                                qgcHo$kj\ ,RA]xwO"!"0eqG|XofkOX||zH,XofkOX||zH,$G:t"xF%),DXofkOX||zH,XofkOX||zH,XofkOX||zH,5\MeC[e.@,7                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         
```

.venv/lib/python3.13/site-packages/pip/__init__.py
```
1 | from typing import List, Optional
2 | 
3 | __version__ = "25.1.1"
4 | 
5 | 
6 | def main(args: Optional[List[str]] = None) -> int:
7 |     """This is an internal API only meant for use by pip's own console scripts.
8 | 
9 |     For additional details, see https://github.com/pypa/pip/issues/7498.
10 |     """
11 |     from pip._internal.utils.entrypoints import _wrapper
12 | 
13 |     return _wrapper(args)
```

.venv/lib/python3.13/site-packages/pip/__main__.py
```
1 | import os
2 | import sys
3 | 
4 | # Remove '' and current working directory from the first entry
5 | # of sys.path, if present to avoid using current directory
6 | # in pip commands check, freeze, install, list and show,
7 | # when invoked as python -m pip <command>
8 | if sys.path[0] in ("", os.getcwd()):
9 |     sys.path.pop(0)
10 | 
11 | # If we are running from a wheel, add the wheel to sys.path
12 | # This allows the usage python pip-*.whl/pip install pip-*.whl
13 | if __package__ == "":
14 |     # __file__ is pip-*.whl/pip/__main__.py
15 |     # first dirname call strips of '/__main__.py', second strips off '/pip'
16 |     # Resulting path is the name of the wheel itself
17 |     # Add that to sys.path so we can import pip
18 |     path = os.path.dirname(os.path.dirname(__file__))
19 |     sys.path.insert(0, path)
20 | 
21 | if __name__ == "__main__":
22 |     from pip._internal.cli.main import main as _main
23 | 
24 |     sys.exit(_main())
```

.venv/lib/python3.13/site-packages/pip/__pip-runner__.py
```
1 | """Execute exactly this copy of pip, within a different environment.
2 | 
3 | This file is named as it is, to ensure that this module can't be imported via
4 | an import statement.
5 | """
6 | 
7 | # /!\ This version compatibility check section must be Python 2 compatible. /!\
8 | 
9 | import sys
10 | 
11 | # Copied from pyproject.toml
12 | PYTHON_REQUIRES = (3, 9)
13 | 
14 | 
15 | def version_str(version):  # type: ignore
16 |     return ".".join(str(v) for v in version)
17 | 
18 | 
19 | if sys.version_info[:2] < PYTHON_REQUIRES:
20 |     raise SystemExit(
21 |         "This version of pip does not support python {} (requires >={}).".format(
22 |             version_str(sys.version_info[:2]), version_str(PYTHON_REQUIRES)
23 |         )
24 |     )
25 | 
26 | # From here on, we can use Python 3 features, but the syntax must remain
27 | # Python 2 compatible.
28 | 
29 | import runpy  # noqa: E402
30 | from importlib.machinery import PathFinder  # noqa: E402
31 | from os.path import dirname  # noqa: E402
32 | 
33 | PIP_SOURCES_ROOT = dirname(dirname(__file__))
34 | 
35 | 
36 | class PipImportRedirectingFinder:
37 |     @classmethod
38 |     def find_spec(self, fullname, path=None, target=None):  # type: ignore
39 |         if fullname != "pip":
40 |             return None
41 | 
42 |         spec = PathFinder.find_spec(fullname, [PIP_SOURCES_ROOT], target)
43 |         assert spec, (PIP_SOURCES_ROOT, fullname)
44 |         return spec
45 | 
46 | 
47 | sys.meta_path.insert(0, PipImportRedirectingFinder())
48 | 
49 | assert __name__ == "__main__", "Cannot run __pip-runner__.py as a non-main module"
50 | runpy.run_module("pip", run_name="__main__", alter_sys=True)
```

.venv/lib/python3.13/site-packages/pip/py.typed
```
1 | pip is a command line program. While it is implemented in Python, and so is
2 | available for import, you must not use pip's internal APIs in this way. Typing
3 | information is provided as a convenience only and is not a guarantee. Expect
4 | unannounced changes to the API and types in releases.
```

.venv/lib/python3.13/site-packages/pip-25.1.1.dist-info/INSTALLER
```
1 | pip
```

.venv/lib/python3.13/site-packages/pip-25.1.1.dist-info/METADATA
```
1 | Metadata-Version: 2.4
2 | Name: pip
3 | Version: 25.1.1
4 | Summary: The PyPA recommended tool for installing Python packages.
5 | Author-email: The pip developers <distutils-sig@python.org>
6 | License: MIT
7 | Project-URL: Homepage, https://pip.pypa.io/
8 | Project-URL: Documentation, https://pip.pypa.io
9 | Project-URL: Source, https://github.com/pypa/pip
10 | Project-URL: Changelog, https://pip.pypa.io/en/stable/news/
11 | Classifier: Development Status :: 5 - Production/Stable
12 | Classifier: Intended Audience :: Developers
13 | Classifier: License :: OSI Approved :: MIT License
14 | Classifier: Topic :: Software Development :: Build Tools
15 | Classifier: Programming Language :: Python
16 | Classifier: Programming Language :: Python :: 3
17 | Classifier: Programming Language :: Python :: 3 :: Only
18 | Classifier: Programming Language :: Python :: 3.9
19 | Classifier: Programming Language :: Python :: 3.10
20 | Classifier: Programming Language :: Python :: 3.11
21 | Classifier: Programming Language :: Python :: 3.12
22 | Classifier: Programming Language :: Python :: 3.13
23 | Classifier: Programming Language :: Python :: Implementation :: CPython
24 | Classifier: Programming Language :: Python :: Implementation :: PyPy
25 | Requires-Python: >=3.9
26 | Description-Content-Type: text/x-rst
27 | License-File: LICENSE.txt
28 | License-File: AUTHORS.txt
29 | Dynamic: license-file
30 | 
31 | pip - The Python Package Installer
32 | ==================================
33 | 
34 | .. |pypi-version| image:: https://img.shields.io/pypi/v/pip.svg
35 |    :target: https://pypi.org/project/pip/
36 |    :alt: PyPI
37 | 
38 | .. |python-versions| image:: https://img.shields.io/pypi/pyversions/pip
39 |    :target: https://pypi.org/project/pip
40 |    :alt: PyPI - Python Version
41 | 
42 | .. |docs-badge| image:: https://readthedocs.org/projects/pip/badge/?version=latest
43 |    :target: https://pip.pypa.io/en/latest
44 |    :alt: Documentation
45 | 
46 | |pypi-version| |python-versions| |docs-badge|
47 | 
48 | pip is the `package installer`_ for Python. You can use pip to install packages from the `Python Package Index`_ and other indexes.
49 | 
50 | Please take a look at our documentation for how to install and use pip:
51 | 
52 | * `Installation`_
53 | * `Usage`_
54 | 
55 | We release updates regularly, with a new version every 3 months. Find more details in our documentation:
56 | 
57 | * `Release notes`_
58 | * `Release process`_
59 | 
60 | If you find bugs, need help, or want to talk to the developers, please use our mailing lists or chat rooms:
61 | 
62 | * `Issue tracking`_
63 | * `Discourse channel`_
64 | * `User IRC`_
65 | 
66 | If you want to get involved head over to GitHub to get the source code, look at our development documentation and feel free to jump on the developer mailing lists and chat rooms:
67 | 
68 | * `GitHub page`_
69 | * `Development documentation`_
70 | * `Development IRC`_
71 | 
72 | Code of Conduct
73 | ---------------
74 | 
75 | Everyone interacting in the pip project's codebases, issue trackers, chat
76 | rooms, and mailing lists is expected to follow the `PSF Code of Conduct`_.
77 | 
78 | .. _package installer: https://packaging.python.org/guides/tool-recommendations/
79 | .. _Python Package Index: https://pypi.org
80 | .. _Installation: https://pip.pypa.io/en/stable/installation/
81 | .. _Usage: https://pip.pypa.io/en/stable/
82 | .. _Release notes: https://pip.pypa.io/en/stable/news.html
83 | .. _Release process: https://pip.pypa.io/en/latest/development/release-process/
84 | .. _GitHub page: https://github.com/pypa/pip
85 | .. _Development documentation: https://pip.pypa.io/en/latest/development
86 | .. _Issue tracking: https://github.com/pypa/pip/issues
87 | .. _Discourse channel: https://discuss.python.org/c/packaging
88 | .. _User IRC: https://kiwiirc.com/nextclient/#ircs://irc.libera.chat:+6697/pypa
89 | .. _Development IRC: https://kiwiirc.com/nextclient/#ircs://irc.libera.chat:+6697/pypa-dev
90 | .. _PSF Code of Conduct: https://github.com/pypa/.github/blob/main/CODE_OF_CONDUCT.md
```

.venv/lib/python3.13/site-packages/pip-25.1.1.dist-info/RECORD
```
1 | ../../../bin/pip,sha256=qZqakgV_VTByRHChlxvOwlFxrWO84cG-sicbgLJBxYI,276
2 | ../../../bin/pip3,sha256=qZqakgV_VTByRHChlxvOwlFxrWO84cG-sicbgLJBxYI,276
3 | ../../../bin/pip3.13,sha256=qZqakgV_VTByRHChlxvOwlFxrWO84cG-sicbgLJBxYI,276
4 | pip-25.1.1.dist-info/INSTALLER,sha256=zuuue4knoyJ-UwPPXg8fezS7VCrXJQrAP7zeNuwvFQg,4
5 | pip-25.1.1.dist-info/METADATA,sha256=QFxj1tLpk8hGWrgQLRhJYUpwo_1FqBr43OT0srIZcmU,3649
6 | pip-25.1.1.dist-info/RECORD,,
7 | pip-25.1.1.dist-info/REQUESTED,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
8 | pip-25.1.1.dist-info/WHEEL,sha256=_zCd3N1l69ArxyTb8rzEoP9TpbYXkqRFSNOD5OuxnTs,91
9 | pip-25.1.1.dist-info/entry_points.txt,sha256=eeIjuzfnfR2PrhbjnbzFU6MnSS70kZLxwaHHq6M-bD0,87
10 | pip-25.1.1.dist-info/licenses/AUTHORS.txt,sha256=YzDFTYpeYnwpmODDFTgyKZNKWcfdO10L5Ex_U6kJLRc,11223
11 | pip-25.1.1.dist-info/licenses/LICENSE.txt,sha256=Y0MApmnUmurmWxLGxIySTFGkzfPR_whtw0VtyLyqIQQ,1093
12 | pip-25.1.1.dist-info/top_level.txt,sha256=zuuue4knoyJ-UwPPXg8fezS7VCrXJQrAP7zeNuwvFQg,4
13 | pip/__init__.py,sha256=zQQ7Na8YWi0IN86IUKEzDAJtyVpXdJXYDkQ536caUiQ,357
14 | pip/__main__.py,sha256=WzbhHXTbSE6gBY19mNN9m4s5o_365LOvTYSgqgbdBhE,854
15 | pip/__pip-runner__.py,sha256=JOoEZTwrtv7jRaXBkgSQKAE04yNyfFmGHxqpHiGHvL0,1450
16 | pip/__pycache__/__init__.cpython-313.pyc,,
17 | pip/__pycache__/__main__.cpython-313.pyc,,
18 | pip/__pycache__/__pip-runner__.cpython-313.pyc,,
19 | pip/_internal/__init__.py,sha256=MfcoOluDZ8QMCFYal04IqOJ9q6m2V7a0aOsnI-WOxUo,513
20 | pip/_internal/__pycache__/__init__.cpython-313.pyc,,
21 | pip/_internal/__pycache__/build_env.cpython-313.pyc,,
22 | pip/_internal/__pycache__/cache.cpython-313.pyc,,
23 | pip/_internal/__pycache__/configuration.cpython-313.pyc,,
24 | pip/_internal/__pycache__/exceptions.cpython-313.pyc,,
25 | pip/_internal/__pycache__/main.cpython-313.pyc,,
26 | pip/_internal/__pycache__/pyproject.cpython-313.pyc,,
27 | pip/_internal/__pycache__/self_outdated_check.cpython-313.pyc,,
28 | pip/_internal/__pycache__/wheel_builder.cpython-313.pyc,,
29 | pip/_internal/build_env.py,sha256=60_espLI9X3C2db3Ww2gIcyjNk2cAPNcc5gsVO4DOqg,10924
30 | pip/_internal/cache.py,sha256=SjhJK1C6NbonrU4AyYXKTOH0CGOk5cJrYt60mRANnPM,10368
31 | pip/_internal/cli/__init__.py,sha256=Iqg_tKA771XuMO1P4t_sDHnSKPzkUb9D0DqunAmw_ko,131
32 | pip/_internal/cli/__pycache__/__init__.cpython-313.pyc,,
33 | pip/_internal/cli/__pycache__/autocompletion.cpython-313.pyc,,
34 | pip/_internal/cli/__pycache__/base_command.cpython-313.pyc,,
35 | pip/_internal/cli/__pycache__/cmdoptions.cpython-313.pyc,,
36 | pip/_internal/cli/__pycache__/command_context.cpython-313.pyc,,
37 | pip/_internal/cli/__pycache__/index_command.cpython-313.pyc,,
38 | pip/_internal/cli/__pycache__/main.cpython-313.pyc,,
39 | pip/_internal/cli/__pycache__/main_parser.cpython-313.pyc,,
40 | pip/_internal/cli/__pycache__/parser.cpython-313.pyc,,
41 | pip/_internal/cli/__pycache__/progress_bars.cpython-313.pyc,,
42 | pip/_internal/cli/__pycache__/req_command.cpython-313.pyc,,
43 | pip/_internal/cli/__pycache__/spinners.cpython-313.pyc,,
44 | pip/_internal/cli/__pycache__/status_codes.cpython-313.pyc,,
45 | pip/_internal/cli/autocompletion.py,sha256=fs0Wy16Ga5tX1IZKvww5BDi7i5zyzfCPvu7cgXlgXys,6864
46 | pip/_internal/cli/base_command.py,sha256=0A8YuJVJh2YyXU8pdW0eidLg1eklCW5cU01mpI-FAxA,8351
47 | pip/_internal/cli/cmdoptions.py,sha256=-_V4gjMa0c3U8-vXKAyb5xVViJNzFAxBI3Zx_6Ds5-g,31909
48 | pip/_internal/cli/command_context.py,sha256=RHgIPwtObh5KhMrd3YZTkl8zbVG-6Okml7YbFX4Ehg0,774
49 | pip/_internal/cli/index_command.py,sha256=kplkusUgCZy75jNCo-etaDmSG8UvqcR2W50ALDdm6dk,5720
50 | pip/_internal/cli/main.py,sha256=1bXC7uL3tdb_EZlGVKs6_TgzC9tlKU7zhAZsbZA-IzY,2816
51 | pip/_internal/cli/main_parser.py,sha256=chZqNmCuO_JYt8ynBCumh4crURaRoXBZ0RxoSYQIwCw,4337
52 | pip/_internal/cli/parser.py,sha256=VCMtduzECUV87KaHNu-xJ-wLNL82yT3x16V4XBxOAqI,10825
53 | pip/_internal/cli/progress_bars.py,sha256=r9BD4T2-egcInB1Uh9Jjw3EP9F3INy5kZhGwSePm9jo,4435
54 | pip/_internal/cli/req_command.py,sha256=1yfssBvnUKNer8D7iT3OHqdJJNdCqRhwDqUFWgieppk,12934
55 | pip/_internal/cli/spinners.py,sha256=hIJ83GerdFgFCdobIA23Jggetegl_uC4Sp586nzFbPE,5118
56 | pip/_internal/cli/status_codes.py,sha256=sEFHUaUJbqv8iArL3HAtcztWZmGOFX01hTesSytDEh0,116
57 | pip/_internal/commands/__init__.py,sha256=3405KyFv4l0ruxeF69oosFanxNQcC_fHBGv7Rpt0PXg,4009
58 | pip/_internal/commands/__pycache__/__init__.cpython-313.pyc,,
59 | pip/_internal/commands/__pycache__/cache.cpython-313.pyc,,
60 | pip/_internal/commands/__pycache__/check.cpython-313.pyc,,
61 | pip/_internal/commands/__pycache__/completion.cpython-313.pyc,,
62 | pip/_internal/commands/__pycache__/configuration.cpython-313.pyc,,
63 | pip/_internal/commands/__pycache__/debug.cpython-313.pyc,,
64 | pip/_internal/commands/__pycache__/download.cpython-313.pyc,,
65 | pip/_internal/commands/__pycache__/freeze.cpython-313.pyc,,
66 | pip/_internal/commands/__pycache__/hash.cpython-313.pyc,,
67 | pip/_internal/commands/__pycache__/help.cpython-313.pyc,,
68 | pip/_internal/commands/__pycache__/index.cpython-313.pyc,,
69 | pip/_internal/commands/__pycache__/inspect.cpython-313.pyc,,
70 | pip/_internal/commands/__pycache__/install.cpython-313.pyc,,
71 | pip/_internal/commands/__pycache__/list.cpython-313.pyc,,
72 | pip/_internal/commands/__pycache__/lock.cpython-313.pyc,,
73 | pip/_internal/commands/__pycache__/search.cpython-313.pyc,,
74 | pip/_internal/commands/__pycache__/show.cpython-313.pyc,,
75 | pip/_internal/commands/__pycache__/uninstall.cpython-313.pyc,,
76 | pip/_internal/commands/__pycache__/wheel.cpython-313.pyc,,
77 | pip/_internal/commands/cache.py,sha256=IOezTicHjGE5sWdBx2nwPVgbjuJHM3s-BZEkpZLemuY,8107
78 | pip/_internal/commands/check.py,sha256=Hr_4eiMd9cgVDgEvjtIdw915NmL7ROIWW8enkr8slPQ,2268
79 | pip/_internal/commands/completion.py,sha256=W9QFQTPLjy2tPACJ_y3g9EgB1pbsh7pvCUX8ocuIdPg,4554
80 | pip/_internal/commands/configuration.py,sha256=n98enwp6y0b5G6fiRQjaZo43FlJKYve_daMhN-4BRNc,9766
81 | pip/_internal/commands/debug.py,sha256=DNDRgE9YsKrbYzU0s3VKi8rHtKF4X13CJ_br_8PUXO0,6797
82 | pip/_internal/commands/download.py,sha256=0qB0nys6ZEPsog451lDsjL5Bx7Z97t-B80oFZKhpzKM,5273
83 | pip/_internal/commands/freeze.py,sha256=YW-aMmAzzOaBWWobo9g4DPKuWp0dTC32lWMqXzKFLzE,3144
84 | pip/_internal/commands/hash.py,sha256=EVVOuvGtoPEdFi8SNnmdqlCQrhCxV-kJsdwtdcCnXGQ,1703
85 | pip/_internal/commands/help.py,sha256=gcc6QDkcgHMOuAn5UxaZwAStsRBrnGSn_yxjS57JIoM,1132
86 | pip/_internal/commands/index.py,sha256=8UucFVwx6FmM8cNbaPY8iI5kZdV3f6jhqDa-S8aGgpg,5068
87 | pip/_internal/commands/inspect.py,sha256=PGrY9TRTRCM3y5Ml8Bdk8DEOXquWRfscr4DRo1LOTPc,3189
88 | pip/_internal/commands/install.py,sha256=SRsiLpead7A8bLdxMqxTAJM3sUFHtgN9zgBT98UQz5E,29757
89 | pip/_internal/commands/list.py,sha256=Rwtf8B0d0-WrkM7Qsv41-dWg8I_r9BLuZV30wSWnzgU,13274
90 | pip/_internal/commands/lock.py,sha256=bUYrryKa769UXM61imojoeVVgc_1ZHK-9a0hIJmmlCg,5941
91 | pip/_internal/commands/search.py,sha256=IrfvxcRCSoZY9A5XAlCF1wtl_y2HPcXslQdHcjzwMNk,5784
92 | pip/_internal/commands/show.py,sha256=Yh5rGYhR2Io5TkL0fFCMWE1VqqM4xhPHjhbdS3QgEac,8028
93 | pip/_internal/commands/uninstall.py,sha256=7pOR7enK76gimyxQbzxcG1OsyLXL3DvX939xmM8Fvtg,3892
94 | pip/_internal/commands/wheel.py,sha256=NEfaVF4f41VBNSn93RL8gkfCEDmdGhbP9xu_dE6cdUk,6346
95 | pip/_internal/configuration.py,sha256=-KOok6jh3hFzXMPQFPJ1_EFjBpAsge-RSreQuLHLmzo,14005
96 | pip/_internal/distributions/__init__.py,sha256=Hq6kt6gXBgjNit5hTTWLAzeCNOKoB-N0pGYSqehrli8,858
97 | pip/_internal/distributions/__pycache__/__init__.cpython-313.pyc,,
98 | pip/_internal/distributions/__pycache__/base.cpython-313.pyc,,
99 | pip/_internal/distributions/__pycache__/installed.cpython-313.pyc,,
100 | pip/_internal/distributions/__pycache__/sdist.cpython-313.pyc,,
101 | pip/_internal/distributions/__pycache__/wheel.cpython-313.pyc,,
102 | pip/_internal/distributions/base.py,sha256=QeB9qvKXDIjLdPBDE5fMgpfGqMMCr-govnuoQnGuiF8,1783
103 | pip/_internal/distributions/installed.py,sha256=QinHFbWAQ8oE0pbD8MFZWkwlnfU1QYTccA1vnhrlYOU,842
104 | pip/_internal/distributions/sdist.py,sha256=PlcP4a6-R6c98XnOM-b6Lkb3rsvh9iG4ok8shaanrzs,6751
105 | pip/_internal/distributions/wheel.py,sha256=THBYfnv7VVt8mYhMYUtH13S1E7FDwtDyDfmUcl8ai0E,1317
106 | pip/_internal/exceptions.py,sha256=wpE11H0e4L9G6AH70sRG149z82X7wX530HK-9eA_DIQ,28464
107 | pip/_internal/index/__init__.py,sha256=tzwMH_fhQeubwMqHdSivasg1cRgTSbNg2CiMVnzMmyU,29
108 | pip/_internal/index/__pycache__/__init__.cpython-313.pyc,,
109 | pip/_internal/index/__pycache__/collector.cpython-313.pyc,,
110 | pip/_internal/index/__pycache__/package_finder.cpython-313.pyc,,
111 | pip/_internal/index/__pycache__/sources.cpython-313.pyc,,
112 | pip/_internal/index/collector.py,sha256=RdPO0JLAlmyBWPAWYHPyRoGjz3GNAeTngCNkbGey_mE,16265
113 | pip/_internal/index/package_finder.py,sha256=RohRzzLExoXl7QDdTiqyxIaQEcHUn6UNOr9KzC1vjL0,38446
114 | pip/_internal/index/sources.py,sha256=lPBLK5Xiy8Q6IQMio26Wl7ocfZOKkgGklIBNyUJ23fI,8632
115 | pip/_internal/locations/__init__.py,sha256=vvTMNxghT0aEXrSdqpNtuRDGx08bzJxfDAUUfQ0Vb0A,14309
116 | pip/_internal/locations/__pycache__/__init__.cpython-313.pyc,,
117 | pip/_internal/locations/__pycache__/_distutils.cpython-313.pyc,,
118 | pip/_internal/locations/__pycache__/_sysconfig.cpython-313.pyc,,
119 | pip/_internal/locations/__pycache__/base.cpython-313.pyc,,
120 | pip/_internal/locations/_distutils.py,sha256=x6nyVLj7X11Y4khIdf-mFlxMl2FWadtVEgeb8upc_WI,6013
121 | pip/_internal/locations/_sysconfig.py,sha256=IGzds60qsFneRogC-oeBaY7bEh3lPt_v47kMJChQXsU,7724
122 | pip/_internal/locations/base.py,sha256=RQiPi1d4FVM2Bxk04dQhXZ2PqkeljEL2fZZ9SYqIQ78,2556
123 | pip/_internal/main.py,sha256=r-UnUe8HLo5XFJz8inTcOOTiu_sxNhgHb6VwlGUllOI,340
124 | pip/_internal/metadata/__init__.py,sha256=nGWuZvjQlIHudlMz_-bsUs2LDA2ZKNPGevZoEGcd64Y,5723
125 | pip/_internal/metadata/__pycache__/__init__.cpython-313.pyc,,
126 | pip/_internal/metadata/__pycache__/_json.cpython-313.pyc,,
127 | pip/_internal/metadata/__pycache__/base.cpython-313.pyc,,
128 | pip/_internal/metadata/__pycache__/pkg_resources.cpython-313.pyc,,
129 | pip/_internal/metadata/_json.py,sha256=ezrIYazHCINM2QUk1eA9wEAMj3aeGWeDVgGalgUzKpc,2707
130 | pip/_internal/metadata/base.py,sha256=jCbzdIc8MgWnPR4rfrvSQhSVzSoOyKOXhj3xe8BoG8c,25467
131 | pip/_internal/metadata/importlib/__init__.py,sha256=jUUidoxnHcfITHHaAWG1G2i5fdBYklv_uJcjo2x7VYE,135
132 | pip/_internal/metadata/importlib/__pycache__/__init__.cpython-313.pyc,,
133 | pip/_internal/metadata/importlib/__pycache__/_compat.cpython-313.pyc,,
134 | pip/_internal/metadata/importlib/__pycache__/_dists.cpython-313.pyc,,
135 | pip/_internal/metadata/importlib/__pycache__/_envs.cpython-313.pyc,,
136 | pip/_internal/metadata/importlib/_compat.py,sha256=c6av8sP8BBjAZuFSJow1iWfygUXNM3xRTCn5nqw6B9M,2796
137 | pip/_internal/metadata/importlib/_dists.py,sha256=ftmYiyfUGUIjnVwt6W-Ijsimy5c28KgmXly5Q5IQ2P4,8279
138 | pip/_internal/metadata/importlib/_envs.py,sha256=X63CkdAPJCYPhefYSLiQzPf9ijMXm5nL_A_Z68yp2-w,5297
139 | pip/_internal/metadata/pkg_resources.py,sha256=U07ETAINSGeSRBfWUG93E4tZZbaW_f7PGzEqZN0hulc,10542
140 | pip/_internal/models/__init__.py,sha256=AjmCEBxX_MH9f_jVjIGNCFJKYCYeSEe18yyvNx4uRKQ,62
141 | pip/_internal/models/__pycache__/__init__.cpython-313.pyc,,
142 | pip/_internal/models/__pycache__/candidate.cpython-313.pyc,,
143 | pip/_internal/models/__pycache__/direct_url.cpython-313.pyc,,
144 | pip/_internal/models/__pycache__/format_control.cpython-313.pyc,,
145 | pip/_internal/models/__pycache__/index.cpython-313.pyc,,
146 | pip/_internal/models/__pycache__/installation_report.cpython-313.pyc,,
147 | pip/_internal/models/__pycache__/link.cpython-313.pyc,,
148 | pip/_internal/models/__pycache__/pylock.cpython-313.pyc,,
149 | pip/_internal/models/__pycache__/scheme.cpython-313.pyc,,
150 | pip/_internal/models/__pycache__/search_scope.cpython-313.pyc,,
151 | pip/_internal/models/__pycache__/selection_prefs.cpython-313.pyc,,
152 | pip/_internal/models/__pycache__/target_python.cpython-313.pyc,,
153 | pip/_internal/models/__pycache__/wheel.cpython-313.pyc,,
154 | pip/_internal/models/candidate.py,sha256=zzgFRuw_kWPjKpGw7LC0ZUMD2CQ2EberUIYs8izjdCA,753
155 | pip/_internal/models/direct_url.py,sha256=lJ1fIVTgk5UG5SzTNR0FpgSGAQjChlH-3otgiEJAhIs,6576
156 | pip/_internal/models/format_control.py,sha256=wtsQqSK9HaUiNxQEuB-C62eVimw6G4_VQFxV9-_KDBE,2486
157 | pip/_internal/models/index.py,sha256=tYnL8oxGi4aSNWur0mG8DAP7rC6yuha_MwJO8xw0crI,1030
158 | pip/_internal/models/installation_report.py,sha256=zRVZoaz-2vsrezj_H3hLOhMZCK9c7TbzWgC-jOalD00,2818
159 | pip/_internal/models/link.py,sha256=wIAgxhiu05ycLhbtAibknXX5L6X9ju_PPLVnMcvh9B4,21511
160 | pip/_internal/models/pylock.py,sha256=n3-I26bf2v-Kn6qcx4ATB_Zel2SLhaUxZBmsMeGgYAo,6196
161 | pip/_internal/models/scheme.py,sha256=PakmHJM3e8OOWSZFtfz1Az7f1meONJnkGuQxFlt3wBE,575
162 | pip/_internal/models/search_scope.py,sha256=67NEnsYY84784S-MM7ekQuo9KXLH-7MzFntXjapvAo0,4531
163 | pip/_internal/models/selection_prefs.py,sha256=qaFfDs3ciqoXPg6xx45N1jPLqccLJw4N0s4P0PyHTQ8,2015
164 | pip/_internal/models/target_python.py,sha256=2XaH2rZ5ZF-K5wcJbEMGEl7SqrTToDDNkrtQ2v_v_-Q,4271
165 | pip/_internal/models/wheel.py,sha256=10NUTXIRjf2P8oe1Wzolv8oUv7-YurrOduVFUIaDhdM,5506
166 | pip/_internal/network/__init__.py,sha256=FMy06P__y6jMjUc8z3ZcQdKF-pmZ2zM14_vBeHPGhUI,49
167 | pip/_internal/network/__pycache__/__init__.cpython-313.pyc,,
168 | pip/_internal/network/__pycache__/auth.cpython-313.pyc,,
169 | pip/_internal/network/__pycache__/cache.cpython-313.pyc,,
170 | pip/_internal/network/__pycache__/download.cpython-313.pyc,,
171 | pip/_internal/network/__pycache__/lazy_wheel.cpython-313.pyc,,
172 | pip/_internal/network/__pycache__/session.cpython-313.pyc,,
173 | pip/_internal/network/__pycache__/utils.cpython-313.pyc,,
174 | pip/_internal/network/__pycache__/xmlrpc.cpython-313.pyc,,
175 | pip/_internal/network/auth.py,sha256=D4gASjUrqoDFlSt6gQ767KAAjv6PUyJU0puDlhXNVRE,20809
176 | pip/_internal/network/cache.py,sha256=JGYT-BUaSMdEBwII_K1UE6qyBItz7hzGkyLl_JRzkBY,4613
177 | pip/_internal/network/download.py,sha256=6IdZyoERWIsXXFUFL_h_e_xi8Z0G0UlpkodPy8qKv2U,11078
178 | pip/_internal/network/lazy_wheel.py,sha256=PBdoMoNQQIA84Fhgne38jWF52W4x_KtsHjxgv4dkRKA,7622
179 | pip/_internal/network/session.py,sha256=msM4es16LmmNEYNkrYyg8fTc7gAHbKFltawfKP27LOI,18771
180 | pip/_internal/network/utils.py,sha256=Inaxel-NxBu4PQWkjyErdnfewsFCcgHph7dzR1-FboY,4088
181 | pip/_internal/network/xmlrpc.py,sha256=jW9oDSWamMld3iZOO9RbonVC8ZStkHyppCszoevkuJg,1837
182 | pip/_internal/operations/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
183 | pip/_internal/operations/__pycache__/__init__.cpython-313.pyc,,
184 | pip/_internal/operations/__pycache__/check.cpython-313.pyc,,
185 | pip/_internal/operations/__pycache__/freeze.cpython-313.pyc,,
186 | pip/_internal/operations/__pycache__/prepare.cpython-313.pyc,,
187 | pip/_internal/operations/build/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
188 | pip/_internal/operations/build/__pycache__/__init__.cpython-313.pyc,,
189 | pip/_internal/operations/build/__pycache__/build_tracker.cpython-313.pyc,,
190 | pip/_internal/operations/build/__pycache__/metadata.cpython-313.pyc,,
191 | pip/_internal/operations/build/__pycache__/metadata_editable.cpython-313.pyc,,
192 | pip/_internal/operations/build/__pycache__/metadata_legacy.cpython-313.pyc,,
193 | pip/_internal/operations/build/__pycache__/wheel.cpython-313.pyc,,
194 | pip/_internal/operations/build/__pycache__/wheel_editable.cpython-313.pyc,,
195 | pip/_internal/operations/build/__pycache__/wheel_legacy.cpython-313.pyc,,
196 | pip/_internal/operations/build/build_tracker.py,sha256=-ARW_TcjHCOX7D2NUOGntB4Fgc6b4aolsXkAK6BWL7w,4774
197 | pip/_internal/operations/build/metadata.py,sha256=INHaeiRfOiLYCXApfDNRo9Cw2xI4VwTc0KItvfdfOjk,1421
198 | pip/_internal/operations/build/metadata_editable.py,sha256=oWudMsnjy4loO_Jy7g4N9nxsnaEX_iDlVRgCy7pu1rs,1509
199 | pip/_internal/operations/build/metadata_legacy.py,sha256=wv8cFA0wTqF62Jlm9QwloYZsofOyQ7sWBBmvCcVvn1k,2189
200 | pip/_internal/operations/build/wheel.py,sha256=sT12FBLAxDC6wyrDorh8kvcZ1jG5qInCRWzzP-UkJiQ,1075
201 | pip/_internal/operations/build/wheel_editable.py,sha256=yOtoH6zpAkoKYEUtr8FhzrYnkNHQaQBjWQ2HYae1MQg,1417
202 | pip/_internal/operations/build/wheel_legacy.py,sha256=KXpyGYoCQYcudXNZvohLXgWHaCk4Gf3z0dbS9ol4uu0,3620
203 | pip/_internal/operations/check.py,sha256=4cnD_2eglsDe5s2CoYkxDt4HcRitTywzLMfTZ-tGQ4U,5911
204 | pip/_internal/operations/freeze.py,sha256=1_M79jAQKnCxWr-KCCmHuVXOVFGaUJHmoWLfFzgh7K4,9843
205 | pip/_internal/operations/install/__init__.py,sha256=ak-UETcQPKlFZaWoYKWu5QVXbpFBvg0sXc3i0O4vSYY,50
206 | pip/_internal/operations/install/__pycache__/__init__.cpython-313.pyc,,
207 | pip/_internal/operations/install/__pycache__/editable_legacy.cpython-313.pyc,,
208 | pip/_internal/operations/install/__pycache__/wheel.cpython-313.pyc,,
209 | pip/_internal/operations/install/editable_legacy.py,sha256=TI6wT8sLqDTprWZLYEOBOe7a6-1B9uwKb7kTBxLIaWY,1282
210 | pip/_internal/operations/install/wheel.py,sha256=4NYSQ9ypl69iiduh5gUPCK3WNYqouTHZ0rMXoVgkiZw,27553
211 | pip/_internal/operations/prepare.py,sha256=-i9dYwwJJjN7h6sZTabcz84tizgn7EAsY0sHnLAfs3Q,28363
212 | pip/_internal/pyproject.py,sha256=GLJ6rWRS5_2noKdajohoLyDty57Z7QXhcUAYghmTnWc,7286
213 | pip/_internal/req/__init__.py,sha256=dX2QGlfDwEqE5pLjOeM-f2qEgXFn6f2Vdi_zIHAYy1k,3096
214 | pip/_internal/req/__pycache__/__init__.cpython-313.pyc,,
215 | pip/_internal/req/__pycache__/constructors.cpython-313.pyc,,
[TRUNCATED]
```

.venv/lib/python3.13/site-packages/pip-25.1.1.dist-info/REQUESTED
```
```

.venv/lib/python3.13/site-packages/pip-25.1.1.dist-info/WHEEL
```
1 | Wheel-Version: 1.0
2 | Generator: setuptools (80.9.0)
3 | Root-Is-Purelib: true
4 | Tag: py3-none-any
5 | 
```

.venv/lib/python3.13/site-packages/pip-25.1.1.dist-info/entry_points.txt
```
1 | [console_scripts]
2 | pip = pip._internal.cli.main:main
3 | pip3 = pip._internal.cli.main:main
```

.venv/lib/python3.13/site-packages/pip-25.1.1.dist-info/top_level.txt
```
1 | pip
```

.venv/lib/python3.13/site-packages/pip/_internal/__init__.py
```
1 | from typing import List, Optional
2 | 
3 | from pip._internal.utils import _log
4 | 
5 | # init_logging() must be called before any call to logging.getLogger()
6 | # which happens at import of most modules.
7 | _log.init_logging()
8 | 
9 | 
10 | def main(args: Optional[List[str]] = None) -> int:
11 |     """This is preserved for old console scripts that may still be referencing
12 |     it.
13 | 
14 |     For additional details, see https://github.com/pypa/pip/issues/7498.
15 |     """
16 |     from pip._internal.utils.entrypoints import _wrapper
17 | 
18 |     return _wrapper(args)
```

.venv/lib/python3.13/site-packages/pip/_internal/build_env.py
```
1 | """Build Environment used for isolation during sdist building"""
2 | 
3 | import logging
4 | import os
5 | import pathlib
6 | import site
7 | import sys
8 | import textwrap
9 | from collections import OrderedDict
10 | from types import TracebackType
11 | from typing import TYPE_CHECKING, Iterable, List, Optional, Set, Tuple, Type, Union
12 | 
13 | from pip._vendor.packaging.version import Version
14 | 
15 | from pip import __file__ as pip_location
16 | from pip._internal.cli.spinners import open_spinner
17 | from pip._internal.locations import get_platlib, get_purelib, get_scheme
18 | from pip._internal.metadata import get_default_environment, get_environment
19 | from pip._internal.utils.logging import VERBOSE
20 | from pip._internal.utils.packaging import get_requirement
21 | from pip._internal.utils.subprocess import call_subprocess
22 | from pip._internal.utils.temp_dir import TempDirectory, tempdir_kinds
23 | 
24 | if TYPE_CHECKING:
25 |     from pip._internal.index.package_finder import PackageFinder
26 | 
27 | logger = logging.getLogger(__name__)
28 | 
29 | 
30 | def _dedup(a: str, b: str) -> Union[Tuple[str], Tuple[str, str]]:
31 |     return (a, b) if a != b else (a,)
32 | 
33 | 
34 | class _Prefix:
35 |     def __init__(self, path: str) -> None:
36 |         self.path = path
37 |         self.setup = False
38 |         scheme = get_scheme("", prefix=path)
39 |         self.bin_dir = scheme.scripts
40 |         self.lib_dirs = _dedup(scheme.purelib, scheme.platlib)
41 | 
42 | 
43 | def get_runnable_pip() -> str:
44 |     """Get a file to pass to a Python executable, to run the currently-running pip.
45 | 
46 |     This is used to run a pip subprocess, for installing requirements into the build
47 |     environment.
48 |     """
49 |     source = pathlib.Path(pip_location).resolve().parent
50 | 
51 |     if not source.is_dir():
52 |         # This would happen if someone is using pip from inside a zip file. In that
53 |         # case, we can use that directly.
54 |         return str(source)
55 | 
56 |     return os.fsdecode(source / "__pip-runner__.py")
57 | 
58 | 
59 | def _get_system_sitepackages() -> Set[str]:
60 |     """Get system site packages
61 | 
62 |     Usually from site.getsitepackages,
63 |     but fallback on `get_purelib()/get_platlib()` if unavailable
64 |     (e.g. in a virtualenv created by virtualenv<20)
65 | 
66 |     Returns normalized set of strings.
67 |     """
68 |     if hasattr(site, "getsitepackages"):
69 |         system_sites = site.getsitepackages()
70 |     else:
71 |         # virtualenv < 20 overwrites site.py without getsitepackages
72 |         # fallback on get_purelib/get_platlib.
73 |         # this is known to miss things, but shouldn't in the cases
74 |         # where getsitepackages() has been removed (inside a virtualenv)
75 |         system_sites = [get_purelib(), get_platlib()]
76 |     return {os.path.normcase(path) for path in system_sites}
77 | 
78 | 
79 | class BuildEnvironment:
80 |     """Creates and manages an isolated environment to install build deps"""
81 | 
82 |     def __init__(self) -> None:
83 |         temp_dir = TempDirectory(kind=tempdir_kinds.BUILD_ENV, globally_managed=True)
84 | 
85 |         self._prefixes = OrderedDict(
86 |             (name, _Prefix(os.path.join(temp_dir.path, name)))
87 |             for name in ("normal", "overlay")
88 |         )
89 | 
90 |         self._bin_dirs: List[str] = []
91 |         self._lib_dirs: List[str] = []
92 |         for prefix in reversed(list(self._prefixes.values())):
93 |             self._bin_dirs.append(prefix.bin_dir)
94 |             self._lib_dirs.extend(prefix.lib_dirs)
95 | 
96 |         # Customize site to:
97 |         # - ensure .pth files are honored
98 |         # - prevent access to system site packages
99 |         system_sites = _get_system_sitepackages()
100 | 
101 |         self._site_dir = os.path.join(temp_dir.path, "site")
102 |         if not os.path.exists(self._site_dir):
103 |             os.mkdir(self._site_dir)
104 |         with open(
105 |             os.path.join(self._site_dir, "sitecustomize.py"), "w", encoding="utf-8"
106 |         ) as fp:
107 |             fp.write(
108 |                 textwrap.dedent(
109 |                     """
110 |                 import os, site, sys
111 | 
112 |                 # First, drop system-sites related paths.
113 |                 original_sys_path = sys.path[:]
114 |                 known_paths = set()
115 |                 for path in {system_sites!r}:
116 |                     site.addsitedir(path, known_paths=known_paths)
117 |                 system_paths = set(
118 |                     os.path.normcase(path)
119 |                     for path in sys.path[len(original_sys_path):]
120 |                 )
121 |                 original_sys_path = [
122 |                     path for path in original_sys_path
123 |                     if os.path.normcase(path) not in system_paths
124 |                 ]
125 |                 sys.path = original_sys_path
126 | 
127 |                 # Second, add lib directories.
128 |                 # ensuring .pth file are processed.
129 |                 for path in {lib_dirs!r}:
130 |                     assert not path in sys.path
131 |                     site.addsitedir(path)
132 |                 """
133 |                 ).format(system_sites=system_sites, lib_dirs=self._lib_dirs)
134 |             )
135 | 
136 |     def __enter__(self) -> None:
137 |         self._save_env = {
138 |             name: os.environ.get(name, None)
139 |             for name in ("PATH", "PYTHONNOUSERSITE", "PYTHONPATH")
140 |         }
141 | 
142 |         path = self._bin_dirs[:]
143 |         old_path = self._save_env["PATH"]
144 |         if old_path:
145 |             path.extend(old_path.split(os.pathsep))
146 | 
147 |         pythonpath = [self._site_dir]
148 | 
149 |         os.environ.update(
150 |             {
151 |                 "PATH": os.pathsep.join(path),
152 |                 "PYTHONNOUSERSITE": "1",
153 |                 "PYTHONPATH": os.pathsep.join(pythonpath),
154 |             }
155 |         )
156 | 
157 |     def __exit__(
158 |         self,
159 |         exc_type: Optional[Type[BaseException]],
160 |         exc_val: Optional[BaseException],
161 |         exc_tb: Optional[TracebackType],
162 |     ) -> None:
163 |         for varname, old_value in self._save_env.items():
164 |             if old_value is None:
165 |                 os.environ.pop(varname, None)
166 |             else:
167 |                 os.environ[varname] = old_value
168 | 
169 |     def check_requirements(
170 |         self, reqs: Iterable[str]
171 |     ) -> Tuple[Set[Tuple[str, str]], Set[str]]:
172 |         """Return 2 sets:
173 |         - conflicting requirements: set of (installed, wanted) reqs tuples
174 |         - missing requirements: set of reqs
175 |         """
176 |         missing = set()
177 |         conflicting = set()
178 |         if reqs:
179 |             env = (
180 |                 get_environment(self._lib_dirs)
181 |                 if hasattr(self, "_lib_dirs")
182 |                 else get_default_environment()
183 |             )
184 |             for req_str in reqs:
185 |                 req = get_requirement(req_str)
186 |                 # We're explicitly evaluating with an empty extra value, since build
187 |                 # environments are not provided any mechanism to select specific extras.
188 |                 if req.marker is not None and not req.marker.evaluate({"extra": ""}):
189 |                     continue
190 |                 dist = env.get_distribution(req.name)
191 |                 if not dist:
192 |                     missing.add(req_str)
193 |                     continue
194 |                 if isinstance(dist.version, Version):
195 |                     installed_req_str = f"{req.name}=={dist.version}"
196 |                 else:
197 |                     installed_req_str = f"{req.name}==={dist.version}"
198 |                 if not req.specifier.contains(dist.version, prereleases=True):
199 |                     conflicting.add((installed_req_str, req_str))
200 |                 # FIXME: Consider direct URL?
201 |         return conflicting, missing
202 | 
203 |     def install_requirements(
204 |         self,
205 |         finder: "PackageFinder",
206 |         requirements: Iterable[str],
207 |         prefix_as_string: str,
208 |         *,
209 |         kind: str,
210 |     ) -> None:
211 |         prefix = self._prefixes[prefix_as_string]
212 |         assert not prefix.setup
213 |         prefix.setup = True
214 |         if not requirements:
215 |             return
216 |         self._install_requirements(
217 |             get_runnable_pip(),
218 |             finder,
219 |             requirements,
220 |             prefix,
221 |             kind=kind,
222 |         )
223 | 
224 |     @staticmethod
225 |     def _install_requirements(
226 |         pip_runnable: str,
227 |         finder: "PackageFinder",
228 |         requirements: Iterable[str],
229 |         prefix: _Prefix,
230 |         *,
231 |         kind: str,
232 |     ) -> None:
233 |         args: List[str] = [
234 |             sys.executable,
235 |             pip_runnable,
236 |             "install",
237 |             "--ignore-installed",
238 |             "--no-user",
239 |             "--prefix",
240 |             prefix.path,
241 |             "--no-warn-script-location",
242 |             "--disable-pip-version-check",
243 |             # As the build environment is ephemeral, it's wasteful to
244 |             # pre-compile everything, especially as not every Python
245 |             # module will be used/compiled in most cases.
246 |             "--no-compile",
247 |             # The prefix specified two lines above, thus
248 |             # target from config file or env var should be ignored
249 |             "--target",
250 |             "",
251 |         ]
252 |         if logger.getEffectiveLevel() <= logging.DEBUG:
253 |             args.append("-vv")
254 |         elif logger.getEffectiveLevel() <= VERBOSE:
255 |             args.append("-v")
256 |         for format_control in ("no_binary", "only_binary"):
257 |             formats = getattr(finder.format_control, format_control)
258 |             args.extend(
259 |                 (
260 |                     "--" + format_control.replace("_", "-"),
261 |                     ",".join(sorted(formats or {":none:"})),
262 |                 )
263 |             )
264 | 
265 |         index_urls = finder.index_urls
266 |         if index_urls:
267 |             args.extend(["-i", index_urls[0]])
268 |             for extra_index in index_urls[1:]:
269 |                 args.extend(["--extra-index-url", extra_index])
270 |         else:
271 |             args.append("--no-index")
272 |         for link in finder.find_links:
273 |             args.extend(["--find-links", link])
274 | 
275 |         if finder.proxy:
276 |             args.extend(["--proxy", finder.proxy])
277 |         for host in finder.trusted_hosts:
278 |             args.extend(["--trusted-host", host])
279 |         if finder.custom_cert:
280 |             args.extend(["--cert", finder.custom_cert])
281 |         if finder.client_cert:
282 |             args.extend(["--client-cert", finder.client_cert])
283 |         if finder.allow_all_prereleases:
284 |             args.append("--pre")
285 |         if finder.prefer_binary:
286 |             args.append("--prefer-binary")
287 |         args.append("--")
288 |         args.extend(requirements)
289 |         with open_spinner(f"Installing {kind}") as spinner:
290 |             call_subprocess(
291 |                 args,
292 |                 command_desc=f"pip subprocess to install {kind}",
293 |                 spinner=spinner,
294 |             )
295 | 
296 | 
297 | class NoOpBuildEnvironment(BuildEnvironment):
298 |     """A no-op drop-in replacement for BuildEnvironment"""
299 | 
300 |     def __init__(self) -> None:
301 |         pass
302 | 
303 |     def __enter__(self) -> None:
304 |         pass
305 | 
306 |     def __exit__(
307 |         self,
308 |         exc_type: Optional[Type[BaseException]],
309 |         exc_val: Optional[BaseException],
310 |         exc_tb: Optional[TracebackType],
311 |     ) -> None:
312 |         pass
313 | 
314 |     def cleanup(self) -> None:
315 |         pass
316 | 
317 |     def install_requirements(
318 |         self,
319 |         finder: "PackageFinder",
320 |         requirements: Iterable[str],
321 |         prefix_as_string: str,
322 |         *,
323 |         kind: str,
324 |     ) -> None:
325 |         raise NotImplementedError()
```

.venv/lib/python3.13/site-packages/pip/_internal/cache.py
```
1 | """Cache Management"""
2 | 
3 | import hashlib
4 | import json
5 | import logging
6 | import os
7 | from pathlib import Path
8 | from typing import Any, Dict, List, Optional
9 | 
10 | from pip._vendor.packaging.tags import Tag, interpreter_name, interpreter_version
11 | from pip._vendor.packaging.utils import canonicalize_name
12 | 
13 | from pip._internal.exceptions import InvalidWheelFilename
14 | from pip._internal.models.direct_url import DirectUrl
15 | from pip._internal.models.link import Link
16 | from pip._internal.models.wheel import Wheel
17 | from pip._internal.utils.temp_dir import TempDirectory, tempdir_kinds
18 | from pip._internal.utils.urls import path_to_url
19 | 
20 | logger = logging.getLogger(__name__)
21 | 
22 | ORIGIN_JSON_NAME = "origin.json"
23 | 
24 | 
25 | def _hash_dict(d: Dict[str, str]) -> str:
26 |     """Return a stable sha224 of a dictionary."""
27 |     s = json.dumps(d, sort_keys=True, separators=(",", ":"), ensure_ascii=True)
28 |     return hashlib.sha224(s.encode("ascii")).hexdigest()
29 | 
30 | 
31 | class Cache:
32 |     """An abstract class - provides cache directories for data from links
33 | 
34 |     :param cache_dir: The root of the cache.
35 |     """
36 | 
37 |     def __init__(self, cache_dir: str) -> None:
38 |         super().__init__()
39 |         assert not cache_dir or os.path.isabs(cache_dir)
40 |         self.cache_dir = cache_dir or None
41 | 
42 |     def _get_cache_path_parts(self, link: Link) -> List[str]:
43 |         """Get parts of part that must be os.path.joined with cache_dir"""
44 | 
45 |         # We want to generate an url to use as our cache key, we don't want to
46 |         # just reuse the URL because it might have other items in the fragment
47 |         # and we don't care about those.
48 |         key_parts = {"url": link.url_without_fragment}
49 |         if link.hash_name is not None and link.hash is not None:
50 |             key_parts[link.hash_name] = link.hash
51 |         if link.subdirectory_fragment:
52 |             key_parts["subdirectory"] = link.subdirectory_fragment
53 | 
54 |         # Include interpreter name, major and minor version in cache key
55 |         # to cope with ill-behaved sdists that build a different wheel
56 |         # depending on the python version their setup.py is being run on,
57 |         # and don't encode the difference in compatibility tags.
58 |         # https://github.com/pypa/pip/issues/7296
59 |         key_parts["interpreter_name"] = interpreter_name()
60 |         key_parts["interpreter_version"] = interpreter_version()
61 | 
62 |         # Encode our key url with sha224, we'll use this because it has similar
63 |         # security properties to sha256, but with a shorter total output (and
64 |         # thus less secure). However the differences don't make a lot of
65 |         # difference for our use case here.
66 |         hashed = _hash_dict(key_parts)
67 | 
68 |         # We want to nest the directories some to prevent having a ton of top
69 |         # level directories where we might run out of sub directories on some
70 |         # FS.
71 |         parts = [hashed[:2], hashed[2:4], hashed[4:6], hashed[6:]]
72 | 
73 |         return parts
74 | 
75 |     def _get_candidates(self, link: Link, canonical_package_name: str) -> List[Any]:
76 |         can_not_cache = not self.cache_dir or not canonical_package_name or not link
77 |         if can_not_cache:
78 |             return []
79 | 
80 |         path = self.get_path_for_link(link)
81 |         if os.path.isdir(path):
82 |             return [(candidate, path) for candidate in os.listdir(path)]
83 |         return []
84 | 
85 |     def get_path_for_link(self, link: Link) -> str:
86 |         """Return a directory to store cached items in for link."""
87 |         raise NotImplementedError()
88 | 
89 |     def get(
90 |         self,
91 |         link: Link,
92 |         package_name: Optional[str],
93 |         supported_tags: List[Tag],
94 |     ) -> Link:
95 |         """Returns a link to a cached item if it exists, otherwise returns the
96 |         passed link.
97 |         """
98 |         raise NotImplementedError()
99 | 
100 | 
101 | class SimpleWheelCache(Cache):
102 |     """A cache of wheels for future installs."""
103 | 
104 |     def __init__(self, cache_dir: str) -> None:
105 |         super().__init__(cache_dir)
106 | 
107 |     def get_path_for_link(self, link: Link) -> str:
108 |         """Return a directory to store cached wheels for link
109 | 
110 |         Because there are M wheels for any one sdist, we provide a directory
111 |         to cache them in, and then consult that directory when looking up
112 |         cache hits.
113 | 
114 |         We only insert things into the cache if they have plausible version
115 |         numbers, so that we don't contaminate the cache with things that were
116 |         not unique. E.g. ./package might have dozens of installs done for it
117 |         and build a version of 0.0...and if we built and cached a wheel, we'd
118 |         end up using the same wheel even if the source has been edited.
119 | 
120 |         :param link: The link of the sdist for which this will cache wheels.
121 |         """
122 |         parts = self._get_cache_path_parts(link)
123 |         assert self.cache_dir
124 |         # Store wheels within the root cache_dir
125 |         return os.path.join(self.cache_dir, "wheels", *parts)
126 | 
127 |     def get(
128 |         self,
129 |         link: Link,
130 |         package_name: Optional[str],
131 |         supported_tags: List[Tag],
132 |     ) -> Link:
133 |         candidates = []
134 | 
135 |         if not package_name:
136 |             return link
137 | 
138 |         canonical_package_name = canonicalize_name(package_name)
139 |         for wheel_name, wheel_dir in self._get_candidates(link, canonical_package_name):
140 |             try:
141 |                 wheel = Wheel(wheel_name)
142 |             except InvalidWheelFilename:
143 |                 continue
144 |             if canonicalize_name(wheel.name) != canonical_package_name:
145 |                 logger.debug(
146 |                     "Ignoring cached wheel %s for %s as it "
147 |                     "does not match the expected distribution name %s.",
148 |                     wheel_name,
149 |                     link,
150 |                     package_name,
151 |                 )
152 |                 continue
153 |             if not wheel.supported(supported_tags):
154 |                 # Built for a different python/arch/etc
155 |                 continue
156 |             candidates.append(
157 |                 (
158 |                     wheel.support_index_min(supported_tags),
159 |                     wheel_name,
160 |                     wheel_dir,
161 |                 )
162 |             )
163 | 
164 |         if not candidates:
165 |             return link
166 | 
167 |         _, wheel_name, wheel_dir = min(candidates)
168 |         return Link(path_to_url(os.path.join(wheel_dir, wheel_name)))
169 | 
170 | 
171 | class EphemWheelCache(SimpleWheelCache):
172 |     """A SimpleWheelCache that creates it's own temporary cache directory"""
173 | 
174 |     def __init__(self) -> None:
175 |         self._temp_dir = TempDirectory(
176 |             kind=tempdir_kinds.EPHEM_WHEEL_CACHE,
177 |             globally_managed=True,
178 |         )
179 | 
180 |         super().__init__(self._temp_dir.path)
181 | 
182 | 
183 | class CacheEntry:
184 |     def __init__(
185 |         self,
186 |         link: Link,
187 |         persistent: bool,
188 |     ):
189 |         self.link = link
190 |         self.persistent = persistent
191 |         self.origin: Optional[DirectUrl] = None
192 |         origin_direct_url_path = Path(self.link.file_path).parent / ORIGIN_JSON_NAME
193 |         if origin_direct_url_path.exists():
194 |             try:
195 |                 self.origin = DirectUrl.from_json(
196 |                     origin_direct_url_path.read_text(encoding="utf-8")
197 |                 )
198 |             except Exception as e:
199 |                 logger.warning(
200 |                     "Ignoring invalid cache entry origin file %s for %s (%s)",
201 |                     origin_direct_url_path,
202 |                     link.filename,
203 |                     e,
204 |                 )
205 | 
206 | 
207 | class WheelCache(Cache):
208 |     """Wraps EphemWheelCache and SimpleWheelCache into a single Cache
209 | 
210 |     This Cache allows for gracefully degradation, using the ephem wheel cache
211 |     when a certain link is not found in the simple wheel cache first.
212 |     """
213 | 
214 |     def __init__(self, cache_dir: str) -> None:
215 |         super().__init__(cache_dir)
216 |         self._wheel_cache = SimpleWheelCache(cache_dir)
217 |         self._ephem_cache = EphemWheelCache()
218 | 
219 |     def get_path_for_link(self, link: Link) -> str:
220 |         return self._wheel_cache.get_path_for_link(link)
221 | 
222 |     def get_ephem_path_for_link(self, link: Link) -> str:
223 |         return self._ephem_cache.get_path_for_link(link)
224 | 
225 |     def get(
226 |         self,
227 |         link: Link,
228 |         package_name: Optional[str],
229 |         supported_tags: List[Tag],
230 |     ) -> Link:
231 |         cache_entry = self.get_cache_entry(link, package_name, supported_tags)
232 |         if cache_entry is None:
233 |             return link
234 |         return cache_entry.link
235 | 
236 |     def get_cache_entry(
237 |         self,
238 |         link: Link,
239 |         package_name: Optional[str],
240 |         supported_tags: List[Tag],
241 |     ) -> Optional[CacheEntry]:
242 |         """Returns a CacheEntry with a link to a cached item if it exists or
243 |         None. The cache entry indicates if the item was found in the persistent
244 |         or ephemeral cache.
245 |         """
246 |         retval = self._wheel_cache.get(
247 |             link=link,
248 |             package_name=package_name,
249 |             supported_tags=supported_tags,
250 |         )
251 |         if retval is not link:
252 |             return CacheEntry(retval, persistent=True)
253 | 
254 |         retval = self._ephem_cache.get(
255 |             link=link,
256 |             package_name=package_name,
257 |             supported_tags=supported_tags,
258 |         )
259 |         if retval is not link:
260 |             return CacheEntry(retval, persistent=False)
261 | 
262 |         return None
263 | 
264 |     @staticmethod
265 |     def record_download_origin(cache_dir: str, download_info: DirectUrl) -> None:
266 |         origin_path = Path(cache_dir) / ORIGIN_JSON_NAME
267 |         if origin_path.exists():
268 |             try:
269 |                 origin = DirectUrl.from_json(origin_path.read_text(encoding="utf-8"))
270 |             except Exception as e:
271 |                 logger.warning(
272 |                     "Could not read origin file %s in cache entry (%s). "
273 |                     "Will attempt to overwrite it.",
274 |                     origin_path,
275 |                     e,
276 |                 )
277 |             else:
278 |                 # TODO: use DirectUrl.equivalent when
279 |                 # https://github.com/pypa/pip/pull/10564 is merged.
280 |                 if origin.url != download_info.url:
281 |                     logger.warning(
282 |                         "Origin URL %s in cache entry %s does not match download URL "
283 |                         "%s. This is likely a pip bug or a cache corruption issue. "
284 |                         "Will overwrite it with the new value.",
285 |                         origin.url,
286 |                         cache_dir,
287 |                         download_info.url,
288 |                     )
289 |         origin_path.write_text(download_info.to_json(), encoding="utf-8")
```

.venv/lib/python3.13/site-packages/pip/_internal/configuration.py
```
1 | """Configuration management setup
2 | 
3 | Some terminology:
4 | - name
5 |   As written in config files.
6 | - value
7 |   Value associated with a name
8 | - key
9 |   Name combined with it's section (section.name)
10 | - variant
11 |   A single word describing where the configuration key-value pair came from
12 | """
13 | 
14 | import configparser
15 | import locale
16 | import os
17 | import sys
18 | from typing import Any, Dict, Iterable, List, NewType, Optional, Tuple
19 | 
20 | from pip._internal.exceptions import (
21 |     ConfigurationError,
22 |     ConfigurationFileCouldNotBeLoaded,
23 | )
24 | from pip._internal.utils import appdirs
25 | from pip._internal.utils.compat import WINDOWS
26 | from pip._internal.utils.logging import getLogger
27 | from pip._internal.utils.misc import ensure_dir, enum
28 | 
29 | RawConfigParser = configparser.RawConfigParser  # Shorthand
30 | Kind = NewType("Kind", str)
31 | 
32 | CONFIG_BASENAME = "pip.ini" if WINDOWS else "pip.conf"
33 | ENV_NAMES_IGNORED = "version", "help"
34 | 
35 | # The kinds of configurations there are.
36 | kinds = enum(
37 |     USER="user",  # User Specific
38 |     GLOBAL="global",  # System Wide
39 |     SITE="site",  # [Virtual] Environment Specific
40 |     ENV="env",  # from PIP_CONFIG_FILE
41 |     ENV_VAR="env-var",  # from Environment Variables
42 | )
43 | OVERRIDE_ORDER = kinds.GLOBAL, kinds.USER, kinds.SITE, kinds.ENV, kinds.ENV_VAR
44 | VALID_LOAD_ONLY = kinds.USER, kinds.GLOBAL, kinds.SITE
45 | 
46 | logger = getLogger(__name__)
47 | 
48 | 
49 | # NOTE: Maybe use the optionx attribute to normalize keynames.
50 | def _normalize_name(name: str) -> str:
51 |     """Make a name consistent regardless of source (environment or file)"""
52 |     name = name.lower().replace("_", "-")
53 |     if name.startswith("--"):
54 |         name = name[2:]  # only prefer long opts
55 |     return name
56 | 
57 | 
58 | def _disassemble_key(name: str) -> List[str]:
59 |     if "." not in name:
60 |         error_message = (
61 |             "Key does not contain dot separated section and key. "
62 |             f"Perhaps you wanted to use 'global.{name}' instead?"
63 |         )
64 |         raise ConfigurationError(error_message)
65 |     return name.split(".", 1)
66 | 
67 | 
68 | def get_configuration_files() -> Dict[Kind, List[str]]:
69 |     global_config_files = [
70 |         os.path.join(path, CONFIG_BASENAME) for path in appdirs.site_config_dirs("pip")
71 |     ]
72 | 
73 |     site_config_file = os.path.join(sys.prefix, CONFIG_BASENAME)
74 |     legacy_config_file = os.path.join(
75 |         os.path.expanduser("~"),
76 |         "pip" if WINDOWS else ".pip",
77 |         CONFIG_BASENAME,
78 |     )
79 |     new_config_file = os.path.join(appdirs.user_config_dir("pip"), CONFIG_BASENAME)
80 |     return {
81 |         kinds.GLOBAL: global_config_files,
82 |         kinds.SITE: [site_config_file],
83 |         kinds.USER: [legacy_config_file, new_config_file],
84 |     }
85 | 
86 | 
87 | class Configuration:
88 |     """Handles management of configuration.
89 | 
90 |     Provides an interface to accessing and managing configuration files.
91 | 
92 |     This class converts provides an API that takes "section.key-name" style
93 |     keys and stores the value associated with it as "key-name" under the
94 |     section "section".
95 | 
96 |     This allows for a clean interface wherein the both the section and the
97 |     key-name are preserved in an easy to manage form in the configuration files
98 |     and the data stored is also nice.
99 |     """
100 | 
101 |     def __init__(self, isolated: bool, load_only: Optional[Kind] = None) -> None:
102 |         super().__init__()
103 | 
104 |         if load_only is not None and load_only not in VALID_LOAD_ONLY:
105 |             raise ConfigurationError(
106 |                 "Got invalid value for load_only - should be one of {}".format(
107 |                     ", ".join(map(repr, VALID_LOAD_ONLY))
108 |                 )
109 |             )
110 |         self.isolated = isolated
111 |         self.load_only = load_only
112 | 
113 |         # Because we keep track of where we got the data from
114 |         self._parsers: Dict[Kind, List[Tuple[str, RawConfigParser]]] = {
115 |             variant: [] for variant in OVERRIDE_ORDER
116 |         }
117 |         self._config: Dict[Kind, Dict[str, Any]] = {
118 |             variant: {} for variant in OVERRIDE_ORDER
119 |         }
120 |         self._modified_parsers: List[Tuple[str, RawConfigParser]] = []
121 | 
122 |     def load(self) -> None:
123 |         """Loads configuration from configuration files and environment"""
124 |         self._load_config_files()
125 |         if not self.isolated:
126 |             self._load_environment_vars()
127 | 
128 |     def get_file_to_edit(self) -> Optional[str]:
129 |         """Returns the file with highest priority in configuration"""
130 |         assert self.load_only is not None, "Need to be specified a file to be editing"
131 | 
132 |         try:
133 |             return self._get_parser_to_modify()[0]
134 |         except IndexError:
135 |             return None
136 | 
137 |     def items(self) -> Iterable[Tuple[str, Any]]:
138 |         """Returns key-value pairs like dict.items() representing the loaded
139 |         configuration
140 |         """
141 |         return self._dictionary.items()
142 | 
143 |     def get_value(self, key: str) -> Any:
144 |         """Get a value from the configuration."""
145 |         orig_key = key
146 |         key = _normalize_name(key)
147 |         try:
148 |             return self._dictionary[key]
149 |         except KeyError:
150 |             # disassembling triggers a more useful error message than simply
151 |             # "No such key" in the case that the key isn't in the form command.option
152 |             _disassemble_key(key)
153 |             raise ConfigurationError(f"No such key - {orig_key}")
154 | 
155 |     def set_value(self, key: str, value: Any) -> None:
156 |         """Modify a value in the configuration."""
157 |         key = _normalize_name(key)
158 |         self._ensure_have_load_only()
159 | 
160 |         assert self.load_only
161 |         fname, parser = self._get_parser_to_modify()
162 | 
163 |         if parser is not None:
164 |             section, name = _disassemble_key(key)
165 | 
166 |             # Modify the parser and the configuration
167 |             if not parser.has_section(section):
168 |                 parser.add_section(section)
169 |             parser.set(section, name, value)
170 | 
171 |         self._config[self.load_only][key] = value
172 |         self._mark_as_modified(fname, parser)
173 | 
174 |     def unset_value(self, key: str) -> None:
175 |         """Unset a value in the configuration."""
176 |         orig_key = key
177 |         key = _normalize_name(key)
178 |         self._ensure_have_load_only()
179 | 
180 |         assert self.load_only
181 |         if key not in self._config[self.load_only]:
182 |             raise ConfigurationError(f"No such key - {orig_key}")
183 | 
184 |         fname, parser = self._get_parser_to_modify()
185 | 
186 |         if parser is not None:
187 |             section, name = _disassemble_key(key)
188 |             if not (
189 |                 parser.has_section(section) and parser.remove_option(section, name)
190 |             ):
191 |                 # The option was not removed.
192 |                 raise ConfigurationError(
193 |                     "Fatal Internal error [id=1]. Please report as a bug."
194 |                 )
195 | 
196 |             # The section may be empty after the option was removed.
197 |             if not parser.items(section):
198 |                 parser.remove_section(section)
199 |             self._mark_as_modified(fname, parser)
200 | 
201 |         del self._config[self.load_only][key]
202 | 
203 |     def save(self) -> None:
204 |         """Save the current in-memory state."""
205 |         self._ensure_have_load_only()
206 | 
207 |         for fname, parser in self._modified_parsers:
208 |             logger.info("Writing to %s", fname)
209 | 
210 |             # Ensure directory exists.
211 |             ensure_dir(os.path.dirname(fname))
212 | 
213 |             # Ensure directory's permission(need to be writeable)
214 |             try:
215 |                 with open(fname, "w") as f:
216 |                     parser.write(f)
217 |             except OSError as error:
218 |                 raise ConfigurationError(
219 |                     f"An error occurred while writing to the configuration file "
220 |                     f"{fname}: {error}"
221 |                 )
222 | 
223 |     #
224 |     # Private routines
225 |     #
226 | 
227 |     def _ensure_have_load_only(self) -> None:
228 |         if self.load_only is None:
229 |             raise ConfigurationError("Needed a specific file to be modifying.")
230 |         logger.debug("Will be working with %s variant only", self.load_only)
231 | 
232 |     @property
233 |     def _dictionary(self) -> Dict[str, Any]:
234 |         """A dictionary representing the loaded configuration."""
235 |         # NOTE: Dictionaries are not populated if not loaded. So, conditionals
236 |         #       are not needed here.
237 |         retval = {}
238 | 
239 |         for variant in OVERRIDE_ORDER:
240 |             retval.update(self._config[variant])
241 | 
242 |         return retval
243 | 
244 |     def _load_config_files(self) -> None:
245 |         """Loads configuration from configuration files"""
246 |         config_files = dict(self.iter_config_files())
247 |         if config_files[kinds.ENV][0:1] == [os.devnull]:
248 |             logger.debug(
249 |                 "Skipping loading configuration files due to "
250 |                 "environment's PIP_CONFIG_FILE being os.devnull"
251 |             )
252 |             return
253 | 
254 |         for variant, files in config_files.items():
255 |             for fname in files:
256 |                 # If there's specific variant set in `load_only`, load only
257 |                 # that variant, not the others.
258 |                 if self.load_only is not None and variant != self.load_only:
259 |                     logger.debug("Skipping file '%s' (variant: %s)", fname, variant)
260 |                     continue
261 | 
262 |                 parser = self._load_file(variant, fname)
263 | 
264 |                 # Keeping track of the parsers used
265 |                 self._parsers[variant].append((fname, parser))
266 | 
267 |     def _load_file(self, variant: Kind, fname: str) -> RawConfigParser:
268 |         logger.verbose("For variant '%s', will try loading '%s'", variant, fname)
269 |         parser = self._construct_parser(fname)
270 | 
271 |         for section in parser.sections():
272 |             items = parser.items(section)
273 |             self._config[variant].update(self._normalized_keys(section, items))
274 | 
275 |         return parser
276 | 
277 |     def _construct_parser(self, fname: str) -> RawConfigParser:
278 |         parser = configparser.RawConfigParser()
279 |         # If there is no such file, don't bother reading it but create the
280 |         # parser anyway, to hold the data.
281 |         # Doing this is useful when modifying and saving files, where we don't
282 |         # need to construct a parser.
283 |         if os.path.exists(fname):
284 |             locale_encoding = locale.getpreferredencoding(False)
285 |             try:
286 |                 parser.read(fname, encoding=locale_encoding)
287 |             except UnicodeDecodeError:
288 |                 # See https://github.com/pypa/pip/issues/4963
289 |                 raise ConfigurationFileCouldNotBeLoaded(
290 |                     reason=f"contains invalid {locale_encoding} characters",
291 |                     fname=fname,
292 |                 )
293 |             except configparser.Error as error:
294 |                 # See https://github.com/pypa/pip/issues/4893
295 |                 raise ConfigurationFileCouldNotBeLoaded(error=error)
296 |         return parser
297 | 
298 |     def _load_environment_vars(self) -> None:
299 |         """Loads configuration from environment variables"""
300 |         self._config[kinds.ENV_VAR].update(
301 |             self._normalized_keys(":env:", self.get_environ_vars())
302 |         )
303 | 
304 |     def _normalized_keys(
305 |         self, section: str, items: Iterable[Tuple[str, Any]]
306 |     ) -> Dict[str, Any]:
307 |         """Normalizes items to construct a dictionary with normalized keys.
308 | 
309 |         This routine is where the names become keys and are made the same
310 |         regardless of source - configuration files or environment.
311 |         """
312 |         normalized = {}
313 |         for name, val in items:
314 |             key = section + "." + _normalize_name(name)
315 |             normalized[key] = val
316 |         return normalized
317 | 
318 |     def get_environ_vars(self) -> Iterable[Tuple[str, str]]:
319 |         """Returns a generator with all environmental vars with prefix PIP_"""
320 |         for key, val in os.environ.items():
321 |             if key.startswith("PIP_"):
322 |                 name = key[4:].lower()
323 |                 if name not in ENV_NAMES_IGNORED:
324 |                     yield name, val
325 | 
326 |     # XXX: This is patched in the tests.
327 |     def iter_config_files(self) -> Iterable[Tuple[Kind, List[str]]]:
328 |         """Yields variant and configuration files associated with it.
329 | 
330 |         This should be treated like items of a dictionary. The order
331 |         here doesn't affect what gets overridden. That is controlled
332 |         by OVERRIDE_ORDER. However this does control the order they are
333 |         displayed to the user. It's probably most ergonomic to display
334 |         things in the same order as OVERRIDE_ORDER
335 |         """
336 |         # SMELL: Move the conditions out of this function
337 | 
338 |         env_config_file = os.environ.get("PIP_CONFIG_FILE", None)
339 |         config_files = get_configuration_files()
[TRUNCATED]
```

.venv/lib/python3.13/site-packages/pip/_internal/exceptions.py
```
1 | """Exceptions used throughout package.
2 | 
3 | This module MUST NOT try to import from anything within `pip._internal` to
4 | operate. This is expected to be importable from any/all files within the
5 | subpackage and, thus, should not depend on them.
6 | """
7 | 
8 | import configparser
9 | import contextlib
10 | import locale
11 | import logging
12 | import pathlib
13 | import re
14 | import sys
15 | from itertools import chain, groupby, repeat
16 | from typing import TYPE_CHECKING, Dict, Iterator, List, Literal, Optional, Union
17 | 
18 | from pip._vendor.packaging.requirements import InvalidRequirement
19 | from pip._vendor.packaging.version import InvalidVersion
20 | from pip._vendor.rich.console import Console, ConsoleOptions, RenderResult
21 | from pip._vendor.rich.markup import escape
22 | from pip._vendor.rich.text import Text
23 | 
24 | if TYPE_CHECKING:
25 |     from hashlib import _Hash
26 | 
27 |     from pip._vendor.requests.models import Request, Response
28 | 
29 |     from pip._internal.metadata import BaseDistribution
30 |     from pip._internal.models.link import Link
31 |     from pip._internal.req.req_install import InstallRequirement
32 | 
33 | logger = logging.getLogger(__name__)
34 | 
35 | 
36 | #
37 | # Scaffolding
38 | #
39 | def _is_kebab_case(s: str) -> bool:
40 |     return re.match(r"^[a-z]+(-[a-z]+)*$", s) is not None
41 | 
42 | 
43 | def _prefix_with_indent(
44 |     s: Union[Text, str],
45 |     console: Console,
46 |     *,
47 |     prefix: str,
48 |     indent: str,
49 | ) -> Text:
50 |     if isinstance(s, Text):
51 |         text = s
52 |     else:
53 |         text = console.render_str(s)
54 | 
55 |     return console.render_str(prefix, overflow="ignore") + console.render_str(
56 |         f"\n{indent}", overflow="ignore"
57 |     ).join(text.split(allow_blank=True))
58 | 
59 | 
60 | class PipError(Exception):
61 |     """The base pip error."""
62 | 
63 | 
64 | class DiagnosticPipError(PipError):
65 |     """An error, that presents diagnostic information to the user.
66 | 
67 |     This contains a bunch of logic, to enable pretty presentation of our error
68 |     messages. Each error gets a unique reference. Each error can also include
69 |     additional context, a hint and/or a note -- which are presented with the
70 |     main error message in a consistent style.
71 | 
72 |     This is adapted from the error output styling in `sphinx-theme-builder`.
73 |     """
74 | 
75 |     reference: str
76 | 
77 |     def __init__(
78 |         self,
79 |         *,
80 |         kind: 'Literal["error", "warning"]' = "error",
81 |         reference: Optional[str] = None,
82 |         message: Union[str, Text],
83 |         context: Optional[Union[str, Text]],
84 |         hint_stmt: Optional[Union[str, Text]],
85 |         note_stmt: Optional[Union[str, Text]] = None,
86 |         link: Optional[str] = None,
87 |     ) -> None:
88 |         # Ensure a proper reference is provided.
89 |         if reference is None:
90 |             assert hasattr(self, "reference"), "error reference not provided!"
91 |             reference = self.reference
92 |         assert _is_kebab_case(reference), "error reference must be kebab-case!"
93 | 
94 |         self.kind = kind
95 |         self.reference = reference
96 | 
97 |         self.message = message
98 |         self.context = context
99 | 
100 |         self.note_stmt = note_stmt
101 |         self.hint_stmt = hint_stmt
102 | 
103 |         self.link = link
104 | 
105 |         super().__init__(f"<{self.__class__.__name__}: {self.reference}>")
106 | 
107 |     def __repr__(self) -> str:
108 |         return (
109 |             f"<{self.__class__.__name__}("
110 |             f"reference={self.reference!r}, "
111 |             f"message={self.message!r}, "
112 |             f"context={self.context!r}, "
113 |             f"note_stmt={self.note_stmt!r}, "
114 |             f"hint_stmt={self.hint_stmt!r}"
115 |             ")>"
116 |         )
117 | 
118 |     def __rich_console__(
119 |         self,
120 |         console: Console,
121 |         options: ConsoleOptions,
122 |     ) -> RenderResult:
123 |         colour = "red" if self.kind == "error" else "yellow"
124 | 
125 |         yield f"[{colour} bold]{self.kind}[/]: [bold]{self.reference}[/]"
126 |         yield ""
127 | 
128 |         if not options.ascii_only:
129 |             # Present the main message, with relevant context indented.
130 |             if self.context is not None:
131 |                 yield _prefix_with_indent(
132 |                     self.message,
133 |                     console,
134 |                     prefix=f"[{colour}][/] ",
135 |                     indent=f"[{colour}][/] ",
136 |                 )
137 |                 yield _prefix_with_indent(
138 |                     self.context,
139 |                     console,
140 |                     prefix=f"[{colour}]>[/] ",
141 |                     indent=f"[{colour}]   [/] ",
142 |                 )
143 |             else:
144 |                 yield _prefix_with_indent(
145 |                     self.message,
146 |                     console,
147 |                     prefix="[red][/] ",
148 |                     indent="  ",
149 |                 )
150 |         else:
151 |             yield self.message
152 |             if self.context is not None:
153 |                 yield ""
154 |                 yield self.context
155 | 
156 |         if self.note_stmt is not None or self.hint_stmt is not None:
157 |             yield ""
158 | 
159 |         if self.note_stmt is not None:
160 |             yield _prefix_with_indent(
161 |                 self.note_stmt,
162 |                 console,
163 |                 prefix="[magenta bold]note[/]: ",
164 |                 indent="      ",
165 |             )
166 |         if self.hint_stmt is not None:
167 |             yield _prefix_with_indent(
168 |                 self.hint_stmt,
169 |                 console,
170 |                 prefix="[cyan bold]hint[/]: ",
171 |                 indent="      ",
172 |             )
173 | 
174 |         if self.link is not None:
175 |             yield ""
176 |             yield f"Link: {self.link}"
177 | 
178 | 
179 | #
180 | # Actual Errors
181 | #
182 | class ConfigurationError(PipError):
183 |     """General exception in configuration"""
184 | 
185 | 
186 | class InstallationError(PipError):
187 |     """General exception during installation"""
188 | 
189 | 
190 | class MissingPyProjectBuildRequires(DiagnosticPipError):
191 |     """Raised when pyproject.toml has `build-system`, but no `build-system.requires`."""
192 | 
193 |     reference = "missing-pyproject-build-system-requires"
194 | 
195 |     def __init__(self, *, package: str) -> None:
196 |         super().__init__(
197 |             message=f"Can not process {escape(package)}",
198 |             context=Text(
199 |                 "This package has an invalid pyproject.toml file.\n"
200 |                 "The [build-system] table is missing the mandatory `requires` key."
201 |             ),
202 |             note_stmt="This is an issue with the package mentioned above, not pip.",
203 |             hint_stmt=Text("See PEP 518 for the detailed specification."),
204 |         )
205 | 
206 | 
207 | class InvalidPyProjectBuildRequires(DiagnosticPipError):
208 |     """Raised when pyproject.toml an invalid `build-system.requires`."""
209 | 
210 |     reference = "invalid-pyproject-build-system-requires"
211 | 
212 |     def __init__(self, *, package: str, reason: str) -> None:
213 |         super().__init__(
214 |             message=f"Can not process {escape(package)}",
215 |             context=Text(
216 |                 "This package has an invalid `build-system.requires` key in "
217 |                 f"pyproject.toml.\n{reason}"
218 |             ),
219 |             note_stmt="This is an issue with the package mentioned above, not pip.",
220 |             hint_stmt=Text("See PEP 518 for the detailed specification."),
221 |         )
222 | 
223 | 
224 | class NoneMetadataError(PipError):
225 |     """Raised when accessing a Distribution's "METADATA" or "PKG-INFO".
226 | 
227 |     This signifies an inconsistency, when the Distribution claims to have
228 |     the metadata file (if not, raise ``FileNotFoundError`` instead), but is
229 |     not actually able to produce its content. This may be due to permission
230 |     errors.
231 |     """
232 | 
233 |     def __init__(
234 |         self,
235 |         dist: "BaseDistribution",
236 |         metadata_name: str,
237 |     ) -> None:
238 |         """
239 |         :param dist: A Distribution object.
240 |         :param metadata_name: The name of the metadata being accessed
241 |             (can be "METADATA" or "PKG-INFO").
242 |         """
243 |         self.dist = dist
244 |         self.metadata_name = metadata_name
245 | 
246 |     def __str__(self) -> str:
247 |         # Use `dist` in the error message because its stringification
248 |         # includes more information, like the version and location.
249 |         return f"None {self.metadata_name} metadata found for distribution: {self.dist}"
250 | 
251 | 
252 | class UserInstallationInvalid(InstallationError):
253 |     """A --user install is requested on an environment without user site."""
254 | 
255 |     def __str__(self) -> str:
256 |         return "User base directory is not specified"
257 | 
258 | 
259 | class InvalidSchemeCombination(InstallationError):
260 |     def __str__(self) -> str:
261 |         before = ", ".join(str(a) for a in self.args[:-1])
262 |         return f"Cannot set {before} and {self.args[-1]} together"
263 | 
264 | 
265 | class DistributionNotFound(InstallationError):
266 |     """Raised when a distribution cannot be found to satisfy a requirement"""
267 | 
268 | 
269 | class RequirementsFileParseError(InstallationError):
270 |     """Raised when a general error occurs parsing a requirements file line."""
271 | 
272 | 
273 | class BestVersionAlreadyInstalled(PipError):
274 |     """Raised when the most up-to-date version of a package is already
275 |     installed."""
276 | 
277 | 
278 | class BadCommand(PipError):
279 |     """Raised when virtualenv or a command is not found"""
280 | 
281 | 
282 | class CommandError(PipError):
283 |     """Raised when there is an error in command-line arguments"""
284 | 
285 | 
286 | class PreviousBuildDirError(PipError):
287 |     """Raised when there's a previous conflicting build directory"""
288 | 
289 | 
290 | class NetworkConnectionError(PipError):
291 |     """HTTP connection error"""
292 | 
293 |     def __init__(
294 |         self,
295 |         error_msg: str,
296 |         response: Optional["Response"] = None,
297 |         request: Optional["Request"] = None,
298 |     ) -> None:
299 |         """
300 |         Initialize NetworkConnectionError with  `request` and `response`
301 |         objects.
302 |         """
303 |         self.response = response
304 |         self.request = request
305 |         self.error_msg = error_msg
306 |         if (
307 |             self.response is not None
308 |             and not self.request
309 |             and hasattr(response, "request")
310 |         ):
311 |             self.request = self.response.request
312 |         super().__init__(error_msg, response, request)
313 | 
314 |     def __str__(self) -> str:
315 |         return str(self.error_msg)
316 | 
317 | 
318 | class InvalidWheelFilename(InstallationError):
319 |     """Invalid wheel filename."""
320 | 
321 | 
322 | class UnsupportedWheel(InstallationError):
323 |     """Unsupported wheel."""
324 | 
325 | 
326 | class InvalidWheel(InstallationError):
327 |     """Invalid (e.g. corrupt) wheel."""
328 | 
329 |     def __init__(self, location: str, name: str):
330 |         self.location = location
331 |         self.name = name
332 | 
333 |     def __str__(self) -> str:
334 |         return f"Wheel '{self.name}' located at {self.location} is invalid."
335 | 
336 | 
337 | class MetadataInconsistent(InstallationError):
338 |     """Built metadata contains inconsistent information.
339 | 
340 |     This is raised when the metadata contains values (e.g. name and version)
341 |     that do not match the information previously obtained from sdist filename,
342 |     user-supplied ``#egg=`` value, or an install requirement name.
343 |     """
344 | 
345 |     def __init__(
346 |         self, ireq: "InstallRequirement", field: str, f_val: str, m_val: str
347 |     ) -> None:
348 |         self.ireq = ireq
349 |         self.field = field
350 |         self.f_val = f_val
351 |         self.m_val = m_val
352 | 
353 |     def __str__(self) -> str:
354 |         return (
355 |             f"Requested {self.ireq} has inconsistent {self.field}: "
356 |             f"expected {self.f_val!r}, but metadata has {self.m_val!r}"
357 |         )
358 | 
359 | 
360 | class MetadataInvalid(InstallationError):
361 |     """Metadata is invalid."""
362 | 
363 |     def __init__(self, ireq: "InstallRequirement", error: str) -> None:
364 |         self.ireq = ireq
365 |         self.error = error
366 | 
367 |     def __str__(self) -> str:
368 |         return f"Requested {self.ireq} has invalid metadata: {self.error}"
369 | 
370 | 
371 | class InstallationSubprocessError(DiagnosticPipError, InstallationError):
372 |     """A subprocess call failed."""
373 | 
374 |     reference = "subprocess-exited-with-error"
375 | 
376 |     def __init__(
377 |         self,
378 |         *,
379 |         command_description: str,
380 |         exit_code: int,
381 |         output_lines: Optional[List[str]],
382 |     ) -> None:
383 |         if output_lines is None:
384 |             output_prompt = Text("See above for output.")
385 |         else:
386 |             output_prompt = (
387 |                 Text.from_markup(f"[red][{len(output_lines)} lines of output][/]\n")
388 |                 + Text("".join(output_lines))
389 |                 + Text.from_markup(R"[red]\[end of output][/]")
390 |             )
391 | 
392 |         super().__init__(
393 |             message=(
394 |                 f"[green]{escape(command_description)}[/] did not run successfully.\n"
395 |                 f"exit code: {exit_code}"
396 |             ),
397 |             context=output_prompt,
398 |             hint_stmt=None,
399 |             note_stmt=(
400 |                 "This error originates from a subprocess, and is likely not a "
401 |                 "problem with pip."
402 |             ),
403 |         )
[TRUNCATED]
```

.venv/lib/python3.13/site-packages/pip/_internal/main.py
```
1 | from typing import List, Optional
2 | 
3 | 
4 | def main(args: Optional[List[str]] = None) -> int:
5 |     """This is preserved for old console scripts that may still be referencing
6 |     it.
7 | 
8 |     For additional details, see https://github.com/pypa/pip/issues/7498.
9 |     """
10 |     from pip._internal.utils.entrypoints import _wrapper
11 | 
12 |     return _wrapper(args)
```

.venv/lib/python3.13/site-packages/pip/_internal/pyproject.py
```
1 | import importlib.util
2 | import os
3 | import sys
4 | from collections import namedtuple
5 | from typing import Any, List, Optional
6 | 
7 | if sys.version_info >= (3, 11):
8 |     import tomllib
9 | else:
10 |     from pip._vendor import tomli as tomllib
11 | 
12 | from pip._vendor.packaging.requirements import InvalidRequirement
13 | 
14 | from pip._internal.exceptions import (
15 |     InstallationError,
16 |     InvalidPyProjectBuildRequires,
17 |     MissingPyProjectBuildRequires,
18 | )
19 | from pip._internal.utils.packaging import get_requirement
20 | 
21 | 
22 | def _is_list_of_str(obj: Any) -> bool:
23 |     return isinstance(obj, list) and all(isinstance(item, str) for item in obj)
24 | 
25 | 
26 | def make_pyproject_path(unpacked_source_directory: str) -> str:
27 |     return os.path.join(unpacked_source_directory, "pyproject.toml")
28 | 
29 | 
30 | BuildSystemDetails = namedtuple(
31 |     "BuildSystemDetails", ["requires", "backend", "check", "backend_path"]
32 | )
33 | 
34 | 
35 | def load_pyproject_toml(
36 |     use_pep517: Optional[bool], pyproject_toml: str, setup_py: str, req_name: str
37 | ) -> Optional[BuildSystemDetails]:
38 |     """Load the pyproject.toml file.
39 | 
40 |     Parameters:
41 |         use_pep517 - Has the user requested PEP 517 processing? None
42 |                      means the user hasn't explicitly specified.
43 |         pyproject_toml - Location of the project's pyproject.toml file
44 |         setup_py - Location of the project's setup.py file
45 |         req_name - The name of the requirement we're processing (for
46 |                    error reporting)
47 | 
48 |     Returns:
49 |         None if we should use the legacy code path, otherwise a tuple
50 |         (
51 |             requirements from pyproject.toml,
52 |             name of PEP 517 backend,
53 |             requirements we should check are installed after setting
54 |                 up the build environment
55 |             directory paths to import the backend from (backend-path),
56 |                 relative to the project root.
57 |         )
58 |     """
59 |     has_pyproject = os.path.isfile(pyproject_toml)
60 |     has_setup = os.path.isfile(setup_py)
61 | 
62 |     if not has_pyproject and not has_setup:
63 |         raise InstallationError(
64 |             f"{req_name} does not appear to be a Python project: "
65 |             f"neither 'setup.py' nor 'pyproject.toml' found."
66 |         )
67 | 
68 |     if has_pyproject:
69 |         with open(pyproject_toml, encoding="utf-8") as f:
70 |             pp_toml = tomllib.loads(f.read())
71 |         build_system = pp_toml.get("build-system")
72 |     else:
73 |         build_system = None
74 | 
75 |     # The following cases must use PEP 517
76 |     # We check for use_pep517 being non-None and falsy because that means
77 |     # the user explicitly requested --no-use-pep517.  The value 0 as
78 |     # opposed to False can occur when the value is provided via an
79 |     # environment variable or config file option (due to the quirk of
80 |     # strtobool() returning an integer in pip's configuration code).
81 |     if has_pyproject and not has_setup:
82 |         if use_pep517 is not None and not use_pep517:
83 |             raise InstallationError(
84 |                 "Disabling PEP 517 processing is invalid: "
85 |                 "project does not have a setup.py"
86 |             )
87 |         use_pep517 = True
88 |     elif build_system and "build-backend" in build_system:
89 |         if use_pep517 is not None and not use_pep517:
90 |             raise InstallationError(
91 |                 "Disabling PEP 517 processing is invalid: "
92 |                 "project specifies a build backend of {} "
93 |                 "in pyproject.toml".format(build_system["build-backend"])
94 |             )
95 |         use_pep517 = True
96 | 
97 |     # If we haven't worked out whether to use PEP 517 yet,
98 |     # and the user hasn't explicitly stated a preference,
99 |     # we do so if the project has a pyproject.toml file
100 |     # or if we cannot import setuptools or wheels.
101 | 
102 |     # We fallback to PEP 517 when without setuptools or without the wheel package,
103 |     # so setuptools can be installed as a default build backend.
104 |     # For more info see:
105 |     # https://discuss.python.org/t/pip-without-setuptools-could-the-experience-be-improved/11810/9
106 |     # https://github.com/pypa/pip/issues/8559
107 |     elif use_pep517 is None:
108 |         use_pep517 = (
109 |             has_pyproject
110 |             or not importlib.util.find_spec("setuptools")
111 |             or not importlib.util.find_spec("wheel")
112 |         )
113 | 
114 |     # At this point, we know whether we're going to use PEP 517.
115 |     assert use_pep517 is not None
116 | 
117 |     # If we're using the legacy code path, there is nothing further
118 |     # for us to do here.
119 |     if not use_pep517:
120 |         return None
121 | 
122 |     if build_system is None:
123 |         # Either the user has a pyproject.toml with no build-system
124 |         # section, or the user has no pyproject.toml, but has opted in
125 |         # explicitly via --use-pep517.
126 |         # In the absence of any explicit backend specification, we
127 |         # assume the setuptools backend that most closely emulates the
128 |         # traditional direct setup.py execution, and require wheel and
129 |         # a version of setuptools that supports that backend.
130 | 
131 |         build_system = {
132 |             "requires": ["setuptools>=40.8.0"],
133 |             "build-backend": "setuptools.build_meta:__legacy__",
134 |         }
135 | 
136 |     # If we're using PEP 517, we have build system information (either
137 |     # from pyproject.toml, or defaulted by the code above).
138 |     # Note that at this point, we do not know if the user has actually
139 |     # specified a backend, though.
140 |     assert build_system is not None
141 | 
142 |     # Ensure that the build-system section in pyproject.toml conforms
143 |     # to PEP 518.
144 | 
145 |     # Specifying the build-system table but not the requires key is invalid
146 |     if "requires" not in build_system:
147 |         raise MissingPyProjectBuildRequires(package=req_name)
148 | 
149 |     # Error out if requires is not a list of strings
150 |     requires = build_system["requires"]
151 |     if not _is_list_of_str(requires):
152 |         raise InvalidPyProjectBuildRequires(
153 |             package=req_name,
154 |             reason="It is not a list of strings.",
155 |         )
156 | 
157 |     # Each requirement must be valid as per PEP 508
158 |     for requirement in requires:
159 |         try:
160 |             get_requirement(requirement)
161 |         except InvalidRequirement as error:
162 |             raise InvalidPyProjectBuildRequires(
163 |                 package=req_name,
164 |                 reason=f"It contains an invalid requirement: {requirement!r}",
165 |             ) from error
166 | 
167 |     backend = build_system.get("build-backend")
168 |     backend_path = build_system.get("backend-path", [])
169 |     check: List[str] = []
170 |     if backend is None:
171 |         # If the user didn't specify a backend, we assume they want to use
172 |         # the setuptools backend. But we can't be sure they have included
173 |         # a version of setuptools which supplies the backend. So we
174 |         # make a note to check that this requirement is present once
175 |         # we have set up the environment.
176 |         # This is quite a lot of work to check for a very specific case. But
177 |         # the problem is, that case is potentially quite common - projects that
178 |         # adopted PEP 518 early for the ability to specify requirements to
179 |         # execute setup.py, but never considered needing to mention the build
180 |         # tools themselves. The original PEP 518 code had a similar check (but
181 |         # implemented in a different way).
182 |         backend = "setuptools.build_meta:__legacy__"
183 |         check = ["setuptools>=40.8.0"]
184 | 
185 |     return BuildSystemDetails(requires, backend, check, backend_path)
```

.venv/lib/python3.13/site-packages/pip/_internal/self_outdated_check.py
```
1 | import datetime
2 | import functools
3 | import hashlib
4 | import json
5 | import logging
6 | import optparse
7 | import os.path
8 | import sys
9 | from dataclasses import dataclass
10 | from typing import Any, Callable, Dict, Optional
11 | 
12 | from pip._vendor.packaging.version import Version
13 | from pip._vendor.packaging.version import parse as parse_version
14 | from pip._vendor.rich.console import Group
15 | from pip._vendor.rich.markup import escape
16 | from pip._vendor.rich.text import Text
17 | 
18 | from pip._internal.index.collector import LinkCollector
19 | from pip._internal.index.package_finder import PackageFinder
20 | from pip._internal.metadata import get_default_environment
21 | from pip._internal.models.selection_prefs import SelectionPreferences
22 | from pip._internal.network.session import PipSession
23 | from pip._internal.utils.compat import WINDOWS
24 | from pip._internal.utils.entrypoints import (
25 |     get_best_invocation_for_this_pip,
26 |     get_best_invocation_for_this_python,
27 | )
28 | from pip._internal.utils.filesystem import adjacent_tmp_file, check_path_owner, replace
29 | from pip._internal.utils.misc import (
30 |     ExternallyManagedEnvironment,
31 |     check_externally_managed,
32 |     ensure_dir,
33 | )
34 | 
35 | _WEEK = datetime.timedelta(days=7)
36 | 
37 | logger = logging.getLogger(__name__)
38 | 
39 | 
40 | def _get_statefile_name(key: str) -> str:
41 |     key_bytes = key.encode()
42 |     name = hashlib.sha224(key_bytes).hexdigest()
43 |     return name
44 | 
45 | 
46 | def _convert_date(isodate: str) -> datetime.datetime:
47 |     """Convert an ISO format string to a date.
48 | 
49 |     Handles the format 2020-01-22T14:24:01Z (trailing Z)
50 |     which is not supported by older versions of fromisoformat.
51 |     """
52 |     return datetime.datetime.fromisoformat(isodate.replace("Z", "+00:00"))
53 | 
54 | 
55 | class SelfCheckState:
56 |     def __init__(self, cache_dir: str) -> None:
57 |         self._state: Dict[str, Any] = {}
58 |         self._statefile_path = None
59 | 
60 |         # Try to load the existing state
61 |         if cache_dir:
62 |             self._statefile_path = os.path.join(
63 |                 cache_dir, "selfcheck", _get_statefile_name(self.key)
64 |             )
65 |             try:
66 |                 with open(self._statefile_path, encoding="utf-8") as statefile:
67 |                     self._state = json.load(statefile)
68 |             except (OSError, ValueError, KeyError):
69 |                 # Explicitly suppressing exceptions, since we don't want to
70 |                 # error out if the cache file is invalid.
71 |                 pass
72 | 
73 |     @property
74 |     def key(self) -> str:
75 |         return sys.prefix
76 | 
77 |     def get(self, current_time: datetime.datetime) -> Optional[str]:
78 |         """Check if we have a not-outdated version loaded already."""
79 |         if not self._state:
80 |             return None
81 | 
82 |         if "last_check" not in self._state:
83 |             return None
84 | 
85 |         if "pypi_version" not in self._state:
86 |             return None
87 | 
88 |         # Determine if we need to refresh the state
89 |         last_check = _convert_date(self._state["last_check"])
90 |         time_since_last_check = current_time - last_check
91 |         if time_since_last_check > _WEEK:
92 |             return None
93 | 
94 |         return self._state["pypi_version"]
95 | 
96 |     def set(self, pypi_version: str, current_time: datetime.datetime) -> None:
97 |         # If we do not have a path to cache in, don't bother saving.
98 |         if not self._statefile_path:
99 |             return
100 | 
101 |         # Check to make sure that we own the directory
102 |         if not check_path_owner(os.path.dirname(self._statefile_path)):
103 |             return
104 | 
105 |         # Now that we've ensured the directory is owned by this user, we'll go
106 |         # ahead and make sure that all our directories are created.
107 |         ensure_dir(os.path.dirname(self._statefile_path))
108 | 
109 |         state = {
110 |             # Include the key so it's easy to tell which pip wrote the
111 |             # file.
112 |             "key": self.key,
113 |             "last_check": current_time.isoformat(),
114 |             "pypi_version": pypi_version,
115 |         }
116 | 
117 |         text = json.dumps(state, sort_keys=True, separators=(",", ":"))
118 | 
119 |         with adjacent_tmp_file(self._statefile_path) as f:
120 |             f.write(text.encode())
121 | 
122 |         try:
123 |             # Since we have a prefix-specific state file, we can just
124 |             # overwrite whatever is there, no need to check.
125 |             replace(f.name, self._statefile_path)
126 |         except OSError:
127 |             # Best effort.
128 |             pass
129 | 
130 | 
131 | @dataclass
132 | class UpgradePrompt:
133 |     old: str
134 |     new: str
135 | 
136 |     def __rich__(self) -> Group:
137 |         if WINDOWS:
138 |             pip_cmd = f"{get_best_invocation_for_this_python()} -m pip"
139 |         else:
140 |             pip_cmd = get_best_invocation_for_this_pip()
141 | 
142 |         notice = "[bold][[reset][blue]notice[reset][bold]][reset]"
143 |         return Group(
144 |             Text(),
145 |             Text.from_markup(
146 |                 f"{notice} A new release of pip is available: "
147 |                 f"[red]{self.old}[reset] -> [green]{self.new}[reset]"
148 |             ),
149 |             Text.from_markup(
150 |                 f"{notice} To update, run: "
151 |                 f"[green]{escape(pip_cmd)} install --upgrade pip"
152 |             ),
153 |         )
154 | 
155 | 
156 | def was_installed_by_pip(pkg: str) -> bool:
157 |     """Checks whether pkg was installed by pip
158 | 
159 |     This is used not to display the upgrade message when pip is in fact
160 |     installed by system package manager, such as dnf on Fedora.
161 |     """
162 |     dist = get_default_environment().get_distribution(pkg)
163 |     return dist is not None and "pip" == dist.installer
164 | 
165 | 
166 | def _get_current_remote_pip_version(
167 |     session: PipSession, options: optparse.Values
168 | ) -> Optional[str]:
169 |     # Lets use PackageFinder to see what the latest pip version is
170 |     link_collector = LinkCollector.create(
171 |         session,
172 |         options=options,
173 |         suppress_no_index=True,
174 |     )
175 | 
176 |     # Pass allow_yanked=False so we don't suggest upgrading to a
177 |     # yanked version.
178 |     selection_prefs = SelectionPreferences(
179 |         allow_yanked=False,
180 |         allow_all_prereleases=False,  # Explicitly set to False
181 |     )
182 | 
183 |     finder = PackageFinder.create(
184 |         link_collector=link_collector,
185 |         selection_prefs=selection_prefs,
186 |     )
187 |     best_candidate = finder.find_best_candidate("pip").best_candidate
188 |     if best_candidate is None:
189 |         return None
190 | 
191 |     return str(best_candidate.version)
192 | 
193 | 
194 | def _self_version_check_logic(
195 |     *,
196 |     state: SelfCheckState,
197 |     current_time: datetime.datetime,
198 |     local_version: Version,
199 |     get_remote_version: Callable[[], Optional[str]],
200 | ) -> Optional[UpgradePrompt]:
201 |     remote_version_str = state.get(current_time)
202 |     if remote_version_str is None:
203 |         remote_version_str = get_remote_version()
204 |         if remote_version_str is None:
205 |             logger.debug("No remote pip version found")
206 |             return None
207 |         state.set(remote_version_str, current_time)
208 | 
209 |     remote_version = parse_version(remote_version_str)
210 |     logger.debug("Remote version of pip: %s", remote_version)
211 |     logger.debug("Local version of pip:  %s", local_version)
212 | 
213 |     pip_installed_by_pip = was_installed_by_pip("pip")
214 |     logger.debug("Was pip installed by pip? %s", pip_installed_by_pip)
215 |     if not pip_installed_by_pip:
216 |         return None  # Only suggest upgrade if pip is installed by pip.
217 | 
218 |     local_version_is_older = (
219 |         local_version < remote_version
220 |         and local_version.base_version != remote_version.base_version
221 |     )
222 |     if local_version_is_older:
223 |         return UpgradePrompt(old=str(local_version), new=remote_version_str)
224 | 
225 |     return None
226 | 
227 | 
228 | def pip_self_version_check(session: PipSession, options: optparse.Values) -> None:
229 |     """Check for an update for pip.
230 | 
231 |     Limit the frequency of checks to once per week. State is stored either in
232 |     the active virtualenv or in the user's USER_CACHE_DIR keyed off the prefix
233 |     of the pip script path.
234 |     """
235 |     installed_dist = get_default_environment().get_distribution("pip")
236 |     if not installed_dist:
237 |         return
238 |     try:
239 |         check_externally_managed()
240 |     except ExternallyManagedEnvironment:
241 |         return
242 | 
243 |     upgrade_prompt = _self_version_check_logic(
244 |         state=SelfCheckState(cache_dir=options.cache_dir),
245 |         current_time=datetime.datetime.now(datetime.timezone.utc),
246 |         local_version=installed_dist.version,
247 |         get_remote_version=functools.partial(
248 |             _get_current_remote_pip_version, session, options
249 |         ),
250 |     )
251 |     if upgrade_prompt is not None:
252 |         logger.warning("%s", upgrade_prompt, extra={"rich": True})
```

.venv/lib/python3.13/site-packages/pip/_internal/wheel_builder.py
```
1 | """Orchestrator for building wheels from InstallRequirements."""
2 | 
3 | import logging
4 | import os.path
5 | import re
6 | import shutil
7 | from typing import Iterable, List, Optional, Tuple
8 | 
9 | from pip._vendor.packaging.utils import canonicalize_name, canonicalize_version
10 | from pip._vendor.packaging.version import InvalidVersion, Version
11 | 
12 | from pip._internal.cache import WheelCache
13 | from pip._internal.exceptions import InvalidWheelFilename, UnsupportedWheel
14 | from pip._internal.metadata import FilesystemWheel, get_wheel_distribution
15 | from pip._internal.models.link import Link
16 | from pip._internal.models.wheel import Wheel
17 | from pip._internal.operations.build.wheel import build_wheel_pep517
18 | from pip._internal.operations.build.wheel_editable import build_wheel_editable
19 | from pip._internal.operations.build.wheel_legacy import build_wheel_legacy
20 | from pip._internal.req.req_install import InstallRequirement
21 | from pip._internal.utils.logging import indent_log
22 | from pip._internal.utils.misc import ensure_dir, hash_file
23 | from pip._internal.utils.setuptools_build import make_setuptools_clean_args
24 | from pip._internal.utils.subprocess import call_subprocess
25 | from pip._internal.utils.temp_dir import TempDirectory
26 | from pip._internal.utils.urls import path_to_url
27 | from pip._internal.vcs import vcs
28 | 
29 | logger = logging.getLogger(__name__)
30 | 
31 | _egg_info_re = re.compile(r"([a-z0-9_.]+)-([a-z0-9_.!+-]+)", re.IGNORECASE)
32 | 
33 | BuildResult = Tuple[List[InstallRequirement], List[InstallRequirement]]
34 | 
35 | 
36 | def _contains_egg_info(s: str) -> bool:
37 |     """Determine whether the string looks like an egg_info.
38 | 
39 |     :param s: The string to parse. E.g. foo-2.1
40 |     """
41 |     return bool(_egg_info_re.search(s))
42 | 
43 | 
44 | def _should_build(
45 |     req: InstallRequirement,
46 | ) -> bool:
47 |     """Return whether an InstallRequirement should be built into a wheel."""
48 |     assert not req.constraint
49 | 
50 |     if req.is_wheel:
51 |         return False
52 | 
53 |     assert req.source_dir
54 | 
55 |     if req.editable:
56 |         # we only build PEP 660 editable requirements
57 |         return req.supports_pyproject_editable
58 | 
59 |     return True
60 | 
61 | 
62 | def should_build_for_install_command(
63 |     req: InstallRequirement,
64 | ) -> bool:
65 |     return _should_build(req)
66 | 
67 | 
68 | def _should_cache(
69 |     req: InstallRequirement,
70 | ) -> Optional[bool]:
71 |     """
72 |     Return whether a built InstallRequirement can be stored in the persistent
73 |     wheel cache, assuming the wheel cache is available, and _should_build()
74 |     has determined a wheel needs to be built.
75 |     """
76 |     if req.editable or not req.source_dir:
77 |         # never cache editable requirements
78 |         return False
79 | 
80 |     if req.link and req.link.is_vcs:
81 |         # VCS checkout. Do not cache
82 |         # unless it points to an immutable commit hash.
83 |         assert not req.editable
84 |         assert req.source_dir
85 |         vcs_backend = vcs.get_backend_for_scheme(req.link.scheme)
86 |         assert vcs_backend
87 |         if vcs_backend.is_immutable_rev_checkout(req.link.url, req.source_dir):
88 |             return True
89 |         return False
90 | 
91 |     assert req.link
92 |     base, ext = req.link.splitext()
93 |     if _contains_egg_info(base):
94 |         return True
95 | 
96 |     # Otherwise, do not cache.
97 |     return False
98 | 
99 | 
100 | def _get_cache_dir(
101 |     req: InstallRequirement,
102 |     wheel_cache: WheelCache,
103 | ) -> str:
104 |     """Return the persistent or temporary cache directory where the built
105 |     wheel need to be stored.
106 |     """
107 |     cache_available = bool(wheel_cache.cache_dir)
108 |     assert req.link
109 |     if cache_available and _should_cache(req):
110 |         cache_dir = wheel_cache.get_path_for_link(req.link)
111 |     else:
112 |         cache_dir = wheel_cache.get_ephem_path_for_link(req.link)
113 |     return cache_dir
114 | 
115 | 
116 | def _verify_one(req: InstallRequirement, wheel_path: str) -> None:
117 |     canonical_name = canonicalize_name(req.name or "")
118 |     w = Wheel(os.path.basename(wheel_path))
119 |     if canonicalize_name(w.name) != canonical_name:
120 |         raise InvalidWheelFilename(
121 |             f"Wheel has unexpected file name: expected {canonical_name!r}, "
122 |             f"got {w.name!r}",
123 |         )
124 |     dist = get_wheel_distribution(FilesystemWheel(wheel_path), canonical_name)
125 |     dist_verstr = str(dist.version)
126 |     if canonicalize_version(dist_verstr) != canonicalize_version(w.version):
127 |         raise InvalidWheelFilename(
128 |             f"Wheel has unexpected file name: expected {dist_verstr!r}, "
129 |             f"got {w.version!r}",
130 |         )
131 |     metadata_version_value = dist.metadata_version
132 |     if metadata_version_value is None:
133 |         raise UnsupportedWheel("Missing Metadata-Version")
134 |     try:
135 |         metadata_version = Version(metadata_version_value)
136 |     except InvalidVersion:
137 |         msg = f"Invalid Metadata-Version: {metadata_version_value}"
138 |         raise UnsupportedWheel(msg)
139 |     if metadata_version >= Version("1.2") and not isinstance(dist.version, Version):
140 |         raise UnsupportedWheel(
141 |             f"Metadata 1.2 mandates PEP 440 version, but {dist_verstr!r} is not"
142 |         )
143 | 
144 | 
145 | def _build_one(
146 |     req: InstallRequirement,
147 |     output_dir: str,
148 |     verify: bool,
149 |     build_options: List[str],
150 |     global_options: List[str],
151 |     editable: bool,
152 | ) -> Optional[str]:
153 |     """Build one wheel.
154 | 
155 |     :return: The filename of the built wheel, or None if the build failed.
156 |     """
157 |     artifact = "editable" if editable else "wheel"
158 |     try:
159 |         ensure_dir(output_dir)
160 |     except OSError as e:
161 |         logger.warning(
162 |             "Building %s for %s failed: %s",
163 |             artifact,
164 |             req.name,
165 |             e,
166 |         )
167 |         return None
168 | 
169 |     # Install build deps into temporary directory (PEP 518)
170 |     with req.build_env:
171 |         wheel_path = _build_one_inside_env(
172 |             req, output_dir, build_options, global_options, editable
173 |         )
174 |     if wheel_path and verify:
175 |         try:
176 |             _verify_one(req, wheel_path)
177 |         except (InvalidWheelFilename, UnsupportedWheel) as e:
178 |             logger.warning("Built %s for %s is invalid: %s", artifact, req.name, e)
179 |             return None
180 |     return wheel_path
181 | 
182 | 
183 | def _build_one_inside_env(
184 |     req: InstallRequirement,
185 |     output_dir: str,
186 |     build_options: List[str],
187 |     global_options: List[str],
188 |     editable: bool,
189 | ) -> Optional[str]:
190 |     with TempDirectory(kind="wheel") as temp_dir:
191 |         assert req.name
192 |         if req.use_pep517:
193 |             assert req.metadata_directory
194 |             assert req.pep517_backend
195 |             if global_options:
196 |                 logger.warning(
197 |                     "Ignoring --global-option when building %s using PEP 517", req.name
198 |                 )
199 |             if build_options:
200 |                 logger.warning(
201 |                     "Ignoring --build-option when building %s using PEP 517", req.name
202 |                 )
203 |             if editable:
204 |                 wheel_path = build_wheel_editable(
205 |                     name=req.name,
206 |                     backend=req.pep517_backend,
207 |                     metadata_directory=req.metadata_directory,
208 |                     tempd=temp_dir.path,
209 |                 )
210 |             else:
211 |                 wheel_path = build_wheel_pep517(
212 |                     name=req.name,
213 |                     backend=req.pep517_backend,
214 |                     metadata_directory=req.metadata_directory,
215 |                     tempd=temp_dir.path,
216 |                 )
217 |         else:
218 |             wheel_path = build_wheel_legacy(
219 |                 name=req.name,
220 |                 setup_py_path=req.setup_py_path,
221 |                 source_dir=req.unpacked_source_directory,
222 |                 global_options=global_options,
223 |                 build_options=build_options,
224 |                 tempd=temp_dir.path,
225 |             )
226 | 
227 |         if wheel_path is not None:
228 |             wheel_name = os.path.basename(wheel_path)
229 |             dest_path = os.path.join(output_dir, wheel_name)
230 |             try:
231 |                 wheel_hash, length = hash_file(wheel_path)
232 |                 shutil.move(wheel_path, dest_path)
233 |                 logger.info(
234 |                     "Created wheel for %s: filename=%s size=%d sha256=%s",
235 |                     req.name,
236 |                     wheel_name,
237 |                     length,
238 |                     wheel_hash.hexdigest(),
239 |                 )
240 |                 logger.info("Stored in directory: %s", output_dir)
241 |                 return dest_path
242 |             except Exception as e:
243 |                 logger.warning(
244 |                     "Building wheel for %s failed: %s",
245 |                     req.name,
246 |                     e,
247 |                 )
248 |         # Ignore return, we can't do anything else useful.
249 |         if not req.use_pep517:
250 |             _clean_one_legacy(req, global_options)
251 |         return None
252 | 
253 | 
254 | def _clean_one_legacy(req: InstallRequirement, global_options: List[str]) -> bool:
255 |     clean_args = make_setuptools_clean_args(
256 |         req.setup_py_path,
257 |         global_options=global_options,
258 |     )
259 | 
260 |     logger.info("Running setup.py clean for %s", req.name)
261 |     try:
262 |         call_subprocess(
263 |             clean_args, command_desc="python setup.py clean", cwd=req.source_dir
264 |         )
265 |         return True
266 |     except Exception:
267 |         logger.error("Failed cleaning build dir for %s", req.name)
268 |         return False
269 | 
270 | 
271 | def build(
272 |     requirements: Iterable[InstallRequirement],
273 |     wheel_cache: WheelCache,
274 |     verify: bool,
275 |     build_options: List[str],
276 |     global_options: List[str],
277 | ) -> BuildResult:
278 |     """Build wheels.
279 | 
280 |     :return: The list of InstallRequirement that succeeded to build and
281 |         the list of InstallRequirement that failed to build.
282 |     """
283 |     if not requirements:
284 |         return [], []
285 | 
286 |     # Build the wheels.
287 |     logger.info(
288 |         "Building wheels for collected packages: %s",
289 |         ", ".join(req.name for req in requirements),  # type: ignore
290 |     )
291 | 
292 |     with indent_log():
293 |         build_successes, build_failures = [], []
294 |         for req in requirements:
295 |             assert req.name
296 |             cache_dir = _get_cache_dir(req, wheel_cache)
297 |             wheel_file = _build_one(
298 |                 req,
299 |                 cache_dir,
300 |                 verify,
301 |                 build_options,
302 |                 global_options,
303 |                 req.editable and req.permit_editable_wheels,
304 |             )
305 |             if wheel_file:
306 |                 # Record the download origin in the cache
307 |                 if req.download_info is not None:
308 |                     # download_info is guaranteed to be set because when we build an
309 |                     # InstallRequirement it has been through the preparer before, but
310 |                     # let's be cautious.
311 |                     wheel_cache.record_download_origin(cache_dir, req.download_info)
312 |                 # Update the link for this.
313 |                 req.link = Link(path_to_url(wheel_file))
314 |                 req.local_file_path = req.link.file_path
315 |                 assert req.link.is_wheel
316 |                 build_successes.append(req)
317 |             else:
318 |                 build_failures.append(req)
319 | 
320 |     # notify success/failure
321 |     if build_successes:
322 |         logger.info(
323 |             "Successfully built %s",
324 |             " ".join([req.name for req in build_successes]),  # type: ignore
325 |         )
326 |     if build_failures:
327 |         logger.info(
328 |             "Failed to build %s",
329 |             " ".join([req.name for req in build_failures]),  # type: ignore
330 |         )
331 |     # Return a list of requirements that failed to build
332 |     return build_successes, build_failures
```

.venv/lib/python3.13/site-packages/pip/_vendor/__init__.py
```
1 | """
2 | pip._vendor is for vendoring dependencies of pip to prevent needing pip to
3 | depend on something external.
4 | 
5 | Files inside of pip._vendor should be considered immutable and should only be
6 | updated to versions from upstream.
7 | """
8 | from __future__ import absolute_import
9 | 
10 | import glob
11 | import os.path
12 | import sys
13 | 
14 | # Downstream redistributors which have debundled our dependencies should also
15 | # patch this value to be true. This will trigger the additional patching
16 | # to cause things like "six" to be available as pip.
17 | DEBUNDLED = False
18 | 
19 | # By default, look in this directory for a bunch of .whl files which we will
20 | # add to the beginning of sys.path before attempting to import anything. This
21 | # is done to support downstream re-distributors like Debian and Fedora who
22 | # wish to create their own Wheels for our dependencies to aid in debundling.
23 | WHEEL_DIR = os.path.abspath(os.path.dirname(__file__))
24 | 
25 | 
26 | # Define a small helper function to alias our vendored modules to the real ones
27 | # if the vendored ones do not exist. This idea of this was taken from
28 | # https://github.com/kennethreitz/requests/pull/2567.
29 | def vendored(modulename):
30 |     vendored_name = "{0}.{1}".format(__name__, modulename)
31 | 
32 |     try:
33 |         __import__(modulename, globals(), locals(), level=0)
34 |     except ImportError:
35 |         # We can just silently allow import failures to pass here. If we
36 |         # got to this point it means that ``import pip._vendor.whatever``
37 |         # failed and so did ``import whatever``. Since we're importing this
38 |         # upfront in an attempt to alias imports, not erroring here will
39 |         # just mean we get a regular import error whenever pip *actually*
40 |         # tries to import one of these modules to use it, which actually
41 |         # gives us a better error message than we would have otherwise
42 |         # gotten.
43 |         pass
44 |     else:
45 |         sys.modules[vendored_name] = sys.modules[modulename]
46 |         base, head = vendored_name.rsplit(".", 1)
47 |         setattr(sys.modules[base], head, sys.modules[modulename])
48 | 
49 | 
50 | # If we're operating in a debundled setup, then we want to go ahead and trigger
51 | # the aliasing of our vendored libraries as well as looking for wheels to add
52 | # to our sys.path. This will cause all of this code to be a no-op typically
53 | # however downstream redistributors can enable it in a consistent way across
54 | # all platforms.
55 | if DEBUNDLED:
56 |     # Actually look inside of WHEEL_DIR to find .whl files and add them to the
57 |     # front of our sys.path.
58 |     sys.path[:] = glob.glob(os.path.join(WHEEL_DIR, "*.whl")) + sys.path
59 | 
60 |     # Actually alias all of our vendored dependencies.
61 |     vendored("cachecontrol")
62 |     vendored("certifi")
63 |     vendored("dependency-groups")
64 |     vendored("distlib")
65 |     vendored("distro")
66 |     vendored("packaging")
67 |     vendored("packaging.version")
68 |     vendored("packaging.specifiers")
69 |     vendored("pkg_resources")
70 |     vendored("platformdirs")
71 |     vendored("progress")
72 |     vendored("pyproject_hooks")
73 |     vendored("requests")
74 |     vendored("requests.exceptions")
75 |     vendored("requests.packages")
76 |     vendored("requests.packages.urllib3")
77 |     vendored("requests.packages.urllib3._collections")
78 |     vendored("requests.packages.urllib3.connection")
79 |     vendored("requests.packages.urllib3.connectionpool")
80 |     vendored("requests.packages.urllib3.contrib")
81 |     vendored("requests.packages.urllib3.contrib.ntlmpool")
82 |     vendored("requests.packages.urllib3.contrib.pyopenssl")
83 |     vendored("requests.packages.urllib3.exceptions")
84 |     vendored("requests.packages.urllib3.fields")
85 |     vendored("requests.packages.urllib3.filepost")
86 |     vendored("requests.packages.urllib3.packages")
87 |     vendored("requests.packages.urllib3.packages.ordered_dict")
88 |     vendored("requests.packages.urllib3.packages.six")
89 |     vendored("requests.packages.urllib3.packages.ssl_match_hostname")
90 |     vendored("requests.packages.urllib3.packages.ssl_match_hostname."
91 |              "_implementation")
92 |     vendored("requests.packages.urllib3.poolmanager")
93 |     vendored("requests.packages.urllib3.request")
94 |     vendored("requests.packages.urllib3.response")
95 |     vendored("requests.packages.urllib3.util")
96 |     vendored("requests.packages.urllib3.util.connection")
97 |     vendored("requests.packages.urllib3.util.request")
98 |     vendored("requests.packages.urllib3.util.response")
99 |     vendored("requests.packages.urllib3.util.retry")
100 |     vendored("requests.packages.urllib3.util.ssl_")
101 |     vendored("requests.packages.urllib3.util.timeout")
102 |     vendored("requests.packages.urllib3.util.url")
103 |     vendored("resolvelib")
104 |     vendored("rich")
105 |     vendored("rich.console")
106 |     vendored("rich.highlighter")
107 |     vendored("rich.logging")
108 |     vendored("rich.markup")
109 |     vendored("rich.progress")
110 |     vendored("rich.segment")
111 |     vendored("rich.style")
112 |     vendored("rich.text")
113 |     vendored("rich.traceback")
114 |     if sys.version_info < (3, 11):
115 |         vendored("tomli")
116 |     vendored("truststore")
117 |     vendored("urllib3")
```

.venv/lib/python3.13/site-packages/pip/_vendor/typing_extensions.py
```
1 | import abc
2 | import builtins
3 | import collections
4 | import collections.abc
5 | import contextlib
6 | import enum
7 | import functools
8 | import inspect
9 | import keyword
10 | import operator
11 | import sys
12 | import types as _types
13 | import typing
14 | import warnings
15 | 
16 | __all__ = [
17 |     # Super-special typing primitives.
18 |     'Any',
19 |     'ClassVar',
20 |     'Concatenate',
21 |     'Final',
22 |     'LiteralString',
23 |     'ParamSpec',
24 |     'ParamSpecArgs',
25 |     'ParamSpecKwargs',
26 |     'Self',
27 |     'Type',
28 |     'TypeVar',
29 |     'TypeVarTuple',
30 |     'Unpack',
31 | 
32 |     # ABCs (from collections.abc).
33 |     'Awaitable',
34 |     'AsyncIterator',
35 |     'AsyncIterable',
36 |     'Coroutine',
37 |     'AsyncGenerator',
38 |     'AsyncContextManager',
39 |     'Buffer',
40 |     'ChainMap',
41 | 
42 |     # Concrete collection types.
43 |     'ContextManager',
44 |     'Counter',
45 |     'Deque',
46 |     'DefaultDict',
47 |     'NamedTuple',
48 |     'OrderedDict',
49 |     'TypedDict',
50 | 
51 |     # Structural checks, a.k.a. protocols.
52 |     'SupportsAbs',
53 |     'SupportsBytes',
54 |     'SupportsComplex',
55 |     'SupportsFloat',
56 |     'SupportsIndex',
57 |     'SupportsInt',
58 |     'SupportsRound',
59 | 
60 |     # One-off things.
61 |     'Annotated',
62 |     'assert_never',
63 |     'assert_type',
64 |     'clear_overloads',
65 |     'dataclass_transform',
66 |     'deprecated',
67 |     'Doc',
68 |     'evaluate_forward_ref',
69 |     'get_overloads',
70 |     'final',
71 |     'Format',
72 |     'get_annotations',
73 |     'get_args',
74 |     'get_origin',
75 |     'get_original_bases',
76 |     'get_protocol_members',
77 |     'get_type_hints',
78 |     'IntVar',
79 |     'is_protocol',
80 |     'is_typeddict',
81 |     'Literal',
82 |     'NewType',
83 |     'overload',
84 |     'override',
85 |     'Protocol',
86 |     'reveal_type',
87 |     'runtime',
88 |     'runtime_checkable',
89 |     'Text',
90 |     'TypeAlias',
91 |     'TypeAliasType',
92 |     'TypeForm',
93 |     'TypeGuard',
94 |     'TypeIs',
95 |     'TYPE_CHECKING',
96 |     'Never',
97 |     'NoReturn',
98 |     'ReadOnly',
99 |     'Required',
100 |     'NotRequired',
101 |     'NoDefault',
102 |     'NoExtraItems',
103 | 
104 |     # Pure aliases, have always been in typing
105 |     'AbstractSet',
106 |     'AnyStr',
107 |     'BinaryIO',
108 |     'Callable',
109 |     'Collection',
110 |     'Container',
111 |     'Dict',
112 |     'ForwardRef',
113 |     'FrozenSet',
114 |     'Generator',
115 |     'Generic',
116 |     'Hashable',
117 |     'IO',
118 |     'ItemsView',
119 |     'Iterable',
120 |     'Iterator',
121 |     'KeysView',
122 |     'List',
123 |     'Mapping',
124 |     'MappingView',
125 |     'Match',
126 |     'MutableMapping',
127 |     'MutableSequence',
128 |     'MutableSet',
129 |     'Optional',
130 |     'Pattern',
131 |     'Reversible',
132 |     'Sequence',
133 |     'Set',
134 |     'Sized',
135 |     'TextIO',
136 |     'Tuple',
137 |     'Union',
138 |     'ValuesView',
139 |     'cast',
140 |     'no_type_check',
141 |     'no_type_check_decorator',
142 | ]
143 | 
144 | # for backward compatibility
145 | PEP_560 = True
146 | GenericMeta = type
147 | _PEP_696_IMPLEMENTED = sys.version_info >= (3, 13, 0, "beta")
148 | 
149 | # Added with bpo-45166 to 3.10.1+ and some 3.9 versions
150 | _FORWARD_REF_HAS_CLASS = "__forward_is_class__" in typing.ForwardRef.__slots__
151 | 
152 | # The functions below are modified copies of typing internal helpers.
153 | # They are needed by _ProtocolMeta and they provide support for PEP 646.
154 | 
155 | 
156 | class _Sentinel:
157 |     def __repr__(self):
158 |         return "<sentinel>"
159 | 
160 | 
161 | _marker = _Sentinel()
162 | 
163 | 
164 | if sys.version_info >= (3, 10):
165 |     def _should_collect_from_parameters(t):
166 |         return isinstance(
167 |             t, (typing._GenericAlias, _types.GenericAlias, _types.UnionType)
168 |         )
169 | elif sys.version_info >= (3, 9):
170 |     def _should_collect_from_parameters(t):
171 |         return isinstance(t, (typing._GenericAlias, _types.GenericAlias))
172 | else:
173 |     def _should_collect_from_parameters(t):
174 |         return isinstance(t, typing._GenericAlias) and not t._special
175 | 
176 | 
177 | NoReturn = typing.NoReturn
178 | 
179 | # Some unconstrained type variables.  These are used by the container types.
180 | # (These are not for export.)
181 | T = typing.TypeVar('T')  # Any type.
182 | KT = typing.TypeVar('KT')  # Key type.
183 | VT = typing.TypeVar('VT')  # Value type.
184 | T_co = typing.TypeVar('T_co', covariant=True)  # Any type covariant containers.
185 | T_contra = typing.TypeVar('T_contra', contravariant=True)  # Ditto contravariant.
186 | 
187 | 
188 | if sys.version_info >= (3, 11):
189 |     from typing import Any
190 | else:
191 | 
192 |     class _AnyMeta(type):
193 |         def __instancecheck__(self, obj):
194 |             if self is Any:
195 |                 raise TypeError("typing_extensions.Any cannot be used with isinstance()")
196 |             return super().__instancecheck__(obj)
197 | 
198 |         def __repr__(self):
199 |             if self is Any:
200 |                 return "typing_extensions.Any"
201 |             return super().__repr__()
202 | 
203 |     class Any(metaclass=_AnyMeta):
204 |         """Special type indicating an unconstrained type.
205 |         - Any is compatible with every type.
206 |         - Any assumed to have all methods.
207 |         - All values assumed to be instances of Any.
208 |         Note that all the above statements are true from the point of view of
209 |         static type checkers. At runtime, Any should not be used with instance
210 |         checks.
211 |         """
212 |         def __new__(cls, *args, **kwargs):
213 |             if cls is Any:
214 |                 raise TypeError("Any cannot be instantiated")
215 |             return super().__new__(cls, *args, **kwargs)
216 | 
217 | 
218 | ClassVar = typing.ClassVar
219 | 
220 | 
221 | class _ExtensionsSpecialForm(typing._SpecialForm, _root=True):
222 |     def __repr__(self):
223 |         return 'typing_extensions.' + self._name
224 | 
225 | 
226 | Final = typing.Final
227 | 
228 | if sys.version_info >= (3, 11):
229 |     final = typing.final
230 | else:
231 |     # @final exists in 3.8+, but we backport it for all versions
232 |     # before 3.11 to keep support for the __final__ attribute.
233 |     # See https://bugs.python.org/issue46342
234 |     def final(f):
235 |         """This decorator can be used to indicate to type checkers that
236 |         the decorated method cannot be overridden, and decorated class
237 |         cannot be subclassed. For example:
238 | 
239 |             class Base:
240 |                 @final
241 |                 def done(self) -> None:
242 |                     ...
243 |             class Sub(Base):
244 |                 def done(self) -> None:  # Error reported by type checker
245 |                     ...
246 |             @final
247 |             class Leaf:
248 |                 ...
249 |             class Other(Leaf):  # Error reported by type checker
250 |                 ...
251 | 
252 |         There is no runtime checking of these properties. The decorator
253 |         sets the ``__final__`` attribute to ``True`` on the decorated object
254 |         to allow runtime introspection.
255 |         """
256 |         try:
257 |             f.__final__ = True
258 |         except (AttributeError, TypeError):
259 |             # Skip the attribute silently if it is not writable.
260 |             # AttributeError happens if the object has __slots__ or a
261 |             # read-only property, TypeError if it's a builtin class.
262 |             pass
263 |         return f
264 | 
265 | 
266 | def IntVar(name):
267 |     return typing.TypeVar(name)
268 | 
269 | 
270 | # A Literal bug was fixed in 3.11.0, 3.10.1 and 3.9.8
271 | if sys.version_info >= (3, 10, 1):
272 |     Literal = typing.Literal
273 | else:
274 |     def _flatten_literal_params(parameters):
275 |         """An internal helper for Literal creation: flatten Literals among parameters"""
276 |         params = []
277 |         for p in parameters:
278 |             if isinstance(p, _LiteralGenericAlias):
279 |                 params.extend(p.__args__)
280 |             else:
281 |                 params.append(p)
282 |         return tuple(params)
283 | 
284 |     def _value_and_type_iter(params):
285 |         for p in params:
286 |             yield p, type(p)
287 | 
288 |     class _LiteralGenericAlias(typing._GenericAlias, _root=True):
289 |         def __eq__(self, other):
290 |             if not isinstance(other, _LiteralGenericAlias):
291 |                 return NotImplemented
292 |             these_args_deduped = set(_value_and_type_iter(self.__args__))
293 |             other_args_deduped = set(_value_and_type_iter(other.__args__))
294 |             return these_args_deduped == other_args_deduped
295 | 
296 |         def __hash__(self):
297 |             return hash(frozenset(_value_and_type_iter(self.__args__)))
298 | 
299 |     class _LiteralForm(_ExtensionsSpecialForm, _root=True):
300 |         def __init__(self, doc: str):
301 |             self._name = 'Literal'
302 |             self._doc = self.__doc__ = doc
303 | 
304 |         def __getitem__(self, parameters):
305 |             if not isinstance(parameters, tuple):
306 |                 parameters = (parameters,)
307 | 
308 |             parameters = _flatten_literal_params(parameters)
309 | 
310 |             val_type_pairs = list(_value_and_type_iter(parameters))
311 |             try:
312 |                 deduped_pairs = set(val_type_pairs)
313 |             except TypeError:
314 |                 # unhashable parameters
315 |                 pass
316 |             else:
317 |                 # similar logic to typing._deduplicate on Python 3.9+
318 |                 if len(deduped_pairs) < len(val_type_pairs):
319 |                     new_parameters = []
320 |                     for pair in val_type_pairs:
321 |                         if pair in deduped_pairs:
322 |                             new_parameters.append(pair[0])
323 |                             deduped_pairs.remove(pair)
324 |                     assert not deduped_pairs, deduped_pairs
325 |                     parameters = tuple(new_parameters)
326 | 
327 |             return _LiteralGenericAlias(self, parameters)
328 | 
329 |     Literal = _LiteralForm(doc="""\
330 |                            A type that can be used to indicate to type checkers
331 |                            that the corresponding value has a value literally equivalent
332 |                            to the provided parameter. For example:
333 | 
334 |                                var: Literal[4] = 4
335 | 
336 |                            The type checker understands that 'var' is literally equal to
337 |                            the value 4 and no other value.
338 | 
339 |                            Literal[...] cannot be subclassed. There is no runtime
340 |                            checking verifying that the parameter is actually a value
341 |                            instead of a type.""")
342 | 
343 | 
344 | _overload_dummy = typing._overload_dummy
345 | 
346 | 
347 | if hasattr(typing, "get_overloads"):  # 3.11+
348 |     overload = typing.overload
349 |     get_overloads = typing.get_overloads
350 |     clear_overloads = typing.clear_overloads
351 | else:
352 |     # {module: {qualname: {firstlineno: func}}}
353 |     _overload_registry = collections.defaultdict(
354 |         functools.partial(collections.defaultdict, dict)
355 |     )
356 | 
357 |     def overload(func):
358 |         """Decorator for overloaded functions/methods.
359 | 
360 |         In a stub file, place two or more stub definitions for the same
361 |         function in a row, each decorated with @overload.  For example:
362 | 
363 |         @overload
364 |         def utf8(value: None) -> None: ...
365 |         @overload
366 |         def utf8(value: bytes) -> bytes: ...
367 |         @overload
368 |         def utf8(value: str) -> bytes: ...
369 | 
370 |         In a non-stub file (i.e. a regular .py file), do the same but
371 |         follow it with an implementation.  The implementation should *not*
372 |         be decorated with @overload.  For example:
373 | 
374 |         @overload
375 |         def utf8(value: None) -> None: ...
376 |         @overload
377 |         def utf8(value: bytes) -> bytes: ...
378 |         @overload
379 |         def utf8(value: str) -> bytes: ...
380 |         def utf8(value):
381 |             # implementation goes here
382 | 
383 |         The overloads for a function can be retrieved at runtime using the
384 |         get_overloads() function.
385 |         """
386 |         # classmethod and staticmethod
387 |         f = getattr(func, "__func__", func)
388 |         try:
389 |             _overload_registry[f.__module__][f.__qualname__][
390 |                 f.__code__.co_firstlineno
391 |             ] = func
392 |         except AttributeError:
393 |             # Not a normal function; ignore.
394 |             pass
395 |         return _overload_dummy
396 | 
397 |     def get_overloads(func):
398 |         """Return all defined overloads for *func* as a sequence."""
399 |         # classmethod and staticmethod
400 |         f = getattr(func, "__func__", func)
401 |         if f.__module__ not in _overload_registry:
402 |             return []
403 |         mod_dict = _overload_registry[f.__module__]
404 |         if f.__qualname__ not in mod_dict:
405 |             return []
406 |         return list(mod_dict[f.__qualname__].values())
407 | 
408 |     def clear_overloads():
409 |         """Clear all overloads in the registry."""
410 |         _overload_registry.clear()
411 | 
412 | 
413 | # This is not a real generic class.  Don't use outside annotations.
414 | Type = typing.Type
415 | 
416 | # Various ABCs mimicking those in collections.abc.
417 | # A few are simply re-exported for completeness.
418 | Awaitable = typing.Awaitable
419 | Coroutine = typing.Coroutine
420 | AsyncIterable = typing.AsyncIterable
421 | AsyncIterator = typing.AsyncIterator
422 | Deque = typing.Deque
423 | DefaultDict = typing.DefaultDict
424 | OrderedDict = typing.OrderedDict
425 | Counter = typing.Counter
426 | ChainMap = typing.ChainMap
427 | Text = typing.Text
[TRUNCATED]
```

.venv/lib/python3.13/site-packages/pip/_vendor/vendor.txt
```
1 | CacheControl==0.14.2
2 | distlib==0.3.9
3 | distro==1.9.0
4 | msgpack==1.1.0
5 | packaging==25.0
6 | platformdirs==4.3.7
7 | pyproject-hooks==1.2.0
8 | requests==2.32.3
9 |     certifi==2025.1.31
10 |     idna==3.10
11 |     urllib3==1.26.20
12 | rich==14.0.0
13 |     pygments==2.19.1
14 |     typing_extensions==4.13.2
15 | resolvelib==1.1.0
16 | setuptools==70.3.0
17 | tomli==2.2.1
18 | tomli-w==1.2.0
19 | truststore==0.10.1
20 | dependency-groups==1.3.1
```

.venv/lib/python3.13/site-packages/pip/_internal/cli/__init__.py
```
1 | """Subpackage containing all of pip's command line interface related code"""
2 | 
3 | # This file intentionally does not import submodules
```

.venv/lib/python3.13/site-packages/pip/_internal/cli/autocompletion.py
```
1 | """Logic that powers autocompletion installed by ``pip completion``."""
2 | 
3 | import optparse
4 | import os
5 | import sys
6 | from itertools import chain
7 | from typing import Any, Iterable, List, Optional
8 | 
9 | from pip._internal.cli.main_parser import create_main_parser
10 | from pip._internal.commands import commands_dict, create_command
11 | from pip._internal.metadata import get_default_environment
12 | 
13 | 
14 | def autocomplete() -> None:
15 |     """Entry Point for completion of main and subcommand options."""
16 |     # Don't complete if user hasn't sourced bash_completion file.
17 |     if "PIP_AUTO_COMPLETE" not in os.environ:
18 |         return
19 |     # Don't complete if autocompletion environment variables
20 |     # are not present
21 |     if not os.environ.get("COMP_WORDS") or not os.environ.get("COMP_CWORD"):
22 |         return
23 |     cwords = os.environ["COMP_WORDS"].split()[1:]
24 |     cword = int(os.environ["COMP_CWORD"])
25 |     try:
26 |         current = cwords[cword - 1]
27 |     except IndexError:
28 |         current = ""
29 | 
30 |     parser = create_main_parser()
31 |     subcommands = list(commands_dict)
32 |     options = []
33 | 
34 |     # subcommand
35 |     subcommand_name: Optional[str] = None
36 |     for word in cwords:
37 |         if word in subcommands:
38 |             subcommand_name = word
39 |             break
40 |     # subcommand options
41 |     if subcommand_name is not None:
42 |         # special case: 'help' subcommand has no options
43 |         if subcommand_name == "help":
44 |             sys.exit(1)
45 |         # special case: list locally installed dists for show and uninstall
46 |         should_list_installed = not current.startswith("-") and subcommand_name in [
47 |             "show",
48 |             "uninstall",
49 |         ]
50 |         if should_list_installed:
51 |             env = get_default_environment()
52 |             lc = current.lower()
53 |             installed = [
54 |                 dist.canonical_name
55 |                 for dist in env.iter_installed_distributions(local_only=True)
56 |                 if dist.canonical_name.startswith(lc)
57 |                 and dist.canonical_name not in cwords[1:]
58 |             ]
59 |             # if there are no dists installed, fall back to option completion
60 |             if installed:
61 |                 for dist in installed:
62 |                     print(dist)
63 |                 sys.exit(1)
64 | 
65 |         should_list_installables = (
66 |             not current.startswith("-") and subcommand_name == "install"
67 |         )
68 |         if should_list_installables:
69 |             for path in auto_complete_paths(current, "path"):
70 |                 print(path)
71 |             sys.exit(1)
72 | 
73 |         subcommand = create_command(subcommand_name)
74 | 
75 |         for opt in subcommand.parser.option_list_all:
76 |             if opt.help != optparse.SUPPRESS_HELP:
77 |                 options += [
78 |                     (opt_str, opt.nargs) for opt_str in opt._long_opts + opt._short_opts
79 |                 ]
80 | 
81 |         # filter out previously specified options from available options
82 |         prev_opts = [x.split("=")[0] for x in cwords[1 : cword - 1]]
83 |         options = [(x, v) for (x, v) in options if x not in prev_opts]
84 |         # filter options by current input
85 |         options = [(k, v) for k, v in options if k.startswith(current)]
86 |         # get completion type given cwords and available subcommand options
87 |         completion_type = get_path_completion_type(
88 |             cwords,
89 |             cword,
90 |             subcommand.parser.option_list_all,
91 |         )
92 |         # get completion files and directories if ``completion_type`` is
93 |         # ``<file>``, ``<dir>`` or ``<path>``
94 |         if completion_type:
95 |             paths = auto_complete_paths(current, completion_type)
96 |             options = [(path, 0) for path in paths]
97 |         for option in options:
98 |             opt_label = option[0]
99 |             # append '=' to options which require args
100 |             if option[1] and option[0][:2] == "--":
101 |                 opt_label += "="
102 |             print(opt_label)
103 |     else:
104 |         # show main parser options only when necessary
105 | 
106 |         opts = [i.option_list for i in parser.option_groups]
107 |         opts.append(parser.option_list)
108 |         flattened_opts = chain.from_iterable(opts)
109 |         if current.startswith("-"):
110 |             for opt in flattened_opts:
111 |                 if opt.help != optparse.SUPPRESS_HELP:
112 |                     subcommands += opt._long_opts + opt._short_opts
113 |         else:
114 |             # get completion type given cwords and all available options
115 |             completion_type = get_path_completion_type(cwords, cword, flattened_opts)
116 |             if completion_type:
117 |                 subcommands = list(auto_complete_paths(current, completion_type))
118 | 
119 |         print(" ".join([x for x in subcommands if x.startswith(current)]))
120 |     sys.exit(1)
121 | 
122 | 
123 | def get_path_completion_type(
124 |     cwords: List[str], cword: int, opts: Iterable[Any]
125 | ) -> Optional[str]:
126 |     """Get the type of path completion (``file``, ``dir``, ``path`` or None)
127 | 
128 |     :param cwords: same as the environmental variable ``COMP_WORDS``
129 |     :param cword: same as the environmental variable ``COMP_CWORD``
130 |     :param opts: The available options to check
131 |     :return: path completion type (``file``, ``dir``, ``path`` or None)
132 |     """
133 |     if cword < 2 or not cwords[cword - 2].startswith("-"):
134 |         return None
135 |     for opt in opts:
136 |         if opt.help == optparse.SUPPRESS_HELP:
137 |             continue
138 |         for o in str(opt).split("/"):
139 |             if cwords[cword - 2].split("=")[0] == o:
140 |                 if not opt.metavar or any(
141 |                     x in ("path", "file", "dir") for x in opt.metavar.split("/")
142 |                 ):
143 |                     return opt.metavar
144 |     return None
145 | 
146 | 
147 | def auto_complete_paths(current: str, completion_type: str) -> Iterable[str]:
148 |     """If ``completion_type`` is ``file`` or ``path``, list all regular files
149 |     and directories starting with ``current``; otherwise only list directories
150 |     starting with ``current``.
151 | 
152 |     :param current: The word to be completed
153 |     :param completion_type: path completion type(``file``, ``path`` or ``dir``)
154 |     :return: A generator of regular files and/or directories
155 |     """
156 |     directory, filename = os.path.split(current)
157 |     current_path = os.path.abspath(directory)
158 |     # Don't complete paths if they can't be accessed
159 |     if not os.access(current_path, os.R_OK):
160 |         return
161 |     filename = os.path.normcase(filename)
162 |     # list all files that start with ``filename``
163 |     file_list = (
164 |         x for x in os.listdir(current_path) if os.path.normcase(x).startswith(filename)
165 |     )
166 |     for f in file_list:
167 |         opt = os.path.join(current_path, f)
168 |         comp_file = os.path.normcase(os.path.join(directory, f))
169 |         # complete regular files when there is not ``<dir>`` after option
170 |         # complete directories when there is ``<file>``, ``<path>`` or
171 |         # ``<dir>``after option
172 |         if completion_type != "dir" and os.path.isfile(opt):
173 |             yield comp_file
174 |         elif os.path.isdir(opt):
175 |             yield os.path.join(comp_file, "")
```

.venv/lib/python3.13/site-packages/pip/_internal/cli/base_command.py
```
1 | """Base Command class, and related routines"""
2 | 
3 | import logging
4 | import logging.config
5 | import optparse
6 | import os
7 | import sys
8 | import traceback
9 | from optparse import Values
10 | from typing import List, Optional, Tuple
11 | 
12 | from pip._vendor.rich import reconfigure
13 | from pip._vendor.rich import traceback as rich_traceback
14 | 
15 | from pip._internal.cli import cmdoptions
16 | from pip._internal.cli.command_context import CommandContextMixIn
17 | from pip._internal.cli.parser import ConfigOptionParser, UpdatingDefaultsHelpFormatter
18 | from pip._internal.cli.status_codes import (
19 |     ERROR,
20 |     PREVIOUS_BUILD_DIR_ERROR,
21 |     UNKNOWN_ERROR,
22 |     VIRTUALENV_NOT_FOUND,
23 | )
24 | from pip._internal.exceptions import (
25 |     BadCommand,
26 |     CommandError,
27 |     DiagnosticPipError,
28 |     InstallationError,
29 |     NetworkConnectionError,
30 |     PreviousBuildDirError,
31 | )
32 | from pip._internal.utils.filesystem import check_path_owner
33 | from pip._internal.utils.logging import BrokenStdoutLoggingError, setup_logging
34 | from pip._internal.utils.misc import get_prog, normalize_path
35 | from pip._internal.utils.temp_dir import TempDirectoryTypeRegistry as TempDirRegistry
36 | from pip._internal.utils.temp_dir import global_tempdir_manager, tempdir_registry
37 | from pip._internal.utils.virtualenv import running_under_virtualenv
38 | 
39 | __all__ = ["Command"]
40 | 
41 | logger = logging.getLogger(__name__)
42 | 
43 | 
44 | class Command(CommandContextMixIn):
45 |     usage: str = ""
46 |     ignore_require_venv: bool = False
47 | 
48 |     def __init__(self, name: str, summary: str, isolated: bool = False) -> None:
49 |         super().__init__()
50 | 
51 |         self.name = name
52 |         self.summary = summary
53 |         self.parser = ConfigOptionParser(
54 |             usage=self.usage,
55 |             prog=f"{get_prog()} {name}",
56 |             formatter=UpdatingDefaultsHelpFormatter(),
57 |             add_help_option=False,
58 |             name=name,
59 |             description=self.__doc__,
60 |             isolated=isolated,
61 |         )
62 | 
63 |         self.tempdir_registry: Optional[TempDirRegistry] = None
64 | 
65 |         # Commands should add options to this option group
66 |         optgroup_name = f"{self.name.capitalize()} Options"
67 |         self.cmd_opts = optparse.OptionGroup(self.parser, optgroup_name)
68 | 
69 |         # Add the general options
70 |         gen_opts = cmdoptions.make_option_group(
71 |             cmdoptions.general_group,
72 |             self.parser,
73 |         )
74 |         self.parser.add_option_group(gen_opts)
75 | 
76 |         self.add_options()
77 | 
78 |     def add_options(self) -> None:
79 |         pass
80 | 
81 |     def handle_pip_version_check(self, options: Values) -> None:
82 |         """
83 |         This is a no-op so that commands by default do not do the pip version
84 |         check.
85 |         """
86 |         # Make sure we do the pip version check if the index_group options
87 |         # are present.
88 |         assert not hasattr(options, "no_index")
89 | 
90 |     def run(self, options: Values, args: List[str]) -> int:
91 |         raise NotImplementedError
92 | 
93 |     def _run_wrapper(self, level_number: int, options: Values, args: List[str]) -> int:
94 |         def _inner_run() -> int:
95 |             try:
96 |                 return self.run(options, args)
97 |             finally:
98 |                 self.handle_pip_version_check(options)
99 | 
100 |         if options.debug_mode:
101 |             rich_traceback.install(show_locals=True)
102 |             return _inner_run()
103 | 
104 |         try:
105 |             status = _inner_run()
106 |             assert isinstance(status, int)
107 |             return status
108 |         except DiagnosticPipError as exc:
109 |             logger.error("%s", exc, extra={"rich": True})
110 |             logger.debug("Exception information:", exc_info=True)
111 | 
112 |             return ERROR
113 |         except PreviousBuildDirError as exc:
114 |             logger.critical(str(exc))
115 |             logger.debug("Exception information:", exc_info=True)
116 | 
117 |             return PREVIOUS_BUILD_DIR_ERROR
118 |         except (
119 |             InstallationError,
120 |             BadCommand,
121 |             NetworkConnectionError,
122 |         ) as exc:
123 |             logger.critical(str(exc))
124 |             logger.debug("Exception information:", exc_info=True)
125 | 
126 |             return ERROR
127 |         except CommandError as exc:
128 |             logger.critical("%s", exc)
129 |             logger.debug("Exception information:", exc_info=True)
130 | 
131 |             return ERROR
132 |         except BrokenStdoutLoggingError:
133 |             # Bypass our logger and write any remaining messages to
134 |             # stderr because stdout no longer works.
135 |             print("ERROR: Pipe to stdout was broken", file=sys.stderr)
136 |             if level_number <= logging.DEBUG:
137 |                 traceback.print_exc(file=sys.stderr)
138 | 
139 |             return ERROR
140 |         except KeyboardInterrupt:
141 |             logger.critical("Operation cancelled by user")
142 |             logger.debug("Exception information:", exc_info=True)
143 | 
144 |             return ERROR
145 |         except BaseException:
146 |             logger.critical("Exception:", exc_info=True)
147 | 
148 |             return UNKNOWN_ERROR
149 | 
150 |     def parse_args(self, args: List[str]) -> Tuple[Values, List[str]]:
151 |         # factored out for testability
152 |         return self.parser.parse_args(args)
153 | 
154 |     def main(self, args: List[str]) -> int:
155 |         try:
156 |             with self.main_context():
157 |                 return self._main(args)
158 |         finally:
159 |             logging.shutdown()
160 | 
161 |     def _main(self, args: List[str]) -> int:
162 |         # We must initialize this before the tempdir manager, otherwise the
163 |         # configuration would not be accessible by the time we clean up the
164 |         # tempdir manager.
165 |         self.tempdir_registry = self.enter_context(tempdir_registry())
166 |         # Intentionally set as early as possible so globally-managed temporary
167 |         # directories are available to the rest of the code.
168 |         self.enter_context(global_tempdir_manager())
169 | 
170 |         options, args = self.parse_args(args)
171 | 
172 |         # Set verbosity so that it can be used elsewhere.
173 |         self.verbosity = options.verbose - options.quiet
174 |         if options.debug_mode:
175 |             self.verbosity = 2
176 | 
177 |         reconfigure(no_color=options.no_color)
178 |         level_number = setup_logging(
179 |             verbosity=self.verbosity,
180 |             no_color=options.no_color,
181 |             user_log_file=options.log,
182 |         )
183 | 
184 |         always_enabled_features = set(options.features_enabled) & set(
185 |             cmdoptions.ALWAYS_ENABLED_FEATURES
186 |         )
187 |         if always_enabled_features:
188 |             logger.warning(
189 |                 "The following features are always enabled: %s. ",
190 |                 ", ".join(sorted(always_enabled_features)),
191 |             )
192 | 
193 |         # Make sure that the --python argument isn't specified after the
194 |         # subcommand. We can tell, because if --python was specified,
195 |         # we should only reach this point if we're running in the created
196 |         # subprocess, which has the _PIP_RUNNING_IN_SUBPROCESS environment
197 |         # variable set.
198 |         if options.python and "_PIP_RUNNING_IN_SUBPROCESS" not in os.environ:
199 |             logger.critical(
200 |                 "The --python option must be placed before the pip subcommand name"
201 |             )
202 |             sys.exit(ERROR)
203 | 
204 |         # TODO: Try to get these passing down from the command?
205 |         #       without resorting to os.environ to hold these.
206 |         #       This also affects isolated builds and it should.
207 | 
208 |         if options.no_input:
209 |             os.environ["PIP_NO_INPUT"] = "1"
210 | 
211 |         if options.exists_action:
212 |             os.environ["PIP_EXISTS_ACTION"] = " ".join(options.exists_action)
213 | 
214 |         if options.require_venv and not self.ignore_require_venv:
215 |             # If a venv is required check if it can really be found
216 |             if not running_under_virtualenv():
217 |                 logger.critical("Could not find an activated virtualenv (required).")
218 |                 sys.exit(VIRTUALENV_NOT_FOUND)
219 | 
220 |         if options.cache_dir:
221 |             options.cache_dir = normalize_path(options.cache_dir)
222 |             if not check_path_owner(options.cache_dir):
223 |                 logger.warning(
224 |                     "The directory '%s' or its parent directory is not owned "
225 |                     "or is not writable by the current user. The cache "
226 |                     "has been disabled. Check the permissions and owner of "
227 |                     "that directory. If executing pip with sudo, you should "
228 |                     "use sudo's -H flag.",
229 |                     options.cache_dir,
230 |                 )
231 |                 options.cache_dir = None
232 | 
233 |         return self._run_wrapper(level_number, options, args)
```

.venv/lib/python3.13/site-packages/pip/_internal/cli/cmdoptions.py
```
1 | """
2 | shared options and groups
3 | 
4 | The principle here is to define options once, but *not* instantiate them
5 | globally. One reason being that options with action='append' can carry state
6 | between parses. pip parses general options twice internally, and shouldn't
7 | pass on state. To be consistent, all options will follow this design.
8 | """
9 | 
10 | # The following comment should be removed at some point in the future.
11 | # mypy: strict-optional=False
12 | 
13 | import importlib.util
14 | import logging
15 | import os
16 | import pathlib
17 | import textwrap
18 | from functools import partial
19 | from optparse import SUPPRESS_HELP, Option, OptionGroup, OptionParser, Values
20 | from textwrap import dedent
21 | from typing import Any, Callable, Dict, Optional, Tuple
22 | 
23 | from pip._vendor.packaging.utils import canonicalize_name
24 | 
25 | from pip._internal.cli.parser import ConfigOptionParser
26 | from pip._internal.exceptions import CommandError
27 | from pip._internal.locations import USER_CACHE_DIR, get_src_prefix
28 | from pip._internal.models.format_control import FormatControl
29 | from pip._internal.models.index import PyPI
30 | from pip._internal.models.target_python import TargetPython
31 | from pip._internal.utils.hashes import STRONG_HASHES
32 | from pip._internal.utils.misc import strtobool
33 | 
34 | logger = logging.getLogger(__name__)
35 | 
36 | 
37 | def raise_option_error(parser: OptionParser, option: Option, msg: str) -> None:
38 |     """
39 |     Raise an option parsing error using parser.error().
40 | 
41 |     Args:
42 |       parser: an OptionParser instance.
43 |       option: an Option instance.
44 |       msg: the error text.
45 |     """
46 |     msg = f"{option} error: {msg}"
47 |     msg = textwrap.fill(" ".join(msg.split()))
48 |     parser.error(msg)
49 | 
50 | 
51 | def make_option_group(group: Dict[str, Any], parser: ConfigOptionParser) -> OptionGroup:
52 |     """
53 |     Return an OptionGroup object
54 |     group  -- assumed to be dict with 'name' and 'options' keys
55 |     parser -- an optparse Parser
56 |     """
57 |     option_group = OptionGroup(parser, group["name"])
58 |     for option in group["options"]:
59 |         option_group.add_option(option())
60 |     return option_group
61 | 
62 | 
63 | def check_dist_restriction(options: Values, check_target: bool = False) -> None:
64 |     """Function for determining if custom platform options are allowed.
65 | 
66 |     :param options: The OptionParser options.
67 |     :param check_target: Whether or not to check if --target is being used.
68 |     """
69 |     dist_restriction_set = any(
70 |         [
71 |             options.python_version,
72 |             options.platforms,
73 |             options.abis,
74 |             options.implementation,
75 |         ]
76 |     )
77 | 
78 |     binary_only = FormatControl(set(), {":all:"})
79 |     sdist_dependencies_allowed = (
80 |         options.format_control != binary_only and not options.ignore_dependencies
81 |     )
82 | 
83 |     # Installations or downloads using dist restrictions must not combine
84 |     # source distributions and dist-specific wheels, as they are not
85 |     # guaranteed to be locally compatible.
86 |     if dist_restriction_set and sdist_dependencies_allowed:
87 |         raise CommandError(
88 |             "When restricting platform and interpreter constraints using "
89 |             "--python-version, --platform, --abi, or --implementation, "
90 |             "either --no-deps must be set, or --only-binary=:all: must be "
91 |             "set and --no-binary must not be set (or must be set to "
92 |             ":none:)."
93 |         )
94 | 
95 |     if check_target:
96 |         if not options.dry_run and dist_restriction_set and not options.target_dir:
97 |             raise CommandError(
98 |                 "Can not use any platform or abi specific options unless "
99 |                 "installing via '--target' or using '--dry-run'"
100 |             )
101 | 
102 | 
103 | def _path_option_check(option: Option, opt: str, value: str) -> str:
104 |     return os.path.expanduser(value)
105 | 
106 | 
107 | def _package_name_option_check(option: Option, opt: str, value: str) -> str:
108 |     return canonicalize_name(value)
109 | 
110 | 
111 | class PipOption(Option):
112 |     TYPES = Option.TYPES + ("path", "package_name")
113 |     TYPE_CHECKER = Option.TYPE_CHECKER.copy()
114 |     TYPE_CHECKER["package_name"] = _package_name_option_check
115 |     TYPE_CHECKER["path"] = _path_option_check
116 | 
117 | 
118 | ###########
119 | # options #
120 | ###########
121 | 
122 | help_: Callable[..., Option] = partial(
123 |     Option,
124 |     "-h",
125 |     "--help",
126 |     dest="help",
127 |     action="help",
128 |     help="Show help.",
129 | )
130 | 
131 | debug_mode: Callable[..., Option] = partial(
132 |     Option,
133 |     "--debug",
134 |     dest="debug_mode",
135 |     action="store_true",
136 |     default=False,
137 |     help=(
138 |         "Let unhandled exceptions propagate outside the main subroutine, "
139 |         "instead of logging them to stderr."
140 |     ),
141 | )
142 | 
143 | isolated_mode: Callable[..., Option] = partial(
144 |     Option,
145 |     "--isolated",
146 |     dest="isolated_mode",
147 |     action="store_true",
148 |     default=False,
149 |     help=(
150 |         "Run pip in an isolated mode, ignoring environment variables and user "
151 |         "configuration."
152 |     ),
153 | )
154 | 
155 | require_virtualenv: Callable[..., Option] = partial(
156 |     Option,
157 |     "--require-virtualenv",
158 |     "--require-venv",
159 |     dest="require_venv",
160 |     action="store_true",
161 |     default=False,
162 |     help=(
163 |         "Allow pip to only run in a virtual environment; "
164 |         "exit with an error otherwise."
165 |     ),
166 | )
167 | 
168 | override_externally_managed: Callable[..., Option] = partial(
169 |     Option,
170 |     "--break-system-packages",
171 |     dest="override_externally_managed",
172 |     action="store_true",
173 |     help="Allow pip to modify an EXTERNALLY-MANAGED Python installation",
174 | )
175 | 
176 | python: Callable[..., Option] = partial(
177 |     Option,
178 |     "--python",
179 |     dest="python",
180 |     help="Run pip with the specified Python interpreter.",
181 | )
182 | 
183 | verbose: Callable[..., Option] = partial(
184 |     Option,
185 |     "-v",
186 |     "--verbose",
187 |     dest="verbose",
188 |     action="count",
189 |     default=0,
190 |     help="Give more output. Option is additive, and can be used up to 3 times.",
191 | )
192 | 
193 | no_color: Callable[..., Option] = partial(
194 |     Option,
195 |     "--no-color",
196 |     dest="no_color",
197 |     action="store_true",
198 |     default=False,
199 |     help="Suppress colored output.",
200 | )
201 | 
202 | version: Callable[..., Option] = partial(
203 |     Option,
204 |     "-V",
205 |     "--version",
206 |     dest="version",
207 |     action="store_true",
208 |     help="Show version and exit.",
209 | )
210 | 
211 | quiet: Callable[..., Option] = partial(
212 |     Option,
213 |     "-q",
214 |     "--quiet",
215 |     dest="quiet",
216 |     action="count",
217 |     default=0,
218 |     help=(
219 |         "Give less output. Option is additive, and can be used up to 3"
220 |         " times (corresponding to WARNING, ERROR, and CRITICAL logging"
221 |         " levels)."
222 |     ),
223 | )
224 | 
225 | progress_bar: Callable[..., Option] = partial(
226 |     Option,
227 |     "--progress-bar",
228 |     dest="progress_bar",
229 |     type="choice",
230 |     choices=["on", "off", "raw"],
231 |     default="on",
232 |     help="Specify whether the progress bar should be used [on, off, raw] (default: on)",
233 | )
234 | 
235 | log: Callable[..., Option] = partial(
236 |     PipOption,
237 |     "--log",
238 |     "--log-file",
239 |     "--local-log",
240 |     dest="log",
241 |     metavar="path",
242 |     type="path",
243 |     help="Path to a verbose appending log.",
244 | )
245 | 
246 | no_input: Callable[..., Option] = partial(
247 |     Option,
248 |     # Don't ask for input
249 |     "--no-input",
250 |     dest="no_input",
251 |     action="store_true",
252 |     default=False,
253 |     help="Disable prompting for input.",
254 | )
255 | 
256 | keyring_provider: Callable[..., Option] = partial(
257 |     Option,
258 |     "--keyring-provider",
259 |     dest="keyring_provider",
260 |     choices=["auto", "disabled", "import", "subprocess"],
261 |     default="auto",
262 |     help=(
263 |         "Enable the credential lookup via the keyring library if user input is allowed."
264 |         " Specify which mechanism to use [auto, disabled, import, subprocess]."
265 |         " (default: %default)"
266 |     ),
267 | )
268 | 
269 | proxy: Callable[..., Option] = partial(
270 |     Option,
271 |     "--proxy",
272 |     dest="proxy",
273 |     type="str",
274 |     default="",
275 |     help="Specify a proxy in the form scheme://[user:passwd@]proxy.server:port.",
276 | )
277 | 
278 | retries: Callable[..., Option] = partial(
279 |     Option,
280 |     "--retries",
281 |     dest="retries",
282 |     type="int",
283 |     default=5,
284 |     help="Maximum attempts to establish a new HTTP connection. (default: %default)",
285 | )
286 | 
287 | resume_retries: Callable[..., Option] = partial(
288 |     Option,
289 |     "--resume-retries",
290 |     dest="resume_retries",
291 |     type="int",
292 |     default=0,
293 |     help="Maximum attempts to resume or restart an incomplete download. "
294 |     "(default: %default)",
295 | )
296 | 
297 | timeout: Callable[..., Option] = partial(
298 |     Option,
299 |     "--timeout",
300 |     "--default-timeout",
301 |     metavar="sec",
302 |     dest="timeout",
303 |     type="float",
304 |     default=15,
305 |     help="Set the socket timeout (default %default seconds).",
306 | )
307 | 
308 | 
309 | def exists_action() -> Option:
310 |     return Option(
311 |         # Option when path already exist
312 |         "--exists-action",
313 |         dest="exists_action",
314 |         type="choice",
315 |         choices=["s", "i", "w", "b", "a"],
316 |         default=[],
317 |         action="append",
318 |         metavar="action",
319 |         help="Default action when a path already exists: "
320 |         "(s)witch, (i)gnore, (w)ipe, (b)ackup, (a)bort.",
321 |     )
322 | 
323 | 
324 | cert: Callable[..., Option] = partial(
325 |     PipOption,
326 |     "--cert",
327 |     dest="cert",
328 |     type="path",
329 |     metavar="path",
330 |     help=(
331 |         "Path to PEM-encoded CA certificate bundle. "
332 |         "If provided, overrides the default. "
333 |         "See 'SSL Certificate Verification' in pip documentation "
334 |         "for more information."
335 |     ),
336 | )
337 | 
338 | client_cert: Callable[..., Option] = partial(
339 |     PipOption,
340 |     "--client-cert",
341 |     dest="client_cert",
342 |     type="path",
343 |     default=None,
344 |     metavar="path",
345 |     help="Path to SSL client certificate, a single file containing the "
346 |     "private key and the certificate in PEM format.",
347 | )
348 | 
349 | index_url: Callable[..., Option] = partial(
350 |     Option,
351 |     "-i",
352 |     "--index-url",
353 |     "--pypi-url",
354 |     dest="index_url",
355 |     metavar="URL",
356 |     default=PyPI.simple_url,
357 |     help="Base URL of the Python Package Index (default %default). "
358 |     "This should point to a repository compliant with PEP 503 "
359 |     "(the simple repository API) or a local directory laid out "
360 |     "in the same format.",
361 | )
362 | 
363 | 
364 | def extra_index_url() -> Option:
365 |     return Option(
366 |         "--extra-index-url",
367 |         dest="extra_index_urls",
368 |         metavar="URL",
369 |         action="append",
370 |         default=[],
371 |         help="Extra URLs of package indexes to use in addition to "
372 |         "--index-url. Should follow the same rules as "
373 |         "--index-url.",
374 |     )
375 | 
376 | 
377 | no_index: Callable[..., Option] = partial(
378 |     Option,
379 |     "--no-index",
380 |     dest="no_index",
381 |     action="store_true",
382 |     default=False,
383 |     help="Ignore package index (only looking at --find-links URLs instead).",
384 | )
385 | 
386 | 
387 | def find_links() -> Option:
388 |     return Option(
389 |         "-f",
390 |         "--find-links",
391 |         dest="find_links",
392 |         action="append",
393 |         default=[],
394 |         metavar="url",
395 |         help="If a URL or path to an html file, then parse for links to "
396 |         "archives such as sdist (.tar.gz) or wheel (.whl) files. "
397 |         "If a local path or file:// URL that's a directory, "
398 |         "then look for archives in the directory listing. "
399 |         "Links to VCS project URLs are not supported.",
400 |     )
401 | 
402 | 
403 | def trusted_host() -> Option:
404 |     return Option(
405 |         "--trusted-host",
406 |         dest="trusted_hosts",
407 |         action="append",
408 |         metavar="HOSTNAME",
409 |         default=[],
410 |         help="Mark this host or host:port pair as trusted, even though it "
411 |         "does not have valid or any HTTPS.",
412 |     )
413 | 
414 | 
415 | def constraints() -> Option:
416 |     return Option(
417 |         "-c",
418 |         "--constraint",
419 |         dest="constraints",
420 |         action="append",
421 |         default=[],
422 |         metavar="file",
423 |         help="Constrain versions using the given constraints file. "
424 |         "This option can be used multiple times.",
425 |     )
426 | 
427 | 
[TRUNCATED]
```

.venv/lib/python3.13/site-packages/pip/_internal/cli/command_context.py
```
1 | from contextlib import ExitStack, contextmanager
2 | from typing import ContextManager, Generator, TypeVar
3 | 
4 | _T = TypeVar("_T", covariant=True)
5 | 
6 | 
7 | class CommandContextMixIn:
8 |     def __init__(self) -> None:
9 |         super().__init__()
10 |         self._in_main_context = False
11 |         self._main_context = ExitStack()
12 | 
13 |     @contextmanager
14 |     def main_context(self) -> Generator[None, None, None]:
15 |         assert not self._in_main_context
16 | 
17 |         self._in_main_context = True
18 |         try:
19 |             with self._main_context:
20 |                 yield
21 |         finally:
22 |             self._in_main_context = False
23 | 
24 |     def enter_context(self, context_provider: ContextManager[_T]) -> _T:
25 |         assert self._in_main_context
26 | 
27 |         return self._main_context.enter_context(context_provider)
```

.venv/lib/python3.13/site-packages/pip/_internal/cli/index_command.py
```
1 | """
2 | Contains command classes which may interact with an index / the network.
3 | 
4 | Unlike its sister module, req_command, this module still uses lazy imports
5 | so commands which don't always hit the network (e.g. list w/o --outdated or
6 | --uptodate) don't need waste time importing PipSession and friends.
7 | """
8 | 
9 | import logging
10 | import os
11 | import sys
12 | from functools import lru_cache
13 | from optparse import Values
14 | from typing import TYPE_CHECKING, List, Optional
15 | 
16 | from pip._vendor import certifi
17 | 
18 | from pip._internal.cli.base_command import Command
19 | from pip._internal.cli.command_context import CommandContextMixIn
20 | 
21 | if TYPE_CHECKING:
22 |     from ssl import SSLContext
23 | 
24 |     from pip._internal.network.session import PipSession
25 | 
26 | logger = logging.getLogger(__name__)
27 | 
28 | 
29 | @lru_cache
30 | def _create_truststore_ssl_context() -> Optional["SSLContext"]:
31 |     if sys.version_info < (3, 10):
32 |         logger.debug("Disabling truststore because Python version isn't 3.10+")
33 |         return None
34 | 
35 |     try:
36 |         import ssl
37 |     except ImportError:
38 |         logger.warning("Disabling truststore since ssl support is missing")
39 |         return None
40 | 
41 |     try:
42 |         from pip._vendor import truststore
43 |     except ImportError:
44 |         logger.warning("Disabling truststore because platform isn't supported")
45 |         return None
46 | 
47 |     ctx = truststore.SSLContext(ssl.PROTOCOL_TLS_CLIENT)
48 |     ctx.load_verify_locations(certifi.where())
49 |     return ctx
50 | 
51 | 
52 | class SessionCommandMixin(CommandContextMixIn):
53 |     """
54 |     A class mixin for command classes needing _build_session().
55 |     """
56 | 
57 |     def __init__(self) -> None:
58 |         super().__init__()
59 |         self._session: Optional[PipSession] = None
60 | 
61 |     @classmethod
62 |     def _get_index_urls(cls, options: Values) -> Optional[List[str]]:
63 |         """Return a list of index urls from user-provided options."""
64 |         index_urls = []
65 |         if not getattr(options, "no_index", False):
66 |             url = getattr(options, "index_url", None)
67 |             if url:
68 |                 index_urls.append(url)
69 |         urls = getattr(options, "extra_index_urls", None)
70 |         if urls:
71 |             index_urls.extend(urls)
72 |         # Return None rather than an empty list
73 |         return index_urls or None
74 | 
75 |     def get_default_session(self, options: Values) -> "PipSession":
76 |         """Get a default-managed session."""
77 |         if self._session is None:
78 |             self._session = self.enter_context(self._build_session(options))
79 |             # there's no type annotation on requests.Session, so it's
80 |             # automatically ContextManager[Any] and self._session becomes Any,
81 |             # then https://github.com/python/mypy/issues/7696 kicks in
82 |             assert self._session is not None
83 |         return self._session
84 | 
85 |     def _build_session(
86 |         self,
87 |         options: Values,
88 |         retries: Optional[int] = None,
89 |         timeout: Optional[int] = None,
90 |     ) -> "PipSession":
91 |         from pip._internal.network.session import PipSession
92 | 
93 |         cache_dir = options.cache_dir
94 |         assert not cache_dir or os.path.isabs(cache_dir)
95 | 
96 |         if "legacy-certs" not in options.deprecated_features_enabled:
97 |             ssl_context = _create_truststore_ssl_context()
98 |         else:
99 |             ssl_context = None
100 | 
101 |         session = PipSession(
102 |             cache=os.path.join(cache_dir, "http-v2") if cache_dir else None,
103 |             retries=retries if retries is not None else options.retries,
104 |             trusted_hosts=options.trusted_hosts,
105 |             index_urls=self._get_index_urls(options),
106 |             ssl_context=ssl_context,
107 |         )
108 | 
109 |         # Handle custom ca-bundles from the user
110 |         if options.cert:
111 |             session.verify = options.cert
112 | 
113 |         # Handle SSL client certificate
114 |         if options.client_cert:
115 |             session.cert = options.client_cert
116 | 
117 |         # Handle timeouts
118 |         if options.timeout or timeout:
119 |             session.timeout = timeout if timeout is not None else options.timeout
120 | 
121 |         # Handle configured proxies
122 |         if options.proxy:
123 |             session.proxies = {
124 |                 "http": options.proxy,
125 |                 "https": options.proxy,
126 |             }
127 |             session.trust_env = False
128 |             session.pip_proxy = options.proxy
129 | 
130 |         # Determine if we can prompt the user for authentication or not
131 |         session.auth.prompting = not options.no_input
132 |         session.auth.keyring_provider = options.keyring_provider
133 | 
134 |         return session
135 | 
136 | 
137 | def _pip_self_version_check(session: "PipSession", options: Values) -> None:
138 |     from pip._internal.self_outdated_check import pip_self_version_check as check
139 | 
140 |     check(session, options)
141 | 
142 | 
143 | class IndexGroupCommand(Command, SessionCommandMixin):
144 |     """
145 |     Abstract base class for commands with the index_group options.
146 | 
147 |     This also corresponds to the commands that permit the pip version check.
148 |     """
149 | 
150 |     def handle_pip_version_check(self, options: Values) -> None:
151 |         """
152 |         Do the pip version check if not disabled.
153 | 
154 |         This overrides the default behavior of not doing the check.
155 |         """
156 |         # Make sure the index_group options are present.
157 |         assert hasattr(options, "no_index")
158 | 
159 |         if options.disable_pip_version_check or options.no_index:
160 |             return
161 | 
162 |         try:
163 |             # Otherwise, check if we're using the latest version of pip available.
164 |             session = self._build_session(
165 |                 options,
166 |                 retries=0,
167 |                 timeout=min(5, options.timeout),
168 |             )
169 |             with session:
170 |                 _pip_self_version_check(session, options)
171 |         except Exception:
172 |             logger.warning("There was an error checking the latest version of pip.")
173 |             logger.debug("See below for error", exc_info=True)
```

.venv/lib/python3.13/site-packages/pip/_internal/cli/main.py
```
1 | """Primary application entrypoint."""
2 | 
3 | import locale
4 | import logging
5 | import os
6 | import sys
7 | import warnings
8 | from typing import List, Optional
9 | 
10 | from pip._internal.cli.autocompletion import autocomplete
11 | from pip._internal.cli.main_parser import parse_command
12 | from pip._internal.commands import create_command
13 | from pip._internal.exceptions import PipError
14 | from pip._internal.utils import deprecation
15 | 
16 | logger = logging.getLogger(__name__)
17 | 
18 | 
19 | # Do not import and use main() directly! Using it directly is actively
20 | # discouraged by pip's maintainers. The name, location and behavior of
21 | # this function is subject to change, so calling it directly is not
22 | # portable across different pip versions.
23 | 
24 | # In addition, running pip in-process is unsupported and unsafe. This is
25 | # elaborated in detail at
26 | # https://pip.pypa.io/en/stable/user_guide/#using-pip-from-your-program.
27 | # That document also provides suggestions that should work for nearly
28 | # all users that are considering importing and using main() directly.
29 | 
30 | # However, we know that certain users will still want to invoke pip
31 | # in-process. If you understand and accept the implications of using pip
32 | # in an unsupported manner, the best approach is to use runpy to avoid
33 | # depending on the exact location of this entry point.
34 | 
35 | # The following example shows how to use runpy to invoke pip in that
36 | # case:
37 | #
38 | #     sys.argv = ["pip", your, args, here]
39 | #     runpy.run_module("pip", run_name="__main__")
40 | #
41 | # Note that this will exit the process after running, unlike a direct
42 | # call to main. As it is not safe to do any processing after calling
43 | # main, this should not be an issue in practice.
44 | 
45 | 
46 | def main(args: Optional[List[str]] = None) -> int:
47 |     if args is None:
48 |         args = sys.argv[1:]
49 | 
50 |     # Suppress the pkg_resources deprecation warning
51 |     # Note - we use a module of .*pkg_resources to cover
52 |     # the normal case (pip._vendor.pkg_resources) and the
53 |     # devendored case (a bare pkg_resources)
54 |     warnings.filterwarnings(
55 |         action="ignore", category=DeprecationWarning, module=".*pkg_resources"
56 |     )
57 | 
58 |     # Configure our deprecation warnings to be sent through loggers
59 |     deprecation.install_warning_logger()
60 | 
61 |     autocomplete()
62 | 
63 |     try:
64 |         cmd_name, cmd_args = parse_command(args)
65 |     except PipError as exc:
66 |         sys.stderr.write(f"ERROR: {exc}")
67 |         sys.stderr.write(os.linesep)
68 |         sys.exit(1)
69 | 
70 |     # Needed for locale.getpreferredencoding(False) to work
71 |     # in pip._internal.utils.encoding.auto_decode
72 |     try:
73 |         locale.setlocale(locale.LC_ALL, "")
74 |     except locale.Error as e:
75 |         # setlocale can apparently crash if locale are uninitialized
76 |         logger.debug("Ignoring error %s when setting locale", e)
77 |     command = create_command(cmd_name, isolated=("--isolated" in cmd_args))
78 | 
79 |     return command.main(cmd_args)
```

.venv/lib/python3.13/site-packages/pip/_internal/cli/main_parser.py
```
1 | """A single place for constructing and exposing the main parser"""
2 | 
3 | import os
4 | import subprocess
5 | import sys
6 | from typing import List, Optional, Tuple
7 | 
8 | from pip._internal.build_env import get_runnable_pip
9 | from pip._internal.cli import cmdoptions
10 | from pip._internal.cli.parser import ConfigOptionParser, UpdatingDefaultsHelpFormatter
11 | from pip._internal.commands import commands_dict, get_similar_commands
12 | from pip._internal.exceptions import CommandError
13 | from pip._internal.utils.misc import get_pip_version, get_prog
14 | 
15 | __all__ = ["create_main_parser", "parse_command"]
16 | 
17 | 
18 | def create_main_parser() -> ConfigOptionParser:
19 |     """Creates and returns the main parser for pip's CLI"""
20 | 
21 |     parser = ConfigOptionParser(
22 |         usage="\n%prog <command> [options]",
23 |         add_help_option=False,
24 |         formatter=UpdatingDefaultsHelpFormatter(),
25 |         name="global",
26 |         prog=get_prog(),
27 |     )
28 |     parser.disable_interspersed_args()
29 | 
30 |     parser.version = get_pip_version()
31 | 
32 |     # add the general options
33 |     gen_opts = cmdoptions.make_option_group(cmdoptions.general_group, parser)
34 |     parser.add_option_group(gen_opts)
35 | 
36 |     # so the help formatter knows
37 |     parser.main = True  # type: ignore
38 | 
39 |     # create command listing for description
40 |     description = [""] + [
41 |         f"{name:27} {command_info.summary}"
42 |         for name, command_info in commands_dict.items()
43 |     ]
44 |     parser.description = "\n".join(description)
45 | 
46 |     return parser
47 | 
48 | 
49 | def identify_python_interpreter(python: str) -> Optional[str]:
50 |     # If the named file exists, use it.
51 |     # If it's a directory, assume it's a virtual environment and
52 |     # look for the environment's Python executable.
53 |     if os.path.exists(python):
54 |         if os.path.isdir(python):
55 |             # bin/python for Unix, Scripts/python.exe for Windows
56 |             # Try both in case of odd cases like cygwin.
57 |             for exe in ("bin/python", "Scripts/python.exe"):
58 |                 py = os.path.join(python, exe)
59 |                 if os.path.exists(py):
60 |                     return py
61 |         else:
62 |             return python
63 | 
64 |     # Could not find the interpreter specified
65 |     return None
66 | 
67 | 
68 | def parse_command(args: List[str]) -> Tuple[str, List[str]]:
69 |     parser = create_main_parser()
70 | 
71 |     # Note: parser calls disable_interspersed_args(), so the result of this
72 |     # call is to split the initial args into the general options before the
73 |     # subcommand and everything else.
74 |     # For example:
75 |     #  args: ['--timeout=5', 'install', '--user', 'INITools']
76 |     #  general_options: ['--timeout==5']
77 |     #  args_else: ['install', '--user', 'INITools']
78 |     general_options, args_else = parser.parse_args(args)
79 | 
80 |     # --python
81 |     if general_options.python and "_PIP_RUNNING_IN_SUBPROCESS" not in os.environ:
82 |         # Re-invoke pip using the specified Python interpreter
83 |         interpreter = identify_python_interpreter(general_options.python)
84 |         if interpreter is None:
85 |             raise CommandError(
86 |                 f"Could not locate Python interpreter {general_options.python}"
87 |             )
88 | 
89 |         pip_cmd = [
90 |             interpreter,
91 |             get_runnable_pip(),
92 |         ]
93 |         pip_cmd.extend(args)
94 | 
95 |         # Set a flag so the child doesn't re-invoke itself, causing
96 |         # an infinite loop.
97 |         os.environ["_PIP_RUNNING_IN_SUBPROCESS"] = "1"
98 |         returncode = 0
99 |         try:
100 |             proc = subprocess.run(pip_cmd)
101 |             returncode = proc.returncode
102 |         except (subprocess.SubprocessError, OSError) as exc:
103 |             raise CommandError(f"Failed to run pip under {interpreter}: {exc}")
104 |         sys.exit(returncode)
105 | 
106 |     # --version
107 |     if general_options.version:
108 |         sys.stdout.write(parser.version)
109 |         sys.stdout.write(os.linesep)
110 |         sys.exit()
111 | 
112 |     # pip || pip help -> print_help()
113 |     if not args_else or (args_else[0] == "help" and len(args_else) == 1):
114 |         parser.print_help()
115 |         sys.exit()
116 | 
117 |     # the subcommand name
118 |     cmd_name = args_else[0]
119 | 
120 |     if cmd_name not in commands_dict:
121 |         guess = get_similar_commands(cmd_name)
122 | 
123 |         msg = [f'unknown command "{cmd_name}"']
124 |         if guess:
125 |             msg.append(f'maybe you meant "{guess}"')
126 | 
127 |         raise CommandError(" - ".join(msg))
128 | 
129 |     # all the args without the subcommand
130 |     cmd_args = args[:]
131 |     cmd_args.remove(cmd_name)
132 | 
133 |     return cmd_name, cmd_args
```

.venv/lib/python3.13/site-packages/pip/_internal/cli/parser.py
```
1 | """Base option parser setup"""
2 | 
3 | import logging
4 | import optparse
5 | import shutil
6 | import sys
7 | import textwrap
8 | from contextlib import suppress
9 | from typing import Any, Dict, Generator, List, NoReturn, Optional, Tuple
10 | 
11 | from pip._internal.cli.status_codes import UNKNOWN_ERROR
12 | from pip._internal.configuration import Configuration, ConfigurationError
13 | from pip._internal.utils.misc import redact_auth_from_url, strtobool
14 | 
15 | logger = logging.getLogger(__name__)
16 | 
17 | 
18 | class PrettyHelpFormatter(optparse.IndentedHelpFormatter):
19 |     """A prettier/less verbose help formatter for optparse."""
20 | 
21 |     def __init__(self, *args: Any, **kwargs: Any) -> None:
22 |         # help position must be aligned with __init__.parseopts.description
23 |         kwargs["max_help_position"] = 30
24 |         kwargs["indent_increment"] = 1
25 |         kwargs["width"] = shutil.get_terminal_size()[0] - 2
26 |         super().__init__(*args, **kwargs)
27 | 
28 |     def format_option_strings(self, option: optparse.Option) -> str:
29 |         return self._format_option_strings(option)
30 | 
31 |     def _format_option_strings(
32 |         self, option: optparse.Option, mvarfmt: str = " <{}>", optsep: str = ", "
33 |     ) -> str:
34 |         """
35 |         Return a comma-separated list of option strings and metavars.
36 | 
37 |         :param option:  tuple of (short opt, long opt), e.g: ('-f', '--format')
38 |         :param mvarfmt: metavar format string
39 |         :param optsep:  separator
40 |         """
41 |         opts = []
42 | 
43 |         if option._short_opts:
44 |             opts.append(option._short_opts[0])
45 |         if option._long_opts:
46 |             opts.append(option._long_opts[0])
47 |         if len(opts) > 1:
48 |             opts.insert(1, optsep)
49 | 
50 |         if option.takes_value():
51 |             assert option.dest is not None
52 |             metavar = option.metavar or option.dest.lower()
53 |             opts.append(mvarfmt.format(metavar.lower()))
54 | 
55 |         return "".join(opts)
56 | 
57 |     def format_heading(self, heading: str) -> str:
58 |         if heading == "Options":
59 |             return ""
60 |         return heading + ":\n"
61 | 
62 |     def format_usage(self, usage: str) -> str:
63 |         """
64 |         Ensure there is only one newline between usage and the first heading
65 |         if there is no description.
66 |         """
67 |         msg = "\nUsage: {}\n".format(self.indent_lines(textwrap.dedent(usage), "  "))
68 |         return msg
69 | 
70 |     def format_description(self, description: Optional[str]) -> str:
71 |         # leave full control over description to us
72 |         if description:
73 |             if hasattr(self.parser, "main"):
74 |                 label = "Commands"
75 |             else:
76 |                 label = "Description"
77 |             # some doc strings have initial newlines, some don't
78 |             description = description.lstrip("\n")
79 |             # some doc strings have final newlines and spaces, some don't
80 |             description = description.rstrip()
81 |             # dedent, then reindent
82 |             description = self.indent_lines(textwrap.dedent(description), "  ")
83 |             description = f"{label}:\n{description}\n"
84 |             return description
85 |         else:
86 |             return ""
87 | 
88 |     def format_epilog(self, epilog: Optional[str]) -> str:
89 |         # leave full control over epilog to us
90 |         if epilog:
91 |             return epilog
92 |         else:
93 |             return ""
94 | 
95 |     def indent_lines(self, text: str, indent: str) -> str:
96 |         new_lines = [indent + line for line in text.split("\n")]
97 |         return "\n".join(new_lines)
98 | 
99 | 
100 | class UpdatingDefaultsHelpFormatter(PrettyHelpFormatter):
101 |     """Custom help formatter for use in ConfigOptionParser.
102 | 
103 |     This is updates the defaults before expanding them, allowing
104 |     them to show up correctly in the help listing.
105 | 
106 |     Also redact auth from url type options
107 |     """
108 | 
109 |     def expand_default(self, option: optparse.Option) -> str:
110 |         default_values = None
111 |         if self.parser is not None:
112 |             assert isinstance(self.parser, ConfigOptionParser)
113 |             self.parser._update_defaults(self.parser.defaults)
114 |             assert option.dest is not None
115 |             default_values = self.parser.defaults.get(option.dest)
116 |         help_text = super().expand_default(option)
117 | 
118 |         if default_values and option.metavar == "URL":
119 |             if isinstance(default_values, str):
120 |                 default_values = [default_values]
121 | 
122 |             # If its not a list, we should abort and just return the help text
123 |             if not isinstance(default_values, list):
124 |                 default_values = []
125 | 
126 |             for val in default_values:
127 |                 help_text = help_text.replace(val, redact_auth_from_url(val))
128 | 
129 |         return help_text
130 | 
131 | 
132 | class CustomOptionParser(optparse.OptionParser):
133 |     def insert_option_group(
134 |         self, idx: int, *args: Any, **kwargs: Any
135 |     ) -> optparse.OptionGroup:
136 |         """Insert an OptionGroup at a given position."""
137 |         group = self.add_option_group(*args, **kwargs)
138 | 
139 |         self.option_groups.pop()
140 |         self.option_groups.insert(idx, group)
141 | 
142 |         return group
143 | 
144 |     @property
145 |     def option_list_all(self) -> List[optparse.Option]:
146 |         """Get a list of all options, including those in option groups."""
147 |         res = self.option_list[:]
148 |         for i in self.option_groups:
149 |             res.extend(i.option_list)
150 | 
151 |         return res
152 | 
153 | 
154 | class ConfigOptionParser(CustomOptionParser):
155 |     """Custom option parser which updates its defaults by checking the
156 |     configuration files and environmental variables"""
157 | 
158 |     def __init__(
159 |         self,
160 |         *args: Any,
161 |         name: str,
162 |         isolated: bool = False,
163 |         **kwargs: Any,
164 |     ) -> None:
165 |         self.name = name
166 |         self.config = Configuration(isolated)
167 | 
168 |         assert self.name
169 |         super().__init__(*args, **kwargs)
170 | 
171 |     def check_default(self, option: optparse.Option, key: str, val: Any) -> Any:
172 |         try:
173 |             return option.check_value(key, val)
174 |         except optparse.OptionValueError as exc:
175 |             print(f"An error occurred during configuration: {exc}")
176 |             sys.exit(3)
177 | 
178 |     def _get_ordered_configuration_items(
179 |         self,
180 |     ) -> Generator[Tuple[str, Any], None, None]:
181 |         # Configuration gives keys in an unordered manner. Order them.
182 |         override_order = ["global", self.name, ":env:"]
183 | 
184 |         # Pool the options into different groups
185 |         section_items: Dict[str, List[Tuple[str, Any]]] = {
186 |             name: [] for name in override_order
187 |         }
188 |         for section_key, val in self.config.items():
189 |             # ignore empty values
190 |             if not val:
191 |                 logger.debug(
192 |                     "Ignoring configuration key '%s' as it's value is empty.",
193 |                     section_key,
194 |                 )
195 |                 continue
196 | 
197 |             section, key = section_key.split(".", 1)
198 |             if section in override_order:
199 |                 section_items[section].append((key, val))
200 | 
201 |         # Yield each group in their override order
202 |         for section in override_order:
203 |             for key, val in section_items[section]:
204 |                 yield key, val
205 | 
206 |     def _update_defaults(self, defaults: Dict[str, Any]) -> Dict[str, Any]:
207 |         """Updates the given defaults with values from the config files and
208 |         the environ. Does a little special handling for certain types of
209 |         options (lists)."""
210 | 
211 |         # Accumulate complex default state.
212 |         self.values = optparse.Values(self.defaults)
213 |         late_eval = set()
214 |         # Then set the options with those values
215 |         for key, val in self._get_ordered_configuration_items():
216 |             # '--' because configuration supports only long names
217 |             option = self.get_option("--" + key)
218 | 
219 |             # Ignore options not present in this parser. E.g. non-globals put
220 |             # in [global] by users that want them to apply to all applicable
221 |             # commands.
222 |             if option is None:
223 |                 continue
224 | 
225 |             assert option.dest is not None
226 | 
227 |             if option.action in ("store_true", "store_false"):
228 |                 try:
229 |                     val = strtobool(val)
230 |                 except ValueError:
231 |                     self.error(
232 |                         f"{val} is not a valid value for {key} option, "
233 |                         "please specify a boolean value like yes/no, "
234 |                         "true/false or 1/0 instead."
235 |                     )
236 |             elif option.action == "count":
237 |                 with suppress(ValueError):
238 |                     val = strtobool(val)
239 |                 with suppress(ValueError):
240 |                     val = int(val)
241 |                 if not isinstance(val, int) or val < 0:
242 |                     self.error(
243 |                         f"{val} is not a valid value for {key} option, "
244 |                         "please instead specify either a non-negative integer "
245 |                         "or a boolean value like yes/no or false/true "
246 |                         "which is equivalent to 1/0."
247 |                     )
248 |             elif option.action == "append":
249 |                 val = val.split()
250 |                 val = [self.check_default(option, key, v) for v in val]
251 |             elif option.action == "callback":
252 |                 assert option.callback is not None
253 |                 late_eval.add(option.dest)
254 |                 opt_str = option.get_opt_string()
255 |                 val = option.convert_value(opt_str, val)
256 |                 # From take_action
257 |                 args = option.callback_args or ()
258 |                 kwargs = option.callback_kwargs or {}
259 |                 option.callback(option, opt_str, val, self, *args, **kwargs)
260 |             else:
261 |                 val = self.check_default(option, key, val)
262 | 
263 |             defaults[option.dest] = val
264 | 
265 |         for key in late_eval:
266 |             defaults[key] = getattr(self.values, key)
267 |         self.values = None
268 |         return defaults
269 | 
270 |     def get_default_values(self) -> optparse.Values:
271 |         """Overriding to make updating the defaults after instantiation of
272 |         the option parser possible, _update_defaults() does the dirty work."""
273 |         if not self.process_default_values:
274 |             # Old, pre-Optik 1.5 behaviour.
275 |             return optparse.Values(self.defaults)
276 | 
277 |         # Load the configuration, or error out in case of an error
278 |         try:
279 |             self.config.load()
280 |         except ConfigurationError as err:
281 |             self.exit(UNKNOWN_ERROR, str(err))
282 | 
283 |         defaults = self._update_defaults(self.defaults.copy())  # ours
284 |         for option in self._get_all_options():
285 |             assert option.dest is not None
286 |             default = defaults.get(option.dest)
287 |             if isinstance(default, str):
288 |                 opt_str = option.get_opt_string()
289 |                 defaults[option.dest] = option.check_value(opt_str, default)
290 |         return optparse.Values(defaults)
291 | 
292 |     def error(self, msg: str) -> NoReturn:
293 |         self.print_usage(sys.stderr)
294 |         self.exit(UNKNOWN_ERROR, f"{msg}\n")
```

.venv/lib/python3.13/site-packages/pip/_internal/cli/progress_bars.py
```
1 | import functools
2 | import sys
3 | from typing import Callable, Generator, Iterable, Iterator, Optional, Tuple, TypeVar
4 | 
5 | from pip._vendor.rich.progress import (
6 |     BarColumn,
7 |     DownloadColumn,
8 |     FileSizeColumn,
9 |     MofNCompleteColumn,
10 |     Progress,
11 |     ProgressColumn,
12 |     SpinnerColumn,
13 |     TextColumn,
14 |     TimeElapsedColumn,
15 |     TimeRemainingColumn,
16 |     TransferSpeedColumn,
17 | )
18 | 
19 | from pip._internal.cli.spinners import RateLimiter
20 | from pip._internal.req.req_install import InstallRequirement
21 | from pip._internal.utils.logging import get_console, get_indentation
22 | 
23 | T = TypeVar("T")
24 | ProgressRenderer = Callable[[Iterable[T]], Iterator[T]]
25 | 
26 | 
27 | def _rich_download_progress_bar(
28 |     iterable: Iterable[bytes],
29 |     *,
30 |     bar_type: str,
31 |     size: Optional[int],
32 |     initial_progress: Optional[int] = None,
33 | ) -> Generator[bytes, None, None]:
34 |     assert bar_type == "on", "This should only be used in the default mode."
35 | 
36 |     if not size:
37 |         total = float("inf")
38 |         columns: Tuple[ProgressColumn, ...] = (
39 |             TextColumn("[progress.description]{task.description}"),
40 |             SpinnerColumn("line", speed=1.5),
41 |             FileSizeColumn(),
42 |             TransferSpeedColumn(),
43 |             TimeElapsedColumn(),
44 |         )
45 |     else:
46 |         total = size
47 |         columns = (
48 |             TextColumn("[progress.description]{task.description}"),
49 |             BarColumn(),
50 |             DownloadColumn(),
51 |             TransferSpeedColumn(),
52 |             TextColumn("eta"),
53 |             TimeRemainingColumn(),
54 |         )
55 | 
56 |     progress = Progress(*columns, refresh_per_second=5)
57 |     task_id = progress.add_task(" " * (get_indentation() + 2), total=total)
58 |     if initial_progress is not None:
59 |         progress.update(task_id, advance=initial_progress)
60 |     with progress:
61 |         for chunk in iterable:
62 |             yield chunk
63 |             progress.update(task_id, advance=len(chunk))
64 | 
65 | 
66 | def _rich_install_progress_bar(
67 |     iterable: Iterable[InstallRequirement], *, total: int
68 | ) -> Iterator[InstallRequirement]:
69 |     columns = (
70 |         TextColumn("{task.fields[indent]}"),
71 |         BarColumn(),
72 |         MofNCompleteColumn(),
73 |         TextColumn("{task.description}"),
74 |     )
75 |     console = get_console()
76 | 
77 |     bar = Progress(*columns, refresh_per_second=6, console=console, transient=True)
78 |     # Hiding the progress bar at initialization forces a refresh cycle to occur
79 |     # until the bar appears, avoiding very short flashes.
80 |     task = bar.add_task("", total=total, indent=" " * get_indentation(), visible=False)
81 |     with bar:
82 |         for req in iterable:
83 |             bar.update(task, description=rf"\[{req.name}]", visible=True)
84 |             yield req
85 |             bar.advance(task)
86 | 
87 | 
88 | def _raw_progress_bar(
89 |     iterable: Iterable[bytes],
90 |     *,
91 |     size: Optional[int],
92 |     initial_progress: Optional[int] = None,
93 | ) -> Generator[bytes, None, None]:
94 |     def write_progress(current: int, total: int) -> None:
95 |         sys.stdout.write(f"Progress {current} of {total}\n")
96 |         sys.stdout.flush()
97 | 
98 |     current = initial_progress or 0
99 |     total = size or 0
100 |     rate_limiter = RateLimiter(0.25)
101 | 
102 |     write_progress(current, total)
103 |     for chunk in iterable:
104 |         current += len(chunk)
105 |         if rate_limiter.ready() or current == total:
106 |             write_progress(current, total)
107 |             rate_limiter.reset()
108 |         yield chunk
109 | 
110 | 
111 | def get_download_progress_renderer(
112 |     *, bar_type: str, size: Optional[int] = None, initial_progress: Optional[int] = None
113 | ) -> ProgressRenderer[bytes]:
114 |     """Get an object that can be used to render the download progress.
115 | 
116 |     Returns a callable, that takes an iterable to "wrap".
117 |     """
118 |     if bar_type == "on":
119 |         return functools.partial(
120 |             _rich_download_progress_bar,
121 |             bar_type=bar_type,
122 |             size=size,
123 |             initial_progress=initial_progress,
124 |         )
125 |     elif bar_type == "raw":
126 |         return functools.partial(
127 |             _raw_progress_bar,
128 |             size=size,
129 |             initial_progress=initial_progress,
130 |         )
131 |     else:
132 |         return iter  # no-op, when passed an iterator
133 | 
134 | 
135 | def get_install_progress_renderer(
136 |     *, bar_type: str, total: int
137 | ) -> ProgressRenderer[InstallRequirement]:
138 |     """Get an object that can be used to render the install progress.
139 |     Returns a callable, that takes an iterable to "wrap".
140 |     """
141 |     if bar_type == "on":
142 |         return functools.partial(_rich_install_progress_bar, total=total)
143 |     else:
144 |         return iter
```

.venv/lib/python3.13/site-packages/pip/_internal/cli/req_command.py
```
1 | """Contains the RequirementCommand base class.
2 | 
3 | This class is in a separate module so the commands that do not always
4 | need PackageFinder capability don't unnecessarily import the
5 | PackageFinder machinery and all its vendored dependencies, etc.
6 | """
7 | 
8 | import logging
9 | from functools import partial
10 | from optparse import Values
11 | from typing import Any, List, Optional, Tuple
12 | 
13 | from pip._internal.cache import WheelCache
14 | from pip._internal.cli import cmdoptions
15 | from pip._internal.cli.index_command import IndexGroupCommand
16 | from pip._internal.cli.index_command import SessionCommandMixin as SessionCommandMixin
17 | from pip._internal.exceptions import CommandError, PreviousBuildDirError
18 | from pip._internal.index.collector import LinkCollector
19 | from pip._internal.index.package_finder import PackageFinder
20 | from pip._internal.models.selection_prefs import SelectionPreferences
21 | from pip._internal.models.target_python import TargetPython
22 | from pip._internal.network.session import PipSession
23 | from pip._internal.operations.build.build_tracker import BuildTracker
24 | from pip._internal.operations.prepare import RequirementPreparer
25 | from pip._internal.req.constructors import (
26 |     install_req_from_editable,
27 |     install_req_from_line,
28 |     install_req_from_parsed_requirement,
29 |     install_req_from_req_string,
30 | )
31 | from pip._internal.req.req_dependency_group import parse_dependency_groups
32 | from pip._internal.req.req_file import parse_requirements
33 | from pip._internal.req.req_install import InstallRequirement
34 | from pip._internal.resolution.base import BaseResolver
35 | from pip._internal.utils.temp_dir import (
36 |     TempDirectory,
37 |     TempDirectoryTypeRegistry,
38 |     tempdir_kinds,
39 | )
40 | 
41 | logger = logging.getLogger(__name__)
42 | 
43 | 
44 | KEEPABLE_TEMPDIR_TYPES = [
45 |     tempdir_kinds.BUILD_ENV,
46 |     tempdir_kinds.EPHEM_WHEEL_CACHE,
47 |     tempdir_kinds.REQ_BUILD,
48 | ]
49 | 
50 | 
51 | def with_cleanup(func: Any) -> Any:
52 |     """Decorator for common logic related to managing temporary
53 |     directories.
54 |     """
55 | 
56 |     def configure_tempdir_registry(registry: TempDirectoryTypeRegistry) -> None:
57 |         for t in KEEPABLE_TEMPDIR_TYPES:
58 |             registry.set_delete(t, False)
59 | 
60 |     def wrapper(
61 |         self: RequirementCommand, options: Values, args: List[Any]
62 |     ) -> Optional[int]:
63 |         assert self.tempdir_registry is not None
64 |         if options.no_clean:
65 |             configure_tempdir_registry(self.tempdir_registry)
66 | 
67 |         try:
68 |             return func(self, options, args)
69 |         except PreviousBuildDirError:
70 |             # This kind of conflict can occur when the user passes an explicit
71 |             # build directory with a pre-existing folder. In that case we do
72 |             # not want to accidentally remove it.
73 |             configure_tempdir_registry(self.tempdir_registry)
74 |             raise
75 | 
76 |     return wrapper
77 | 
78 | 
79 | class RequirementCommand(IndexGroupCommand):
80 |     def __init__(self, *args: Any, **kw: Any) -> None:
81 |         super().__init__(*args, **kw)
82 | 
83 |         self.cmd_opts.add_option(cmdoptions.dependency_groups())
84 |         self.cmd_opts.add_option(cmdoptions.no_clean())
85 | 
86 |     @staticmethod
87 |     def determine_resolver_variant(options: Values) -> str:
88 |         """Determines which resolver should be used, based on the given options."""
89 |         if "legacy-resolver" in options.deprecated_features_enabled:
90 |             return "legacy"
91 | 
92 |         return "resolvelib"
93 | 
94 |     @classmethod
95 |     def make_requirement_preparer(
96 |         cls,
97 |         temp_build_dir: TempDirectory,
98 |         options: Values,
99 |         build_tracker: BuildTracker,
100 |         session: PipSession,
101 |         finder: PackageFinder,
102 |         use_user_site: bool,
103 |         download_dir: Optional[str] = None,
104 |         verbosity: int = 0,
105 |     ) -> RequirementPreparer:
106 |         """
107 |         Create a RequirementPreparer instance for the given parameters.
108 |         """
109 |         temp_build_dir_path = temp_build_dir.path
110 |         assert temp_build_dir_path is not None
111 |         legacy_resolver = False
112 | 
113 |         resolver_variant = cls.determine_resolver_variant(options)
114 |         if resolver_variant == "resolvelib":
115 |             lazy_wheel = "fast-deps" in options.features_enabled
116 |             if lazy_wheel:
117 |                 logger.warning(
118 |                     "pip is using lazily downloaded wheels using HTTP "
119 |                     "range requests to obtain dependency information. "
120 |                     "This experimental feature is enabled through "
121 |                     "--use-feature=fast-deps and it is not ready for "
122 |                     "production."
123 |                 )
124 |         else:
125 |             legacy_resolver = True
126 |             lazy_wheel = False
127 |             if "fast-deps" in options.features_enabled:
128 |                 logger.warning(
129 |                     "fast-deps has no effect when used with the legacy resolver."
130 |                 )
131 | 
132 |         return RequirementPreparer(
133 |             build_dir=temp_build_dir_path,
134 |             src_dir=options.src_dir,
135 |             download_dir=download_dir,
136 |             build_isolation=options.build_isolation,
137 |             check_build_deps=options.check_build_deps,
138 |             build_tracker=build_tracker,
139 |             session=session,
140 |             progress_bar=options.progress_bar,
141 |             finder=finder,
142 |             require_hashes=options.require_hashes,
143 |             use_user_site=use_user_site,
144 |             lazy_wheel=lazy_wheel,
145 |             verbosity=verbosity,
146 |             legacy_resolver=legacy_resolver,
147 |             resume_retries=options.resume_retries,
148 |         )
149 | 
150 |     @classmethod
151 |     def make_resolver(
152 |         cls,
153 |         preparer: RequirementPreparer,
154 |         finder: PackageFinder,
155 |         options: Values,
156 |         wheel_cache: Optional[WheelCache] = None,
157 |         use_user_site: bool = False,
158 |         ignore_installed: bool = True,
159 |         ignore_requires_python: bool = False,
160 |         force_reinstall: bool = False,
161 |         upgrade_strategy: str = "to-satisfy-only",
162 |         use_pep517: Optional[bool] = None,
163 |         py_version_info: Optional[Tuple[int, ...]] = None,
164 |     ) -> BaseResolver:
165 |         """
166 |         Create a Resolver instance for the given parameters.
167 |         """
168 |         make_install_req = partial(
169 |             install_req_from_req_string,
170 |             isolated=options.isolated_mode,
171 |             use_pep517=use_pep517,
172 |         )
173 |         resolver_variant = cls.determine_resolver_variant(options)
174 |         # The long import name and duplicated invocation is needed to convince
175 |         # Mypy into correctly typechecking. Otherwise it would complain the
176 |         # "Resolver" class being redefined.
177 |         if resolver_variant == "resolvelib":
178 |             import pip._internal.resolution.resolvelib.resolver
179 | 
180 |             return pip._internal.resolution.resolvelib.resolver.Resolver(
181 |                 preparer=preparer,
182 |                 finder=finder,
183 |                 wheel_cache=wheel_cache,
184 |                 make_install_req=make_install_req,
185 |                 use_user_site=use_user_site,
186 |                 ignore_dependencies=options.ignore_dependencies,
187 |                 ignore_installed=ignore_installed,
188 |                 ignore_requires_python=ignore_requires_python,
189 |                 force_reinstall=force_reinstall,
190 |                 upgrade_strategy=upgrade_strategy,
191 |                 py_version_info=py_version_info,
192 |             )
193 |         import pip._internal.resolution.legacy.resolver
194 | 
195 |         return pip._internal.resolution.legacy.resolver.Resolver(
196 |             preparer=preparer,
197 |             finder=finder,
198 |             wheel_cache=wheel_cache,
199 |             make_install_req=make_install_req,
200 |             use_user_site=use_user_site,
201 |             ignore_dependencies=options.ignore_dependencies,
202 |             ignore_installed=ignore_installed,
203 |             ignore_requires_python=ignore_requires_python,
204 |             force_reinstall=force_reinstall,
205 |             upgrade_strategy=upgrade_strategy,
206 |             py_version_info=py_version_info,
207 |         )
208 | 
209 |     def get_requirements(
210 |         self,
211 |         args: List[str],
212 |         options: Values,
213 |         finder: PackageFinder,
214 |         session: PipSession,
215 |     ) -> List[InstallRequirement]:
216 |         """
217 |         Parse command-line arguments into the corresponding requirements.
218 |         """
219 |         requirements: List[InstallRequirement] = []
220 |         for filename in options.constraints:
221 |             for parsed_req in parse_requirements(
222 |                 filename,
223 |                 constraint=True,
224 |                 finder=finder,
225 |                 options=options,
226 |                 session=session,
227 |             ):
228 |                 req_to_add = install_req_from_parsed_requirement(
229 |                     parsed_req,
230 |                     isolated=options.isolated_mode,
231 |                     user_supplied=False,
232 |                 )
233 |                 requirements.append(req_to_add)
234 | 
235 |         for req in args:
236 |             req_to_add = install_req_from_line(
237 |                 req,
238 |                 comes_from=None,
239 |                 isolated=options.isolated_mode,
240 |                 use_pep517=options.use_pep517,
241 |                 user_supplied=True,
242 |                 config_settings=getattr(options, "config_settings", None),
243 |             )
244 |             requirements.append(req_to_add)
245 | 
246 |         if options.dependency_groups:
247 |             for req in parse_dependency_groups(options.dependency_groups):
248 |                 req_to_add = install_req_from_req_string(
249 |                     req,
250 |                     isolated=options.isolated_mode,
251 |                     use_pep517=options.use_pep517,
252 |                     user_supplied=True,
253 |                 )
254 |                 requirements.append(req_to_add)
255 | 
256 |         for req in options.editables:
257 |             req_to_add = install_req_from_editable(
258 |                 req,
259 |                 user_supplied=True,
260 |                 isolated=options.isolated_mode,
261 |                 use_pep517=options.use_pep517,
262 |                 config_settings=getattr(options, "config_settings", None),
263 |             )
264 |             requirements.append(req_to_add)
265 | 
266 |         # NOTE: options.require_hashes may be set if --require-hashes is True
267 |         for filename in options.requirements:
268 |             for parsed_req in parse_requirements(
269 |                 filename, finder=finder, options=options, session=session
270 |             ):
271 |                 req_to_add = install_req_from_parsed_requirement(
272 |                     parsed_req,
273 |                     isolated=options.isolated_mode,
274 |                     use_pep517=options.use_pep517,
275 |                     user_supplied=True,
276 |                     config_settings=(
277 |                         parsed_req.options.get("config_settings")
278 |                         if parsed_req.options
279 |                         else None
280 |                     ),
281 |                 )
282 |                 requirements.append(req_to_add)
283 | 
284 |         # If any requirement has hash options, enable hash checking.
285 |         if any(req.has_hash_options for req in requirements):
286 |             options.require_hashes = True
287 | 
288 |         if not (
289 |             args
290 |             or options.editables
291 |             or options.requirements
292 |             or options.dependency_groups
293 |         ):
294 |             opts = {"name": self.name}
295 |             if options.find_links:
296 |                 raise CommandError(
297 |                     "You must give at least one requirement to {name} "
298 |                     '(maybe you meant "pip {name} {links}"?)'.format(
299 |                         **dict(opts, links=" ".join(options.find_links))
300 |                     )
301 |                 )
302 |             else:
303 |                 raise CommandError(
304 |                     "You must give at least one requirement to {name} "
305 |                     '(see "pip help {name}")'.format(**opts)
306 |                 )
307 | 
308 |         return requirements
309 | 
310 |     @staticmethod
311 |     def trace_basic_info(finder: PackageFinder) -> None:
312 |         """
313 |         Trace basic information about the provided objects.
314 |         """
315 |         # Display where finder is looking for packages
316 |         search_scope = finder.search_scope
317 |         locations = search_scope.get_formatted_locations()
318 |         if locations:
319 |             logger.info(locations)
320 | 
321 |     def _build_package_finder(
322 |         self,
323 |         options: Values,
324 |         session: PipSession,
325 |         target_python: Optional[TargetPython] = None,
326 |         ignore_requires_python: Optional[bool] = None,
327 |     ) -> PackageFinder:
328 |         """
329 |         Create a package finder appropriate to this requirement command.
330 | 
331 |         :param ignore_requires_python: Whether to ignore incompatible
332 |             "Requires-Python" values in links. Defaults to False.
333 |         """
334 |         link_collector = LinkCollector.create(session, options=options)
335 |         selection_prefs = SelectionPreferences(
336 |             allow_yanked=True,
337 |             format_control=options.format_control,
338 |             allow_all_prereleases=options.pre,
339 |             prefer_binary=options.prefer_binary,
340 |             ignore_requires_python=ignore_requires_python,
341 |         )
342 | 
343 |         return PackageFinder.create(
344 |             link_collector=link_collector,
345 |             selection_prefs=selection_prefs,
346 |             target_python=target_python,
347 |         )
```

.venv/lib/python3.13/site-packages/pip/_internal/cli/spinners.py
```
1 | import contextlib
2 | import itertools
3 | import logging
4 | import sys
5 | import time
6 | from typing import IO, Generator, Optional
7 | 
8 | from pip._internal.utils.compat import WINDOWS
9 | from pip._internal.utils.logging import get_indentation
10 | 
11 | logger = logging.getLogger(__name__)
12 | 
13 | 
14 | class SpinnerInterface:
15 |     def spin(self) -> None:
16 |         raise NotImplementedError()
17 | 
18 |     def finish(self, final_status: str) -> None:
19 |         raise NotImplementedError()
20 | 
21 | 
22 | class InteractiveSpinner(SpinnerInterface):
23 |     def __init__(
24 |         self,
25 |         message: str,
26 |         file: Optional[IO[str]] = None,
27 |         spin_chars: str = "-\\|/",
28 |         # Empirically, 8 updates/second looks nice
29 |         min_update_interval_seconds: float = 0.125,
30 |     ):
31 |         self._message = message
32 |         if file is None:
33 |             file = sys.stdout
34 |         self._file = file
35 |         self._rate_limiter = RateLimiter(min_update_interval_seconds)
36 |         self._finished = False
37 | 
38 |         self._spin_cycle = itertools.cycle(spin_chars)
39 | 
40 |         self._file.write(" " * get_indentation() + self._message + " ... ")
41 |         self._width = 0
42 | 
43 |     def _write(self, status: str) -> None:
44 |         assert not self._finished
45 |         # Erase what we wrote before by backspacing to the beginning, writing
46 |         # spaces to overwrite the old text, and then backspacing again
47 |         backup = "\b" * self._width
48 |         self._file.write(backup + " " * self._width + backup)
49 |         # Now we have a blank slate to add our status
50 |         self._file.write(status)
51 |         self._width = len(status)
52 |         self._file.flush()
53 |         self._rate_limiter.reset()
54 | 
55 |     def spin(self) -> None:
56 |         if self._finished:
57 |             return
58 |         if not self._rate_limiter.ready():
59 |             return
60 |         self._write(next(self._spin_cycle))
61 | 
62 |     def finish(self, final_status: str) -> None:
63 |         if self._finished:
64 |             return
65 |         self._write(final_status)
66 |         self._file.write("\n")
67 |         self._file.flush()
68 |         self._finished = True
69 | 
70 | 
71 | # Used for dumb terminals, non-interactive installs (no tty), etc.
72 | # We still print updates occasionally (once every 60 seconds by default) to
73 | # act as a keep-alive for systems like Travis-CI that take lack-of-output as
74 | # an indication that a task has frozen.
75 | class NonInteractiveSpinner(SpinnerInterface):
76 |     def __init__(self, message: str, min_update_interval_seconds: float = 60.0) -> None:
77 |         self._message = message
78 |         self._finished = False
79 |         self._rate_limiter = RateLimiter(min_update_interval_seconds)
80 |         self._update("started")
81 | 
82 |     def _update(self, status: str) -> None:
83 |         assert not self._finished
84 |         self._rate_limiter.reset()
85 |         logger.info("%s: %s", self._message, status)
86 | 
87 |     def spin(self) -> None:
88 |         if self._finished:
89 |             return
90 |         if not self._rate_limiter.ready():
91 |             return
92 |         self._update("still running...")
93 | 
94 |     def finish(self, final_status: str) -> None:
95 |         if self._finished:
96 |             return
97 |         self._update(f"finished with status '{final_status}'")
98 |         self._finished = True
99 | 
100 | 
101 | class RateLimiter:
102 |     def __init__(self, min_update_interval_seconds: float) -> None:
103 |         self._min_update_interval_seconds = min_update_interval_seconds
104 |         self._last_update: float = 0
105 | 
106 |     def ready(self) -> bool:
107 |         now = time.time()
108 |         delta = now - self._last_update
109 |         return delta >= self._min_update_interval_seconds
110 | 
111 |     def reset(self) -> None:
112 |         self._last_update = time.time()
113 | 
114 | 
115 | @contextlib.contextmanager
116 | def open_spinner(message: str) -> Generator[SpinnerInterface, None, None]:
117 |     # Interactive spinner goes directly to sys.stdout rather than being routed
118 |     # through the logging system, but it acts like it has level INFO,
119 |     # i.e. it's only displayed if we're at level INFO or better.
120 |     # Non-interactive spinner goes through the logging system, so it is always
121 |     # in sync with logging configuration.
122 |     if sys.stdout.isatty() and logger.getEffectiveLevel() <= logging.INFO:
123 |         spinner: SpinnerInterface = InteractiveSpinner(message)
124 |     else:
125 |         spinner = NonInteractiveSpinner(message)
126 |     try:
127 |         with hidden_cursor(sys.stdout):
128 |             yield spinner
129 |     except KeyboardInterrupt:
130 |         spinner.finish("canceled")
131 |         raise
132 |     except Exception:
133 |         spinner.finish("error")
134 |         raise
135 |     else:
136 |         spinner.finish("done")
137 | 
138 | 
139 | HIDE_CURSOR = "\x1b[?25l"
140 | SHOW_CURSOR = "\x1b[?25h"
141 | 
142 | 
143 | @contextlib.contextmanager
144 | def hidden_cursor(file: IO[str]) -> Generator[None, None, None]:
145 |     # The Windows terminal does not support the hide/show cursor ANSI codes,
146 |     # even via colorama. So don't even try.
147 |     if WINDOWS:
148 |         yield
149 |     # We don't want to clutter the output with control characters if we're
150 |     # writing to a file, or if the user is running with --quiet.
151 |     # See https://github.com/pypa/pip/issues/3418
152 |     elif not file.isatty() or logger.getEffectiveLevel() > logging.INFO:
153 |         yield
154 |     else:
155 |         file.write(HIDE_CURSOR)
156 |         try:
157 |             yield
158 |         finally:
159 |             file.write(SHOW_CURSOR)
```

.venv/lib/python3.13/site-packages/pip/_internal/cli/status_codes.py
```
1 | SUCCESS = 0
2 | ERROR = 1
3 | UNKNOWN_ERROR = 2
4 | VIRTUALENV_NOT_FOUND = 3
5 | PREVIOUS_BUILD_DIR_ERROR = 4
6 | NO_MATCHES_FOUND = 23
```

.venv/lib/python3.13/site-packages/pip/_internal/distributions/__init__.py
```
1 | from pip._internal.distributions.base import AbstractDistribution
2 | from pip._internal.distributions.sdist import SourceDistribution
3 | from pip._internal.distributions.wheel import WheelDistribution
4 | from pip._internal.req.req_install import InstallRequirement
5 | 
6 | 
7 | def make_distribution_for_install_requirement(
8 |     install_req: InstallRequirement,
9 | ) -> AbstractDistribution:
10 |     """Returns a Distribution for the given InstallRequirement"""
11 |     # Editable requirements will always be source distributions. They use the
12 |     # legacy logic until we create a modern standard for them.
13 |     if install_req.editable:
14 |         return SourceDistribution(install_req)
15 | 
16 |     # If it's a wheel, it's a WheelDistribution
17 |     if install_req.is_wheel:
18 |         return WheelDistribution(install_req)
19 | 
20 |     # Otherwise, a SourceDistribution
21 |     return SourceDistribution(install_req)
```

.venv/lib/python3.13/site-packages/pip/_internal/distributions/base.py
```
1 | import abc
2 | from typing import TYPE_CHECKING, Optional
3 | 
4 | from pip._internal.metadata.base import BaseDistribution
5 | from pip._internal.req import InstallRequirement
6 | 
7 | if TYPE_CHECKING:
8 |     from pip._internal.index.package_finder import PackageFinder
9 | 
10 | 
11 | class AbstractDistribution(metaclass=abc.ABCMeta):
12 |     """A base class for handling installable artifacts.
13 | 
14 |     The requirements for anything installable are as follows:
15 | 
16 |      - we must be able to determine the requirement name
17 |        (or we can't correctly handle the non-upgrade case).
18 | 
19 |      - for packages with setup requirements, we must also be able
20 |        to determine their requirements without installing additional
21 |        packages (for the same reason as run-time dependencies)
22 | 
23 |      - we must be able to create a Distribution object exposing the
24 |        above metadata.
25 | 
26 |      - if we need to do work in the build tracker, we must be able to generate a unique
27 |        string to identify the requirement in the build tracker.
28 |     """
29 | 
30 |     def __init__(self, req: InstallRequirement) -> None:
31 |         super().__init__()
32 |         self.req = req
33 | 
34 |     @abc.abstractproperty
35 |     def build_tracker_id(self) -> Optional[str]:
36 |         """A string that uniquely identifies this requirement to the build tracker.
37 | 
38 |         If None, then this dist has no work to do in the build tracker, and
39 |         ``.prepare_distribution_metadata()`` will not be called."""
40 |         raise NotImplementedError()
41 | 
42 |     @abc.abstractmethod
43 |     def get_metadata_distribution(self) -> BaseDistribution:
44 |         raise NotImplementedError()
45 | 
46 |     @abc.abstractmethod
47 |     def prepare_distribution_metadata(
48 |         self,
49 |         finder: "PackageFinder",
50 |         build_isolation: bool,
51 |         check_build_deps: bool,
52 |     ) -> None:
53 |         raise NotImplementedError()
```

.venv/lib/python3.13/site-packages/pip/_internal/distributions/installed.py
```
1 | from typing import Optional
2 | 
3 | from pip._internal.distributions.base import AbstractDistribution
4 | from pip._internal.index.package_finder import PackageFinder
5 | from pip._internal.metadata import BaseDistribution
6 | 
7 | 
8 | class InstalledDistribution(AbstractDistribution):
9 |     """Represents an installed package.
10 | 
11 |     This does not need any preparation as the required information has already
12 |     been computed.
13 |     """
14 | 
15 |     @property
16 |     def build_tracker_id(self) -> Optional[str]:
17 |         return None
18 | 
19 |     def get_metadata_distribution(self) -> BaseDistribution:
20 |         assert self.req.satisfied_by is not None, "not actually installed"
21 |         return self.req.satisfied_by
22 | 
23 |     def prepare_distribution_metadata(
24 |         self,
25 |         finder: PackageFinder,
26 |         build_isolation: bool,
27 |         check_build_deps: bool,
28 |     ) -> None:
29 |         pass
```

.venv/lib/python3.13/site-packages/pip/_internal/distributions/sdist.py
```
1 | import logging
2 | from typing import TYPE_CHECKING, Iterable, Optional, Set, Tuple
3 | 
4 | from pip._internal.build_env import BuildEnvironment
5 | from pip._internal.distributions.base import AbstractDistribution
6 | from pip._internal.exceptions import InstallationError
7 | from pip._internal.metadata import BaseDistribution
8 | from pip._internal.utils.subprocess import runner_with_spinner_message
9 | 
10 | if TYPE_CHECKING:
11 |     from pip._internal.index.package_finder import PackageFinder
12 | 
13 | logger = logging.getLogger(__name__)
14 | 
15 | 
16 | class SourceDistribution(AbstractDistribution):
17 |     """Represents a source distribution.
18 | 
19 |     The preparation step for these needs metadata for the packages to be
20 |     generated, either using PEP 517 or using the legacy `setup.py egg_info`.
21 |     """
22 | 
23 |     @property
24 |     def build_tracker_id(self) -> Optional[str]:
25 |         """Identify this requirement uniquely by its link."""
26 |         assert self.req.link
27 |         return self.req.link.url_without_fragment
28 | 
29 |     def get_metadata_distribution(self) -> BaseDistribution:
30 |         return self.req.get_dist()
31 | 
32 |     def prepare_distribution_metadata(
33 |         self,
34 |         finder: "PackageFinder",
35 |         build_isolation: bool,
36 |         check_build_deps: bool,
37 |     ) -> None:
38 |         # Load pyproject.toml, to determine whether PEP 517 is to be used
39 |         self.req.load_pyproject_toml()
40 | 
41 |         # Set up the build isolation, if this requirement should be isolated
42 |         should_isolate = self.req.use_pep517 and build_isolation
43 |         if should_isolate:
44 |             # Setup an isolated environment and install the build backend static
45 |             # requirements in it.
46 |             self._prepare_build_backend(finder)
47 |             # Check that if the requirement is editable, it either supports PEP 660 or
48 |             # has a setup.py or a setup.cfg. This cannot be done earlier because we need
49 |             # to setup the build backend to verify it supports build_editable, nor can
50 |             # it be done later, because we want to avoid installing build requirements
51 |             # needlessly. Doing it here also works around setuptools generating
52 |             # UNKNOWN.egg-info when running get_requires_for_build_wheel on a directory
53 |             # without setup.py nor setup.cfg.
54 |             self.req.isolated_editable_sanity_check()
55 |             # Install the dynamic build requirements.
56 |             self._install_build_reqs(finder)
57 |         # Check if the current environment provides build dependencies
58 |         should_check_deps = self.req.use_pep517 and check_build_deps
59 |         if should_check_deps:
60 |             pyproject_requires = self.req.pyproject_requires
61 |             assert pyproject_requires is not None
62 |             conflicting, missing = self.req.build_env.check_requirements(
63 |                 pyproject_requires
64 |             )
65 |             if conflicting:
66 |                 self._raise_conflicts("the backend dependencies", conflicting)
67 |             if missing:
68 |                 self._raise_missing_reqs(missing)
69 |         self.req.prepare_metadata()
70 | 
71 |     def _prepare_build_backend(self, finder: "PackageFinder") -> None:
72 |         # Isolate in a BuildEnvironment and install the build-time
73 |         # requirements.
74 |         pyproject_requires = self.req.pyproject_requires
75 |         assert pyproject_requires is not None
76 | 
77 |         self.req.build_env = BuildEnvironment()
78 |         self.req.build_env.install_requirements(
79 |             finder, pyproject_requires, "overlay", kind="build dependencies"
80 |         )
81 |         conflicting, missing = self.req.build_env.check_requirements(
82 |             self.req.requirements_to_check
83 |         )
84 |         if conflicting:
85 |             self._raise_conflicts("PEP 517/518 supported requirements", conflicting)
86 |         if missing:
87 |             logger.warning(
88 |                 "Missing build requirements in pyproject.toml for %s.",
89 |                 self.req,
90 |             )
91 |             logger.warning(
92 |                 "The project does not specify a build backend, and "
93 |                 "pip cannot fall back to setuptools without %s.",
94 |                 " and ".join(map(repr, sorted(missing))),
95 |             )
96 | 
97 |     def _get_build_requires_wheel(self) -> Iterable[str]:
98 |         with self.req.build_env:
99 |             runner = runner_with_spinner_message("Getting requirements to build wheel")
100 |             backend = self.req.pep517_backend
101 |             assert backend is not None
102 |             with backend.subprocess_runner(runner):
103 |                 return backend.get_requires_for_build_wheel()
104 | 
105 |     def _get_build_requires_editable(self) -> Iterable[str]:
106 |         with self.req.build_env:
107 |             runner = runner_with_spinner_message(
108 |                 "Getting requirements to build editable"
109 |             )
110 |             backend = self.req.pep517_backend
111 |             assert backend is not None
112 |             with backend.subprocess_runner(runner):
113 |                 return backend.get_requires_for_build_editable()
114 | 
115 |     def _install_build_reqs(self, finder: "PackageFinder") -> None:
116 |         # Install any extra build dependencies that the backend requests.
117 |         # This must be done in a second pass, as the pyproject.toml
118 |         # dependencies must be installed before we can call the backend.
119 |         if (
120 |             self.req.editable
121 |             and self.req.permit_editable_wheels
122 |             and self.req.supports_pyproject_editable
123 |         ):
124 |             build_reqs = self._get_build_requires_editable()
125 |         else:
126 |             build_reqs = self._get_build_requires_wheel()
127 |         conflicting, missing = self.req.build_env.check_requirements(build_reqs)
128 |         if conflicting:
129 |             self._raise_conflicts("the backend dependencies", conflicting)
130 |         self.req.build_env.install_requirements(
131 |             finder, missing, "normal", kind="backend dependencies"
132 |         )
133 | 
134 |     def _raise_conflicts(
135 |         self, conflicting_with: str, conflicting_reqs: Set[Tuple[str, str]]
136 |     ) -> None:
137 |         format_string = (
138 |             "Some build dependencies for {requirement} "
139 |             "conflict with {conflicting_with}: {description}."
140 |         )
141 |         error_message = format_string.format(
142 |             requirement=self.req,
143 |             conflicting_with=conflicting_with,
144 |             description=", ".join(
145 |                 f"{installed} is incompatible with {wanted}"
146 |                 for installed, wanted in sorted(conflicting_reqs)
147 |             ),
148 |         )
149 |         raise InstallationError(error_message)
150 | 
151 |     def _raise_missing_reqs(self, missing: Set[str]) -> None:
152 |         format_string = (
153 |             "Some build dependencies for {requirement} are missing: {missing}."
154 |         )
155 |         error_message = format_string.format(
156 |             requirement=self.req, missing=", ".join(map(repr, sorted(missing)))
157 |         )
158 |         raise InstallationError(error_message)
```

.venv/lib/python3.13/site-packages/pip/_internal/distributions/wheel.py
```
1 | from typing import TYPE_CHECKING, Optional
2 | 
3 | from pip._vendor.packaging.utils import canonicalize_name
4 | 
5 | from pip._internal.distributions.base import AbstractDistribution
6 | from pip._internal.metadata import (
7 |     BaseDistribution,
8 |     FilesystemWheel,
9 |     get_wheel_distribution,
10 | )
11 | 
12 | if TYPE_CHECKING:
13 |     from pip._internal.index.package_finder import PackageFinder
14 | 
15 | 
16 | class WheelDistribution(AbstractDistribution):
17 |     """Represents a wheel distribution.
18 | 
19 |     This does not need any preparation as wheels can be directly unpacked.
20 |     """
21 | 
22 |     @property
23 |     def build_tracker_id(self) -> Optional[str]:
24 |         return None
25 | 
26 |     def get_metadata_distribution(self) -> BaseDistribution:
27 |         """Loads the metadata from the wheel file into memory and returns a
28 |         Distribution that uses it, not relying on the wheel file or
29 |         requirement.
30 |         """
31 |         assert self.req.local_file_path, "Set as part of preparation during download"
32 |         assert self.req.name, "Wheels are never unnamed"
33 |         wheel = FilesystemWheel(self.req.local_file_path)
34 |         return get_wheel_distribution(wheel, canonicalize_name(self.req.name))
35 | 
36 |     def prepare_distribution_metadata(
37 |         self,
38 |         finder: "PackageFinder",
39 |         build_isolation: bool,
40 |         check_build_deps: bool,
41 |     ) -> None:
42 |         pass
```

.venv/lib/python3.13/site-packages/pip/_internal/locations/__init__.py
```
1 | import functools
2 | import logging
3 | import os
4 | import pathlib
5 | import sys
6 | import sysconfig
7 | from typing import Any, Dict, Optional
8 | 
9 | from pip._internal.models.scheme import SCHEME_KEYS, Scheme
10 | from pip._internal.utils.compat import WINDOWS
11 | from pip._internal.utils.deprecation import deprecated
12 | from pip._internal.utils.virtualenv import running_under_virtualenv
13 | 
14 | from . import _sysconfig
15 | from .base import (
16 |     USER_CACHE_DIR,
17 |     get_major_minor_version,
18 |     get_src_prefix,
19 |     is_osx_framework,
20 |     site_packages,
21 |     user_site,
22 | )
23 | 
24 | __all__ = [
25 |     "USER_CACHE_DIR",
26 |     "get_bin_prefix",
27 |     "get_bin_user",
28 |     "get_major_minor_version",
29 |     "get_platlib",
30 |     "get_purelib",
31 |     "get_scheme",
32 |     "get_src_prefix",
33 |     "site_packages",
34 |     "user_site",
35 | ]
36 | 
37 | 
38 | logger = logging.getLogger(__name__)
39 | 
40 | 
41 | _PLATLIBDIR: str = getattr(sys, "platlibdir", "lib")
42 | 
43 | _USE_SYSCONFIG_DEFAULT = sys.version_info >= (3, 10)
44 | 
45 | 
46 | def _should_use_sysconfig() -> bool:
47 |     """This function determines the value of _USE_SYSCONFIG.
48 | 
49 |     By default, pip uses sysconfig on Python 3.10+.
50 |     But Python distributors can override this decision by setting:
51 |         sysconfig._PIP_USE_SYSCONFIG = True / False
52 |     Rationale in https://github.com/pypa/pip/issues/10647
53 | 
54 |     This is a function for testability, but should be constant during any one
55 |     run.
56 |     """
57 |     return bool(getattr(sysconfig, "_PIP_USE_SYSCONFIG", _USE_SYSCONFIG_DEFAULT))
58 | 
59 | 
60 | _USE_SYSCONFIG = _should_use_sysconfig()
61 | 
62 | if not _USE_SYSCONFIG:
63 |     # Import distutils lazily to avoid deprecation warnings,
64 |     # but import it soon enough that it is in memory and available during
65 |     # a pip reinstall.
66 |     from . import _distutils
67 | 
68 | # Be noisy about incompatibilities if this platforms "should" be using
69 | # sysconfig, but is explicitly opting out and using distutils instead.
70 | if _USE_SYSCONFIG_DEFAULT and not _USE_SYSCONFIG:
71 |     _MISMATCH_LEVEL = logging.WARNING
72 | else:
73 |     _MISMATCH_LEVEL = logging.DEBUG
74 | 
75 | 
76 | def _looks_like_bpo_44860() -> bool:
77 |     """The resolution to bpo-44860 will change this incorrect platlib.
78 | 
79 |     See <https://bugs.python.org/issue44860>.
80 |     """
81 |     from distutils.command.install import INSTALL_SCHEMES
82 | 
83 |     try:
84 |         unix_user_platlib = INSTALL_SCHEMES["unix_user"]["platlib"]
85 |     except KeyError:
86 |         return False
87 |     return unix_user_platlib == "$usersite"
88 | 
89 | 
90 | def _looks_like_red_hat_patched_platlib_purelib(scheme: Dict[str, str]) -> bool:
91 |     platlib = scheme["platlib"]
92 |     if "/$platlibdir/" in platlib:
93 |         platlib = platlib.replace("/$platlibdir/", f"/{_PLATLIBDIR}/")
94 |     if "/lib64/" not in platlib:
95 |         return False
96 |     unpatched = platlib.replace("/lib64/", "/lib/")
97 |     return unpatched.replace("$platbase/", "$base/") == scheme["purelib"]
98 | 
99 | 
100 | @functools.lru_cache(maxsize=None)
101 | def _looks_like_red_hat_lib() -> bool:
102 |     """Red Hat patches platlib in unix_prefix and unix_home, but not purelib.
103 | 
104 |     This is the only way I can see to tell a Red Hat-patched Python.
105 |     """
106 |     from distutils.command.install import INSTALL_SCHEMES
107 | 
108 |     return all(
109 |         k in INSTALL_SCHEMES
110 |         and _looks_like_red_hat_patched_platlib_purelib(INSTALL_SCHEMES[k])
111 |         for k in ("unix_prefix", "unix_home")
112 |     )
113 | 
114 | 
115 | @functools.lru_cache(maxsize=None)
116 | def _looks_like_debian_scheme() -> bool:
117 |     """Debian adds two additional schemes."""
118 |     from distutils.command.install import INSTALL_SCHEMES
119 | 
120 |     return "deb_system" in INSTALL_SCHEMES and "unix_local" in INSTALL_SCHEMES
121 | 
122 | 
123 | @functools.lru_cache(maxsize=None)
124 | def _looks_like_red_hat_scheme() -> bool:
125 |     """Red Hat patches ``sys.prefix`` and ``sys.exec_prefix``.
126 | 
127 |     Red Hat's ``00251-change-user-install-location.patch`` changes the install
128 |     command's ``prefix`` and ``exec_prefix`` to append ``"/local"``. This is
129 |     (fortunately?) done quite unconditionally, so we create a default command
130 |     object without any configuration to detect this.
131 |     """
132 |     from distutils.command.install import install
133 |     from distutils.dist import Distribution
134 | 
135 |     cmd: Any = install(Distribution())
136 |     cmd.finalize_options()
137 |     return (
138 |         cmd.exec_prefix == f"{os.path.normpath(sys.exec_prefix)}/local"
139 |         and cmd.prefix == f"{os.path.normpath(sys.prefix)}/local"
140 |     )
141 | 
142 | 
143 | @functools.lru_cache(maxsize=None)
144 | def _looks_like_slackware_scheme() -> bool:
145 |     """Slackware patches sysconfig but fails to patch distutils and site.
146 | 
147 |     Slackware changes sysconfig's user scheme to use ``"lib64"`` for the lib
148 |     path, but does not do the same to the site module.
149 |     """
150 |     if user_site is None:  # User-site not available.
151 |         return False
152 |     try:
153 |         paths = sysconfig.get_paths(scheme="posix_user", expand=False)
154 |     except KeyError:  # User-site not available.
155 |         return False
156 |     return "/lib64/" in paths["purelib"] and "/lib64/" not in user_site
157 | 
158 | 
159 | @functools.lru_cache(maxsize=None)
160 | def _looks_like_msys2_mingw_scheme() -> bool:
161 |     """MSYS2 patches distutils and sysconfig to use a UNIX-like scheme.
162 | 
163 |     However, MSYS2 incorrectly patches sysconfig ``nt`` scheme. The fix is
164 |     likely going to be included in their 3.10 release, so we ignore the warning.
165 |     See msys2/MINGW-packages#9319.
166 | 
167 |     MSYS2 MINGW's patch uses lowercase ``"lib"`` instead of the usual uppercase,
168 |     and is missing the final ``"site-packages"``.
169 |     """
170 |     paths = sysconfig.get_paths("nt", expand=False)
171 |     return all(
172 |         "Lib" not in p and "lib" in p and not p.endswith("site-packages")
173 |         for p in (paths[key] for key in ("platlib", "purelib"))
174 |     )
175 | 
176 | 
177 | @functools.lru_cache(maxsize=None)
178 | def _warn_mismatched(old: pathlib.Path, new: pathlib.Path, *, key: str) -> None:
179 |     issue_url = "https://github.com/pypa/pip/issues/10151"
180 |     message = (
181 |         "Value for %s does not match. Please report this to <%s>"
182 |         "\ndistutils: %s"
183 |         "\nsysconfig: %s"
184 |     )
185 |     logger.log(_MISMATCH_LEVEL, message, key, issue_url, old, new)
186 | 
187 | 
188 | def _warn_if_mismatch(old: pathlib.Path, new: pathlib.Path, *, key: str) -> bool:
189 |     if old == new:
190 |         return False
191 |     _warn_mismatched(old, new, key=key)
192 |     return True
193 | 
194 | 
195 | @functools.lru_cache(maxsize=None)
196 | def _log_context(
197 |     *,
198 |     user: bool = False,
199 |     home: Optional[str] = None,
200 |     root: Optional[str] = None,
201 |     prefix: Optional[str] = None,
202 | ) -> None:
203 |     parts = [
204 |         "Additional context:",
205 |         "user = %r",
206 |         "home = %r",
207 |         "root = %r",
208 |         "prefix = %r",
209 |     ]
210 | 
211 |     logger.log(_MISMATCH_LEVEL, "\n".join(parts), user, home, root, prefix)
212 | 
213 | 
214 | def get_scheme(
215 |     dist_name: str,
216 |     user: bool = False,
217 |     home: Optional[str] = None,
218 |     root: Optional[str] = None,
219 |     isolated: bool = False,
220 |     prefix: Optional[str] = None,
221 | ) -> Scheme:
222 |     new = _sysconfig.get_scheme(
223 |         dist_name,
224 |         user=user,
225 |         home=home,
226 |         root=root,
227 |         isolated=isolated,
228 |         prefix=prefix,
229 |     )
230 |     if _USE_SYSCONFIG:
231 |         return new
232 | 
233 |     old = _distutils.get_scheme(
234 |         dist_name,
235 |         user=user,
236 |         home=home,
237 |         root=root,
238 |         isolated=isolated,
239 |         prefix=prefix,
240 |     )
241 | 
242 |     warning_contexts = []
243 |     for k in SCHEME_KEYS:
244 |         old_v = pathlib.Path(getattr(old, k))
245 |         new_v = pathlib.Path(getattr(new, k))
246 | 
247 |         if old_v == new_v:
248 |             continue
249 | 
250 |         # distutils incorrectly put PyPy packages under ``site-packages/python``
251 |         # in the ``posix_home`` scheme, but PyPy devs said they expect the
252 |         # directory name to be ``pypy`` instead. So we treat this as a bug fix
253 |         # and not warn about it. See bpo-43307 and python/cpython#24628.
254 |         skip_pypy_special_case = (
255 |             sys.implementation.name == "pypy"
256 |             and home is not None
257 |             and k in ("platlib", "purelib")
258 |             and old_v.parent == new_v.parent
259 |             and old_v.name.startswith("python")
260 |             and new_v.name.startswith("pypy")
261 |         )
262 |         if skip_pypy_special_case:
263 |             continue
264 | 
265 |         # sysconfig's ``osx_framework_user`` does not include ``pythonX.Y`` in
266 |         # the ``include`` value, but distutils's ``headers`` does. We'll let
267 |         # CPython decide whether this is a bug or feature. See bpo-43948.
268 |         skip_osx_framework_user_special_case = (
269 |             user
270 |             and is_osx_framework()
271 |             and k == "headers"
272 |             and old_v.parent.parent == new_v.parent
273 |             and old_v.parent.name.startswith("python")
274 |         )
275 |         if skip_osx_framework_user_special_case:
276 |             continue
277 | 
278 |         # On Red Hat and derived Linux distributions, distutils is patched to
279 |         # use "lib64" instead of "lib" for platlib.
280 |         if k == "platlib" and _looks_like_red_hat_lib():
281 |             continue
282 | 
283 |         # On Python 3.9+, sysconfig's posix_user scheme sets platlib against
284 |         # sys.platlibdir, but distutils's unix_user incorrectly coninutes
285 |         # using the same $usersite for both platlib and purelib. This creates a
286 |         # mismatch when sys.platlibdir is not "lib".
287 |         skip_bpo_44860 = (
288 |             user
289 |             and k == "platlib"
290 |             and not WINDOWS
291 |             and _PLATLIBDIR != "lib"
292 |             and _looks_like_bpo_44860()
293 |         )
294 |         if skip_bpo_44860:
295 |             continue
296 | 
297 |         # Slackware incorrectly patches posix_user to use lib64 instead of lib,
298 |         # but not usersite to match the location.
299 |         skip_slackware_user_scheme = (
300 |             user
301 |             and k in ("platlib", "purelib")
302 |             and not WINDOWS
303 |             and _looks_like_slackware_scheme()
304 |         )
305 |         if skip_slackware_user_scheme:
306 |             continue
307 | 
308 |         # Both Debian and Red Hat patch Python to place the system site under
309 |         # /usr/local instead of /usr. Debian also places lib in dist-packages
310 |         # instead of site-packages, but the /usr/local check should cover it.
311 |         skip_linux_system_special_case = (
312 |             not (user or home or prefix or running_under_virtualenv())
313 |             and old_v.parts[1:3] == ("usr", "local")
314 |             and len(new_v.parts) > 1
315 |             and new_v.parts[1] == "usr"
316 |             and (len(new_v.parts) < 3 or new_v.parts[2] != "local")
317 |             and (_looks_like_red_hat_scheme() or _looks_like_debian_scheme())
318 |         )
319 |         if skip_linux_system_special_case:
320 |             continue
321 | 
322 |         # MSYS2 MINGW's sysconfig patch does not include the "site-packages"
323 |         # part of the path. This is incorrect and will be fixed in MSYS.
324 |         skip_msys2_mingw_bug = (
325 |             WINDOWS and k in ("platlib", "purelib") and _looks_like_msys2_mingw_scheme()
326 |         )
327 |         if skip_msys2_mingw_bug:
328 |             continue
329 | 
330 |         # CPython's POSIX install script invokes pip (via ensurepip) against the
331 |         # interpreter located in the source tree, not the install site. This
332 |         # triggers special logic in sysconfig that's not present in distutils.
333 |         # https://github.com/python/cpython/blob/8c21941ddaf/Lib/sysconfig.py#L178-L194
334 |         skip_cpython_build = (
335 |             sysconfig.is_python_build(check_home=True)
336 |             and not WINDOWS
337 |             and k in ("headers", "include", "platinclude")
338 |         )
339 |         if skip_cpython_build:
340 |             continue
341 | 
342 |         warning_contexts.append((old_v, new_v, f"scheme.{k}"))
343 | 
344 |     if not warning_contexts:
345 |         return old
346 | 
[TRUNCATED]
```

.venv/lib/python3.13/site-packages/pip/_internal/locations/_distutils.py
```
1 | """Locations where we look for configs, install stuff, etc"""
2 | 
3 | # The following comment should be removed at some point in the future.
4 | # mypy: strict-optional=False
5 | 
6 | # If pip's going to use distutils, it should not be using the copy that setuptools
7 | # might have injected into the environment. This is done by removing the injected
8 | # shim, if it's injected.
9 | #
10 | # See https://github.com/pypa/pip/issues/8761 for the original discussion and
11 | # rationale for why this is done within pip.
12 | try:
13 |     __import__("_distutils_hack").remove_shim()
14 | except (ImportError, AttributeError):
15 |     pass
16 | 
17 | import logging
18 | import os
19 | import sys
20 | from distutils.cmd import Command as DistutilsCommand
21 | from distutils.command.install import SCHEME_KEYS
22 | from distutils.command.install import install as distutils_install_command
23 | from distutils.sysconfig import get_python_lib
24 | from typing import Dict, List, Optional, Union
25 | 
26 | from pip._internal.models.scheme import Scheme
27 | from pip._internal.utils.compat import WINDOWS
28 | from pip._internal.utils.virtualenv import running_under_virtualenv
29 | 
30 | from .base import get_major_minor_version
31 | 
32 | logger = logging.getLogger(__name__)
33 | 
34 | 
35 | def distutils_scheme(
36 |     dist_name: str,
37 |     user: bool = False,
38 |     home: Optional[str] = None,
39 |     root: Optional[str] = None,
40 |     isolated: bool = False,
41 |     prefix: Optional[str] = None,
42 |     *,
43 |     ignore_config_files: bool = False,
44 | ) -> Dict[str, str]:
45 |     """
46 |     Return a distutils install scheme
47 |     """
48 |     from distutils.dist import Distribution
49 | 
50 |     dist_args: Dict[str, Union[str, List[str]]] = {"name": dist_name}
51 |     if isolated:
52 |         dist_args["script_args"] = ["--no-user-cfg"]
53 | 
54 |     d = Distribution(dist_args)
55 |     if not ignore_config_files:
56 |         try:
57 |             d.parse_config_files()
58 |         except UnicodeDecodeError:
59 |             paths = d.find_config_files()
60 |             logger.warning(
61 |                 "Ignore distutils configs in %s due to encoding errors.",
62 |                 ", ".join(os.path.basename(p) for p in paths),
63 |             )
64 |     obj: Optional[DistutilsCommand] = None
65 |     obj = d.get_command_obj("install", create=True)
66 |     assert obj is not None
67 |     i: distutils_install_command = obj
68 |     # NOTE: setting user or home has the side-effect of creating the home dir
69 |     # or user base for installations during finalize_options()
70 |     # ideally, we'd prefer a scheme class that has no side-effects.
71 |     assert not (user and prefix), f"user={user} prefix={prefix}"
72 |     assert not (home and prefix), f"home={home} prefix={prefix}"
73 |     i.user = user or i.user
74 |     if user or home:
75 |         i.prefix = ""
76 |     i.prefix = prefix or i.prefix
77 |     i.home = home or i.home
78 |     i.root = root or i.root
79 |     i.finalize_options()
80 | 
81 |     scheme: Dict[str, str] = {}
82 |     for key in SCHEME_KEYS:
83 |         scheme[key] = getattr(i, "install_" + key)
84 | 
85 |     # install_lib specified in setup.cfg should install *everything*
86 |     # into there (i.e. it takes precedence over both purelib and
87 |     # platlib).  Note, i.install_lib is *always* set after
88 |     # finalize_options(); we only want to override here if the user
89 |     # has explicitly requested it hence going back to the config
90 |     if "install_lib" in d.get_option_dict("install"):
91 |         scheme.update({"purelib": i.install_lib, "platlib": i.install_lib})
92 | 
93 |     if running_under_virtualenv():
94 |         if home:
95 |             prefix = home
96 |         elif user:
97 |             prefix = i.install_userbase
98 |         else:
99 |             prefix = i.prefix
100 |         scheme["headers"] = os.path.join(
101 |             prefix,
102 |             "include",
103 |             "site",
104 |             f"python{get_major_minor_version()}",
105 |             dist_name,
106 |         )
107 | 
108 |         if root is not None:
109 |             path_no_drive = os.path.splitdrive(os.path.abspath(scheme["headers"]))[1]
110 |             scheme["headers"] = os.path.join(root, path_no_drive[1:])
111 | 
112 |     return scheme
113 | 
114 | 
115 | def get_scheme(
116 |     dist_name: str,
117 |     user: bool = False,
118 |     home: Optional[str] = None,
119 |     root: Optional[str] = None,
120 |     isolated: bool = False,
121 |     prefix: Optional[str] = None,
122 | ) -> Scheme:
123 |     """
124 |     Get the "scheme" corresponding to the input parameters. The distutils
125 |     documentation provides the context for the available schemes:
126 |     https://docs.python.org/3/install/index.html#alternate-installation
127 | 
128 |     :param dist_name: the name of the package to retrieve the scheme for, used
129 |         in the headers scheme path
130 |     :param user: indicates to use the "user" scheme
131 |     :param home: indicates to use the "home" scheme and provides the base
132 |         directory for the same
133 |     :param root: root under which other directories are re-based
134 |     :param isolated: equivalent to --no-user-cfg, i.e. do not consider
135 |         ~/.pydistutils.cfg (posix) or ~/pydistutils.cfg (non-posix) for
136 |         scheme paths
137 |     :param prefix: indicates to use the "prefix" scheme and provides the
138 |         base directory for the same
139 |     """
140 |     scheme = distutils_scheme(dist_name, user, home, root, isolated, prefix)
141 |     return Scheme(
142 |         platlib=scheme["platlib"],
143 |         purelib=scheme["purelib"],
144 |         headers=scheme["headers"],
145 |         scripts=scheme["scripts"],
146 |         data=scheme["data"],
147 |     )
148 | 
149 | 
150 | def get_bin_prefix() -> str:
151 |     # XXX: In old virtualenv versions, sys.prefix can contain '..' components,
152 |     # so we need to call normpath to eliminate them.
153 |     prefix = os.path.normpath(sys.prefix)
154 |     if WINDOWS:
155 |         bin_py = os.path.join(prefix, "Scripts")
156 |         # buildout uses 'bin' on Windows too?
157 |         if not os.path.exists(bin_py):
158 |             bin_py = os.path.join(prefix, "bin")
159 |         return bin_py
160 |     # Forcing to use /usr/local/bin for standard macOS framework installs
161 |     # Also log to ~/Library/Logs/ for use with the Console.app log viewer
162 |     if sys.platform[:6] == "darwin" and prefix[:16] == "/System/Library/":
163 |         return "/usr/local/bin"
164 |     return os.path.join(prefix, "bin")
165 | 
166 | 
167 | def get_purelib() -> str:
168 |     return get_python_lib(plat_specific=False)
169 | 
170 | 
171 | def get_platlib() -> str:
172 |     return get_python_lib(plat_specific=True)
```

.venv/lib/python3.13/site-packages/pip/_internal/locations/_sysconfig.py
```
1 | import logging
2 | import os
3 | import sys
4 | import sysconfig
5 | import typing
6 | 
7 | from pip._internal.exceptions import InvalidSchemeCombination, UserInstallationInvalid
8 | from pip._internal.models.scheme import SCHEME_KEYS, Scheme
9 | from pip._internal.utils.virtualenv import running_under_virtualenv
10 | 
11 | from .base import change_root, get_major_minor_version, is_osx_framework
12 | 
13 | logger = logging.getLogger(__name__)
14 | 
15 | 
16 | # Notes on _infer_* functions.
17 | # Unfortunately ``get_default_scheme()`` didn't exist before 3.10, so there's no
18 | # way to ask things like "what is the '_prefix' scheme on this platform". These
19 | # functions try to answer that with some heuristics while accounting for ad-hoc
20 | # platforms not covered by CPython's default sysconfig implementation. If the
21 | # ad-hoc implementation does not fully implement sysconfig, we'll fall back to
22 | # a POSIX scheme.
23 | 
24 | _AVAILABLE_SCHEMES = set(sysconfig.get_scheme_names())
25 | 
26 | _PREFERRED_SCHEME_API = getattr(sysconfig, "get_preferred_scheme", None)
27 | 
28 | 
29 | def _should_use_osx_framework_prefix() -> bool:
30 |     """Check for Apple's ``osx_framework_library`` scheme.
31 | 
32 |     Python distributed by Apple's Command Line Tools has this special scheme
33 |     that's used when:
34 | 
35 |     * This is a framework build.
36 |     * We are installing into the system prefix.
37 | 
38 |     This does not account for ``pip install --prefix`` (also means we're not
39 |     installing to the system prefix), which should use ``posix_prefix``, but
40 |     logic here means ``_infer_prefix()`` outputs ``osx_framework_library``. But
41 |     since ``prefix`` is not available for ``sysconfig.get_default_scheme()``,
42 |     which is the stdlib replacement for ``_infer_prefix()``, presumably Apple
43 |     wouldn't be able to magically switch between ``osx_framework_library`` and
44 |     ``posix_prefix``. ``_infer_prefix()`` returning ``osx_framework_library``
45 |     means its behavior is consistent whether we use the stdlib implementation
46 |     or our own, and we deal with this special case in ``get_scheme()`` instead.
47 |     """
48 |     return (
49 |         "osx_framework_library" in _AVAILABLE_SCHEMES
50 |         and not running_under_virtualenv()
51 |         and is_osx_framework()
52 |     )
53 | 
54 | 
55 | def _infer_prefix() -> str:
56 |     """Try to find a prefix scheme for the current platform.
57 | 
58 |     This tries:
59 | 
60 |     * A special ``osx_framework_library`` for Python distributed by Apple's
61 |       Command Line Tools, when not running in a virtual environment.
62 |     * Implementation + OS, used by PyPy on Windows (``pypy_nt``).
63 |     * Implementation without OS, used by PyPy on POSIX (``pypy``).
64 |     * OS + "prefix", used by CPython on POSIX (``posix_prefix``).
65 |     * Just the OS name, used by CPython on Windows (``nt``).
66 | 
67 |     If none of the above works, fall back to ``posix_prefix``.
68 |     """
69 |     if _PREFERRED_SCHEME_API:
70 |         return _PREFERRED_SCHEME_API("prefix")
71 |     if _should_use_osx_framework_prefix():
72 |         return "osx_framework_library"
73 |     implementation_suffixed = f"{sys.implementation.name}_{os.name}"
74 |     if implementation_suffixed in _AVAILABLE_SCHEMES:
75 |         return implementation_suffixed
76 |     if sys.implementation.name in _AVAILABLE_SCHEMES:
77 |         return sys.implementation.name
78 |     suffixed = f"{os.name}_prefix"
79 |     if suffixed in _AVAILABLE_SCHEMES:
80 |         return suffixed
81 |     if os.name in _AVAILABLE_SCHEMES:  # On Windows, prefx is just called "nt".
82 |         return os.name
83 |     return "posix_prefix"
84 | 
85 | 
86 | def _infer_user() -> str:
87 |     """Try to find a user scheme for the current platform."""
88 |     if _PREFERRED_SCHEME_API:
89 |         return _PREFERRED_SCHEME_API("user")
90 |     if is_osx_framework() and not running_under_virtualenv():
91 |         suffixed = "osx_framework_user"
92 |     else:
93 |         suffixed = f"{os.name}_user"
94 |     if suffixed in _AVAILABLE_SCHEMES:
95 |         return suffixed
96 |     if "posix_user" not in _AVAILABLE_SCHEMES:  # User scheme unavailable.
97 |         raise UserInstallationInvalid()
98 |     return "posix_user"
99 | 
100 | 
101 | def _infer_home() -> str:
102 |     """Try to find a home for the current platform."""
103 |     if _PREFERRED_SCHEME_API:
104 |         return _PREFERRED_SCHEME_API("home")
105 |     suffixed = f"{os.name}_home"
106 |     if suffixed in _AVAILABLE_SCHEMES:
107 |         return suffixed
108 |     return "posix_home"
109 | 
110 | 
111 | # Update these keys if the user sets a custom home.
112 | _HOME_KEYS = [
113 |     "installed_base",
114 |     "base",
115 |     "installed_platbase",
116 |     "platbase",
117 |     "prefix",
118 |     "exec_prefix",
119 | ]
120 | if sysconfig.get_config_var("userbase") is not None:
121 |     _HOME_KEYS.append("userbase")
122 | 
123 | 
124 | def get_scheme(
125 |     dist_name: str,
126 |     user: bool = False,
127 |     home: typing.Optional[str] = None,
128 |     root: typing.Optional[str] = None,
129 |     isolated: bool = False,
130 |     prefix: typing.Optional[str] = None,
131 | ) -> Scheme:
132 |     """
133 |     Get the "scheme" corresponding to the input parameters.
134 | 
135 |     :param dist_name: the name of the package to retrieve the scheme for, used
136 |         in the headers scheme path
137 |     :param user: indicates to use the "user" scheme
138 |     :param home: indicates to use the "home" scheme
139 |     :param root: root under which other directories are re-based
140 |     :param isolated: ignored, but kept for distutils compatibility (where
141 |         this controls whether the user-site pydistutils.cfg is honored)
142 |     :param prefix: indicates to use the "prefix" scheme and provides the
143 |         base directory for the same
144 |     """
145 |     if user and prefix:
146 |         raise InvalidSchemeCombination("--user", "--prefix")
147 |     if home and prefix:
148 |         raise InvalidSchemeCombination("--home", "--prefix")
149 | 
150 |     if home is not None:
151 |         scheme_name = _infer_home()
152 |     elif user:
153 |         scheme_name = _infer_user()
154 |     else:
155 |         scheme_name = _infer_prefix()
156 | 
157 |     # Special case: When installing into a custom prefix, use posix_prefix
158 |     # instead of osx_framework_library. See _should_use_osx_framework_prefix()
159 |     # docstring for details.
160 |     if prefix is not None and scheme_name == "osx_framework_library":
161 |         scheme_name = "posix_prefix"
162 | 
163 |     if home is not None:
164 |         variables = {k: home for k in _HOME_KEYS}
165 |     elif prefix is not None:
166 |         variables = {k: prefix for k in _HOME_KEYS}
167 |     else:
168 |         variables = {}
169 | 
170 |     paths = sysconfig.get_paths(scheme=scheme_name, vars=variables)
171 | 
172 |     # Logic here is very arbitrary, we're doing it for compatibility, don't ask.
173 |     # 1. Pip historically uses a special header path in virtual environments.
174 |     # 2. If the distribution name is not known, distutils uses 'UNKNOWN'. We
175 |     #    only do the same when not running in a virtual environment because
176 |     #    pip's historical header path logic (see point 1) did not do this.
177 |     if running_under_virtualenv():
178 |         if user:
179 |             base = variables.get("userbase", sys.prefix)
180 |         else:
181 |             base = variables.get("base", sys.prefix)
182 |         python_xy = f"python{get_major_minor_version()}"
183 |         paths["include"] = os.path.join(base, "include", "site", python_xy)
184 |     elif not dist_name:
185 |         dist_name = "UNKNOWN"
186 | 
187 |     scheme = Scheme(
188 |         platlib=paths["platlib"],
189 |         purelib=paths["purelib"],
190 |         headers=os.path.join(paths["include"], dist_name),
191 |         scripts=paths["scripts"],
192 |         data=paths["data"],
193 |     )
194 |     if root is not None:
195 |         converted_keys = {}
196 |         for key in SCHEME_KEYS:
197 |             converted_keys[key] = change_root(root, getattr(scheme, key))
198 |         scheme = Scheme(**converted_keys)
199 |     return scheme
200 | 
201 | 
202 | def get_bin_prefix() -> str:
203 |     # Forcing to use /usr/local/bin for standard macOS framework installs.
204 |     if sys.platform[:6] == "darwin" and sys.prefix[:16] == "/System/Library/":
205 |         return "/usr/local/bin"
206 |     return sysconfig.get_paths()["scripts"]
207 | 
208 | 
209 | def get_purelib() -> str:
210 |     return sysconfig.get_paths()["purelib"]
211 | 
212 | 
213 | def get_platlib() -> str:
214 |     return sysconfig.get_paths()["platlib"]
```

.venv/lib/python3.13/site-packages/pip/_internal/locations/base.py
```
1 | import functools
2 | import os
3 | import site
4 | import sys
5 | import sysconfig
6 | import typing
7 | 
8 | from pip._internal.exceptions import InstallationError
9 | from pip._internal.utils import appdirs
10 | from pip._internal.utils.virtualenv import running_under_virtualenv
11 | 
12 | # Application Directories
13 | USER_CACHE_DIR = appdirs.user_cache_dir("pip")
14 | 
15 | # FIXME doesn't account for venv linked to global site-packages
16 | site_packages: str = sysconfig.get_path("purelib")
17 | 
18 | 
19 | def get_major_minor_version() -> str:
20 |     """
21 |     Return the major-minor version of the current Python as a string, e.g.
22 |     "3.7" or "3.10".
23 |     """
24 |     return "{}.{}".format(*sys.version_info)
25 | 
26 | 
27 | def change_root(new_root: str, pathname: str) -> str:
28 |     """Return 'pathname' with 'new_root' prepended.
29 | 
30 |     If 'pathname' is relative, this is equivalent to os.path.join(new_root, pathname).
31 |     Otherwise, it requires making 'pathname' relative and then joining the
32 |     two, which is tricky on DOS/Windows and Mac OS.
33 | 
34 |     This is borrowed from Python's standard library's distutils module.
35 |     """
36 |     if os.name == "posix":
37 |         if not os.path.isabs(pathname):
38 |             return os.path.join(new_root, pathname)
39 |         else:
40 |             return os.path.join(new_root, pathname[1:])
41 | 
42 |     elif os.name == "nt":
43 |         (drive, path) = os.path.splitdrive(pathname)
44 |         if path[0] == "\\":
45 |             path = path[1:]
46 |         return os.path.join(new_root, path)
47 | 
48 |     else:
49 |         raise InstallationError(
50 |             f"Unknown platform: {os.name}\n"
51 |             "Can not change root path prefix on unknown platform."
52 |         )
53 | 
54 | 
55 | def get_src_prefix() -> str:
56 |     if running_under_virtualenv():
57 |         src_prefix = os.path.join(sys.prefix, "src")
58 |     else:
59 |         # FIXME: keep src in cwd for now (it is not a temporary folder)
60 |         try:
61 |             src_prefix = os.path.join(os.getcwd(), "src")
62 |         except OSError:
63 |             # In case the current working directory has been renamed or deleted
64 |             sys.exit("The folder you are executing pip from can no longer be found.")
65 | 
66 |     # under macOS + virtualenv sys.prefix is not properly resolved
67 |     # it is something like /path/to/python/bin/..
68 |     return os.path.abspath(src_prefix)
69 | 
70 | 
71 | try:
72 |     # Use getusersitepackages if this is present, as it ensures that the
73 |     # value is initialised properly.
74 |     user_site: typing.Optional[str] = site.getusersitepackages()
75 | except AttributeError:
76 |     user_site = site.USER_SITE
77 | 
78 | 
79 | @functools.lru_cache(maxsize=None)
80 | def is_osx_framework() -> bool:
81 |     return bool(sysconfig.get_config_var("PYTHONFRAMEWORK"))
```

.venv/lib/python3.13/site-packages/pip/_internal/metadata/__init__.py
```
1 | import contextlib
2 | import functools
3 | import os
4 | import sys
5 | from typing import List, Literal, Optional, Protocol, Type, cast
6 | 
7 | from pip._internal.utils.deprecation import deprecated
8 | from pip._internal.utils.misc import strtobool
9 | 
10 | from .base import BaseDistribution, BaseEnvironment, FilesystemWheel, MemoryWheel, Wheel
11 | 
12 | __all__ = [
13 |     "BaseDistribution",
14 |     "BaseEnvironment",
15 |     "FilesystemWheel",
16 |     "MemoryWheel",
17 |     "Wheel",
18 |     "get_default_environment",
19 |     "get_environment",
20 |     "get_wheel_distribution",
21 |     "select_backend",
22 | ]
23 | 
24 | 
25 | def _should_use_importlib_metadata() -> bool:
26 |     """Whether to use the ``importlib.metadata`` or ``pkg_resources`` backend.
27 | 
28 |     By default, pip uses ``importlib.metadata`` on Python 3.11+, and
29 |     ``pkg_resources`` otherwise. Up to Python 3.13, This can be
30 |     overridden by a couple of ways:
31 | 
32 |     * If environment variable ``_PIP_USE_IMPORTLIB_METADATA`` is set, it
33 |       dictates whether ``importlib.metadata`` is used, for Python <3.14.
34 |     * On Python 3.11, 3.12 and 3.13, Python distributors can patch
35 |       ``importlib.metadata`` to add a global constant
36 |       ``_PIP_USE_IMPORTLIB_METADATA = False``. This makes pip use
37 |       ``pkg_resources`` (unless the user set the aforementioned environment
38 |       variable to *True*).
39 | 
40 |     On Python 3.14+, the ``pkg_resources`` backend cannot be used.
41 |     """
42 |     if sys.version_info >= (3, 14):
43 |         # On Python >=3.14 we only support importlib.metadata.
44 |         return True
45 |     with contextlib.suppress(KeyError, ValueError):
46 |         # On Python <3.14, if the environment variable is set, we obey what it says.
47 |         return bool(strtobool(os.environ["_PIP_USE_IMPORTLIB_METADATA"]))
48 |     if sys.version_info < (3, 11):
49 |         # On Python <3.11, we always use pkg_resources, unless the environment
50 |         # variable was set.
51 |         return False
52 |     # On Python 3.11, 3.12 and 3.13, we check if the global constant is set.
53 |     import importlib.metadata
54 | 
55 |     return bool(getattr(importlib.metadata, "_PIP_USE_IMPORTLIB_METADATA", True))
56 | 
57 | 
58 | def _emit_pkg_resources_deprecation_if_needed() -> None:
59 |     if sys.version_info < (3, 11):
60 |         # All pip versions supporting Python<=3.11 will support pkg_resources,
61 |         # and pkg_resources is the default for these, so let's not bother users.
62 |         return
63 | 
64 |     import importlib.metadata
65 | 
66 |     if hasattr(importlib.metadata, "_PIP_USE_IMPORTLIB_METADATA"):
67 |         # The Python distributor has set the global constant, so we don't
68 |         # warn, since it is not a user decision.
69 |         return
70 | 
71 |     # The user has decided to use pkg_resources, so we warn.
72 |     deprecated(
73 |         reason="Using the pkg_resources metadata backend is deprecated.",
74 |         replacement=(
75 |             "to use the default importlib.metadata backend, "
76 |             "by unsetting the _PIP_USE_IMPORTLIB_METADATA environment variable"
77 |         ),
78 |         gone_in="26.3",
79 |         issue=13317,
80 |     )
81 | 
82 | 
83 | class Backend(Protocol):
84 |     NAME: 'Literal["importlib", "pkg_resources"]'
85 |     Distribution: Type[BaseDistribution]
86 |     Environment: Type[BaseEnvironment]
87 | 
88 | 
89 | @functools.lru_cache(maxsize=None)
90 | def select_backend() -> Backend:
91 |     if _should_use_importlib_metadata():
92 |         from . import importlib
93 | 
94 |         return cast(Backend, importlib)
95 | 
96 |     _emit_pkg_resources_deprecation_if_needed()
97 | 
98 |     from . import pkg_resources
99 | 
100 |     return cast(Backend, pkg_resources)
101 | 
102 | 
103 | def get_default_environment() -> BaseEnvironment:
104 |     """Get the default representation for the current environment.
105 | 
106 |     This returns an Environment instance from the chosen backend. The default
107 |     Environment instance should be built from ``sys.path`` and may use caching
108 |     to share instance state across calls.
109 |     """
110 |     return select_backend().Environment.default()
111 | 
112 | 
113 | def get_environment(paths: Optional[List[str]]) -> BaseEnvironment:
114 |     """Get a representation of the environment specified by ``paths``.
115 | 
116 |     This returns an Environment instance from the chosen backend based on the
117 |     given import paths. The backend must build a fresh instance representing
118 |     the state of installed distributions when this function is called.
119 |     """
120 |     return select_backend().Environment.from_paths(paths)
121 | 
122 | 
123 | def get_directory_distribution(directory: str) -> BaseDistribution:
124 |     """Get the distribution metadata representation in the specified directory.
125 | 
126 |     This returns a Distribution instance from the chosen backend based on
127 |     the given on-disk ``.dist-info`` directory.
128 |     """
129 |     return select_backend().Distribution.from_directory(directory)
130 | 
131 | 
132 | def get_wheel_distribution(wheel: Wheel, canonical_name: str) -> BaseDistribution:
133 |     """Get the representation of the specified wheel's distribution metadata.
134 | 
135 |     This returns a Distribution instance from the chosen backend based on
136 |     the given wheel's ``.dist-info`` directory.
137 | 
138 |     :param canonical_name: Normalized project name of the given wheel.
139 |     """
140 |     return select_backend().Distribution.from_wheel(wheel, canonical_name)
141 | 
142 | 
143 | def get_metadata_distribution(
144 |     metadata_contents: bytes,
145 |     filename: str,
146 |     canonical_name: str,
147 | ) -> BaseDistribution:
148 |     """Get the dist representation of the specified METADATA file contents.
149 | 
150 |     This returns a Distribution instance from the chosen backend sourced from the data
151 |     in `metadata_contents`.
152 | 
153 |     :param metadata_contents: Contents of a METADATA file within a dist, or one served
154 |                               via PEP 658.
155 |     :param filename: Filename for the dist this metadata represents.
156 |     :param canonical_name: Normalized project name of the given dist.
157 |     """
158 |     return select_backend().Distribution.from_metadata_file_contents(
159 |         metadata_contents,
160 |         filename,
161 |         canonical_name,
162 |     )
```

.venv/lib/python3.13/site-packages/pip/_internal/metadata/_json.py
```
1 | # Extracted from https://github.com/pfmoore/pkg_metadata
2 | 
3 | from email.header import Header, decode_header, make_header
4 | from email.message import Message
5 | from typing import Any, Dict, List, Union, cast
6 | 
7 | METADATA_FIELDS = [
8 |     # Name, Multiple-Use
9 |     ("Metadata-Version", False),
10 |     ("Name", False),
11 |     ("Version", False),
12 |     ("Dynamic", True),
13 |     ("Platform", True),
14 |     ("Supported-Platform", True),
15 |     ("Summary", False),
16 |     ("Description", False),
17 |     ("Description-Content-Type", False),
18 |     ("Keywords", False),
19 |     ("Home-page", False),
20 |     ("Download-URL", False),
21 |     ("Author", False),
22 |     ("Author-email", False),
23 |     ("Maintainer", False),
24 |     ("Maintainer-email", False),
25 |     ("License", False),
26 |     ("License-Expression", False),
27 |     ("License-File", True),
28 |     ("Classifier", True),
29 |     ("Requires-Dist", True),
30 |     ("Requires-Python", False),
31 |     ("Requires-External", True),
32 |     ("Project-URL", True),
33 |     ("Provides-Extra", True),
34 |     ("Provides-Dist", True),
35 |     ("Obsoletes-Dist", True),
36 | ]
37 | 
38 | 
39 | def json_name(field: str) -> str:
40 |     return field.lower().replace("-", "_")
41 | 
42 | 
43 | def msg_to_json(msg: Message) -> Dict[str, Any]:
44 |     """Convert a Message object into a JSON-compatible dictionary."""
45 | 
46 |     def sanitise_header(h: Union[Header, str]) -> str:
47 |         if isinstance(h, Header):
48 |             chunks = []
49 |             for bytes, encoding in decode_header(h):
50 |                 if encoding == "unknown-8bit":
51 |                     try:
52 |                         # See if UTF-8 works
53 |                         bytes.decode("utf-8")
54 |                         encoding = "utf-8"
55 |                     except UnicodeDecodeError:
56 |                         # If not, latin1 at least won't fail
57 |                         encoding = "latin1"
58 |                 chunks.append((bytes, encoding))
59 |             return str(make_header(chunks))
60 |         return str(h)
61 | 
62 |     result = {}
63 |     for field, multi in METADATA_FIELDS:
64 |         if field not in msg:
65 |             continue
66 |         key = json_name(field)
67 |         if multi:
68 |             value: Union[str, List[str]] = [
69 |                 sanitise_header(v) for v in msg.get_all(field)  # type: ignore
70 |             ]
71 |         else:
72 |             value = sanitise_header(msg.get(field))  # type: ignore
73 |             if key == "keywords":
74 |                 # Accept both comma-separated and space-separated
75 |                 # forms, for better compatibility with old data.
76 |                 if "," in value:
77 |                     value = [v.strip() for v in value.split(",")]
78 |                 else:
79 |                     value = value.split()
80 |         result[key] = value
81 | 
82 |     payload = cast(str, msg.get_payload())
83 |     if payload:
84 |         result["description"] = payload
85 | 
86 |     return result
```

.venv/lib/python3.13/site-packages/pip/_internal/metadata/base.py
```
1 | import csv
2 | import email.message
3 | import functools
4 | import json
5 | import logging
6 | import pathlib
7 | import re
8 | import zipfile
9 | from typing import (
10 |     IO,
11 |     Any,
12 |     Collection,
13 |     Container,
14 |     Dict,
15 |     Iterable,
16 |     Iterator,
17 |     List,
18 |     NamedTuple,
19 |     Optional,
20 |     Protocol,
21 |     Tuple,
22 |     Union,
23 | )
24 | 
25 | from pip._vendor.packaging.requirements import Requirement
26 | from pip._vendor.packaging.specifiers import InvalidSpecifier, SpecifierSet
27 | from pip._vendor.packaging.utils import NormalizedName, canonicalize_name
28 | from pip._vendor.packaging.version import Version
29 | 
30 | from pip._internal.exceptions import NoneMetadataError
31 | from pip._internal.locations import site_packages, user_site
32 | from pip._internal.models.direct_url import (
33 |     DIRECT_URL_METADATA_NAME,
34 |     DirectUrl,
35 |     DirectUrlValidationError,
36 | )
37 | from pip._internal.utils.compat import stdlib_pkgs  # TODO: Move definition here.
38 | from pip._internal.utils.egg_link import egg_link_path_from_sys_path
39 | from pip._internal.utils.misc import is_local, normalize_path
40 | from pip._internal.utils.urls import url_to_path
41 | 
42 | from ._json import msg_to_json
43 | 
44 | InfoPath = Union[str, pathlib.PurePath]
45 | 
46 | logger = logging.getLogger(__name__)
47 | 
48 | 
49 | class BaseEntryPoint(Protocol):
50 |     @property
51 |     def name(self) -> str:
52 |         raise NotImplementedError()
53 | 
54 |     @property
55 |     def value(self) -> str:
56 |         raise NotImplementedError()
57 | 
58 |     @property
59 |     def group(self) -> str:
60 |         raise NotImplementedError()
61 | 
62 | 
63 | def _convert_installed_files_path(
64 |     entry: Tuple[str, ...],
65 |     info: Tuple[str, ...],
66 | ) -> str:
67 |     """Convert a legacy installed-files.txt path into modern RECORD path.
68 | 
69 |     The legacy format stores paths relative to the info directory, while the
70 |     modern format stores paths relative to the package root, e.g. the
71 |     site-packages directory.
72 | 
73 |     :param entry: Path parts of the installed-files.txt entry.
74 |     :param info: Path parts of the egg-info directory relative to package root.
75 |     :returns: The converted entry.
76 | 
77 |     For best compatibility with symlinks, this does not use ``abspath()`` or
78 |     ``Path.resolve()``, but tries to work with path parts:
79 | 
80 |     1. While ``entry`` starts with ``..``, remove the equal amounts of parts
81 |        from ``info``; if ``info`` is empty, start appending ``..`` instead.
82 |     2. Join the two directly.
83 |     """
84 |     while entry and entry[0] == "..":
85 |         if not info or info[-1] == "..":
86 |             info += ("..",)
87 |         else:
88 |             info = info[:-1]
89 |         entry = entry[1:]
90 |     return str(pathlib.Path(*info, *entry))
91 | 
92 | 
93 | class RequiresEntry(NamedTuple):
94 |     requirement: str
95 |     extra: str
96 |     marker: str
97 | 
98 | 
99 | class BaseDistribution(Protocol):
100 |     @classmethod
101 |     def from_directory(cls, directory: str) -> "BaseDistribution":
102 |         """Load the distribution from a metadata directory.
103 | 
104 |         :param directory: Path to a metadata directory, e.g. ``.dist-info``.
105 |         """
106 |         raise NotImplementedError()
107 | 
108 |     @classmethod
109 |     def from_metadata_file_contents(
110 |         cls,
111 |         metadata_contents: bytes,
112 |         filename: str,
113 |         project_name: str,
114 |     ) -> "BaseDistribution":
115 |         """Load the distribution from the contents of a METADATA file.
116 | 
117 |         This is used to implement PEP 658 by generating a "shallow" dist object that can
118 |         be used for resolution without downloading or building the actual dist yet.
119 | 
120 |         :param metadata_contents: The contents of a METADATA file.
121 |         :param filename: File name for the dist with this metadata.
122 |         :param project_name: Name of the project this dist represents.
123 |         """
124 |         raise NotImplementedError()
125 | 
126 |     @classmethod
127 |     def from_wheel(cls, wheel: "Wheel", name: str) -> "BaseDistribution":
128 |         """Load the distribution from a given wheel.
129 | 
130 |         :param wheel: A concrete wheel definition.
131 |         :param name: File name of the wheel.
132 | 
133 |         :raises InvalidWheel: Whenever loading of the wheel causes a
134 |             :py:exc:`zipfile.BadZipFile` exception to be thrown.
135 |         :raises UnsupportedWheel: If the wheel is a valid zip, but malformed
136 |             internally.
137 |         """
138 |         raise NotImplementedError()
139 | 
140 |     def __repr__(self) -> str:
141 |         return f"{self.raw_name} {self.raw_version} ({self.location})"
142 | 
143 |     def __str__(self) -> str:
144 |         return f"{self.raw_name} {self.raw_version}"
145 | 
146 |     @property
147 |     def location(self) -> Optional[str]:
148 |         """Where the distribution is loaded from.
149 | 
150 |         A string value is not necessarily a filesystem path, since distributions
151 |         can be loaded from other sources, e.g. arbitrary zip archives. ``None``
152 |         means the distribution is created in-memory.
153 | 
154 |         Do not canonicalize this value with e.g. ``pathlib.Path.resolve()``. If
155 |         this is a symbolic link, we want to preserve the relative path between
156 |         it and files in the distribution.
157 |         """
158 |         raise NotImplementedError()
159 | 
160 |     @property
161 |     def editable_project_location(self) -> Optional[str]:
162 |         """The project location for editable distributions.
163 | 
164 |         This is the directory where pyproject.toml or setup.py is located.
165 |         None if the distribution is not installed in editable mode.
166 |         """
167 |         # TODO: this property is relatively costly to compute, memoize it ?
168 |         direct_url = self.direct_url
169 |         if direct_url:
170 |             if direct_url.is_local_editable():
171 |                 return url_to_path(direct_url.url)
172 |         else:
173 |             # Search for an .egg-link file by walking sys.path, as it was
174 |             # done before by dist_is_editable().
175 |             egg_link_path = egg_link_path_from_sys_path(self.raw_name)
176 |             if egg_link_path:
177 |                 # TODO: get project location from second line of egg_link file
178 |                 #       (https://github.com/pypa/pip/issues/10243)
179 |                 return self.location
180 |         return None
181 | 
182 |     @property
183 |     def installed_location(self) -> Optional[str]:
184 |         """The distribution's "installed" location.
185 | 
186 |         This should generally be a ``site-packages`` directory. This is
187 |         usually ``dist.location``, except for legacy develop-installed packages,
188 |         where ``dist.location`` is the source code location, and this is where
189 |         the ``.egg-link`` file is.
190 | 
191 |         The returned location is normalized (in particular, with symlinks removed).
192 |         """
193 |         raise NotImplementedError()
194 | 
195 |     @property
196 |     def info_location(self) -> Optional[str]:
197 |         """Location of the .[egg|dist]-info directory or file.
198 | 
199 |         Similarly to ``location``, a string value is not necessarily a
200 |         filesystem path. ``None`` means the distribution is created in-memory.
201 | 
202 |         For a modern .dist-info installation on disk, this should be something
203 |         like ``{location}/{raw_name}-{version}.dist-info``.
204 | 
205 |         Do not canonicalize this value with e.g. ``pathlib.Path.resolve()``. If
206 |         this is a symbolic link, we want to preserve the relative path between
207 |         it and other files in the distribution.
208 |         """
209 |         raise NotImplementedError()
210 | 
211 |     @property
212 |     def installed_by_distutils(self) -> bool:
213 |         """Whether this distribution is installed with legacy distutils format.
214 | 
215 |         A distribution installed with "raw" distutils not patched by setuptools
216 |         uses one single file at ``info_location`` to store metadata. We need to
217 |         treat this specially on uninstallation.
218 |         """
219 |         info_location = self.info_location
220 |         if not info_location:
221 |             return False
222 |         return pathlib.Path(info_location).is_file()
223 | 
224 |     @property
225 |     def installed_as_egg(self) -> bool:
226 |         """Whether this distribution is installed as an egg.
227 | 
228 |         This usually indicates the distribution was installed by (older versions
229 |         of) easy_install.
230 |         """
231 |         location = self.location
232 |         if not location:
233 |             return False
234 |         # XXX if the distribution is a zipped egg, location has a trailing /
235 |         # so we resort to pathlib.Path to check the suffix in a reliable way.
236 |         return pathlib.Path(location).suffix == ".egg"
237 | 
238 |     @property
239 |     def installed_with_setuptools_egg_info(self) -> bool:
240 |         """Whether this distribution is installed with the ``.egg-info`` format.
241 | 
242 |         This usually indicates the distribution was installed with setuptools
243 |         with an old pip version or with ``single-version-externally-managed``.
244 | 
245 |         Note that this ensure the metadata store is a directory. distutils can
246 |         also installs an ``.egg-info``, but as a file, not a directory. This
247 |         property is *False* for that case. Also see ``installed_by_distutils``.
248 |         """
249 |         info_location = self.info_location
250 |         if not info_location:
251 |             return False
252 |         if not info_location.endswith(".egg-info"):
253 |             return False
254 |         return pathlib.Path(info_location).is_dir()
255 | 
256 |     @property
257 |     def installed_with_dist_info(self) -> bool:
258 |         """Whether this distribution is installed with the "modern format".
259 | 
260 |         This indicates a "modern" installation, e.g. storing metadata in the
261 |         ``.dist-info`` directory. This applies to installations made by
262 |         setuptools (but through pip, not directly), or anything using the
263 |         standardized build backend interface (PEP 517).
264 |         """
265 |         info_location = self.info_location
266 |         if not info_location:
267 |             return False
268 |         if not info_location.endswith(".dist-info"):
269 |             return False
270 |         return pathlib.Path(info_location).is_dir()
271 | 
272 |     @property
273 |     def canonical_name(self) -> NormalizedName:
274 |         raise NotImplementedError()
275 | 
276 |     @property
277 |     def version(self) -> Version:
278 |         raise NotImplementedError()
279 | 
280 |     @property
281 |     def raw_version(self) -> str:
282 |         raise NotImplementedError()
283 | 
284 |     @property
285 |     def setuptools_filename(self) -> str:
286 |         """Convert a project name to its setuptools-compatible filename.
287 | 
288 |         This is a copy of ``pkg_resources.to_filename()`` for compatibility.
289 |         """
290 |         return self.raw_name.replace("-", "_")
291 | 
292 |     @property
293 |     def direct_url(self) -> Optional[DirectUrl]:
294 |         """Obtain a DirectUrl from this distribution.
295 | 
296 |         Returns None if the distribution has no `direct_url.json` metadata,
297 |         or if `direct_url.json` is invalid.
298 |         """
299 |         try:
300 |             content = self.read_text(DIRECT_URL_METADATA_NAME)
301 |         except FileNotFoundError:
302 |             return None
303 |         try:
304 |             return DirectUrl.from_json(content)
305 |         except (
306 |             UnicodeDecodeError,
307 |             json.JSONDecodeError,
308 |             DirectUrlValidationError,
309 |         ) as e:
310 |             logger.warning(
311 |                 "Error parsing %s for %s: %s",
312 |                 DIRECT_URL_METADATA_NAME,
313 |                 self.canonical_name,
314 |                 e,
315 |             )
316 |             return None
317 | 
318 |     @property
319 |     def installer(self) -> str:
320 |         try:
321 |             installer_text = self.read_text("INSTALLER")
322 |         except (OSError, ValueError, NoneMetadataError):
323 |             return ""  # Fail silently if the installer file cannot be read.
324 |         for line in installer_text.splitlines():
325 |             cleaned_line = line.strip()
326 |             if cleaned_line:
327 |                 return cleaned_line
328 |         return ""
329 | 
330 |     @property
331 |     def requested(self) -> bool:
332 |         return self.is_file("REQUESTED")
333 | 
334 |     @property
335 |     def editable(self) -> bool:
336 |         return bool(self.editable_project_location)
337 | 
338 |     @property
339 |     def local(self) -> bool:
340 |         """If distribution is installed in the current virtual environment.
341 | 
342 |         Always True if we're not in a virtualenv.
343 |         """
344 |         if self.installed_location is None:
345 |             return False
346 |         return is_local(self.installed_location)
347 | 
348 |     @property
349 |     def in_usersite(self) -> bool:
350 |         if self.installed_location is None or user_site is None:
351 |             return False
352 |         return self.installed_location.startswith(normalize_path(user_site))
353 | 
354 |     @property
355 |     def in_site_packages(self) -> bool:
356 |         if self.installed_location is None or site_packages is None:
357 |             return False
[TRUNCATED]
```

.venv/lib/python3.13/site-packages/pip/_internal/metadata/pkg_resources.py
```
1 | import email.message
2 | import email.parser
3 | import logging
4 | import os
5 | import zipfile
6 | from typing import (
7 |     Collection,
8 |     Iterable,
9 |     Iterator,
10 |     List,
11 |     Mapping,
12 |     NamedTuple,
13 |     Optional,
14 | )
15 | 
16 | from pip._vendor import pkg_resources
17 | from pip._vendor.packaging.requirements import Requirement
18 | from pip._vendor.packaging.utils import NormalizedName, canonicalize_name
19 | from pip._vendor.packaging.version import Version
20 | from pip._vendor.packaging.version import parse as parse_version
21 | 
22 | from pip._internal.exceptions import InvalidWheel, NoneMetadataError, UnsupportedWheel
23 | from pip._internal.utils.egg_link import egg_link_path_from_location
24 | from pip._internal.utils.misc import display_path, normalize_path
25 | from pip._internal.utils.wheel import parse_wheel, read_wheel_metadata_file
26 | 
27 | from .base import (
28 |     BaseDistribution,
29 |     BaseEntryPoint,
30 |     BaseEnvironment,
31 |     InfoPath,
32 |     Wheel,
33 | )
34 | 
35 | __all__ = ["NAME", "Distribution", "Environment"]
36 | 
37 | logger = logging.getLogger(__name__)
38 | 
39 | NAME = "pkg_resources"
40 | 
41 | 
42 | class EntryPoint(NamedTuple):
43 |     name: str
44 |     value: str
45 |     group: str
46 | 
47 | 
48 | class InMemoryMetadata:
49 |     """IMetadataProvider that reads metadata files from a dictionary.
50 | 
51 |     This also maps metadata decoding exceptions to our internal exception type.
52 |     """
53 | 
54 |     def __init__(self, metadata: Mapping[str, bytes], wheel_name: str) -> None:
55 |         self._metadata = metadata
56 |         self._wheel_name = wheel_name
57 | 
58 |     def has_metadata(self, name: str) -> bool:
59 |         return name in self._metadata
60 | 
61 |     def get_metadata(self, name: str) -> str:
62 |         try:
63 |             return self._metadata[name].decode()
64 |         except UnicodeDecodeError as e:
65 |             # Augment the default error with the origin of the file.
66 |             raise UnsupportedWheel(
67 |                 f"Error decoding metadata for {self._wheel_name}: {e} in {name} file"
68 |             )
69 | 
70 |     def get_metadata_lines(self, name: str) -> Iterable[str]:
71 |         return pkg_resources.yield_lines(self.get_metadata(name))
72 | 
73 |     def metadata_isdir(self, name: str) -> bool:
74 |         return False
75 | 
76 |     def metadata_listdir(self, name: str) -> List[str]:
77 |         return []
78 | 
79 |     def run_script(self, script_name: str, namespace: str) -> None:
80 |         pass
81 | 
82 | 
83 | class Distribution(BaseDistribution):
84 |     def __init__(self, dist: pkg_resources.Distribution) -> None:
85 |         self._dist = dist
86 |         # This is populated lazily, to avoid loading metadata for all possible
87 |         # distributions eagerly.
88 |         self.__extra_mapping: Optional[Mapping[NormalizedName, str]] = None
89 | 
90 |     @property
91 |     def _extra_mapping(self) -> Mapping[NormalizedName, str]:
92 |         if self.__extra_mapping is None:
93 |             self.__extra_mapping = {
94 |                 canonicalize_name(extra): extra for extra in self._dist.extras
95 |             }
96 | 
97 |         return self.__extra_mapping
98 | 
99 |     @classmethod
100 |     def from_directory(cls, directory: str) -> BaseDistribution:
101 |         dist_dir = directory.rstrip(os.sep)
102 | 
103 |         # Build a PathMetadata object, from path to metadata. :wink:
104 |         base_dir, dist_dir_name = os.path.split(dist_dir)
105 |         metadata = pkg_resources.PathMetadata(base_dir, dist_dir)
106 | 
107 |         # Determine the correct Distribution object type.
108 |         if dist_dir.endswith(".egg-info"):
109 |             dist_cls = pkg_resources.Distribution
110 |             dist_name = os.path.splitext(dist_dir_name)[0]
111 |         else:
112 |             assert dist_dir.endswith(".dist-info")
113 |             dist_cls = pkg_resources.DistInfoDistribution
114 |             dist_name = os.path.splitext(dist_dir_name)[0].split("-")[0]
115 | 
116 |         dist = dist_cls(base_dir, project_name=dist_name, metadata=metadata)
117 |         return cls(dist)
118 | 
119 |     @classmethod
120 |     def from_metadata_file_contents(
121 |         cls,
122 |         metadata_contents: bytes,
123 |         filename: str,
124 |         project_name: str,
125 |     ) -> BaseDistribution:
126 |         metadata_dict = {
127 |             "METADATA": metadata_contents,
128 |         }
129 |         dist = pkg_resources.DistInfoDistribution(
130 |             location=filename,
131 |             metadata=InMemoryMetadata(metadata_dict, filename),
132 |             project_name=project_name,
133 |         )
134 |         return cls(dist)
135 | 
136 |     @classmethod
137 |     def from_wheel(cls, wheel: Wheel, name: str) -> BaseDistribution:
138 |         try:
139 |             with wheel.as_zipfile() as zf:
140 |                 info_dir, _ = parse_wheel(zf, name)
141 |                 metadata_dict = {
142 |                     path.split("/", 1)[-1]: read_wheel_metadata_file(zf, path)
143 |                     for path in zf.namelist()
144 |                     if path.startswith(f"{info_dir}/")
145 |                 }
146 |         except zipfile.BadZipFile as e:
147 |             raise InvalidWheel(wheel.location, name) from e
148 |         except UnsupportedWheel as e:
149 |             raise UnsupportedWheel(f"{name} has an invalid wheel, {e}")
150 |         dist = pkg_resources.DistInfoDistribution(
151 |             location=wheel.location,
152 |             metadata=InMemoryMetadata(metadata_dict, wheel.location),
153 |             project_name=name,
154 |         )
155 |         return cls(dist)
156 | 
157 |     @property
158 |     def location(self) -> Optional[str]:
159 |         return self._dist.location
160 | 
161 |     @property
162 |     def installed_location(self) -> Optional[str]:
163 |         egg_link = egg_link_path_from_location(self.raw_name)
164 |         if egg_link:
165 |             location = egg_link
166 |         elif self.location:
167 |             location = self.location
168 |         else:
169 |             return None
170 |         return normalize_path(location)
171 | 
172 |     @property
173 |     def info_location(self) -> Optional[str]:
174 |         return self._dist.egg_info
175 | 
176 |     @property
177 |     def installed_by_distutils(self) -> bool:
178 |         # A distutils-installed distribution is provided by FileMetadata. This
179 |         # provider has a "path" attribute not present anywhere else. Not the
180 |         # best introspection logic, but pip has been doing this for a long time.
181 |         try:
182 |             return bool(self._dist._provider.path)
183 |         except AttributeError:
184 |             return False
185 | 
186 |     @property
187 |     def canonical_name(self) -> NormalizedName:
188 |         return canonicalize_name(self._dist.project_name)
189 | 
190 |     @property
191 |     def version(self) -> Version:
192 |         return parse_version(self._dist.version)
193 | 
194 |     @property
195 |     def raw_version(self) -> str:
196 |         return self._dist.version
197 | 
198 |     def is_file(self, path: InfoPath) -> bool:
199 |         return self._dist.has_metadata(str(path))
200 | 
201 |     def iter_distutils_script_names(self) -> Iterator[str]:
202 |         yield from self._dist.metadata_listdir("scripts")
203 | 
204 |     def read_text(self, path: InfoPath) -> str:
205 |         name = str(path)
206 |         if not self._dist.has_metadata(name):
207 |             raise FileNotFoundError(name)
208 |         content = self._dist.get_metadata(name)
209 |         if content is None:
210 |             raise NoneMetadataError(self, name)
211 |         return content
212 | 
213 |     def iter_entry_points(self) -> Iterable[BaseEntryPoint]:
214 |         for group, entries in self._dist.get_entry_map().items():
215 |             for name, entry_point in entries.items():
216 |                 name, _, value = str(entry_point).partition("=")
217 |                 yield EntryPoint(name=name.strip(), value=value.strip(), group=group)
218 | 
219 |     def _metadata_impl(self) -> email.message.Message:
220 |         """
221 |         :raises NoneMetadataError: if the distribution reports `has_metadata()`
222 |             True but `get_metadata()` returns None.
223 |         """
224 |         if isinstance(self._dist, pkg_resources.DistInfoDistribution):
225 |             metadata_name = "METADATA"
226 |         else:
227 |             metadata_name = "PKG-INFO"
228 |         try:
229 |             metadata = self.read_text(metadata_name)
230 |         except FileNotFoundError:
231 |             if self.location:
232 |                 displaying_path = display_path(self.location)
233 |             else:
234 |                 displaying_path = repr(self.location)
235 |             logger.warning("No metadata found in %s", displaying_path)
236 |             metadata = ""
237 |         feed_parser = email.parser.FeedParser()
238 |         feed_parser.feed(metadata)
239 |         return feed_parser.close()
240 | 
241 |     def iter_dependencies(self, extras: Collection[str] = ()) -> Iterable[Requirement]:
242 |         if extras:
243 |             relevant_extras = set(self._extra_mapping) & set(
244 |                 map(canonicalize_name, extras)
245 |             )
246 |             extras = [self._extra_mapping[extra] for extra in relevant_extras]
247 |         return self._dist.requires(extras)
248 | 
249 |     def iter_provided_extras(self) -> Iterable[NormalizedName]:
250 |         return self._extra_mapping.keys()
251 | 
252 | 
253 | class Environment(BaseEnvironment):
254 |     def __init__(self, ws: pkg_resources.WorkingSet) -> None:
255 |         self._ws = ws
256 | 
257 |     @classmethod
258 |     def default(cls) -> BaseEnvironment:
259 |         return cls(pkg_resources.working_set)
260 | 
261 |     @classmethod
262 |     def from_paths(cls, paths: Optional[List[str]]) -> BaseEnvironment:
263 |         return cls(pkg_resources.WorkingSet(paths))
264 | 
265 |     def _iter_distributions(self) -> Iterator[BaseDistribution]:
266 |         for dist in self._ws:
267 |             yield Distribution(dist)
268 | 
269 |     def _search_distribution(self, name: str) -> Optional[BaseDistribution]:
270 |         """Find a distribution matching the ``name`` in the environment.
271 | 
272 |         This searches from *all* distributions available in the environment, to
273 |         match the behavior of ``pkg_resources.get_distribution()``.
274 |         """
275 |         canonical_name = canonicalize_name(name)
276 |         for dist in self.iter_all_distributions():
277 |             if dist.canonical_name == canonical_name:
278 |                 return dist
279 |         return None
280 | 
281 |     def get_distribution(self, name: str) -> Optional[BaseDistribution]:
282 |         # Search the distribution by looking through the working set.
283 |         dist = self._search_distribution(name)
284 |         if dist:
285 |             return dist
286 | 
287 |         # If distribution could not be found, call working_set.require to
288 |         # update the working set, and try to find the distribution again.
289 |         # This might happen for e.g. when you install a package twice, once
290 |         # using setup.py develop and again using setup.py install. Now when
291 |         # running pip uninstall twice, the package gets removed from the
292 |         # working set in the first uninstall, so we have to populate the
293 |         # working set again so that pip knows about it and the packages gets
294 |         # picked up and is successfully uninstalled the second time too.
295 |         try:
296 |             # We didn't pass in any version specifiers, so this can never
297 |             # raise pkg_resources.VersionConflict.
298 |             self._ws.require(name)
299 |         except pkg_resources.DistributionNotFound:
300 |             return None
301 |         return self._search_distribution(name)
```

.venv/lib/python3.13/site-packages/pip/_internal/commands/__init__.py
```
1 | """
2 | Package containing all pip commands
3 | """
4 | 
5 | import importlib
6 | from collections import namedtuple
7 | from typing import Any, Dict, Optional
8 | 
9 | from pip._internal.cli.base_command import Command
10 | 
11 | CommandInfo = namedtuple("CommandInfo", "module_path, class_name, summary")
12 | 
13 | # This dictionary does a bunch of heavy lifting for help output:
14 | # - Enables avoiding additional (costly) imports for presenting `--help`.
15 | # - The ordering matters for help display.
16 | #
17 | # Even though the module path starts with the same "pip._internal.commands"
18 | # prefix, the full path makes testing easier (specifically when modifying
19 | # `commands_dict` in test setup / teardown).
20 | commands_dict: Dict[str, CommandInfo] = {
21 |     "install": CommandInfo(
22 |         "pip._internal.commands.install",
23 |         "InstallCommand",
24 |         "Install packages.",
25 |     ),
26 |     "lock": CommandInfo(
27 |         "pip._internal.commands.lock",
28 |         "LockCommand",
29 |         "Generate a lock file.",
30 |     ),
31 |     "download": CommandInfo(
32 |         "pip._internal.commands.download",
33 |         "DownloadCommand",
34 |         "Download packages.",
35 |     ),
36 |     "uninstall": CommandInfo(
37 |         "pip._internal.commands.uninstall",
38 |         "UninstallCommand",
39 |         "Uninstall packages.",
40 |     ),
41 |     "freeze": CommandInfo(
42 |         "pip._internal.commands.freeze",
43 |         "FreezeCommand",
44 |         "Output installed packages in requirements format.",
45 |     ),
46 |     "inspect": CommandInfo(
47 |         "pip._internal.commands.inspect",
48 |         "InspectCommand",
49 |         "Inspect the python environment.",
50 |     ),
51 |     "list": CommandInfo(
52 |         "pip._internal.commands.list",
53 |         "ListCommand",
54 |         "List installed packages.",
55 |     ),
56 |     "show": CommandInfo(
57 |         "pip._internal.commands.show",
58 |         "ShowCommand",
59 |         "Show information about installed packages.",
60 |     ),
61 |     "check": CommandInfo(
62 |         "pip._internal.commands.check",
63 |         "CheckCommand",
64 |         "Verify installed packages have compatible dependencies.",
65 |     ),
66 |     "config": CommandInfo(
67 |         "pip._internal.commands.configuration",
68 |         "ConfigurationCommand",
69 |         "Manage local and global configuration.",
70 |     ),
71 |     "search": CommandInfo(
72 |         "pip._internal.commands.search",
73 |         "SearchCommand",
74 |         "Search PyPI for packages.",
75 |     ),
76 |     "cache": CommandInfo(
77 |         "pip._internal.commands.cache",
78 |         "CacheCommand",
79 |         "Inspect and manage pip's wheel cache.",
80 |     ),
81 |     "index": CommandInfo(
82 |         "pip._internal.commands.index",
83 |         "IndexCommand",
84 |         "Inspect information available from package indexes.",
85 |     ),
86 |     "wheel": CommandInfo(
87 |         "pip._internal.commands.wheel",
88 |         "WheelCommand",
89 |         "Build wheels from your requirements.",
90 |     ),
91 |     "hash": CommandInfo(
92 |         "pip._internal.commands.hash",
93 |         "HashCommand",
94 |         "Compute hashes of package archives.",
95 |     ),
96 |     "completion": CommandInfo(
97 |         "pip._internal.commands.completion",
98 |         "CompletionCommand",
99 |         "A helper command used for command completion.",
100 |     ),
101 |     "debug": CommandInfo(
102 |         "pip._internal.commands.debug",
103 |         "DebugCommand",
104 |         "Show information useful for debugging.",
105 |     ),
106 |     "help": CommandInfo(
107 |         "pip._internal.commands.help",
108 |         "HelpCommand",
109 |         "Show help for commands.",
110 |     ),
111 | }
112 | 
113 | 
114 | def create_command(name: str, **kwargs: Any) -> Command:
115 |     """
116 |     Create an instance of the Command class with the given name.
117 |     """
118 |     module_path, class_name, summary = commands_dict[name]
119 |     module = importlib.import_module(module_path)
120 |     command_class = getattr(module, class_name)
121 |     command = command_class(name=name, summary=summary, **kwargs)
122 | 
123 |     return command
124 | 
125 | 
126 | def get_similar_commands(name: str) -> Optional[str]:
127 |     """Command name auto-correct."""
128 |     from difflib import get_close_matches
129 | 
130 |     name = name.lower()
131 | 
132 |     close_commands = get_close_matches(name, commands_dict.keys())
133 | 
134 |     if close_commands:
135 |         return close_commands[0]
136 |     else:
137 |         return None
```

.venv/lib/python3.13/site-packages/pip/_internal/commands/cache.py
```
1 | import os
2 | import textwrap
3 | from optparse import Values
4 | from typing import Any, List
5 | 
6 | from pip._internal.cli.base_command import Command
7 | from pip._internal.cli.status_codes import ERROR, SUCCESS
8 | from pip._internal.exceptions import CommandError, PipError
9 | from pip._internal.utils import filesystem
10 | from pip._internal.utils.logging import getLogger
11 | from pip._internal.utils.misc import format_size
12 | 
13 | logger = getLogger(__name__)
14 | 
15 | 
16 | class CacheCommand(Command):
17 |     """
18 |     Inspect and manage pip's wheel cache.
19 | 
20 |     Subcommands:
21 | 
22 |     - dir: Show the cache directory.
23 |     - info: Show information about the cache.
24 |     - list: List filenames of packages stored in the cache.
25 |     - remove: Remove one or more package from the cache.
26 |     - purge: Remove all items from the cache.
27 | 
28 |     ``<pattern>`` can be a glob expression or a package name.
29 |     """
30 | 
31 |     ignore_require_venv = True
32 |     usage = """
33 |         %prog dir
34 |         %prog info
35 |         %prog list [<pattern>] [--format=[human, abspath]]
36 |         %prog remove <pattern>
37 |         %prog purge
38 |     """
39 | 
40 |     def add_options(self) -> None:
41 |         self.cmd_opts.add_option(
42 |             "--format",
43 |             action="store",
44 |             dest="list_format",
45 |             default="human",
46 |             choices=("human", "abspath"),
47 |             help="Select the output format among: human (default) or abspath",
48 |         )
49 | 
50 |         self.parser.insert_option_group(0, self.cmd_opts)
51 | 
52 |     def run(self, options: Values, args: List[str]) -> int:
53 |         handlers = {
54 |             "dir": self.get_cache_dir,
55 |             "info": self.get_cache_info,
56 |             "list": self.list_cache_items,
57 |             "remove": self.remove_cache_items,
58 |             "purge": self.purge_cache,
59 |         }
60 | 
61 |         if not options.cache_dir:
62 |             logger.error("pip cache commands can not function since cache is disabled.")
63 |             return ERROR
64 | 
65 |         # Determine action
66 |         if not args or args[0] not in handlers:
67 |             logger.error(
68 |                 "Need an action (%s) to perform.",
69 |                 ", ".join(sorted(handlers)),
70 |             )
71 |             return ERROR
72 | 
73 |         action = args[0]
74 | 
75 |         # Error handling happens here, not in the action-handlers.
76 |         try:
77 |             handlers[action](options, args[1:])
78 |         except PipError as e:
79 |             logger.error(e.args[0])
80 |             return ERROR
81 | 
82 |         return SUCCESS
83 | 
84 |     def get_cache_dir(self, options: Values, args: List[Any]) -> None:
85 |         if args:
86 |             raise CommandError("Too many arguments")
87 | 
88 |         logger.info(options.cache_dir)
89 | 
90 |     def get_cache_info(self, options: Values, args: List[Any]) -> None:
91 |         if args:
92 |             raise CommandError("Too many arguments")
93 | 
94 |         num_http_files = len(self._find_http_files(options))
95 |         num_packages = len(self._find_wheels(options, "*"))
96 | 
97 |         http_cache_location = self._cache_dir(options, "http-v2")
98 |         old_http_cache_location = self._cache_dir(options, "http")
99 |         wheels_cache_location = self._cache_dir(options, "wheels")
100 |         http_cache_size = filesystem.format_size(
101 |             filesystem.directory_size(http_cache_location)
102 |             + filesystem.directory_size(old_http_cache_location)
103 |         )
104 |         wheels_cache_size = filesystem.format_directory_size(wheels_cache_location)
105 | 
106 |         message = (
107 |             textwrap.dedent(
108 |                 """
109 |                     Package index page cache location (pip v23.3+): {http_cache_location}
110 |                     Package index page cache location (older pips): {old_http_cache_location}
111 |                     Package index page cache size: {http_cache_size}
112 |                     Number of HTTP files: {num_http_files}
113 |                     Locally built wheels location: {wheels_cache_location}
114 |                     Locally built wheels size: {wheels_cache_size}
115 |                     Number of locally built wheels: {package_count}
116 |                 """  # noqa: E501
117 |             )
118 |             .format(
119 |                 http_cache_location=http_cache_location,
120 |                 old_http_cache_location=old_http_cache_location,
121 |                 http_cache_size=http_cache_size,
122 |                 num_http_files=num_http_files,
123 |                 wheels_cache_location=wheels_cache_location,
124 |                 package_count=num_packages,
125 |                 wheels_cache_size=wheels_cache_size,
126 |             )
127 |             .strip()
128 |         )
129 | 
130 |         logger.info(message)
131 | 
132 |     def list_cache_items(self, options: Values, args: List[Any]) -> None:
133 |         if len(args) > 1:
134 |             raise CommandError("Too many arguments")
135 | 
136 |         if args:
137 |             pattern = args[0]
138 |         else:
139 |             pattern = "*"
140 | 
141 |         files = self._find_wheels(options, pattern)
142 |         if options.list_format == "human":
143 |             self.format_for_human(files)
144 |         else:
145 |             self.format_for_abspath(files)
146 | 
147 |     def format_for_human(self, files: List[str]) -> None:
148 |         if not files:
149 |             logger.info("No locally built wheels cached.")
150 |             return
151 | 
152 |         results = []
153 |         for filename in files:
154 |             wheel = os.path.basename(filename)
155 |             size = filesystem.format_file_size(filename)
156 |             results.append(f" - {wheel} ({size})")
157 |         logger.info("Cache contents:\n")
158 |         logger.info("\n".join(sorted(results)))
159 | 
160 |     def format_for_abspath(self, files: List[str]) -> None:
161 |         if files:
162 |             logger.info("\n".join(sorted(files)))
163 | 
164 |     def remove_cache_items(self, options: Values, args: List[Any]) -> None:
165 |         if len(args) > 1:
166 |             raise CommandError("Too many arguments")
167 | 
168 |         if not args:
169 |             raise CommandError("Please provide a pattern")
170 | 
171 |         files = self._find_wheels(options, args[0])
172 | 
173 |         no_matching_msg = "No matching packages"
174 |         if args[0] == "*":
175 |             # Only fetch http files if no specific pattern given
176 |             files += self._find_http_files(options)
177 |         else:
178 |             # Add the pattern to the log message
179 |             no_matching_msg += f' for pattern "{args[0]}"'
180 | 
181 |         if not files:
182 |             logger.warning(no_matching_msg)
183 | 
184 |         bytes_removed = 0
185 |         for filename in files:
186 |             bytes_removed += os.stat(filename).st_size
187 |             os.unlink(filename)
188 |             logger.verbose("Removed %s", filename)
189 |         logger.info("Files removed: %s (%s)", len(files), format_size(bytes_removed))
190 | 
191 |     def purge_cache(self, options: Values, args: List[Any]) -> None:
192 |         if args:
193 |             raise CommandError("Too many arguments")
194 | 
195 |         return self.remove_cache_items(options, ["*"])
196 | 
197 |     def _cache_dir(self, options: Values, subdir: str) -> str:
198 |         return os.path.join(options.cache_dir, subdir)
199 | 
200 |     def _find_http_files(self, options: Values) -> List[str]:
201 |         old_http_dir = self._cache_dir(options, "http")
202 |         new_http_dir = self._cache_dir(options, "http-v2")
203 |         return filesystem.find_files(old_http_dir, "*") + filesystem.find_files(
204 |             new_http_dir, "*"
205 |         )
206 | 
207 |     def _find_wheels(self, options: Values, pattern: str) -> List[str]:
208 |         wheel_dir = self._cache_dir(options, "wheels")
209 | 
210 |         # The wheel filename format, as specified in PEP 427, is:
211 |         #     {distribution}-{version}(-{build})?-{python}-{abi}-{platform}.whl
212 |         #
213 |         # Additionally, non-alphanumeric values in the distribution are
214 |         # normalized to underscores (_), meaning hyphens can never occur
215 |         # before `-{version}`.
216 |         #
217 |         # Given that information:
218 |         # - If the pattern we're given contains a hyphen (-), the user is
219 |         #   providing at least the version. Thus, we can just append `*.whl`
220 |         #   to match the rest of it.
221 |         # - If the pattern we're given doesn't contain a hyphen (-), the
222 |         #   user is only providing the name. Thus, we append `-*.whl` to
223 |         #   match the hyphen before the version, followed by anything else.
224 |         #
225 |         # PEP 427: https://www.python.org/dev/peps/pep-0427/
226 |         pattern = pattern + ("*.whl" if "-" in pattern else "-*.whl")
227 | 
228 |         return filesystem.find_files(wheel_dir, pattern)
```

.venv/lib/python3.13/site-packages/pip/_internal/commands/check.py
```
1 | import logging
2 | from optparse import Values
3 | from typing import List
4 | 
5 | from pip._internal.cli.base_command import Command
6 | from pip._internal.cli.status_codes import ERROR, SUCCESS
7 | from pip._internal.metadata import get_default_environment
8 | from pip._internal.operations.check import (
9 |     check_package_set,
10 |     check_unsupported,
11 |     create_package_set_from_installed,
12 | )
13 | from pip._internal.utils.compatibility_tags import get_supported
14 | from pip._internal.utils.misc import write_output
15 | 
16 | logger = logging.getLogger(__name__)
17 | 
18 | 
19 | class CheckCommand(Command):
20 |     """Verify installed packages have compatible dependencies."""
21 | 
22 |     ignore_require_venv = True
23 |     usage = """
24 |       %prog [options]"""
25 | 
26 |     def run(self, options: Values, args: List[str]) -> int:
27 |         package_set, parsing_probs = create_package_set_from_installed()
28 |         missing, conflicting = check_package_set(package_set)
29 |         unsupported = list(
30 |             check_unsupported(
31 |                 get_default_environment().iter_installed_distributions(),
32 |                 get_supported(),
33 |             )
34 |         )
35 | 
36 |         for project_name in missing:
37 |             version = package_set[project_name].version
38 |             for dependency in missing[project_name]:
39 |                 write_output(
40 |                     "%s %s requires %s, which is not installed.",
41 |                     project_name,
42 |                     version,
43 |                     dependency[0],
44 |                 )
45 | 
46 |         for project_name in conflicting:
47 |             version = package_set[project_name].version
48 |             for dep_name, dep_version, req in conflicting[project_name]:
49 |                 write_output(
50 |                     "%s %s has requirement %s, but you have %s %s.",
51 |                     project_name,
52 |                     version,
53 |                     req,
54 |                     dep_name,
55 |                     dep_version,
56 |                 )
57 |         for package in unsupported:
58 |             write_output(
59 |                 "%s %s is not supported on this platform",
60 |                 package.raw_name,
61 |                 package.version,
62 |             )
63 |         if missing or conflicting or parsing_probs or unsupported:
64 |             return ERROR
65 |         else:
66 |             write_output("No broken requirements found.")
67 |             return SUCCESS
```

.venv/lib/python3.13/site-packages/pip/_internal/commands/completion.py
```
1 | import sys
2 | import textwrap
3 | from optparse import Values
4 | from typing import List
5 | 
6 | from pip._internal.cli.base_command import Command
7 | from pip._internal.cli.status_codes import SUCCESS
8 | from pip._internal.utils.misc import get_prog
9 | 
10 | BASE_COMPLETION = """
11 | # pip {shell} completion start{script}# pip {shell} completion end
12 | """
13 | 
14 | COMPLETION_SCRIPTS = {
15 |     "bash": """
16 |         _pip_completion()
17 |         {{
18 |             COMPREPLY=( $( COMP_WORDS="${{COMP_WORDS[*]}}" \\
19 |                            COMP_CWORD=$COMP_CWORD \\
20 |                            PIP_AUTO_COMPLETE=1 $1 2>/dev/null ) )
21 |         }}
22 |         complete -o default -F _pip_completion {prog}
23 |     """,
24 |     "zsh": """
25 |         #compdef -P pip[0-9.]#
26 |         __pip() {{
27 |           compadd $( COMP_WORDS="$words[*]" \\
28 |                      COMP_CWORD=$((CURRENT-1)) \\
29 |                      PIP_AUTO_COMPLETE=1 $words[1] 2>/dev/null )
30 |         }}
31 |         if [[ $zsh_eval_context[-1] == loadautofunc ]]; then
32 |           # autoload from fpath, call function directly
33 |           __pip "$@"
34 |         else
35 |           # eval/source/. command, register function for later
36 |           compdef __pip -P 'pip[0-9.]#'
37 |         fi
38 |     """,
39 |     "fish": """
40 |         function __fish_complete_pip
41 |             set -lx COMP_WORDS \\
42 |                 (commandline --current-process --tokenize --cut-at-cursor) \\
43 |                 (commandline --current-token --cut-at-cursor)
44 |             set -lx COMP_CWORD (math (count $COMP_WORDS) - 1)
45 |             set -lx PIP_AUTO_COMPLETE 1
46 |             set -l completions
47 |             if string match -q '2.*' $version
48 |                 set completions (eval $COMP_WORDS[1])
49 |             else
50 |                 set completions ($COMP_WORDS[1])
51 |             end
52 |             string split \\  -- $completions
53 |         end
54 |         complete -fa "(__fish_complete_pip)" -c {prog}
55 |     """,
56 |     "powershell": """
57 |         if ((Test-Path Function:\\TabExpansion) -and -not `
58 |             (Test-Path Function:\\_pip_completeBackup)) {{
59 |             Rename-Item Function:\\TabExpansion _pip_completeBackup
60 |         }}
61 |         function TabExpansion($line, $lastWord) {{
62 |             $lastBlock = [regex]::Split($line, '[|;]')[-1].TrimStart()
63 |             if ($lastBlock.StartsWith("{prog} ")) {{
64 |                 $Env:COMP_WORDS=$lastBlock
65 |                 $Env:COMP_CWORD=$lastBlock.Split().Length - 1
66 |                 $Env:PIP_AUTO_COMPLETE=1
67 |                 (& {prog}).Split()
68 |                 Remove-Item Env:COMP_WORDS
69 |                 Remove-Item Env:COMP_CWORD
70 |                 Remove-Item Env:PIP_AUTO_COMPLETE
71 |             }}
72 |             elseif (Test-Path Function:\\_pip_completeBackup) {{
73 |                 # Fall back on existing tab expansion
74 |                 _pip_completeBackup $line $lastWord
75 |             }}
76 |         }}
77 |     """,
78 | }
79 | 
80 | 
81 | class CompletionCommand(Command):
82 |     """A helper command to be used for command completion."""
83 | 
84 |     ignore_require_venv = True
85 | 
86 |     def add_options(self) -> None:
87 |         self.cmd_opts.add_option(
88 |             "--bash",
89 |             "-b",
90 |             action="store_const",
91 |             const="bash",
92 |             dest="shell",
93 |             help="Emit completion code for bash",
94 |         )
95 |         self.cmd_opts.add_option(
96 |             "--zsh",
97 |             "-z",
98 |             action="store_const",
99 |             const="zsh",
100 |             dest="shell",
101 |             help="Emit completion code for zsh",
102 |         )
103 |         self.cmd_opts.add_option(
104 |             "--fish",
105 |             "-f",
106 |             action="store_const",
107 |             const="fish",
108 |             dest="shell",
109 |             help="Emit completion code for fish",
110 |         )
111 |         self.cmd_opts.add_option(
112 |             "--powershell",
113 |             "-p",
114 |             action="store_const",
115 |             const="powershell",
116 |             dest="shell",
117 |             help="Emit completion code for powershell",
118 |         )
119 | 
120 |         self.parser.insert_option_group(0, self.cmd_opts)
121 | 
122 |     def run(self, options: Values, args: List[str]) -> int:
123 |         """Prints the completion code of the given shell"""
124 |         shells = COMPLETION_SCRIPTS.keys()
125 |         shell_options = ["--" + shell for shell in sorted(shells)]
126 |         if options.shell in shells:
127 |             script = textwrap.dedent(
128 |                 COMPLETION_SCRIPTS.get(options.shell, "").format(prog=get_prog())
129 |             )
130 |             print(BASE_COMPLETION.format(script=script, shell=options.shell))
131 |             return SUCCESS
132 |         else:
133 |             sys.stderr.write(
134 |                 "ERROR: You must pass {}\n".format(" or ".join(shell_options))
135 |             )
136 |             return SUCCESS
```

.venv/lib/python3.13/site-packages/pip/_internal/commands/configuration.py
```
1 | import logging
2 | import os
3 | import subprocess
4 | from optparse import Values
5 | from typing import Any, List, Optional
6 | 
7 | from pip._internal.cli.base_command import Command
8 | from pip._internal.cli.status_codes import ERROR, SUCCESS
9 | from pip._internal.configuration import (
10 |     Configuration,
11 |     Kind,
12 |     get_configuration_files,
13 |     kinds,
14 | )
15 | from pip._internal.exceptions import PipError
16 | from pip._internal.utils.logging import indent_log
17 | from pip._internal.utils.misc import get_prog, write_output
18 | 
19 | logger = logging.getLogger(__name__)
20 | 
21 | 
22 | class ConfigurationCommand(Command):
23 |     """
24 |     Manage local and global configuration.
25 | 
26 |     Subcommands:
27 | 
28 |     - list: List the active configuration (or from the file specified)
29 |     - edit: Edit the configuration file in an editor
30 |     - get: Get the value associated with command.option
31 |     - set: Set the command.option=value
32 |     - unset: Unset the value associated with command.option
33 |     - debug: List the configuration files and values defined under them
34 | 
35 |     Configuration keys should be dot separated command and option name,
36 |     with the special prefix "global" affecting any command. For example,
37 |     "pip config set global.index-url https://example.org/" would configure
38 |     the index url for all commands, but "pip config set download.timeout 10"
39 |     would configure a 10 second timeout only for "pip download" commands.
40 | 
41 |     If none of --user, --global and --site are passed, a virtual
42 |     environment configuration file is used if one is active and the file
43 |     exists. Otherwise, all modifications happen to the user file by
44 |     default.
45 |     """
46 | 
47 |     ignore_require_venv = True
48 |     usage = """
49 |         %prog [<file-option>] list
50 |         %prog [<file-option>] [--editor <editor-path>] edit
51 | 
52 |         %prog [<file-option>] get command.option
53 |         %prog [<file-option>] set command.option value
54 |         %prog [<file-option>] unset command.option
55 |         %prog [<file-option>] debug
56 |     """
57 | 
58 |     def add_options(self) -> None:
59 |         self.cmd_opts.add_option(
60 |             "--editor",
61 |             dest="editor",
62 |             action="store",
63 |             default=None,
64 |             help=(
65 |                 "Editor to use to edit the file. Uses VISUAL or EDITOR "
66 |                 "environment variables if not provided."
67 |             ),
68 |         )
69 | 
70 |         self.cmd_opts.add_option(
71 |             "--global",
72 |             dest="global_file",
73 |             action="store_true",
74 |             default=False,
75 |             help="Use the system-wide configuration file only",
76 |         )
77 | 
78 |         self.cmd_opts.add_option(
79 |             "--user",
80 |             dest="user_file",
81 |             action="store_true",
82 |             default=False,
83 |             help="Use the user configuration file only",
84 |         )
85 | 
86 |         self.cmd_opts.add_option(
87 |             "--site",
88 |             dest="site_file",
89 |             action="store_true",
90 |             default=False,
91 |             help="Use the current environment configuration file only",
92 |         )
93 | 
94 |         self.parser.insert_option_group(0, self.cmd_opts)
95 | 
96 |     def run(self, options: Values, args: List[str]) -> int:
97 |         handlers = {
98 |             "list": self.list_values,
99 |             "edit": self.open_in_editor,
100 |             "get": self.get_name,
101 |             "set": self.set_name_value,
102 |             "unset": self.unset_name,
103 |             "debug": self.list_config_values,
104 |         }
105 | 
106 |         # Determine action
107 |         if not args or args[0] not in handlers:
108 |             logger.error(
109 |                 "Need an action (%s) to perform.",
110 |                 ", ".join(sorted(handlers)),
111 |             )
112 |             return ERROR
113 | 
114 |         action = args[0]
115 | 
116 |         # Determine which configuration files are to be loaded
117 |         #    Depends on whether the command is modifying.
118 |         try:
119 |             load_only = self._determine_file(
120 |                 options, need_value=(action in ["get", "set", "unset", "edit"])
121 |             )
122 |         except PipError as e:
123 |             logger.error(e.args[0])
124 |             return ERROR
125 | 
126 |         # Load a new configuration
127 |         self.configuration = Configuration(
128 |             isolated=options.isolated_mode, load_only=load_only
129 |         )
130 |         self.configuration.load()
131 | 
132 |         # Error handling happens here, not in the action-handlers.
133 |         try:
134 |             handlers[action](options, args[1:])
135 |         except PipError as e:
136 |             logger.error(e.args[0])
137 |             return ERROR
138 | 
139 |         return SUCCESS
140 | 
141 |     def _determine_file(self, options: Values, need_value: bool) -> Optional[Kind]:
142 |         file_options = [
143 |             key
144 |             for key, value in (
145 |                 (kinds.USER, options.user_file),
146 |                 (kinds.GLOBAL, options.global_file),
147 |                 (kinds.SITE, options.site_file),
148 |             )
149 |             if value
150 |         ]
151 | 
152 |         if not file_options:
153 |             if not need_value:
154 |                 return None
155 |             # Default to user, unless there's a site file.
156 |             elif any(
157 |                 os.path.exists(site_config_file)
158 |                 for site_config_file in get_configuration_files()[kinds.SITE]
159 |             ):
160 |                 return kinds.SITE
161 |             else:
162 |                 return kinds.USER
163 |         elif len(file_options) == 1:
164 |             return file_options[0]
165 | 
166 |         raise PipError(
167 |             "Need exactly one file to operate upon "
168 |             "(--user, --site, --global) to perform."
169 |         )
170 | 
171 |     def list_values(self, options: Values, args: List[str]) -> None:
172 |         self._get_n_args(args, "list", n=0)
173 | 
174 |         for key, value in sorted(self.configuration.items()):
175 |             write_output("%s=%r", key, value)
176 | 
177 |     def get_name(self, options: Values, args: List[str]) -> None:
178 |         key = self._get_n_args(args, "get [name]", n=1)
179 |         value = self.configuration.get_value(key)
180 | 
181 |         write_output("%s", value)
182 | 
183 |     def set_name_value(self, options: Values, args: List[str]) -> None:
184 |         key, value = self._get_n_args(args, "set [name] [value]", n=2)
185 |         self.configuration.set_value(key, value)
186 | 
187 |         self._save_configuration()
188 | 
189 |     def unset_name(self, options: Values, args: List[str]) -> None:
190 |         key = self._get_n_args(args, "unset [name]", n=1)
191 |         self.configuration.unset_value(key)
192 | 
193 |         self._save_configuration()
194 | 
195 |     def list_config_values(self, options: Values, args: List[str]) -> None:
196 |         """List config key-value pairs across different config files"""
197 |         self._get_n_args(args, "debug", n=0)
198 | 
199 |         self.print_env_var_values()
200 |         # Iterate over config files and print if they exist, and the
201 |         # key-value pairs present in them if they do
202 |         for variant, files in sorted(self.configuration.iter_config_files()):
203 |             write_output("%s:", variant)
204 |             for fname in files:
205 |                 with indent_log():
206 |                     file_exists = os.path.exists(fname)
207 |                     write_output("%s, exists: %r", fname, file_exists)
208 |                     if file_exists:
209 |                         self.print_config_file_values(variant)
210 | 
211 |     def print_config_file_values(self, variant: Kind) -> None:
212 |         """Get key-value pairs from the file of a variant"""
213 |         for name, value in self.configuration.get_values_in_config(variant).items():
214 |             with indent_log():
215 |                 write_output("%s: %s", name, value)
216 | 
217 |     def print_env_var_values(self) -> None:
218 |         """Get key-values pairs present as environment variables"""
219 |         write_output("%s:", "env_var")
220 |         with indent_log():
221 |             for key, value in sorted(self.configuration.get_environ_vars()):
222 |                 env_var = f"PIP_{key.upper()}"
223 |                 write_output("%s=%r", env_var, value)
224 | 
225 |     def open_in_editor(self, options: Values, args: List[str]) -> None:
226 |         editor = self._determine_editor(options)
227 | 
228 |         fname = self.configuration.get_file_to_edit()
229 |         if fname is None:
230 |             raise PipError("Could not determine appropriate file.")
231 |         elif '"' in fname:
232 |             # This shouldn't happen, unless we see a username like that.
233 |             # If that happens, we'd appreciate a pull request fixing this.
234 |             raise PipError(
235 |                 f'Can not open an editor for a file name containing "\n{fname}'
236 |             )
237 | 
238 |         try:
239 |             subprocess.check_call(f'{editor} "{fname}"', shell=True)
240 |         except FileNotFoundError as e:
241 |             if not e.filename:
242 |                 e.filename = editor
243 |             raise
244 |         except subprocess.CalledProcessError as e:
245 |             raise PipError(f"Editor Subprocess exited with exit code {e.returncode}")
246 | 
247 |     def _get_n_args(self, args: List[str], example: str, n: int) -> Any:
248 |         """Helper to make sure the command got the right number of arguments"""
249 |         if len(args) != n:
250 |             msg = (
251 |                 f"Got unexpected number of arguments, expected {n}. "
252 |                 f'(example: "{get_prog()} config {example}")'
253 |             )
254 |             raise PipError(msg)
255 | 
256 |         if n == 1:
257 |             return args[0]
258 |         else:
259 |             return args
260 | 
261 |     def _save_configuration(self) -> None:
262 |         # We successfully ran a modifying command. Need to save the
263 |         # configuration.
264 |         try:
265 |             self.configuration.save()
266 |         except Exception:
267 |             logger.exception(
268 |                 "Unable to save configuration. Please report this as a bug."
269 |             )
270 |             raise PipError("Internal Error.")
271 | 
272 |     def _determine_editor(self, options: Values) -> str:
273 |         if options.editor is not None:
274 |             return options.editor
275 |         elif "VISUAL" in os.environ:
276 |             return os.environ["VISUAL"]
277 |         elif "EDITOR" in os.environ:
278 |             return os.environ["EDITOR"]
279 |         else:
280 |             raise PipError("Could not determine editor to use.")
```

.venv/lib/python3.13/site-packages/pip/_internal/commands/debug.py
```
1 | import locale
2 | import logging
3 | import os
4 | import sys
5 | from optparse import Values
6 | from types import ModuleType
7 | from typing import Any, Dict, List, Optional
8 | 
9 | import pip._vendor
10 | from pip._vendor.certifi import where
11 | from pip._vendor.packaging.version import parse as parse_version
12 | 
13 | from pip._internal.cli import cmdoptions
14 | from pip._internal.cli.base_command import Command
15 | from pip._internal.cli.cmdoptions import make_target_python
16 | from pip._internal.cli.status_codes import SUCCESS
17 | from pip._internal.configuration import Configuration
18 | from pip._internal.metadata import get_environment
19 | from pip._internal.utils.compat import open_text_resource
20 | from pip._internal.utils.logging import indent_log
21 | from pip._internal.utils.misc import get_pip_version
22 | 
23 | logger = logging.getLogger(__name__)
24 | 
25 | 
26 | def show_value(name: str, value: Any) -> None:
27 |     logger.info("%s: %s", name, value)
28 | 
29 | 
30 | def show_sys_implementation() -> None:
31 |     logger.info("sys.implementation:")
32 |     implementation_name = sys.implementation.name
33 |     with indent_log():
34 |         show_value("name", implementation_name)
35 | 
36 | 
37 | def create_vendor_txt_map() -> Dict[str, str]:
38 |     with open_text_resource("pip._vendor", "vendor.txt") as f:
39 |         # Purge non version specifying lines.
40 |         # Also, remove any space prefix or suffixes (including comments).
41 |         lines = [
42 |             line.strip().split(" ", 1)[0] for line in f.readlines() if "==" in line
43 |         ]
44 | 
45 |     # Transform into "module" -> version dict.
46 |     return dict(line.split("==", 1) for line in lines)
47 | 
48 | 
49 | def get_module_from_module_name(module_name: str) -> Optional[ModuleType]:
50 |     # Module name can be uppercase in vendor.txt for some reason...
51 |     module_name = module_name.lower().replace("-", "_")
52 |     # PATCH: setuptools is actually only pkg_resources.
53 |     if module_name == "setuptools":
54 |         module_name = "pkg_resources"
55 | 
56 |     try:
57 |         __import__(f"pip._vendor.{module_name}", globals(), locals(), level=0)
58 |         return getattr(pip._vendor, module_name)
59 |     except ImportError:
60 |         # We allow 'truststore' to fail to import due
61 |         # to being unavailable on Python 3.9 and earlier.
62 |         if module_name == "truststore" and sys.version_info < (3, 10):
63 |             return None
64 |         raise
65 | 
66 | 
67 | def get_vendor_version_from_module(module_name: str) -> Optional[str]:
68 |     module = get_module_from_module_name(module_name)
69 |     version = getattr(module, "__version__", None)
70 | 
71 |     if module and not version:
72 |         # Try to find version in debundled module info.
73 |         assert module.__file__ is not None
74 |         env = get_environment([os.path.dirname(module.__file__)])
75 |         dist = env.get_distribution(module_name)
76 |         if dist:
77 |             version = str(dist.version)
78 | 
79 |     return version
80 | 
81 | 
82 | def show_actual_vendor_versions(vendor_txt_versions: Dict[str, str]) -> None:
83 |     """Log the actual version and print extra info if there is
84 |     a conflict or if the actual version could not be imported.
85 |     """
86 |     for module_name, expected_version in vendor_txt_versions.items():
87 |         extra_message = ""
88 |         actual_version = get_vendor_version_from_module(module_name)
89 |         if not actual_version:
90 |             extra_message = (
91 |                 " (Unable to locate actual module version, using"
92 |                 " vendor.txt specified version)"
93 |             )
94 |             actual_version = expected_version
95 |         elif parse_version(actual_version) != parse_version(expected_version):
96 |             extra_message = (
97 |                 " (CONFLICT: vendor.txt suggests version should"
98 |                 f" be {expected_version})"
99 |             )
100 |         logger.info("%s==%s%s", module_name, actual_version, extra_message)
101 | 
102 | 
103 | def show_vendor_versions() -> None:
104 |     logger.info("vendored library versions:")
105 | 
106 |     vendor_txt_versions = create_vendor_txt_map()
107 |     with indent_log():
108 |         show_actual_vendor_versions(vendor_txt_versions)
109 | 
110 | 
111 | def show_tags(options: Values) -> None:
112 |     tag_limit = 10
113 | 
114 |     target_python = make_target_python(options)
115 |     tags = target_python.get_sorted_tags()
116 | 
117 |     # Display the target options that were explicitly provided.
118 |     formatted_target = target_python.format_given()
119 |     suffix = ""
120 |     if formatted_target:
121 |         suffix = f" (target: {formatted_target})"
122 | 
123 |     msg = f"Compatible tags: {len(tags)}{suffix}"
124 |     logger.info(msg)
125 | 
126 |     if options.verbose < 1 and len(tags) > tag_limit:
127 |         tags_limited = True
128 |         tags = tags[:tag_limit]
129 |     else:
130 |         tags_limited = False
131 | 
132 |     with indent_log():
133 |         for tag in tags:
134 |             logger.info(str(tag))
135 | 
136 |         if tags_limited:
137 |             msg = f"...\n[First {tag_limit} tags shown. Pass --verbose to show all.]"
138 |             logger.info(msg)
139 | 
140 | 
141 | def ca_bundle_info(config: Configuration) -> str:
142 |     levels = {key.split(".", 1)[0] for key, _ in config.items()}
143 |     if not levels:
144 |         return "Not specified"
145 | 
146 |     levels_that_override_global = ["install", "wheel", "download"]
147 |     global_overriding_level = [
148 |         level for level in levels if level in levels_that_override_global
149 |     ]
150 |     if not global_overriding_level:
151 |         return "global"
152 | 
153 |     if "global" in levels:
154 |         levels.remove("global")
155 |     return ", ".join(levels)
156 | 
157 | 
158 | class DebugCommand(Command):
159 |     """
160 |     Display debug information.
161 |     """
162 | 
163 |     usage = """
164 |       %prog <options>"""
165 |     ignore_require_venv = True
166 | 
167 |     def add_options(self) -> None:
168 |         cmdoptions.add_target_python_options(self.cmd_opts)
169 |         self.parser.insert_option_group(0, self.cmd_opts)
170 |         self.parser.config.load()
171 | 
172 |     def run(self, options: Values, args: List[str]) -> int:
173 |         logger.warning(
174 |             "This command is only meant for debugging. "
175 |             "Do not use this with automation for parsing and getting these "
176 |             "details, since the output and options of this command may "
177 |             "change without notice."
178 |         )
179 |         show_value("pip version", get_pip_version())
180 |         show_value("sys.version", sys.version)
181 |         show_value("sys.executable", sys.executable)
182 |         show_value("sys.getdefaultencoding", sys.getdefaultencoding())
183 |         show_value("sys.getfilesystemencoding", sys.getfilesystemencoding())
184 |         show_value(
185 |             "locale.getpreferredencoding",
186 |             locale.getpreferredencoding(),
187 |         )
188 |         show_value("sys.platform", sys.platform)
189 |         show_sys_implementation()
190 | 
191 |         show_value("'cert' config value", ca_bundle_info(self.parser.config))
192 |         show_value("REQUESTS_CA_BUNDLE", os.environ.get("REQUESTS_CA_BUNDLE"))
193 |         show_value("CURL_CA_BUNDLE", os.environ.get("CURL_CA_BUNDLE"))
194 |         show_value("pip._vendor.certifi.where()", where())
195 |         show_value("pip._vendor.DEBUNDLED", pip._vendor.DEBUNDLED)
196 | 
197 |         show_vendor_versions()
198 | 
199 |         show_tags(options)
200 | 
201 |         return SUCCESS
```

.venv/lib/python3.13/site-packages/pip/_internal/commands/download.py
```
1 | import logging
2 | import os
3 | from optparse import Values
4 | from typing import List
5 | 
6 | from pip._internal.cli import cmdoptions
7 | from pip._internal.cli.cmdoptions import make_target_python
8 | from pip._internal.cli.req_command import RequirementCommand, with_cleanup
9 | from pip._internal.cli.status_codes import SUCCESS
10 | from pip._internal.operations.build.build_tracker import get_build_tracker
11 | from pip._internal.req.req_install import check_legacy_setup_py_options
12 | from pip._internal.utils.misc import ensure_dir, normalize_path, write_output
13 | from pip._internal.utils.temp_dir import TempDirectory
14 | 
15 | logger = logging.getLogger(__name__)
16 | 
17 | 
18 | class DownloadCommand(RequirementCommand):
19 |     """
20 |     Download packages from:
21 | 
22 |     - PyPI (and other indexes) using requirement specifiers.
23 |     - VCS project urls.
24 |     - Local project directories.
25 |     - Local or remote source archives.
26 | 
27 |     pip also supports downloading from "requirements files", which provide
28 |     an easy way to specify a whole environment to be downloaded.
29 |     """
30 | 
31 |     usage = """
32 |       %prog [options] <requirement specifier> [package-index-options] ...
33 |       %prog [options] -r <requirements file> [package-index-options] ...
34 |       %prog [options] <vcs project url> ...
35 |       %prog [options] <local project path> ...
36 |       %prog [options] <archive url/path> ..."""
37 | 
38 |     def add_options(self) -> None:
39 |         self.cmd_opts.add_option(cmdoptions.constraints())
40 |         self.cmd_opts.add_option(cmdoptions.requirements())
41 |         self.cmd_opts.add_option(cmdoptions.no_deps())
42 |         self.cmd_opts.add_option(cmdoptions.global_options())
43 |         self.cmd_opts.add_option(cmdoptions.no_binary())
44 |         self.cmd_opts.add_option(cmdoptions.only_binary())
45 |         self.cmd_opts.add_option(cmdoptions.prefer_binary())
46 |         self.cmd_opts.add_option(cmdoptions.src())
47 |         self.cmd_opts.add_option(cmdoptions.pre())
48 |         self.cmd_opts.add_option(cmdoptions.require_hashes())
49 |         self.cmd_opts.add_option(cmdoptions.progress_bar())
50 |         self.cmd_opts.add_option(cmdoptions.no_build_isolation())
51 |         self.cmd_opts.add_option(cmdoptions.use_pep517())
52 |         self.cmd_opts.add_option(cmdoptions.no_use_pep517())
53 |         self.cmd_opts.add_option(cmdoptions.check_build_deps())
54 |         self.cmd_opts.add_option(cmdoptions.ignore_requires_python())
55 | 
56 |         self.cmd_opts.add_option(
57 |             "-d",
58 |             "--dest",
59 |             "--destination-dir",
60 |             "--destination-directory",
61 |             dest="download_dir",
62 |             metavar="dir",
63 |             default=os.curdir,
64 |             help="Download packages into <dir>.",
65 |         )
66 | 
67 |         cmdoptions.add_target_python_options(self.cmd_opts)
68 | 
69 |         index_opts = cmdoptions.make_option_group(
70 |             cmdoptions.index_group,
71 |             self.parser,
72 |         )
73 | 
74 |         self.parser.insert_option_group(0, index_opts)
75 |         self.parser.insert_option_group(0, self.cmd_opts)
76 | 
77 |     @with_cleanup
78 |     def run(self, options: Values, args: List[str]) -> int:
79 |         options.ignore_installed = True
80 |         # editable doesn't really make sense for `pip download`, but the bowels
81 |         # of the RequirementSet code require that property.
82 |         options.editables = []
83 | 
84 |         cmdoptions.check_dist_restriction(options)
85 | 
86 |         options.download_dir = normalize_path(options.download_dir)
87 |         ensure_dir(options.download_dir)
88 | 
89 |         session = self.get_default_session(options)
90 | 
91 |         target_python = make_target_python(options)
92 |         finder = self._build_package_finder(
93 |             options=options,
94 |             session=session,
95 |             target_python=target_python,
96 |             ignore_requires_python=options.ignore_requires_python,
97 |         )
98 | 
99 |         build_tracker = self.enter_context(get_build_tracker())
100 | 
101 |         directory = TempDirectory(
102 |             delete=not options.no_clean,
103 |             kind="download",
104 |             globally_managed=True,
105 |         )
106 | 
107 |         reqs = self.get_requirements(args, options, finder, session)
108 |         check_legacy_setup_py_options(options, reqs)
109 | 
110 |         preparer = self.make_requirement_preparer(
111 |             temp_build_dir=directory,
112 |             options=options,
113 |             build_tracker=build_tracker,
114 |             session=session,
115 |             finder=finder,
116 |             download_dir=options.download_dir,
117 |             use_user_site=False,
118 |             verbosity=self.verbosity,
119 |         )
120 | 
121 |         resolver = self.make_resolver(
122 |             preparer=preparer,
123 |             finder=finder,
124 |             options=options,
125 |             ignore_requires_python=options.ignore_requires_python,
126 |             use_pep517=options.use_pep517,
127 |             py_version_info=options.python_version,
128 |         )
129 | 
130 |         self.trace_basic_info(finder)
131 | 
132 |         requirement_set = resolver.resolve(reqs, check_supported_wheels=True)
133 | 
134 |         downloaded: List[str] = []
135 |         for req in requirement_set.requirements.values():
136 |             if req.satisfied_by is None:
137 |                 assert req.name is not None
138 |                 preparer.save_linked_requirement(req)
139 |                 downloaded.append(req.name)
140 | 
141 |         preparer.prepare_linked_requirements_more(requirement_set.requirements.values())
142 | 
143 |         if downloaded:
144 |             write_output("Successfully downloaded %s", " ".join(downloaded))
145 | 
146 |         return SUCCESS
```

.venv/lib/python3.13/site-packages/pip/_internal/commands/freeze.py
```
1 | import sys
2 | from optparse import Values
3 | from typing import AbstractSet, List
4 | 
5 | from pip._internal.cli import cmdoptions
6 | from pip._internal.cli.base_command import Command
7 | from pip._internal.cli.status_codes import SUCCESS
8 | from pip._internal.operations.freeze import freeze
9 | from pip._internal.utils.compat import stdlib_pkgs
10 | 
11 | 
12 | def _should_suppress_build_backends() -> bool:
13 |     return sys.version_info < (3, 12)
14 | 
15 | 
16 | def _dev_pkgs() -> AbstractSet[str]:
17 |     pkgs = {"pip"}
18 | 
19 |     if _should_suppress_build_backends():
20 |         pkgs |= {"setuptools", "distribute", "wheel"}
21 | 
22 |     return pkgs
23 | 
24 | 
25 | class FreezeCommand(Command):
26 |     """
27 |     Output installed packages in requirements format.
28 | 
29 |     packages are listed in a case-insensitive sorted order.
30 |     """
31 | 
32 |     ignore_require_venv = True
33 |     usage = """
34 |       %prog [options]"""
35 | 
36 |     def add_options(self) -> None:
37 |         self.cmd_opts.add_option(
38 |             "-r",
39 |             "--requirement",
40 |             dest="requirements",
41 |             action="append",
42 |             default=[],
43 |             metavar="file",
44 |             help=(
45 |                 "Use the order in the given requirements file and its "
46 |                 "comments when generating output. This option can be "
47 |                 "used multiple times."
48 |             ),
49 |         )
50 |         self.cmd_opts.add_option(
51 |             "-l",
52 |             "--local",
53 |             dest="local",
54 |             action="store_true",
55 |             default=False,
56 |             help=(
57 |                 "If in a virtualenv that has global access, do not output "
58 |                 "globally-installed packages."
59 |             ),
60 |         )
61 |         self.cmd_opts.add_option(
62 |             "--user",
63 |             dest="user",
64 |             action="store_true",
65 |             default=False,
66 |             help="Only output packages installed in user-site.",
67 |         )
68 |         self.cmd_opts.add_option(cmdoptions.list_path())
69 |         self.cmd_opts.add_option(
70 |             "--all",
71 |             dest="freeze_all",
72 |             action="store_true",
73 |             help=(
74 |                 "Do not skip these packages in the output:"
75 |                 " {}".format(", ".join(_dev_pkgs()))
76 |             ),
77 |         )
78 |         self.cmd_opts.add_option(
79 |             "--exclude-editable",
80 |             dest="exclude_editable",
81 |             action="store_true",
82 |             help="Exclude editable package from output.",
83 |         )
84 |         self.cmd_opts.add_option(cmdoptions.list_exclude())
85 | 
86 |         self.parser.insert_option_group(0, self.cmd_opts)
87 | 
88 |     def run(self, options: Values, args: List[str]) -> int:
89 |         skip = set(stdlib_pkgs)
90 |         if not options.freeze_all:
91 |             skip.update(_dev_pkgs())
92 | 
93 |         if options.excludes:
94 |             skip.update(options.excludes)
95 | 
96 |         cmdoptions.check_list_path_option(options)
97 | 
98 |         for line in freeze(
99 |             requirement=options.requirements,
100 |             local_only=options.local,
101 |             user_only=options.user,
102 |             paths=options.path,
103 |             isolated=options.isolated_mode,
104 |             skip=skip,
105 |             exclude_editable=options.exclude_editable,
106 |         ):
107 |             sys.stdout.write(line + "\n")
108 |         return SUCCESS
```

.venv/lib/python3.13/site-packages/pip/_internal/commands/hash.py
```
1 | import hashlib
2 | import logging
3 | import sys
4 | from optparse import Values
5 | from typing import List
6 | 
7 | from pip._internal.cli.base_command import Command
8 | from pip._internal.cli.status_codes import ERROR, SUCCESS
9 | from pip._internal.utils.hashes import FAVORITE_HASH, STRONG_HASHES
10 | from pip._internal.utils.misc import read_chunks, write_output
11 | 
12 | logger = logging.getLogger(__name__)
13 | 
14 | 
15 | class HashCommand(Command):
16 |     """
17 |     Compute a hash of a local package archive.
18 | 
19 |     These can be used with --hash in a requirements file to do repeatable
20 |     installs.
21 |     """
22 | 
23 |     usage = "%prog [options] <file> ..."
24 |     ignore_require_venv = True
25 | 
26 |     def add_options(self) -> None:
27 |         self.cmd_opts.add_option(
28 |             "-a",
29 |             "--algorithm",
30 |             dest="algorithm",
31 |             choices=STRONG_HASHES,
32 |             action="store",
33 |             default=FAVORITE_HASH,
34 |             help="The hash algorithm to use: one of {}".format(
35 |                 ", ".join(STRONG_HASHES)
36 |             ),
37 |         )
38 |         self.parser.insert_option_group(0, self.cmd_opts)
39 | 
40 |     def run(self, options: Values, args: List[str]) -> int:
41 |         if not args:
42 |             self.parser.print_usage(sys.stderr)
43 |             return ERROR
44 | 
45 |         algorithm = options.algorithm
46 |         for path in args:
47 |             write_output(
48 |                 "%s:\n--hash=%s:%s", path, algorithm, _hash_of_file(path, algorithm)
49 |             )
50 |         return SUCCESS
51 | 
52 | 
53 | def _hash_of_file(path: str, algorithm: str) -> str:
54 |     """Return the hash digest of a file."""
55 |     with open(path, "rb") as archive:
56 |         hash = hashlib.new(algorithm)
57 |         for chunk in read_chunks(archive):
58 |             hash.update(chunk)
59 |     return hash.hexdigest()
```

.venv/lib/python3.13/site-packages/pip/_internal/commands/help.py
```
1 | from optparse import Values
2 | from typing import List
3 | 
4 | from pip._internal.cli.base_command import Command
5 | from pip._internal.cli.status_codes import SUCCESS
6 | from pip._internal.exceptions import CommandError
7 | 
8 | 
9 | class HelpCommand(Command):
10 |     """Show help for commands"""
11 | 
12 |     usage = """
13 |       %prog <command>"""
14 |     ignore_require_venv = True
15 | 
16 |     def run(self, options: Values, args: List[str]) -> int:
17 |         from pip._internal.commands import (
18 |             commands_dict,
19 |             create_command,
20 |             get_similar_commands,
21 |         )
22 | 
23 |         try:
24 |             # 'pip help' with no args is handled by pip.__init__.parseopt()
25 |             cmd_name = args[0]  # the command we need help for
26 |         except IndexError:
27 |             return SUCCESS
28 | 
29 |         if cmd_name not in commands_dict:
30 |             guess = get_similar_commands(cmd_name)
31 | 
32 |             msg = [f'unknown command "{cmd_name}"']
33 |             if guess:
34 |                 msg.append(f'maybe you meant "{guess}"')
35 | 
36 |             raise CommandError(" - ".join(msg))
37 | 
38 |         command = create_command(cmd_name)
39 |         command.parser.print_help()
40 | 
41 |         return SUCCESS
```

.venv/lib/python3.13/site-packages/pip/_internal/commands/index.py
```
1 | import json
2 | import logging
3 | from optparse import Values
4 | from typing import Any, Iterable, List, Optional
5 | 
6 | from pip._vendor.packaging.version import Version
7 | 
8 | from pip._internal.cli import cmdoptions
9 | from pip._internal.cli.req_command import IndexGroupCommand
10 | from pip._internal.cli.status_codes import ERROR, SUCCESS
11 | from pip._internal.commands.search import (
12 |     get_installed_distribution,
13 |     print_dist_installation_info,
14 | )
15 | from pip._internal.exceptions import CommandError, DistributionNotFound, PipError
16 | from pip._internal.index.collector import LinkCollector
17 | from pip._internal.index.package_finder import PackageFinder
18 | from pip._internal.models.selection_prefs import SelectionPreferences
19 | from pip._internal.models.target_python import TargetPython
20 | from pip._internal.network.session import PipSession
21 | from pip._internal.utils.misc import write_output
22 | 
23 | logger = logging.getLogger(__name__)
24 | 
25 | 
26 | class IndexCommand(IndexGroupCommand):
27 |     """
28 |     Inspect information available from package indexes.
29 |     """
30 | 
31 |     ignore_require_venv = True
32 |     usage = """
33 |         %prog versions <package>
34 |     """
35 | 
36 |     def add_options(self) -> None:
37 |         cmdoptions.add_target_python_options(self.cmd_opts)
38 | 
39 |         self.cmd_opts.add_option(cmdoptions.ignore_requires_python())
40 |         self.cmd_opts.add_option(cmdoptions.pre())
41 |         self.cmd_opts.add_option(cmdoptions.json())
42 |         self.cmd_opts.add_option(cmdoptions.no_binary())
43 |         self.cmd_opts.add_option(cmdoptions.only_binary())
44 | 
45 |         index_opts = cmdoptions.make_option_group(
46 |             cmdoptions.index_group,
47 |             self.parser,
48 |         )
49 | 
50 |         self.parser.insert_option_group(0, index_opts)
51 |         self.parser.insert_option_group(0, self.cmd_opts)
52 | 
53 |     def run(self, options: Values, args: List[str]) -> int:
54 |         handlers = {
55 |             "versions": self.get_available_package_versions,
56 |         }
57 | 
58 |         # Determine action
59 |         if not args or args[0] not in handlers:
60 |             logger.error(
61 |                 "Need an action (%s) to perform.",
62 |                 ", ".join(sorted(handlers)),
63 |             )
64 |             return ERROR
65 | 
66 |         action = args[0]
67 | 
68 |         # Error handling happens here, not in the action-handlers.
69 |         try:
70 |             handlers[action](options, args[1:])
71 |         except PipError as e:
72 |             logger.error(e.args[0])
73 |             return ERROR
74 | 
75 |         return SUCCESS
76 | 
77 |     def _build_package_finder(
78 |         self,
79 |         options: Values,
80 |         session: PipSession,
81 |         target_python: Optional[TargetPython] = None,
82 |         ignore_requires_python: Optional[bool] = None,
83 |     ) -> PackageFinder:
84 |         """
85 |         Create a package finder appropriate to the index command.
86 |         """
87 |         link_collector = LinkCollector.create(session, options=options)
88 | 
89 |         # Pass allow_yanked=False to ignore yanked versions.
90 |         selection_prefs = SelectionPreferences(
91 |             allow_yanked=False,
92 |             allow_all_prereleases=options.pre,
93 |             ignore_requires_python=ignore_requires_python,
94 |         )
95 | 
96 |         return PackageFinder.create(
97 |             link_collector=link_collector,
98 |             selection_prefs=selection_prefs,
99 |             target_python=target_python,
100 |         )
101 | 
102 |     def get_available_package_versions(self, options: Values, args: List[Any]) -> None:
103 |         if len(args) != 1:
104 |             raise CommandError("You need to specify exactly one argument")
105 | 
106 |         target_python = cmdoptions.make_target_python(options)
107 |         query = args[0]
108 | 
109 |         with self._build_session(options) as session:
110 |             finder = self._build_package_finder(
111 |                 options=options,
112 |                 session=session,
113 |                 target_python=target_python,
114 |                 ignore_requires_python=options.ignore_requires_python,
115 |             )
116 | 
117 |             versions: Iterable[Version] = (
118 |                 candidate.version for candidate in finder.find_all_candidates(query)
119 |             )
120 | 
121 |             if not options.pre:
122 |                 # Remove prereleases
123 |                 versions = (
124 |                     version for version in versions if not version.is_prerelease
125 |                 )
126 |             versions = set(versions)
127 | 
128 |             if not versions:
129 |                 raise DistributionNotFound(
130 |                     f"No matching distribution found for {query}"
131 |                 )
132 | 
133 |             formatted_versions = [str(ver) for ver in sorted(versions, reverse=True)]
134 |             latest = formatted_versions[0]
135 | 
136 |         dist = get_installed_distribution(query)
137 | 
138 |         if options.json:
139 |             structured_output = {
140 |                 "name": query,
141 |                 "versions": formatted_versions,
142 |                 "latest": latest,
143 |             }
144 | 
145 |             if dist is not None:
146 |                 structured_output["installed_version"] = str(dist.version)
147 | 
148 |             write_output(json.dumps(structured_output))
149 | 
150 |         else:
151 |             write_output(f"{query} ({latest})")
152 |             write_output("Available versions: {}".format(", ".join(formatted_versions)))
153 |             print_dist_installation_info(latest, dist)
```

.venv/lib/python3.13/site-packages/pip/_internal/commands/inspect.py
```
1 | import logging
2 | from optparse import Values
3 | from typing import Any, Dict, List
4 | 
5 | from pip._vendor.packaging.markers import default_environment
6 | from pip._vendor.rich import print_json
7 | 
8 | from pip import __version__
9 | from pip._internal.cli import cmdoptions
10 | from pip._internal.cli.base_command import Command
11 | from pip._internal.cli.status_codes import SUCCESS
12 | from pip._internal.metadata import BaseDistribution, get_environment
13 | from pip._internal.utils.compat import stdlib_pkgs
14 | from pip._internal.utils.urls import path_to_url
15 | 
16 | logger = logging.getLogger(__name__)
17 | 
18 | 
19 | class InspectCommand(Command):
20 |     """
21 |     Inspect the content of a Python environment and produce a report in JSON format.
22 |     """
23 | 
24 |     ignore_require_venv = True
25 |     usage = """
26 |       %prog [options]"""
27 | 
28 |     def add_options(self) -> None:
29 |         self.cmd_opts.add_option(
30 |             "--local",
31 |             action="store_true",
32 |             default=False,
33 |             help=(
34 |                 "If in a virtualenv that has global access, do not list "
35 |                 "globally-installed packages."
36 |             ),
37 |         )
38 |         self.cmd_opts.add_option(
39 |             "--user",
40 |             dest="user",
41 |             action="store_true",
42 |             default=False,
43 |             help="Only output packages installed in user-site.",
44 |         )
45 |         self.cmd_opts.add_option(cmdoptions.list_path())
46 |         self.parser.insert_option_group(0, self.cmd_opts)
47 | 
48 |     def run(self, options: Values, args: List[str]) -> int:
49 |         cmdoptions.check_list_path_option(options)
50 |         dists = get_environment(options.path).iter_installed_distributions(
51 |             local_only=options.local,
52 |             user_only=options.user,
53 |             skip=set(stdlib_pkgs),
54 |         )
55 |         output = {
56 |             "version": "1",
57 |             "pip_version": __version__,
58 |             "installed": [self._dist_to_dict(dist) for dist in dists],
59 |             "environment": default_environment(),
60 |             # TODO tags? scheme?
61 |         }
62 |         print_json(data=output)
63 |         return SUCCESS
64 | 
65 |     def _dist_to_dict(self, dist: BaseDistribution) -> Dict[str, Any]:
66 |         res: Dict[str, Any] = {
67 |             "metadata": dist.metadata_dict,
68 |             "metadata_location": dist.info_location,
69 |         }
70 |         # direct_url. Note that we don't have download_info (as in the installation
71 |         # report) since it is not recorded in installed metadata.
72 |         direct_url = dist.direct_url
73 |         if direct_url is not None:
74 |             res["direct_url"] = direct_url.to_dict()
75 |         else:
76 |             # Emulate direct_url for legacy editable installs.
77 |             editable_project_location = dist.editable_project_location
78 |             if editable_project_location is not None:
79 |                 res["direct_url"] = {
80 |                     "url": path_to_url(editable_project_location),
81 |                     "dir_info": {
82 |                         "editable": True,
83 |                     },
84 |                 }
85 |         # installer
86 |         installer = dist.installer
87 |         if dist.installer:
88 |             res["installer"] = installer
89 |         # requested
90 |         if dist.installed_with_dist_info:
91 |             res["requested"] = dist.requested
92 |         return res
```

.venv/lib/python3.13/site-packages/pip/_internal/commands/install.py
```
1 | import errno
2 | import json
3 | import operator
4 | import os
5 | import shutil
6 | import site
7 | from optparse import SUPPRESS_HELP, Values
8 | from typing import List, Optional
9 | 
10 | from pip._vendor.packaging.utils import canonicalize_name
11 | from pip._vendor.requests.exceptions import InvalidProxyURL
12 | from pip._vendor.rich import print_json
13 | 
14 | # Eagerly import self_outdated_check to avoid crashes. Otherwise,
15 | # this module would be imported *after* pip was replaced, resulting
16 | # in crashes if the new self_outdated_check module was incompatible
17 | # with the rest of pip that's already imported, or allowing a
18 | # wheel to execute arbitrary code on install by replacing
19 | # self_outdated_check.
20 | import pip._internal.self_outdated_check  # noqa: F401
21 | from pip._internal.cache import WheelCache
22 | from pip._internal.cli import cmdoptions
23 | from pip._internal.cli.cmdoptions import make_target_python
24 | from pip._internal.cli.req_command import (
25 |     RequirementCommand,
26 |     with_cleanup,
27 | )
28 | from pip._internal.cli.status_codes import ERROR, SUCCESS
29 | from pip._internal.exceptions import CommandError, InstallationError
30 | from pip._internal.locations import get_scheme
31 | from pip._internal.metadata import get_environment
32 | from pip._internal.models.installation_report import InstallationReport
33 | from pip._internal.operations.build.build_tracker import get_build_tracker
34 | from pip._internal.operations.check import ConflictDetails, check_install_conflicts
35 | from pip._internal.req import install_given_reqs
36 | from pip._internal.req.req_install import (
37 |     InstallRequirement,
38 |     check_legacy_setup_py_options,
39 | )
40 | from pip._internal.utils.compat import WINDOWS
41 | from pip._internal.utils.filesystem import test_writable_dir
42 | from pip._internal.utils.logging import getLogger
43 | from pip._internal.utils.misc import (
44 |     check_externally_managed,
45 |     ensure_dir,
46 |     get_pip_version,
47 |     protect_pip_from_modification_on_windows,
48 |     warn_if_run_as_root,
49 |     write_output,
50 | )
51 | from pip._internal.utils.temp_dir import TempDirectory
52 | from pip._internal.utils.virtualenv import (
53 |     running_under_virtualenv,
54 |     virtualenv_no_global,
55 | )
56 | from pip._internal.wheel_builder import build, should_build_for_install_command
57 | 
58 | logger = getLogger(__name__)
59 | 
60 | 
61 | class InstallCommand(RequirementCommand):
62 |     """
63 |     Install packages from:
64 | 
65 |     - PyPI (and other indexes) using requirement specifiers.
66 |     - VCS project urls.
67 |     - Local project directories.
68 |     - Local or remote source archives.
69 | 
70 |     pip also supports installing from "requirements files", which provide
71 |     an easy way to specify a whole environment to be installed.
72 |     """
73 | 
74 |     usage = """
75 |       %prog [options] <requirement specifier> [package-index-options] ...
76 |       %prog [options] -r <requirements file> [package-index-options] ...
77 |       %prog [options] [-e] <vcs project url> ...
78 |       %prog [options] [-e] <local project path> ...
79 |       %prog [options] <archive url/path> ..."""
80 | 
81 |     def add_options(self) -> None:
82 |         self.cmd_opts.add_option(cmdoptions.requirements())
83 |         self.cmd_opts.add_option(cmdoptions.constraints())
84 |         self.cmd_opts.add_option(cmdoptions.no_deps())
85 |         self.cmd_opts.add_option(cmdoptions.pre())
86 | 
87 |         self.cmd_opts.add_option(cmdoptions.editable())
88 |         self.cmd_opts.add_option(
89 |             "--dry-run",
90 |             action="store_true",
91 |             dest="dry_run",
92 |             default=False,
93 |             help=(
94 |                 "Don't actually install anything, just print what would be. "
95 |                 "Can be used in combination with --ignore-installed "
96 |                 "to 'resolve' the requirements."
97 |             ),
98 |         )
99 |         self.cmd_opts.add_option(
100 |             "-t",
101 |             "--target",
102 |             dest="target_dir",
103 |             metavar="dir",
104 |             default=None,
105 |             help=(
106 |                 "Install packages into <dir>. "
107 |                 "By default this will not replace existing files/folders in "
108 |                 "<dir>. Use --upgrade to replace existing packages in <dir> "
109 |                 "with new versions."
110 |             ),
111 |         )
112 |         cmdoptions.add_target_python_options(self.cmd_opts)
113 | 
114 |         self.cmd_opts.add_option(
115 |             "--user",
116 |             dest="use_user_site",
117 |             action="store_true",
118 |             help=(
119 |                 "Install to the Python user install directory for your "
120 |                 "platform. Typically ~/.local/, or %APPDATA%\\Python on "
121 |                 "Windows. (See the Python documentation for site.USER_BASE "
122 |                 "for full details.)"
123 |             ),
124 |         )
125 |         self.cmd_opts.add_option(
126 |             "--no-user",
127 |             dest="use_user_site",
128 |             action="store_false",
129 |             help=SUPPRESS_HELP,
130 |         )
131 |         self.cmd_opts.add_option(
132 |             "--root",
133 |             dest="root_path",
134 |             metavar="dir",
135 |             default=None,
136 |             help="Install everything relative to this alternate root directory.",
137 |         )
138 |         self.cmd_opts.add_option(
139 |             "--prefix",
140 |             dest="prefix_path",
141 |             metavar="dir",
142 |             default=None,
143 |             help=(
144 |                 "Installation prefix where lib, bin and other top-level "
145 |                 "folders are placed. Note that the resulting installation may "
146 |                 "contain scripts and other resources which reference the "
147 |                 "Python interpreter of pip, and not that of ``--prefix``. "
148 |                 "See also the ``--python`` option if the intention is to "
149 |                 "install packages into another (possibly pip-free) "
150 |                 "environment."
151 |             ),
152 |         )
153 | 
154 |         self.cmd_opts.add_option(cmdoptions.src())
155 | 
156 |         self.cmd_opts.add_option(
157 |             "-U",
158 |             "--upgrade",
159 |             dest="upgrade",
160 |             action="store_true",
161 |             help=(
162 |                 "Upgrade all specified packages to the newest available "
163 |                 "version. The handling of dependencies depends on the "
164 |                 "upgrade-strategy used."
165 |             ),
166 |         )
167 | 
168 |         self.cmd_opts.add_option(
169 |             "--upgrade-strategy",
170 |             dest="upgrade_strategy",
171 |             default="only-if-needed",
172 |             choices=["only-if-needed", "eager"],
173 |             help=(
174 |                 "Determines how dependency upgrading should be handled "
175 |                 "[default: %default]. "
176 |                 '"eager" - dependencies are upgraded regardless of '
177 |                 "whether the currently installed version satisfies the "
178 |                 "requirements of the upgraded package(s). "
179 |                 '"only-if-needed" -  are upgraded only when they do not '
180 |                 "satisfy the requirements of the upgraded package(s)."
181 |             ),
182 |         )
183 | 
184 |         self.cmd_opts.add_option(
185 |             "--force-reinstall",
186 |             dest="force_reinstall",
187 |             action="store_true",
188 |             help="Reinstall all packages even if they are already up-to-date.",
189 |         )
190 | 
191 |         self.cmd_opts.add_option(
192 |             "-I",
193 |             "--ignore-installed",
194 |             dest="ignore_installed",
195 |             action="store_true",
196 |             help=(
197 |                 "Ignore the installed packages, overwriting them. "
198 |                 "This can break your system if the existing package "
199 |                 "is of a different version or was installed "
200 |                 "with a different package manager!"
201 |             ),
202 |         )
203 | 
204 |         self.cmd_opts.add_option(cmdoptions.ignore_requires_python())
205 |         self.cmd_opts.add_option(cmdoptions.no_build_isolation())
206 |         self.cmd_opts.add_option(cmdoptions.use_pep517())
207 |         self.cmd_opts.add_option(cmdoptions.no_use_pep517())
208 |         self.cmd_opts.add_option(cmdoptions.check_build_deps())
209 |         self.cmd_opts.add_option(cmdoptions.override_externally_managed())
210 | 
211 |         self.cmd_opts.add_option(cmdoptions.config_settings())
212 |         self.cmd_opts.add_option(cmdoptions.global_options())
213 | 
214 |         self.cmd_opts.add_option(
215 |             "--compile",
216 |             action="store_true",
217 |             dest="compile",
218 |             default=True,
219 |             help="Compile Python source files to bytecode",
220 |         )
221 | 
222 |         self.cmd_opts.add_option(
223 |             "--no-compile",
224 |             action="store_false",
225 |             dest="compile",
226 |             help="Do not compile Python source files to bytecode",
227 |         )
228 | 
229 |         self.cmd_opts.add_option(
230 |             "--no-warn-script-location",
231 |             action="store_false",
232 |             dest="warn_script_location",
233 |             default=True,
234 |             help="Do not warn when installing scripts outside PATH",
235 |         )
236 |         self.cmd_opts.add_option(
237 |             "--no-warn-conflicts",
238 |             action="store_false",
239 |             dest="warn_about_conflicts",
240 |             default=True,
241 |             help="Do not warn about broken dependencies",
242 |         )
243 |         self.cmd_opts.add_option(cmdoptions.no_binary())
244 |         self.cmd_opts.add_option(cmdoptions.only_binary())
245 |         self.cmd_opts.add_option(cmdoptions.prefer_binary())
246 |         self.cmd_opts.add_option(cmdoptions.require_hashes())
247 |         self.cmd_opts.add_option(cmdoptions.progress_bar())
248 |         self.cmd_opts.add_option(cmdoptions.root_user_action())
249 | 
250 |         index_opts = cmdoptions.make_option_group(
251 |             cmdoptions.index_group,
252 |             self.parser,
253 |         )
254 | 
255 |         self.parser.insert_option_group(0, index_opts)
256 |         self.parser.insert_option_group(0, self.cmd_opts)
257 | 
258 |         self.cmd_opts.add_option(
259 |             "--report",
260 |             dest="json_report_file",
261 |             metavar="file",
262 |             default=None,
263 |             help=(
264 |                 "Generate a JSON file describing what pip did to install "
265 |                 "the provided requirements. "
266 |                 "Can be used in combination with --dry-run and --ignore-installed "
267 |                 "to 'resolve' the requirements. "
268 |                 "When - is used as file name it writes to stdout. "
269 |                 "When writing to stdout, please combine with the --quiet option "
270 |                 "to avoid mixing pip logging output with JSON output."
271 |             ),
272 |         )
273 | 
274 |     @with_cleanup
275 |     def run(self, options: Values, args: List[str]) -> int:
276 |         if options.use_user_site and options.target_dir is not None:
277 |             raise CommandError("Can not combine '--user' and '--target'")
278 | 
279 |         # Check whether the environment we're installing into is externally
280 |         # managed, as specified in PEP 668. Specifying --root, --target, or
281 |         # --prefix disables the check, since there's no reliable way to locate
282 |         # the EXTERNALLY-MANAGED file for those cases. An exception is also
283 |         # made specifically for "--dry-run --report" for convenience.
284 |         installing_into_current_environment = (
285 |             not (options.dry_run and options.json_report_file)
286 |             and options.root_path is None
287 |             and options.target_dir is None
288 |             and options.prefix_path is None
289 |         )
290 |         if (
291 |             installing_into_current_environment
292 |             and not options.override_externally_managed
293 |         ):
294 |             check_externally_managed()
295 | 
296 |         upgrade_strategy = "to-satisfy-only"
297 |         if options.upgrade:
298 |             upgrade_strategy = options.upgrade_strategy
299 | 
300 |         cmdoptions.check_dist_restriction(options, check_target=True)
301 | 
302 |         logger.verbose("Using %s", get_pip_version())
303 |         options.use_user_site = decide_user_install(
304 |             options.use_user_site,
305 |             prefix_path=options.prefix_path,
306 |             target_dir=options.target_dir,
307 |             root_path=options.root_path,
308 |             isolated_mode=options.isolated_mode,
309 |         )
310 | 
311 |         target_temp_dir: Optional[TempDirectory] = None
312 |         target_temp_dir_path: Optional[str] = None
313 |         if options.target_dir:
314 |             options.ignore_installed = True
315 |             options.target_dir = os.path.abspath(options.target_dir)
316 |             if (
317 |                 # fmt: off
318 |                 os.path.exists(options.target_dir) and
319 |                 not os.path.isdir(options.target_dir)
320 |                 # fmt: on
321 |             ):
322 |                 raise CommandError(
323 |                     "Target path exists but is not a directory, will not continue."
324 |                 )
325 | 
326 |             # Create a target directory for using with the target option
327 |             target_temp_dir = TempDirectory(kind="target")
328 |             target_temp_dir_path = target_temp_dir.path
329 |             self.enter_context(target_temp_dir)
330 | 
331 |         global_options = options.global_options or []
332 | 
333 |         session = self.get_default_session(options)
334 | 
335 |         target_python = make_target_python(options)
336 |         finder = self._build_package_finder(
337 |             options=options,
338 |             session=session,
339 |             target_python=target_python,
340 |             ignore_requires_python=options.ignore_requires_python,
341 |         )
342 |         build_tracker = self.enter_context(get_build_tracker())
343 | 
344 |         directory = TempDirectory(
345 |             delete=not options.no_clean,
346 |             kind="install",
347 |             globally_managed=True,
348 |         )
349 | 
350 |         try:
351 |             reqs = self.get_requirements(args, options, finder, session)
352 |             check_legacy_setup_py_options(options, reqs)
353 | 
354 |             wheel_cache = WheelCache(options.cache_dir)
355 | 
356 |             # Only when installing is it permitted to use PEP 660.
357 |             # In other circumstances (pip wheel, pip download) we generate
358 |             # regular (i.e. non editable) metadata and wheels.
[TRUNCATED]
```

.venv/lib/python3.13/site-packages/pip/_internal/commands/list.py
```
1 | import json
2 | import logging
3 | from email.parser import Parser
4 | from optparse import Values
5 | from typing import TYPE_CHECKING, Generator, List, Optional, Sequence, Tuple, cast
6 | 
7 | from pip._vendor.packaging.utils import canonicalize_name
8 | from pip._vendor.packaging.version import Version
9 | 
10 | from pip._internal.cli import cmdoptions
11 | from pip._internal.cli.index_command import IndexGroupCommand
12 | from pip._internal.cli.status_codes import SUCCESS
13 | from pip._internal.exceptions import CommandError
14 | from pip._internal.metadata import BaseDistribution, get_environment
15 | from pip._internal.models.selection_prefs import SelectionPreferences
16 | from pip._internal.utils.compat import stdlib_pkgs
17 | from pip._internal.utils.misc import tabulate, write_output
18 | 
19 | if TYPE_CHECKING:
20 |     from pip._internal.index.package_finder import PackageFinder
21 |     from pip._internal.network.session import PipSession
22 | 
23 |     class _DistWithLatestInfo(BaseDistribution):
24 |         """Give the distribution object a couple of extra fields.
25 | 
26 |         These will be populated during ``get_outdated()``. This is dirty but
27 |         makes the rest of the code much cleaner.
28 |         """
29 | 
30 |         latest_version: Version
31 |         latest_filetype: str
32 | 
33 |     _ProcessedDists = Sequence[_DistWithLatestInfo]
34 | 
35 | 
36 | logger = logging.getLogger(__name__)
37 | 
38 | 
39 | class ListCommand(IndexGroupCommand):
40 |     """
41 |     List installed packages, including editables.
42 | 
43 |     Packages are listed in a case-insensitive sorted order.
44 |     """
45 | 
46 |     ignore_require_venv = True
47 |     usage = """
48 |       %prog [options]"""
49 | 
50 |     def add_options(self) -> None:
51 |         self.cmd_opts.add_option(
52 |             "-o",
53 |             "--outdated",
54 |             action="store_true",
55 |             default=False,
56 |             help="List outdated packages",
57 |         )
58 |         self.cmd_opts.add_option(
59 |             "-u",
60 |             "--uptodate",
61 |             action="store_true",
62 |             default=False,
63 |             help="List uptodate packages",
64 |         )
65 |         self.cmd_opts.add_option(
66 |             "-e",
67 |             "--editable",
68 |             action="store_true",
69 |             default=False,
70 |             help="List editable projects.",
71 |         )
72 |         self.cmd_opts.add_option(
73 |             "-l",
74 |             "--local",
75 |             action="store_true",
76 |             default=False,
77 |             help=(
78 |                 "If in a virtualenv that has global access, do not list "
79 |                 "globally-installed packages."
80 |             ),
81 |         )
82 |         self.cmd_opts.add_option(
83 |             "--user",
84 |             dest="user",
85 |             action="store_true",
86 |             default=False,
87 |             help="Only output packages installed in user-site.",
88 |         )
89 |         self.cmd_opts.add_option(cmdoptions.list_path())
90 |         self.cmd_opts.add_option(
91 |             "--pre",
92 |             action="store_true",
93 |             default=False,
94 |             help=(
95 |                 "Include pre-release and development versions. By default, "
96 |                 "pip only finds stable versions."
97 |             ),
98 |         )
99 | 
100 |         self.cmd_opts.add_option(
101 |             "--format",
102 |             action="store",
103 |             dest="list_format",
104 |             default="columns",
105 |             choices=("columns", "freeze", "json"),
106 |             help=(
107 |                 "Select the output format among: columns (default), freeze, or json. "
108 |                 "The 'freeze' format cannot be used with the --outdated option."
109 |             ),
110 |         )
111 | 
112 |         self.cmd_opts.add_option(
113 |             "--not-required",
114 |             action="store_true",
115 |             dest="not_required",
116 |             help="List packages that are not dependencies of installed packages.",
117 |         )
118 | 
119 |         self.cmd_opts.add_option(
120 |             "--exclude-editable",
121 |             action="store_false",
122 |             dest="include_editable",
123 |             help="Exclude editable package from output.",
124 |         )
125 |         self.cmd_opts.add_option(
126 |             "--include-editable",
127 |             action="store_true",
128 |             dest="include_editable",
129 |             help="Include editable package in output.",
130 |             default=True,
131 |         )
132 |         self.cmd_opts.add_option(cmdoptions.list_exclude())
133 |         index_opts = cmdoptions.make_option_group(cmdoptions.index_group, self.parser)
134 | 
135 |         self.parser.insert_option_group(0, index_opts)
136 |         self.parser.insert_option_group(0, self.cmd_opts)
137 | 
138 |     def handle_pip_version_check(self, options: Values) -> None:
139 |         if options.outdated or options.uptodate:
140 |             super().handle_pip_version_check(options)
141 | 
142 |     def _build_package_finder(
143 |         self, options: Values, session: "PipSession"
144 |     ) -> "PackageFinder":
145 |         """
146 |         Create a package finder appropriate to this list command.
147 |         """
148 |         # Lazy import the heavy index modules as most list invocations won't need 'em.
149 |         from pip._internal.index.collector import LinkCollector
150 |         from pip._internal.index.package_finder import PackageFinder
151 | 
152 |         link_collector = LinkCollector.create(session, options=options)
153 | 
154 |         # Pass allow_yanked=False to ignore yanked versions.
155 |         selection_prefs = SelectionPreferences(
156 |             allow_yanked=False,
157 |             allow_all_prereleases=options.pre,
158 |         )
159 | 
160 |         return PackageFinder.create(
161 |             link_collector=link_collector,
162 |             selection_prefs=selection_prefs,
163 |         )
164 | 
165 |     def run(self, options: Values, args: List[str]) -> int:
166 |         if options.outdated and options.uptodate:
167 |             raise CommandError("Options --outdated and --uptodate cannot be combined.")
168 | 
169 |         if options.outdated and options.list_format == "freeze":
170 |             raise CommandError(
171 |                 "List format 'freeze' cannot be used with the --outdated option."
172 |             )
173 | 
174 |         cmdoptions.check_list_path_option(options)
175 | 
176 |         skip = set(stdlib_pkgs)
177 |         if options.excludes:
178 |             skip.update(canonicalize_name(n) for n in options.excludes)
179 | 
180 |         packages: _ProcessedDists = [
181 |             cast("_DistWithLatestInfo", d)
182 |             for d in get_environment(options.path).iter_installed_distributions(
183 |                 local_only=options.local,
184 |                 user_only=options.user,
185 |                 editables_only=options.editable,
186 |                 include_editables=options.include_editable,
187 |                 skip=skip,
188 |             )
189 |         ]
190 | 
191 |         # get_not_required must be called firstly in order to find and
192 |         # filter out all dependencies correctly. Otherwise a package
193 |         # can't be identified as requirement because some parent packages
194 |         # could be filtered out before.
195 |         if options.not_required:
196 |             packages = self.get_not_required(packages, options)
197 | 
198 |         if options.outdated:
199 |             packages = self.get_outdated(packages, options)
200 |         elif options.uptodate:
201 |             packages = self.get_uptodate(packages, options)
202 | 
203 |         self.output_package_listing(packages, options)
204 |         return SUCCESS
205 | 
206 |     def get_outdated(
207 |         self, packages: "_ProcessedDists", options: Values
208 |     ) -> "_ProcessedDists":
209 |         return [
210 |             dist
211 |             for dist in self.iter_packages_latest_infos(packages, options)
212 |             if dist.latest_version > dist.version
213 |         ]
214 | 
215 |     def get_uptodate(
216 |         self, packages: "_ProcessedDists", options: Values
217 |     ) -> "_ProcessedDists":
218 |         return [
219 |             dist
220 |             for dist in self.iter_packages_latest_infos(packages, options)
221 |             if dist.latest_version == dist.version
222 |         ]
223 | 
224 |     def get_not_required(
225 |         self, packages: "_ProcessedDists", options: Values
226 |     ) -> "_ProcessedDists":
227 |         dep_keys = {
228 |             canonicalize_name(dep.name)
229 |             for dist in packages
230 |             for dep in (dist.iter_dependencies() or ())
231 |         }
232 | 
233 |         # Create a set to remove duplicate packages, and cast it to a list
234 |         # to keep the return type consistent with get_outdated and
235 |         # get_uptodate
236 |         return list({pkg for pkg in packages if pkg.canonical_name not in dep_keys})
237 | 
238 |     def iter_packages_latest_infos(
239 |         self, packages: "_ProcessedDists", options: Values
240 |     ) -> Generator["_DistWithLatestInfo", None, None]:
241 |         with self._build_session(options) as session:
242 |             finder = self._build_package_finder(options, session)
243 | 
244 |             def latest_info(
245 |                 dist: "_DistWithLatestInfo",
246 |             ) -> Optional["_DistWithLatestInfo"]:
247 |                 all_candidates = finder.find_all_candidates(dist.canonical_name)
248 |                 if not options.pre:
249 |                     # Remove prereleases
250 |                     all_candidates = [
251 |                         candidate
252 |                         for candidate in all_candidates
253 |                         if not candidate.version.is_prerelease
254 |                     ]
255 | 
256 |                 evaluator = finder.make_candidate_evaluator(
257 |                     project_name=dist.canonical_name,
258 |                 )
259 |                 best_candidate = evaluator.sort_best_candidate(all_candidates)
260 |                 if best_candidate is None:
261 |                     return None
262 | 
263 |                 remote_version = best_candidate.version
264 |                 if best_candidate.link.is_wheel:
265 |                     typ = "wheel"
266 |                 else:
267 |                     typ = "sdist"
268 |                 dist.latest_version = remote_version
269 |                 dist.latest_filetype = typ
270 |                 return dist
271 | 
272 |             for dist in map(latest_info, packages):
273 |                 if dist is not None:
274 |                     yield dist
275 | 
276 |     def output_package_listing(
277 |         self, packages: "_ProcessedDists", options: Values
278 |     ) -> None:
279 |         packages = sorted(
280 |             packages,
281 |             key=lambda dist: dist.canonical_name,
282 |         )
283 |         if options.list_format == "columns" and packages:
284 |             data, header = format_for_columns(packages, options)
285 |             self.output_package_listing_columns(data, header)
286 |         elif options.list_format == "freeze":
287 |             for dist in packages:
288 |                 if options.verbose >= 1:
289 |                     write_output(
290 |                         "%s==%s (%s)", dist.raw_name, dist.version, dist.location
291 |                     )
292 |                 else:
293 |                     write_output("%s==%s", dist.raw_name, dist.version)
294 |         elif options.list_format == "json":
295 |             write_output(format_for_json(packages, options))
296 | 
297 |     def output_package_listing_columns(
298 |         self, data: List[List[str]], header: List[str]
299 |     ) -> None:
300 |         # insert the header first: we need to know the size of column names
301 |         if len(data) > 0:
302 |             data.insert(0, header)
303 | 
304 |         pkg_strings, sizes = tabulate(data)
305 | 
306 |         # Create and add a separator.
307 |         if len(data) > 0:
308 |             pkg_strings.insert(1, " ".join("-" * x for x in sizes))
309 | 
310 |         for val in pkg_strings:
311 |             write_output(val)
312 | 
313 | 
314 | def format_for_columns(
315 |     pkgs: "_ProcessedDists", options: Values
316 | ) -> Tuple[List[List[str]], List[str]]:
317 |     """
318 |     Convert the package data into something usable
319 |     by output_package_listing_columns.
320 |     """
321 |     header = ["Package", "Version"]
322 | 
323 |     running_outdated = options.outdated
324 |     if running_outdated:
325 |         header.extend(["Latest", "Type"])
326 | 
327 |     def wheel_build_tag(dist: BaseDistribution) -> Optional[str]:
328 |         try:
329 |             wheel_file = dist.read_text("WHEEL")
330 |         except FileNotFoundError:
331 |             return None
332 |         return Parser().parsestr(wheel_file).get("Build")
333 | 
334 |     build_tags = [wheel_build_tag(p) for p in pkgs]
335 |     has_build_tags = any(build_tags)
336 |     if has_build_tags:
337 |         header.append("Build")
338 | 
339 |     if options.verbose >= 1:
340 |         header.append("Location")
341 |     if options.verbose >= 1:
342 |         header.append("Installer")
343 | 
344 |     has_editables = any(x.editable for x in pkgs)
345 |     if has_editables:
346 |         header.append("Editable project location")
347 | 
348 |     data = []
349 |     for i, proj in enumerate(pkgs):
350 |         # if we're working on the 'outdated' list, separate out the
351 |         # latest_version and type
352 |         row = [proj.raw_name, proj.raw_version]
353 | 
354 |         if running_outdated:
355 |             row.append(str(proj.latest_version))
356 |             row.append(proj.latest_filetype)
357 | 
358 |         if has_build_tags:
359 |             row.append(build_tags[i] or "")
360 | 
361 |         if has_editables:
362 |             row.append(proj.editable_project_location or "")
363 | 
364 |         if options.verbose >= 1:
365 |             row.append(proj.location or "")
366 |         if options.verbose >= 1:
367 |             row.append(proj.installer)
368 | 
369 |         data.append(row)
370 | 
371 |     return data, header
372 | 
373 | 
374 | def format_for_json(packages: "_ProcessedDists", options: Values) -> str:
375 |     data = []
376 |     for dist in packages:
377 |         info = {
378 |             "name": dist.raw_name,
379 |             "version": str(dist.version),
380 |         }
381 |         if options.verbose >= 1:
382 |             info["location"] = dist.location or ""
383 |             info["installer"] = dist.installer
384 |         if options.outdated:
385 |             info["latest_version"] = str(dist.latest_version)
386 |             info["latest_filetype"] = dist.latest_filetype
387 |         editable_project_location = dist.editable_project_location
388 |         if editable_project_location:
389 |             info["editable_project_location"] = editable_project_location
[TRUNCATED]
```

.venv/lib/python3.13/site-packages/pip/_internal/commands/lock.py
```
1 | import sys
2 | from optparse import Values
3 | from pathlib import Path
4 | from typing import List
5 | 
6 | from pip._internal.cache import WheelCache
7 | from pip._internal.cli import cmdoptions
8 | from pip._internal.cli.req_command import (
9 |     RequirementCommand,
10 |     with_cleanup,
11 | )
12 | from pip._internal.cli.status_codes import SUCCESS
13 | from pip._internal.models.pylock import Pylock, is_valid_pylock_file_name
14 | from pip._internal.operations.build.build_tracker import get_build_tracker
15 | from pip._internal.req.req_install import (
16 |     check_legacy_setup_py_options,
17 | )
18 | from pip._internal.utils.logging import getLogger
19 | from pip._internal.utils.misc import (
20 |     get_pip_version,
21 | )
22 | from pip._internal.utils.temp_dir import TempDirectory
23 | 
24 | logger = getLogger(__name__)
25 | 
26 | 
27 | class LockCommand(RequirementCommand):
28 |     """
29 |     EXPERIMENTAL - Lock packages and their dependencies from:
30 | 
31 |     - PyPI (and other indexes) using requirement specifiers.
32 |     - VCS project urls.
33 |     - Local project directories.
34 |     - Local or remote source archives.
35 | 
36 |     pip also supports locking from "requirements files", which provide an easy
37 |     way to specify a whole environment to be installed.
38 | 
39 |     The generated lock file is only guaranteed to be valid for the current
40 |     python version and platform.
41 |     """
42 | 
43 |     usage = """
44 |       %prog [options] [-e] <local project path> ...
45 |       %prog [options] <requirement specifier> [package-index-options] ...
46 |       %prog [options] -r <requirements file> [package-index-options] ...
47 |       %prog [options] <archive url/path> ..."""
48 | 
49 |     def add_options(self) -> None:
50 |         self.cmd_opts.add_option(
51 |             cmdoptions.PipOption(
52 |                 "--output",
53 |                 "-o",
54 |                 dest="output_file",
55 |                 metavar="path",
56 |                 type="path",
57 |                 default="pylock.toml",
58 |                 help="Lock file name (default=pylock.toml). Use - for stdout.",
59 |             )
60 |         )
61 |         self.cmd_opts.add_option(cmdoptions.requirements())
62 |         self.cmd_opts.add_option(cmdoptions.constraints())
63 |         self.cmd_opts.add_option(cmdoptions.no_deps())
64 |         self.cmd_opts.add_option(cmdoptions.pre())
65 | 
66 |         self.cmd_opts.add_option(cmdoptions.editable())
67 | 
68 |         self.cmd_opts.add_option(cmdoptions.src())
69 | 
70 |         self.cmd_opts.add_option(cmdoptions.ignore_requires_python())
71 |         self.cmd_opts.add_option(cmdoptions.no_build_isolation())
72 |         self.cmd_opts.add_option(cmdoptions.use_pep517())
73 |         self.cmd_opts.add_option(cmdoptions.no_use_pep517())
74 |         self.cmd_opts.add_option(cmdoptions.check_build_deps())
75 | 
76 |         self.cmd_opts.add_option(cmdoptions.config_settings())
77 | 
78 |         self.cmd_opts.add_option(cmdoptions.no_binary())
79 |         self.cmd_opts.add_option(cmdoptions.only_binary())
80 |         self.cmd_opts.add_option(cmdoptions.prefer_binary())
81 |         self.cmd_opts.add_option(cmdoptions.require_hashes())
82 |         self.cmd_opts.add_option(cmdoptions.progress_bar())
83 | 
84 |         index_opts = cmdoptions.make_option_group(
85 |             cmdoptions.index_group,
86 |             self.parser,
87 |         )
88 | 
89 |         self.parser.insert_option_group(0, index_opts)
90 |         self.parser.insert_option_group(0, self.cmd_opts)
91 | 
92 |     @with_cleanup
93 |     def run(self, options: Values, args: List[str]) -> int:
94 |         logger.verbose("Using %s", get_pip_version())
95 | 
96 |         logger.warning(
97 |             "pip lock is currently an experimental command. "
98 |             "It may be removed/changed in a future release "
99 |             "without prior warning."
100 |         )
101 | 
102 |         session = self.get_default_session(options)
103 | 
104 |         finder = self._build_package_finder(
105 |             options=options,
106 |             session=session,
107 |             ignore_requires_python=options.ignore_requires_python,
108 |         )
109 |         build_tracker = self.enter_context(get_build_tracker())
110 | 
111 |         directory = TempDirectory(
112 |             delete=not options.no_clean,
113 |             kind="install",
114 |             globally_managed=True,
115 |         )
116 | 
117 |         reqs = self.get_requirements(args, options, finder, session)
118 |         check_legacy_setup_py_options(options, reqs)
119 | 
120 |         wheel_cache = WheelCache(options.cache_dir)
121 | 
122 |         # Only when installing is it permitted to use PEP 660.
123 |         # In other circumstances (pip wheel, pip download) we generate
124 |         # regular (i.e. non editable) metadata and wheels.
125 |         for req in reqs:
126 |             req.permit_editable_wheels = True
127 | 
128 |         preparer = self.make_requirement_preparer(
129 |             temp_build_dir=directory,
130 |             options=options,
131 |             build_tracker=build_tracker,
132 |             session=session,
133 |             finder=finder,
134 |             use_user_site=False,
135 |             verbosity=self.verbosity,
136 |         )
137 |         resolver = self.make_resolver(
138 |             preparer=preparer,
139 |             finder=finder,
140 |             options=options,
141 |             wheel_cache=wheel_cache,
142 |             use_user_site=False,
143 |             ignore_installed=True,
144 |             ignore_requires_python=options.ignore_requires_python,
145 |             upgrade_strategy="to-satisfy-only",
146 |             use_pep517=options.use_pep517,
147 |         )
148 | 
149 |         self.trace_basic_info(finder)
150 | 
151 |         requirement_set = resolver.resolve(reqs, check_supported_wheels=True)
152 | 
153 |         if options.output_file == "-":
154 |             base_dir = Path.cwd()
155 |         else:
156 |             output_file_path = Path(options.output_file)
157 |             if not is_valid_pylock_file_name(output_file_path):
158 |                 logger.warning(
159 |                     "%s is not a valid lock file name.",
160 |                     output_file_path,
161 |                 )
162 |             base_dir = output_file_path.parent
163 |         pylock_toml = Pylock.from_install_requirements(
164 |             requirement_set.requirements.values(), base_dir=base_dir
165 |         ).as_toml()
166 |         if options.output_file == "-":
167 |             sys.stdout.write(pylock_toml)
168 |         else:
169 |             output_file_path.write_text(pylock_toml, encoding="utf-8")
170 | 
171 |         return SUCCESS
```

.venv/lib/python3.13/site-packages/pip/_internal/commands/search.py
```
1 | import logging
2 | import shutil
3 | import sys
4 | import textwrap
5 | import xmlrpc.client
6 | from collections import OrderedDict
7 | from optparse import Values
8 | from typing import Dict, List, Optional, TypedDict
9 | 
10 | from pip._vendor.packaging.version import parse as parse_version
11 | 
12 | from pip._internal.cli.base_command import Command
13 | from pip._internal.cli.req_command import SessionCommandMixin
14 | from pip._internal.cli.status_codes import NO_MATCHES_FOUND, SUCCESS
15 | from pip._internal.exceptions import CommandError
16 | from pip._internal.metadata import get_default_environment
17 | from pip._internal.metadata.base import BaseDistribution
18 | from pip._internal.models.index import PyPI
19 | from pip._internal.network.xmlrpc import PipXmlrpcTransport
20 | from pip._internal.utils.logging import indent_log
21 | from pip._internal.utils.misc import write_output
22 | 
23 | 
24 | class TransformedHit(TypedDict):
25 |     name: str
26 |     summary: str
27 |     versions: List[str]
28 | 
29 | 
30 | logger = logging.getLogger(__name__)
31 | 
32 | 
33 | class SearchCommand(Command, SessionCommandMixin):
34 |     """Search for PyPI packages whose name or summary contains <query>."""
35 | 
36 |     usage = """
37 |       %prog [options] <query>"""
38 |     ignore_require_venv = True
39 | 
40 |     def add_options(self) -> None:
41 |         self.cmd_opts.add_option(
42 |             "-i",
43 |             "--index",
44 |             dest="index",
45 |             metavar="URL",
46 |             default=PyPI.pypi_url,
47 |             help="Base URL of Python Package Index (default %default)",
48 |         )
49 | 
50 |         self.parser.insert_option_group(0, self.cmd_opts)
51 | 
52 |     def run(self, options: Values, args: List[str]) -> int:
53 |         if not args:
54 |             raise CommandError("Missing required argument (search query).")
55 |         query = args
56 |         pypi_hits = self.search(query, options)
57 |         hits = transform_hits(pypi_hits)
58 | 
59 |         terminal_width = None
60 |         if sys.stdout.isatty():
61 |             terminal_width = shutil.get_terminal_size()[0]
62 | 
63 |         print_results(hits, terminal_width=terminal_width)
64 |         if pypi_hits:
65 |             return SUCCESS
66 |         return NO_MATCHES_FOUND
67 | 
68 |     def search(self, query: List[str], options: Values) -> List[Dict[str, str]]:
69 |         index_url = options.index
70 | 
71 |         session = self.get_default_session(options)
72 | 
73 |         transport = PipXmlrpcTransport(index_url, session)
74 |         pypi = xmlrpc.client.ServerProxy(index_url, transport)
75 |         try:
76 |             hits = pypi.search({"name": query, "summary": query}, "or")
77 |         except xmlrpc.client.Fault as fault:
78 |             message = (
79 |                 f"XMLRPC request failed [code: {fault.faultCode}]\n{fault.faultString}"
80 |             )
81 |             raise CommandError(message)
82 |         assert isinstance(hits, list)
83 |         return hits
84 | 
85 | 
86 | def transform_hits(hits: List[Dict[str, str]]) -> List["TransformedHit"]:
87 |     """
88 |     The list from pypi is really a list of versions. We want a list of
89 |     packages with the list of versions stored inline. This converts the
90 |     list from pypi into one we can use.
91 |     """
92 |     packages: Dict[str, TransformedHit] = OrderedDict()
93 |     for hit in hits:
94 |         name = hit["name"]
95 |         summary = hit["summary"]
96 |         version = hit["version"]
97 | 
98 |         if name not in packages.keys():
99 |             packages[name] = {
100 |                 "name": name,
101 |                 "summary": summary,
102 |                 "versions": [version],
103 |             }
104 |         else:
105 |             packages[name]["versions"].append(version)
106 | 
107 |             # if this is the highest version, replace summary and score
108 |             if version == highest_version(packages[name]["versions"]):
109 |                 packages[name]["summary"] = summary
110 | 
111 |     return list(packages.values())
112 | 
113 | 
114 | def print_dist_installation_info(latest: str, dist: Optional[BaseDistribution]) -> None:
115 |     if dist is not None:
116 |         with indent_log():
117 |             if dist.version == latest:
118 |                 write_output("INSTALLED: %s (latest)", dist.version)
119 |             else:
120 |                 write_output("INSTALLED: %s", dist.version)
121 |                 if parse_version(latest).pre:
122 |                     write_output(
123 |                         "LATEST:    %s (pre-release; install"
124 |                         " with `pip install --pre`)",
125 |                         latest,
126 |                     )
127 |                 else:
128 |                     write_output("LATEST:    %s", latest)
129 | 
130 | 
131 | def get_installed_distribution(name: str) -> Optional[BaseDistribution]:
132 |     env = get_default_environment()
133 |     return env.get_distribution(name)
134 | 
135 | 
136 | def print_results(
137 |     hits: List["TransformedHit"],
138 |     name_column_width: Optional[int] = None,
139 |     terminal_width: Optional[int] = None,
140 | ) -> None:
141 |     if not hits:
142 |         return
143 |     if name_column_width is None:
144 |         name_column_width = (
145 |             max(
146 |                 [
147 |                     len(hit["name"]) + len(highest_version(hit.get("versions", ["-"])))
148 |                     for hit in hits
149 |                 ]
150 |             )
151 |             + 4
152 |         )
153 | 
154 |     for hit in hits:
155 |         name = hit["name"]
156 |         summary = hit["summary"] or ""
157 |         latest = highest_version(hit.get("versions", ["-"]))
158 |         if terminal_width is not None:
159 |             target_width = terminal_width - name_column_width - 5
160 |             if target_width > 10:
161 |                 # wrap and indent summary to fit terminal
162 |                 summary_lines = textwrap.wrap(summary, target_width)
163 |                 summary = ("\n" + " " * (name_column_width + 3)).join(summary_lines)
164 | 
165 |         name_latest = f"{name} ({latest})"
166 |         line = f"{name_latest:{name_column_width}} - {summary}"
167 |         try:
168 |             write_output(line)
169 |             dist = get_installed_distribution(name)
170 |             print_dist_installation_info(latest, dist)
171 |         except UnicodeEncodeError:
172 |             pass
173 | 
174 | 
175 | def highest_version(versions: List[str]) -> str:
176 |     return max(versions, key=parse_version)
```

.venv/lib/python3.13/site-packages/pip/_internal/commands/show.py
```
1 | import logging
2 | import string
3 | from optparse import Values
4 | from typing import Generator, Iterable, Iterator, List, NamedTuple, Optional
5 | 
6 | from pip._vendor.packaging.requirements import InvalidRequirement
7 | from pip._vendor.packaging.utils import canonicalize_name
8 | 
9 | from pip._internal.cli.base_command import Command
10 | from pip._internal.cli.status_codes import ERROR, SUCCESS
11 | from pip._internal.metadata import BaseDistribution, get_default_environment
12 | from pip._internal.utils.misc import write_output
13 | 
14 | logger = logging.getLogger(__name__)
15 | 
16 | 
17 | def normalize_project_url_label(label: str) -> str:
18 |     # This logic is from PEP 753 (Well-known Project URLs in Metadata).
19 |     chars_to_remove = string.punctuation + string.whitespace
20 |     removal_map = str.maketrans("", "", chars_to_remove)
21 |     return label.translate(removal_map).lower()
22 | 
23 | 
24 | class ShowCommand(Command):
25 |     """
26 |     Show information about one or more installed packages.
27 | 
28 |     The output is in RFC-compliant mail header format.
29 |     """
30 | 
31 |     usage = """
32 |       %prog [options] <package> ..."""
33 |     ignore_require_venv = True
34 | 
35 |     def add_options(self) -> None:
36 |         self.cmd_opts.add_option(
37 |             "-f",
38 |             "--files",
39 |             dest="files",
40 |             action="store_true",
41 |             default=False,
42 |             help="Show the full list of installed files for each package.",
43 |         )
44 | 
45 |         self.parser.insert_option_group(0, self.cmd_opts)
46 | 
47 |     def run(self, options: Values, args: List[str]) -> int:
48 |         if not args:
49 |             logger.warning("ERROR: Please provide a package name or names.")
50 |             return ERROR
51 |         query = args
52 | 
53 |         results = search_packages_info(query)
54 |         if not print_results(
55 |             results, list_files=options.files, verbose=options.verbose
56 |         ):
57 |             return ERROR
58 |         return SUCCESS
59 | 
60 | 
61 | class _PackageInfo(NamedTuple):
62 |     name: str
63 |     version: str
64 |     location: str
65 |     editable_project_location: Optional[str]
66 |     requires: List[str]
67 |     required_by: List[str]
68 |     installer: str
69 |     metadata_version: str
70 |     classifiers: List[str]
71 |     summary: str
72 |     homepage: str
73 |     project_urls: List[str]
74 |     author: str
75 |     author_email: str
76 |     license: str
77 |     license_expression: str
78 |     entry_points: List[str]
79 |     files: Optional[List[str]]
80 | 
81 | 
82 | def search_packages_info(query: List[str]) -> Generator[_PackageInfo, None, None]:
83 |     """
84 |     Gather details from installed distributions. Print distribution name,
85 |     version, location, and installed files. Installed files requires a
86 |     pip generated 'installed-files.txt' in the distributions '.egg-info'
87 |     directory.
88 |     """
89 |     env = get_default_environment()
90 | 
91 |     installed = {dist.canonical_name: dist for dist in env.iter_all_distributions()}
92 |     query_names = [canonicalize_name(name) for name in query]
93 |     missing = sorted(
94 |         [name for name, pkg in zip(query, query_names) if pkg not in installed]
95 |     )
96 |     if missing:
97 |         logger.warning("Package(s) not found: %s", ", ".join(missing))
98 | 
99 |     def _get_requiring_packages(current_dist: BaseDistribution) -> Iterator[str]:
100 |         return (
101 |             dist.metadata["Name"] or "UNKNOWN"
102 |             for dist in installed.values()
103 |             if current_dist.canonical_name
104 |             in {canonicalize_name(d.name) for d in dist.iter_dependencies()}
105 |         )
106 | 
107 |     for query_name in query_names:
108 |         try:
109 |             dist = installed[query_name]
110 |         except KeyError:
111 |             continue
112 | 
113 |         try:
114 |             requires = sorted(
115 |                 # Avoid duplicates in requirements (e.g. due to environment markers).
116 |                 {req.name for req in dist.iter_dependencies()},
117 |                 key=str.lower,
118 |             )
119 |         except InvalidRequirement:
120 |             requires = sorted(dist.iter_raw_dependencies(), key=str.lower)
121 | 
122 |         try:
123 |             required_by = sorted(_get_requiring_packages(dist), key=str.lower)
124 |         except InvalidRequirement:
125 |             required_by = ["#N/A"]
126 | 
127 |         try:
128 |             entry_points_text = dist.read_text("entry_points.txt")
129 |             entry_points = entry_points_text.splitlines(keepends=False)
130 |         except FileNotFoundError:
131 |             entry_points = []
132 | 
133 |         files_iter = dist.iter_declared_entries()
134 |         if files_iter is None:
135 |             files: Optional[List[str]] = None
136 |         else:
137 |             files = sorted(files_iter)
138 | 
139 |         metadata = dist.metadata
140 | 
141 |         project_urls = metadata.get_all("Project-URL", [])
142 |         homepage = metadata.get("Home-page", "")
143 |         if not homepage:
144 |             # It's common that there is a "homepage" Project-URL, but Home-page
145 |             # remains unset (especially as PEP 621 doesn't surface the field).
146 |             for url in project_urls:
147 |                 url_label, url = url.split(",", maxsplit=1)
148 |                 normalized_label = normalize_project_url_label(url_label)
149 |                 if normalized_label == "homepage":
150 |                     homepage = url.strip()
151 |                     break
152 | 
153 |         yield _PackageInfo(
154 |             name=dist.raw_name,
155 |             version=dist.raw_version,
156 |             location=dist.location or "",
157 |             editable_project_location=dist.editable_project_location,
158 |             requires=requires,
159 |             required_by=required_by,
160 |             installer=dist.installer,
161 |             metadata_version=dist.metadata_version or "",
162 |             classifiers=metadata.get_all("Classifier", []),
163 |             summary=metadata.get("Summary", ""),
164 |             homepage=homepage,
165 |             project_urls=project_urls,
166 |             author=metadata.get("Author", ""),
167 |             author_email=metadata.get("Author-email", ""),
168 |             license=metadata.get("License", ""),
169 |             license_expression=metadata.get("License-Expression", ""),
170 |             entry_points=entry_points,
171 |             files=files,
172 |         )
173 | 
174 | 
175 | def print_results(
176 |     distributions: Iterable[_PackageInfo],
177 |     list_files: bool,
178 |     verbose: bool,
179 | ) -> bool:
180 |     """
181 |     Print the information from installed distributions found.
182 |     """
183 |     results_printed = False
184 |     for i, dist in enumerate(distributions):
185 |         results_printed = True
186 |         if i > 0:
187 |             write_output("---")
188 | 
189 |         metadata_version_tuple = tuple(map(int, dist.metadata_version.split(".")))
190 | 
191 |         write_output("Name: %s", dist.name)
192 |         write_output("Version: %s", dist.version)
193 |         write_output("Summary: %s", dist.summary)
194 |         write_output("Home-page: %s", dist.homepage)
195 |         write_output("Author: %s", dist.author)
196 |         write_output("Author-email: %s", dist.author_email)
197 |         if metadata_version_tuple >= (2, 4) and dist.license_expression:
198 |             write_output("License-Expression: %s", dist.license_expression)
199 |         else:
200 |             write_output("License: %s", dist.license)
201 |         write_output("Location: %s", dist.location)
202 |         if dist.editable_project_location is not None:
203 |             write_output(
204 |                 "Editable project location: %s", dist.editable_project_location
205 |             )
206 |         write_output("Requires: %s", ", ".join(dist.requires))
207 |         write_output("Required-by: %s", ", ".join(dist.required_by))
208 | 
209 |         if verbose:
210 |             write_output("Metadata-Version: %s", dist.metadata_version)
211 |             write_output("Installer: %s", dist.installer)
212 |             write_output("Classifiers:")
213 |             for classifier in dist.classifiers:
214 |                 write_output("  %s", classifier)
215 |             write_output("Entry-points:")
216 |             for entry in dist.entry_points:
217 |                 write_output("  %s", entry.strip())
218 |             write_output("Project-URLs:")
219 |             for project_url in dist.project_urls:
220 |                 write_output("  %s", project_url)
221 |         if list_files:
222 |             write_output("Files:")
223 |             if dist.files is None:
224 |                 write_output("Cannot locate RECORD or installed-files.txt")
225 |             else:
226 |                 for line in dist.files:
227 |                     write_output("  %s", line.strip())
228 |     return results_printed
```

.venv/lib/python3.13/site-packages/pip/_internal/commands/uninstall.py
```
1 | import logging
2 | from optparse import Values
3 | from typing import List
4 | 
5 | from pip._vendor.packaging.utils import canonicalize_name
6 | 
7 | from pip._internal.cli import cmdoptions
8 | from pip._internal.cli.base_command import Command
9 | from pip._internal.cli.index_command import SessionCommandMixin
10 | from pip._internal.cli.status_codes import SUCCESS
11 | from pip._internal.exceptions import InstallationError
12 | from pip._internal.req import parse_requirements
13 | from pip._internal.req.constructors import (
14 |     install_req_from_line,
15 |     install_req_from_parsed_requirement,
16 | )
17 | from pip._internal.utils.misc import (
18 |     check_externally_managed,
19 |     protect_pip_from_modification_on_windows,
20 |     warn_if_run_as_root,
21 | )
22 | 
23 | logger = logging.getLogger(__name__)
24 | 
25 | 
26 | class UninstallCommand(Command, SessionCommandMixin):
27 |     """
28 |     Uninstall packages.
29 | 
30 |     pip is able to uninstall most installed packages. Known exceptions are:
31 | 
32 |     - Pure distutils packages installed with ``python setup.py install``, which
33 |       leave behind no metadata to determine what files were installed.
34 |     - Script wrappers installed by ``python setup.py develop``.
35 |     """
36 | 
37 |     usage = """
38 |       %prog [options] <package> ...
39 |       %prog [options] -r <requirements file> ..."""
40 | 
41 |     def add_options(self) -> None:
42 |         self.cmd_opts.add_option(
43 |             "-r",
44 |             "--requirement",
45 |             dest="requirements",
46 |             action="append",
47 |             default=[],
48 |             metavar="file",
49 |             help=(
50 |                 "Uninstall all the packages listed in the given requirements "
51 |                 "file.  This option can be used multiple times."
52 |             ),
53 |         )
54 |         self.cmd_opts.add_option(
55 |             "-y",
56 |             "--yes",
57 |             dest="yes",
58 |             action="store_true",
59 |             help="Don't ask for confirmation of uninstall deletions.",
60 |         )
61 |         self.cmd_opts.add_option(cmdoptions.root_user_action())
62 |         self.cmd_opts.add_option(cmdoptions.override_externally_managed())
63 |         self.parser.insert_option_group(0, self.cmd_opts)
64 | 
65 |     def run(self, options: Values, args: List[str]) -> int:
66 |         session = self.get_default_session(options)
67 | 
68 |         reqs_to_uninstall = {}
69 |         for name in args:
70 |             req = install_req_from_line(
71 |                 name,
72 |                 isolated=options.isolated_mode,
73 |             )
74 |             if req.name:
75 |                 reqs_to_uninstall[canonicalize_name(req.name)] = req
76 |             else:
77 |                 logger.warning(
78 |                     "Invalid requirement: %r ignored -"
79 |                     " the uninstall command expects named"
80 |                     " requirements.",
81 |                     name,
82 |                 )
83 |         for filename in options.requirements:
84 |             for parsed_req in parse_requirements(
85 |                 filename, options=options, session=session
86 |             ):
87 |                 req = install_req_from_parsed_requirement(
88 |                     parsed_req, isolated=options.isolated_mode
89 |                 )
90 |                 if req.name:
91 |                     reqs_to_uninstall[canonicalize_name(req.name)] = req
92 |         if not reqs_to_uninstall:
93 |             raise InstallationError(
94 |                 f"You must give at least one requirement to {self.name} (see "
95 |                 f'"pip help {self.name}")'
96 |             )
97 | 
98 |         if not options.override_externally_managed:
99 |             check_externally_managed()
100 | 
101 |         protect_pip_from_modification_on_windows(
102 |             modifying_pip="pip" in reqs_to_uninstall
103 |         )
104 | 
105 |         for req in reqs_to_uninstall.values():
106 |             uninstall_pathset = req.uninstall(
107 |                 auto_confirm=options.yes,
108 |                 verbose=self.verbosity > 0,
109 |             )
110 |             if uninstall_pathset:
111 |                 uninstall_pathset.commit()
112 |         if options.root_user_action == "warn":
113 |             warn_if_run_as_root()
114 |         return SUCCESS
```

.venv/lib/python3.13/site-packages/pip/_internal/commands/wheel.py
```
1 | import logging
2 | import os
3 | import shutil
4 | from optparse import Values
5 | from typing import List
6 | 
7 | from pip._internal.cache import WheelCache
8 | from pip._internal.cli import cmdoptions
9 | from pip._internal.cli.req_command import RequirementCommand, with_cleanup
10 | from pip._internal.cli.status_codes import SUCCESS
11 | from pip._internal.exceptions import CommandError
12 | from pip._internal.operations.build.build_tracker import get_build_tracker
13 | from pip._internal.req.req_install import (
14 |     InstallRequirement,
15 |     check_legacy_setup_py_options,
16 | )
17 | from pip._internal.utils.misc import ensure_dir, normalize_path
18 | from pip._internal.utils.temp_dir import TempDirectory
19 | from pip._internal.wheel_builder import build
20 | 
21 | logger = logging.getLogger(__name__)
22 | 
23 | 
24 | class WheelCommand(RequirementCommand):
25 |     """
26 |     Build Wheel archives for your requirements and dependencies.
27 | 
28 |     Wheel is a built-package format, and offers the advantage of not
29 |     recompiling your software during every install. For more details, see the
30 |     wheel docs: https://wheel.readthedocs.io/en/latest/
31 | 
32 |     'pip wheel' uses the build system interface as described here:
33 |     https://pip.pypa.io/en/stable/reference/build-system/
34 | 
35 |     """
36 | 
37 |     usage = """
38 |       %prog [options] <requirement specifier> ...
39 |       %prog [options] -r <requirements file> ...
40 |       %prog [options] [-e] <vcs project url> ...
41 |       %prog [options] [-e] <local project path> ...
42 |       %prog [options] <archive url/path> ..."""
43 | 
44 |     def add_options(self) -> None:
45 |         self.cmd_opts.add_option(
46 |             "-w",
47 |             "--wheel-dir",
48 |             dest="wheel_dir",
49 |             metavar="dir",
50 |             default=os.curdir,
51 |             help=(
52 |                 "Build wheels into <dir>, where the default is the "
53 |                 "current working directory."
54 |             ),
55 |         )
56 |         self.cmd_opts.add_option(cmdoptions.no_binary())
57 |         self.cmd_opts.add_option(cmdoptions.only_binary())
58 |         self.cmd_opts.add_option(cmdoptions.prefer_binary())
59 |         self.cmd_opts.add_option(cmdoptions.no_build_isolation())
60 |         self.cmd_opts.add_option(cmdoptions.use_pep517())
61 |         self.cmd_opts.add_option(cmdoptions.no_use_pep517())
62 |         self.cmd_opts.add_option(cmdoptions.check_build_deps())
63 |         self.cmd_opts.add_option(cmdoptions.constraints())
64 |         self.cmd_opts.add_option(cmdoptions.editable())
65 |         self.cmd_opts.add_option(cmdoptions.requirements())
66 |         self.cmd_opts.add_option(cmdoptions.src())
67 |         self.cmd_opts.add_option(cmdoptions.ignore_requires_python())
68 |         self.cmd_opts.add_option(cmdoptions.no_deps())
69 |         self.cmd_opts.add_option(cmdoptions.progress_bar())
70 | 
71 |         self.cmd_opts.add_option(
72 |             "--no-verify",
73 |             dest="no_verify",
74 |             action="store_true",
75 |             default=False,
76 |             help="Don't verify if built wheel is valid.",
77 |         )
78 | 
79 |         self.cmd_opts.add_option(cmdoptions.config_settings())
80 |         self.cmd_opts.add_option(cmdoptions.build_options())
81 |         self.cmd_opts.add_option(cmdoptions.global_options())
82 | 
83 |         self.cmd_opts.add_option(
84 |             "--pre",
85 |             action="store_true",
86 |             default=False,
87 |             help=(
88 |                 "Include pre-release and development versions. By default, "
89 |                 "pip only finds stable versions."
90 |             ),
91 |         )
92 | 
93 |         self.cmd_opts.add_option(cmdoptions.require_hashes())
94 | 
95 |         index_opts = cmdoptions.make_option_group(
96 |             cmdoptions.index_group,
97 |             self.parser,
98 |         )
99 | 
100 |         self.parser.insert_option_group(0, index_opts)
101 |         self.parser.insert_option_group(0, self.cmd_opts)
102 | 
103 |     @with_cleanup
104 |     def run(self, options: Values, args: List[str]) -> int:
105 |         session = self.get_default_session(options)
106 | 
107 |         finder = self._build_package_finder(options, session)
108 | 
109 |         options.wheel_dir = normalize_path(options.wheel_dir)
110 |         ensure_dir(options.wheel_dir)
111 | 
112 |         build_tracker = self.enter_context(get_build_tracker())
113 | 
114 |         directory = TempDirectory(
115 |             delete=not options.no_clean,
116 |             kind="wheel",
117 |             globally_managed=True,
118 |         )
119 | 
120 |         reqs = self.get_requirements(args, options, finder, session)
121 |         check_legacy_setup_py_options(options, reqs)
122 | 
123 |         wheel_cache = WheelCache(options.cache_dir)
124 | 
125 |         preparer = self.make_requirement_preparer(
126 |             temp_build_dir=directory,
127 |             options=options,
128 |             build_tracker=build_tracker,
129 |             session=session,
130 |             finder=finder,
131 |             download_dir=options.wheel_dir,
132 |             use_user_site=False,
133 |             verbosity=self.verbosity,
134 |         )
135 | 
136 |         resolver = self.make_resolver(
137 |             preparer=preparer,
138 |             finder=finder,
139 |             options=options,
140 |             wheel_cache=wheel_cache,
141 |             ignore_requires_python=options.ignore_requires_python,
142 |             use_pep517=options.use_pep517,
143 |         )
144 | 
145 |         self.trace_basic_info(finder)
146 | 
147 |         requirement_set = resolver.resolve(reqs, check_supported_wheels=True)
148 | 
149 |         reqs_to_build: List[InstallRequirement] = []
150 |         for req in requirement_set.requirements.values():
151 |             if req.is_wheel:
152 |                 preparer.save_linked_requirement(req)
153 |             else:
154 |                 reqs_to_build.append(req)
155 | 
156 |         preparer.prepare_linked_requirements_more(requirement_set.requirements.values())
157 | 
158 |         # build wheels
159 |         build_successes, build_failures = build(
160 |             reqs_to_build,
161 |             wheel_cache=wheel_cache,
162 |             verify=(not options.no_verify),
163 |             build_options=options.build_options or [],
164 |             global_options=options.global_options or [],
165 |         )
166 |         for req in build_successes:
167 |             assert req.link and req.link.is_wheel
168 |             assert req.local_file_path
169 |             # copy from cache to target directory
170 |             try:
171 |                 shutil.copy(req.local_file_path, options.wheel_dir)
172 |             except OSError as e:
173 |                 logger.warning(
174 |                     "Building wheel for %s failed: %s",
175 |                     req.name,
176 |                     e,
177 |                 )
178 |                 build_failures.append(req)
179 |         if len(build_failures) != 0:
180 |             raise CommandError("Failed to build one or more wheels")
181 | 
182 |         return SUCCESS
```

.venv/lib/python3.13/site-packages/pip/_internal/index/__init__.py
```
1 | """Index interaction code"""
```

.venv/lib/python3.13/site-packages/pip/_internal/index/collector.py
```
1 | """
2 | The main purpose of this module is to expose LinkCollector.collect_sources().
3 | """
4 | 
5 | import collections
6 | import email.message
7 | import functools
8 | import itertools
9 | import json
10 | import logging
11 | import os
12 | import urllib.parse
13 | import urllib.request
14 | from dataclasses import dataclass
15 | from html.parser import HTMLParser
16 | from optparse import Values
17 | from typing import (
18 |     Callable,
19 |     Dict,
20 |     Iterable,
21 |     List,
22 |     MutableMapping,
23 |     NamedTuple,
24 |     Optional,
25 |     Protocol,
26 |     Sequence,
27 |     Tuple,
28 |     Union,
29 | )
30 | 
31 | from pip._vendor import requests
32 | from pip._vendor.requests import Response
33 | from pip._vendor.requests.exceptions import RetryError, SSLError
34 | 
35 | from pip._internal.exceptions import NetworkConnectionError
36 | from pip._internal.models.link import Link
37 | from pip._internal.models.search_scope import SearchScope
38 | from pip._internal.network.session import PipSession
39 | from pip._internal.network.utils import raise_for_status
40 | from pip._internal.utils.filetypes import is_archive_file
41 | from pip._internal.utils.misc import redact_auth_from_url
42 | from pip._internal.vcs import vcs
43 | 
44 | from .sources import CandidatesFromPage, LinkSource, build_source
45 | 
46 | logger = logging.getLogger(__name__)
47 | 
48 | ResponseHeaders = MutableMapping[str, str]
49 | 
50 | 
51 | def _match_vcs_scheme(url: str) -> Optional[str]:
52 |     """Look for VCS schemes in the URL.
53 | 
54 |     Returns the matched VCS scheme, or None if there's no match.
55 |     """
56 |     for scheme in vcs.schemes:
57 |         if url.lower().startswith(scheme) and url[len(scheme)] in "+:":
58 |             return scheme
59 |     return None
60 | 
61 | 
62 | class _NotAPIContent(Exception):
63 |     def __init__(self, content_type: str, request_desc: str) -> None:
64 |         super().__init__(content_type, request_desc)
65 |         self.content_type = content_type
66 |         self.request_desc = request_desc
67 | 
68 | 
69 | def _ensure_api_header(response: Response) -> None:
70 |     """
71 |     Check the Content-Type header to ensure the response contains a Simple
72 |     API Response.
73 | 
74 |     Raises `_NotAPIContent` if the content type is not a valid content-type.
75 |     """
76 |     content_type = response.headers.get("Content-Type", "Unknown")
77 | 
78 |     content_type_l = content_type.lower()
79 |     if content_type_l.startswith(
80 |         (
81 |             "text/html",
82 |             "application/vnd.pypi.simple.v1+html",
83 |             "application/vnd.pypi.simple.v1+json",
84 |         )
85 |     ):
86 |         return
87 | 
88 |     raise _NotAPIContent(content_type, response.request.method)
89 | 
90 | 
91 | class _NotHTTP(Exception):
92 |     pass
93 | 
94 | 
95 | def _ensure_api_response(url: str, session: PipSession) -> None:
96 |     """
97 |     Send a HEAD request to the URL, and ensure the response contains a simple
98 |     API Response.
99 | 
100 |     Raises `_NotHTTP` if the URL is not available for a HEAD request, or
101 |     `_NotAPIContent` if the content type is not a valid content type.
102 |     """
103 |     scheme, netloc, path, query, fragment = urllib.parse.urlsplit(url)
104 |     if scheme not in {"http", "https"}:
105 |         raise _NotHTTP()
106 | 
107 |     resp = session.head(url, allow_redirects=True)
108 |     raise_for_status(resp)
109 | 
110 |     _ensure_api_header(resp)
111 | 
112 | 
113 | def _get_simple_response(url: str, session: PipSession) -> Response:
114 |     """Access an Simple API response with GET, and return the response.
115 | 
116 |     This consists of three parts:
117 | 
118 |     1. If the URL looks suspiciously like an archive, send a HEAD first to
119 |        check the Content-Type is HTML or Simple API, to avoid downloading a
120 |        large file. Raise `_NotHTTP` if the content type cannot be determined, or
121 |        `_NotAPIContent` if it is not HTML or a Simple API.
122 |     2. Actually perform the request. Raise HTTP exceptions on network failures.
123 |     3. Check the Content-Type header to make sure we got a Simple API response,
124 |        and raise `_NotAPIContent` otherwise.
125 |     """
126 |     if is_archive_file(Link(url).filename):
127 |         _ensure_api_response(url, session=session)
128 | 
129 |     logger.debug("Getting page %s", redact_auth_from_url(url))
130 | 
131 |     resp = session.get(
132 |         url,
133 |         headers={
134 |             "Accept": ", ".join(
135 |                 [
136 |                     "application/vnd.pypi.simple.v1+json",
137 |                     "application/vnd.pypi.simple.v1+html; q=0.1",
138 |                     "text/html; q=0.01",
139 |                 ]
140 |             ),
141 |             # We don't want to blindly returned cached data for
142 |             # /simple/, because authors generally expecting that
143 |             # twine upload && pip install will function, but if
144 |             # they've done a pip install in the last ~10 minutes
145 |             # it won't. Thus by setting this to zero we will not
146 |             # blindly use any cached data, however the benefit of
147 |             # using max-age=0 instead of no-cache, is that we will
148 |             # still support conditional requests, so we will still
149 |             # minimize traffic sent in cases where the page hasn't
150 |             # changed at all, we will just always incur the round
151 |             # trip for the conditional GET now instead of only
152 |             # once per 10 minutes.
153 |             # For more information, please see pypa/pip#5670.
154 |             "Cache-Control": "max-age=0",
155 |         },
156 |     )
157 |     raise_for_status(resp)
158 | 
159 |     # The check for archives above only works if the url ends with
160 |     # something that looks like an archive. However that is not a
161 |     # requirement of an url. Unless we issue a HEAD request on every
162 |     # url we cannot know ahead of time for sure if something is a
163 |     # Simple API response or not. However we can check after we've
164 |     # downloaded it.
165 |     _ensure_api_header(resp)
166 | 
167 |     logger.debug(
168 |         "Fetched page %s as %s",
169 |         redact_auth_from_url(url),
170 |         resp.headers.get("Content-Type", "Unknown"),
171 |     )
172 | 
173 |     return resp
174 | 
175 | 
176 | def _get_encoding_from_headers(headers: ResponseHeaders) -> Optional[str]:
177 |     """Determine if we have any encoding information in our headers."""
178 |     if headers and "Content-Type" in headers:
179 |         m = email.message.Message()
180 |         m["content-type"] = headers["Content-Type"]
181 |         charset = m.get_param("charset")
182 |         if charset:
183 |             return str(charset)
184 |     return None
185 | 
186 | 
187 | class CacheablePageContent:
188 |     def __init__(self, page: "IndexContent") -> None:
189 |         assert page.cache_link_parsing
190 |         self.page = page
191 | 
192 |     def __eq__(self, other: object) -> bool:
193 |         return isinstance(other, type(self)) and self.page.url == other.page.url
194 | 
195 |     def __hash__(self) -> int:
196 |         return hash(self.page.url)
197 | 
198 | 
199 | class ParseLinks(Protocol):
200 |     def __call__(self, page: "IndexContent") -> Iterable[Link]: ...
201 | 
202 | 
203 | def with_cached_index_content(fn: ParseLinks) -> ParseLinks:
204 |     """
205 |     Given a function that parses an Iterable[Link] from an IndexContent, cache the
206 |     function's result (keyed by CacheablePageContent), unless the IndexContent
207 |     `page` has `page.cache_link_parsing == False`.
208 |     """
209 | 
210 |     @functools.lru_cache(maxsize=None)
211 |     def wrapper(cacheable_page: CacheablePageContent) -> List[Link]:
212 |         return list(fn(cacheable_page.page))
213 | 
214 |     @functools.wraps(fn)
215 |     def wrapper_wrapper(page: "IndexContent") -> List[Link]:
216 |         if page.cache_link_parsing:
217 |             return wrapper(CacheablePageContent(page))
218 |         return list(fn(page))
219 | 
220 |     return wrapper_wrapper
221 | 
222 | 
223 | @with_cached_index_content
224 | def parse_links(page: "IndexContent") -> Iterable[Link]:
225 |     """
226 |     Parse a Simple API's Index Content, and yield its anchor elements as Link objects.
227 |     """
228 | 
229 |     content_type_l = page.content_type.lower()
230 |     if content_type_l.startswith("application/vnd.pypi.simple.v1+json"):
231 |         data = json.loads(page.content)
232 |         for file in data.get("files", []):
233 |             link = Link.from_json(file, page.url)
234 |             if link is None:
235 |                 continue
236 |             yield link
237 |         return
238 | 
239 |     parser = HTMLLinkParser(page.url)
240 |     encoding = page.encoding or "utf-8"
241 |     parser.feed(page.content.decode(encoding))
242 | 
243 |     url = page.url
244 |     base_url = parser.base_url or url
245 |     for anchor in parser.anchors:
246 |         link = Link.from_element(anchor, page_url=url, base_url=base_url)
247 |         if link is None:
248 |             continue
249 |         yield link
250 | 
251 | 
252 | @dataclass(frozen=True)
253 | class IndexContent:
254 |     """Represents one response (or page), along with its URL.
255 | 
256 |     :param encoding: the encoding to decode the given content.
257 |     :param url: the URL from which the HTML was downloaded.
258 |     :param cache_link_parsing: whether links parsed from this page's url
259 |                                should be cached. PyPI index urls should
260 |                                have this set to False, for example.
261 |     """
262 | 
263 |     content: bytes
264 |     content_type: str
265 |     encoding: Optional[str]
266 |     url: str
267 |     cache_link_parsing: bool = True
268 | 
269 |     def __str__(self) -> str:
270 |         return redact_auth_from_url(self.url)
271 | 
272 | 
273 | class HTMLLinkParser(HTMLParser):
274 |     """
275 |     HTMLParser that keeps the first base HREF and a list of all anchor
276 |     elements' attributes.
277 |     """
278 | 
279 |     def __init__(self, url: str) -> None:
280 |         super().__init__(convert_charrefs=True)
281 | 
282 |         self.url: str = url
283 |         self.base_url: Optional[str] = None
284 |         self.anchors: List[Dict[str, Optional[str]]] = []
285 | 
286 |     def handle_starttag(self, tag: str, attrs: List[Tuple[str, Optional[str]]]) -> None:
287 |         if tag == "base" and self.base_url is None:
288 |             href = self.get_href(attrs)
289 |             if href is not None:
290 |                 self.base_url = href
291 |         elif tag == "a":
292 |             self.anchors.append(dict(attrs))
293 | 
294 |     def get_href(self, attrs: List[Tuple[str, Optional[str]]]) -> Optional[str]:
295 |         for name, value in attrs:
296 |             if name == "href":
297 |                 return value
298 |         return None
299 | 
300 | 
301 | def _handle_get_simple_fail(
302 |     link: Link,
303 |     reason: Union[str, Exception],
304 |     meth: Optional[Callable[..., None]] = None,
305 | ) -> None:
306 |     if meth is None:
307 |         meth = logger.debug
308 |     meth("Could not fetch URL %s: %s - skipping", link, reason)
309 | 
310 | 
311 | def _make_index_content(
312 |     response: Response, cache_link_parsing: bool = True
313 | ) -> IndexContent:
314 |     encoding = _get_encoding_from_headers(response.headers)
315 |     return IndexContent(
316 |         response.content,
317 |         response.headers["Content-Type"],
318 |         encoding=encoding,
319 |         url=response.url,
320 |         cache_link_parsing=cache_link_parsing,
321 |     )
322 | 
323 | 
324 | def _get_index_content(link: Link, *, session: PipSession) -> Optional["IndexContent"]:
325 |     url = link.url.split("#", 1)[0]
326 | 
327 |     # Check for VCS schemes that do not support lookup as web pages.
328 |     vcs_scheme = _match_vcs_scheme(url)
329 |     if vcs_scheme:
330 |         logger.warning(
331 |             "Cannot look at %s URL %s because it does not support lookup as web pages.",
332 |             vcs_scheme,
333 |             link,
334 |         )
335 |         return None
336 | 
337 |     # Tack index.html onto file:// URLs that point to directories
338 |     scheme, _, path, _, _, _ = urllib.parse.urlparse(url)
339 |     if scheme == "file" and os.path.isdir(urllib.request.url2pathname(path)):
340 |         # add trailing slash if not present so urljoin doesn't trim
341 |         # final segment
342 |         if not url.endswith("/"):
343 |             url += "/"
344 |         # TODO: In the future, it would be nice if pip supported PEP 691
345 |         #       style responses in the file:// URLs, however there's no
346 |         #       standard file extension for application/vnd.pypi.simple.v1+json
347 |         #       so we'll need to come up with something on our own.
348 |         url = urllib.parse.urljoin(url, "index.html")
349 |         logger.debug(" file: URL is directory, getting %s", url)
350 | 
[TRUNCATED]
```

.venv/lib/python3.13/site-packages/pip/_internal/index/package_finder.py
```
1 | """Routines related to PyPI, indexes"""
2 | 
3 | import enum
4 | import functools
5 | import itertools
6 | import logging
7 | import re
8 | from dataclasses import dataclass
9 | from typing import (
10 |     TYPE_CHECKING,
11 |     Dict,
12 |     FrozenSet,
13 |     Iterable,
14 |     List,
15 |     Optional,
16 |     Set,
17 |     Tuple,
18 |     Union,
19 | )
20 | 
21 | from pip._vendor.packaging import specifiers
22 | from pip._vendor.packaging.tags import Tag
23 | from pip._vendor.packaging.utils import canonicalize_name
24 | from pip._vendor.packaging.version import InvalidVersion, _BaseVersion
25 | from pip._vendor.packaging.version import parse as parse_version
26 | 
27 | from pip._internal.exceptions import (
28 |     BestVersionAlreadyInstalled,
29 |     DistributionNotFound,
30 |     InvalidWheelFilename,
31 |     UnsupportedWheel,
32 | )
33 | from pip._internal.index.collector import LinkCollector, parse_links
34 | from pip._internal.models.candidate import InstallationCandidate
35 | from pip._internal.models.format_control import FormatControl
36 | from pip._internal.models.link import Link
37 | from pip._internal.models.search_scope import SearchScope
38 | from pip._internal.models.selection_prefs import SelectionPreferences
39 | from pip._internal.models.target_python import TargetPython
40 | from pip._internal.models.wheel import Wheel
41 | from pip._internal.req import InstallRequirement
42 | from pip._internal.utils._log import getLogger
43 | from pip._internal.utils.filetypes import WHEEL_EXTENSION
44 | from pip._internal.utils.hashes import Hashes
45 | from pip._internal.utils.logging import indent_log
46 | from pip._internal.utils.misc import build_netloc
47 | from pip._internal.utils.packaging import check_requires_python
48 | from pip._internal.utils.unpacking import SUPPORTED_EXTENSIONS
49 | 
50 | if TYPE_CHECKING:
51 |     from pip._vendor.typing_extensions import TypeGuard
52 | 
53 | __all__ = ["FormatControl", "BestCandidateResult", "PackageFinder"]
54 | 
55 | 
56 | logger = getLogger(__name__)
57 | 
58 | BuildTag = Union[Tuple[()], Tuple[int, str]]
59 | CandidateSortingKey = Tuple[int, int, int, _BaseVersion, Optional[int], BuildTag]
60 | 
61 | 
62 | def _check_link_requires_python(
63 |     link: Link,
64 |     version_info: Tuple[int, int, int],
65 |     ignore_requires_python: bool = False,
66 | ) -> bool:
67 |     """
68 |     Return whether the given Python version is compatible with a link's
69 |     "Requires-Python" value.
70 | 
71 |     :param version_info: A 3-tuple of ints representing the Python
72 |         major-minor-micro version to check.
73 |     :param ignore_requires_python: Whether to ignore the "Requires-Python"
74 |         value if the given Python version isn't compatible.
75 |     """
76 |     try:
77 |         is_compatible = check_requires_python(
78 |             link.requires_python,
79 |             version_info=version_info,
80 |         )
81 |     except specifiers.InvalidSpecifier:
82 |         logger.debug(
83 |             "Ignoring invalid Requires-Python (%r) for link: %s",
84 |             link.requires_python,
85 |             link,
86 |         )
87 |     else:
88 |         if not is_compatible:
89 |             version = ".".join(map(str, version_info))
90 |             if not ignore_requires_python:
91 |                 logger.verbose(
92 |                     "Link requires a different Python (%s not in: %r): %s",
93 |                     version,
94 |                     link.requires_python,
95 |                     link,
96 |                 )
97 |                 return False
98 | 
99 |             logger.debug(
100 |                 "Ignoring failed Requires-Python check (%s not in: %r) for link: %s",
101 |                 version,
102 |                 link.requires_python,
103 |                 link,
104 |             )
105 | 
106 |     return True
107 | 
108 | 
109 | class LinkType(enum.Enum):
110 |     candidate = enum.auto()
111 |     different_project = enum.auto()
112 |     yanked = enum.auto()
113 |     format_unsupported = enum.auto()
114 |     format_invalid = enum.auto()
115 |     platform_mismatch = enum.auto()
116 |     requires_python_mismatch = enum.auto()
117 | 
118 | 
119 | class LinkEvaluator:
120 |     """
121 |     Responsible for evaluating links for a particular project.
122 |     """
123 | 
124 |     _py_version_re = re.compile(r"-py([123]\.?[0-9]?)$")
125 | 
126 |     # Don't include an allow_yanked default value to make sure each call
127 |     # site considers whether yanked releases are allowed. This also causes
128 |     # that decision to be made explicit in the calling code, which helps
129 |     # people when reading the code.
130 |     def __init__(
131 |         self,
132 |         project_name: str,
133 |         canonical_name: str,
134 |         formats: FrozenSet[str],
135 |         target_python: TargetPython,
136 |         allow_yanked: bool,
137 |         ignore_requires_python: Optional[bool] = None,
138 |     ) -> None:
139 |         """
140 |         :param project_name: The user supplied package name.
141 |         :param canonical_name: The canonical package name.
142 |         :param formats: The formats allowed for this package. Should be a set
143 |             with 'binary' or 'source' or both in it.
144 |         :param target_python: The target Python interpreter to use when
145 |             evaluating link compatibility. This is used, for example, to
146 |             check wheel compatibility, as well as when checking the Python
147 |             version, e.g. the Python version embedded in a link filename
148 |             (or egg fragment) and against an HTML link's optional PEP 503
149 |             "data-requires-python" attribute.
150 |         :param allow_yanked: Whether files marked as yanked (in the sense
151 |             of PEP 592) are permitted to be candidates for install.
152 |         :param ignore_requires_python: Whether to ignore incompatible
153 |             PEP 503 "data-requires-python" values in HTML links. Defaults
154 |             to False.
155 |         """
156 |         if ignore_requires_python is None:
157 |             ignore_requires_python = False
158 | 
159 |         self._allow_yanked = allow_yanked
160 |         self._canonical_name = canonical_name
161 |         self._ignore_requires_python = ignore_requires_python
162 |         self._formats = formats
163 |         self._target_python = target_python
164 | 
165 |         self.project_name = project_name
166 | 
167 |     def evaluate_link(self, link: Link) -> Tuple[LinkType, str]:
168 |         """
169 |         Determine whether a link is a candidate for installation.
170 | 
171 |         :return: A tuple (result, detail), where *result* is an enum
172 |             representing whether the evaluation found a candidate, or the reason
173 |             why one is not found. If a candidate is found, *detail* will be the
174 |             candidate's version string; if one is not found, it contains the
175 |             reason the link fails to qualify.
176 |         """
177 |         version = None
178 |         if link.is_yanked and not self._allow_yanked:
179 |             reason = link.yanked_reason or "<none given>"
180 |             return (LinkType.yanked, f"yanked for reason: {reason}")
181 | 
182 |         if link.egg_fragment:
183 |             egg_info = link.egg_fragment
184 |             ext = link.ext
185 |         else:
186 |             egg_info, ext = link.splitext()
187 |             if not ext:
188 |                 return (LinkType.format_unsupported, "not a file")
189 |             if ext not in SUPPORTED_EXTENSIONS:
190 |                 return (
191 |                     LinkType.format_unsupported,
192 |                     f"unsupported archive format: {ext}",
193 |                 )
194 |             if "binary" not in self._formats and ext == WHEEL_EXTENSION:
195 |                 reason = f"No binaries permitted for {self.project_name}"
196 |                 return (LinkType.format_unsupported, reason)
197 |             if "macosx10" in link.path and ext == ".zip":
198 |                 return (LinkType.format_unsupported, "macosx10 one")
199 |             if ext == WHEEL_EXTENSION:
200 |                 try:
201 |                     wheel = Wheel(link.filename)
202 |                 except InvalidWheelFilename:
203 |                     return (
204 |                         LinkType.format_invalid,
205 |                         "invalid wheel filename",
206 |                     )
207 |                 if canonicalize_name(wheel.name) != self._canonical_name:
208 |                     reason = f"wrong project name (not {self.project_name})"
209 |                     return (LinkType.different_project, reason)
210 | 
211 |                 supported_tags = self._target_python.get_unsorted_tags()
212 |                 if not wheel.supported(supported_tags):
213 |                     # Include the wheel's tags in the reason string to
214 |                     # simplify troubleshooting compatibility issues.
215 |                     file_tags = ", ".join(wheel.get_formatted_file_tags())
216 |                     reason = (
217 |                         f"none of the wheel's tags ({file_tags}) are compatible "
218 |                         f"(run pip debug --verbose to show compatible tags)"
219 |                     )
220 |                     return (LinkType.platform_mismatch, reason)
221 | 
222 |                 version = wheel.version
223 | 
224 |         # This should be up by the self.ok_binary check, but see issue 2700.
225 |         if "source" not in self._formats and ext != WHEEL_EXTENSION:
226 |             reason = f"No sources permitted for {self.project_name}"
227 |             return (LinkType.format_unsupported, reason)
228 | 
229 |         if not version:
230 |             version = _extract_version_from_fragment(
231 |                 egg_info,
232 |                 self._canonical_name,
233 |             )
234 |         if not version:
235 |             reason = f"Missing project version for {self.project_name}"
236 |             return (LinkType.format_invalid, reason)
237 | 
238 |         match = self._py_version_re.search(version)
239 |         if match:
240 |             version = version[: match.start()]
241 |             py_version = match.group(1)
242 |             if py_version != self._target_python.py_version:
243 |                 return (
244 |                     LinkType.platform_mismatch,
245 |                     "Python version is incorrect",
246 |                 )
247 | 
248 |         supports_python = _check_link_requires_python(
249 |             link,
250 |             version_info=self._target_python.py_version_info,
251 |             ignore_requires_python=self._ignore_requires_python,
252 |         )
253 |         if not supports_python:
254 |             reason = f"{version} Requires-Python {link.requires_python}"
255 |             return (LinkType.requires_python_mismatch, reason)
256 | 
257 |         logger.debug("Found link %s, version: %s", link, version)
258 | 
259 |         return (LinkType.candidate, version)
260 | 
261 | 
262 | def filter_unallowed_hashes(
263 |     candidates: List[InstallationCandidate],
264 |     hashes: Optional[Hashes],
265 |     project_name: str,
266 | ) -> List[InstallationCandidate]:
267 |     """
268 |     Filter out candidates whose hashes aren't allowed, and return a new
269 |     list of candidates.
270 | 
271 |     If at least one candidate has an allowed hash, then all candidates with
272 |     either an allowed hash or no hash specified are returned.  Otherwise,
273 |     the given candidates are returned.
274 | 
275 |     Including the candidates with no hash specified when there is a match
276 |     allows a warning to be logged if there is a more preferred candidate
277 |     with no hash specified.  Returning all candidates in the case of no
278 |     matches lets pip report the hash of the candidate that would otherwise
279 |     have been installed (e.g. permitting the user to more easily update
280 |     their requirements file with the desired hash).
281 |     """
282 |     if not hashes:
283 |         logger.debug(
284 |             "Given no hashes to check %s links for project %r: "
285 |             "discarding no candidates",
286 |             len(candidates),
287 |             project_name,
288 |         )
289 |         # Make sure we're not returning back the given value.
290 |         return list(candidates)
291 | 
292 |     matches_or_no_digest = []
293 |     # Collect the non-matches for logging purposes.
294 |     non_matches = []
295 |     match_count = 0
296 |     for candidate in candidates:
297 |         link = candidate.link
298 |         if not link.has_hash:
299 |             pass
300 |         elif link.is_hash_allowed(hashes=hashes):
301 |             match_count += 1
302 |         else:
303 |             non_matches.append(candidate)
304 |             continue
305 | 
306 |         matches_or_no_digest.append(candidate)
307 | 
308 |     if match_count:
309 |         filtered = matches_or_no_digest
310 |     else:
311 |         # Make sure we're not returning back the given value.
312 |         filtered = list(candidates)
313 | 
314 |     if len(filtered) == len(candidates):
315 |         discard_message = "discarding no candidates"
316 |     else:
317 |         discard_message = "discarding {} non-matches:\n  {}".format(
318 |             len(non_matches),
319 |             "\n  ".join(str(candidate.link) for candidate in non_matches),
320 |         )
321 | 
322 |     logger.debug(
323 |         "Checked %s links for project %r against %s hashes "
324 |         "(%s matches, %s no digest): %s",
325 |         len(candidates),
326 |         project_name,
327 |         hashes.digest_count,
328 |         match_count,
329 |         len(matches_or_no_digest) - match_count,
330 |         discard_message,
331 |     )
332 | 
333 |     return filtered
334 | 
335 | 
336 | @dataclass
337 | class CandidatePreferences:
338 |     """
339 |     Encapsulates some of the preferences for filtering and sorting
340 |     InstallationCandidate objects.
341 |     """
342 | 
343 |     prefer_binary: bool = False
344 |     allow_all_prereleases: bool = False
345 | 
346 | 
347 | @dataclass(frozen=True)
348 | class BestCandidateResult:
349 |     """A collection of candidates, returned by `PackageFinder.find_best_candidate`.
350 | 
351 |     This class is only intended to be instantiated by CandidateEvaluator's
352 |     `compute_best_candidate()` method.
353 | 
[TRUNCATED]
```

.venv/lib/python3.13/site-packages/pip/_internal/index/sources.py
```
1 | import logging
2 | import mimetypes
3 | import os
4 | from collections import defaultdict
5 | from typing import Callable, Dict, Iterable, List, Optional, Tuple
6 | 
7 | from pip._vendor.packaging.utils import (
8 |     InvalidSdistFilename,
9 |     InvalidWheelFilename,
10 |     canonicalize_name,
11 |     parse_sdist_filename,
12 |     parse_wheel_filename,
13 | )
14 | 
15 | from pip._internal.models.candidate import InstallationCandidate
16 | from pip._internal.models.link import Link
17 | from pip._internal.utils.urls import path_to_url, url_to_path
18 | from pip._internal.vcs import is_url
19 | 
20 | logger = logging.getLogger(__name__)
21 | 
22 | FoundCandidates = Iterable[InstallationCandidate]
23 | FoundLinks = Iterable[Link]
24 | CandidatesFromPage = Callable[[Link], Iterable[InstallationCandidate]]
25 | PageValidator = Callable[[Link], bool]
26 | 
27 | 
28 | class LinkSource:
29 |     @property
30 |     def link(self) -> Optional[Link]:
31 |         """Returns the underlying link, if there's one."""
32 |         raise NotImplementedError()
33 | 
34 |     def page_candidates(self) -> FoundCandidates:
35 |         """Candidates found by parsing an archive listing HTML file."""
36 |         raise NotImplementedError()
37 | 
38 |     def file_links(self) -> FoundLinks:
39 |         """Links found by specifying archives directly."""
40 |         raise NotImplementedError()
41 | 
42 | 
43 | def _is_html_file(file_url: str) -> bool:
44 |     return mimetypes.guess_type(file_url, strict=False)[0] == "text/html"
45 | 
46 | 
47 | class _FlatDirectoryToUrls:
48 |     """Scans directory and caches results"""
49 | 
50 |     def __init__(self, path: str) -> None:
51 |         self._path = path
52 |         self._page_candidates: List[str] = []
53 |         self._project_name_to_urls: Dict[str, List[str]] = defaultdict(list)
54 |         self._scanned_directory = False
55 | 
56 |     def _scan_directory(self) -> None:
57 |         """Scans directory once and populates both page_candidates
58 |         and project_name_to_urls at the same time
59 |         """
60 |         for entry in os.scandir(self._path):
61 |             url = path_to_url(entry.path)
62 |             if _is_html_file(url):
63 |                 self._page_candidates.append(url)
64 |                 continue
65 | 
66 |             # File must have a valid wheel or sdist name,
67 |             # otherwise not worth considering as a package
68 |             try:
69 |                 project_filename = parse_wheel_filename(entry.name)[0]
70 |             except InvalidWheelFilename:
71 |                 try:
72 |                     project_filename = parse_sdist_filename(entry.name)[0]
73 |                 except InvalidSdistFilename:
74 |                     continue
75 | 
76 |             self._project_name_to_urls[project_filename].append(url)
77 |         self._scanned_directory = True
78 | 
79 |     @property
80 |     def page_candidates(self) -> List[str]:
81 |         if not self._scanned_directory:
82 |             self._scan_directory()
83 | 
84 |         return self._page_candidates
85 | 
86 |     @property
87 |     def project_name_to_urls(self) -> Dict[str, List[str]]:
88 |         if not self._scanned_directory:
89 |             self._scan_directory()
90 | 
91 |         return self._project_name_to_urls
92 | 
93 | 
94 | class _FlatDirectorySource(LinkSource):
95 |     """Link source specified by ``--find-links=<path-to-dir>``.
96 | 
97 |     This looks the content of the directory, and returns:
98 | 
99 |     * ``page_candidates``: Links listed on each HTML file in the directory.
100 |     * ``file_candidates``: Archives in the directory.
101 |     """
102 | 
103 |     _paths_to_urls: Dict[str, _FlatDirectoryToUrls] = {}
104 | 
105 |     def __init__(
106 |         self,
107 |         candidates_from_page: CandidatesFromPage,
108 |         path: str,
109 |         project_name: str,
110 |     ) -> None:
111 |         self._candidates_from_page = candidates_from_page
112 |         self._project_name = canonicalize_name(project_name)
113 | 
114 |         # Get existing instance of _FlatDirectoryToUrls if it exists
115 |         if path in self._paths_to_urls:
116 |             self._path_to_urls = self._paths_to_urls[path]
117 |         else:
118 |             self._path_to_urls = _FlatDirectoryToUrls(path=path)
119 |             self._paths_to_urls[path] = self._path_to_urls
120 | 
121 |     @property
122 |     def link(self) -> Optional[Link]:
123 |         return None
124 | 
125 |     def page_candidates(self) -> FoundCandidates:
126 |         for url in self._path_to_urls.page_candidates:
127 |             yield from self._candidates_from_page(Link(url))
128 | 
129 |     def file_links(self) -> FoundLinks:
130 |         for url in self._path_to_urls.project_name_to_urls[self._project_name]:
131 |             yield Link(url)
132 | 
133 | 
134 | class _LocalFileSource(LinkSource):
135 |     """``--find-links=<path-or-url>`` or ``--[extra-]index-url=<path-or-url>``.
136 | 
137 |     If a URL is supplied, it must be a ``file:`` URL. If a path is supplied to
138 |     the option, it is converted to a URL first. This returns:
139 | 
140 |     * ``page_candidates``: Links listed on an HTML file.
141 |     * ``file_candidates``: The non-HTML file.
142 |     """
143 | 
144 |     def __init__(
145 |         self,
146 |         candidates_from_page: CandidatesFromPage,
147 |         link: Link,
148 |     ) -> None:
149 |         self._candidates_from_page = candidates_from_page
150 |         self._link = link
151 | 
152 |     @property
153 |     def link(self) -> Optional[Link]:
154 |         return self._link
155 | 
156 |     def page_candidates(self) -> FoundCandidates:
157 |         if not _is_html_file(self._link.url):
158 |             return
159 |         yield from self._candidates_from_page(self._link)
160 | 
161 |     def file_links(self) -> FoundLinks:
162 |         if _is_html_file(self._link.url):
163 |             return
164 |         yield self._link
165 | 
166 | 
167 | class _RemoteFileSource(LinkSource):
168 |     """``--find-links=<url>`` or ``--[extra-]index-url=<url>``.
169 | 
170 |     This returns:
171 | 
172 |     * ``page_candidates``: Links listed on an HTML file.
173 |     * ``file_candidates``: The non-HTML file.
174 |     """
175 | 
176 |     def __init__(
177 |         self,
178 |         candidates_from_page: CandidatesFromPage,
179 |         page_validator: PageValidator,
180 |         link: Link,
181 |     ) -> None:
182 |         self._candidates_from_page = candidates_from_page
183 |         self._page_validator = page_validator
184 |         self._link = link
185 | 
186 |     @property
187 |     def link(self) -> Optional[Link]:
188 |         return self._link
189 | 
190 |     def page_candidates(self) -> FoundCandidates:
191 |         if not self._page_validator(self._link):
192 |             return
193 |         yield from self._candidates_from_page(self._link)
194 | 
195 |     def file_links(self) -> FoundLinks:
196 |         yield self._link
197 | 
198 | 
199 | class _IndexDirectorySource(LinkSource):
200 |     """``--[extra-]index-url=<path-to-directory>``.
201 | 
202 |     This is treated like a remote URL; ``candidates_from_page`` contains logic
203 |     for this by appending ``index.html`` to the link.
204 |     """
205 | 
206 |     def __init__(
207 |         self,
208 |         candidates_from_page: CandidatesFromPage,
209 |         link: Link,
210 |     ) -> None:
211 |         self._candidates_from_page = candidates_from_page
212 |         self._link = link
213 | 
214 |     @property
215 |     def link(self) -> Optional[Link]:
216 |         return self._link
217 | 
218 |     def page_candidates(self) -> FoundCandidates:
219 |         yield from self._candidates_from_page(self._link)
220 | 
221 |     def file_links(self) -> FoundLinks:
222 |         return ()
223 | 
224 | 
225 | def build_source(
226 |     location: str,
227 |     *,
228 |     candidates_from_page: CandidatesFromPage,
229 |     page_validator: PageValidator,
230 |     expand_dir: bool,
231 |     cache_link_parsing: bool,
232 |     project_name: str,
233 | ) -> Tuple[Optional[str], Optional[LinkSource]]:
234 |     path: Optional[str] = None
235 |     url: Optional[str] = None
236 |     if os.path.exists(location):  # Is a local path.
237 |         url = path_to_url(location)
238 |         path = location
239 |     elif location.startswith("file:"):  # A file: URL.
240 |         url = location
241 |         path = url_to_path(location)
242 |     elif is_url(location):
243 |         url = location
244 | 
245 |     if url is None:
246 |         msg = (
247 |             "Location '%s' is ignored: "
248 |             "it is either a non-existing path or lacks a specific scheme."
249 |         )
250 |         logger.warning(msg, location)
251 |         return (None, None)
252 | 
253 |     if path is None:
254 |         source: LinkSource = _RemoteFileSource(
255 |             candidates_from_page=candidates_from_page,
256 |             page_validator=page_validator,
257 |             link=Link(url, cache_link_parsing=cache_link_parsing),
258 |         )
259 |         return (url, source)
260 | 
261 |     if os.path.isdir(path):
262 |         if expand_dir:
263 |             source = _FlatDirectorySource(
264 |                 candidates_from_page=candidates_from_page,
265 |                 path=path,
266 |                 project_name=project_name,
267 |             )
268 |         else:
269 |             source = _IndexDirectorySource(
270 |                 candidates_from_page=candidates_from_page,
271 |                 link=Link(url, cache_link_parsing=cache_link_parsing),
272 |             )
273 |         return (url, source)
274 |     elif os.path.isfile(path):
275 |         source = _LocalFileSource(
276 |             candidates_from_page=candidates_from_page,
277 |             link=Link(url, cache_link_parsing=cache_link_parsing),
278 |         )
279 |         return (url, source)
280 |     logger.warning(
281 |         "Location '%s' is ignored: it is neither a file nor a directory.",
282 |         location,
283 |     )
284 |     return (url, None)
```

.venv/lib/python3.13/site-packages/pip/_internal/req/__init__.py
```
1 | import collections
2 | import logging
3 | from dataclasses import dataclass
4 | from typing import Generator, List, Optional, Sequence, Tuple
5 | 
6 | from pip._internal.cli.progress_bars import get_install_progress_renderer
7 | from pip._internal.utils.logging import indent_log
8 | 
9 | from .req_file import parse_requirements
10 | from .req_install import InstallRequirement
11 | from .req_set import RequirementSet
12 | 
13 | __all__ = [
14 |     "RequirementSet",
15 |     "InstallRequirement",
16 |     "parse_requirements",
17 |     "install_given_reqs",
18 | ]
19 | 
20 | logger = logging.getLogger(__name__)
21 | 
22 | 
23 | @dataclass(frozen=True)
24 | class InstallationResult:
25 |     name: str
26 | 
27 | 
28 | def _validate_requirements(
29 |     requirements: List[InstallRequirement],
30 | ) -> Generator[Tuple[str, InstallRequirement], None, None]:
31 |     for req in requirements:
32 |         assert req.name, f"invalid to-be-installed requirement: {req}"
33 |         yield req.name, req
34 | 
35 | 
36 | def install_given_reqs(
37 |     requirements: List[InstallRequirement],
38 |     global_options: Sequence[str],
39 |     root: Optional[str],
40 |     home: Optional[str],
41 |     prefix: Optional[str],
42 |     warn_script_location: bool,
43 |     use_user_site: bool,
44 |     pycompile: bool,
45 |     progress_bar: str,
46 | ) -> List[InstallationResult]:
47 |     """
48 |     Install everything in the given list.
49 | 
50 |     (to be called after having downloaded and unpacked the packages)
51 |     """
52 |     to_install = collections.OrderedDict(_validate_requirements(requirements))
53 | 
54 |     if to_install:
55 |         logger.info(
56 |             "Installing collected packages: %s",
57 |             ", ".join(to_install.keys()),
58 |         )
59 | 
60 |     installed = []
61 | 
62 |     show_progress = logger.isEnabledFor(logging.INFO) and len(to_install) > 1
63 | 
64 |     items = iter(to_install.values())
65 |     if show_progress:
66 |         renderer = get_install_progress_renderer(
67 |             bar_type=progress_bar, total=len(to_install)
68 |         )
69 |         items = renderer(items)
70 | 
71 |     with indent_log():
72 |         for requirement in items:
73 |             req_name = requirement.name
74 |             assert req_name is not None
75 |             if requirement.should_reinstall:
76 |                 logger.info("Attempting uninstall: %s", req_name)
77 |                 with indent_log():
78 |                     uninstalled_pathset = requirement.uninstall(auto_confirm=True)
79 |             else:
80 |                 uninstalled_pathset = None
81 | 
82 |             try:
83 |                 requirement.install(
84 |                     global_options,
85 |                     root=root,
86 |                     home=home,
87 |                     prefix=prefix,
88 |                     warn_script_location=warn_script_location,
89 |                     use_user_site=use_user_site,
90 |                     pycompile=pycompile,
91 |                 )
92 |             except Exception:
93 |                 # if install did not succeed, rollback previous uninstall
94 |                 if uninstalled_pathset and not requirement.install_succeeded:
95 |                     uninstalled_pathset.rollback()
96 |                 raise
97 |             else:
98 |                 if uninstalled_pathset and requirement.install_succeeded:
99 |                     uninstalled_pathset.commit()
100 | 
101 |             installed.append(InstallationResult(req_name))
102 | 
103 |     return installed
```

.venv/lib/python3.13/site-packages/pip/_internal/req/constructors.py
```
1 | """Backing implementation for InstallRequirement's various constructors
2 | 
3 | The idea here is that these formed a major chunk of InstallRequirement's size
4 | so, moving them and support code dedicated to them outside of that class
5 | helps creates for better understandability for the rest of the code.
6 | 
7 | These are meant to be used elsewhere within pip to create instances of
8 | InstallRequirement.
9 | """
10 | 
11 | import copy
12 | import logging
13 | import os
14 | import re
15 | from dataclasses import dataclass
16 | from typing import Collection, Dict, List, Optional, Set, Tuple, Union
17 | 
18 | from pip._vendor.packaging.markers import Marker
19 | from pip._vendor.packaging.requirements import InvalidRequirement, Requirement
20 | from pip._vendor.packaging.specifiers import Specifier
21 | 
22 | from pip._internal.exceptions import InstallationError
23 | from pip._internal.models.index import PyPI, TestPyPI
24 | from pip._internal.models.link import Link
25 | from pip._internal.models.wheel import Wheel
26 | from pip._internal.req.req_file import ParsedRequirement
27 | from pip._internal.req.req_install import InstallRequirement
28 | from pip._internal.utils.filetypes import is_archive_file
29 | from pip._internal.utils.misc import is_installable_dir
30 | from pip._internal.utils.packaging import get_requirement
31 | from pip._internal.utils.urls import path_to_url
32 | from pip._internal.vcs import is_url, vcs
33 | 
34 | __all__ = [
35 |     "install_req_from_editable",
36 |     "install_req_from_line",
37 |     "parse_editable",
38 | ]
39 | 
40 | logger = logging.getLogger(__name__)
41 | operators = Specifier._operators.keys()
42 | 
43 | 
44 | def _strip_extras(path: str) -> Tuple[str, Optional[str]]:
45 |     m = re.match(r"^(.+)(\[[^\]]+\])$", path)
46 |     extras = None
47 |     if m:
48 |         path_no_extras = m.group(1)
49 |         extras = m.group(2)
50 |     else:
51 |         path_no_extras = path
52 | 
53 |     return path_no_extras, extras
54 | 
55 | 
56 | def convert_extras(extras: Optional[str]) -> Set[str]:
57 |     if not extras:
58 |         return set()
59 |     return get_requirement("placeholder" + extras.lower()).extras
60 | 
61 | 
62 | def _set_requirement_extras(req: Requirement, new_extras: Set[str]) -> Requirement:
63 |     """
64 |     Returns a new requirement based on the given one, with the supplied extras. If the
65 |     given requirement already has extras those are replaced (or dropped if no new extras
66 |     are given).
67 |     """
68 |     match: Optional[re.Match[str]] = re.fullmatch(
69 |         # see https://peps.python.org/pep-0508/#complete-grammar
70 |         r"([\w\t .-]+)(\[[^\]]*\])?(.*)",
71 |         str(req),
72 |         flags=re.ASCII,
73 |     )
74 |     # ireq.req is a valid requirement so the regex should always match
75 |     assert (
76 |         match is not None
77 |     ), f"regex match on requirement {req} failed, this should never happen"
78 |     pre: Optional[str] = match.group(1)
79 |     post: Optional[str] = match.group(3)
80 |     assert (
81 |         pre is not None and post is not None
82 |     ), f"regex group selection for requirement {req} failed, this should never happen"
83 |     extras: str = "[{}]".format(",".join(sorted(new_extras)) if new_extras else "")
84 |     return get_requirement(f"{pre}{extras}{post}")
85 | 
86 | 
87 | def parse_editable(editable_req: str) -> Tuple[Optional[str], str, Set[str]]:
88 |     """Parses an editable requirement into:
89 |         - a requirement name
90 |         - an URL
91 |         - extras
92 |         - editable options
93 |     Accepted requirements:
94 |         svn+http://blahblah@rev#egg=Foobar[baz]&subdirectory=version_subdir
95 |         .[some_extra]
96 |     """
97 | 
98 |     url = editable_req
99 | 
100 |     # If a file path is specified with extras, strip off the extras.
101 |     url_no_extras, extras = _strip_extras(url)
102 | 
103 |     if os.path.isdir(url_no_extras):
104 |         # Treating it as code that has already been checked out
105 |         url_no_extras = path_to_url(url_no_extras)
106 | 
107 |     if url_no_extras.lower().startswith("file:"):
108 |         package_name = Link(url_no_extras).egg_fragment
109 |         if extras:
110 |             return (
111 |                 package_name,
112 |                 url_no_extras,
113 |                 get_requirement("placeholder" + extras.lower()).extras,
114 |             )
115 |         else:
116 |             return package_name, url_no_extras, set()
117 | 
118 |     for version_control in vcs:
119 |         if url.lower().startswith(f"{version_control}:"):
120 |             url = f"{version_control}+{url}"
121 |             break
122 | 
123 |     link = Link(url)
124 | 
125 |     if not link.is_vcs:
126 |         backends = ", ".join(vcs.all_schemes)
127 |         raise InstallationError(
128 |             f"{editable_req} is not a valid editable requirement. "
129 |             f"It should either be a path to a local project or a VCS URL "
130 |             f"(beginning with {backends})."
131 |         )
132 | 
133 |     package_name = link.egg_fragment
134 |     if not package_name:
135 |         raise InstallationError(
136 |             f"Could not detect requirement name for '{editable_req}', "
137 |             "please specify one with #egg=your_package_name"
138 |         )
139 |     return package_name, url, set()
140 | 
141 | 
142 | def check_first_requirement_in_file(filename: str) -> None:
143 |     """Check if file is parsable as a requirements file.
144 | 
145 |     This is heavily based on ``pkg_resources.parse_requirements``, but
146 |     simplified to just check the first meaningful line.
147 | 
148 |     :raises InvalidRequirement: If the first meaningful line cannot be parsed
149 |         as an requirement.
150 |     """
151 |     with open(filename, encoding="utf-8", errors="ignore") as f:
152 |         # Create a steppable iterator, so we can handle \-continuations.
153 |         lines = (
154 |             line
155 |             for line in (line.strip() for line in f)
156 |             if line and not line.startswith("#")  # Skip blank lines/comments.
157 |         )
158 | 
159 |         for line in lines:
160 |             # Drop comments -- a hash without a space may be in a URL.
161 |             if " #" in line:
162 |                 line = line[: line.find(" #")]
163 |             # If there is a line continuation, drop it, and append the next line.
164 |             if line.endswith("\\"):
165 |                 line = line[:-2].strip() + next(lines, "")
166 |             get_requirement(line)
167 |             return
168 | 
169 | 
170 | def deduce_helpful_msg(req: str) -> str:
171 |     """Returns helpful msg in case requirements file does not exist,
172 |     or cannot be parsed.
173 | 
174 |     :params req: Requirements file path
175 |     """
176 |     if not os.path.exists(req):
177 |         return f" File '{req}' does not exist."
178 |     msg = " The path does exist. "
179 |     # Try to parse and check if it is a requirements file.
180 |     try:
181 |         check_first_requirement_in_file(req)
182 |     except InvalidRequirement:
183 |         logger.debug("Cannot parse '%s' as requirements file", req)
184 |     else:
185 |         msg += (
186 |             f"The argument you provided "
187 |             f"({req}) appears to be a"
188 |             f" requirements file. If that is the"
189 |             f" case, use the '-r' flag to install"
190 |             f" the packages specified within it."
191 |         )
192 |     return msg
193 | 
194 | 
195 | @dataclass(frozen=True)
196 | class RequirementParts:
197 |     requirement: Optional[Requirement]
198 |     link: Optional[Link]
199 |     markers: Optional[Marker]
200 |     extras: Set[str]
201 | 
202 | 
203 | def parse_req_from_editable(editable_req: str) -> RequirementParts:
204 |     name, url, extras_override = parse_editable(editable_req)
205 | 
206 |     if name is not None:
207 |         try:
208 |             req: Optional[Requirement] = get_requirement(name)
209 |         except InvalidRequirement as exc:
210 |             raise InstallationError(f"Invalid requirement: {name!r}: {exc}")
211 |     else:
212 |         req = None
213 | 
214 |     link = Link(url)
215 | 
216 |     return RequirementParts(req, link, None, extras_override)
217 | 
218 | 
219 | # ---- The actual constructors follow ----
220 | 
221 | 
222 | def install_req_from_editable(
223 |     editable_req: str,
224 |     comes_from: Optional[Union[InstallRequirement, str]] = None,
225 |     *,
226 |     use_pep517: Optional[bool] = None,
227 |     isolated: bool = False,
228 |     global_options: Optional[List[str]] = None,
229 |     hash_options: Optional[Dict[str, List[str]]] = None,
230 |     constraint: bool = False,
231 |     user_supplied: bool = False,
232 |     permit_editable_wheels: bool = False,
233 |     config_settings: Optional[Dict[str, Union[str, List[str]]]] = None,
234 | ) -> InstallRequirement:
235 |     parts = parse_req_from_editable(editable_req)
236 | 
237 |     return InstallRequirement(
238 |         parts.requirement,
239 |         comes_from=comes_from,
240 |         user_supplied=user_supplied,
241 |         editable=True,
242 |         permit_editable_wheels=permit_editable_wheels,
243 |         link=parts.link,
244 |         constraint=constraint,
245 |         use_pep517=use_pep517,
246 |         isolated=isolated,
247 |         global_options=global_options,
248 |         hash_options=hash_options,
249 |         config_settings=config_settings,
250 |         extras=parts.extras,
251 |     )
252 | 
253 | 
254 | def _looks_like_path(name: str) -> bool:
255 |     """Checks whether the string "looks like" a path on the filesystem.
256 | 
257 |     This does not check whether the target actually exists, only judge from the
258 |     appearance.
259 | 
260 |     Returns true if any of the following conditions is true:
261 |     * a path separator is found (either os.path.sep or os.path.altsep);
262 |     * a dot is found (which represents the current directory).
263 |     """
264 |     if os.path.sep in name:
265 |         return True
266 |     if os.path.altsep is not None and os.path.altsep in name:
267 |         return True
268 |     if name.startswith("."):
269 |         return True
270 |     return False
271 | 
272 | 
273 | def _get_url_from_path(path: str, name: str) -> Optional[str]:
274 |     """
275 |     First, it checks whether a provided path is an installable directory. If it
276 |     is, returns the path.
277 | 
278 |     If false, check if the path is an archive file (such as a .whl).
279 |     The function checks if the path is a file. If false, if the path has
280 |     an @, it will treat it as a PEP 440 URL requirement and return the path.
281 |     """
282 |     if _looks_like_path(name) and os.path.isdir(path):
283 |         if is_installable_dir(path):
284 |             return path_to_url(path)
285 |         # TODO: The is_installable_dir test here might not be necessary
286 |         #       now that it is done in load_pyproject_toml too.
287 |         raise InstallationError(
288 |             f"Directory {name!r} is not installable. Neither 'setup.py' "
289 |             "nor 'pyproject.toml' found."
290 |         )
291 |     if not is_archive_file(path):
292 |         return None
293 |     if os.path.isfile(path):
294 |         return path_to_url(path)
295 |     urlreq_parts = name.split("@", 1)
296 |     if len(urlreq_parts) >= 2 and not _looks_like_path(urlreq_parts[0]):
297 |         # If the path contains '@' and the part before it does not look
298 |         # like a path, try to treat it as a PEP 440 URL req instead.
299 |         return None
300 |     logger.warning(
301 |         "Requirement %r looks like a filename, but the file does not exist",
302 |         name,
303 |     )
304 |     return path_to_url(path)
305 | 
306 | 
307 | def parse_req_from_line(name: str, line_source: Optional[str]) -> RequirementParts:
308 |     if is_url(name):
309 |         marker_sep = "; "
310 |     else:
311 |         marker_sep = ";"
312 |     if marker_sep in name:
313 |         name, markers_as_string = name.split(marker_sep, 1)
314 |         markers_as_string = markers_as_string.strip()
315 |         if not markers_as_string:
316 |             markers = None
317 |         else:
318 |             markers = Marker(markers_as_string)
319 |     else:
320 |         markers = None
321 |     name = name.strip()
322 |     req_as_string = None
323 |     path = os.path.normpath(os.path.abspath(name))
324 |     link = None
325 |     extras_as_string = None
326 | 
327 |     if is_url(name):
328 |         link = Link(name)
329 |     else:
330 |         p, extras_as_string = _strip_extras(path)
331 |         url = _get_url_from_path(p, name)
332 |         if url is not None:
333 |             link = Link(url)
334 | 
335 |     # it's a local file, dir, or url
336 |     if link:
337 |         # Handle relative file URLs
338 |         if link.scheme == "file" and re.search(r"\.\./", link.url):
[TRUNCATED]
```

.venv/lib/python3.13/site-packages/pip/_internal/req/req_dependency_group.py
```
1 | import sys
2 | from typing import Any, Dict, Iterable, Iterator, List, Tuple
3 | 
4 | if sys.version_info >= (3, 11):
5 |     import tomllib
6 | else:
7 |     from pip._vendor import tomli as tomllib
8 | 
9 | from pip._vendor.dependency_groups import DependencyGroupResolver
10 | 
11 | from pip._internal.exceptions import InstallationError
12 | 
13 | 
14 | def parse_dependency_groups(groups: List[Tuple[str, str]]) -> List[str]:
15 |     """
16 |     Parse dependency groups data as provided via the CLI, in a `[path:]group` syntax.
17 | 
18 |     Raises InstallationErrors if anything goes wrong.
19 |     """
20 |     resolvers = _build_resolvers(path for (path, _) in groups)
21 |     return list(_resolve_all_groups(resolvers, groups))
22 | 
23 | 
24 | def _resolve_all_groups(
25 |     resolvers: Dict[str, DependencyGroupResolver], groups: List[Tuple[str, str]]
26 | ) -> Iterator[str]:
27 |     """
28 |     Run all resolution, converting any error from `DependencyGroupResolver` into
29 |     an InstallationError.
30 |     """
31 |     for path, groupname in groups:
32 |         resolver = resolvers[path]
33 |         try:
34 |             yield from (str(req) for req in resolver.resolve(groupname))
35 |         except (ValueError, TypeError, LookupError) as e:
36 |             raise InstallationError(
37 |                 f"[dependency-groups] resolution failed for '{groupname}' "
38 |                 f"from '{path}': {e}"
39 |             ) from e
40 | 
41 | 
42 | def _build_resolvers(paths: Iterable[str]) -> Dict[str, Any]:
43 |     resolvers = {}
44 |     for path in paths:
45 |         if path in resolvers:
46 |             continue
47 | 
48 |         pyproject = _load_pyproject(path)
49 |         if "dependency-groups" not in pyproject:
50 |             raise InstallationError(
51 |                 f"[dependency-groups] table was missing from '{path}'. "
52 |                 "Cannot resolve '--group' option."
53 |             )
54 |         raw_dependency_groups = pyproject["dependency-groups"]
55 |         if not isinstance(raw_dependency_groups, dict):
56 |             raise InstallationError(
57 |                 f"[dependency-groups] table was malformed in {path}. "
58 |                 "Cannot resolve '--group' option."
59 |             )
60 | 
61 |         resolvers[path] = DependencyGroupResolver(raw_dependency_groups)
62 |     return resolvers
63 | 
64 | 
65 | def _load_pyproject(path: str) -> Dict[str, Any]:
66 |     """
67 |     This helper loads a pyproject.toml as TOML.
68 | 
69 |     It raises an InstallationError if the operation fails.
70 |     """
71 |     try:
72 |         with open(path, "rb") as fp:
73 |             return tomllib.load(fp)
74 |     except FileNotFoundError:
75 |         raise InstallationError(f"{path} not found. Cannot resolve '--group' option.")
76 |     except tomllib.TOMLDecodeError as e:
77 |         raise InstallationError(f"Error parsing {path}: {e}") from e
78 |     except OSError as e:
79 |         raise InstallationError(f"Error reading {path}: {e}") from e
```

.venv/lib/python3.13/site-packages/pip/_internal/req/req_file.py
```
1 | """
2 | Requirements file parsing
3 | """
4 | 
5 | import codecs
6 | import locale
7 | import logging
8 | import optparse
9 | import os
10 | import re
11 | import shlex
12 | import sys
13 | import urllib.parse
14 | from dataclasses import dataclass
15 | from optparse import Values
16 | from typing import (
17 |     TYPE_CHECKING,
18 |     Any,
19 |     Callable,
20 |     Dict,
21 |     Generator,
22 |     Iterable,
23 |     List,
24 |     NoReturn,
25 |     Optional,
26 |     Tuple,
27 | )
28 | 
29 | from pip._internal.cli import cmdoptions
30 | from pip._internal.exceptions import InstallationError, RequirementsFileParseError
31 | from pip._internal.models.search_scope import SearchScope
32 | 
33 | if TYPE_CHECKING:
34 |     from pip._internal.index.package_finder import PackageFinder
35 |     from pip._internal.network.session import PipSession
36 | 
37 | __all__ = ["parse_requirements"]
38 | 
39 | ReqFileLines = Iterable[Tuple[int, str]]
40 | 
41 | LineParser = Callable[[str], Tuple[str, Values]]
42 | 
43 | SCHEME_RE = re.compile(r"^(http|https|file):", re.I)
44 | COMMENT_RE = re.compile(r"(^|\s+)#.*$")
45 | 
46 | # Matches environment variable-style values in '${MY_VARIABLE_1}' with the
47 | # variable name consisting of only uppercase letters, digits or the '_'
48 | # (underscore). This follows the POSIX standard defined in IEEE Std 1003.1,
49 | # 2013 Edition.
50 | ENV_VAR_RE = re.compile(r"(?P<var>\$\{(?P<name>[A-Z0-9_]+)\})")
51 | 
52 | SUPPORTED_OPTIONS: List[Callable[..., optparse.Option]] = [
53 |     cmdoptions.index_url,
54 |     cmdoptions.extra_index_url,
55 |     cmdoptions.no_index,
56 |     cmdoptions.constraints,
57 |     cmdoptions.requirements,
58 |     cmdoptions.editable,
59 |     cmdoptions.find_links,
60 |     cmdoptions.no_binary,
61 |     cmdoptions.only_binary,
62 |     cmdoptions.prefer_binary,
63 |     cmdoptions.require_hashes,
64 |     cmdoptions.pre,
65 |     cmdoptions.trusted_host,
66 |     cmdoptions.use_new_feature,
67 | ]
68 | 
69 | # options to be passed to requirements
70 | SUPPORTED_OPTIONS_REQ: List[Callable[..., optparse.Option]] = [
71 |     cmdoptions.global_options,
72 |     cmdoptions.hash,
73 |     cmdoptions.config_settings,
74 | ]
75 | 
76 | SUPPORTED_OPTIONS_EDITABLE_REQ: List[Callable[..., optparse.Option]] = [
77 |     cmdoptions.config_settings,
78 | ]
79 | 
80 | 
81 | # the 'dest' string values
82 | SUPPORTED_OPTIONS_REQ_DEST = [str(o().dest) for o in SUPPORTED_OPTIONS_REQ]
83 | SUPPORTED_OPTIONS_EDITABLE_REQ_DEST = [
84 |     str(o().dest) for o in SUPPORTED_OPTIONS_EDITABLE_REQ
85 | ]
86 | 
87 | # order of BOMS is important: codecs.BOM_UTF16_LE is a prefix of codecs.BOM_UTF32_LE
88 | # so data.startswith(BOM_UTF16_LE) would be true for UTF32_LE data
89 | BOMS: List[Tuple[bytes, str]] = [
90 |     (codecs.BOM_UTF8, "utf-8"),
91 |     (codecs.BOM_UTF32, "utf-32"),
92 |     (codecs.BOM_UTF32_BE, "utf-32-be"),
93 |     (codecs.BOM_UTF32_LE, "utf-32-le"),
94 |     (codecs.BOM_UTF16, "utf-16"),
95 |     (codecs.BOM_UTF16_BE, "utf-16-be"),
96 |     (codecs.BOM_UTF16_LE, "utf-16-le"),
97 | ]
98 | 
99 | PEP263_ENCODING_RE = re.compile(rb"coding[:=]\s*([-\w.]+)")
100 | DEFAULT_ENCODING = "utf-8"
101 | 
102 | logger = logging.getLogger(__name__)
103 | 
104 | 
105 | @dataclass(frozen=True)
106 | class ParsedRequirement:
107 |     # TODO: replace this with slots=True when dropping Python 3.9 support.
108 |     __slots__ = (
109 |         "requirement",
110 |         "is_editable",
111 |         "comes_from",
112 |         "constraint",
113 |         "options",
114 |         "line_source",
115 |     )
116 | 
117 |     requirement: str
118 |     is_editable: bool
119 |     comes_from: str
120 |     constraint: bool
121 |     options: Optional[Dict[str, Any]]
122 |     line_source: Optional[str]
123 | 
124 | 
125 | @dataclass(frozen=True)
126 | class ParsedLine:
127 |     __slots__ = ("filename", "lineno", "args", "opts", "constraint")
128 | 
129 |     filename: str
130 |     lineno: int
131 |     args: str
132 |     opts: Values
133 |     constraint: bool
134 | 
135 |     @property
136 |     def is_editable(self) -> bool:
137 |         return bool(self.opts.editables)
138 | 
139 |     @property
140 |     def requirement(self) -> Optional[str]:
141 |         if self.args:
142 |             return self.args
143 |         elif self.is_editable:
144 |             # We don't support multiple -e on one line
145 |             return self.opts.editables[0]
146 |         return None
147 | 
148 | 
149 | def parse_requirements(
150 |     filename: str,
151 |     session: "PipSession",
152 |     finder: Optional["PackageFinder"] = None,
153 |     options: Optional[optparse.Values] = None,
154 |     constraint: bool = False,
155 | ) -> Generator[ParsedRequirement, None, None]:
156 |     """Parse a requirements file and yield ParsedRequirement instances.
157 | 
158 |     :param filename:    Path or url of requirements file.
159 |     :param session:     PipSession instance.
160 |     :param finder:      Instance of pip.index.PackageFinder.
161 |     :param options:     cli options.
162 |     :param constraint:  If true, parsing a constraint file rather than
163 |         requirements file.
164 |     """
165 |     line_parser = get_line_parser(finder)
166 |     parser = RequirementsFileParser(session, line_parser)
167 | 
168 |     for parsed_line in parser.parse(filename, constraint):
169 |         parsed_req = handle_line(
170 |             parsed_line, options=options, finder=finder, session=session
171 |         )
172 |         if parsed_req is not None:
173 |             yield parsed_req
174 | 
175 | 
176 | def preprocess(content: str) -> ReqFileLines:
177 |     """Split, filter, and join lines, and return a line iterator
178 | 
179 |     :param content: the content of the requirements file
180 |     """
181 |     lines_enum: ReqFileLines = enumerate(content.splitlines(), start=1)
182 |     lines_enum = join_lines(lines_enum)
183 |     lines_enum = ignore_comments(lines_enum)
184 |     lines_enum = expand_env_variables(lines_enum)
185 |     return lines_enum
186 | 
187 | 
188 | def handle_requirement_line(
189 |     line: ParsedLine,
190 |     options: Optional[optparse.Values] = None,
191 | ) -> ParsedRequirement:
192 |     # preserve for the nested code path
193 |     line_comes_from = "{} {} (line {})".format(
194 |         "-c" if line.constraint else "-r",
195 |         line.filename,
196 |         line.lineno,
197 |     )
198 | 
199 |     assert line.requirement is not None
200 | 
201 |     # get the options that apply to requirements
202 |     if line.is_editable:
203 |         supported_dest = SUPPORTED_OPTIONS_EDITABLE_REQ_DEST
204 |     else:
205 |         supported_dest = SUPPORTED_OPTIONS_REQ_DEST
206 |     req_options = {}
207 |     for dest in supported_dest:
208 |         if dest in line.opts.__dict__ and line.opts.__dict__[dest]:
209 |             req_options[dest] = line.opts.__dict__[dest]
210 | 
211 |     line_source = f"line {line.lineno} of {line.filename}"
212 |     return ParsedRequirement(
213 |         requirement=line.requirement,
214 |         is_editable=line.is_editable,
215 |         comes_from=line_comes_from,
216 |         constraint=line.constraint,
217 |         options=req_options,
218 |         line_source=line_source,
219 |     )
220 | 
221 | 
222 | def handle_option_line(
223 |     opts: Values,
224 |     filename: str,
225 |     lineno: int,
226 |     finder: Optional["PackageFinder"] = None,
227 |     options: Optional[optparse.Values] = None,
228 |     session: Optional["PipSession"] = None,
229 | ) -> None:
230 |     if opts.hashes:
231 |         logger.warning(
232 |             "%s line %s has --hash but no requirement, and will be ignored.",
233 |             filename,
234 |             lineno,
235 |         )
236 | 
237 |     if options:
238 |         # percolate options upward
239 |         if opts.require_hashes:
240 |             options.require_hashes = opts.require_hashes
241 |         if opts.features_enabled:
242 |             options.features_enabled.extend(
243 |                 f for f in opts.features_enabled if f not in options.features_enabled
244 |             )
245 | 
246 |     # set finder options
247 |     if finder:
248 |         find_links = finder.find_links
249 |         index_urls = finder.index_urls
250 |         no_index = finder.search_scope.no_index
251 |         if opts.no_index is True:
252 |             no_index = True
253 |             index_urls = []
254 |         if opts.index_url and not no_index:
255 |             index_urls = [opts.index_url]
256 |         if opts.extra_index_urls and not no_index:
257 |             index_urls.extend(opts.extra_index_urls)
258 |         if opts.find_links:
259 |             # FIXME: it would be nice to keep track of the source
260 |             # of the find_links: support a find-links local path
261 |             # relative to a requirements file.
262 |             value = opts.find_links[0]
263 |             req_dir = os.path.dirname(os.path.abspath(filename))
264 |             relative_to_reqs_file = os.path.join(req_dir, value)
265 |             if os.path.exists(relative_to_reqs_file):
266 |                 value = relative_to_reqs_file
267 |             find_links.append(value)
268 | 
269 |         if session:
270 |             # We need to update the auth urls in session
271 |             session.update_index_urls(index_urls)
272 | 
273 |         search_scope = SearchScope(
274 |             find_links=find_links,
275 |             index_urls=index_urls,
276 |             no_index=no_index,
277 |         )
278 |         finder.search_scope = search_scope
279 | 
280 |         if opts.pre:
281 |             finder.set_allow_all_prereleases()
282 | 
283 |         if opts.prefer_binary:
284 |             finder.set_prefer_binary()
285 | 
286 |         if session:
287 |             for host in opts.trusted_hosts or []:
288 |                 source = f"line {lineno} of {filename}"
289 |                 session.add_trusted_host(host, source=source)
290 | 
291 | 
292 | def handle_line(
293 |     line: ParsedLine,
294 |     options: Optional[optparse.Values] = None,
295 |     finder: Optional["PackageFinder"] = None,
296 |     session: Optional["PipSession"] = None,
297 | ) -> Optional[ParsedRequirement]:
298 |     """Handle a single parsed requirements line; This can result in
299 |     creating/yielding requirements, or updating the finder.
300 | 
301 |     :param line:        The parsed line to be processed.
302 |     :param options:     CLI options.
303 |     :param finder:      The finder - updated by non-requirement lines.
304 |     :param session:     The session - updated by non-requirement lines.
305 | 
306 |     Returns a ParsedRequirement object if the line is a requirement line,
307 |     otherwise returns None.
308 | 
309 |     For lines that contain requirements, the only options that have an effect
310 |     are from SUPPORTED_OPTIONS_REQ, and they are scoped to the
311 |     requirement. Other options from SUPPORTED_OPTIONS may be present, but are
312 |     ignored.
313 | 
314 |     For lines that do not contain requirements, the only options that have an
315 |     effect are from SUPPORTED_OPTIONS. Options from SUPPORTED_OPTIONS_REQ may
316 |     be present, but are ignored. These lines may contain multiple options
317 |     (although our docs imply only one is supported), and all our parsed and
318 |     affect the finder.
319 |     """
320 | 
321 |     if line.requirement is not None:
322 |         parsed_req = handle_requirement_line(line, options)
323 |         return parsed_req
324 |     else:
325 |         handle_option_line(
326 |             line.opts,
327 |             line.filename,
328 |             line.lineno,
329 |             finder,
330 |             options,
331 |             session,
332 |         )
333 |         return None
334 | 
335 | 
336 | class RequirementsFileParser:
337 |     def __init__(
338 |         self,
339 |         session: "PipSession",
340 |         line_parser: LineParser,
341 |     ) -> None:
342 |         self._session = session
343 |         self._line_parser = line_parser
344 | 
345 |     def parse(
346 |         self, filename: str, constraint: bool
347 |     ) -> Generator[ParsedLine, None, None]:
348 |         """Parse a given file, yielding parsed lines."""
349 |         yield from self._parse_and_recurse(
350 |             filename, constraint, [{os.path.abspath(filename): None}]
351 |         )
352 | 
353 |     def _parse_and_recurse(
354 |         self,
355 |         filename: str,
356 |         constraint: bool,
357 |         parsed_files_stack: List[Dict[str, Optional[str]]],
358 |     ) -> Generator[ParsedLine, None, None]:
359 |         for line in self._parse_file(filename, constraint):
360 |             if line.requirement is None and (
361 |                 line.opts.requirements or line.opts.constraints
362 |             ):
363 |                 # parse a nested requirements file
364 |                 if line.opts.requirements:
365 |                     req_path = line.opts.requirements[0]
366 |                     nested_constraint = False
367 |                 else:
368 |                     req_path = line.opts.constraints[0]
369 |                     nested_constraint = True
370 | 
371 |                 # original file is over http
372 |                 if SCHEME_RE.search(filename):
373 |                     # do a url join so relative paths work
374 |                     req_path = urllib.parse.urljoin(filename, req_path)
375 |                 # original file and nested file are paths
376 |                 elif not SCHEME_RE.search(req_path):
377 |                     # do a join so relative paths work
378 |                     # and then abspath so that we can identify recursive references
379 |                     req_path = os.path.abspath(
[TRUNCATED]
```

.venv/lib/python3.13/site-packages/pip/_internal/req/req_install.py
```
1 | import functools
2 | import logging
3 | import os
4 | import shutil
5 | import sys
6 | import uuid
7 | import zipfile
8 | from optparse import Values
9 | from pathlib import Path
10 | from typing import Any, Collection, Dict, Iterable, List, Optional, Sequence, Union
11 | 
12 | from pip._vendor.packaging.markers import Marker
13 | from pip._vendor.packaging.requirements import Requirement
14 | from pip._vendor.packaging.specifiers import SpecifierSet
15 | from pip._vendor.packaging.utils import canonicalize_name
16 | from pip._vendor.packaging.version import Version
17 | from pip._vendor.packaging.version import parse as parse_version
18 | from pip._vendor.pyproject_hooks import BuildBackendHookCaller
19 | 
20 | from pip._internal.build_env import BuildEnvironment, NoOpBuildEnvironment
21 | from pip._internal.exceptions import InstallationError, PreviousBuildDirError
22 | from pip._internal.locations import get_scheme
23 | from pip._internal.metadata import (
24 |     BaseDistribution,
25 |     get_default_environment,
26 |     get_directory_distribution,
27 |     get_wheel_distribution,
28 | )
29 | from pip._internal.metadata.base import FilesystemWheel
30 | from pip._internal.models.direct_url import DirectUrl
31 | from pip._internal.models.link import Link
32 | from pip._internal.operations.build.metadata import generate_metadata
33 | from pip._internal.operations.build.metadata_editable import generate_editable_metadata
34 | from pip._internal.operations.build.metadata_legacy import (
35 |     generate_metadata as generate_metadata_legacy,
36 | )
37 | from pip._internal.operations.install.editable_legacy import (
38 |     install_editable as install_editable_legacy,
39 | )
40 | from pip._internal.operations.install.wheel import install_wheel
41 | from pip._internal.pyproject import load_pyproject_toml, make_pyproject_path
42 | from pip._internal.req.req_uninstall import UninstallPathSet
43 | from pip._internal.utils.deprecation import deprecated
44 | from pip._internal.utils.hashes import Hashes
45 | from pip._internal.utils.misc import (
46 |     ConfiguredBuildBackendHookCaller,
47 |     ask_path_exists,
48 |     backup_dir,
49 |     display_path,
50 |     hide_url,
51 |     is_installable_dir,
52 |     redact_auth_from_requirement,
53 |     redact_auth_from_url,
54 | )
55 | from pip._internal.utils.packaging import get_requirement
56 | from pip._internal.utils.subprocess import runner_with_spinner_message
57 | from pip._internal.utils.temp_dir import TempDirectory, tempdir_kinds
58 | from pip._internal.utils.unpacking import unpack_file
59 | from pip._internal.utils.virtualenv import running_under_virtualenv
60 | from pip._internal.vcs import vcs
61 | 
62 | logger = logging.getLogger(__name__)
63 | 
64 | 
65 | class InstallRequirement:
66 |     """
67 |     Represents something that may be installed later on, may have information
68 |     about where to fetch the relevant requirement and also contains logic for
69 |     installing the said requirement.
70 |     """
71 | 
72 |     def __init__(
73 |         self,
74 |         req: Optional[Requirement],
75 |         comes_from: Optional[Union[str, "InstallRequirement"]],
76 |         editable: bool = False,
77 |         link: Optional[Link] = None,
78 |         markers: Optional[Marker] = None,
79 |         use_pep517: Optional[bool] = None,
80 |         isolated: bool = False,
81 |         *,
82 |         global_options: Optional[List[str]] = None,
83 |         hash_options: Optional[Dict[str, List[str]]] = None,
84 |         config_settings: Optional[Dict[str, Union[str, List[str]]]] = None,
85 |         constraint: bool = False,
86 |         extras: Collection[str] = (),
87 |         user_supplied: bool = False,
88 |         permit_editable_wheels: bool = False,
89 |     ) -> None:
90 |         assert req is None or isinstance(req, Requirement), req
91 |         self.req = req
92 |         self.comes_from = comes_from
93 |         self.constraint = constraint
94 |         self.editable = editable
95 |         self.permit_editable_wheels = permit_editable_wheels
96 | 
97 |         # source_dir is the local directory where the linked requirement is
98 |         # located, or unpacked. In case unpacking is needed, creating and
99 |         # populating source_dir is done by the RequirementPreparer. Note this
100 |         # is not necessarily the directory where pyproject.toml or setup.py is
101 |         # located - that one is obtained via unpacked_source_directory.
102 |         self.source_dir: Optional[str] = None
103 |         if self.editable:
104 |             assert link
105 |             if link.is_file:
106 |                 self.source_dir = os.path.normpath(os.path.abspath(link.file_path))
107 | 
108 |         # original_link is the direct URL that was provided by the user for the
109 |         # requirement, either directly or via a constraints file.
110 |         if link is None and req and req.url:
111 |             # PEP 508 URL requirement
112 |             link = Link(req.url)
113 |         self.link = self.original_link = link
114 | 
115 |         # When this InstallRequirement is a wheel obtained from the cache of locally
116 |         # built wheels, this is the source link corresponding to the cache entry, which
117 |         # was used to download and build the cached wheel.
118 |         self.cached_wheel_source_link: Optional[Link] = None
119 | 
120 |         # Information about the location of the artifact that was downloaded . This
121 |         # property is guaranteed to be set in resolver results.
122 |         self.download_info: Optional[DirectUrl] = None
123 | 
124 |         # Path to any downloaded or already-existing package.
125 |         self.local_file_path: Optional[str] = None
126 |         if self.link and self.link.is_file:
127 |             self.local_file_path = self.link.file_path
128 | 
129 |         if extras:
130 |             self.extras = extras
131 |         elif req:
132 |             self.extras = req.extras
133 |         else:
134 |             self.extras = set()
135 |         if markers is None and req:
136 |             markers = req.marker
137 |         self.markers = markers
138 | 
139 |         # This holds the Distribution object if this requirement is already installed.
140 |         self.satisfied_by: Optional[BaseDistribution] = None
141 |         # Whether the installation process should try to uninstall an existing
142 |         # distribution before installing this requirement.
143 |         self.should_reinstall = False
144 |         # Temporary build location
145 |         self._temp_build_dir: Optional[TempDirectory] = None
146 |         # Set to True after successful installation
147 |         self.install_succeeded: Optional[bool] = None
148 |         # Supplied options
149 |         self.global_options = global_options if global_options else []
150 |         self.hash_options = hash_options if hash_options else {}
151 |         self.config_settings = config_settings
152 |         # Set to True after successful preparation of this requirement
153 |         self.prepared = False
154 |         # User supplied requirement are explicitly requested for installation
155 |         # by the user via CLI arguments or requirements files, as opposed to,
156 |         # e.g. dependencies, extras or constraints.
157 |         self.user_supplied = user_supplied
158 | 
159 |         self.isolated = isolated
160 |         self.build_env: BuildEnvironment = NoOpBuildEnvironment()
161 | 
162 |         # For PEP 517, the directory where we request the project metadata
163 |         # gets stored. We need this to pass to build_wheel, so the backend
164 |         # can ensure that the wheel matches the metadata (see the PEP for
165 |         # details).
166 |         self.metadata_directory: Optional[str] = None
167 | 
168 |         # The static build requirements (from pyproject.toml)
169 |         self.pyproject_requires: Optional[List[str]] = None
170 | 
171 |         # Build requirements that we will check are available
172 |         self.requirements_to_check: List[str] = []
173 | 
174 |         # The PEP 517 backend we should use to build the project
175 |         self.pep517_backend: Optional[BuildBackendHookCaller] = None
176 | 
177 |         # Are we using PEP 517 for this requirement?
178 |         # After pyproject.toml has been loaded, the only valid values are True
179 |         # and False. Before loading, None is valid (meaning "use the default").
180 |         # Setting an explicit value before loading pyproject.toml is supported,
181 |         # but after loading this flag should be treated as read only.
182 |         self.use_pep517 = use_pep517
183 | 
184 |         # If config settings are provided, enforce PEP 517.
185 |         if self.config_settings:
186 |             if self.use_pep517 is False:
187 |                 logger.warning(
188 |                     "--no-use-pep517 ignored for %s "
189 |                     "because --config-settings are specified.",
190 |                     self,
191 |                 )
192 |             self.use_pep517 = True
193 | 
194 |         # This requirement needs more preparation before it can be built
195 |         self.needs_more_preparation = False
196 | 
197 |         # This requirement needs to be unpacked before it can be installed.
198 |         self._archive_source: Optional[Path] = None
199 | 
200 |     def __str__(self) -> str:
201 |         if self.req:
202 |             s = redact_auth_from_requirement(self.req)
203 |             if self.link:
204 |                 s += f" from {redact_auth_from_url(self.link.url)}"
205 |         elif self.link:
206 |             s = redact_auth_from_url(self.link.url)
207 |         else:
208 |             s = "<InstallRequirement>"
209 |         if self.satisfied_by is not None:
210 |             if self.satisfied_by.location is not None:
211 |                 location = display_path(self.satisfied_by.location)
212 |             else:
213 |                 location = "<memory>"
214 |             s += f" in {location}"
215 |         if self.comes_from:
216 |             if isinstance(self.comes_from, str):
217 |                 comes_from: Optional[str] = self.comes_from
218 |             else:
219 |                 comes_from = self.comes_from.from_path()
220 |             if comes_from:
221 |                 s += f" (from {comes_from})"
222 |         return s
223 | 
224 |     def __repr__(self) -> str:
225 |         return (
226 |             f"<{self.__class__.__name__} object: "
227 |             f"{str(self)} editable={self.editable!r}>"
228 |         )
229 | 
230 |     def format_debug(self) -> str:
231 |         """An un-tested helper for getting state, for debugging."""
232 |         attributes = vars(self)
233 |         names = sorted(attributes)
234 | 
235 |         state = (f"{attr}={attributes[attr]!r}" for attr in sorted(names))
236 |         return "<{name} object: {{{state}}}>".format(
237 |             name=self.__class__.__name__,
238 |             state=", ".join(state),
239 |         )
240 | 
241 |     # Things that are valid for all kinds of requirements?
242 |     @property
243 |     def name(self) -> Optional[str]:
244 |         if self.req is None:
245 |             return None
246 |         return self.req.name
247 | 
248 |     @functools.cached_property
249 |     def supports_pyproject_editable(self) -> bool:
250 |         if not self.use_pep517:
251 |             return False
252 |         assert self.pep517_backend
253 |         with self.build_env:
254 |             runner = runner_with_spinner_message(
255 |                 "Checking if build backend supports build_editable"
256 |             )
257 |             with self.pep517_backend.subprocess_runner(runner):
258 |                 return "build_editable" in self.pep517_backend._supported_features()
259 | 
260 |     @property
261 |     def specifier(self) -> SpecifierSet:
262 |         assert self.req is not None
263 |         return self.req.specifier
264 | 
265 |     @property
266 |     def is_direct(self) -> bool:
267 |         """Whether this requirement was specified as a direct URL."""
268 |         return self.original_link is not None
269 | 
270 |     @property
271 |     def is_pinned(self) -> bool:
272 |         """Return whether I am pinned to an exact version.
273 | 
274 |         For example, some-package==1.2 is pinned; some-package>1.2 is not.
275 |         """
276 |         assert self.req is not None
277 |         specifiers = self.req.specifier
278 |         return len(specifiers) == 1 and next(iter(specifiers)).operator in {"==", "==="}
279 | 
280 |     def match_markers(self, extras_requested: Optional[Iterable[str]] = None) -> bool:
281 |         if not extras_requested:
282 |             # Provide an extra to safely evaluate the markers
283 |             # without matching any extra
284 |             extras_requested = ("",)
285 |         if self.markers is not None:
286 |             return any(
287 |                 self.markers.evaluate({"extra": extra}) for extra in extras_requested
288 |             )
289 |         else:
290 |             return True
291 | 
292 |     @property
293 |     def has_hash_options(self) -> bool:
294 |         """Return whether any known-good hashes are specified as options.
295 | 
296 |         These activate --require-hashes mode; hashes specified as part of a
297 |         URL do not.
298 | 
299 |         """
300 |         return bool(self.hash_options)
301 | 
302 |     def hashes(self, trust_internet: bool = True) -> Hashes:
303 |         """Return a hash-comparer that considers my option- and URL-based
304 |         hashes to be known-good.
305 | 
306 |         Hashes in URLs--ones embedded in the requirements file, not ones
307 |         downloaded from an index server--are almost peers with ones from
308 |         flags. They satisfy --require-hashes (whether it was implicitly or
309 |         explicitly activated) but do not activate it. md5 and sha224 are not
310 |         allowed in flags, which should nudge people toward good algos. We
[TRUNCATED]
```

.venv/lib/python3.13/site-packages/pip/_internal/req/req_set.py
```
1 | import logging
2 | from collections import OrderedDict
3 | from typing import Dict, List
4 | 
5 | from pip._vendor.packaging.utils import canonicalize_name
6 | 
7 | from pip._internal.req.req_install import InstallRequirement
8 | 
9 | logger = logging.getLogger(__name__)
10 | 
11 | 
12 | class RequirementSet:
13 |     def __init__(self, check_supported_wheels: bool = True) -> None:
14 |         """Create a RequirementSet."""
15 | 
16 |         self.requirements: Dict[str, InstallRequirement] = OrderedDict()
17 |         self.check_supported_wheels = check_supported_wheels
18 | 
19 |         self.unnamed_requirements: List[InstallRequirement] = []
20 | 
21 |     def __str__(self) -> str:
22 |         requirements = sorted(
23 |             (req for req in self.requirements.values() if not req.comes_from),
24 |             key=lambda req: canonicalize_name(req.name or ""),
25 |         )
26 |         return " ".join(str(req.req) for req in requirements)
27 | 
28 |     def __repr__(self) -> str:
29 |         requirements = sorted(
30 |             self.requirements.values(),
31 |             key=lambda req: canonicalize_name(req.name or ""),
32 |         )
33 | 
34 |         format_string = "<{classname} object; {count} requirement(s): {reqs}>"
35 |         return format_string.format(
36 |             classname=self.__class__.__name__,
37 |             count=len(requirements),
38 |             reqs=", ".join(str(req.req) for req in requirements),
39 |         )
40 | 
41 |     def add_unnamed_requirement(self, install_req: InstallRequirement) -> None:
42 |         assert not install_req.name
43 |         self.unnamed_requirements.append(install_req)
44 | 
45 |     def add_named_requirement(self, install_req: InstallRequirement) -> None:
46 |         assert install_req.name
47 | 
48 |         project_name = canonicalize_name(install_req.name)
49 |         self.requirements[project_name] = install_req
50 | 
51 |     def has_requirement(self, name: str) -> bool:
52 |         project_name = canonicalize_name(name)
53 | 
54 |         return (
55 |             project_name in self.requirements
56 |             and not self.requirements[project_name].constraint
57 |         )
58 | 
59 |     def get_requirement(self, name: str) -> InstallRequirement:
60 |         project_name = canonicalize_name(name)
61 | 
62 |         if project_name in self.requirements:
63 |             return self.requirements[project_name]
64 | 
65 |         raise KeyError(f"No project with the name {name!r}")
66 | 
67 |     @property
68 |     def all_requirements(self) -> List[InstallRequirement]:
69 |         return self.unnamed_requirements + list(self.requirements.values())
70 | 
71 |     @property
72 |     def requirements_to_install(self) -> List[InstallRequirement]:
73 |         """Return the list of requirements that need to be installed.
74 | 
75 |         TODO remove this property together with the legacy resolver, since the new
76 |              resolver only returns requirements that need to be installed.
77 |         """
78 |         return [
79 |             install_req
80 |             for install_req in self.all_requirements
81 |             if not install_req.constraint and not install_req.satisfied_by
82 |         ]
```

.venv/lib/python3.13/site-packages/pip/_internal/req/req_uninstall.py
```
1 | import functools
2 | import os
3 | import sys
4 | import sysconfig
5 | from importlib.util import cache_from_source
6 | from typing import Any, Callable, Dict, Generator, Iterable, List, Optional, Set, Tuple
7 | 
8 | from pip._internal.exceptions import LegacyDistutilsInstall, UninstallMissingRecord
9 | from pip._internal.locations import get_bin_prefix, get_bin_user
10 | from pip._internal.metadata import BaseDistribution
11 | from pip._internal.utils.compat import WINDOWS
12 | from pip._internal.utils.egg_link import egg_link_path_from_location
13 | from pip._internal.utils.logging import getLogger, indent_log
14 | from pip._internal.utils.misc import ask, normalize_path, renames, rmtree
15 | from pip._internal.utils.temp_dir import AdjacentTempDirectory, TempDirectory
16 | from pip._internal.utils.virtualenv import running_under_virtualenv
17 | 
18 | logger = getLogger(__name__)
19 | 
20 | 
21 | def _script_names(
22 |     bin_dir: str, script_name: str, is_gui: bool
23 | ) -> Generator[str, None, None]:
24 |     """Create the fully qualified name of the files created by
25 |     {console,gui}_scripts for the given ``dist``.
26 |     Returns the list of file names
27 |     """
28 |     exe_name = os.path.join(bin_dir, script_name)
29 |     yield exe_name
30 |     if not WINDOWS:
31 |         return
32 |     yield f"{exe_name}.exe"
33 |     yield f"{exe_name}.exe.manifest"
34 |     if is_gui:
35 |         yield f"{exe_name}-script.pyw"
36 |     else:
37 |         yield f"{exe_name}-script.py"
38 | 
39 | 
40 | def _unique(
41 |     fn: Callable[..., Generator[Any, None, None]],
42 | ) -> Callable[..., Generator[Any, None, None]]:
43 |     @functools.wraps(fn)
44 |     def unique(*args: Any, **kw: Any) -> Generator[Any, None, None]:
45 |         seen: Set[Any] = set()
46 |         for item in fn(*args, **kw):
47 |             if item not in seen:
48 |                 seen.add(item)
49 |                 yield item
50 | 
51 |     return unique
52 | 
53 | 
54 | @_unique
55 | def uninstallation_paths(dist: BaseDistribution) -> Generator[str, None, None]:
56 |     """
57 |     Yield all the uninstallation paths for dist based on RECORD-without-.py[co]
58 | 
59 |     Yield paths to all the files in RECORD. For each .py file in RECORD, add
60 |     the .pyc and .pyo in the same directory.
61 | 
62 |     UninstallPathSet.add() takes care of the __pycache__ .py[co].
63 | 
64 |     If RECORD is not found, raises an error,
65 |     with possible information from the INSTALLER file.
66 | 
67 |     https://packaging.python.org/specifications/recording-installed-packages/
68 |     """
69 |     location = dist.location
70 |     assert location is not None, "not installed"
71 | 
72 |     entries = dist.iter_declared_entries()
73 |     if entries is None:
74 |         raise UninstallMissingRecord(distribution=dist)
75 | 
76 |     for entry in entries:
77 |         path = os.path.join(location, entry)
78 |         yield path
79 |         if path.endswith(".py"):
80 |             dn, fn = os.path.split(path)
81 |             base = fn[:-3]
82 |             path = os.path.join(dn, base + ".pyc")
83 |             yield path
84 |             path = os.path.join(dn, base + ".pyo")
85 |             yield path
86 | 
87 | 
88 | def compact(paths: Iterable[str]) -> Set[str]:
89 |     """Compact a path set to contain the minimal number of paths
90 |     necessary to contain all paths in the set. If /a/path/ and
91 |     /a/path/to/a/file.txt are both in the set, leave only the
92 |     shorter path."""
93 | 
94 |     sep = os.path.sep
95 |     short_paths: Set[str] = set()
96 |     for path in sorted(paths, key=len):
97 |         should_skip = any(
98 |             path.startswith(shortpath.rstrip("*"))
99 |             and path[len(shortpath.rstrip("*").rstrip(sep))] == sep
100 |             for shortpath in short_paths
101 |         )
102 |         if not should_skip:
103 |             short_paths.add(path)
104 |     return short_paths
105 | 
106 | 
107 | def compress_for_rename(paths: Iterable[str]) -> Set[str]:
108 |     """Returns a set containing the paths that need to be renamed.
109 | 
110 |     This set may include directories when the original sequence of paths
111 |     included every file on disk.
112 |     """
113 |     case_map = {os.path.normcase(p): p for p in paths}
114 |     remaining = set(case_map)
115 |     unchecked = sorted({os.path.split(p)[0] for p in case_map.values()}, key=len)
116 |     wildcards: Set[str] = set()
117 | 
118 |     def norm_join(*a: str) -> str:
119 |         return os.path.normcase(os.path.join(*a))
120 | 
121 |     for root in unchecked:
122 |         if any(os.path.normcase(root).startswith(w) for w in wildcards):
123 |             # This directory has already been handled.
124 |             continue
125 | 
126 |         all_files: Set[str] = set()
127 |         all_subdirs: Set[str] = set()
128 |         for dirname, subdirs, files in os.walk(root):
129 |             all_subdirs.update(norm_join(root, dirname, d) for d in subdirs)
130 |             all_files.update(norm_join(root, dirname, f) for f in files)
131 |         # If all the files we found are in our remaining set of files to
132 |         # remove, then remove them from the latter set and add a wildcard
133 |         # for the directory.
134 |         if not (all_files - remaining):
135 |             remaining.difference_update(all_files)
136 |             wildcards.add(root + os.sep)
137 | 
138 |     return set(map(case_map.__getitem__, remaining)) | wildcards
139 | 
140 | 
141 | def compress_for_output_listing(paths: Iterable[str]) -> Tuple[Set[str], Set[str]]:
142 |     """Returns a tuple of 2 sets of which paths to display to user
143 | 
144 |     The first set contains paths that would be deleted. Files of a package
145 |     are not added and the top-level directory of the package has a '*' added
146 |     at the end - to signify that all it's contents are removed.
147 | 
148 |     The second set contains files that would have been skipped in the above
149 |     folders.
150 |     """
151 | 
152 |     will_remove = set(paths)
153 |     will_skip = set()
154 | 
155 |     # Determine folders and files
156 |     folders = set()
157 |     files = set()
158 |     for path in will_remove:
159 |         if path.endswith(".pyc"):
160 |             continue
161 |         if path.endswith("__init__.py") or ".dist-info" in path:
162 |             folders.add(os.path.dirname(path))
163 |         files.add(path)
164 | 
165 |     _normcased_files = set(map(os.path.normcase, files))
166 | 
167 |     folders = compact(folders)
168 | 
169 |     # This walks the tree using os.walk to not miss extra folders
170 |     # that might get added.
171 |     for folder in folders:
172 |         for dirpath, _, dirfiles in os.walk(folder):
173 |             for fname in dirfiles:
174 |                 if fname.endswith(".pyc"):
175 |                     continue
176 | 
177 |                 file_ = os.path.join(dirpath, fname)
178 |                 if (
179 |                     os.path.isfile(file_)
180 |                     and os.path.normcase(file_) not in _normcased_files
181 |                 ):
182 |                     # We are skipping this file. Add it to the set.
183 |                     will_skip.add(file_)
184 | 
185 |     will_remove = files | {os.path.join(folder, "*") for folder in folders}
186 | 
187 |     return will_remove, will_skip
188 | 
189 | 
190 | class StashedUninstallPathSet:
191 |     """A set of file rename operations to stash files while
192 |     tentatively uninstalling them."""
193 | 
194 |     def __init__(self) -> None:
195 |         # Mapping from source file root to [Adjacent]TempDirectory
196 |         # for files under that directory.
197 |         self._save_dirs: Dict[str, TempDirectory] = {}
198 |         # (old path, new path) tuples for each move that may need
199 |         # to be undone.
200 |         self._moves: List[Tuple[str, str]] = []
201 | 
202 |     def _get_directory_stash(self, path: str) -> str:
203 |         """Stashes a directory.
204 | 
205 |         Directories are stashed adjacent to their original location if
206 |         possible, or else moved/copied into the user's temp dir."""
207 | 
208 |         try:
209 |             save_dir: TempDirectory = AdjacentTempDirectory(path)
210 |         except OSError:
211 |             save_dir = TempDirectory(kind="uninstall")
212 |         self._save_dirs[os.path.normcase(path)] = save_dir
213 | 
214 |         return save_dir.path
215 | 
216 |     def _get_file_stash(self, path: str) -> str:
217 |         """Stashes a file.
218 | 
219 |         If no root has been provided, one will be created for the directory
220 |         in the user's temp directory."""
221 |         path = os.path.normcase(path)
222 |         head, old_head = os.path.dirname(path), None
223 |         save_dir = None
224 | 
225 |         while head != old_head:
226 |             try:
227 |                 save_dir = self._save_dirs[head]
228 |                 break
229 |             except KeyError:
230 |                 pass
231 |             head, old_head = os.path.dirname(head), head
232 |         else:
233 |             # Did not find any suitable root
234 |             head = os.path.dirname(path)
235 |             save_dir = TempDirectory(kind="uninstall")
236 |             self._save_dirs[head] = save_dir
237 | 
238 |         relpath = os.path.relpath(path, head)
239 |         if relpath and relpath != os.path.curdir:
240 |             return os.path.join(save_dir.path, relpath)
241 |         return save_dir.path
242 | 
243 |     def stash(self, path: str) -> str:
244 |         """Stashes the directory or file and returns its new location.
245 |         Handle symlinks as files to avoid modifying the symlink targets.
246 |         """
247 |         path_is_dir = os.path.isdir(path) and not os.path.islink(path)
248 |         if path_is_dir:
249 |             new_path = self._get_directory_stash(path)
250 |         else:
251 |             new_path = self._get_file_stash(path)
252 | 
253 |         self._moves.append((path, new_path))
254 |         if path_is_dir and os.path.isdir(new_path):
255 |             # If we're moving a directory, we need to
256 |             # remove the destination first or else it will be
257 |             # moved to inside the existing directory.
258 |             # We just created new_path ourselves, so it will
259 |             # be removable.
260 |             os.rmdir(new_path)
261 |         renames(path, new_path)
262 |         return new_path
263 | 
264 |     def commit(self) -> None:
265 |         """Commits the uninstall by removing stashed files."""
266 |         for save_dir in self._save_dirs.values():
267 |             save_dir.cleanup()
268 |         self._moves = []
269 |         self._save_dirs = {}
270 | 
271 |     def rollback(self) -> None:
272 |         """Undoes the uninstall by moving stashed files back."""
273 |         for p in self._moves:
274 |             logger.info("Moving to %s\n from %s", *p)
275 | 
276 |         for new_path, path in self._moves:
277 |             try:
278 |                 logger.debug("Replacing %s from %s", new_path, path)
279 |                 if os.path.isfile(new_path) or os.path.islink(new_path):
280 |                     os.unlink(new_path)
281 |                 elif os.path.isdir(new_path):
282 |                     rmtree(new_path)
283 |                 renames(path, new_path)
284 |             except OSError as ex:
285 |                 logger.error("Failed to restore %s", new_path)
286 |                 logger.debug("Exception: %s", ex)
287 | 
288 |         self.commit()
289 | 
290 |     @property
291 |     def can_rollback(self) -> bool:
292 |         return bool(self._moves)
293 | 
294 | 
295 | class UninstallPathSet:
296 |     """A set of file paths to be removed in the uninstallation of a
297 |     requirement."""
298 | 
299 |     def __init__(self, dist: BaseDistribution) -> None:
300 |         self._paths: Set[str] = set()
301 |         self._refuse: Set[str] = set()
302 |         self._pth: Dict[str, UninstallPthEntries] = {}
303 |         self._dist = dist
304 |         self._moved_paths = StashedUninstallPathSet()
305 |         # Create local cache of normalize_path results. Creating an UninstallPathSet
306 |         # can result in hundreds/thousands of redundant calls to normalize_path with
307 |         # the same args, which hurts performance.
308 |         self._normalize_path_cached = functools.lru_cache(normalize_path)
309 | 
310 |     def _permitted(self, path: str) -> bool:
311 |         """
312 |         Return True if the given path is one we are permitted to
313 |         remove/modify, False otherwise.
314 | 
315 |         """
316 |         # aka is_local, but caching normalized sys.prefix
317 |         if not running_under_virtualenv():
318 |             return True
319 |         return path.startswith(self._normalize_path_cached(sys.prefix))
320 | 
321 |     def add(self, path: str) -> None:
322 |         head, tail = os.path.split(path)
323 | 
[TRUNCATED]
```

.venv/lib/python3.13/site-packages/pip/_internal/network/__init__.py
```
1 | """Contains purely network-related utilities."""
```

.venv/lib/python3.13/site-packages/pip/_internal/network/auth.py
```
1 | """Network Authentication Helpers
2 | 
3 | Contains interface (MultiDomainBasicAuth) and associated glue code for
4 | providing credentials in the context of network requests.
5 | """
6 | 
7 | import logging
8 | import os
9 | import shutil
10 | import subprocess
11 | import sysconfig
12 | import typing
13 | import urllib.parse
14 | from abc import ABC, abstractmethod
15 | from functools import lru_cache
16 | from os.path import commonprefix
17 | from pathlib import Path
18 | from typing import Any, Dict, List, NamedTuple, Optional, Tuple
19 | 
20 | from pip._vendor.requests.auth import AuthBase, HTTPBasicAuth
21 | from pip._vendor.requests.models import Request, Response
22 | from pip._vendor.requests.utils import get_netrc_auth
23 | 
24 | from pip._internal.utils.logging import getLogger
25 | from pip._internal.utils.misc import (
26 |     ask,
27 |     ask_input,
28 |     ask_password,
29 |     remove_auth_from_url,
30 |     split_auth_netloc_from_url,
31 | )
32 | from pip._internal.vcs.versioncontrol import AuthInfo
33 | 
34 | logger = getLogger(__name__)
35 | 
36 | KEYRING_DISABLED = False
37 | 
38 | 
39 | class Credentials(NamedTuple):
40 |     url: str
41 |     username: str
42 |     password: str
43 | 
44 | 
45 | class KeyRingBaseProvider(ABC):
46 |     """Keyring base provider interface"""
47 | 
48 |     has_keyring: bool
49 | 
50 |     @abstractmethod
51 |     def get_auth_info(
52 |         self, url: str, username: Optional[str]
53 |     ) -> Optional[AuthInfo]: ...
54 | 
55 |     @abstractmethod
56 |     def save_auth_info(self, url: str, username: str, password: str) -> None: ...
57 | 
58 | 
59 | class KeyRingNullProvider(KeyRingBaseProvider):
60 |     """Keyring null provider"""
61 | 
62 |     has_keyring = False
63 | 
64 |     def get_auth_info(self, url: str, username: Optional[str]) -> Optional[AuthInfo]:
65 |         return None
66 | 
67 |     def save_auth_info(self, url: str, username: str, password: str) -> None:
68 |         return None
69 | 
70 | 
71 | class KeyRingPythonProvider(KeyRingBaseProvider):
72 |     """Keyring interface which uses locally imported `keyring`"""
73 | 
74 |     has_keyring = True
75 | 
76 |     def __init__(self) -> None:
77 |         import keyring
78 | 
79 |         self.keyring = keyring
80 | 
81 |     def get_auth_info(self, url: str, username: Optional[str]) -> Optional[AuthInfo]:
82 |         # Support keyring's get_credential interface which supports getting
83 |         # credentials without a username. This is only available for
84 |         # keyring>=15.2.0.
85 |         if hasattr(self.keyring, "get_credential"):
86 |             logger.debug("Getting credentials from keyring for %s", url)
87 |             cred = self.keyring.get_credential(url, username)
88 |             if cred is not None:
89 |                 return cred.username, cred.password
90 |             return None
91 | 
92 |         if username is not None:
93 |             logger.debug("Getting password from keyring for %s", url)
94 |             password = self.keyring.get_password(url, username)
95 |             if password:
96 |                 return username, password
97 |         return None
98 | 
99 |     def save_auth_info(self, url: str, username: str, password: str) -> None:
100 |         self.keyring.set_password(url, username, password)
101 | 
102 | 
103 | class KeyRingCliProvider(KeyRingBaseProvider):
104 |     """Provider which uses `keyring` cli
105 | 
106 |     Instead of calling the keyring package installed alongside pip
107 |     we call keyring on the command line which will enable pip to
108 |     use which ever installation of keyring is available first in
109 |     PATH.
110 |     """
111 | 
112 |     has_keyring = True
113 | 
114 |     def __init__(self, cmd: str) -> None:
115 |         self.keyring = cmd
116 | 
117 |     def get_auth_info(self, url: str, username: Optional[str]) -> Optional[AuthInfo]:
118 |         # This is the default implementation of keyring.get_credential
119 |         # https://github.com/jaraco/keyring/blob/97689324abcf01bd1793d49063e7ca01e03d7d07/keyring/backend.py#L134-L139
120 |         if username is not None:
121 |             password = self._get_password(url, username)
122 |             if password is not None:
123 |                 return username, password
124 |         return None
125 | 
126 |     def save_auth_info(self, url: str, username: str, password: str) -> None:
127 |         return self._set_password(url, username, password)
128 | 
129 |     def _get_password(self, service_name: str, username: str) -> Optional[str]:
130 |         """Mirror the implementation of keyring.get_password using cli"""
131 |         if self.keyring is None:
132 |             return None
133 | 
134 |         cmd = [self.keyring, "get", service_name, username]
135 |         env = os.environ.copy()
136 |         env["PYTHONIOENCODING"] = "utf-8"
137 |         res = subprocess.run(
138 |             cmd,
139 |             stdin=subprocess.DEVNULL,
140 |             stdout=subprocess.PIPE,
141 |             env=env,
142 |         )
143 |         if res.returncode:
144 |             return None
145 |         return res.stdout.decode("utf-8").strip(os.linesep)
146 | 
147 |     def _set_password(self, service_name: str, username: str, password: str) -> None:
148 |         """Mirror the implementation of keyring.set_password using cli"""
149 |         if self.keyring is None:
150 |             return None
151 |         env = os.environ.copy()
152 |         env["PYTHONIOENCODING"] = "utf-8"
153 |         subprocess.run(
154 |             [self.keyring, "set", service_name, username],
155 |             input=f"{password}{os.linesep}".encode(),
156 |             env=env,
157 |             check=True,
158 |         )
159 |         return None
160 | 
161 | 
162 | @lru_cache(maxsize=None)
163 | def get_keyring_provider(provider: str) -> KeyRingBaseProvider:
164 |     logger.verbose("Keyring provider requested: %s", provider)
165 | 
166 |     # keyring has previously failed and been disabled
167 |     if KEYRING_DISABLED:
168 |         provider = "disabled"
169 |     if provider in ["import", "auto"]:
170 |         try:
171 |             impl = KeyRingPythonProvider()
172 |             logger.verbose("Keyring provider set: import")
173 |             return impl
174 |         except ImportError:
175 |             pass
176 |         except Exception as exc:
177 |             # In the event of an unexpected exception
178 |             # we should warn the user
179 |             msg = "Installed copy of keyring fails with exception %s"
180 |             if provider == "auto":
181 |                 msg = msg + ", trying to find a keyring executable as a fallback"
182 |             logger.warning(msg, exc, exc_info=logger.isEnabledFor(logging.DEBUG))
183 |     if provider in ["subprocess", "auto"]:
184 |         cli = shutil.which("keyring")
185 |         if cli and cli.startswith(sysconfig.get_path("scripts")):
186 |             # all code within this function is stolen from shutil.which implementation
187 |             @typing.no_type_check
188 |             def PATH_as_shutil_which_determines_it() -> str:
189 |                 path = os.environ.get("PATH", None)
190 |                 if path is None:
191 |                     try:
192 |                         path = os.confstr("CS_PATH")
193 |                     except (AttributeError, ValueError):
194 |                         # os.confstr() or CS_PATH is not available
195 |                         path = os.defpath
196 |                 # bpo-35755: Don't use os.defpath if the PATH environment variable is
197 |                 # set to an empty string
198 | 
199 |                 return path
200 | 
201 |             scripts = Path(sysconfig.get_path("scripts"))
202 | 
203 |             paths = []
204 |             for path in PATH_as_shutil_which_determines_it().split(os.pathsep):
205 |                 p = Path(path)
206 |                 try:
207 |                     if not p.samefile(scripts):
208 |                         paths.append(path)
209 |                 except FileNotFoundError:
210 |                     pass
211 | 
212 |             path = os.pathsep.join(paths)
213 | 
214 |             cli = shutil.which("keyring", path=path)
215 | 
216 |         if cli:
217 |             logger.verbose("Keyring provider set: subprocess with executable %s", cli)
218 |             return KeyRingCliProvider(cli)
219 | 
220 |     logger.verbose("Keyring provider set: disabled")
221 |     return KeyRingNullProvider()
222 | 
223 | 
224 | class MultiDomainBasicAuth(AuthBase):
225 |     def __init__(
226 |         self,
227 |         prompting: bool = True,
228 |         index_urls: Optional[List[str]] = None,
229 |         keyring_provider: str = "auto",
230 |     ) -> None:
231 |         self.prompting = prompting
232 |         self.index_urls = index_urls
233 |         self.keyring_provider = keyring_provider  # type: ignore[assignment]
234 |         self.passwords: Dict[str, AuthInfo] = {}
235 |         # When the user is prompted to enter credentials and keyring is
236 |         # available, we will offer to save them. If the user accepts,
237 |         # this value is set to the credentials they entered. After the
238 |         # request authenticates, the caller should call
239 |         # ``save_credentials`` to save these.
240 |         self._credentials_to_save: Optional[Credentials] = None
241 | 
242 |     @property
243 |     def keyring_provider(self) -> KeyRingBaseProvider:
244 |         return get_keyring_provider(self._keyring_provider)
245 | 
246 |     @keyring_provider.setter
247 |     def keyring_provider(self, provider: str) -> None:
248 |         # The free function get_keyring_provider has been decorated with
249 |         # functools.cache. If an exception occurs in get_keyring_auth that
250 |         # cache will be cleared and keyring disabled, take that into account
251 |         # if you want to remove this indirection.
252 |         self._keyring_provider = provider
253 | 
254 |     @property
255 |     def use_keyring(self) -> bool:
256 |         # We won't use keyring when --no-input is passed unless
257 |         # a specific provider is requested because it might require
258 |         # user interaction
259 |         return self.prompting or self._keyring_provider not in ["auto", "disabled"]
260 | 
261 |     def _get_keyring_auth(
262 |         self,
263 |         url: Optional[str],
264 |         username: Optional[str],
265 |     ) -> Optional[AuthInfo]:
266 |         """Return the tuple auth for a given url from keyring."""
267 |         # Do nothing if no url was provided
268 |         if not url:
269 |             return None
270 | 
271 |         try:
272 |             return self.keyring_provider.get_auth_info(url, username)
273 |         except Exception as exc:
274 |             # Log the full exception (with stacktrace) at debug, so it'll only
275 |             # show up when running in verbose mode.
276 |             logger.debug("Keyring is skipped due to an exception", exc_info=True)
277 |             # Always log a shortened version of the exception.
278 |             logger.warning(
279 |                 "Keyring is skipped due to an exception: %s",
280 |                 str(exc),
281 |             )
282 |             global KEYRING_DISABLED
283 |             KEYRING_DISABLED = True
284 |             get_keyring_provider.cache_clear()
285 |             return None
286 | 
287 |     def _get_index_url(self, url: str) -> Optional[str]:
288 |         """Return the original index URL matching the requested URL.
289 | 
290 |         Cached or dynamically generated credentials may work against
291 |         the original index URL rather than just the netloc.
292 | 
293 |         The provided url should have had its username and password
294 |         removed already. If the original index url had credentials then
295 |         they will be included in the return value.
296 | 
297 |         Returns None if no matching index was found, or if --no-index
298 |         was specified by the user.
299 |         """
300 |         if not url or not self.index_urls:
301 |             return None
302 | 
303 |         url = remove_auth_from_url(url).rstrip("/") + "/"
304 |         parsed_url = urllib.parse.urlsplit(url)
305 | 
306 |         candidates = []
307 | 
308 |         for index in self.index_urls:
309 |             index = index.rstrip("/") + "/"
310 |             parsed_index = urllib.parse.urlsplit(remove_auth_from_url(index))
311 |             if parsed_url == parsed_index:
312 |                 return index
313 | 
314 |             if parsed_url.netloc != parsed_index.netloc:
315 |                 continue
316 | 
317 |             candidate = urllib.parse.urlsplit(index)
318 |             candidates.append(candidate)
319 | 
320 |         if not candidates:
321 |             return None
322 | 
323 |         candidates.sort(
324 |             reverse=True,
325 |             key=lambda candidate: commonprefix(
326 |                 [
327 |                     parsed_url.path,
328 |                     candidate.path,
329 |                 ]
330 |             ).rfind("/"),
331 |         )
332 | 
333 |         return urllib.parse.urlunsplit(candidates[0])
334 | 
335 |     def _get_new_credentials(
336 |         self,
337 |         original_url: str,
338 |         *,
339 |         allow_netrc: bool = True,
340 |         allow_keyring: bool = False,
341 |     ) -> AuthInfo:
342 |         """Find and return credentials for the specified URL."""
343 |         # Split the credentials and netloc from the url.
344 |         url, netloc, url_user_password = split_auth_netloc_from_url(
345 |             original_url,
346 |         )
347 | 
348 |         # Start with the credentials embedded in the url
349 |         username, password = url_user_password
350 |         if username is not None and password is not None:
351 |             logger.debug("Found credentials in url for %s", netloc)
352 |             return url_user_password
353 | 
354 |         # Find a matching index url for this request
355 |         index_url = self._get_index_url(url)
356 |         if index_url:
357 |             # Split the credentials from the url.
358 |             index_info = split_auth_netloc_from_url(index_url)
359 |             if index_info:
360 |                 index_url, _, index_url_user_password = index_info
[TRUNCATED]
```

.venv/lib/python3.13/site-packages/pip/_internal/network/cache.py
```
1 | """HTTP cache implementation."""
2 | 
3 | import os
4 | from contextlib import contextmanager
5 | from datetime import datetime
6 | from typing import BinaryIO, Generator, Optional, Union
7 | 
8 | from pip._vendor.cachecontrol.cache import SeparateBodyBaseCache
9 | from pip._vendor.cachecontrol.caches import SeparateBodyFileCache
10 | from pip._vendor.requests.models import Response
11 | 
12 | from pip._internal.utils.filesystem import adjacent_tmp_file, replace
13 | from pip._internal.utils.misc import ensure_dir
14 | 
15 | 
16 | def is_from_cache(response: Response) -> bool:
17 |     return getattr(response, "from_cache", False)
18 | 
19 | 
20 | @contextmanager
21 | def suppressed_cache_errors() -> Generator[None, None, None]:
22 |     """If we can't access the cache then we can just skip caching and process
23 |     requests as if caching wasn't enabled.
24 |     """
25 |     try:
26 |         yield
27 |     except OSError:
28 |         pass
29 | 
30 | 
31 | class SafeFileCache(SeparateBodyBaseCache):
32 |     """
33 |     A file based cache which is safe to use even when the target directory may
34 |     not be accessible or writable.
35 | 
36 |     There is a race condition when two processes try to write and/or read the
37 |     same entry at the same time, since each entry consists of two separate
38 |     files (https://github.com/psf/cachecontrol/issues/324).  We therefore have
39 |     additional logic that makes sure that both files to be present before
40 |     returning an entry; this fixes the read side of the race condition.
41 | 
42 |     For the write side, we assume that the server will only ever return the
43 |     same data for the same URL, which ought to be the case for files pip is
44 |     downloading.  PyPI does not have a mechanism to swap out a wheel for
45 |     another wheel, for example.  If this assumption is not true, the
46 |     CacheControl issue will need to be fixed.
47 |     """
48 | 
49 |     def __init__(self, directory: str) -> None:
50 |         assert directory is not None, "Cache directory must not be None."
51 |         super().__init__()
52 |         self.directory = directory
53 | 
54 |     def _get_cache_path(self, name: str) -> str:
55 |         # From cachecontrol.caches.file_cache.FileCache._fn, brought into our
56 |         # class for backwards-compatibility and to avoid using a non-public
57 |         # method.
58 |         hashed = SeparateBodyFileCache.encode(name)
59 |         parts = list(hashed[:5]) + [hashed]
60 |         return os.path.join(self.directory, *parts)
61 | 
62 |     def get(self, key: str) -> Optional[bytes]:
63 |         # The cache entry is only valid if both metadata and body exist.
64 |         metadata_path = self._get_cache_path(key)
65 |         body_path = metadata_path + ".body"
66 |         if not (os.path.exists(metadata_path) and os.path.exists(body_path)):
67 |             return None
68 |         with suppressed_cache_errors():
69 |             with open(metadata_path, "rb") as f:
70 |                 return f.read()
71 | 
72 |     def _write(self, path: str, data: bytes) -> None:
73 |         with suppressed_cache_errors():
74 |             ensure_dir(os.path.dirname(path))
75 | 
76 |             with adjacent_tmp_file(path) as f:
77 |                 f.write(data)
78 |                 # Inherit the read/write permissions of the cache directory
79 |                 # to enable multi-user cache use-cases.
80 |                 mode = (
81 |                     os.stat(self.directory).st_mode
82 |                     & 0o666  # select read/write permissions of cache directory
83 |                     | 0o600  # set owner read/write permissions
84 |                 )
85 |                 # Change permissions only if there is no risk of following a symlink.
86 |                 if os.chmod in os.supports_fd:
87 |                     os.chmod(f.fileno(), mode)
88 |                 elif os.chmod in os.supports_follow_symlinks:
89 |                     os.chmod(f.name, mode, follow_symlinks=False)
90 | 
91 |             replace(f.name, path)
92 | 
93 |     def set(
94 |         self, key: str, value: bytes, expires: Union[int, datetime, None] = None
95 |     ) -> None:
96 |         path = self._get_cache_path(key)
97 |         self._write(path, value)
98 | 
99 |     def delete(self, key: str) -> None:
100 |         path = self._get_cache_path(key)
101 |         with suppressed_cache_errors():
102 |             os.remove(path)
103 |         with suppressed_cache_errors():
104 |             os.remove(path + ".body")
105 | 
106 |     def get_body(self, key: str) -> Optional[BinaryIO]:
107 |         # The cache entry is only valid if both metadata and body exist.
108 |         metadata_path = self._get_cache_path(key)
109 |         body_path = metadata_path + ".body"
110 |         if not (os.path.exists(metadata_path) and os.path.exists(body_path)):
111 |             return None
112 |         with suppressed_cache_errors():
113 |             return open(body_path, "rb")
114 | 
115 |     def set_body(self, key: str, body: bytes) -> None:
116 |         path = self._get_cache_path(key) + ".body"
117 |         self._write(path, body)
```

.venv/lib/python3.13/site-packages/pip/_internal/network/download.py
```
1 | """Download files with progress indicators."""
2 | 
3 | import email.message
4 | import logging
5 | import mimetypes
6 | import os
7 | from http import HTTPStatus
8 | from typing import BinaryIO, Iterable, Optional, Tuple
9 | 
10 | from pip._vendor.requests.models import Response
11 | from pip._vendor.urllib3.exceptions import ReadTimeoutError
12 | 
13 | from pip._internal.cli.progress_bars import get_download_progress_renderer
14 | from pip._internal.exceptions import IncompleteDownloadError, NetworkConnectionError
15 | from pip._internal.models.index import PyPI
16 | from pip._internal.models.link import Link
17 | from pip._internal.network.cache import is_from_cache
18 | from pip._internal.network.session import PipSession
19 | from pip._internal.network.utils import HEADERS, raise_for_status, response_chunks
20 | from pip._internal.utils.misc import format_size, redact_auth_from_url, splitext
21 | 
22 | logger = logging.getLogger(__name__)
23 | 
24 | 
25 | def _get_http_response_size(resp: Response) -> Optional[int]:
26 |     try:
27 |         return int(resp.headers["content-length"])
28 |     except (ValueError, KeyError, TypeError):
29 |         return None
30 | 
31 | 
32 | def _get_http_response_etag_or_last_modified(resp: Response) -> Optional[str]:
33 |     """
34 |     Return either the ETag or Last-Modified header (or None if neither exists).
35 |     The return value can be used in an If-Range header.
36 |     """
37 |     return resp.headers.get("etag", resp.headers.get("last-modified"))
38 | 
39 | 
40 | def _prepare_download(
41 |     resp: Response,
42 |     link: Link,
43 |     progress_bar: str,
44 |     total_length: Optional[int],
45 |     range_start: Optional[int] = 0,
46 | ) -> Iterable[bytes]:
47 |     if link.netloc == PyPI.file_storage_domain:
48 |         url = link.show_url
49 |     else:
50 |         url = link.url_without_fragment
51 | 
52 |     logged_url = redact_auth_from_url(url)
53 | 
54 |     if total_length:
55 |         if range_start:
56 |             logged_url = (
57 |                 f"{logged_url} ({format_size(range_start)}/{format_size(total_length)})"
58 |             )
59 |         else:
60 |             logged_url = f"{logged_url} ({format_size(total_length)})"
61 | 
62 |     if is_from_cache(resp):
63 |         logger.info("Using cached %s", logged_url)
64 |     elif range_start:
65 |         logger.info("Resuming download %s", logged_url)
66 |     else:
67 |         logger.info("Downloading %s", logged_url)
68 | 
69 |     if logger.getEffectiveLevel() > logging.INFO:
70 |         show_progress = False
71 |     elif is_from_cache(resp):
72 |         show_progress = False
73 |     elif not total_length:
74 |         show_progress = True
75 |     elif total_length > (512 * 1024):
76 |         show_progress = True
77 |     else:
78 |         show_progress = False
79 | 
80 |     chunks = response_chunks(resp)
81 | 
82 |     if not show_progress:
83 |         return chunks
84 | 
85 |     renderer = get_download_progress_renderer(
86 |         bar_type=progress_bar, size=total_length, initial_progress=range_start
87 |     )
88 |     return renderer(chunks)
89 | 
90 | 
91 | def sanitize_content_filename(filename: str) -> str:
92 |     """
93 |     Sanitize the "filename" value from a Content-Disposition header.
94 |     """
95 |     return os.path.basename(filename)
96 | 
97 | 
98 | def parse_content_disposition(content_disposition: str, default_filename: str) -> str:
99 |     """
100 |     Parse the "filename" value from a Content-Disposition header, and
101 |     return the default filename if the result is empty.
102 |     """
103 |     m = email.message.Message()
104 |     m["content-type"] = content_disposition
105 |     filename = m.get_param("filename")
106 |     if filename:
107 |         # We need to sanitize the filename to prevent directory traversal
108 |         # in case the filename contains ".." path parts.
109 |         filename = sanitize_content_filename(str(filename))
110 |     return filename or default_filename
111 | 
112 | 
113 | def _get_http_response_filename(resp: Response, link: Link) -> str:
114 |     """Get an ideal filename from the given HTTP response, falling back to
115 |     the link filename if not provided.
116 |     """
117 |     filename = link.filename  # fallback
118 |     # Have a look at the Content-Disposition header for a better guess
119 |     content_disposition = resp.headers.get("content-disposition")
120 |     if content_disposition:
121 |         filename = parse_content_disposition(content_disposition, filename)
122 |     ext: Optional[str] = splitext(filename)[1]
123 |     if not ext:
124 |         ext = mimetypes.guess_extension(resp.headers.get("content-type", ""))
125 |         if ext:
126 |             filename += ext
127 |     if not ext and link.url != resp.url:
128 |         ext = os.path.splitext(resp.url)[1]
129 |         if ext:
130 |             filename += ext
131 |     return filename
132 | 
133 | 
134 | def _http_get_download(
135 |     session: PipSession,
136 |     link: Link,
137 |     range_start: Optional[int] = 0,
138 |     if_range: Optional[str] = None,
139 | ) -> Response:
140 |     target_url = link.url.split("#", 1)[0]
141 |     headers = HEADERS.copy()
142 |     # request a partial download
143 |     if range_start:
144 |         headers["Range"] = f"bytes={range_start}-"
145 |     # make sure the file hasn't changed
146 |     if if_range:
147 |         headers["If-Range"] = if_range
148 |     try:
149 |         resp = session.get(target_url, headers=headers, stream=True)
150 |         raise_for_status(resp)
151 |     except NetworkConnectionError as e:
152 |         assert e.response is not None
153 |         logger.critical("HTTP error %s while getting %s", e.response.status_code, link)
154 |         raise
155 |     return resp
156 | 
157 | 
158 | class Downloader:
159 |     def __init__(
160 |         self,
161 |         session: PipSession,
162 |         progress_bar: str,
163 |         resume_retries: int,
164 |     ) -> None:
165 |         assert (
166 |             resume_retries >= 0
167 |         ), "Number of max resume retries must be bigger or equal to zero"
168 |         self._session = session
169 |         self._progress_bar = progress_bar
170 |         self._resume_retries = resume_retries
171 | 
172 |     def __call__(self, link: Link, location: str) -> Tuple[str, str]:
173 |         """Download the file given by link into location."""
174 |         resp = _http_get_download(self._session, link)
175 |         # NOTE: The original download size needs to be passed down everywhere
176 |         # so if the download is resumed (with a HTTP Range request) the progress
177 |         # bar will report the right size.
178 |         total_length = _get_http_response_size(resp)
179 |         content_type = resp.headers.get("Content-Type", "")
180 | 
181 |         filename = _get_http_response_filename(resp, link)
182 |         filepath = os.path.join(location, filename)
183 | 
184 |         with open(filepath, "wb") as content_file:
185 |             bytes_received = self._process_response(
186 |                 resp, link, content_file, 0, total_length
187 |             )
188 |             # If possible, check for an incomplete download and attempt resuming.
189 |             if total_length and bytes_received < total_length:
190 |                 self._attempt_resume(
191 |                     resp, link, content_file, total_length, bytes_received
192 |                 )
193 | 
194 |         return filepath, content_type
195 | 
196 |     def _process_response(
197 |         self,
198 |         resp: Response,
199 |         link: Link,
200 |         content_file: BinaryIO,
201 |         bytes_received: int,
202 |         total_length: Optional[int],
203 |     ) -> int:
204 |         """Process the response and write the chunks to the file."""
205 |         chunks = _prepare_download(
206 |             resp, link, self._progress_bar, total_length, range_start=bytes_received
207 |         )
208 |         return self._write_chunks_to_file(
209 |             chunks, content_file, allow_partial=bool(total_length)
210 |         )
211 | 
212 |     def _write_chunks_to_file(
213 |         self, chunks: Iterable[bytes], content_file: BinaryIO, *, allow_partial: bool
214 |     ) -> int:
215 |         """Write the chunks to the file and return the number of bytes received."""
216 |         bytes_received = 0
217 |         try:
218 |             for chunk in chunks:
219 |                 bytes_received += len(chunk)
220 |                 content_file.write(chunk)
221 |         except ReadTimeoutError as e:
222 |             # If partial downloads are OK (the download will be retried), don't bail.
223 |             if not allow_partial:
224 |                 raise e
225 | 
226 |             # Ensuring bytes_received is returned to attempt resume
227 |             logger.warning("Connection timed out while downloading.")
228 | 
229 |         return bytes_received
230 | 
231 |     def _attempt_resume(
232 |         self,
233 |         resp: Response,
234 |         link: Link,
235 |         content_file: BinaryIO,
236 |         total_length: Optional[int],
237 |         bytes_received: int,
238 |     ) -> None:
239 |         """Attempt to resume the download if connection was dropped."""
240 |         etag_or_last_modified = _get_http_response_etag_or_last_modified(resp)
241 | 
242 |         attempts_left = self._resume_retries
243 |         while total_length and attempts_left and bytes_received < total_length:
244 |             attempts_left -= 1
245 | 
246 |             logger.warning(
247 |                 "Attempting to resume incomplete download (%s/%s, attempt %d)",
248 |                 format_size(bytes_received),
249 |                 format_size(total_length),
250 |                 (self._resume_retries - attempts_left),
251 |             )
252 | 
253 |             try:
254 |                 # Try to resume the download using a HTTP range request.
255 |                 resume_resp = _http_get_download(
256 |                     self._session,
257 |                     link,
258 |                     range_start=bytes_received,
259 |                     if_range=etag_or_last_modified,
260 |                 )
261 | 
262 |                 # Fallback: if the server responded with 200 (i.e., the file has
263 |                 # since been modified or range requests are unsupported) or any
264 |                 # other unexpected status, restart the download from the beginning.
265 |                 must_restart = resume_resp.status_code != HTTPStatus.PARTIAL_CONTENT
266 |                 if must_restart:
267 |                     bytes_received, total_length, etag_or_last_modified = (
268 |                         self._reset_download_state(resume_resp, content_file)
269 |                     )
270 | 
271 |                 bytes_received += self._process_response(
272 |                     resume_resp, link, content_file, bytes_received, total_length
273 |                 )
274 |             except (ConnectionError, ReadTimeoutError, OSError):
275 |                 continue
276 | 
277 |         # No more resume attempts. Raise an error if the download is still incomplete.
278 |         if total_length and bytes_received < total_length:
279 |             os.remove(content_file.name)
280 |             raise IncompleteDownloadError(
281 |                 link, bytes_received, total_length, retries=self._resume_retries
282 |             )
283 | 
284 |     def _reset_download_state(
285 |         self,
286 |         resp: Response,
287 |         content_file: BinaryIO,
288 |     ) -> Tuple[int, Optional[int], Optional[str]]:
289 |         """Reset the download state to restart downloading from the beginning."""
290 |         content_file.seek(0)
291 |         content_file.truncate()
292 |         bytes_received = 0
293 |         total_length = _get_http_response_size(resp)
294 |         etag_or_last_modified = _get_http_response_etag_or_last_modified(resp)
295 | 
296 |         return bytes_received, total_length, etag_or_last_modified
297 | 
298 | 
299 | class BatchDownloader:
300 |     def __init__(
301 |         self,
302 |         session: PipSession,
303 |         progress_bar: str,
304 |         resume_retries: int,
305 |     ) -> None:
306 |         self._downloader = Downloader(session, progress_bar, resume_retries)
307 | 
308 |     def __call__(
309 |         self, links: Iterable[Link], location: str
310 |     ) -> Iterable[Tuple[Link, Tuple[str, str]]]:
311 |         """Download the files given by links into location."""
312 |         for link in links:
313 |             filepath, content_type = self._downloader(link, location)
314 |             yield link, (filepath, content_type)
```

.venv/lib/python3.13/site-packages/pip/_internal/network/lazy_wheel.py
```
1 | """Lazy ZIP over HTTP"""
2 | 
3 | __all__ = ["HTTPRangeRequestUnsupported", "dist_from_wheel_url"]
4 | 
5 | from bisect import bisect_left, bisect_right
6 | from contextlib import contextmanager
7 | from tempfile import NamedTemporaryFile
8 | from typing import Any, Dict, Generator, List, Optional, Tuple
9 | from zipfile import BadZipFile, ZipFile
10 | 
11 | from pip._vendor.packaging.utils import canonicalize_name
12 | from pip._vendor.requests.models import CONTENT_CHUNK_SIZE, Response
13 | 
14 | from pip._internal.metadata import BaseDistribution, MemoryWheel, get_wheel_distribution
15 | from pip._internal.network.session import PipSession
16 | from pip._internal.network.utils import HEADERS, raise_for_status, response_chunks
17 | 
18 | 
19 | class HTTPRangeRequestUnsupported(Exception):
20 |     pass
21 | 
22 | 
23 | def dist_from_wheel_url(name: str, url: str, session: PipSession) -> BaseDistribution:
24 |     """Return a distribution object from the given wheel URL.
25 | 
26 |     This uses HTTP range requests to only fetch the portion of the wheel
27 |     containing metadata, just enough for the object to be constructed.
28 |     If such requests are not supported, HTTPRangeRequestUnsupported
29 |     is raised.
30 |     """
31 |     with LazyZipOverHTTP(url, session) as zf:
32 |         # For read-only ZIP files, ZipFile only needs methods read,
33 |         # seek, seekable and tell, not the whole IO protocol.
34 |         wheel = MemoryWheel(zf.name, zf)  # type: ignore
35 |         # After context manager exit, wheel.name
36 |         # is an invalid file by intention.
37 |         return get_wheel_distribution(wheel, canonicalize_name(name))
38 | 
39 | 
40 | class LazyZipOverHTTP:
41 |     """File-like object mapped to a ZIP file over HTTP.
42 | 
43 |     This uses HTTP range requests to lazily fetch the file's content,
44 |     which is supposed to be fed to ZipFile.  If such requests are not
45 |     supported by the server, raise HTTPRangeRequestUnsupported
46 |     during initialization.
47 |     """
48 | 
49 |     def __init__(
50 |         self, url: str, session: PipSession, chunk_size: int = CONTENT_CHUNK_SIZE
51 |     ) -> None:
52 |         head = session.head(url, headers=HEADERS)
53 |         raise_for_status(head)
54 |         assert head.status_code == 200
55 |         self._session, self._url, self._chunk_size = session, url, chunk_size
56 |         self._length = int(head.headers["Content-Length"])
57 |         self._file = NamedTemporaryFile()
58 |         self.truncate(self._length)
59 |         self._left: List[int] = []
60 |         self._right: List[int] = []
61 |         if "bytes" not in head.headers.get("Accept-Ranges", "none"):
62 |             raise HTTPRangeRequestUnsupported("range request is not supported")
63 |         self._check_zip()
64 | 
65 |     @property
66 |     def mode(self) -> str:
67 |         """Opening mode, which is always rb."""
68 |         return "rb"
69 | 
70 |     @property
71 |     def name(self) -> str:
72 |         """Path to the underlying file."""
73 |         return self._file.name
74 | 
75 |     def seekable(self) -> bool:
76 |         """Return whether random access is supported, which is True."""
77 |         return True
78 | 
79 |     def close(self) -> None:
80 |         """Close the file."""
81 |         self._file.close()
82 | 
83 |     @property
84 |     def closed(self) -> bool:
85 |         """Whether the file is closed."""
86 |         return self._file.closed
87 | 
88 |     def read(self, size: int = -1) -> bytes:
89 |         """Read up to size bytes from the object and return them.
90 | 
91 |         As a convenience, if size is unspecified or -1,
92 |         all bytes until EOF are returned.  Fewer than
93 |         size bytes may be returned if EOF is reached.
94 |         """
95 |         download_size = max(size, self._chunk_size)
96 |         start, length = self.tell(), self._length
97 |         stop = length if size < 0 else min(start + download_size, length)
98 |         start = max(0, stop - download_size)
99 |         self._download(start, stop - 1)
100 |         return self._file.read(size)
101 | 
102 |     def readable(self) -> bool:
103 |         """Return whether the file is readable, which is True."""
104 |         return True
105 | 
106 |     def seek(self, offset: int, whence: int = 0) -> int:
107 |         """Change stream position and return the new absolute position.
108 | 
109 |         Seek to offset relative position indicated by whence:
110 |         * 0: Start of stream (the default).  pos should be >= 0;
111 |         * 1: Current position - pos may be negative;
112 |         * 2: End of stream - pos usually negative.
113 |         """
114 |         return self._file.seek(offset, whence)
115 | 
116 |     def tell(self) -> int:
117 |         """Return the current position."""
118 |         return self._file.tell()
119 | 
120 |     def truncate(self, size: Optional[int] = None) -> int:
121 |         """Resize the stream to the given size in bytes.
122 | 
123 |         If size is unspecified resize to the current position.
124 |         The current stream position isn't changed.
125 | 
126 |         Return the new file size.
127 |         """
128 |         return self._file.truncate(size)
129 | 
130 |     def writable(self) -> bool:
131 |         """Return False."""
132 |         return False
133 | 
134 |     def __enter__(self) -> "LazyZipOverHTTP":
135 |         self._file.__enter__()
136 |         return self
137 | 
138 |     def __exit__(self, *exc: Any) -> None:
139 |         self._file.__exit__(*exc)
140 | 
141 |     @contextmanager
142 |     def _stay(self) -> Generator[None, None, None]:
143 |         """Return a context manager keeping the position.
144 | 
145 |         At the end of the block, seek back to original position.
146 |         """
147 |         pos = self.tell()
148 |         try:
149 |             yield
150 |         finally:
151 |             self.seek(pos)
152 | 
153 |     def _check_zip(self) -> None:
154 |         """Check and download until the file is a valid ZIP."""
155 |         end = self._length - 1
156 |         for start in reversed(range(0, end, self._chunk_size)):
157 |             self._download(start, end)
158 |             with self._stay():
159 |                 try:
160 |                     # For read-only ZIP files, ZipFile only needs
161 |                     # methods read, seek, seekable and tell.
162 |                     ZipFile(self)
163 |                 except BadZipFile:
164 |                     pass
165 |                 else:
166 |                     break
167 | 
168 |     def _stream_response(
169 |         self, start: int, end: int, base_headers: Dict[str, str] = HEADERS
170 |     ) -> Response:
171 |         """Return HTTP response to a range request from start to end."""
172 |         headers = base_headers.copy()
173 |         headers["Range"] = f"bytes={start}-{end}"
174 |         # TODO: Get range requests to be correctly cached
175 |         headers["Cache-Control"] = "no-cache"
176 |         return self._session.get(self._url, headers=headers, stream=True)
177 | 
178 |     def _merge(
179 |         self, start: int, end: int, left: int, right: int
180 |     ) -> Generator[Tuple[int, int], None, None]:
181 |         """Return a generator of intervals to be fetched.
182 | 
183 |         Args:
184 |             start (int): Start of needed interval
185 |             end (int): End of needed interval
186 |             left (int): Index of first overlapping downloaded data
187 |             right (int): Index after last overlapping downloaded data
188 |         """
189 |         lslice, rslice = self._left[left:right], self._right[left:right]
190 |         i = start = min([start] + lslice[:1])
191 |         end = max([end] + rslice[-1:])
192 |         for j, k in zip(lslice, rslice):
193 |             if j > i:
194 |                 yield i, j - 1
195 |             i = k + 1
196 |         if i <= end:
197 |             yield i, end
198 |         self._left[left:right], self._right[left:right] = [start], [end]
199 | 
200 |     def _download(self, start: int, end: int) -> None:
201 |         """Download bytes from start to end inclusively."""
202 |         with self._stay():
203 |             left = bisect_left(self._right, start)
204 |             right = bisect_right(self._left, end)
205 |             for start, end in self._merge(start, end, left, right):
206 |                 response = self._stream_response(start, end)
207 |                 response.raise_for_status()
208 |                 self.seek(start)
209 |                 for chunk in response_chunks(response, self._chunk_size):
210 |                     self._file.write(chunk)
```

.venv/lib/python3.13/site-packages/pip/_internal/network/session.py
```
1 | """PipSession and supporting code, containing all pip-specific
2 | network request configuration and behavior.
3 | """
4 | 
5 | import email.utils
6 | import functools
7 | import io
8 | import ipaddress
9 | import json
10 | import logging
11 | import mimetypes
12 | import os
13 | import platform
14 | import shutil
15 | import subprocess
16 | import sys
17 | import urllib.parse
18 | import warnings
19 | from typing import (
20 |     TYPE_CHECKING,
21 |     Any,
22 |     Dict,
23 |     Generator,
24 |     List,
25 |     Mapping,
26 |     Optional,
27 |     Sequence,
28 |     Tuple,
29 |     Union,
30 | )
31 | 
32 | from pip._vendor import requests, urllib3
33 | from pip._vendor.cachecontrol import CacheControlAdapter as _BaseCacheControlAdapter
34 | from pip._vendor.requests.adapters import DEFAULT_POOLBLOCK, BaseAdapter
35 | from pip._vendor.requests.adapters import HTTPAdapter as _BaseHTTPAdapter
36 | from pip._vendor.requests.models import PreparedRequest, Response
37 | from pip._vendor.requests.structures import CaseInsensitiveDict
38 | from pip._vendor.urllib3.connectionpool import ConnectionPool
39 | from pip._vendor.urllib3.exceptions import InsecureRequestWarning
40 | 
41 | from pip import __version__
42 | from pip._internal.metadata import get_default_environment
43 | from pip._internal.models.link import Link
44 | from pip._internal.network.auth import MultiDomainBasicAuth
45 | from pip._internal.network.cache import SafeFileCache
46 | 
47 | # Import ssl from compat so the initial import occurs in only one place.
48 | from pip._internal.utils.compat import has_tls
49 | from pip._internal.utils.glibc import libc_ver
50 | from pip._internal.utils.misc import build_url_from_netloc, parse_netloc
51 | from pip._internal.utils.urls import url_to_path
52 | 
53 | if TYPE_CHECKING:
54 |     from ssl import SSLContext
55 | 
56 |     from pip._vendor.urllib3.poolmanager import PoolManager
57 | 
58 | 
59 | logger = logging.getLogger(__name__)
60 | 
61 | SecureOrigin = Tuple[str, str, Optional[Union[int, str]]]
62 | 
63 | 
64 | # Ignore warning raised when using --trusted-host.
65 | warnings.filterwarnings("ignore", category=InsecureRequestWarning)
66 | 
67 | 
68 | SECURE_ORIGINS: List[SecureOrigin] = [
69 |     # protocol, hostname, port
70 |     # Taken from Chrome's list of secure origins (See: http://bit.ly/1qrySKC)
71 |     ("https", "*", "*"),
72 |     ("*", "localhost", "*"),
73 |     ("*", "127.0.0.0/8", "*"),
74 |     ("*", "::1/128", "*"),
75 |     ("file", "*", None),
76 |     # ssh is always secure.
77 |     ("ssh", "*", "*"),
78 | ]
79 | 
80 | 
81 | # These are environment variables present when running under various
82 | # CI systems.  For each variable, some CI systems that use the variable
83 | # are indicated.  The collection was chosen so that for each of a number
84 | # of popular systems, at least one of the environment variables is used.
85 | # This list is used to provide some indication of and lower bound for
86 | # CI traffic to PyPI.  Thus, it is okay if the list is not comprehensive.
87 | # For more background, see: https://github.com/pypa/pip/issues/5499
88 | CI_ENVIRONMENT_VARIABLES = (
89 |     # Azure Pipelines
90 |     "BUILD_BUILDID",
91 |     # Jenkins
92 |     "BUILD_ID",
93 |     # AppVeyor, CircleCI, Codeship, Gitlab CI, Shippable, Travis CI
94 |     "CI",
95 |     # Explicit environment variable.
96 |     "PIP_IS_CI",
97 | )
98 | 
99 | 
100 | def looks_like_ci() -> bool:
101 |     """
102 |     Return whether it looks like pip is running under CI.
103 |     """
104 |     # We don't use the method of checking for a tty (e.g. using isatty())
105 |     # because some CI systems mimic a tty (e.g. Travis CI).  Thus that
106 |     # method doesn't provide definitive information in either direction.
107 |     return any(name in os.environ for name in CI_ENVIRONMENT_VARIABLES)
108 | 
109 | 
110 | @functools.lru_cache(maxsize=1)
111 | def user_agent() -> str:
112 |     """
113 |     Return a string representing the user agent.
114 |     """
115 |     data: Dict[str, Any] = {
116 |         "installer": {"name": "pip", "version": __version__},
117 |         "python": platform.python_version(),
118 |         "implementation": {
119 |             "name": platform.python_implementation(),
120 |         },
121 |     }
122 | 
123 |     if data["implementation"]["name"] == "CPython":
124 |         data["implementation"]["version"] = platform.python_version()
125 |     elif data["implementation"]["name"] == "PyPy":
126 |         pypy_version_info = sys.pypy_version_info  # type: ignore
127 |         if pypy_version_info.releaselevel == "final":
128 |             pypy_version_info = pypy_version_info[:3]
129 |         data["implementation"]["version"] = ".".join(
130 |             [str(x) for x in pypy_version_info]
131 |         )
132 |     elif data["implementation"]["name"] == "Jython":
133 |         # Complete Guess
134 |         data["implementation"]["version"] = platform.python_version()
135 |     elif data["implementation"]["name"] == "IronPython":
136 |         # Complete Guess
137 |         data["implementation"]["version"] = platform.python_version()
138 | 
139 |     if sys.platform.startswith("linux"):
140 |         from pip._vendor import distro
141 | 
142 |         linux_distribution = distro.name(), distro.version(), distro.codename()
143 |         distro_infos: Dict[str, Any] = dict(
144 |             filter(
145 |                 lambda x: x[1],
146 |                 zip(["name", "version", "id"], linux_distribution),
147 |             )
148 |         )
149 |         libc = dict(
150 |             filter(
151 |                 lambda x: x[1],
152 |                 zip(["lib", "version"], libc_ver()),
153 |             )
154 |         )
155 |         if libc:
156 |             distro_infos["libc"] = libc
157 |         if distro_infos:
158 |             data["distro"] = distro_infos
159 | 
160 |     if sys.platform.startswith("darwin") and platform.mac_ver()[0]:
161 |         data["distro"] = {"name": "macOS", "version": platform.mac_ver()[0]}
162 | 
163 |     if platform.system():
164 |         data.setdefault("system", {})["name"] = platform.system()
165 | 
166 |     if platform.release():
167 |         data.setdefault("system", {})["release"] = platform.release()
168 | 
169 |     if platform.machine():
170 |         data["cpu"] = platform.machine()
171 | 
172 |     if has_tls():
173 |         import _ssl as ssl
174 | 
175 |         data["openssl_version"] = ssl.OPENSSL_VERSION
176 | 
177 |     setuptools_dist = get_default_environment().get_distribution("setuptools")
178 |     if setuptools_dist is not None:
179 |         data["setuptools_version"] = str(setuptools_dist.version)
180 | 
181 |     if shutil.which("rustc") is not None:
182 |         # If for any reason `rustc --version` fails, silently ignore it
183 |         try:
184 |             rustc_output = subprocess.check_output(
185 |                 ["rustc", "--version"], stderr=subprocess.STDOUT, timeout=0.5
186 |             )
187 |         except Exception:
188 |             pass
189 |         else:
190 |             if rustc_output.startswith(b"rustc "):
191 |                 # The format of `rustc --version` is:
192 |                 # `b'rustc 1.52.1 (9bc8c42bb 2021-05-09)\n'`
193 |                 # We extract just the middle (1.52.1) part
194 |                 data["rustc_version"] = rustc_output.split(b" ")[1].decode()
195 | 
196 |     # Use None rather than False so as not to give the impression that
197 |     # pip knows it is not being run under CI.  Rather, it is a null or
198 |     # inconclusive result.  Also, we include some value rather than no
199 |     # value to make it easier to know that the check has been run.
200 |     data["ci"] = True if looks_like_ci() else None
201 | 
202 |     user_data = os.environ.get("PIP_USER_AGENT_USER_DATA")
203 |     if user_data is not None:
204 |         data["user_data"] = user_data
205 | 
206 |     return "{data[installer][name]}/{data[installer][version]} {json}".format(
207 |         data=data,
208 |         json=json.dumps(data, separators=(",", ":"), sort_keys=True),
209 |     )
210 | 
211 | 
212 | class LocalFSAdapter(BaseAdapter):
213 |     def send(
214 |         self,
215 |         request: PreparedRequest,
216 |         stream: bool = False,
217 |         timeout: Optional[Union[float, Tuple[float, float]]] = None,
218 |         verify: Union[bool, str] = True,
219 |         cert: Optional[Union[str, Tuple[str, str]]] = None,
220 |         proxies: Optional[Mapping[str, str]] = None,
221 |     ) -> Response:
222 |         pathname = url_to_path(request.url)
223 | 
224 |         resp = Response()
225 |         resp.status_code = 200
226 |         resp.url = request.url
227 | 
228 |         try:
229 |             stats = os.stat(pathname)
230 |         except OSError as exc:
231 |             # format the exception raised as a io.BytesIO object,
232 |             # to return a better error message:
233 |             resp.status_code = 404
234 |             resp.reason = type(exc).__name__
235 |             resp.raw = io.BytesIO(f"{resp.reason}: {exc}".encode())
236 |         else:
237 |             modified = email.utils.formatdate(stats.st_mtime, usegmt=True)
238 |             content_type = mimetypes.guess_type(pathname)[0] or "text/plain"
239 |             resp.headers = CaseInsensitiveDict(
240 |                 {
241 |                     "Content-Type": content_type,
242 |                     "Content-Length": stats.st_size,
243 |                     "Last-Modified": modified,
244 |                 }
245 |             )
246 | 
247 |             resp.raw = open(pathname, "rb")
248 |             resp.close = resp.raw.close
249 | 
250 |         return resp
251 | 
252 |     def close(self) -> None:
253 |         pass
254 | 
255 | 
256 | class _SSLContextAdapterMixin:
257 |     """Mixin to add the ``ssl_context`` constructor argument to HTTP adapters.
258 | 
259 |     The additional argument is forwarded directly to the pool manager. This allows us
260 |     to dynamically decide what SSL store to use at runtime, which is used to implement
261 |     the optional ``truststore`` backend.
262 |     """
263 | 
264 |     def __init__(
265 |         self,
266 |         *,
267 |         ssl_context: Optional["SSLContext"] = None,
268 |         **kwargs: Any,
269 |     ) -> None:
270 |         self._ssl_context = ssl_context
271 |         super().__init__(**kwargs)
272 | 
273 |     def init_poolmanager(
274 |         self,
275 |         connections: int,
276 |         maxsize: int,
277 |         block: bool = DEFAULT_POOLBLOCK,
278 |         **pool_kwargs: Any,
279 |     ) -> "PoolManager":
280 |         if self._ssl_context is not None:
281 |             pool_kwargs.setdefault("ssl_context", self._ssl_context)
282 |         return super().init_poolmanager(  # type: ignore[misc]
283 |             connections=connections,
284 |             maxsize=maxsize,
285 |             block=block,
286 |             **pool_kwargs,
287 |         )
288 | 
289 | 
290 | class HTTPAdapter(_SSLContextAdapterMixin, _BaseHTTPAdapter):
291 |     pass
292 | 
293 | 
294 | class CacheControlAdapter(_SSLContextAdapterMixin, _BaseCacheControlAdapter):
295 |     pass
296 | 
297 | 
298 | class InsecureHTTPAdapter(HTTPAdapter):
299 |     def cert_verify(
300 |         self,
301 |         conn: ConnectionPool,
302 |         url: str,
303 |         verify: Union[bool, str],
304 |         cert: Optional[Union[str, Tuple[str, str]]],
305 |     ) -> None:
306 |         super().cert_verify(conn=conn, url=url, verify=False, cert=cert)
307 | 
308 | 
309 | class InsecureCacheControlAdapter(CacheControlAdapter):
310 |     def cert_verify(
311 |         self,
312 |         conn: ConnectionPool,
313 |         url: str,
314 |         verify: Union[bool, str],
315 |         cert: Optional[Union[str, Tuple[str, str]]],
316 |     ) -> None:
317 |         super().cert_verify(conn=conn, url=url, verify=False, cert=cert)
318 | 
319 | 
320 | class PipSession(requests.Session):
321 |     timeout: Optional[int] = None
322 | 
323 |     def __init__(
324 |         self,
325 |         *args: Any,
326 |         retries: int = 0,
327 |         cache: Optional[str] = None,
328 |         trusted_hosts: Sequence[str] = (),
329 |         index_urls: Optional[List[str]] = None,
330 |         ssl_context: Optional["SSLContext"] = None,
331 |         **kwargs: Any,
332 |     ) -> None:
333 |         """
334 |         :param trusted_hosts: Domains not to emit warnings for when not using
335 |             HTTPS.
336 |         """
337 |         super().__init__(*args, **kwargs)
338 | 
339 |         # Namespace the attribute with "pip_" just in case to prevent
340 |         # possible conflicts with the base class.
341 |         self.pip_trusted_origins: List[Tuple[str, Optional[int]]] = []
342 |         self.pip_proxy = None
343 | 
344 |         # Attach our User Agent to the request
345 |         self.headers["User-Agent"] = user_agent()
346 | 
347 |         # Attach our Authentication handler to the session
348 |         self.auth = MultiDomainBasicAuth(index_urls=index_urls)
349 | 
350 |         # Create our urllib3.Retry instance which will allow us to customize
351 |         # how we handle retries.
352 |         retries = urllib3.Retry(
353 |             # Set the total number of retries that a particular request can
354 |             # have.
355 |             total=retries,
356 |             # A 503 error from PyPI typically means that the Fastly -> Origin
357 |             # connection got interrupted in some way. A 503 error in general
358 |             # is typically considered a transient error so we'll go ahead and
359 |             # retry it.
360 |             # A 500 may indicate transient error in Amazon S3
361 |             # A 502 may be a transient error from a CDN like CloudFlare or CloudFront
362 |             # A 520 or 527 - may indicate transient error in CloudFlare
363 |             status_forcelist=[500, 502, 503, 520, 527],
364 |             # Add a small amount of back off between failed requests in
365 |             # order to prevent hammering the service.
366 |             backoff_factor=0.25,
367 |         )  # type: ignore
368 | 
[TRUNCATED]
```

.venv/lib/python3.13/site-packages/pip/_internal/network/utils.py
```
1 | from typing import Dict, Generator
2 | 
3 | from pip._vendor.requests.models import Response
4 | 
5 | from pip._internal.exceptions import NetworkConnectionError
6 | 
7 | # The following comments and HTTP headers were originally added by
8 | # Donald Stufft in git commit 22c562429a61bb77172039e480873fb239dd8c03.
9 | #
10 | # We use Accept-Encoding: identity here because requests defaults to
11 | # accepting compressed responses. This breaks in a variety of ways
12 | # depending on how the server is configured.
13 | # - Some servers will notice that the file isn't a compressible file
14 | #   and will leave the file alone and with an empty Content-Encoding
15 | # - Some servers will notice that the file is already compressed and
16 | #   will leave the file alone, adding a Content-Encoding: gzip header
17 | # - Some servers won't notice anything at all and will take a file
18 | #   that's already been compressed and compress it again, and set
19 | #   the Content-Encoding: gzip header
20 | # By setting this to request only the identity encoding we're hoping
21 | # to eliminate the third case.  Hopefully there does not exist a server
22 | # which when given a file will notice it is already compressed and that
23 | # you're not asking for a compressed file and will then decompress it
24 | # before sending because if that's the case I don't think it'll ever be
25 | # possible to make this work.
26 | HEADERS: Dict[str, str] = {"Accept-Encoding": "identity"}
27 | 
28 | DOWNLOAD_CHUNK_SIZE = 256 * 1024
29 | 
30 | 
31 | def raise_for_status(resp: Response) -> None:
32 |     http_error_msg = ""
33 |     if isinstance(resp.reason, bytes):
34 |         # We attempt to decode utf-8 first because some servers
35 |         # choose to localize their reason strings. If the string
36 |         # isn't utf-8, we fall back to iso-8859-1 for all other
37 |         # encodings.
38 |         try:
39 |             reason = resp.reason.decode("utf-8")
40 |         except UnicodeDecodeError:
41 |             reason = resp.reason.decode("iso-8859-1")
42 |     else:
43 |         reason = resp.reason
44 | 
45 |     if 400 <= resp.status_code < 500:
46 |         http_error_msg = (
47 |             f"{resp.status_code} Client Error: {reason} for url: {resp.url}"
48 |         )
49 | 
50 |     elif 500 <= resp.status_code < 600:
51 |         http_error_msg = (
52 |             f"{resp.status_code} Server Error: {reason} for url: {resp.url}"
53 |         )
54 | 
55 |     if http_error_msg:
56 |         raise NetworkConnectionError(http_error_msg, response=resp)
57 | 
58 | 
59 | def response_chunks(
60 |     response: Response, chunk_size: int = DOWNLOAD_CHUNK_SIZE
61 | ) -> Generator[bytes, None, None]:
62 |     """Given a requests Response, provide the data chunks."""
63 |     try:
64 |         # Special case for urllib3.
65 |         for chunk in response.raw.stream(
66 |             chunk_size,
67 |             # We use decode_content=False here because we don't
68 |             # want urllib3 to mess with the raw bytes we get
69 |             # from the server. If we decompress inside of
70 |             # urllib3 then we cannot verify the checksum
71 |             # because the checksum will be of the compressed
72 |             # file. This breakage will only occur if the
73 |             # server adds a Content-Encoding header, which
74 |             # depends on how the server was configured:
75 |             # - Some servers will notice that the file isn't a
76 |             #   compressible file and will leave the file alone
77 |             #   and with an empty Content-Encoding
78 |             # - Some servers will notice that the file is
79 |             #   already compressed and will leave the file
80 |             #   alone and will add a Content-Encoding: gzip
81 |             #   header
82 |             # - Some servers won't notice anything at all and
83 |             #   will take a file that's already been compressed
84 |             #   and compress it again and set the
85 |             #   Content-Encoding: gzip header
86 |             #
87 |             # By setting this not to decode automatically we
88 |             # hope to eliminate problems with the second case.
89 |             decode_content=False,
90 |         ):
91 |             yield chunk
92 |     except AttributeError:
93 |         # Standard file-like object.
94 |         while True:
95 |             chunk = response.raw.read(chunk_size)
96 |             if not chunk:
97 |                 break
98 |             yield chunk
```

.venv/lib/python3.13/site-packages/pip/_internal/network/xmlrpc.py
```
1 | """xmlrpclib.Transport implementation"""
2 | 
3 | import logging
4 | import urllib.parse
5 | import xmlrpc.client
6 | from typing import TYPE_CHECKING, Tuple
7 | 
8 | from pip._internal.exceptions import NetworkConnectionError
9 | from pip._internal.network.session import PipSession
10 | from pip._internal.network.utils import raise_for_status
11 | 
12 | if TYPE_CHECKING:
13 |     from xmlrpc.client import _HostType, _Marshallable
14 | 
15 |     from _typeshed import SizedBuffer
16 | 
17 | logger = logging.getLogger(__name__)
18 | 
19 | 
20 | class PipXmlrpcTransport(xmlrpc.client.Transport):
21 |     """Provide a `xmlrpclib.Transport` implementation via a `PipSession`
22 |     object.
23 |     """
24 | 
25 |     def __init__(
26 |         self, index_url: str, session: PipSession, use_datetime: bool = False
27 |     ) -> None:
28 |         super().__init__(use_datetime)
29 |         index_parts = urllib.parse.urlparse(index_url)
30 |         self._scheme = index_parts.scheme
31 |         self._session = session
32 | 
33 |     def request(
34 |         self,
35 |         host: "_HostType",
36 |         handler: str,
37 |         request_body: "SizedBuffer",
38 |         verbose: bool = False,
39 |     ) -> Tuple["_Marshallable", ...]:
40 |         assert isinstance(host, str)
41 |         parts = (self._scheme, host, handler, None, None, None)
42 |         url = urllib.parse.urlunparse(parts)
43 |         try:
44 |             headers = {"Content-Type": "text/xml"}
45 |             response = self._session.post(
46 |                 url,
47 |                 data=request_body,
48 |                 headers=headers,
49 |                 stream=True,
50 |             )
51 |             raise_for_status(response)
52 |             self.verbose = verbose
53 |             return self.parse_response(response.raw)
54 |         except NetworkConnectionError as exc:
55 |             assert exc.response
56 |             logger.critical(
57 |                 "HTTP error %s while getting %s",
58 |                 exc.response.status_code,
59 |                 url,
60 |             )
61 |             raise
```

.venv/lib/python3.13/site-packages/pip/_internal/models/__init__.py
```
1 | """A package that contains models that represent entities."""
```

.venv/lib/python3.13/site-packages/pip/_internal/models/candidate.py
```
1 | from dataclasses import dataclass
2 | 
3 | from pip._vendor.packaging.version import Version
4 | from pip._vendor.packaging.version import parse as parse_version
5 | 
6 | from pip._internal.models.link import Link
7 | 
8 | 
9 | @dataclass(frozen=True)
10 | class InstallationCandidate:
11 |     """Represents a potential "candidate" for installation."""
12 | 
13 |     __slots__ = ["name", "version", "link"]
14 | 
15 |     name: str
16 |     version: Version
17 |     link: Link
18 | 
19 |     def __init__(self, name: str, version: str, link: Link) -> None:
20 |         object.__setattr__(self, "name", name)
21 |         object.__setattr__(self, "version", parse_version(version))
22 |         object.__setattr__(self, "link", link)
23 | 
24 |     def __str__(self) -> str:
25 |         return f"{self.name!r} candidate (version {self.version} at {self.link})"
```

.venv/lib/python3.13/site-packages/pip/_internal/models/direct_url.py
```
1 | """PEP 610"""
2 | 
3 | import json
4 | import re
5 | import urllib.parse
6 | from dataclasses import dataclass
7 | from typing import Any, ClassVar, Dict, Iterable, Optional, Type, TypeVar, Union
8 | 
9 | __all__ = [
10 |     "DirectUrl",
11 |     "DirectUrlValidationError",
12 |     "DirInfo",
13 |     "ArchiveInfo",
14 |     "VcsInfo",
15 | ]
16 | 
17 | T = TypeVar("T")
18 | 
19 | DIRECT_URL_METADATA_NAME = "direct_url.json"
20 | ENV_VAR_RE = re.compile(r"^\$\{[A-Za-z0-9-_]+\}(:\$\{[A-Za-z0-9-_]+\})?$")
21 | 
22 | 
23 | class DirectUrlValidationError(Exception):
24 |     pass
25 | 
26 | 
27 | def _get(
28 |     d: Dict[str, Any], expected_type: Type[T], key: str, default: Optional[T] = None
29 | ) -> Optional[T]:
30 |     """Get value from dictionary and verify expected type."""
31 |     if key not in d:
32 |         return default
33 |     value = d[key]
34 |     if not isinstance(value, expected_type):
35 |         raise DirectUrlValidationError(
36 |             f"{value!r} has unexpected type for {key} (expected {expected_type})"
37 |         )
38 |     return value
39 | 
40 | 
41 | def _get_required(
42 |     d: Dict[str, Any], expected_type: Type[T], key: str, default: Optional[T] = None
43 | ) -> T:
44 |     value = _get(d, expected_type, key, default)
45 |     if value is None:
46 |         raise DirectUrlValidationError(f"{key} must have a value")
47 |     return value
48 | 
49 | 
50 | def _exactly_one_of(infos: Iterable[Optional["InfoType"]]) -> "InfoType":
51 |     infos = [info for info in infos if info is not None]
52 |     if not infos:
53 |         raise DirectUrlValidationError(
54 |             "missing one of archive_info, dir_info, vcs_info"
55 |         )
56 |     if len(infos) > 1:
57 |         raise DirectUrlValidationError(
58 |             "more than one of archive_info, dir_info, vcs_info"
59 |         )
60 |     assert infos[0] is not None
61 |     return infos[0]
62 | 
63 | 
64 | def _filter_none(**kwargs: Any) -> Dict[str, Any]:
65 |     """Make dict excluding None values."""
66 |     return {k: v for k, v in kwargs.items() if v is not None}
67 | 
68 | 
69 | @dataclass
70 | class VcsInfo:
71 |     name: ClassVar = "vcs_info"
72 | 
73 |     vcs: str
74 |     commit_id: str
75 |     requested_revision: Optional[str] = None
76 | 
77 |     @classmethod
78 |     def _from_dict(cls, d: Optional[Dict[str, Any]]) -> Optional["VcsInfo"]:
79 |         if d is None:
80 |             return None
81 |         return cls(
82 |             vcs=_get_required(d, str, "vcs"),
83 |             commit_id=_get_required(d, str, "commit_id"),
84 |             requested_revision=_get(d, str, "requested_revision"),
85 |         )
86 | 
87 |     def _to_dict(self) -> Dict[str, Any]:
88 |         return _filter_none(
89 |             vcs=self.vcs,
90 |             requested_revision=self.requested_revision,
91 |             commit_id=self.commit_id,
92 |         )
93 | 
94 | 
95 | class ArchiveInfo:
96 |     name = "archive_info"
97 | 
98 |     def __init__(
99 |         self,
100 |         hash: Optional[str] = None,
101 |         hashes: Optional[Dict[str, str]] = None,
102 |     ) -> None:
103 |         # set hashes before hash, since the hash setter will further populate hashes
104 |         self.hashes = hashes
105 |         self.hash = hash
106 | 
107 |     @property
108 |     def hash(self) -> Optional[str]:
109 |         return self._hash
110 | 
111 |     @hash.setter
112 |     def hash(self, value: Optional[str]) -> None:
113 |         if value is not None:
114 |             # Auto-populate the hashes key to upgrade to the new format automatically.
115 |             # We don't back-populate the legacy hash key from hashes.
116 |             try:
117 |                 hash_name, hash_value = value.split("=", 1)
118 |             except ValueError:
119 |                 raise DirectUrlValidationError(
120 |                     f"invalid archive_info.hash format: {value!r}"
121 |                 )
122 |             if self.hashes is None:
123 |                 self.hashes = {hash_name: hash_value}
124 |             elif hash_name not in self.hashes:
125 |                 self.hashes = self.hashes.copy()
126 |                 self.hashes[hash_name] = hash_value
127 |         self._hash = value
128 | 
129 |     @classmethod
130 |     def _from_dict(cls, d: Optional[Dict[str, Any]]) -> Optional["ArchiveInfo"]:
131 |         if d is None:
132 |             return None
133 |         return cls(hash=_get(d, str, "hash"), hashes=_get(d, dict, "hashes"))
134 | 
135 |     def _to_dict(self) -> Dict[str, Any]:
136 |         return _filter_none(hash=self.hash, hashes=self.hashes)
137 | 
138 | 
139 | @dataclass
140 | class DirInfo:
141 |     name: ClassVar = "dir_info"
142 | 
143 |     editable: bool = False
144 | 
145 |     @classmethod
146 |     def _from_dict(cls, d: Optional[Dict[str, Any]]) -> Optional["DirInfo"]:
147 |         if d is None:
148 |             return None
149 |         return cls(editable=_get_required(d, bool, "editable", default=False))
150 | 
151 |     def _to_dict(self) -> Dict[str, Any]:
152 |         return _filter_none(editable=self.editable or None)
153 | 
154 | 
155 | InfoType = Union[ArchiveInfo, DirInfo, VcsInfo]
156 | 
157 | 
158 | @dataclass
159 | class DirectUrl:
160 |     url: str
161 |     info: InfoType
162 |     subdirectory: Optional[str] = None
163 | 
164 |     def _remove_auth_from_netloc(self, netloc: str) -> str:
165 |         if "@" not in netloc:
166 |             return netloc
167 |         user_pass, netloc_no_user_pass = netloc.split("@", 1)
168 |         if (
169 |             isinstance(self.info, VcsInfo)
170 |             and self.info.vcs == "git"
171 |             and user_pass == "git"
172 |         ):
173 |             return netloc
174 |         if ENV_VAR_RE.match(user_pass):
175 |             return netloc
176 |         return netloc_no_user_pass
177 | 
178 |     @property
179 |     def redacted_url(self) -> str:
180 |         """url with user:password part removed unless it is formed with
181 |         environment variables as specified in PEP 610, or it is ``git``
182 |         in the case of a git URL.
183 |         """
184 |         purl = urllib.parse.urlsplit(self.url)
185 |         netloc = self._remove_auth_from_netloc(purl.netloc)
186 |         surl = urllib.parse.urlunsplit(
187 |             (purl.scheme, netloc, purl.path, purl.query, purl.fragment)
188 |         )
189 |         return surl
190 | 
191 |     def validate(self) -> None:
192 |         self.from_dict(self.to_dict())
193 | 
194 |     @classmethod
195 |     def from_dict(cls, d: Dict[str, Any]) -> "DirectUrl":
196 |         return DirectUrl(
197 |             url=_get_required(d, str, "url"),
198 |             subdirectory=_get(d, str, "subdirectory"),
199 |             info=_exactly_one_of(
200 |                 [
201 |                     ArchiveInfo._from_dict(_get(d, dict, "archive_info")),
202 |                     DirInfo._from_dict(_get(d, dict, "dir_info")),
203 |                     VcsInfo._from_dict(_get(d, dict, "vcs_info")),
204 |                 ]
205 |             ),
206 |         )
207 | 
208 |     def to_dict(self) -> Dict[str, Any]:
209 |         res = _filter_none(
210 |             url=self.redacted_url,
211 |             subdirectory=self.subdirectory,
212 |         )
213 |         res[self.info.name] = self.info._to_dict()
214 |         return res
215 | 
216 |     @classmethod
217 |     def from_json(cls, s: str) -> "DirectUrl":
218 |         return cls.from_dict(json.loads(s))
219 | 
220 |     def to_json(self) -> str:
221 |         return json.dumps(self.to_dict(), sort_keys=True)
222 | 
223 |     def is_local_editable(self) -> bool:
224 |         return isinstance(self.info, DirInfo) and self.info.editable
```

.venv/lib/python3.13/site-packages/pip/_internal/models/format_control.py
```
1 | from typing import FrozenSet, Optional, Set
2 | 
3 | from pip._vendor.packaging.utils import canonicalize_name
4 | 
5 | from pip._internal.exceptions import CommandError
6 | 
7 | 
8 | class FormatControl:
9 |     """Helper for managing formats from which a package can be installed."""
10 | 
11 |     __slots__ = ["no_binary", "only_binary"]
12 | 
13 |     def __init__(
14 |         self,
15 |         no_binary: Optional[Set[str]] = None,
16 |         only_binary: Optional[Set[str]] = None,
17 |     ) -> None:
18 |         if no_binary is None:
19 |             no_binary = set()
20 |         if only_binary is None:
21 |             only_binary = set()
22 | 
23 |         self.no_binary = no_binary
24 |         self.only_binary = only_binary
25 | 
26 |     def __eq__(self, other: object) -> bool:
27 |         if not isinstance(other, self.__class__):
28 |             return NotImplemented
29 | 
30 |         if self.__slots__ != other.__slots__:
31 |             return False
32 | 
33 |         return all(getattr(self, k) == getattr(other, k) for k in self.__slots__)
34 | 
35 |     def __repr__(self) -> str:
36 |         return f"{self.__class__.__name__}({self.no_binary}, {self.only_binary})"
37 | 
38 |     @staticmethod
39 |     def handle_mutual_excludes(value: str, target: Set[str], other: Set[str]) -> None:
40 |         if value.startswith("-"):
41 |             raise CommandError(
42 |                 "--no-binary / --only-binary option requires 1 argument."
43 |             )
44 |         new = value.split(",")
45 |         while ":all:" in new:
46 |             other.clear()
47 |             target.clear()
48 |             target.add(":all:")
49 |             del new[: new.index(":all:") + 1]
50 |             # Without a none, we want to discard everything as :all: covers it
51 |             if ":none:" not in new:
52 |                 return
53 |         for name in new:
54 |             if name == ":none:":
55 |                 target.clear()
56 |                 continue
57 |             name = canonicalize_name(name)
58 |             other.discard(name)
59 |             target.add(name)
60 | 
61 |     def get_allowed_formats(self, canonical_name: str) -> FrozenSet[str]:
62 |         result = {"binary", "source"}
63 |         if canonical_name in self.only_binary:
64 |             result.discard("source")
65 |         elif canonical_name in self.no_binary:
66 |             result.discard("binary")
67 |         elif ":all:" in self.only_binary:
68 |             result.discard("source")
69 |         elif ":all:" in self.no_binary:
70 |             result.discard("binary")
71 |         return frozenset(result)
72 | 
73 |     def disallow_binaries(self) -> None:
74 |         self.handle_mutual_excludes(
75 |             ":all:",
76 |             self.no_binary,
77 |             self.only_binary,
78 |         )
```

.venv/lib/python3.13/site-packages/pip/_internal/models/index.py
```
1 | import urllib.parse
2 | 
3 | 
4 | class PackageIndex:
5 |     """Represents a Package Index and provides easier access to endpoints"""
6 | 
7 |     __slots__ = ["url", "netloc", "simple_url", "pypi_url", "file_storage_domain"]
8 | 
9 |     def __init__(self, url: str, file_storage_domain: str) -> None:
10 |         super().__init__()
11 |         self.url = url
12 |         self.netloc = urllib.parse.urlsplit(url).netloc
13 |         self.simple_url = self._url_for_path("simple")
14 |         self.pypi_url = self._url_for_path("pypi")
15 | 
16 |         # This is part of a temporary hack used to block installs of PyPI
17 |         # packages which depend on external urls only necessary until PyPI can
18 |         # block such packages themselves
19 |         self.file_storage_domain = file_storage_domain
20 | 
21 |     def _url_for_path(self, path: str) -> str:
22 |         return urllib.parse.urljoin(self.url, path)
23 | 
24 | 
25 | PyPI = PackageIndex("https://pypi.org/", file_storage_domain="files.pythonhosted.org")
26 | TestPyPI = PackageIndex(
27 |     "https://test.pypi.org/", file_storage_domain="test-files.pythonhosted.org"
28 | )
```

.venv/lib/python3.13/site-packages/pip/_internal/models/installation_report.py
```
1 | from typing import Any, Dict, Sequence
2 | 
3 | from pip._vendor.packaging.markers import default_environment
4 | 
5 | from pip import __version__
6 | from pip._internal.req.req_install import InstallRequirement
7 | 
8 | 
9 | class InstallationReport:
10 |     def __init__(self, install_requirements: Sequence[InstallRequirement]):
11 |         self._install_requirements = install_requirements
12 | 
13 |     @classmethod
14 |     def _install_req_to_dict(cls, ireq: InstallRequirement) -> Dict[str, Any]:
15 |         assert ireq.download_info, f"No download_info for {ireq}"
16 |         res = {
17 |             # PEP 610 json for the download URL. download_info.archive_info.hashes may
18 |             # be absent when the requirement was installed from the wheel cache
19 |             # and the cache entry was populated by an older pip version that did not
20 |             # record origin.json.
21 |             "download_info": ireq.download_info.to_dict(),
22 |             # is_direct is true if the requirement was a direct URL reference (which
23 |             # includes editable requirements), and false if the requirement was
24 |             # downloaded from a PEP 503 index or --find-links.
25 |             "is_direct": ireq.is_direct,
26 |             # is_yanked is true if the requirement was yanked from the index, but
27 |             # was still selected by pip to conform to PEP 592.
28 |             "is_yanked": ireq.link.is_yanked if ireq.link else False,
29 |             # requested is true if the requirement was specified by the user (aka
30 |             # top level requirement), and false if it was installed as a dependency of a
31 |             # requirement. https://peps.python.org/pep-0376/#requested
32 |             "requested": ireq.user_supplied,
33 |             # PEP 566 json encoding for metadata
34 |             # https://www.python.org/dev/peps/pep-0566/#json-compatible-metadata
35 |             "metadata": ireq.get_dist().metadata_dict,
36 |         }
37 |         if ireq.user_supplied and ireq.extras:
38 |             # For top level requirements, the list of requested extras, if any.
39 |             res["requested_extras"] = sorted(ireq.extras)
40 |         return res
41 | 
42 |     def to_dict(self) -> Dict[str, Any]:
43 |         return {
44 |             "version": "1",
45 |             "pip_version": __version__,
46 |             "install": [
47 |                 self._install_req_to_dict(ireq) for ireq in self._install_requirements
48 |             ],
49 |             # https://peps.python.org/pep-0508/#environment-markers
50 |             # TODO: currently, the resolver uses the default environment to evaluate
51 |             # environment markers, so that is what we report here. In the future, it
52 |             # should also take into account options such as --python-version or
53 |             # --platform, perhaps under the form of an environment_override field?
54 |             # https://github.com/pypa/pip/issues/11198
55 |             "environment": default_environment(),
56 |         }
```

.venv/lib/python3.13/site-packages/pip/_internal/models/link.py
```
1 | import functools
2 | import itertools
3 | import logging
4 | import os
5 | import posixpath
6 | import re
7 | import urllib.parse
8 | from dataclasses import dataclass
9 | from typing import (
10 |     TYPE_CHECKING,
11 |     Any,
12 |     Dict,
13 |     List,
14 |     Mapping,
15 |     NamedTuple,
16 |     Optional,
17 |     Tuple,
18 |     Union,
19 | )
20 | 
21 | from pip._internal.utils.deprecation import deprecated
22 | from pip._internal.utils.filetypes import WHEEL_EXTENSION
23 | from pip._internal.utils.hashes import Hashes
24 | from pip._internal.utils.misc import (
25 |     pairwise,
26 |     redact_auth_from_url,
27 |     split_auth_from_netloc,
28 |     splitext,
29 | )
30 | from pip._internal.utils.urls import path_to_url, url_to_path
31 | 
32 | if TYPE_CHECKING:
33 |     from pip._internal.index.collector import IndexContent
34 | 
35 | logger = logging.getLogger(__name__)
36 | 
37 | 
38 | # Order matters, earlier hashes have a precedence over later hashes for what
39 | # we will pick to use.
40 | _SUPPORTED_HASHES = ("sha512", "sha384", "sha256", "sha224", "sha1", "md5")
41 | 
42 | 
43 | @dataclass(frozen=True)
44 | class LinkHash:
45 |     """Links to content may have embedded hash values. This class parses those.
46 | 
47 |     `name` must be any member of `_SUPPORTED_HASHES`.
48 | 
49 |     This class can be converted to and from `ArchiveInfo`. While ArchiveInfo intends to
50 |     be JSON-serializable to conform to PEP 610, this class contains the logic for
51 |     parsing a hash name and value for correctness, and then checking whether that hash
52 |     conforms to a schema with `.is_hash_allowed()`."""
53 | 
54 |     name: str
55 |     value: str
56 | 
57 |     _hash_url_fragment_re = re.compile(
58 |         # NB: we do not validate that the second group (.*) is a valid hex
59 |         # digest. Instead, we simply keep that string in this class, and then check it
60 |         # against Hashes when hash-checking is needed. This is easier to debug than
61 |         # proactively discarding an invalid hex digest, as we handle incorrect hashes
62 |         # and malformed hashes in the same place.
63 |         r"[#&]({choices})=([^&]*)".format(
64 |             choices="|".join(re.escape(hash_name) for hash_name in _SUPPORTED_HASHES)
65 |         ),
66 |     )
67 | 
68 |     def __post_init__(self) -> None:
69 |         assert self.name in _SUPPORTED_HASHES
70 | 
71 |     @classmethod
72 |     @functools.lru_cache(maxsize=None)
73 |     def find_hash_url_fragment(cls, url: str) -> Optional["LinkHash"]:
74 |         """Search a string for a checksum algorithm name and encoded output value."""
75 |         match = cls._hash_url_fragment_re.search(url)
76 |         if match is None:
77 |             return None
78 |         name, value = match.groups()
79 |         return cls(name=name, value=value)
80 | 
81 |     def as_dict(self) -> Dict[str, str]:
82 |         return {self.name: self.value}
83 | 
84 |     def as_hashes(self) -> Hashes:
85 |         """Return a Hashes instance which checks only for the current hash."""
86 |         return Hashes({self.name: [self.value]})
87 | 
88 |     def is_hash_allowed(self, hashes: Optional[Hashes]) -> bool:
89 |         """
90 |         Return True if the current hash is allowed by `hashes`.
91 |         """
92 |         if hashes is None:
93 |             return False
94 |         return hashes.is_hash_allowed(self.name, hex_digest=self.value)
95 | 
96 | 
97 | @dataclass(frozen=True)
98 | class MetadataFile:
99 |     """Information about a core metadata file associated with a distribution."""
100 | 
101 |     hashes: Optional[Dict[str, str]]
102 | 
103 |     def __post_init__(self) -> None:
104 |         if self.hashes is not None:
105 |             assert all(name in _SUPPORTED_HASHES for name in self.hashes)
106 | 
107 | 
108 | def supported_hashes(hashes: Optional[Dict[str, str]]) -> Optional[Dict[str, str]]:
109 |     # Remove any unsupported hash types from the mapping. If this leaves no
110 |     # supported hashes, return None
111 |     if hashes is None:
112 |         return None
113 |     hashes = {n: v for n, v in hashes.items() if n in _SUPPORTED_HASHES}
114 |     if not hashes:
115 |         return None
116 |     return hashes
117 | 
118 | 
119 | def _clean_url_path_part(part: str) -> str:
120 |     """
121 |     Clean a "part" of a URL path (i.e. after splitting on "@" characters).
122 |     """
123 |     # We unquote prior to quoting to make sure nothing is double quoted.
124 |     return urllib.parse.quote(urllib.parse.unquote(part))
125 | 
126 | 
127 | def _clean_file_url_path(part: str) -> str:
128 |     """
129 |     Clean the first part of a URL path that corresponds to a local
130 |     filesystem path (i.e. the first part after splitting on "@" characters).
131 |     """
132 |     # We unquote prior to quoting to make sure nothing is double quoted.
133 |     # Also, on Windows the path part might contain a drive letter which
134 |     # should not be quoted. On Linux where drive letters do not
135 |     # exist, the colon should be quoted. We rely on urllib.request
136 |     # to do the right thing here.
137 |     return urllib.request.pathname2url(urllib.request.url2pathname(part))
138 | 
139 | 
140 | # percent-encoded:                   /
141 | _reserved_chars_re = re.compile("(@|%2F)", re.IGNORECASE)
142 | 
143 | 
144 | def _clean_url_path(path: str, is_local_path: bool) -> str:
145 |     """
146 |     Clean the path portion of a URL.
147 |     """
148 |     if is_local_path:
149 |         clean_func = _clean_file_url_path
150 |     else:
151 |         clean_func = _clean_url_path_part
152 | 
153 |     # Split on the reserved characters prior to cleaning so that
154 |     # revision strings in VCS URLs are properly preserved.
155 |     parts = _reserved_chars_re.split(path)
156 | 
157 |     cleaned_parts = []
158 |     for to_clean, reserved in pairwise(itertools.chain(parts, [""])):
159 |         cleaned_parts.append(clean_func(to_clean))
160 |         # Normalize %xx escapes (e.g. %2f -> %2F)
161 |         cleaned_parts.append(reserved.upper())
162 | 
163 |     return "".join(cleaned_parts)
164 | 
165 | 
166 | def _ensure_quoted_url(url: str) -> str:
167 |     """
168 |     Make sure a link is fully quoted.
169 |     For example, if ' ' occurs in the URL, it will be replaced with "%20",
170 |     and without double-quoting other characters.
171 |     """
172 |     # Split the URL into parts according to the general structure
173 |     # `scheme://netloc/path?query#fragment`.
174 |     result = urllib.parse.urlsplit(url)
175 |     # If the netloc is empty, then the URL refers to a local filesystem path.
176 |     is_local_path = not result.netloc
177 |     path = _clean_url_path(result.path, is_local_path=is_local_path)
178 |     return urllib.parse.urlunsplit(result._replace(path=path))
179 | 
180 | 
181 | def _absolute_link_url(base_url: str, url: str) -> str:
182 |     """
183 |     A faster implementation of urllib.parse.urljoin with a shortcut
184 |     for absolute http/https URLs.
185 |     """
186 |     if url.startswith(("https://", "http://")):
187 |         return url
188 |     else:
189 |         return urllib.parse.urljoin(base_url, url)
190 | 
191 | 
192 | @functools.total_ordering
193 | class Link:
194 |     """Represents a parsed link from a Package Index's simple URL"""
195 | 
196 |     __slots__ = [
197 |         "_parsed_url",
198 |         "_url",
199 |         "_path",
200 |         "_hashes",
201 |         "comes_from",
202 |         "requires_python",
203 |         "yanked_reason",
204 |         "metadata_file_data",
205 |         "cache_link_parsing",
206 |         "egg_fragment",
207 |     ]
208 | 
209 |     def __init__(
210 |         self,
211 |         url: str,
212 |         comes_from: Optional[Union[str, "IndexContent"]] = None,
213 |         requires_python: Optional[str] = None,
214 |         yanked_reason: Optional[str] = None,
215 |         metadata_file_data: Optional[MetadataFile] = None,
216 |         cache_link_parsing: bool = True,
217 |         hashes: Optional[Mapping[str, str]] = None,
218 |     ) -> None:
219 |         """
220 |         :param url: url of the resource pointed to (href of the link)
221 |         :param comes_from: instance of IndexContent where the link was found,
222 |             or string.
223 |         :param requires_python: String containing the `Requires-Python`
224 |             metadata field, specified in PEP 345. This may be specified by
225 |             a data-requires-python attribute in the HTML link tag, as
226 |             described in PEP 503.
227 |         :param yanked_reason: the reason the file has been yanked, if the
228 |             file has been yanked, or None if the file hasn't been yanked.
229 |             This is the value of the "data-yanked" attribute, if present, in
230 |             a simple repository HTML link. If the file has been yanked but
231 |             no reason was provided, this should be the empty string. See
232 |             PEP 592 for more information and the specification.
233 |         :param metadata_file_data: the metadata attached to the file, or None if
234 |             no such metadata is provided. This argument, if not None, indicates
235 |             that a separate metadata file exists, and also optionally supplies
236 |             hashes for that file.
237 |         :param cache_link_parsing: A flag that is used elsewhere to determine
238 |             whether resources retrieved from this link should be cached. PyPI
239 |             URLs should generally have this set to False, for example.
240 |         :param hashes: A mapping of hash names to digests to allow us to
241 |             determine the validity of a download.
242 |         """
243 | 
244 |         # The comes_from, requires_python, and metadata_file_data arguments are
245 |         # only used by classmethods of this class, and are not used in client
246 |         # code directly.
247 | 
248 |         # url can be a UNC windows share
249 |         if url.startswith("\\\\"):
250 |             url = path_to_url(url)
251 | 
252 |         self._parsed_url = urllib.parse.urlsplit(url)
253 |         # Store the url as a private attribute to prevent accidentally
254 |         # trying to set a new value.
255 |         self._url = url
256 |         # The .path property is hot, so calculate its value ahead of time.
257 |         self._path = urllib.parse.unquote(self._parsed_url.path)
258 | 
259 |         link_hash = LinkHash.find_hash_url_fragment(url)
260 |         hashes_from_link = {} if link_hash is None else link_hash.as_dict()
261 |         if hashes is None:
262 |             self._hashes = hashes_from_link
263 |         else:
264 |             self._hashes = {**hashes, **hashes_from_link}
265 | 
266 |         self.comes_from = comes_from
267 |         self.requires_python = requires_python if requires_python else None
268 |         self.yanked_reason = yanked_reason
269 |         self.metadata_file_data = metadata_file_data
270 | 
271 |         self.cache_link_parsing = cache_link_parsing
272 |         self.egg_fragment = self._egg_fragment()
273 | 
274 |     @classmethod
275 |     def from_json(
276 |         cls,
277 |         file_data: Dict[str, Any],
278 |         page_url: str,
279 |     ) -> Optional["Link"]:
280 |         """
281 |         Convert an pypi json document from a simple repository page into a Link.
282 |         """
283 |         file_url = file_data.get("url")
284 |         if file_url is None:
285 |             return None
286 | 
287 |         url = _ensure_quoted_url(_absolute_link_url(page_url, file_url))
288 |         pyrequire = file_data.get("requires-python")
289 |         yanked_reason = file_data.get("yanked")
290 |         hashes = file_data.get("hashes", {})
291 | 
292 |         # PEP 714: Indexes must use the name core-metadata, but
293 |         # clients should support the old name as a fallback for compatibility.
294 |         metadata_info = file_data.get("core-metadata")
295 |         if metadata_info is None:
296 |             metadata_info = file_data.get("dist-info-metadata")
297 | 
298 |         # The metadata info value may be a boolean, or a dict of hashes.
299 |         if isinstance(metadata_info, dict):
300 |             # The file exists, and hashes have been supplied
301 |             metadata_file_data = MetadataFile(supported_hashes(metadata_info))
302 |         elif metadata_info:
303 |             # The file exists, but there are no hashes
304 |             metadata_file_data = MetadataFile(None)
305 |         else:
306 |             # False or not present: the file does not exist
307 |             metadata_file_data = None
308 | 
309 |         # The Link.yanked_reason expects an empty string instead of a boolean.
310 |         if yanked_reason and not isinstance(yanked_reason, str):
311 |             yanked_reason = ""
312 |         # The Link.yanked_reason expects None instead of False.
313 |         elif not yanked_reason:
314 |             yanked_reason = None
315 | 
316 |         return cls(
317 |             url,
[TRUNCATED]
```

.venv/lib/python3.13/site-packages/pip/_internal/models/pylock.py
```
1 | import dataclasses
2 | import re
3 | from dataclasses import dataclass
4 | from pathlib import Path
5 | from typing import Any, Dict, Iterable, List, Optional, Tuple
6 | 
7 | from pip._vendor import tomli_w
8 | from pip._vendor.typing_extensions import Self
9 | 
10 | from pip._internal.models.direct_url import ArchiveInfo, DirInfo, VcsInfo
11 | from pip._internal.models.link import Link
12 | from pip._internal.req.req_install import InstallRequirement
13 | from pip._internal.utils.urls import url_to_path
14 | 
15 | PYLOCK_FILE_NAME_RE = re.compile(r"^pylock\.([^.]+)\.toml$")
16 | 
17 | 
18 | def is_valid_pylock_file_name(path: Path) -> bool:
19 |     return path.name == "pylock.toml" or bool(re.match(PYLOCK_FILE_NAME_RE, path.name))
20 | 
21 | 
22 | def _toml_dict_factory(data: List[Tuple[str, Any]]) -> Dict[str, Any]:
23 |     return {key.replace("_", "-"): value for key, value in data if value is not None}
24 | 
25 | 
26 | @dataclass
27 | class PackageVcs:
28 |     type: str
29 |     url: Optional[str]
30 |     # (not supported) path: Optional[str]
31 |     requested_revision: Optional[str]
32 |     commit_id: str
33 |     subdirectory: Optional[str]
34 | 
35 | 
36 | @dataclass
37 | class PackageDirectory:
38 |     path: str
39 |     editable: Optional[bool]
40 |     subdirectory: Optional[str]
41 | 
42 | 
43 | @dataclass
44 | class PackageArchive:
45 |     url: Optional[str]
46 |     # (not supported) path: Optional[str]
47 |     # (not supported) size: Optional[int]
48 |     # (not supported) upload_time: Optional[datetime]
49 |     hashes: Dict[str, str]
50 |     subdirectory: Optional[str]
51 | 
52 | 
53 | @dataclass
54 | class PackageSdist:
55 |     name: str
56 |     # (not supported) upload_time: Optional[datetime]
57 |     url: Optional[str]
58 |     # (not supported) path: Optional[str]
59 |     # (not supported) size: Optional[int]
60 |     hashes: Dict[str, str]
61 | 
62 | 
63 | @dataclass
64 | class PackageWheel:
65 |     name: str
66 |     # (not supported) upload_time: Optional[datetime]
67 |     url: Optional[str]
68 |     # (not supported) path: Optional[str]
69 |     # (not supported) size: Optional[int]
70 |     hashes: Dict[str, str]
71 | 
72 | 
73 | @dataclass
74 | class Package:
75 |     name: str
76 |     version: Optional[str] = None
77 |     # (not supported) marker: Optional[str]
78 |     # (not supported) requires_python: Optional[str]
79 |     # (not supported) dependencies
80 |     vcs: Optional[PackageVcs] = None
81 |     directory: Optional[PackageDirectory] = None
82 |     archive: Optional[PackageArchive] = None
83 |     # (not supported) index: Optional[str]
84 |     sdist: Optional[PackageSdist] = None
85 |     wheels: Optional[List[PackageWheel]] = None
86 |     # (not supported) attestation_identities: Optional[List[Dict[str, Any]]]
87 |     # (not supported) tool: Optional[Dict[str, Any]]
88 | 
89 |     @classmethod
90 |     def from_install_requirement(cls, ireq: InstallRequirement, base_dir: Path) -> Self:
91 |         base_dir = base_dir.resolve()
92 |         dist = ireq.get_dist()
93 |         download_info = ireq.download_info
94 |         assert download_info
95 |         package = cls(name=dist.canonical_name)
96 |         if ireq.is_direct:
97 |             if isinstance(download_info.info, VcsInfo):
98 |                 package.vcs = PackageVcs(
99 |                     type=download_info.info.vcs,
100 |                     url=download_info.url,
101 |                     requested_revision=download_info.info.requested_revision,
102 |                     commit_id=download_info.info.commit_id,
103 |                     subdirectory=download_info.subdirectory,
104 |                 )
105 |             elif isinstance(download_info.info, DirInfo):
106 |                 package.directory = PackageDirectory(
107 |                     path=(
108 |                         Path(url_to_path(download_info.url))
109 |                         .resolve()
110 |                         .relative_to(base_dir)
111 |                         .as_posix()
112 |                     ),
113 |                     editable=(
114 |                         download_info.info.editable
115 |                         if download_info.info.editable
116 |                         else None
117 |                     ),
118 |                     subdirectory=download_info.subdirectory,
119 |                 )
120 |             elif isinstance(download_info.info, ArchiveInfo):
121 |                 if not download_info.info.hashes:
122 |                     raise NotImplementedError()
123 |                 package.archive = PackageArchive(
124 |                     url=download_info.url,
125 |                     hashes=download_info.info.hashes,
126 |                     subdirectory=download_info.subdirectory,
127 |                 )
128 |             else:
129 |                 # should never happen
130 |                 raise NotImplementedError()
131 |         else:
132 |             package.version = str(dist.version)
133 |             if isinstance(download_info.info, ArchiveInfo):
134 |                 if not download_info.info.hashes:
135 |                     raise NotImplementedError()
136 |                 link = Link(download_info.url)
137 |                 if link.is_wheel:
138 |                     package.wheels = [
139 |                         PackageWheel(
140 |                             name=link.filename,
141 |                             url=download_info.url,
142 |                             hashes=download_info.info.hashes,
143 |                         )
144 |                     ]
145 |                 else:
146 |                     package.sdist = PackageSdist(
147 |                         name=link.filename,
148 |                         url=download_info.url,
149 |                         hashes=download_info.info.hashes,
150 |                     )
151 |             else:
152 |                 # should never happen
153 |                 raise NotImplementedError()
154 |         return package
155 | 
156 | 
157 | @dataclass
158 | class Pylock:
159 |     lock_version: str = "1.0"
160 |     # (not supported) environments: Optional[List[str]]
161 |     # (not supported) requires_python: Optional[str]
162 |     # (not supported) extras: List[str] = []
163 |     # (not supported) dependency_groups: List[str] = []
164 |     created_by: str = "pip"
165 |     packages: List[Package] = dataclasses.field(default_factory=list)
166 |     # (not supported) tool: Optional[Dict[str, Any]]
167 | 
168 |     def as_toml(self) -> str:
169 |         return tomli_w.dumps(dataclasses.asdict(self, dict_factory=_toml_dict_factory))
170 | 
171 |     @classmethod
172 |     def from_install_requirements(
173 |         cls, install_requirements: Iterable[InstallRequirement], base_dir: Path
174 |     ) -> Self:
175 |         return cls(
176 |             packages=sorted(
177 |                 (
178 |                     Package.from_install_requirement(ireq, base_dir)
179 |                     for ireq in install_requirements
180 |                 ),
181 |                 key=lambda p: p.name,
182 |             )
183 |         )
```

.venv/lib/python3.13/site-packages/pip/_internal/models/scheme.py
```
1 | """
2 | For types associated with installation schemes.
3 | 
4 | For a general overview of available schemes and their context, see
5 | https://docs.python.org/3/install/index.html#alternate-installation.
6 | """
7 | 
8 | from dataclasses import dataclass
9 | 
10 | SCHEME_KEYS = ["platlib", "purelib", "headers", "scripts", "data"]
11 | 
12 | 
13 | @dataclass(frozen=True)
14 | class Scheme:
15 |     """A Scheme holds paths which are used as the base directories for
16 |     artifacts associated with a Python package.
17 |     """
18 | 
19 |     __slots__ = SCHEME_KEYS
20 | 
21 |     platlib: str
22 |     purelib: str
23 |     headers: str
24 |     scripts: str
25 |     data: str
```

.venv/lib/python3.13/site-packages/pip/_internal/models/search_scope.py
```
1 | import itertools
2 | import logging
3 | import os
4 | import posixpath
5 | import urllib.parse
6 | from dataclasses import dataclass
7 | from typing import List
8 | 
9 | from pip._vendor.packaging.utils import canonicalize_name
10 | 
11 | from pip._internal.models.index import PyPI
12 | from pip._internal.utils.compat import has_tls
13 | from pip._internal.utils.misc import normalize_path, redact_auth_from_url
14 | 
15 | logger = logging.getLogger(__name__)
16 | 
17 | 
18 | @dataclass(frozen=True)
19 | class SearchScope:
20 |     """
21 |     Encapsulates the locations that pip is configured to search.
22 |     """
23 | 
24 |     __slots__ = ["find_links", "index_urls", "no_index"]
25 | 
26 |     find_links: List[str]
27 |     index_urls: List[str]
28 |     no_index: bool
29 | 
30 |     @classmethod
31 |     def create(
32 |         cls,
33 |         find_links: List[str],
34 |         index_urls: List[str],
35 |         no_index: bool,
36 |     ) -> "SearchScope":
37 |         """
38 |         Create a SearchScope object after normalizing the `find_links`.
39 |         """
40 |         # Build find_links. If an argument starts with ~, it may be
41 |         # a local file relative to a home directory. So try normalizing
42 |         # it and if it exists, use the normalized version.
43 |         # This is deliberately conservative - it might be fine just to
44 |         # blindly normalize anything starting with a ~...
45 |         built_find_links: List[str] = []
46 |         for link in find_links:
47 |             if link.startswith("~"):
48 |                 new_link = normalize_path(link)
49 |                 if os.path.exists(new_link):
50 |                     link = new_link
51 |             built_find_links.append(link)
52 | 
53 |         # If we don't have TLS enabled, then WARN if anyplace we're looking
54 |         # relies on TLS.
55 |         if not has_tls():
56 |             for link in itertools.chain(index_urls, built_find_links):
57 |                 parsed = urllib.parse.urlparse(link)
58 |                 if parsed.scheme == "https":
59 |                     logger.warning(
60 |                         "pip is configured with locations that require "
61 |                         "TLS/SSL, however the ssl module in Python is not "
62 |                         "available."
63 |                     )
64 |                     break
65 | 
66 |         return cls(
67 |             find_links=built_find_links,
68 |             index_urls=index_urls,
69 |             no_index=no_index,
70 |         )
71 | 
72 |     def get_formatted_locations(self) -> str:
73 |         lines = []
74 |         redacted_index_urls = []
75 |         if self.index_urls and self.index_urls != [PyPI.simple_url]:
76 |             for url in self.index_urls:
77 |                 redacted_index_url = redact_auth_from_url(url)
78 | 
79 |                 # Parse the URL
80 |                 purl = urllib.parse.urlsplit(redacted_index_url)
81 | 
82 |                 # URL is generally invalid if scheme and netloc is missing
83 |                 # there are issues with Python and URL parsing, so this test
84 |                 # is a bit crude. See bpo-20271, bpo-23505. Python doesn't
85 |                 # always parse invalid URLs correctly - it should raise
86 |                 # exceptions for malformed URLs
87 |                 if not purl.scheme and not purl.netloc:
88 |                     logger.warning(
89 |                         'The index url "%s" seems invalid, please provide a scheme.',
90 |                         redacted_index_url,
91 |                     )
92 | 
93 |                 redacted_index_urls.append(redacted_index_url)
94 | 
95 |             lines.append(
96 |                 "Looking in indexes: {}".format(", ".join(redacted_index_urls))
97 |             )
98 | 
99 |         if self.find_links:
100 |             lines.append(
101 |                 "Looking in links: {}".format(
102 |                     ", ".join(redact_auth_from_url(url) for url in self.find_links)
103 |                 )
104 |             )
105 |         return "\n".join(lines)
106 | 
107 |     def get_index_urls_locations(self, project_name: str) -> List[str]:
108 |         """Returns the locations found via self.index_urls
109 | 
110 |         Checks the url_name on the main (first in the list) index and
111 |         use this url_name to produce all locations
112 |         """
113 | 
114 |         def mkurl_pypi_url(url: str) -> str:
115 |             loc = posixpath.join(
116 |                 url, urllib.parse.quote(canonicalize_name(project_name))
117 |             )
118 |             # For maximum compatibility with easy_install, ensure the path
119 |             # ends in a trailing slash.  Although this isn't in the spec
120 |             # (and PyPI can handle it without the slash) some other index
121 |             # implementations might break if they relied on easy_install's
122 |             # behavior.
123 |             if not loc.endswith("/"):
124 |                 loc = loc + "/"
125 |             return loc
126 | 
127 |         return [mkurl_pypi_url(url) for url in self.index_urls]
```

.venv/lib/python3.13/site-packages/pip/_internal/models/selection_prefs.py
```
1 | from typing import Optional
2 | 
3 | from pip._internal.models.format_control import FormatControl
4 | 
5 | 
6 | # TODO: This needs Python 3.10's improved slots support for dataclasses
7 | # to be converted into a dataclass.
8 | class SelectionPreferences:
9 |     """
10 |     Encapsulates the candidate selection preferences for downloading
11 |     and installing files.
12 |     """
13 | 
14 |     __slots__ = [
15 |         "allow_yanked",
16 |         "allow_all_prereleases",
17 |         "format_control",
18 |         "prefer_binary",
19 |         "ignore_requires_python",
20 |     ]
21 | 
22 |     # Don't include an allow_yanked default value to make sure each call
23 |     # site considers whether yanked releases are allowed. This also causes
24 |     # that decision to be made explicit in the calling code, which helps
25 |     # people when reading the code.
26 |     def __init__(
27 |         self,
28 |         allow_yanked: bool,
29 |         allow_all_prereleases: bool = False,
30 |         format_control: Optional[FormatControl] = None,
31 |         prefer_binary: bool = False,
32 |         ignore_requires_python: Optional[bool] = None,
33 |     ) -> None:
34 |         """Create a SelectionPreferences object.
35 | 
36 |         :param allow_yanked: Whether files marked as yanked (in the sense
37 |             of PEP 592) are permitted to be candidates for install.
38 |         :param format_control: A FormatControl object or None. Used to control
39 |             the selection of source packages / binary packages when consulting
40 |             the index and links.
41 |         :param prefer_binary: Whether to prefer an old, but valid, binary
42 |             dist over a new source dist.
43 |         :param ignore_requires_python: Whether to ignore incompatible
44 |             "Requires-Python" values in links. Defaults to False.
45 |         """
46 |         if ignore_requires_python is None:
47 |             ignore_requires_python = False
48 | 
49 |         self.allow_yanked = allow_yanked
50 |         self.allow_all_prereleases = allow_all_prereleases
51 |         self.format_control = format_control
52 |         self.prefer_binary = prefer_binary
53 |         self.ignore_requires_python = ignore_requires_python
```

.venv/lib/python3.13/site-packages/pip/_internal/models/target_python.py
```
1 | import sys
2 | from typing import List, Optional, Set, Tuple
3 | 
4 | from pip._vendor.packaging.tags import Tag
5 | 
6 | from pip._internal.utils.compatibility_tags import get_supported, version_info_to_nodot
7 | from pip._internal.utils.misc import normalize_version_info
8 | 
9 | 
10 | class TargetPython:
11 |     """
12 |     Encapsulates the properties of a Python interpreter one is targeting
13 |     for a package install, download, etc.
14 |     """
15 | 
16 |     __slots__ = [
17 |         "_given_py_version_info",
18 |         "abis",
19 |         "implementation",
20 |         "platforms",
21 |         "py_version",
22 |         "py_version_info",
23 |         "_valid_tags",
24 |         "_valid_tags_set",
25 |     ]
26 | 
27 |     def __init__(
28 |         self,
29 |         platforms: Optional[List[str]] = None,
30 |         py_version_info: Optional[Tuple[int, ...]] = None,
31 |         abis: Optional[List[str]] = None,
32 |         implementation: Optional[str] = None,
33 |     ) -> None:
34 |         """
35 |         :param platforms: A list of strings or None. If None, searches for
36 |             packages that are supported by the current system. Otherwise, will
37 |             find packages that can be built on the platforms passed in. These
38 |             packages will only be downloaded for distribution: they will
39 |             not be built locally.
40 |         :param py_version_info: An optional tuple of ints representing the
41 |             Python version information to use (e.g. `sys.version_info[:3]`).
42 |             This can have length 1, 2, or 3 when provided.
43 |         :param abis: A list of strings or None. This is passed to
44 |             compatibility_tags.py's get_supported() function as is.
45 |         :param implementation: A string or None. This is passed to
46 |             compatibility_tags.py's get_supported() function as is.
47 |         """
48 |         # Store the given py_version_info for when we call get_supported().
49 |         self._given_py_version_info = py_version_info
50 | 
51 |         if py_version_info is None:
52 |             py_version_info = sys.version_info[:3]
53 |         else:
54 |             py_version_info = normalize_version_info(py_version_info)
55 | 
56 |         py_version = ".".join(map(str, py_version_info[:2]))
57 | 
58 |         self.abis = abis
59 |         self.implementation = implementation
60 |         self.platforms = platforms
61 |         self.py_version = py_version
62 |         self.py_version_info = py_version_info
63 | 
64 |         # This is used to cache the return value of get_(un)sorted_tags.
65 |         self._valid_tags: Optional[List[Tag]] = None
66 |         self._valid_tags_set: Optional[Set[Tag]] = None
67 | 
68 |     def format_given(self) -> str:
69 |         """
70 |         Format the given, non-None attributes for display.
71 |         """
72 |         display_version = None
73 |         if self._given_py_version_info is not None:
74 |             display_version = ".".join(
75 |                 str(part) for part in self._given_py_version_info
76 |             )
77 | 
78 |         key_values = [
79 |             ("platforms", self.platforms),
80 |             ("version_info", display_version),
81 |             ("abis", self.abis),
82 |             ("implementation", self.implementation),
83 |         ]
84 |         return " ".join(
85 |             f"{key}={value!r}" for key, value in key_values if value is not None
86 |         )
87 | 
88 |     def get_sorted_tags(self) -> List[Tag]:
89 |         """
90 |         Return the supported PEP 425 tags to check wheel candidates against.
91 | 
92 |         The tags are returned in order of preference (most preferred first).
93 |         """
94 |         if self._valid_tags is None:
95 |             # Pass versions=None if no py_version_info was given since
96 |             # versions=None uses special default logic.
97 |             py_version_info = self._given_py_version_info
98 |             if py_version_info is None:
99 |                 version = None
100 |             else:
101 |                 version = version_info_to_nodot(py_version_info)
102 | 
103 |             tags = get_supported(
104 |                 version=version,
105 |                 platforms=self.platforms,
106 |                 abis=self.abis,
107 |                 impl=self.implementation,
108 |             )
109 |             self._valid_tags = tags
110 | 
111 |         return self._valid_tags
112 | 
113 |     def get_unsorted_tags(self) -> Set[Tag]:
114 |         """Exactly the same as get_sorted_tags, but returns a set.
115 | 
116 |         This is important for performance.
117 |         """
118 |         if self._valid_tags_set is None:
119 |             self._valid_tags_set = set(self.get_sorted_tags())
120 | 
121 |         return self._valid_tags_set
```

.venv/lib/python3.13/site-packages/pip/_internal/models/wheel.py
```
1 | """Represents a wheel file and provides access to the various parts of the
2 | name that have meaning.
3 | """
4 | 
5 | import re
6 | from typing import Dict, Iterable, List, Optional
7 | 
8 | from pip._vendor.packaging.tags import Tag
9 | from pip._vendor.packaging.utils import BuildTag, parse_wheel_filename
10 | from pip._vendor.packaging.utils import (
11 |     InvalidWheelFilename as _PackagingInvalidWheelFilename,
12 | )
13 | 
14 | from pip._internal.exceptions import InvalidWheelFilename
15 | from pip._internal.utils.deprecation import deprecated
16 | 
17 | 
18 | class Wheel:
19 |     """A wheel file"""
20 | 
21 |     legacy_wheel_file_re = re.compile(
22 |         r"""^(?P<namever>(?P<name>[^\s-]+?)-(?P<ver>[^\s-]*?))
23 |         ((-(?P<build>\d[^-]*?))?-(?P<pyver>[^\s-]+?)-(?P<abi>[^\s-]+?)-(?P<plat>[^\s-]+?)
24 |         \.whl|\.dist-info)$""",
25 |         re.VERBOSE,
26 |     )
27 | 
28 |     def __init__(self, filename: str) -> None:
29 |         self.filename = filename
30 | 
31 |         # To make mypy happy specify type hints that can come from either
32 |         # parse_wheel_filename or the legacy_wheel_file_re match.
33 |         self.name: str
34 |         self._build_tag: Optional[BuildTag] = None
35 | 
36 |         try:
37 |             wheel_info = parse_wheel_filename(filename)
38 |             self.name, _version, self._build_tag, self.file_tags = wheel_info
39 |             self.version = str(_version)
40 |         except _PackagingInvalidWheelFilename as e:
41 |             # Check if the wheel filename is in the legacy format
42 |             legacy_wheel_info = self.legacy_wheel_file_re.match(filename)
43 |             if not legacy_wheel_info:
44 |                 raise InvalidWheelFilename(e.args[0]) from None
45 | 
46 |             deprecated(
47 |                 reason=(
48 |                     f"Wheel filename {filename!r} is not correctly normalised. "
49 |                     "Future versions of pip will raise the following error:\n"
50 |                     f"{e.args[0]}\n\n"
51 |                 ),
52 |                 replacement=(
53 |                     "to rename the wheel to use a correctly normalised "
54 |                     "name (this may require updating the version in "
55 |                     "the project metadata)"
56 |                 ),
57 |                 gone_in="25.3",
58 |                 issue=12938,
59 |             )
60 | 
61 |             self.name = legacy_wheel_info.group("name").replace("_", "-")
62 |             self.version = legacy_wheel_info.group("ver").replace("_", "-")
63 | 
64 |             # Generate the file tags from the legacy wheel filename
65 |             pyversions = legacy_wheel_info.group("pyver").split(".")
66 |             abis = legacy_wheel_info.group("abi").split(".")
67 |             plats = legacy_wheel_info.group("plat").split(".")
68 |             self.file_tags = frozenset(
69 |                 Tag(interpreter=py, abi=abi, platform=plat)
70 |                 for py in pyversions
71 |                 for abi in abis
72 |                 for plat in plats
73 |             )
74 | 
75 |     @property
76 |     def build_tag(self) -> BuildTag:
77 |         if self._build_tag is not None:
78 |             return self._build_tag
79 | 
80 |         # Parse the build tag from the legacy wheel filename
81 |         legacy_wheel_info = self.legacy_wheel_file_re.match(self.filename)
82 |         assert legacy_wheel_info is not None, "guaranteed by filename validation"
83 |         build_tag = legacy_wheel_info.group("build")
84 |         match = re.match(r"^(\d+)(.*)$", build_tag)
85 |         assert match is not None, "guaranteed by filename validation"
86 |         build_tag_groups = match.groups()
87 |         self._build_tag = (int(build_tag_groups[0]), build_tag_groups[1])
88 | 
89 |         return self._build_tag
90 | 
91 |     def get_formatted_file_tags(self) -> List[str]:
92 |         """Return the wheel's tags as a sorted list of strings."""
93 |         return sorted(str(tag) for tag in self.file_tags)
94 | 
95 |     def support_index_min(self, tags: List[Tag]) -> int:
96 |         """Return the lowest index that one of the wheel's file_tag combinations
97 |         achieves in the given list of supported tags.
98 | 
99 |         For example, if there are 8 supported tags and one of the file tags
100 |         is first in the list, then return 0.
101 | 
102 |         :param tags: the PEP 425 tags to check the wheel against, in order
103 |             with most preferred first.
104 | 
105 |         :raises ValueError: If none of the wheel's file tags match one of
106 |             the supported tags.
107 |         """
108 |         try:
109 |             return next(i for i, t in enumerate(tags) if t in self.file_tags)
110 |         except StopIteration:
111 |             raise ValueError()
112 | 
113 |     def find_most_preferred_tag(
114 |         self, tags: List[Tag], tag_to_priority: Dict[Tag, int]
115 |     ) -> int:
116 |         """Return the priority of the most preferred tag that one of the wheel's file
117 |         tag combinations achieves in the given list of supported tags using the given
118 |         tag_to_priority mapping, where lower priorities are more-preferred.
119 | 
120 |         This is used in place of support_index_min in some cases in order to avoid
121 |         an expensive linear scan of a large list of tags.
122 | 
123 |         :param tags: the PEP 425 tags to check the wheel against.
124 |         :param tag_to_priority: a mapping from tag to priority of that tag, where
125 |             lower is more preferred.
126 | 
127 |         :raises ValueError: If none of the wheel's file tags match one of
128 |             the supported tags.
129 |         """
130 |         return min(
131 |             tag_to_priority[tag] for tag in self.file_tags if tag in tag_to_priority
132 |         )
133 | 
134 |     def supported(self, tags: Iterable[Tag]) -> bool:
135 |         """Return whether the wheel is compatible with one of the given tags.
136 | 
137 |         :param tags: the PEP 425 tags to check the wheel against.
138 |         """
139 |         return not self.file_tags.isdisjoint(tags)
```

.venv/lib/python3.13/site-packages/pip/_internal/resolution/__init__.py
```
```

.venv/lib/python3.13/site-packages/pip/_internal/resolution/base.py
```
1 | from typing import Callable, List, Optional
2 | 
3 | from pip._internal.req.req_install import InstallRequirement
4 | from pip._internal.req.req_set import RequirementSet
5 | 
6 | InstallRequirementProvider = Callable[
7 |     [str, Optional[InstallRequirement]], InstallRequirement
8 | ]
9 | 
10 | 
11 | class BaseResolver:
12 |     def resolve(
13 |         self, root_reqs: List[InstallRequirement], check_supported_wheels: bool
14 |     ) -> RequirementSet:
15 |         raise NotImplementedError()
16 | 
17 |     def get_installation_order(
18 |         self, req_set: RequirementSet
19 |     ) -> List[InstallRequirement]:
20 |         raise NotImplementedError()
```

.venv/lib/python3.13/site-packages/pip/_internal/operations/__init__.py
```
```

.venv/lib/python3.13/site-packages/pip/_internal/operations/check.py
```
1 | """Validation of dependencies of packages"""
2 | 
3 | import logging
4 | from contextlib import suppress
5 | from email.parser import Parser
6 | from functools import reduce
7 | from typing import (
8 |     Callable,
9 |     Dict,
10 |     FrozenSet,
11 |     Generator,
12 |     Iterable,
13 |     List,
14 |     NamedTuple,
15 |     Optional,
16 |     Set,
17 |     Tuple,
18 | )
19 | 
20 | from pip._vendor.packaging.requirements import Requirement
21 | from pip._vendor.packaging.tags import Tag, parse_tag
22 | from pip._vendor.packaging.utils import NormalizedName, canonicalize_name
23 | from pip._vendor.packaging.version import Version
24 | 
25 | from pip._internal.distributions import make_distribution_for_install_requirement
26 | from pip._internal.metadata import get_default_environment
27 | from pip._internal.metadata.base import BaseDistribution
28 | from pip._internal.req.req_install import InstallRequirement
29 | 
30 | logger = logging.getLogger(__name__)
31 | 
32 | 
33 | class PackageDetails(NamedTuple):
34 |     version: Version
35 |     dependencies: List[Requirement]
36 | 
37 | 
38 | # Shorthands
39 | PackageSet = Dict[NormalizedName, PackageDetails]
40 | Missing = Tuple[NormalizedName, Requirement]
41 | Conflicting = Tuple[NormalizedName, Version, Requirement]
42 | 
43 | MissingDict = Dict[NormalizedName, List[Missing]]
44 | ConflictingDict = Dict[NormalizedName, List[Conflicting]]
45 | CheckResult = Tuple[MissingDict, ConflictingDict]
46 | ConflictDetails = Tuple[PackageSet, CheckResult]
47 | 
48 | 
49 | def create_package_set_from_installed() -> Tuple[PackageSet, bool]:
50 |     """Converts a list of distributions into a PackageSet."""
51 |     package_set = {}
52 |     problems = False
53 |     env = get_default_environment()
54 |     for dist in env.iter_installed_distributions(local_only=False, skip=()):
55 |         name = dist.canonical_name
56 |         try:
57 |             dependencies = list(dist.iter_dependencies())
58 |             package_set[name] = PackageDetails(dist.version, dependencies)
59 |         except (OSError, ValueError) as e:
60 |             # Don't crash on unreadable or broken metadata.
61 |             logger.warning("Error parsing dependencies of %s: %s", name, e)
62 |             problems = True
63 |     return package_set, problems
64 | 
65 | 
66 | def check_package_set(
67 |     package_set: PackageSet, should_ignore: Optional[Callable[[str], bool]] = None
68 | ) -> CheckResult:
69 |     """Check if a package set is consistent
70 | 
71 |     If should_ignore is passed, it should be a callable that takes a
72 |     package name and returns a boolean.
73 |     """
74 | 
75 |     missing = {}
76 |     conflicting = {}
77 | 
78 |     for package_name, package_detail in package_set.items():
79 |         # Info about dependencies of package_name
80 |         missing_deps: Set[Missing] = set()
81 |         conflicting_deps: Set[Conflicting] = set()
82 | 
83 |         if should_ignore and should_ignore(package_name):
84 |             continue
85 | 
86 |         for req in package_detail.dependencies:
87 |             name = canonicalize_name(req.name)
88 | 
89 |             # Check if it's missing
90 |             if name not in package_set:
91 |                 missed = True
92 |                 if req.marker is not None:
93 |                     missed = req.marker.evaluate({"extra": ""})
94 |                 if missed:
95 |                     missing_deps.add((name, req))
96 |                 continue
97 | 
98 |             # Check if there's a conflict
99 |             version = package_set[name].version
100 |             if not req.specifier.contains(version, prereleases=True):
101 |                 conflicting_deps.add((name, version, req))
102 | 
103 |         if missing_deps:
104 |             missing[package_name] = sorted(missing_deps, key=str)
105 |         if conflicting_deps:
106 |             conflicting[package_name] = sorted(conflicting_deps, key=str)
107 | 
108 |     return missing, conflicting
109 | 
110 | 
111 | def check_install_conflicts(to_install: List[InstallRequirement]) -> ConflictDetails:
112 |     """For checking if the dependency graph would be consistent after \
113 |     installing given requirements
114 |     """
115 |     # Start from the current state
116 |     package_set, _ = create_package_set_from_installed()
117 |     # Install packages
118 |     would_be_installed = _simulate_installation_of(to_install, package_set)
119 | 
120 |     # Only warn about directly-dependent packages; create a whitelist of them
121 |     whitelist = _create_whitelist(would_be_installed, package_set)
122 | 
123 |     return (
124 |         package_set,
125 |         check_package_set(
126 |             package_set, should_ignore=lambda name: name not in whitelist
127 |         ),
128 |     )
129 | 
130 | 
131 | def check_unsupported(
132 |     packages: Iterable[BaseDistribution],
133 |     supported_tags: Iterable[Tag],
134 | ) -> Generator[BaseDistribution, None, None]:
135 |     for p in packages:
136 |         with suppress(FileNotFoundError):
137 |             wheel_file = p.read_text("WHEEL")
138 |             wheel_tags: FrozenSet[Tag] = reduce(
139 |                 frozenset.union,
140 |                 map(parse_tag, Parser().parsestr(wheel_file).get_all("Tag", [])),
141 |                 frozenset(),
142 |             )
143 |             if wheel_tags.isdisjoint(supported_tags):
144 |                 yield p
145 | 
146 | 
147 | def _simulate_installation_of(
148 |     to_install: List[InstallRequirement], package_set: PackageSet
149 | ) -> Set[NormalizedName]:
150 |     """Computes the version of packages after installing to_install."""
151 |     # Keep track of packages that were installed
152 |     installed = set()
153 | 
154 |     # Modify it as installing requirement_set would (assuming no errors)
155 |     for inst_req in to_install:
156 |         abstract_dist = make_distribution_for_install_requirement(inst_req)
157 |         dist = abstract_dist.get_metadata_distribution()
158 |         name = dist.canonical_name
159 |         package_set[name] = PackageDetails(dist.version, list(dist.iter_dependencies()))
160 | 
161 |         installed.add(name)
162 | 
163 |     return installed
164 | 
165 | 
166 | def _create_whitelist(
167 |     would_be_installed: Set[NormalizedName], package_set: PackageSet
168 | ) -> Set[NormalizedName]:
169 |     packages_affected = set(would_be_installed)
170 | 
171 |     for package_name in package_set:
172 |         if package_name in packages_affected:
173 |             continue
174 | 
175 |         for req in package_set[package_name].dependencies:
176 |             if canonicalize_name(req.name) in packages_affected:
177 |                 packages_affected.add(package_name)
178 |                 break
179 | 
180 |     return packages_affected
```

.venv/lib/python3.13/site-packages/pip/_internal/operations/freeze.py
```
1 | import collections
2 | import logging
3 | import os
4 | from dataclasses import dataclass, field
5 | from typing import Container, Dict, Generator, Iterable, List, NamedTuple, Optional, Set
6 | 
7 | from pip._vendor.packaging.utils import NormalizedName, canonicalize_name
8 | from pip._vendor.packaging.version import InvalidVersion
9 | 
10 | from pip._internal.exceptions import BadCommand, InstallationError
11 | from pip._internal.metadata import BaseDistribution, get_environment
12 | from pip._internal.req.constructors import (
13 |     install_req_from_editable,
14 |     install_req_from_line,
15 | )
16 | from pip._internal.req.req_file import COMMENT_RE
17 | from pip._internal.utils.direct_url_helpers import direct_url_as_pep440_direct_reference
18 | 
19 | logger = logging.getLogger(__name__)
20 | 
21 | 
22 | class _EditableInfo(NamedTuple):
23 |     requirement: str
24 |     comments: List[str]
25 | 
26 | 
27 | def freeze(
28 |     requirement: Optional[List[str]] = None,
29 |     local_only: bool = False,
30 |     user_only: bool = False,
31 |     paths: Optional[List[str]] = None,
32 |     isolated: bool = False,
33 |     exclude_editable: bool = False,
34 |     skip: Container[str] = (),
35 | ) -> Generator[str, None, None]:
36 |     installations: Dict[str, FrozenRequirement] = {}
37 | 
38 |     dists = get_environment(paths).iter_installed_distributions(
39 |         local_only=local_only,
40 |         skip=(),
41 |         user_only=user_only,
42 |     )
43 |     for dist in dists:
44 |         req = FrozenRequirement.from_dist(dist)
45 |         if exclude_editable and req.editable:
46 |             continue
47 |         installations[req.canonical_name] = req
48 | 
49 |     if requirement:
50 |         # the options that don't get turned into an InstallRequirement
51 |         # should only be emitted once, even if the same option is in multiple
52 |         # requirements files, so we need to keep track of what has been emitted
53 |         # so that we don't emit it again if it's seen again
54 |         emitted_options: Set[str] = set()
55 |         # keep track of which files a requirement is in so that we can
56 |         # give an accurate warning if a requirement appears multiple times.
57 |         req_files: Dict[str, List[str]] = collections.defaultdict(list)
58 |         for req_file_path in requirement:
59 |             with open(req_file_path) as req_file:
60 |                 for line in req_file:
61 |                     if (
62 |                         not line.strip()
63 |                         or line.strip().startswith("#")
64 |                         or line.startswith(
65 |                             (
66 |                                 "-r",
67 |                                 "--requirement",
68 |                                 "-f",
69 |                                 "--find-links",
70 |                                 "-i",
71 |                                 "--index-url",
72 |                                 "--pre",
73 |                                 "--trusted-host",
74 |                                 "--process-dependency-links",
75 |                                 "--extra-index-url",
76 |                                 "--use-feature",
77 |                             )
78 |                         )
79 |                     ):
80 |                         line = line.rstrip()
81 |                         if line not in emitted_options:
82 |                             emitted_options.add(line)
83 |                             yield line
84 |                         continue
85 | 
86 |                     if line.startswith("-e") or line.startswith("--editable"):
87 |                         if line.startswith("-e"):
88 |                             line = line[2:].strip()
89 |                         else:
90 |                             line = line[len("--editable") :].strip().lstrip("=")
91 |                         line_req = install_req_from_editable(
92 |                             line,
93 |                             isolated=isolated,
94 |                         )
95 |                     else:
96 |                         line_req = install_req_from_line(
97 |                             COMMENT_RE.sub("", line).strip(),
98 |                             isolated=isolated,
99 |                         )
100 | 
101 |                     if not line_req.name:
102 |                         logger.info(
103 |                             "Skipping line in requirement file [%s] because "
104 |                             "it's not clear what it would install: %s",
105 |                             req_file_path,
106 |                             line.strip(),
107 |                         )
108 |                         logger.info(
109 |                             "  (add #egg=PackageName to the URL to avoid"
110 |                             " this warning)"
111 |                         )
112 |                     else:
113 |                         line_req_canonical_name = canonicalize_name(line_req.name)
114 |                         if line_req_canonical_name not in installations:
115 |                             # either it's not installed, or it is installed
116 |                             # but has been processed already
117 |                             if not req_files[line_req.name]:
118 |                                 logger.warning(
119 |                                     "Requirement file [%s] contains %s, but "
120 |                                     "package %r is not installed",
121 |                                     req_file_path,
122 |                                     COMMENT_RE.sub("", line).strip(),
123 |                                     line_req.name,
124 |                                 )
125 |                             else:
126 |                                 req_files[line_req.name].append(req_file_path)
127 |                         else:
128 |                             yield str(installations[line_req_canonical_name]).rstrip()
129 |                             del installations[line_req_canonical_name]
130 |                             req_files[line_req.name].append(req_file_path)
131 | 
132 |         # Warn about requirements that were included multiple times (in a
133 |         # single requirements file or in different requirements files).
134 |         for name, files in req_files.items():
135 |             if len(files) > 1:
136 |                 logger.warning(
137 |                     "Requirement %s included multiple times [%s]",
138 |                     name,
139 |                     ", ".join(sorted(set(files))),
140 |                 )
141 | 
142 |         yield ("## The following requirements were added by pip freeze:")
143 |     for installation in sorted(installations.values(), key=lambda x: x.name.lower()):
144 |         if installation.canonical_name not in skip:
145 |             yield str(installation).rstrip()
146 | 
147 | 
148 | def _format_as_name_version(dist: BaseDistribution) -> str:
149 |     try:
150 |         dist_version = dist.version
151 |     except InvalidVersion:
152 |         # legacy version
153 |         return f"{dist.raw_name}==={dist.raw_version}"
154 |     else:
155 |         return f"{dist.raw_name}=={dist_version}"
156 | 
157 | 
158 | def _get_editable_info(dist: BaseDistribution) -> _EditableInfo:
159 |     """
160 |     Compute and return values (req, comments) for use in
161 |     FrozenRequirement.from_dist().
162 |     """
163 |     editable_project_location = dist.editable_project_location
164 |     assert editable_project_location
165 |     location = os.path.normcase(os.path.abspath(editable_project_location))
166 | 
167 |     from pip._internal.vcs import RemoteNotFoundError, RemoteNotValidError, vcs
168 | 
169 |     vcs_backend = vcs.get_backend_for_dir(location)
170 | 
171 |     if vcs_backend is None:
172 |         display = _format_as_name_version(dist)
173 |         logger.debug(
174 |             'No VCS found for editable requirement "%s" in: %r',
175 |             display,
176 |             location,
177 |         )
178 |         return _EditableInfo(
179 |             requirement=location,
180 |             comments=[f"# Editable install with no version control ({display})"],
181 |         )
182 | 
183 |     vcs_name = type(vcs_backend).__name__
184 | 
185 |     try:
186 |         req = vcs_backend.get_src_requirement(location, dist.raw_name)
187 |     except RemoteNotFoundError:
188 |         display = _format_as_name_version(dist)
189 |         return _EditableInfo(
190 |             requirement=location,
191 |             comments=[f"# Editable {vcs_name} install with no remote ({display})"],
192 |         )
193 |     except RemoteNotValidError as ex:
194 |         display = _format_as_name_version(dist)
195 |         return _EditableInfo(
196 |             requirement=location,
197 |             comments=[
198 |                 f"# Editable {vcs_name} install ({display}) with either a deleted "
199 |                 f"local remote or invalid URI:",
200 |                 f"# '{ex.url}'",
201 |             ],
202 |         )
203 |     except BadCommand:
204 |         logger.warning(
205 |             "cannot determine version of editable source in %s "
206 |             "(%s command not found in path)",
207 |             location,
208 |             vcs_backend.name,
209 |         )
210 |         return _EditableInfo(requirement=location, comments=[])
211 |     except InstallationError as exc:
212 |         logger.warning("Error when trying to get requirement for VCS system %s", exc)
213 |     else:
214 |         return _EditableInfo(requirement=req, comments=[])
215 | 
216 |     logger.warning("Could not determine repository location of %s", location)
217 | 
218 |     return _EditableInfo(
219 |         requirement=location,
220 |         comments=["## !! Could not determine repository location"],
221 |     )
222 | 
223 | 
224 | @dataclass(frozen=True)
225 | class FrozenRequirement:
226 |     name: str
227 |     req: str
228 |     editable: bool
229 |     comments: Iterable[str] = field(default_factory=tuple)
230 | 
231 |     @property
232 |     def canonical_name(self) -> NormalizedName:
233 |         return canonicalize_name(self.name)
234 | 
235 |     @classmethod
236 |     def from_dist(cls, dist: BaseDistribution) -> "FrozenRequirement":
237 |         editable = dist.editable
238 |         if editable:
239 |             req, comments = _get_editable_info(dist)
240 |         else:
241 |             comments = []
242 |             direct_url = dist.direct_url
243 |             if direct_url:
244 |                 # if PEP 610 metadata is present, use it
245 |                 req = direct_url_as_pep440_direct_reference(direct_url, dist.raw_name)
246 |             else:
247 |                 # name==version requirement
248 |                 req = _format_as_name_version(dist)
249 | 
250 |         return cls(dist.raw_name, req, editable, comments=comments)
251 | 
252 |     def __str__(self) -> str:
253 |         req = self.req
254 |         if self.editable:
255 |             req = f"-e {req}"
256 |         return "\n".join(list(self.comments) + [str(req)]) + "\n"
```

.venv/lib/python3.13/site-packages/pip/_internal/operations/prepare.py
```
1 | """Prepares a distribution for installation"""
2 | 
3 | # The following comment should be removed at some point in the future.
4 | # mypy: strict-optional=False
5 | 
6 | import mimetypes
7 | import os
8 | import shutil
9 | from dataclasses import dataclass
10 | from pathlib import Path
11 | from typing import Dict, Iterable, List, Optional
12 | 
13 | from pip._vendor.packaging.utils import canonicalize_name
14 | 
15 | from pip._internal.distributions import make_distribution_for_install_requirement
16 | from pip._internal.distributions.installed import InstalledDistribution
17 | from pip._internal.exceptions import (
18 |     DirectoryUrlHashUnsupported,
19 |     HashMismatch,
20 |     HashUnpinned,
21 |     InstallationError,
22 |     MetadataInconsistent,
23 |     NetworkConnectionError,
24 |     VcsHashUnsupported,
25 | )
26 | from pip._internal.index.package_finder import PackageFinder
27 | from pip._internal.metadata import BaseDistribution, get_metadata_distribution
28 | from pip._internal.models.direct_url import ArchiveInfo
29 | from pip._internal.models.link import Link
30 | from pip._internal.models.wheel import Wheel
31 | from pip._internal.network.download import BatchDownloader, Downloader
32 | from pip._internal.network.lazy_wheel import (
33 |     HTTPRangeRequestUnsupported,
34 |     dist_from_wheel_url,
35 | )
36 | from pip._internal.network.session import PipSession
37 | from pip._internal.operations.build.build_tracker import BuildTracker
38 | from pip._internal.req.req_install import InstallRequirement
39 | from pip._internal.utils._log import getLogger
40 | from pip._internal.utils.direct_url_helpers import (
41 |     direct_url_for_editable,
42 |     direct_url_from_link,
43 | )
44 | from pip._internal.utils.hashes import Hashes, MissingHashes
45 | from pip._internal.utils.logging import indent_log
46 | from pip._internal.utils.misc import (
47 |     display_path,
48 |     hash_file,
49 |     hide_url,
50 |     redact_auth_from_requirement,
51 | )
52 | from pip._internal.utils.temp_dir import TempDirectory
53 | from pip._internal.utils.unpacking import unpack_file
54 | from pip._internal.vcs import vcs
55 | 
56 | logger = getLogger(__name__)
57 | 
58 | 
59 | def _get_prepared_distribution(
60 |     req: InstallRequirement,
61 |     build_tracker: BuildTracker,
62 |     finder: PackageFinder,
63 |     build_isolation: bool,
64 |     check_build_deps: bool,
65 | ) -> BaseDistribution:
66 |     """Prepare a distribution for installation."""
67 |     abstract_dist = make_distribution_for_install_requirement(req)
68 |     tracker_id = abstract_dist.build_tracker_id
69 |     if tracker_id is not None:
70 |         with build_tracker.track(req, tracker_id):
71 |             abstract_dist.prepare_distribution_metadata(
72 |                 finder, build_isolation, check_build_deps
73 |             )
74 |     return abstract_dist.get_metadata_distribution()
75 | 
76 | 
77 | def unpack_vcs_link(link: Link, location: str, verbosity: int) -> None:
78 |     vcs_backend = vcs.get_backend_for_scheme(link.scheme)
79 |     assert vcs_backend is not None
80 |     vcs_backend.unpack(location, url=hide_url(link.url), verbosity=verbosity)
81 | 
82 | 
83 | @dataclass
84 | class File:
85 |     path: str
86 |     content_type: Optional[str] = None
87 | 
88 |     def __post_init__(self) -> None:
89 |         if self.content_type is None:
90 |             # Try to guess the file's MIME type. If the system MIME tables
91 |             # can't be loaded, give up.
92 |             try:
93 |                 self.content_type = mimetypes.guess_type(self.path)[0]
94 |             except OSError:
95 |                 pass
96 | 
97 | 
98 | def get_http_url(
99 |     link: Link,
100 |     download: Downloader,
101 |     download_dir: Optional[str] = None,
102 |     hashes: Optional[Hashes] = None,
103 | ) -> File:
104 |     temp_dir = TempDirectory(kind="unpack", globally_managed=True)
105 |     # If a download dir is specified, is the file already downloaded there?
106 |     already_downloaded_path = None
107 |     if download_dir:
108 |         already_downloaded_path = _check_download_dir(link, download_dir, hashes)
109 | 
110 |     if already_downloaded_path:
111 |         from_path = already_downloaded_path
112 |         content_type = None
113 |     else:
114 |         # let's download to a tmp dir
115 |         from_path, content_type = download(link, temp_dir.path)
116 |         if hashes:
117 |             hashes.check_against_path(from_path)
118 | 
119 |     return File(from_path, content_type)
120 | 
121 | 
122 | def get_file_url(
123 |     link: Link, download_dir: Optional[str] = None, hashes: Optional[Hashes] = None
124 | ) -> File:
125 |     """Get file and optionally check its hash."""
126 |     # If a download dir is specified, is the file already there and valid?
127 |     already_downloaded_path = None
128 |     if download_dir:
129 |         already_downloaded_path = _check_download_dir(link, download_dir, hashes)
130 | 
131 |     if already_downloaded_path:
132 |         from_path = already_downloaded_path
133 |     else:
134 |         from_path = link.file_path
135 | 
136 |     # If --require-hashes is off, `hashes` is either empty, the
137 |     # link's embedded hash, or MissingHashes; it is required to
138 |     # match. If --require-hashes is on, we are satisfied by any
139 |     # hash in `hashes` matching: a URL-based or an option-based
140 |     # one; no internet-sourced hash will be in `hashes`.
141 |     if hashes:
142 |         hashes.check_against_path(from_path)
143 |     return File(from_path, None)
144 | 
145 | 
146 | def unpack_url(
147 |     link: Link,
148 |     location: str,
149 |     download: Downloader,
150 |     verbosity: int,
151 |     download_dir: Optional[str] = None,
152 |     hashes: Optional[Hashes] = None,
153 | ) -> Optional[File]:
154 |     """Unpack link into location, downloading if required.
155 | 
156 |     :param hashes: A Hashes object, one of whose embedded hashes must match,
157 |         or HashMismatch will be raised. If the Hashes is empty, no matches are
158 |         required, and unhashable types of requirements (like VCS ones, which
159 |         would ordinarily raise HashUnsupported) are allowed.
160 |     """
161 |     # non-editable vcs urls
162 |     if link.is_vcs:
163 |         unpack_vcs_link(link, location, verbosity=verbosity)
164 |         return None
165 | 
166 |     assert not link.is_existing_dir()
167 | 
168 |     # file urls
169 |     if link.is_file:
170 |         file = get_file_url(link, download_dir, hashes=hashes)
171 | 
172 |     # http urls
173 |     else:
174 |         file = get_http_url(
175 |             link,
176 |             download,
177 |             download_dir,
178 |             hashes=hashes,
179 |         )
180 | 
181 |     # unpack the archive to the build dir location. even when only downloading
182 |     # archives, they have to be unpacked to parse dependencies, except wheels
183 |     if not link.is_wheel:
184 |         unpack_file(file.path, location, file.content_type)
185 | 
186 |     return file
187 | 
188 | 
189 | def _check_download_dir(
190 |     link: Link,
191 |     download_dir: str,
192 |     hashes: Optional[Hashes],
193 |     warn_on_hash_mismatch: bool = True,
194 | ) -> Optional[str]:
195 |     """Check download_dir for previously downloaded file with correct hash
196 |     If a correct file is found return its path else None
197 |     """
198 |     download_path = os.path.join(download_dir, link.filename)
199 | 
200 |     if not os.path.exists(download_path):
201 |         return None
202 | 
203 |     # If already downloaded, does its hash match?
204 |     logger.info("File was already downloaded %s", download_path)
205 |     if hashes:
206 |         try:
207 |             hashes.check_against_path(download_path)
208 |         except HashMismatch:
209 |             if warn_on_hash_mismatch:
210 |                 logger.warning(
211 |                     "Previously-downloaded file %s has bad hash. Re-downloading.",
212 |                     download_path,
213 |                 )
214 |             os.unlink(download_path)
215 |             return None
216 |     return download_path
217 | 
218 | 
219 | class RequirementPreparer:
220 |     """Prepares a Requirement"""
221 | 
222 |     def __init__(
223 |         self,
224 |         build_dir: str,
225 |         download_dir: Optional[str],
226 |         src_dir: str,
227 |         build_isolation: bool,
228 |         check_build_deps: bool,
229 |         build_tracker: BuildTracker,
230 |         session: PipSession,
231 |         progress_bar: str,
232 |         finder: PackageFinder,
233 |         require_hashes: bool,
234 |         use_user_site: bool,
235 |         lazy_wheel: bool,
236 |         verbosity: int,
237 |         legacy_resolver: bool,
238 |         resume_retries: int,
239 |     ) -> None:
240 |         super().__init__()
241 | 
242 |         self.src_dir = src_dir
243 |         self.build_dir = build_dir
244 |         self.build_tracker = build_tracker
245 |         self._session = session
246 |         self._download = Downloader(session, progress_bar, resume_retries)
247 |         self._batch_download = BatchDownloader(session, progress_bar, resume_retries)
248 |         self.finder = finder
249 | 
250 |         # Where still-packed archives should be written to. If None, they are
251 |         # not saved, and are deleted immediately after unpacking.
252 |         self.download_dir = download_dir
253 | 
254 |         # Is build isolation allowed?
255 |         self.build_isolation = build_isolation
256 | 
257 |         # Should check build dependencies?
258 |         self.check_build_deps = check_build_deps
259 | 
260 |         # Should hash-checking be required?
261 |         self.require_hashes = require_hashes
262 | 
263 |         # Should install in user site-packages?
264 |         self.use_user_site = use_user_site
265 | 
266 |         # Should wheels be downloaded lazily?
267 |         self.use_lazy_wheel = lazy_wheel
268 | 
269 |         # How verbose should underlying tooling be?
270 |         self.verbosity = verbosity
271 | 
272 |         # Are we using the legacy resolver?
273 |         self.legacy_resolver = legacy_resolver
274 | 
275 |         # Memoized downloaded files, as mapping of url: path.
276 |         self._downloaded: Dict[str, str] = {}
277 | 
278 |         # Previous "header" printed for a link-based InstallRequirement
279 |         self._previous_requirement_header = ("", "")
280 | 
281 |     def _log_preparing_link(self, req: InstallRequirement) -> None:
282 |         """Provide context for the requirement being prepared."""
283 |         if req.link.is_file and not req.is_wheel_from_cache:
284 |             message = "Processing %s"
285 |             information = str(display_path(req.link.file_path))
286 |         else:
287 |             message = "Collecting %s"
288 |             information = redact_auth_from_requirement(req.req) if req.req else str(req)
289 | 
290 |         # If we used req.req, inject requirement source if available (this
291 |         # would already be included if we used req directly)
292 |         if req.req and req.comes_from:
293 |             if isinstance(req.comes_from, str):
294 |                 comes_from: Optional[str] = req.comes_from
295 |             else:
296 |                 comes_from = req.comes_from.from_path()
297 |             if comes_from:
298 |                 information += f" (from {comes_from})"
299 | 
300 |         if (message, information) != self._previous_requirement_header:
301 |             self._previous_requirement_header = (message, information)
302 |             logger.info(message, information)
303 | 
304 |         if req.is_wheel_from_cache:
305 |             with indent_log():
306 |                 logger.info("Using cached %s", req.link.filename)
307 | 
308 |     def _ensure_link_req_src_dir(
309 |         self, req: InstallRequirement, parallel_builds: bool
310 |     ) -> None:
311 |         """Ensure source_dir of a linked InstallRequirement."""
312 |         # Since source_dir is only set for editable requirements.
313 |         if req.link.is_wheel:
314 |             # We don't need to unpack wheels, so no need for a source
315 |             # directory.
316 |             return
317 |         assert req.source_dir is None
318 |         if req.link.is_existing_dir():
319 |             # build local directories in-tree
320 |             req.source_dir = req.link.file_path
321 |             return
322 | 
323 |         # We always delete unpacked sdists after pip runs.
324 |         req.ensure_has_source_dir(
325 |             self.build_dir,
326 |             autodelete=True,
327 |             parallel_builds=parallel_builds,
328 |         )
329 |         req.ensure_pristine_source_checkout()
330 | 
331 |     def _get_linked_req_hashes(self, req: InstallRequirement) -> Hashes:
332 |         # By the time this is called, the requirement's link should have
333 |         # been checked so we can tell what kind of requirements req is
334 |         # and raise some more informative errors than otherwise.
335 |         # (For example, we can raise VcsHashUnsupported for a VCS URL
336 |         # rather than HashMissing.)
337 |         if not self.require_hashes:
338 |             return req.hashes(trust_internet=True)
339 | 
340 |         # We could check these first 2 conditions inside unpack_url
341 |         # and save repetition of conditions, but then we would
342 |         # report less-useful error messages for unhashable
343 |         # requirements, complaining that there's no hash provided.
344 |         if req.link.is_vcs:
345 |             raise VcsHashUnsupported()
346 |         if req.link.is_existing_dir():
347 |             raise DirectoryUrlHashUnsupported()
348 | 
349 |         # Unpinned packages are asking for trouble when a new version
[TRUNCATED]
```

.venv/lib/python3.13/site-packages/pip/_internal/vcs/__init__.py
```
1 | # Expose a limited set of classes and functions so callers outside of
2 | # the vcs package don't need to import deeper than `pip._internal.vcs`.
3 | # (The test directory may still need to import from a vcs sub-package.)
4 | # Import all vcs modules to register each VCS in the VcsSupport object.
5 | import pip._internal.vcs.bazaar
6 | import pip._internal.vcs.git
7 | import pip._internal.vcs.mercurial
8 | import pip._internal.vcs.subversion  # noqa: F401
9 | from pip._internal.vcs.versioncontrol import (  # noqa: F401
10 |     RemoteNotFoundError,
11 |     RemoteNotValidError,
12 |     is_url,
13 |     make_vcs_requirement_url,
14 |     vcs,
15 | )
```

.venv/lib/python3.13/site-packages/pip/_internal/vcs/bazaar.py
```
1 | import logging
2 | from typing import List, Optional, Tuple
3 | 
4 | from pip._internal.utils.misc import HiddenText, display_path
5 | from pip._internal.utils.subprocess import make_command
6 | from pip._internal.utils.urls import path_to_url
7 | from pip._internal.vcs.versioncontrol import (
8 |     AuthInfo,
9 |     RemoteNotFoundError,
10 |     RevOptions,
11 |     VersionControl,
12 |     vcs,
13 | )
14 | 
15 | logger = logging.getLogger(__name__)
16 | 
17 | 
18 | class Bazaar(VersionControl):
19 |     name = "bzr"
20 |     dirname = ".bzr"
21 |     repo_name = "branch"
22 |     schemes = (
23 |         "bzr+http",
24 |         "bzr+https",
25 |         "bzr+ssh",
26 |         "bzr+sftp",
27 |         "bzr+ftp",
28 |         "bzr+lp",
29 |         "bzr+file",
30 |     )
31 | 
32 |     @staticmethod
33 |     def get_base_rev_args(rev: str) -> List[str]:
34 |         return ["-r", rev]
35 | 
36 |     def fetch_new(
37 |         self, dest: str, url: HiddenText, rev_options: RevOptions, verbosity: int
38 |     ) -> None:
39 |         rev_display = rev_options.to_display()
40 |         logger.info(
41 |             "Checking out %s%s to %s",
42 |             url,
43 |             rev_display,
44 |             display_path(dest),
45 |         )
46 |         if verbosity <= 0:
47 |             flags = ["--quiet"]
48 |         elif verbosity == 1:
49 |             flags = []
50 |         else:
51 |             flags = [f"-{'v'*verbosity}"]
52 |         cmd_args = make_command(
53 |             "checkout", "--lightweight", *flags, rev_options.to_args(), url, dest
54 |         )
55 |         self.run_command(cmd_args)
56 | 
57 |     def switch(self, dest: str, url: HiddenText, rev_options: RevOptions) -> None:
58 |         self.run_command(make_command("switch", url), cwd=dest)
59 | 
60 |     def update(self, dest: str, url: HiddenText, rev_options: RevOptions) -> None:
61 |         output = self.run_command(
62 |             make_command("info"), show_stdout=False, stdout_only=True, cwd=dest
63 |         )
64 |         if output.startswith("Standalone "):
65 |             # Older versions of pip used to create standalone branches.
66 |             # Convert the standalone branch to a checkout by calling "bzr bind".
67 |             cmd_args = make_command("bind", "-q", url)
68 |             self.run_command(cmd_args, cwd=dest)
69 | 
70 |         cmd_args = make_command("update", "-q", rev_options.to_args())
71 |         self.run_command(cmd_args, cwd=dest)
72 | 
73 |     @classmethod
74 |     def get_url_rev_and_auth(cls, url: str) -> Tuple[str, Optional[str], AuthInfo]:
75 |         # hotfix the URL scheme after removing bzr+ from bzr+ssh:// re-add it
76 |         url, rev, user_pass = super().get_url_rev_and_auth(url)
77 |         if url.startswith("ssh://"):
78 |             url = "bzr+" + url
79 |         return url, rev, user_pass
80 | 
81 |     @classmethod
82 |     def get_remote_url(cls, location: str) -> str:
83 |         urls = cls.run_command(
84 |             ["info"], show_stdout=False, stdout_only=True, cwd=location
85 |         )
86 |         for line in urls.splitlines():
87 |             line = line.strip()
88 |             for x in ("checkout of branch: ", "parent branch: "):
89 |                 if line.startswith(x):
90 |                     repo = line.split(x)[1]
91 |                     if cls._is_local_repository(repo):
92 |                         return path_to_url(repo)
93 |                     return repo
94 |         raise RemoteNotFoundError
95 | 
96 |     @classmethod
97 |     def get_revision(cls, location: str) -> str:
98 |         revision = cls.run_command(
99 |             ["revno"],
100 |             show_stdout=False,
101 |             stdout_only=True,
102 |             cwd=location,
103 |         )
104 |         return revision.splitlines()[-1]
105 | 
106 |     @classmethod
107 |     def is_commit_id_equal(cls, dest: str, name: Optional[str]) -> bool:
108 |         """Always assume the versions don't match"""
109 |         return False
110 | 
111 | 
112 | vcs.register(Bazaar)
```

.venv/lib/python3.13/site-packages/pip/_internal/vcs/git.py
```
1 | import logging
2 | import os.path
3 | import pathlib
4 | import re
5 | import urllib.parse
6 | import urllib.request
7 | from dataclasses import replace
8 | from typing import Any, List, Optional, Tuple
9 | 
10 | from pip._internal.exceptions import BadCommand, InstallationError
11 | from pip._internal.utils.misc import HiddenText, display_path, hide_url
12 | from pip._internal.utils.subprocess import make_command
13 | from pip._internal.vcs.versioncontrol import (
14 |     AuthInfo,
15 |     RemoteNotFoundError,
16 |     RemoteNotValidError,
17 |     RevOptions,
18 |     VersionControl,
19 |     find_path_to_project_root_from_repo_root,
20 |     vcs,
21 | )
22 | 
23 | urlsplit = urllib.parse.urlsplit
24 | urlunsplit = urllib.parse.urlunsplit
25 | 
26 | 
27 | logger = logging.getLogger(__name__)
28 | 
29 | 
30 | GIT_VERSION_REGEX = re.compile(
31 |     r"^git version "  # Prefix.
32 |     r"(\d+)"  # Major.
33 |     r"\.(\d+)"  # Dot, minor.
34 |     r"(?:\.(\d+))?"  # Optional dot, patch.
35 |     r".*$"  # Suffix, including any pre- and post-release segments we don't care about.
36 | )
37 | 
38 | HASH_REGEX = re.compile("^[a-fA-F0-9]{40}$")
39 | 
40 | # SCP (Secure copy protocol) shorthand. e.g. 'git@example.com:foo/bar.git'
41 | SCP_REGEX = re.compile(
42 |     r"""^
43 |     # Optional user, e.g. 'git@'
44 |     (\w+@)?
45 |     # Server, e.g. 'github.com'.
46 |     ([^/:]+):
47 |     # The server-side path. e.g. 'user/project.git'. Must start with an
48 |     # alphanumeric character so as not to be confusable with a Windows paths
49 |     # like 'C:/foo/bar' or 'C:\foo\bar'.
50 |     (\w[^:]*)
51 |     $""",
52 |     re.VERBOSE,
53 | )
54 | 
55 | 
56 | def looks_like_hash(sha: str) -> bool:
57 |     return bool(HASH_REGEX.match(sha))
58 | 
59 | 
60 | class Git(VersionControl):
61 |     name = "git"
62 |     dirname = ".git"
63 |     repo_name = "clone"
64 |     schemes = (
65 |         "git+http",
66 |         "git+https",
67 |         "git+ssh",
68 |         "git+git",
69 |         "git+file",
70 |     )
71 |     # Prevent the user's environment variables from interfering with pip:
72 |     # https://github.com/pypa/pip/issues/1130
73 |     unset_environ = ("GIT_DIR", "GIT_WORK_TREE")
74 |     default_arg_rev = "HEAD"
75 | 
76 |     @staticmethod
77 |     def get_base_rev_args(rev: str) -> List[str]:
78 |         return [rev]
79 | 
80 |     @classmethod
81 |     def run_command(cls, *args: Any, **kwargs: Any) -> str:
82 |         if os.environ.get("PIP_NO_INPUT"):
83 |             extra_environ = kwargs.get("extra_environ", {})
84 |             extra_environ["GIT_TERMINAL_PROMPT"] = "0"
85 |             extra_environ["GIT_SSH_COMMAND"] = "ssh -oBatchMode=yes"
86 |             kwargs["extra_environ"] = extra_environ
87 |         return super().run_command(*args, **kwargs)
88 | 
89 |     def is_immutable_rev_checkout(self, url: str, dest: str) -> bool:
90 |         _, rev_options = self.get_url_rev_options(hide_url(url))
91 |         if not rev_options.rev:
92 |             return False
93 |         if not self.is_commit_id_equal(dest, rev_options.rev):
94 |             # the current commit is different from rev,
95 |             # which means rev was something else than a commit hash
96 |             return False
97 |         # return False in the rare case rev is both a commit hash
98 |         # and a tag or a branch; we don't want to cache in that case
99 |         # because that branch/tag could point to something else in the future
100 |         is_tag_or_branch = bool(self.get_revision_sha(dest, rev_options.rev)[0])
101 |         return not is_tag_or_branch
102 | 
103 |     def get_git_version(self) -> Tuple[int, ...]:
104 |         version = self.run_command(
105 |             ["version"],
106 |             command_desc="git version",
107 |             show_stdout=False,
108 |             stdout_only=True,
109 |         )
110 |         match = GIT_VERSION_REGEX.match(version)
111 |         if not match:
112 |             logger.warning("Can't parse git version: %s", version)
113 |             return ()
114 |         return (int(match.group(1)), int(match.group(2)))
115 | 
116 |     @classmethod
117 |     def get_current_branch(cls, location: str) -> Optional[str]:
118 |         """
119 |         Return the current branch, or None if HEAD isn't at a branch
120 |         (e.g. detached HEAD).
121 |         """
122 |         # git-symbolic-ref exits with empty stdout if "HEAD" is a detached
123 |         # HEAD rather than a symbolic ref.  In addition, the -q causes the
124 |         # command to exit with status code 1 instead of 128 in this case
125 |         # and to suppress the message to stderr.
126 |         args = ["symbolic-ref", "-q", "HEAD"]
127 |         output = cls.run_command(
128 |             args,
129 |             extra_ok_returncodes=(1,),
130 |             show_stdout=False,
131 |             stdout_only=True,
132 |             cwd=location,
133 |         )
134 |         ref = output.strip()
135 | 
136 |         if ref.startswith("refs/heads/"):
137 |             return ref[len("refs/heads/") :]
138 | 
139 |         return None
140 | 
141 |     @classmethod
142 |     def get_revision_sha(cls, dest: str, rev: str) -> Tuple[Optional[str], bool]:
143 |         """
144 |         Return (sha_or_none, is_branch), where sha_or_none is a commit hash
145 |         if the revision names a remote branch or tag, otherwise None.
146 | 
147 |         Args:
148 |           dest: the repository directory.
149 |           rev: the revision name.
150 |         """
151 |         # Pass rev to pre-filter the list.
152 |         output = cls.run_command(
153 |             ["show-ref", rev],
154 |             cwd=dest,
155 |             show_stdout=False,
156 |             stdout_only=True,
157 |             on_returncode="ignore",
158 |         )
159 |         refs = {}
160 |         # NOTE: We do not use splitlines here since that would split on other
161 |         #       unicode separators, which can be maliciously used to install a
162 |         #       different revision.
163 |         for line in output.strip().split("\n"):
164 |             line = line.rstrip("\r")
165 |             if not line:
166 |                 continue
167 |             try:
168 |                 ref_sha, ref_name = line.split(" ", maxsplit=2)
169 |             except ValueError:
170 |                 # Include the offending line to simplify troubleshooting if
171 |                 # this error ever occurs.
172 |                 raise ValueError(f"unexpected show-ref line: {line!r}")
173 | 
174 |             refs[ref_name] = ref_sha
175 | 
176 |         branch_ref = f"refs/remotes/origin/{rev}"
177 |         tag_ref = f"refs/tags/{rev}"
178 | 
179 |         sha = refs.get(branch_ref)
180 |         if sha is not None:
181 |             return (sha, True)
182 | 
183 |         sha = refs.get(tag_ref)
184 | 
185 |         return (sha, False)
186 | 
187 |     @classmethod
188 |     def _should_fetch(cls, dest: str, rev: str) -> bool:
189 |         """
190 |         Return true if rev is a ref or is a commit that we don't have locally.
191 | 
192 |         Branches and tags are not considered in this method because they are
193 |         assumed to be always available locally (which is a normal outcome of
194 |         ``git clone`` and ``git fetch --tags``).
195 |         """
196 |         if rev.startswith("refs/"):
197 |             # Always fetch remote refs.
198 |             return True
199 | 
200 |         if not looks_like_hash(rev):
201 |             # Git fetch would fail with abbreviated commits.
202 |             return False
203 | 
204 |         if cls.has_commit(dest, rev):
205 |             # Don't fetch if we have the commit locally.
206 |             return False
207 | 
208 |         return True
209 | 
210 |     @classmethod
211 |     def resolve_revision(
212 |         cls, dest: str, url: HiddenText, rev_options: RevOptions
213 |     ) -> RevOptions:
214 |         """
215 |         Resolve a revision to a new RevOptions object with the SHA1 of the
216 |         branch, tag, or ref if found.
217 | 
218 |         Args:
219 |           rev_options: a RevOptions object.
220 |         """
221 |         rev = rev_options.arg_rev
222 |         # The arg_rev property's implementation for Git ensures that the
223 |         # rev return value is always non-None.
224 |         assert rev is not None
225 | 
226 |         sha, is_branch = cls.get_revision_sha(dest, rev)
227 | 
228 |         if sha is not None:
229 |             rev_options = rev_options.make_new(sha)
230 |             rev_options = replace(rev_options, branch_name=(rev if is_branch else None))
231 | 
232 |             return rev_options
233 | 
234 |         # Do not show a warning for the common case of something that has
235 |         # the form of a Git commit hash.
236 |         if not looks_like_hash(rev):
237 |             logger.warning(
238 |                 "Did not find branch or tag '%s', assuming revision or ref.",
239 |                 rev,
240 |             )
241 | 
242 |         if not cls._should_fetch(dest, rev):
243 |             return rev_options
244 | 
245 |         # fetch the requested revision
246 |         cls.run_command(
247 |             make_command("fetch", "-q", url, rev_options.to_args()),
248 |             cwd=dest,
249 |         )
250 |         # Change the revision to the SHA of the ref we fetched
251 |         sha = cls.get_revision(dest, rev="FETCH_HEAD")
252 |         rev_options = rev_options.make_new(sha)
253 | 
254 |         return rev_options
255 | 
256 |     @classmethod
257 |     def is_commit_id_equal(cls, dest: str, name: Optional[str]) -> bool:
258 |         """
259 |         Return whether the current commit hash equals the given name.
260 | 
261 |         Args:
262 |           dest: the repository directory.
263 |           name: a string name.
264 |         """
265 |         if not name:
266 |             # Then avoid an unnecessary subprocess call.
267 |             return False
268 | 
269 |         return cls.get_revision(dest) == name
270 | 
271 |     def fetch_new(
272 |         self, dest: str, url: HiddenText, rev_options: RevOptions, verbosity: int
273 |     ) -> None:
274 |         rev_display = rev_options.to_display()
275 |         logger.info("Cloning %s%s to %s", url, rev_display, display_path(dest))
276 |         if verbosity <= 0:
277 |             flags: Tuple[str, ...] = ("--quiet",)
278 |         elif verbosity == 1:
279 |             flags = ()
280 |         else:
281 |             flags = ("--verbose", "--progress")
282 |         if self.get_git_version() >= (2, 17):
283 |             # Git added support for partial clone in 2.17
284 |             # https://git-scm.com/docs/partial-clone
285 |             # Speeds up cloning by functioning without a complete copy of repository
286 |             self.run_command(
287 |                 make_command(
288 |                     "clone",
289 |                     "--filter=blob:none",
290 |                     *flags,
291 |                     url,
292 |                     dest,
293 |                 )
294 |             )
295 |         else:
296 |             self.run_command(make_command("clone", *flags, url, dest))
297 | 
298 |         if rev_options.rev:
299 |             # Then a specific revision was requested.
300 |             rev_options = self.resolve_revision(dest, url, rev_options)
301 |             branch_name = getattr(rev_options, "branch_name", None)
302 |             logger.debug("Rev options %s, branch_name %s", rev_options, branch_name)
303 |             if branch_name is None:
304 |                 # Only do a checkout if the current commit id doesn't match
305 |                 # the requested revision.
306 |                 if not self.is_commit_id_equal(dest, rev_options.rev):
307 |                     cmd_args = make_command(
308 |                         "checkout",
309 |                         "-q",
310 |                         rev_options.to_args(),
311 |                     )
312 |                     self.run_command(cmd_args, cwd=dest)
313 |             elif self.get_current_branch(dest) != branch_name:
314 |                 # Then a specific branch was requested, and that branch
315 |                 # is not yet checked out.
316 |                 track_branch = f"origin/{branch_name}"
317 |                 cmd_args = [
318 |                     "checkout",
319 |                     "-b",
320 |                     branch_name,
321 |                     "--track",
322 |                     track_branch,
323 |                 ]
324 |                 self.run_command(cmd_args, cwd=dest)
325 |         else:
326 |             sha = self.get_revision(dest)
327 |             rev_options = rev_options.make_new(sha)
328 | 
329 |         logger.info("Resolved %s to commit %s", url, rev_options.rev)
330 | 
331 |         #: repo may contain submodules
332 |         self.update_submodules(dest)
333 | 
334 |     def switch(self, dest: str, url: HiddenText, rev_options: RevOptions) -> None:
335 |         self.run_command(
336 |             make_command("config", "remote.origin.url", url),
337 |             cwd=dest,
338 |         )
339 |         cmd_args = make_command("checkout", "-q", rev_options.to_args())
340 |         self.run_command(cmd_args, cwd=dest)
341 | 
342 |         self.update_submodules(dest)
343 | 
344 |     def update(self, dest: str, url: HiddenText, rev_options: RevOptions) -> None:
345 |         # First fetch changes from the default remote
346 |         if self.get_git_version() >= (1, 9):
347 |             # fetch tags in addition to everything else
348 |             self.run_command(["fetch", "-q", "--tags"], cwd=dest)
349 |         else:
350 |             self.run_command(["fetch", "-q"], cwd=dest)
[TRUNCATED]
```

.venv/lib/python3.13/site-packages/pip/_internal/vcs/mercurial.py
```
1 | import configparser
2 | import logging
3 | import os
4 | from typing import List, Optional, Tuple
5 | 
6 | from pip._internal.exceptions import BadCommand, InstallationError
7 | from pip._internal.utils.misc import HiddenText, display_path
8 | from pip._internal.utils.subprocess import make_command
9 | from pip._internal.utils.urls import path_to_url
10 | from pip._internal.vcs.versioncontrol import (
11 |     RevOptions,
12 |     VersionControl,
13 |     find_path_to_project_root_from_repo_root,
14 |     vcs,
15 | )
16 | 
17 | logger = logging.getLogger(__name__)
18 | 
19 | 
20 | class Mercurial(VersionControl):
21 |     name = "hg"
22 |     dirname = ".hg"
23 |     repo_name = "clone"
24 |     schemes = (
25 |         "hg+file",
26 |         "hg+http",
27 |         "hg+https",
28 |         "hg+ssh",
29 |         "hg+static-http",
30 |     )
31 | 
32 |     @staticmethod
33 |     def get_base_rev_args(rev: str) -> List[str]:
34 |         return [f"--rev={rev}"]
35 | 
36 |     def fetch_new(
37 |         self, dest: str, url: HiddenText, rev_options: RevOptions, verbosity: int
38 |     ) -> None:
39 |         rev_display = rev_options.to_display()
40 |         logger.info(
41 |             "Cloning hg %s%s to %s",
42 |             url,
43 |             rev_display,
44 |             display_path(dest),
45 |         )
46 |         if verbosity <= 0:
47 |             flags: Tuple[str, ...] = ("--quiet",)
48 |         elif verbosity == 1:
49 |             flags = ()
50 |         elif verbosity == 2:
51 |             flags = ("--verbose",)
52 |         else:
53 |             flags = ("--verbose", "--debug")
54 |         self.run_command(make_command("clone", "--noupdate", *flags, url, dest))
55 |         self.run_command(
56 |             make_command("update", *flags, rev_options.to_args()),
57 |             cwd=dest,
58 |         )
59 | 
60 |     def switch(self, dest: str, url: HiddenText, rev_options: RevOptions) -> None:
61 |         repo_config = os.path.join(dest, self.dirname, "hgrc")
62 |         config = configparser.RawConfigParser()
63 |         try:
64 |             config.read(repo_config)
65 |             config.set("paths", "default", url.secret)
66 |             with open(repo_config, "w") as config_file:
67 |                 config.write(config_file)
68 |         except (OSError, configparser.NoSectionError) as exc:
69 |             logger.warning("Could not switch Mercurial repository to %s: %s", url, exc)
70 |         else:
71 |             cmd_args = make_command("update", "-q", rev_options.to_args())
72 |             self.run_command(cmd_args, cwd=dest)
73 | 
74 |     def update(self, dest: str, url: HiddenText, rev_options: RevOptions) -> None:
75 |         self.run_command(["pull", "-q"], cwd=dest)
76 |         cmd_args = make_command("update", "-q", rev_options.to_args())
77 |         self.run_command(cmd_args, cwd=dest)
78 | 
79 |     @classmethod
80 |     def get_remote_url(cls, location: str) -> str:
81 |         url = cls.run_command(
82 |             ["showconfig", "paths.default"],
83 |             show_stdout=False,
84 |             stdout_only=True,
85 |             cwd=location,
86 |         ).strip()
87 |         if cls._is_local_repository(url):
88 |             url = path_to_url(url)
89 |         return url.strip()
90 | 
91 |     @classmethod
92 |     def get_revision(cls, location: str) -> str:
93 |         """
94 |         Return the repository-local changeset revision number, as an integer.
95 |         """
96 |         current_revision = cls.run_command(
97 |             ["parents", "--template={rev}"],
98 |             show_stdout=False,
99 |             stdout_only=True,
100 |             cwd=location,
101 |         ).strip()
102 |         return current_revision
103 | 
104 |     @classmethod
105 |     def get_requirement_revision(cls, location: str) -> str:
106 |         """
107 |         Return the changeset identification hash, as a 40-character
108 |         hexadecimal string
109 |         """
110 |         current_rev_hash = cls.run_command(
111 |             ["parents", "--template={node}"],
112 |             show_stdout=False,
113 |             stdout_only=True,
114 |             cwd=location,
115 |         ).strip()
116 |         return current_rev_hash
117 | 
118 |     @classmethod
119 |     def is_commit_id_equal(cls, dest: str, name: Optional[str]) -> bool:
120 |         """Always assume the versions don't match"""
121 |         return False
122 | 
123 |     @classmethod
124 |     def get_subdirectory(cls, location: str) -> Optional[str]:
125 |         """
126 |         Return the path to Python project root, relative to the repo root.
127 |         Return None if the project root is in the repo root.
128 |         """
129 |         # find the repo root
130 |         repo_root = cls.run_command(
131 |             ["root"], show_stdout=False, stdout_only=True, cwd=location
132 |         ).strip()
133 |         if not os.path.isabs(repo_root):
134 |             repo_root = os.path.abspath(os.path.join(location, repo_root))
135 |         return find_path_to_project_root_from_repo_root(location, repo_root)
136 | 
137 |     @classmethod
138 |     def get_repository_root(cls, location: str) -> Optional[str]:
139 |         loc = super().get_repository_root(location)
140 |         if loc:
141 |             return loc
142 |         try:
143 |             r = cls.run_command(
144 |                 ["root"],
145 |                 cwd=location,
146 |                 show_stdout=False,
147 |                 stdout_only=True,
148 |                 on_returncode="raise",
149 |                 log_failed_cmd=False,
150 |             )
151 |         except BadCommand:
152 |             logger.debug(
153 |                 "could not determine if %s is under hg control "
154 |                 "because hg is not available",
155 |                 location,
156 |             )
157 |             return None
158 |         except InstallationError:
159 |             return None
160 |         return os.path.normpath(r.rstrip("\r\n"))
161 | 
162 | 
163 | vcs.register(Mercurial)
```

.venv/lib/python3.13/site-packages/pip/_internal/vcs/subversion.py
```
1 | import logging
2 | import os
3 | import re
4 | from typing import List, Optional, Tuple
5 | 
6 | from pip._internal.utils.misc import (
7 |     HiddenText,
8 |     display_path,
9 |     is_console_interactive,
10 |     is_installable_dir,
11 |     split_auth_from_netloc,
12 | )
13 | from pip._internal.utils.subprocess import CommandArgs, make_command
14 | from pip._internal.vcs.versioncontrol import (
15 |     AuthInfo,
16 |     RemoteNotFoundError,
17 |     RevOptions,
18 |     VersionControl,
19 |     vcs,
20 | )
21 | 
22 | logger = logging.getLogger(__name__)
23 | 
24 | _svn_xml_url_re = re.compile('url="([^"]+)"')
25 | _svn_rev_re = re.compile(r'committed-rev="(\d+)"')
26 | _svn_info_xml_rev_re = re.compile(r'\s*revision="(\d+)"')
27 | _svn_info_xml_url_re = re.compile(r"<url>(.*)</url>")
28 | 
29 | 
30 | class Subversion(VersionControl):
31 |     name = "svn"
32 |     dirname = ".svn"
33 |     repo_name = "checkout"
34 |     schemes = ("svn+ssh", "svn+http", "svn+https", "svn+svn", "svn+file")
35 | 
36 |     @classmethod
37 |     def should_add_vcs_url_prefix(cls, remote_url: str) -> bool:
38 |         return True
39 | 
40 |     @staticmethod
41 |     def get_base_rev_args(rev: str) -> List[str]:
42 |         return ["-r", rev]
43 | 
44 |     @classmethod
45 |     def get_revision(cls, location: str) -> str:
46 |         """
47 |         Return the maximum revision for all files under a given location
48 |         """
49 |         # Note: taken from setuptools.command.egg_info
50 |         revision = 0
51 | 
52 |         for base, dirs, _ in os.walk(location):
53 |             if cls.dirname not in dirs:
54 |                 dirs[:] = []
55 |                 continue  # no sense walking uncontrolled subdirs
56 |             dirs.remove(cls.dirname)
57 |             entries_fn = os.path.join(base, cls.dirname, "entries")
58 |             if not os.path.exists(entries_fn):
59 |                 # FIXME: should we warn?
60 |                 continue
61 | 
62 |             dirurl, localrev = cls._get_svn_url_rev(base)
63 | 
64 |             if base == location:
65 |                 assert dirurl is not None
66 |                 base = dirurl + "/"  # save the root url
67 |             elif not dirurl or not dirurl.startswith(base):
68 |                 dirs[:] = []
69 |                 continue  # not part of the same svn tree, skip it
70 |             revision = max(revision, localrev)
71 |         return str(revision)
72 | 
73 |     @classmethod
74 |     def get_netloc_and_auth(
75 |         cls, netloc: str, scheme: str
76 |     ) -> Tuple[str, Tuple[Optional[str], Optional[str]]]:
77 |         """
78 |         This override allows the auth information to be passed to svn via the
79 |         --username and --password options instead of via the URL.
80 |         """
81 |         if scheme == "ssh":
82 |             # The --username and --password options can't be used for
83 |             # svn+ssh URLs, so keep the auth information in the URL.
84 |             return super().get_netloc_and_auth(netloc, scheme)
85 | 
86 |         return split_auth_from_netloc(netloc)
87 | 
88 |     @classmethod
89 |     def get_url_rev_and_auth(cls, url: str) -> Tuple[str, Optional[str], AuthInfo]:
90 |         # hotfix the URL scheme after removing svn+ from svn+ssh:// re-add it
91 |         url, rev, user_pass = super().get_url_rev_and_auth(url)
92 |         if url.startswith("ssh://"):
93 |             url = "svn+" + url
94 |         return url, rev, user_pass
95 | 
96 |     @staticmethod
97 |     def make_rev_args(
98 |         username: Optional[str], password: Optional[HiddenText]
99 |     ) -> CommandArgs:
100 |         extra_args: CommandArgs = []
101 |         if username:
102 |             extra_args += ["--username", username]
103 |         if password:
104 |             extra_args += ["--password", password]
105 | 
106 |         return extra_args
107 | 
108 |     @classmethod
109 |     def get_remote_url(cls, location: str) -> str:
110 |         # In cases where the source is in a subdirectory, we have to look up in
111 |         # the location until we find a valid project root.
112 |         orig_location = location
113 |         while not is_installable_dir(location):
114 |             last_location = location
115 |             location = os.path.dirname(location)
116 |             if location == last_location:
117 |                 # We've traversed up to the root of the filesystem without
118 |                 # finding a Python project.
119 |                 logger.warning(
120 |                     "Could not find Python project for directory %s (tried all "
121 |                     "parent directories)",
122 |                     orig_location,
123 |                 )
124 |                 raise RemoteNotFoundError
125 | 
126 |         url, _rev = cls._get_svn_url_rev(location)
127 |         if url is None:
128 |             raise RemoteNotFoundError
129 | 
130 |         return url
131 | 
132 |     @classmethod
133 |     def _get_svn_url_rev(cls, location: str) -> Tuple[Optional[str], int]:
134 |         from pip._internal.exceptions import InstallationError
135 | 
136 |         entries_path = os.path.join(location, cls.dirname, "entries")
137 |         if os.path.exists(entries_path):
138 |             with open(entries_path) as f:
139 |                 data = f.read()
140 |         else:  # subversion >= 1.7 does not have the 'entries' file
141 |             data = ""
142 | 
143 |         url = None
144 |         if data.startswith("8") or data.startswith("9") or data.startswith("10"):
145 |             entries = list(map(str.splitlines, data.split("\n\x0c\n")))
146 |             del entries[0][0]  # get rid of the '8'
147 |             url = entries[0][3]
148 |             revs = [int(d[9]) for d in entries if len(d) > 9 and d[9]] + [0]
149 |         elif data.startswith("<?xml"):
150 |             match = _svn_xml_url_re.search(data)
151 |             if not match:
152 |                 raise ValueError(f"Badly formatted data: {data!r}")
153 |             url = match.group(1)  # get repository URL
154 |             revs = [int(m.group(1)) for m in _svn_rev_re.finditer(data)] + [0]
155 |         else:
156 |             try:
157 |                 # subversion >= 1.7
158 |                 # Note that using get_remote_call_options is not necessary here
159 |                 # because `svn info` is being run against a local directory.
160 |                 # We don't need to worry about making sure interactive mode
161 |                 # is being used to prompt for passwords, because passwords
162 |                 # are only potentially needed for remote server requests.
163 |                 xml = cls.run_command(
164 |                     ["info", "--xml", location],
165 |                     show_stdout=False,
166 |                     stdout_only=True,
167 |                 )
168 |                 match = _svn_info_xml_url_re.search(xml)
169 |                 assert match is not None
170 |                 url = match.group(1)
171 |                 revs = [int(m.group(1)) for m in _svn_info_xml_rev_re.finditer(xml)]
172 |             except InstallationError:
173 |                 url, revs = None, []
174 | 
175 |         if revs:
176 |             rev = max(revs)
177 |         else:
178 |             rev = 0
179 | 
180 |         return url, rev
181 | 
182 |     @classmethod
183 |     def is_commit_id_equal(cls, dest: str, name: Optional[str]) -> bool:
184 |         """Always assume the versions don't match"""
185 |         return False
186 | 
187 |     def __init__(self, use_interactive: Optional[bool] = None) -> None:
188 |         if use_interactive is None:
189 |             use_interactive = is_console_interactive()
190 |         self.use_interactive = use_interactive
191 | 
192 |         # This member is used to cache the fetched version of the current
193 |         # ``svn`` client.
194 |         # Special value definitions:
195 |         #   None: Not evaluated yet.
196 |         #   Empty tuple: Could not parse version.
197 |         self._vcs_version: Optional[Tuple[int, ...]] = None
198 | 
199 |         super().__init__()
200 | 
201 |     def call_vcs_version(self) -> Tuple[int, ...]:
202 |         """Query the version of the currently installed Subversion client.
203 | 
204 |         :return: A tuple containing the parts of the version information or
205 |             ``()`` if the version returned from ``svn`` could not be parsed.
206 |         :raises: BadCommand: If ``svn`` is not installed.
207 |         """
208 |         # Example versions:
209 |         #   svn, version 1.10.3 (r1842928)
210 |         #      compiled Feb 25 2019, 14:20:39 on x86_64-apple-darwin17.0.0
211 |         #   svn, version 1.7.14 (r1542130)
212 |         #      compiled Mar 28 2018, 08:49:13 on x86_64-pc-linux-gnu
213 |         #   svn, version 1.12.0-SlikSvn (SlikSvn/1.12.0)
214 |         #      compiled May 28 2019, 13:44:56 on x86_64-microsoft-windows6.2
215 |         version_prefix = "svn, version "
216 |         version = self.run_command(["--version"], show_stdout=False, stdout_only=True)
217 |         if not version.startswith(version_prefix):
218 |             return ()
219 | 
220 |         version = version[len(version_prefix) :].split()[0]
221 |         version_list = version.partition("-")[0].split(".")
222 |         try:
223 |             parsed_version = tuple(map(int, version_list))
224 |         except ValueError:
225 |             return ()
226 | 
227 |         return parsed_version
228 | 
229 |     def get_vcs_version(self) -> Tuple[int, ...]:
230 |         """Return the version of the currently installed Subversion client.
231 | 
232 |         If the version of the Subversion client has already been queried,
233 |         a cached value will be used.
234 | 
235 |         :return: A tuple containing the parts of the version information or
236 |             ``()`` if the version returned from ``svn`` could not be parsed.
237 |         :raises: BadCommand: If ``svn`` is not installed.
238 |         """
239 |         if self._vcs_version is not None:
240 |             # Use cached version, if available.
241 |             # If parsing the version failed previously (empty tuple),
242 |             # do not attempt to parse it again.
243 |             return self._vcs_version
244 | 
245 |         vcs_version = self.call_vcs_version()
246 |         self._vcs_version = vcs_version
247 |         return vcs_version
248 | 
249 |     def get_remote_call_options(self) -> CommandArgs:
250 |         """Return options to be used on calls to Subversion that contact the server.
251 | 
252 |         These options are applicable for the following ``svn`` subcommands used
253 |         in this class.
254 | 
255 |             - checkout
256 |             - switch
257 |             - update
258 | 
259 |         :return: A list of command line arguments to pass to ``svn``.
260 |         """
261 |         if not self.use_interactive:
262 |             # --non-interactive switch is available since Subversion 0.14.4.
263 |             # Subversion < 1.8 runs in interactive mode by default.
264 |             return ["--non-interactive"]
265 | 
266 |         svn_version = self.get_vcs_version()
267 |         # By default, Subversion >= 1.8 runs in non-interactive mode if
268 |         # stdin is not a TTY. Since that is how pip invokes SVN, in
269 |         # call_subprocess(), pip must pass --force-interactive to ensure
270 |         # the user can be prompted for a password, if required.
271 |         #   SVN added the --force-interactive option in SVN 1.8. Since
272 |         # e.g. RHEL/CentOS 7, which is supported until 2024, ships with
273 |         # SVN 1.7, pip should continue to support SVN 1.7. Therefore, pip
274 |         # can't safely add the option if the SVN version is < 1.8 (or unknown).
275 |         if svn_version >= (1, 8):
276 |             return ["--force-interactive"]
277 | 
278 |         return []
279 | 
280 |     def fetch_new(
281 |         self, dest: str, url: HiddenText, rev_options: RevOptions, verbosity: int
282 |     ) -> None:
283 |         rev_display = rev_options.to_display()
284 |         logger.info(
285 |             "Checking out %s%s to %s",
286 |             url,
287 |             rev_display,
288 |             display_path(dest),
289 |         )
290 |         if verbosity <= 0:
291 |             flags = ["--quiet"]
292 |         else:
293 |             flags = []
294 |         cmd_args = make_command(
295 |             "checkout",
296 |             *flags,
297 |             self.get_remote_call_options(),
298 |             rev_options.to_args(),
299 |             url,
300 |             dest,
301 |         )
302 |         self.run_command(cmd_args)
303 | 
304 |     def switch(self, dest: str, url: HiddenText, rev_options: RevOptions) -> None:
305 |         cmd_args = make_command(
306 |             "switch",
307 |             self.get_remote_call_options(),
308 |             rev_options.to_args(),
309 |             url,
310 |             dest,
311 |         )
312 |         self.run_command(cmd_args)
313 | 
314 |     def update(self, dest: str, url: HiddenText, rev_options: RevOptions) -> None:
315 |         cmd_args = make_command(
316 |             "update",
317 |             self.get_remote_call_options(),
318 |             rev_options.to_args(),
319 |             dest,
320 |         )
321 |         self.run_command(cmd_args)
322 | 
323 | 
324 | vcs.register(Subversion)
```

.venv/lib/python3.13/site-packages/pip/_internal/vcs/versioncontrol.py
```
1 | """Handles all VCS (version control) support"""
2 | 
3 | import logging
4 | import os
5 | import shutil
6 | import sys
7 | import urllib.parse
8 | from dataclasses import dataclass, field
9 | from typing import (
10 |     Any,
11 |     Dict,
12 |     Iterable,
13 |     Iterator,
14 |     List,
15 |     Literal,
16 |     Mapping,
17 |     Optional,
18 |     Tuple,
19 |     Type,
20 |     Union,
21 | )
22 | 
23 | from pip._internal.cli.spinners import SpinnerInterface
24 | from pip._internal.exceptions import BadCommand, InstallationError
25 | from pip._internal.utils.misc import (
26 |     HiddenText,
27 |     ask_path_exists,
28 |     backup_dir,
29 |     display_path,
30 |     hide_url,
31 |     hide_value,
32 |     is_installable_dir,
33 |     rmtree,
34 | )
35 | from pip._internal.utils.subprocess import (
36 |     CommandArgs,
37 |     call_subprocess,
38 |     format_command_args,
39 |     make_command,
40 | )
41 | 
42 | __all__ = ["vcs"]
43 | 
44 | 
45 | logger = logging.getLogger(__name__)
46 | 
47 | AuthInfo = Tuple[Optional[str], Optional[str]]
48 | 
49 | 
50 | def is_url(name: str) -> bool:
51 |     """
52 |     Return true if the name looks like a URL.
53 |     """
54 |     scheme = urllib.parse.urlsplit(name).scheme
55 |     if not scheme:
56 |         return False
57 |     return scheme in ["http", "https", "file", "ftp"] + vcs.all_schemes
58 | 
59 | 
60 | def make_vcs_requirement_url(
61 |     repo_url: str, rev: str, project_name: str, subdir: Optional[str] = None
62 | ) -> str:
63 |     """
64 |     Return the URL for a VCS requirement.
65 | 
66 |     Args:
67 |       repo_url: the remote VCS url, with any needed VCS prefix (e.g. "git+").
68 |       project_name: the (unescaped) project name.
69 |     """
70 |     egg_project_name = project_name.replace("-", "_")
71 |     req = f"{repo_url}@{rev}#egg={egg_project_name}"
72 |     if subdir:
73 |         req += f"&subdirectory={subdir}"
74 | 
75 |     return req
76 | 
77 | 
78 | def find_path_to_project_root_from_repo_root(
79 |     location: str, repo_root: str
80 | ) -> Optional[str]:
81 |     """
82 |     Find the the Python project's root by searching up the filesystem from
83 |     `location`. Return the path to project root relative to `repo_root`.
84 |     Return None if the project root is `repo_root`, or cannot be found.
85 |     """
86 |     # find project root.
87 |     orig_location = location
88 |     while not is_installable_dir(location):
89 |         last_location = location
90 |         location = os.path.dirname(location)
91 |         if location == last_location:
92 |             # We've traversed up to the root of the filesystem without
93 |             # finding a Python project.
94 |             logger.warning(
95 |                 "Could not find a Python project for directory %s (tried all "
96 |                 "parent directories)",
97 |                 orig_location,
98 |             )
99 |             return None
100 | 
101 |     if os.path.samefile(repo_root, location):
102 |         return None
103 | 
104 |     return os.path.relpath(location, repo_root)
105 | 
106 | 
107 | class RemoteNotFoundError(Exception):
108 |     pass
109 | 
110 | 
111 | class RemoteNotValidError(Exception):
112 |     def __init__(self, url: str):
113 |         super().__init__(url)
114 |         self.url = url
115 | 
116 | 
117 | @dataclass(frozen=True)
118 | class RevOptions:
119 |     """
120 |     Encapsulates a VCS-specific revision to install, along with any VCS
121 |     install options.
122 | 
123 |     Args:
124 |         vc_class: a VersionControl subclass.
125 |         rev: the name of the revision to install.
126 |         extra_args: a list of extra options.
127 |     """
128 | 
129 |     vc_class: Type["VersionControl"]
130 |     rev: Optional[str] = None
131 |     extra_args: CommandArgs = field(default_factory=list)
132 |     branch_name: Optional[str] = None
133 | 
134 |     def __repr__(self) -> str:
135 |         return f"<RevOptions {self.vc_class.name}: rev={self.rev!r}>"
136 | 
137 |     @property
138 |     def arg_rev(self) -> Optional[str]:
139 |         if self.rev is None:
140 |             return self.vc_class.default_arg_rev
141 | 
142 |         return self.rev
143 | 
144 |     def to_args(self) -> CommandArgs:
145 |         """
146 |         Return the VCS-specific command arguments.
147 |         """
148 |         args: CommandArgs = []
149 |         rev = self.arg_rev
150 |         if rev is not None:
151 |             args += self.vc_class.get_base_rev_args(rev)
152 |         args += self.extra_args
153 | 
154 |         return args
155 | 
156 |     def to_display(self) -> str:
157 |         if not self.rev:
158 |             return ""
159 | 
160 |         return f" (to revision {self.rev})"
161 | 
162 |     def make_new(self, rev: str) -> "RevOptions":
163 |         """
164 |         Make a copy of the current instance, but with a new rev.
165 | 
166 |         Args:
167 |           rev: the name of the revision for the new object.
168 |         """
169 |         return self.vc_class.make_rev_options(rev, extra_args=self.extra_args)
170 | 
171 | 
172 | class VcsSupport:
173 |     _registry: Dict[str, "VersionControl"] = {}
174 |     schemes = ["ssh", "git", "hg", "bzr", "sftp", "svn"]
175 | 
176 |     def __init__(self) -> None:
177 |         # Register more schemes with urlparse for various version control
178 |         # systems
179 |         urllib.parse.uses_netloc.extend(self.schemes)
180 |         super().__init__()
181 | 
182 |     def __iter__(self) -> Iterator[str]:
183 |         return self._registry.__iter__()
184 | 
185 |     @property
186 |     def backends(self) -> List["VersionControl"]:
187 |         return list(self._registry.values())
188 | 
189 |     @property
190 |     def dirnames(self) -> List[str]:
191 |         return [backend.dirname for backend in self.backends]
192 | 
193 |     @property
194 |     def all_schemes(self) -> List[str]:
195 |         schemes: List[str] = []
196 |         for backend in self.backends:
197 |             schemes.extend(backend.schemes)
198 |         return schemes
199 | 
200 |     def register(self, cls: Type["VersionControl"]) -> None:
201 |         if not hasattr(cls, "name"):
202 |             logger.warning("Cannot register VCS %s", cls.__name__)
203 |             return
204 |         if cls.name not in self._registry:
205 |             self._registry[cls.name] = cls()
206 |             logger.debug("Registered VCS backend: %s", cls.name)
207 | 
208 |     def unregister(self, name: str) -> None:
209 |         if name in self._registry:
210 |             del self._registry[name]
211 | 
212 |     def get_backend_for_dir(self, location: str) -> Optional["VersionControl"]:
213 |         """
214 |         Return a VersionControl object if a repository of that type is found
215 |         at the given directory.
216 |         """
217 |         vcs_backends = {}
218 |         for vcs_backend in self._registry.values():
219 |             repo_path = vcs_backend.get_repository_root(location)
220 |             if not repo_path:
221 |                 continue
222 |             logger.debug("Determine that %s uses VCS: %s", location, vcs_backend.name)
223 |             vcs_backends[repo_path] = vcs_backend
224 | 
225 |         if not vcs_backends:
226 |             return None
227 | 
228 |         # Choose the VCS in the inner-most directory. Since all repository
229 |         # roots found here would be either `location` or one of its
230 |         # parents, the longest path should have the most path components,
231 |         # i.e. the backend representing the inner-most repository.
232 |         inner_most_repo_path = max(vcs_backends, key=len)
233 |         return vcs_backends[inner_most_repo_path]
234 | 
235 |     def get_backend_for_scheme(self, scheme: str) -> Optional["VersionControl"]:
236 |         """
237 |         Return a VersionControl object or None.
238 |         """
239 |         for vcs_backend in self._registry.values():
240 |             if scheme in vcs_backend.schemes:
241 |                 return vcs_backend
242 |         return None
243 | 
244 |     def get_backend(self, name: str) -> Optional["VersionControl"]:
245 |         """
246 |         Return a VersionControl object or None.
247 |         """
248 |         name = name.lower()
249 |         return self._registry.get(name)
250 | 
251 | 
252 | vcs = VcsSupport()
253 | 
254 | 
255 | class VersionControl:
256 |     name = ""
257 |     dirname = ""
258 |     repo_name = ""
259 |     # List of supported schemes for this Version Control
260 |     schemes: Tuple[str, ...] = ()
261 |     # Iterable of environment variable names to pass to call_subprocess().
262 |     unset_environ: Tuple[str, ...] = ()
263 |     default_arg_rev: Optional[str] = None
264 | 
265 |     @classmethod
266 |     def should_add_vcs_url_prefix(cls, remote_url: str) -> bool:
267 |         """
268 |         Return whether the vcs prefix (e.g. "git+") should be added to a
269 |         repository's remote url when used in a requirement.
270 |         """
271 |         return not remote_url.lower().startswith(f"{cls.name}:")
272 | 
273 |     @classmethod
274 |     def get_subdirectory(cls, location: str) -> Optional[str]:
275 |         """
276 |         Return the path to Python project root, relative to the repo root.
277 |         Return None if the project root is in the repo root.
278 |         """
279 |         return None
280 | 
281 |     @classmethod
282 |     def get_requirement_revision(cls, repo_dir: str) -> str:
283 |         """
284 |         Return the revision string that should be used in a requirement.
285 |         """
286 |         return cls.get_revision(repo_dir)
287 | 
288 |     @classmethod
289 |     def get_src_requirement(cls, repo_dir: str, project_name: str) -> str:
290 |         """
291 |         Return the requirement string to use to redownload the files
292 |         currently at the given repository directory.
293 | 
294 |         Args:
295 |           project_name: the (unescaped) project name.
296 | 
297 |         The return value has a form similar to the following:
298 | 
299 |             {repository_url}@{revision}#egg={project_name}
300 |         """
301 |         repo_url = cls.get_remote_url(repo_dir)
302 | 
303 |         if cls.should_add_vcs_url_prefix(repo_url):
304 |             repo_url = f"{cls.name}+{repo_url}"
305 | 
306 |         revision = cls.get_requirement_revision(repo_dir)
307 |         subdir = cls.get_subdirectory(repo_dir)
308 |         req = make_vcs_requirement_url(repo_url, revision, project_name, subdir=subdir)
309 | 
310 |         return req
311 | 
312 |     @staticmethod
313 |     def get_base_rev_args(rev: str) -> List[str]:
314 |         """
315 |         Return the base revision arguments for a vcs command.
316 | 
317 |         Args:
318 |           rev: the name of a revision to install.  Cannot be None.
319 |         """
320 |         raise NotImplementedError
321 | 
322 |     def is_immutable_rev_checkout(self, url: str, dest: str) -> bool:
323 |         """
324 |         Return true if the commit hash checked out at dest matches
325 |         the revision in url.
326 | 
327 |         Always return False, if the VCS does not support immutable commit
328 |         hashes.
329 | 
330 |         This method does not check if there are local uncommitted changes
331 |         in dest after checkout, as pip currently has no use case for that.
332 |         """
333 |         return False
334 | 
335 |     @classmethod
336 |     def make_rev_options(
337 |         cls, rev: Optional[str] = None, extra_args: Optional[CommandArgs] = None
338 |     ) -> RevOptions:
339 |         """
340 |         Return a RevOptions object.
341 | 
342 |         Args:
343 |           rev: the name of a revision to install.
344 |           extra_args: a list of extra options.
345 |         """
346 |         return RevOptions(cls, rev, extra_args=extra_args or [])
347 | 
348 |     @classmethod
349 |     def _is_local_repository(cls, repo: str) -> bool:
350 |         """
351 |         posix absolute paths start with os.path.sep,
352 |         win32 ones start with drive (like c:\\folder)
353 |         """
354 |         drive, tail = os.path.splitdrive(repo)
355 |         return repo.startswith(os.path.sep) or bool(drive)
356 | 
357 |     @classmethod
358 |     def get_netloc_and_auth(
359 |         cls, netloc: str, scheme: str
360 |     ) -> Tuple[str, Tuple[Optional[str], Optional[str]]]:
361 |         """
362 |         Parse the repository URL's netloc, and return the new netloc to use
363 |         along with auth information.
364 | 
365 |         Args:
366 |           netloc: the original repository URL netloc.
367 |           scheme: the repository URL's scheme without the vcs prefix.
368 | 
369 |         This is mainly for the Subversion class to override, so that auth
370 |         information can be provided via the --username and --password options
371 |         instead of through the URL.  For other subclasses like Git without
372 |         such an option, auth information must stay in the URL.
373 | 
374 |         Returns: (netloc, (username, password)).
375 |         """
376 |         return netloc, (None, None)
377 | 
378 |     @classmethod
379 |     def get_url_rev_and_auth(cls, url: str) -> Tuple[str, Optional[str], AuthInfo]:
[TRUNCATED]
```

.venv/lib/python3.13/site-packages/pip/_vendor/cachecontrol/__init__.py
```
1 | # SPDX-FileCopyrightText: 2015 Eric Larson
2 | #
3 | # SPDX-License-Identifier: Apache-2.0
4 | 
5 | """CacheControl import Interface.
6 | 
7 | Make it easy to import from cachecontrol without long namespaces.
8 | """
9 | 
10 | __author__ = "Eric Larson"
11 | __email__ = "eric@ionrock.org"
12 | __version__ = "0.14.2"
13 | 
14 | from pip._vendor.cachecontrol.adapter import CacheControlAdapter
15 | from pip._vendor.cachecontrol.controller import CacheController
16 | from pip._vendor.cachecontrol.wrapper import CacheControl
17 | 
18 | __all__ = [
19 |     "__author__",
20 |     "__email__",
21 |     "__version__",
22 |     "CacheControlAdapter",
23 |     "CacheController",
24 |     "CacheControl",
25 | ]
26 | 
27 | import logging
28 | 
29 | logging.getLogger(__name__).addHandler(logging.NullHandler())
```

.venv/lib/python3.13/site-packages/pip/_vendor/cachecontrol/_cmd.py
```
1 | # SPDX-FileCopyrightText: 2015 Eric Larson
2 | #
3 | # SPDX-License-Identifier: Apache-2.0
4 | from __future__ import annotations
5 | 
6 | import logging
7 | from argparse import ArgumentParser
8 | from typing import TYPE_CHECKING
9 | 
10 | from pip._vendor import requests
11 | 
12 | from pip._vendor.cachecontrol.adapter import CacheControlAdapter
13 | from pip._vendor.cachecontrol.cache import DictCache
14 | from pip._vendor.cachecontrol.controller import logger
15 | 
16 | if TYPE_CHECKING:
17 |     from argparse import Namespace
18 | 
19 |     from pip._vendor.cachecontrol.controller import CacheController
20 | 
21 | 
22 | def setup_logging() -> None:
23 |     logger.setLevel(logging.DEBUG)
24 |     handler = logging.StreamHandler()
25 |     logger.addHandler(handler)
26 | 
27 | 
28 | def get_session() -> requests.Session:
29 |     adapter = CacheControlAdapter(
30 |         DictCache(), cache_etags=True, serializer=None, heuristic=None
31 |     )
32 |     sess = requests.Session()
33 |     sess.mount("http://", adapter)
34 |     sess.mount("https://", adapter)
35 | 
36 |     sess.cache_controller = adapter.controller  # type: ignore[attr-defined]
37 |     return sess
38 | 
39 | 
40 | def get_args() -> Namespace:
41 |     parser = ArgumentParser()
42 |     parser.add_argument("url", help="The URL to try and cache")
43 |     return parser.parse_args()
44 | 
45 | 
46 | def main() -> None:
47 |     args = get_args()
48 |     sess = get_session()
49 | 
50 |     # Make a request to get a response
51 |     resp = sess.get(args.url)
52 | 
53 |     # Turn on logging
54 |     setup_logging()
55 | 
56 |     # try setting the cache
57 |     cache_controller: CacheController = (
58 |         sess.cache_controller  # type: ignore[attr-defined]
59 |     )
60 |     cache_controller.cache_response(resp.request, resp.raw)
61 | 
62 |     # Now try to get it
63 |     if cache_controller.cached_request(resp.request):
64 |         print("Cached!")
65 |     else:
66 |         print("Not cached :(")
67 | 
68 | 
69 | if __name__ == "__main__":
70 |     main()
```

.venv/lib/python3.13/site-packages/pip/_vendor/cachecontrol/adapter.py
```
1 | # SPDX-FileCopyrightText: 2015 Eric Larson
2 | #
3 | # SPDX-License-Identifier: Apache-2.0
4 | from __future__ import annotations
5 | 
6 | import functools
7 | import types
8 | import weakref
9 | import zlib
10 | from typing import TYPE_CHECKING, Any, Collection, Mapping
11 | 
12 | from pip._vendor.requests.adapters import HTTPAdapter
13 | 
14 | from pip._vendor.cachecontrol.cache import DictCache
15 | from pip._vendor.cachecontrol.controller import PERMANENT_REDIRECT_STATUSES, CacheController
16 | from pip._vendor.cachecontrol.filewrapper import CallbackFileWrapper
17 | 
18 | if TYPE_CHECKING:
19 |     from pip._vendor.requests import PreparedRequest, Response
20 |     from pip._vendor.urllib3 import HTTPResponse
21 | 
22 |     from pip._vendor.cachecontrol.cache import BaseCache
23 |     from pip._vendor.cachecontrol.heuristics import BaseHeuristic
24 |     from pip._vendor.cachecontrol.serialize import Serializer
25 | 
26 | 
27 | class CacheControlAdapter(HTTPAdapter):
28 |     invalidating_methods = {"PUT", "PATCH", "DELETE"}
29 | 
30 |     def __init__(
31 |         self,
32 |         cache: BaseCache | None = None,
33 |         cache_etags: bool = True,
34 |         controller_class: type[CacheController] | None = None,
35 |         serializer: Serializer | None = None,
36 |         heuristic: BaseHeuristic | None = None,
37 |         cacheable_methods: Collection[str] | None = None,
38 |         *args: Any,
39 |         **kw: Any,
40 |     ) -> None:
41 |         super().__init__(*args, **kw)
42 |         self.cache = DictCache() if cache is None else cache
43 |         self.heuristic = heuristic
44 |         self.cacheable_methods = cacheable_methods or ("GET",)
45 | 
46 |         controller_factory = controller_class or CacheController
47 |         self.controller = controller_factory(
48 |             self.cache, cache_etags=cache_etags, serializer=serializer
49 |         )
50 | 
51 |     def send(
52 |         self,
53 |         request: PreparedRequest,
54 |         stream: bool = False,
55 |         timeout: None | float | tuple[float, float] | tuple[float, None] = None,
56 |         verify: bool | str = True,
57 |         cert: (None | bytes | str | tuple[bytes | str, bytes | str]) = None,
58 |         proxies: Mapping[str, str] | None = None,
59 |         cacheable_methods: Collection[str] | None = None,
60 |     ) -> Response:
61 |         """
62 |         Send a request. Use the request information to see if it
63 |         exists in the cache and cache the response if we need to and can.
64 |         """
65 |         cacheable = cacheable_methods or self.cacheable_methods
66 |         if request.method in cacheable:
67 |             try:
68 |                 cached_response = self.controller.cached_request(request)
69 |             except zlib.error:
70 |                 cached_response = None
71 |             if cached_response:
72 |                 return self.build_response(request, cached_response, from_cache=True)
73 | 
74 |             # check for etags and add headers if appropriate
75 |             request.headers.update(self.controller.conditional_headers(request))
76 | 
77 |         resp = super().send(request, stream, timeout, verify, cert, proxies)
78 | 
79 |         return resp
80 | 
81 |     def build_response(  # type: ignore[override]
82 |         self,
83 |         request: PreparedRequest,
84 |         response: HTTPResponse,
85 |         from_cache: bool = False,
86 |         cacheable_methods: Collection[str] | None = None,
87 |     ) -> Response:
88 |         """
89 |         Build a response by making a request or using the cache.
90 | 
91 |         This will end up calling send and returning a potentially
92 |         cached response
93 |         """
94 |         cacheable = cacheable_methods or self.cacheable_methods
95 |         if not from_cache and request.method in cacheable:
96 |             # Check for any heuristics that might update headers
97 |             # before trying to cache.
98 |             if self.heuristic:
99 |                 response = self.heuristic.apply(response)
100 | 
101 |             # apply any expiration heuristics
102 |             if response.status == 304:
103 |                 # We must have sent an ETag request. This could mean
104 |                 # that we've been expired already or that we simply
105 |                 # have an etag. In either case, we want to try and
106 |                 # update the cache if that is the case.
107 |                 cached_response = self.controller.update_cached_response(
108 |                     request, response
109 |                 )
110 | 
111 |                 if cached_response is not response:
112 |                     from_cache = True
113 | 
114 |                 # We are done with the server response, read a
115 |                 # possible response body (compliant servers will
116 |                 # not return one, but we cannot be 100% sure) and
117 |                 # release the connection back to the pool.
118 |                 response.read(decode_content=False)
119 |                 response.release_conn()
120 | 
121 |                 response = cached_response
122 | 
123 |             # We always cache the 301 responses
124 |             elif int(response.status) in PERMANENT_REDIRECT_STATUSES:
125 |                 self.controller.cache_response(request, response)
126 |             else:
127 |                 # Wrap the response file with a wrapper that will cache the
128 |                 #   response when the stream has been consumed.
129 |                 response._fp = CallbackFileWrapper(  # type: ignore[assignment]
130 |                     response._fp,  # type: ignore[arg-type]
131 |                     functools.partial(
132 |                         self.controller.cache_response, request, weakref.ref(response)
133 |                     ),
134 |                 )
135 |                 if response.chunked:
136 |                     super_update_chunk_length = response.__class__._update_chunk_length
137 | 
138 |                     def _update_chunk_length(
139 |                         weak_self: weakref.ReferenceType[HTTPResponse],
140 |                     ) -> None:
141 |                         self = weak_self()
142 |                         if self is None:
143 |                             return
144 | 
145 |                         super_update_chunk_length(self)
146 |                         if self.chunk_left == 0:
147 |                             self._fp._close()  # type: ignore[union-attr]
148 | 
149 |                     response._update_chunk_length = functools.partial(  # type: ignore[method-assign]
150 |                         _update_chunk_length, weakref.ref(response)
151 |                     )
152 | 
153 |         resp: Response = super().build_response(request, response)
154 | 
155 |         # See if we should invalidate the cache.
156 |         if request.method in self.invalidating_methods and resp.ok:
157 |             assert request.url is not None
158 |             cache_url = self.controller.cache_url(request.url)
159 |             self.cache.delete(cache_url)
160 | 
161 |         # Give the request a from_cache attr to let people use it
162 |         resp.from_cache = from_cache  # type: ignore[attr-defined]
163 | 
164 |         return resp
165 | 
166 |     def close(self) -> None:
167 |         self.cache.close()
168 |         super().close()  # type: ignore[no-untyped-call]
```

.venv/lib/python3.13/site-packages/pip/_vendor/cachecontrol/cache.py
```
1 | # SPDX-FileCopyrightText: 2015 Eric Larson
2 | #
3 | # SPDX-License-Identifier: Apache-2.0
4 | 
5 | """
6 | The cache object API for implementing caches. The default is a thread
7 | safe in-memory dictionary.
8 | """
9 | 
10 | from __future__ import annotations
11 | 
12 | from threading import Lock
13 | from typing import IO, TYPE_CHECKING, MutableMapping
14 | 
15 | if TYPE_CHECKING:
16 |     from datetime import datetime
17 | 
18 | 
19 | class BaseCache:
20 |     def get(self, key: str) -> bytes | None:
21 |         raise NotImplementedError()
22 | 
23 |     def set(
24 |         self, key: str, value: bytes, expires: int | datetime | None = None
25 |     ) -> None:
26 |         raise NotImplementedError()
27 | 
28 |     def delete(self, key: str) -> None:
29 |         raise NotImplementedError()
30 | 
31 |     def close(self) -> None:
32 |         pass
33 | 
34 | 
35 | class DictCache(BaseCache):
36 |     def __init__(self, init_dict: MutableMapping[str, bytes] | None = None) -> None:
37 |         self.lock = Lock()
38 |         self.data = init_dict or {}
39 | 
40 |     def get(self, key: str) -> bytes | None:
41 |         return self.data.get(key, None)
42 | 
43 |     def set(
44 |         self, key: str, value: bytes, expires: int | datetime | None = None
45 |     ) -> None:
46 |         with self.lock:
47 |             self.data.update({key: value})
48 | 
49 |     def delete(self, key: str) -> None:
50 |         with self.lock:
51 |             if key in self.data:
52 |                 self.data.pop(key)
53 | 
54 | 
55 | class SeparateBodyBaseCache(BaseCache):
56 |     """
57 |     In this variant, the body is not stored mixed in with the metadata, but is
58 |     passed in (as a bytes-like object) in a separate call to ``set_body()``.
59 | 
60 |     That is, the expected interaction pattern is::
61 | 
62 |         cache.set(key, serialized_metadata)
63 |         cache.set_body(key)
64 | 
65 |     Similarly, the body should be loaded separately via ``get_body()``.
66 |     """
67 | 
68 |     def set_body(self, key: str, body: bytes) -> None:
69 |         raise NotImplementedError()
70 | 
71 |     def get_body(self, key: str) -> IO[bytes] | None:
72 |         """
73 |         Return the body as file-like object.
74 |         """
75 |         raise NotImplementedError()
```

.venv/lib/python3.13/site-packages/pip/_vendor/cachecontrol/controller.py
```
1 | # SPDX-FileCopyrightText: 2015 Eric Larson
2 | #
3 | # SPDX-License-Identifier: Apache-2.0
4 | 
5 | """
6 | The httplib2 algorithms ported for use with requests.
7 | """
8 | 
9 | from __future__ import annotations
10 | 
11 | import calendar
12 | import logging
13 | import re
14 | import time
15 | import weakref
16 | from email.utils import parsedate_tz
17 | from typing import TYPE_CHECKING, Collection, Mapping
18 | 
19 | from pip._vendor.requests.structures import CaseInsensitiveDict
20 | 
21 | from pip._vendor.cachecontrol.cache import DictCache, SeparateBodyBaseCache
22 | from pip._vendor.cachecontrol.serialize import Serializer
23 | 
24 | if TYPE_CHECKING:
25 |     from typing import Literal
26 | 
27 |     from pip._vendor.requests import PreparedRequest
28 |     from pip._vendor.urllib3 import HTTPResponse
29 | 
30 |     from pip._vendor.cachecontrol.cache import BaseCache
31 | 
32 | logger = logging.getLogger(__name__)
33 | 
34 | URI = re.compile(r"^(([^:/?#]+):)?(//([^/?#]*))?([^?#]*)(\?([^#]*))?(#(.*))?")
35 | 
36 | PERMANENT_REDIRECT_STATUSES = (301, 308)
37 | 
38 | 
39 | def parse_uri(uri: str) -> tuple[str, str, str, str, str]:
40 |     """Parses a URI using the regex given in Appendix B of RFC 3986.
41 | 
42 |     (scheme, authority, path, query, fragment) = parse_uri(uri)
43 |     """
44 |     match = URI.match(uri)
45 |     assert match is not None
46 |     groups = match.groups()
47 |     return (groups[1], groups[3], groups[4], groups[6], groups[8])
48 | 
49 | 
50 | class CacheController:
51 |     """An interface to see if request should cached or not."""
52 | 
53 |     def __init__(
54 |         self,
55 |         cache: BaseCache | None = None,
56 |         cache_etags: bool = True,
57 |         serializer: Serializer | None = None,
58 |         status_codes: Collection[int] | None = None,
59 |     ):
60 |         self.cache = DictCache() if cache is None else cache
61 |         self.cache_etags = cache_etags
62 |         self.serializer = serializer or Serializer()
63 |         self.cacheable_status_codes = status_codes or (200, 203, 300, 301, 308)
64 | 
65 |     @classmethod
66 |     def _urlnorm(cls, uri: str) -> str:
67 |         """Normalize the URL to create a safe key for the cache"""
68 |         (scheme, authority, path, query, fragment) = parse_uri(uri)
69 |         if not scheme or not authority:
70 |             raise Exception("Only absolute URIs are allowed. uri = %s" % uri)
71 | 
72 |         scheme = scheme.lower()
73 |         authority = authority.lower()
74 | 
75 |         if not path:
76 |             path = "/"
77 | 
78 |         # Could do syntax based normalization of the URI before
79 |         # computing the digest. See Section 6.2.2 of Std 66.
80 |         request_uri = query and "?".join([path, query]) or path
81 |         defrag_uri = scheme + "://" + authority + request_uri
82 | 
83 |         return defrag_uri
84 | 
85 |     @classmethod
86 |     def cache_url(cls, uri: str) -> str:
87 |         return cls._urlnorm(uri)
88 | 
89 |     def parse_cache_control(self, headers: Mapping[str, str]) -> dict[str, int | None]:
90 |         known_directives = {
91 |             # https://tools.ietf.org/html/rfc7234#section-5.2
92 |             "max-age": (int, True),
93 |             "max-stale": (int, False),
94 |             "min-fresh": (int, True),
95 |             "no-cache": (None, False),
96 |             "no-store": (None, False),
97 |             "no-transform": (None, False),
98 |             "only-if-cached": (None, False),
99 |             "must-revalidate": (None, False),
100 |             "public": (None, False),
101 |             "private": (None, False),
102 |             "proxy-revalidate": (None, False),
103 |             "s-maxage": (int, True),
104 |         }
105 | 
106 |         cc_headers = headers.get("cache-control", headers.get("Cache-Control", ""))
107 | 
108 |         retval: dict[str, int | None] = {}
109 | 
110 |         for cc_directive in cc_headers.split(","):
111 |             if not cc_directive.strip():
112 |                 continue
113 | 
114 |             parts = cc_directive.split("=", 1)
115 |             directive = parts[0].strip()
116 | 
117 |             try:
118 |                 typ, required = known_directives[directive]
119 |             except KeyError:
120 |                 logger.debug("Ignoring unknown cache-control directive: %s", directive)
121 |                 continue
122 | 
123 |             if not typ or not required:
124 |                 retval[directive] = None
125 |             if typ:
126 |                 try:
127 |                     retval[directive] = typ(parts[1].strip())
128 |                 except IndexError:
129 |                     if required:
130 |                         logger.debug(
131 |                             "Missing value for cache-control " "directive: %s",
132 |                             directive,
133 |                         )
134 |                 except ValueError:
135 |                     logger.debug(
136 |                         "Invalid value for cache-control directive " "%s, must be %s",
137 |                         directive,
138 |                         typ.__name__,
139 |                     )
140 | 
141 |         return retval
142 | 
143 |     def _load_from_cache(self, request: PreparedRequest) -> HTTPResponse | None:
144 |         """
145 |         Load a cached response, or return None if it's not available.
146 |         """
147 |         # We do not support caching of partial content: so if the request contains a
148 |         # Range header then we don't want to load anything from the cache.
149 |         if "Range" in request.headers:
150 |             return None
151 | 
152 |         cache_url = request.url
153 |         assert cache_url is not None
154 |         cache_data = self.cache.get(cache_url)
155 |         if cache_data is None:
156 |             logger.debug("No cache entry available")
157 |             return None
158 | 
159 |         if isinstance(self.cache, SeparateBodyBaseCache):
160 |             body_file = self.cache.get_body(cache_url)
161 |         else:
162 |             body_file = None
163 | 
164 |         result = self.serializer.loads(request, cache_data, body_file)
165 |         if result is None:
166 |             logger.warning("Cache entry deserialization failed, entry ignored")
167 |         return result
168 | 
169 |     def cached_request(self, request: PreparedRequest) -> HTTPResponse | Literal[False]:
170 |         """
171 |         Return a cached response if it exists in the cache, otherwise
172 |         return False.
173 |         """
174 |         assert request.url is not None
175 |         cache_url = self.cache_url(request.url)
176 |         logger.debug('Looking up "%s" in the cache', cache_url)
177 |         cc = self.parse_cache_control(request.headers)
178 | 
179 |         # Bail out if the request insists on fresh data
180 |         if "no-cache" in cc:
181 |             logger.debug('Request header has "no-cache", cache bypassed')
182 |             return False
183 | 
184 |         if "max-age" in cc and cc["max-age"] == 0:
185 |             logger.debug('Request header has "max_age" as 0, cache bypassed')
186 |             return False
187 | 
188 |         # Check whether we can load the response from the cache:
189 |         resp = self._load_from_cache(request)
190 |         if not resp:
191 |             return False
192 | 
193 |         # If we have a cached permanent redirect, return it immediately. We
194 |         # don't need to test our response for other headers b/c it is
195 |         # intrinsically "cacheable" as it is Permanent.
196 |         #
197 |         # See:
198 |         #   https://tools.ietf.org/html/rfc7231#section-6.4.2
199 |         #
200 |         # Client can try to refresh the value by repeating the request
201 |         # with cache busting headers as usual (ie no-cache).
202 |         if int(resp.status) in PERMANENT_REDIRECT_STATUSES:
203 |             msg = (
204 |                 "Returning cached permanent redirect response "
205 |                 "(ignoring date and etag information)"
206 |             )
207 |             logger.debug(msg)
208 |             return resp
209 | 
210 |         headers: CaseInsensitiveDict[str] = CaseInsensitiveDict(resp.headers)
211 |         if not headers or "date" not in headers:
212 |             if "etag" not in headers:
213 |                 # Without date or etag, the cached response can never be used
214 |                 # and should be deleted.
215 |                 logger.debug("Purging cached response: no date or etag")
216 |                 self.cache.delete(cache_url)
217 |             logger.debug("Ignoring cached response: no date")
218 |             return False
219 | 
220 |         now = time.time()
221 |         time_tuple = parsedate_tz(headers["date"])
222 |         assert time_tuple is not None
223 |         date = calendar.timegm(time_tuple[:6])
224 |         current_age = max(0, now - date)
225 |         logger.debug("Current age based on date: %i", current_age)
226 | 
227 |         # TODO: There is an assumption that the result will be a
228 |         #       urllib3 response object. This may not be best since we
229 |         #       could probably avoid instantiating or constructing the
230 |         #       response until we know we need it.
231 |         resp_cc = self.parse_cache_control(headers)
232 | 
233 |         # determine freshness
234 |         freshness_lifetime = 0
235 | 
236 |         # Check the max-age pragma in the cache control header
237 |         max_age = resp_cc.get("max-age")
238 |         if max_age is not None:
239 |             freshness_lifetime = max_age
240 |             logger.debug("Freshness lifetime from max-age: %i", freshness_lifetime)
241 | 
242 |         # If there isn't a max-age, check for an expires header
243 |         elif "expires" in headers:
244 |             expires = parsedate_tz(headers["expires"])
245 |             if expires is not None:
246 |                 expire_time = calendar.timegm(expires[:6]) - date
247 |                 freshness_lifetime = max(0, expire_time)
248 |                 logger.debug("Freshness lifetime from expires: %i", freshness_lifetime)
249 | 
250 |         # Determine if we are setting freshness limit in the
251 |         # request. Note, this overrides what was in the response.
252 |         max_age = cc.get("max-age")
253 |         if max_age is not None:
254 |             freshness_lifetime = max_age
255 |             logger.debug(
256 |                 "Freshness lifetime from request max-age: %i", freshness_lifetime
257 |             )
258 | 
259 |         min_fresh = cc.get("min-fresh")
260 |         if min_fresh is not None:
261 |             # adjust our current age by our min fresh
262 |             current_age += min_fresh
263 |             logger.debug("Adjusted current age from min-fresh: %i", current_age)
264 | 
265 |         # Return entry if it is fresh enough
266 |         if freshness_lifetime > current_age:
267 |             logger.debug('The response is "fresh", returning cached response')
268 |             logger.debug("%i > %i", freshness_lifetime, current_age)
269 |             return resp
270 | 
271 |         # we're not fresh. If we don't have an Etag, clear it out
272 |         if "etag" not in headers:
273 |             logger.debug('The cached response is "stale" with no etag, purging')
274 |             self.cache.delete(cache_url)
275 | 
276 |         # return the original handler
277 |         return False
278 | 
279 |     def conditional_headers(self, request: PreparedRequest) -> dict[str, str]:
280 |         resp = self._load_from_cache(request)
281 |         new_headers = {}
282 | 
283 |         if resp:
284 |             headers: CaseInsensitiveDict[str] = CaseInsensitiveDict(resp.headers)
285 | 
286 |             if "etag" in headers:
287 |                 new_headers["If-None-Match"] = headers["ETag"]
288 | 
289 |             if "last-modified" in headers:
290 |                 new_headers["If-Modified-Since"] = headers["Last-Modified"]
291 | 
292 |         return new_headers
293 | 
294 |     def _cache_set(
295 |         self,
296 |         cache_url: str,
297 |         request: PreparedRequest,
298 |         response: HTTPResponse,
299 |         body: bytes | None = None,
300 |         expires_time: int | None = None,
301 |     ) -> None:
302 |         """
303 |         Store the data in the cache.
304 |         """
305 |         if isinstance(self.cache, SeparateBodyBaseCache):
306 |             # We pass in the body separately; just put a placeholder empty
307 |             # string in the metadata.
308 |             self.cache.set(
309 |                 cache_url,
310 |                 self.serializer.dumps(request, response, b""),
311 |                 expires=expires_time,
312 |             )
313 |             # body is None can happen when, for example, we're only updating
314 |             # headers, as is the case in update_cached_response().
315 |             if body is not None:
316 |                 self.cache.set_body(cache_url, body)
317 |         else:
318 |             self.cache.set(
319 |                 cache_url,
320 |                 self.serializer.dumps(request, response, body),
321 |                 expires=expires_time,
322 |             )
323 | 
324 |     def cache_response(
325 |         self,
326 |         request: PreparedRequest,
327 |         response_or_ref: HTTPResponse | weakref.ReferenceType[HTTPResponse],
328 |         body: bytes | None = None,
329 |         status_codes: Collection[int] | None = None,
330 |     ) -> None:
331 |         """
332 |         Algorithm for caching requests.
333 | 
334 |         This assumes a requests Response object.
335 |         """
336 |         if isinstance(response_or_ref, weakref.ReferenceType):
337 |             response = response_or_ref()
338 |             if response is None:
339 |                 # The weakref can be None only in case the user used streamed request
340 |                 # and did not consume or close it, and holds no reference to requests.Response.
341 |                 # In such case, we don't want to cache the response.
342 |                 return
[TRUNCATED]
```

.venv/lib/python3.13/site-packages/pip/_vendor/cachecontrol/filewrapper.py
```
1 | # SPDX-FileCopyrightText: 2015 Eric Larson
2 | #
3 | # SPDX-License-Identifier: Apache-2.0
4 | from __future__ import annotations
5 | 
6 | import mmap
7 | from tempfile import NamedTemporaryFile
8 | from typing import TYPE_CHECKING, Any, Callable
9 | 
10 | if TYPE_CHECKING:
11 |     from http.client import HTTPResponse
12 | 
13 | 
14 | class CallbackFileWrapper:
15 |     """
16 |     Small wrapper around a fp object which will tee everything read into a
17 |     buffer, and when that file is closed it will execute a callback with the
18 |     contents of that buffer.
19 | 
20 |     All attributes are proxied to the underlying file object.
21 | 
22 |     This class uses members with a double underscore (__) leading prefix so as
23 |     not to accidentally shadow an attribute.
24 | 
25 |     The data is stored in a temporary file until it is all available.  As long
26 |     as the temporary files directory is disk-based (sometimes it's a
27 |     memory-backed-``tmpfs`` on Linux), data will be unloaded to disk if memory
28 |     pressure is high.  For small files the disk usually won't be used at all,
29 |     it'll all be in the filesystem memory cache, so there should be no
30 |     performance impact.
31 |     """
32 | 
33 |     def __init__(
34 |         self, fp: HTTPResponse, callback: Callable[[bytes], None] | None
35 |     ) -> None:
36 |         self.__buf = NamedTemporaryFile("rb+", delete=True)
37 |         self.__fp = fp
38 |         self.__callback = callback
39 | 
40 |     def __getattr__(self, name: str) -> Any:
41 |         # The vagaries of garbage collection means that self.__fp is
42 |         # not always set.  By using __getattribute__ and the private
43 |         # name[0] allows looking up the attribute value and raising an
44 |         # AttributeError when it doesn't exist. This stop things from
45 |         # infinitely recursing calls to getattr in the case where
46 |         # self.__fp hasn't been set.
47 |         #
48 |         # [0] https://docs.python.org/2/reference/expressions.html#atom-identifiers
49 |         fp = self.__getattribute__("_CallbackFileWrapper__fp")
50 |         return getattr(fp, name)
51 | 
52 |     def __is_fp_closed(self) -> bool:
53 |         try:
54 |             return self.__fp.fp is None
55 | 
56 |         except AttributeError:
57 |             pass
58 | 
59 |         try:
60 |             closed: bool = self.__fp.closed
61 |             return closed
62 | 
63 |         except AttributeError:
64 |             pass
65 | 
66 |         # We just don't cache it then.
67 |         # TODO: Add some logging here...
68 |         return False
69 | 
70 |     def _close(self) -> None:
71 |         if self.__callback:
72 |             if self.__buf.tell() == 0:
73 |                 # Empty file:
74 |                 result = b""
75 |             else:
76 |                 # Return the data without actually loading it into memory,
77 |                 # relying on Python's buffer API and mmap(). mmap() just gives
78 |                 # a view directly into the filesystem's memory cache, so it
79 |                 # doesn't result in duplicate memory use.
80 |                 self.__buf.seek(0, 0)
81 |                 result = memoryview(
82 |                     mmap.mmap(self.__buf.fileno(), 0, access=mmap.ACCESS_READ)
83 |                 )
84 |             self.__callback(result)
85 | 
86 |         # We assign this to None here, because otherwise we can get into
87 |         # really tricky problems where the CPython interpreter dead locks
88 |         # because the callback is holding a reference to something which
89 |         # has a __del__ method. Setting this to None breaks the cycle
90 |         # and allows the garbage collector to do it's thing normally.
91 |         self.__callback = None
92 | 
93 |         # Closing the temporary file releases memory and frees disk space.
94 |         # Important when caching big files.
95 |         self.__buf.close()
96 | 
97 |     def read(self, amt: int | None = None) -> bytes:
98 |         data: bytes = self.__fp.read(amt)
99 |         if data:
100 |             # We may be dealing with b'', a sign that things are over:
101 |             # it's passed e.g. after we've already closed self.__buf.
102 |             self.__buf.write(data)
103 |         if self.__is_fp_closed():
104 |             self._close()
105 | 
106 |         return data
107 | 
108 |     def _safe_read(self, amt: int) -> bytes:
109 |         data: bytes = self.__fp._safe_read(amt)  # type: ignore[attr-defined]
110 |         if amt == 2 and data == b"\r\n":
111 |             # urllib executes this read to toss the CRLF at the end
112 |             # of the chunk.
113 |             return data
114 | 
115 |         self.__buf.write(data)
116 |         if self.__is_fp_closed():
117 |             self._close()
118 | 
119 |         return data
```

.venv/lib/python3.13/site-packages/pip/_vendor/cachecontrol/heuristics.py
```
1 | # SPDX-FileCopyrightText: 2015 Eric Larson
2 | #
3 | # SPDX-License-Identifier: Apache-2.0
4 | from __future__ import annotations
5 | 
6 | import calendar
7 | import time
8 | from datetime import datetime, timedelta, timezone
9 | from email.utils import formatdate, parsedate, parsedate_tz
10 | from typing import TYPE_CHECKING, Any, Mapping
11 | 
12 | if TYPE_CHECKING:
13 |     from pip._vendor.urllib3 import HTTPResponse
14 | 
15 | TIME_FMT = "%a, %d %b %Y %H:%M:%S GMT"
16 | 
17 | 
18 | def expire_after(delta: timedelta, date: datetime | None = None) -> datetime:
19 |     date = date or datetime.now(timezone.utc)
20 |     return date + delta
21 | 
22 | 
23 | def datetime_to_header(dt: datetime) -> str:
24 |     return formatdate(calendar.timegm(dt.timetuple()))
25 | 
26 | 
27 | class BaseHeuristic:
28 |     def warning(self, response: HTTPResponse) -> str | None:
29 |         """
30 |         Return a valid 1xx warning header value describing the cache
31 |         adjustments.
32 | 
33 |         The response is provided too allow warnings like 113
34 |         http://tools.ietf.org/html/rfc7234#section-5.5.4 where we need
35 |         to explicitly say response is over 24 hours old.
36 |         """
37 |         return '110 - "Response is Stale"'
38 | 
39 |     def update_headers(self, response: HTTPResponse) -> dict[str, str]:
40 |         """Update the response headers with any new headers.
41 | 
42 |         NOTE: This SHOULD always include some Warning header to
43 |               signify that the response was cached by the client, not
44 |               by way of the provided headers.
45 |         """
46 |         return {}
47 | 
48 |     def apply(self, response: HTTPResponse) -> HTTPResponse:
49 |         updated_headers = self.update_headers(response)
50 | 
51 |         if updated_headers:
52 |             response.headers.update(updated_headers)
53 |             warning_header_value = self.warning(response)
54 |             if warning_header_value is not None:
55 |                 response.headers.update({"Warning": warning_header_value})
56 | 
57 |         return response
58 | 
59 | 
60 | class OneDayCache(BaseHeuristic):
61 |     """
62 |     Cache the response by providing an expires 1 day in the
63 |     future.
64 |     """
65 | 
66 |     def update_headers(self, response: HTTPResponse) -> dict[str, str]:
67 |         headers = {}
68 | 
69 |         if "expires" not in response.headers:
70 |             date = parsedate(response.headers["date"])
71 |             expires = expire_after(
72 |                 timedelta(days=1),
73 |                 date=datetime(*date[:6], tzinfo=timezone.utc),  # type: ignore[index,misc]
74 |             )
75 |             headers["expires"] = datetime_to_header(expires)
76 |             headers["cache-control"] = "public"
77 |         return headers
78 | 
79 | 
80 | class ExpiresAfter(BaseHeuristic):
81 |     """
82 |     Cache **all** requests for a defined time period.
83 |     """
84 | 
85 |     def __init__(self, **kw: Any) -> None:
86 |         self.delta = timedelta(**kw)
87 | 
88 |     def update_headers(self, response: HTTPResponse) -> dict[str, str]:
89 |         expires = expire_after(self.delta)
90 |         return {"expires": datetime_to_header(expires), "cache-control": "public"}
91 | 
92 |     def warning(self, response: HTTPResponse) -> str | None:
93 |         tmpl = "110 - Automatically cached for %s. Response might be stale"
94 |         return tmpl % self.delta
95 | 
96 | 
97 | class LastModified(BaseHeuristic):
98 |     """
99 |     If there is no Expires header already, fall back on Last-Modified
100 |     using the heuristic from
101 |     http://tools.ietf.org/html/rfc7234#section-4.2.2
102 |     to calculate a reasonable value.
103 | 
104 |     Firefox also does something like this per
105 |     https://developer.mozilla.org/en-US/docs/Web/HTTP/Caching_FAQ
106 |     http://lxr.mozilla.org/mozilla-release/source/netwerk/protocol/http/nsHttpResponseHead.cpp#397
107 |     Unlike mozilla we limit this to 24-hr.
108 |     """
109 | 
110 |     cacheable_by_default_statuses = {
111 |         200,
112 |         203,
113 |         204,
114 |         206,
115 |         300,
116 |         301,
117 |         404,
118 |         405,
119 |         410,
120 |         414,
121 |         501,
122 |     }
123 | 
124 |     def update_headers(self, resp: HTTPResponse) -> dict[str, str]:
125 |         headers: Mapping[str, str] = resp.headers
126 | 
127 |         if "expires" in headers:
128 |             return {}
129 | 
130 |         if "cache-control" in headers and headers["cache-control"] != "public":
131 |             return {}
132 | 
133 |         if resp.status not in self.cacheable_by_default_statuses:
134 |             return {}
135 | 
136 |         if "date" not in headers or "last-modified" not in headers:
137 |             return {}
138 | 
139 |         time_tuple = parsedate_tz(headers["date"])
140 |         assert time_tuple is not None
141 |         date = calendar.timegm(time_tuple[:6])
142 |         last_modified = parsedate(headers["last-modified"])
143 |         if last_modified is None:
144 |             return {}
145 | 
146 |         now = time.time()
147 |         current_age = max(0, now - date)
148 |         delta = date - calendar.timegm(last_modified)
149 |         freshness_lifetime = max(0, min(delta / 10, 24 * 3600))
150 |         if freshness_lifetime <= current_age:
151 |             return {}
152 | 
153 |         expires = date + freshness_lifetime
154 |         return {"expires": time.strftime(TIME_FMT, time.gmtime(expires))}
155 | 
156 |     def warning(self, resp: HTTPResponse) -> str | None:
157 |         return None
```

.venv/lib/python3.13/site-packages/pip/_vendor/cachecontrol/py.typed
```
```

.venv/lib/python3.13/site-packages/pip/_vendor/cachecontrol/serialize.py
```
1 | # SPDX-FileCopyrightText: 2015 Eric Larson
2 | #
3 | # SPDX-License-Identifier: Apache-2.0
4 | from __future__ import annotations
5 | 
6 | import io
7 | from typing import IO, TYPE_CHECKING, Any, Mapping, cast
8 | 
9 | from pip._vendor import msgpack
10 | from pip._vendor.requests.structures import CaseInsensitiveDict
11 | from pip._vendor.urllib3 import HTTPResponse
12 | 
13 | if TYPE_CHECKING:
14 |     from pip._vendor.requests import PreparedRequest
15 | 
16 | 
17 | class Serializer:
18 |     serde_version = "4"
19 | 
20 |     def dumps(
21 |         self,
22 |         request: PreparedRequest,
23 |         response: HTTPResponse,
24 |         body: bytes | None = None,
25 |     ) -> bytes:
26 |         response_headers: CaseInsensitiveDict[str] = CaseInsensitiveDict(
27 |             response.headers
28 |         )
29 | 
30 |         if body is None:
31 |             # When a body isn't passed in, we'll read the response. We
32 |             # also update the response with a new file handler to be
33 |             # sure it acts as though it was never read.
34 |             body = response.read(decode_content=False)
35 |             response._fp = io.BytesIO(body)  # type: ignore[assignment]
36 |             response.length_remaining = len(body)
37 | 
38 |         data = {
39 |             "response": {
40 |                 "body": body,  # Empty bytestring if body is stored separately
41 |                 "headers": {str(k): str(v) for k, v in response.headers.items()},
42 |                 "status": response.status,
43 |                 "version": response.version,
44 |                 "reason": str(response.reason),
45 |                 "decode_content": response.decode_content,
46 |             }
47 |         }
48 | 
49 |         # Construct our vary headers
50 |         data["vary"] = {}
51 |         if "vary" in response_headers:
52 |             varied_headers = response_headers["vary"].split(",")
53 |             for header in varied_headers:
54 |                 header = str(header).strip()
55 |                 header_value = request.headers.get(header, None)
56 |                 if header_value is not None:
57 |                     header_value = str(header_value)
58 |                 data["vary"][header] = header_value
59 | 
60 |         return b",".join([f"cc={self.serde_version}".encode(), self.serialize(data)])
61 | 
62 |     def serialize(self, data: dict[str, Any]) -> bytes:
63 |         return cast(bytes, msgpack.dumps(data, use_bin_type=True))
64 | 
65 |     def loads(
66 |         self,
67 |         request: PreparedRequest,
68 |         data: bytes,
69 |         body_file: IO[bytes] | None = None,
70 |     ) -> HTTPResponse | None:
71 |         # Short circuit if we've been given an empty set of data
72 |         if not data:
73 |             return None
74 | 
75 |         # Previous versions of this library supported other serialization
76 |         # formats, but these have all been removed.
77 |         if not data.startswith(f"cc={self.serde_version},".encode()):
78 |             return None
79 | 
80 |         data = data[5:]
81 |         return self._loads_v4(request, data, body_file)
82 | 
83 |     def prepare_response(
84 |         self,
85 |         request: PreparedRequest,
86 |         cached: Mapping[str, Any],
87 |         body_file: IO[bytes] | None = None,
88 |     ) -> HTTPResponse | None:
89 |         """Verify our vary headers match and construct a real urllib3
90 |         HTTPResponse object.
91 |         """
92 |         # Special case the '*' Vary value as it means we cannot actually
93 |         # determine if the cached response is suitable for this request.
94 |         # This case is also handled in the controller code when creating
95 |         # a cache entry, but is left here for backwards compatibility.
96 |         if "*" in cached.get("vary", {}):
97 |             return None
98 | 
99 |         # Ensure that the Vary headers for the cached response match our
100 |         # request
101 |         for header, value in cached.get("vary", {}).items():
102 |             if request.headers.get(header, None) != value:
103 |                 return None
104 | 
105 |         body_raw = cached["response"].pop("body")
106 | 
107 |         headers: CaseInsensitiveDict[str] = CaseInsensitiveDict(
108 |             data=cached["response"]["headers"]
109 |         )
110 |         if headers.get("transfer-encoding", "") == "chunked":
111 |             headers.pop("transfer-encoding")
112 | 
113 |         cached["response"]["headers"] = headers
114 | 
115 |         try:
116 |             body: IO[bytes]
117 |             if body_file is None:
118 |                 body = io.BytesIO(body_raw)
119 |             else:
120 |                 body = body_file
121 |         except TypeError:
122 |             # This can happen if cachecontrol serialized to v1 format (pickle)
123 |             # using Python 2. A Python 2 str(byte string) will be unpickled as
124 |             # a Python 3 str (unicode string), which will cause the above to
125 |             # fail with:
126 |             #
127 |             #     TypeError: 'str' does not support the buffer interface
128 |             body = io.BytesIO(body_raw.encode("utf8"))
129 | 
130 |         # Discard any `strict` parameter serialized by older version of cachecontrol.
131 |         cached["response"].pop("strict", None)
132 | 
133 |         return HTTPResponse(body=body, preload_content=False, **cached["response"])
134 | 
135 |     def _loads_v4(
136 |         self,
137 |         request: PreparedRequest,
138 |         data: bytes,
139 |         body_file: IO[bytes] | None = None,
140 |     ) -> HTTPResponse | None:
141 |         try:
142 |             cached = msgpack.loads(data, raw=False)
143 |         except ValueError:
144 |             return None
145 | 
146 |         return self.prepare_response(request, cached, body_file)
```

.venv/lib/python3.13/site-packages/pip/_vendor/cachecontrol/wrapper.py
```
1 | # SPDX-FileCopyrightText: 2015 Eric Larson
2 | #
3 | # SPDX-License-Identifier: Apache-2.0
4 | from __future__ import annotations
5 | 
6 | from typing import TYPE_CHECKING, Collection
7 | 
8 | from pip._vendor.cachecontrol.adapter import CacheControlAdapter
9 | from pip._vendor.cachecontrol.cache import DictCache
10 | 
11 | if TYPE_CHECKING:
12 |     from pip._vendor import requests
13 | 
14 |     from pip._vendor.cachecontrol.cache import BaseCache
15 |     from pip._vendor.cachecontrol.controller import CacheController
16 |     from pip._vendor.cachecontrol.heuristics import BaseHeuristic
17 |     from pip._vendor.cachecontrol.serialize import Serializer
18 | 
19 | 
20 | def CacheControl(
21 |     sess: requests.Session,
22 |     cache: BaseCache | None = None,
23 |     cache_etags: bool = True,
24 |     serializer: Serializer | None = None,
25 |     heuristic: BaseHeuristic | None = None,
26 |     controller_class: type[CacheController] | None = None,
27 |     adapter_class: type[CacheControlAdapter] | None = None,
28 |     cacheable_methods: Collection[str] | None = None,
29 | ) -> requests.Session:
30 |     cache = DictCache() if cache is None else cache
31 |     adapter_class = adapter_class or CacheControlAdapter
32 |     adapter = adapter_class(
33 |         cache,
34 |         cache_etags=cache_etags,
35 |         serializer=serializer,
36 |         heuristic=heuristic,
37 |         controller_class=controller_class,
38 |         cacheable_methods=cacheable_methods,
39 |     )
40 |     sess.mount("http://", adapter)
41 |     sess.mount("https://", adapter)
42 | 
43 |     return sess
```

.venv/lib/python3.13/site-packages/pip/_internal/utils/__init__.py
```
```

.venv/lib/python3.13/site-packages/pip/_internal/utils/_jaraco_text.py
```
1 | """Functions brought over from jaraco.text.
2 | 
3 | These functions are not supposed to be used within `pip._internal`. These are
4 | helper functions brought over from `jaraco.text` to enable vendoring newer
5 | copies of `pkg_resources` without having to vendor `jaraco.text` and its entire
6 | dependency cone; something that our vendoring setup is not currently capable of
7 | handling.
8 | 
9 | License reproduced from original source below:
10 | 
11 | Copyright Jason R. Coombs
12 | 
13 | Permission is hereby granted, free of charge, to any person obtaining a copy
14 | of this software and associated documentation files (the "Software"), to
15 | deal in the Software without restriction, including without limitation the
16 | rights to use, copy, modify, merge, publish, distribute, sublicense, and/or
17 | sell copies of the Software, and to permit persons to whom the Software is
18 | furnished to do so, subject to the following conditions:
19 | 
20 | The above copyright notice and this permission notice shall be included in
21 | all copies or substantial portions of the Software.
22 | 
23 | THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
24 | IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
25 | FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
26 | AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
27 | LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
28 | FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS
29 | IN THE SOFTWARE.
30 | """
31 | 
32 | import functools
33 | import itertools
34 | 
35 | 
36 | def _nonblank(str):
37 |     return str and not str.startswith("#")
38 | 
39 | 
40 | @functools.singledispatch
41 | def yield_lines(iterable):
42 |     r"""
43 |     Yield valid lines of a string or iterable.
44 | 
45 |     >>> list(yield_lines(''))
46 |     []
47 |     >>> list(yield_lines(['foo', 'bar']))
48 |     ['foo', 'bar']
49 |     >>> list(yield_lines('foo\nbar'))
50 |     ['foo', 'bar']
51 |     >>> list(yield_lines('\nfoo\n#bar\nbaz #comment'))
52 |     ['foo', 'baz #comment']
53 |     >>> list(yield_lines(['foo\nbar', 'baz', 'bing\n\n\n']))
54 |     ['foo', 'bar', 'baz', 'bing']
55 |     """
56 |     return itertools.chain.from_iterable(map(yield_lines, iterable))
57 | 
58 | 
59 | @yield_lines.register(str)
60 | def _(text):
61 |     return filter(_nonblank, map(str.strip, text.splitlines()))
62 | 
63 | 
64 | def drop_comment(line):
65 |     """
66 |     Drop comments.
67 | 
68 |     >>> drop_comment('foo # bar')
69 |     'foo'
70 | 
71 |     A hash without a space may be in a URL.
72 | 
73 |     >>> drop_comment('http://example.com/foo#bar')
74 |     'http://example.com/foo#bar'
75 |     """
76 |     return line.partition(" #")[0]
77 | 
78 | 
79 | def join_continuation(lines):
80 |     r"""
81 |     Join lines continued by a trailing backslash.
82 | 
83 |     >>> list(join_continuation(['foo \\', 'bar', 'baz']))
84 |     ['foobar', 'baz']
85 |     >>> list(join_continuation(['foo \\', 'bar', 'baz']))
86 |     ['foobar', 'baz']
87 |     >>> list(join_continuation(['foo \\', 'bar \\', 'baz']))
88 |     ['foobarbaz']
89 | 
90 |     Not sure why, but...
91 |     The character preceding the backslash is also elided.
92 | 
93 |     >>> list(join_continuation(['goo\\', 'dly']))
94 |     ['godly']
95 | 
96 |     A terrible idea, but...
97 |     If no line is available to continue, suppress the lines.
98 | 
99 |     >>> list(join_continuation(['foo', 'bar\\', 'baz\\']))
100 |     ['foo']
101 |     """
102 |     lines = iter(lines)
103 |     for item in lines:
104 |         while item.endswith("\\"):
105 |             try:
106 |                 item = item[:-2].strip() + next(lines)
107 |             except StopIteration:
108 |                 return
109 |         yield item
```

.venv/lib/python3.13/site-packages/pip/_internal/utils/_log.py
```
1 | """Customize logging
2 | 
3 | Defines custom logger class for the `logger.verbose(...)` method.
4 | 
5 | init_logging() must be called before any other modules that call logging.getLogger.
6 | """
7 | 
8 | import logging
9 | from typing import Any, cast
10 | 
11 | # custom log level for `--verbose` output
12 | # between DEBUG and INFO
13 | VERBOSE = 15
14 | 
15 | 
16 | class VerboseLogger(logging.Logger):
17 |     """Custom Logger, defining a verbose log-level
18 | 
19 |     VERBOSE is between INFO and DEBUG.
20 |     """
21 | 
22 |     def verbose(self, msg: str, *args: Any, **kwargs: Any) -> None:
23 |         return self.log(VERBOSE, msg, *args, **kwargs)
24 | 
25 | 
26 | def getLogger(name: str) -> VerboseLogger:
27 |     """logging.getLogger, but ensures our VerboseLogger class is returned"""
28 |     return cast(VerboseLogger, logging.getLogger(name))
29 | 
30 | 
31 | def init_logging() -> None:
32 |     """Register our VerboseLogger and VERBOSE log level.
33 | 
34 |     Should be called before any calls to getLogger(),
35 |     i.e. in pip._internal.__init__
36 |     """
37 |     logging.setLoggerClass(VerboseLogger)
38 |     logging.addLevelName(VERBOSE, "VERBOSE")
```

.venv/lib/python3.13/site-packages/pip/_internal/utils/appdirs.py
```
1 | """
2 | This code wraps the vendored appdirs module to so the return values are
3 | compatible for the current pip code base.
4 | 
5 | The intention is to rewrite current usages gradually, keeping the tests pass,
6 | and eventually drop this after all usages are changed.
7 | """
8 | 
9 | import os
10 | import sys
11 | from typing import List
12 | 
13 | from pip._vendor import platformdirs as _appdirs
14 | 
15 | 
16 | def user_cache_dir(appname: str) -> str:
17 |     return _appdirs.user_cache_dir(appname, appauthor=False)
18 | 
19 | 
20 | def _macos_user_config_dir(appname: str, roaming: bool = True) -> str:
21 |     # Use ~/Application Support/pip, if the directory exists.
22 |     path = _appdirs.user_data_dir(appname, appauthor=False, roaming=roaming)
23 |     if os.path.isdir(path):
24 |         return path
25 | 
26 |     # Use a Linux-like ~/.config/pip, by default.
27 |     linux_like_path = "~/.config/"
28 |     if appname:
29 |         linux_like_path = os.path.join(linux_like_path, appname)
30 | 
31 |     return os.path.expanduser(linux_like_path)
32 | 
33 | 
34 | def user_config_dir(appname: str, roaming: bool = True) -> str:
35 |     if sys.platform == "darwin":
36 |         return _macos_user_config_dir(appname, roaming)
37 | 
38 |     return _appdirs.user_config_dir(appname, appauthor=False, roaming=roaming)
39 | 
40 | 
41 | # for the discussion regarding site_config_dir locations
42 | # see <https://github.com/pypa/pip/issues/1733>
43 | def site_config_dirs(appname: str) -> List[str]:
44 |     if sys.platform == "darwin":
45 |         dirval = _appdirs.site_data_dir(appname, appauthor=False, multipath=True)
46 |         return dirval.split(os.pathsep)
47 | 
48 |     dirval = _appdirs.site_config_dir(appname, appauthor=False, multipath=True)
49 |     if sys.platform == "win32":
50 |         return [dirval]
51 | 
52 |     # Unix-y system. Look in /etc as well.
53 |     return dirval.split(os.pathsep) + ["/etc"]
```

.venv/lib/python3.13/site-packages/pip/_internal/utils/compat.py
```
1 | """Stuff that differs in different Python versions and platform
2 | distributions."""
3 | 
4 | import importlib.resources
5 | import logging
6 | import os
7 | import sys
8 | from typing import IO
9 | 
10 | __all__ = ["get_path_uid", "stdlib_pkgs", "WINDOWS"]
11 | 
12 | 
13 | logger = logging.getLogger(__name__)
14 | 
15 | 
16 | def has_tls() -> bool:
17 |     try:
18 |         import _ssl  # noqa: F401  # ignore unused
19 | 
20 |         return True
21 |     except ImportError:
22 |         pass
23 | 
24 |     from pip._vendor.urllib3.util import IS_PYOPENSSL
25 | 
26 |     return IS_PYOPENSSL
27 | 
28 | 
29 | def get_path_uid(path: str) -> int:
30 |     """
31 |     Return path's uid.
32 | 
33 |     Does not follow symlinks:
34 |         https://github.com/pypa/pip/pull/935#discussion_r5307003
35 | 
36 |     Placed this function in compat due to differences on AIX and
37 |     Jython, that should eventually go away.
38 | 
39 |     :raises OSError: When path is a symlink or can't be read.
40 |     """
41 |     if hasattr(os, "O_NOFOLLOW"):
42 |         fd = os.open(path, os.O_RDONLY | os.O_NOFOLLOW)
43 |         file_uid = os.fstat(fd).st_uid
44 |         os.close(fd)
45 |     else:  # AIX and Jython
46 |         # WARNING: time of check vulnerability, but best we can do w/o NOFOLLOW
47 |         if not os.path.islink(path):
48 |             # older versions of Jython don't have `os.fstat`
49 |             file_uid = os.stat(path).st_uid
50 |         else:
51 |             # raise OSError for parity with os.O_NOFOLLOW above
52 |             raise OSError(f"{path} is a symlink; Will not return uid for symlinks")
53 |     return file_uid
54 | 
55 | 
56 | # The importlib.resources.open_text function was deprecated in 3.11 with suggested
57 | # replacement we use below.
58 | if sys.version_info < (3, 11):
59 |     open_text_resource = importlib.resources.open_text
60 | else:
61 | 
62 |     def open_text_resource(
63 |         package: str, resource: str, encoding: str = "utf-8", errors: str = "strict"
64 |     ) -> IO[str]:
65 |         return (importlib.resources.files(package) / resource).open(
66 |             "r", encoding=encoding, errors=errors
67 |         )
68 | 
69 | 
70 | # packages in the stdlib that may have installation metadata, but should not be
71 | # considered 'installed'.  this theoretically could be determined based on
72 | # dist.location (py27:`sysconfig.get_paths()['stdlib']`,
73 | # py26:sysconfig.get_config_vars('LIBDEST')), but fear platform variation may
74 | # make this ineffective, so hard-coding
75 | stdlib_pkgs = {"python", "wsgiref", "argparse"}
76 | 
77 | 
78 | # windows detection, covers cpython and ironpython
79 | WINDOWS = sys.platform.startswith("win") or (sys.platform == "cli" and os.name == "nt")
```

.venv/lib/python3.13/site-packages/pip/_internal/utils/compatibility_tags.py
```
1 | """Generate and work with PEP 425 Compatibility Tags."""
2 | 
3 | import re
4 | from typing import List, Optional, Tuple
5 | 
6 | from pip._vendor.packaging.tags import (
7 |     PythonVersion,
8 |     Tag,
9 |     android_platforms,
10 |     compatible_tags,
11 |     cpython_tags,
12 |     generic_tags,
13 |     interpreter_name,
14 |     interpreter_version,
15 |     ios_platforms,
16 |     mac_platforms,
17 | )
18 | 
19 | _apple_arch_pat = re.compile(r"(.+)_(\d+)_(\d+)_(.+)")
20 | 
21 | 
22 | def version_info_to_nodot(version_info: Tuple[int, ...]) -> str:
23 |     # Only use up to the first two numbers.
24 |     return "".join(map(str, version_info[:2]))
25 | 
26 | 
27 | def _mac_platforms(arch: str) -> List[str]:
28 |     match = _apple_arch_pat.match(arch)
29 |     if match:
30 |         name, major, minor, actual_arch = match.groups()
31 |         mac_version = (int(major), int(minor))
32 |         arches = [
33 |             # Since we have always only checked that the platform starts
34 |             # with "macosx", for backwards-compatibility we extract the
35 |             # actual prefix provided by the user in case they provided
36 |             # something like "macosxcustom_". It may be good to remove
37 |             # this as undocumented or deprecate it in the future.
38 |             "{}_{}".format(name, arch[len("macosx_") :])
39 |             for arch in mac_platforms(mac_version, actual_arch)
40 |         ]
41 |     else:
42 |         # arch pattern didn't match (?!)
43 |         arches = [arch]
44 |     return arches
45 | 
46 | 
47 | def _ios_platforms(arch: str) -> List[str]:
48 |     match = _apple_arch_pat.match(arch)
49 |     if match:
50 |         name, major, minor, actual_multiarch = match.groups()
51 |         ios_version = (int(major), int(minor))
52 |         arches = [
53 |             # Since we have always only checked that the platform starts
54 |             # with "ios", for backwards-compatibility we extract the
55 |             # actual prefix provided by the user in case they provided
56 |             # something like "ioscustom_". It may be good to remove
57 |             # this as undocumented or deprecate it in the future.
58 |             "{}_{}".format(name, arch[len("ios_") :])
59 |             for arch in ios_platforms(ios_version, actual_multiarch)
60 |         ]
61 |     else:
62 |         # arch pattern didn't match (?!)
63 |         arches = [arch]
64 |     return arches
65 | 
66 | 
67 | def _android_platforms(arch: str) -> List[str]:
68 |     match = re.fullmatch(r"android_(\d+)_(.+)", arch)
69 |     if match:
70 |         api_level, abi = match.groups()
71 |         return list(android_platforms(int(api_level), abi))
72 |     else:
73 |         # arch pattern didn't match (?!)
74 |         return [arch]
75 | 
76 | 
77 | def _custom_manylinux_platforms(arch: str) -> List[str]:
78 |     arches = [arch]
79 |     arch_prefix, arch_sep, arch_suffix = arch.partition("_")
80 |     if arch_prefix == "manylinux2014":
81 |         # manylinux1/manylinux2010 wheels run on most manylinux2014 systems
82 |         # with the exception of wheels depending on ncurses. PEP 599 states
83 |         # manylinux1/manylinux2010 wheels should be considered
84 |         # manylinux2014 wheels:
85 |         # https://www.python.org/dev/peps/pep-0599/#backwards-compatibility-with-manylinux2010-wheels
86 |         if arch_suffix in {"i686", "x86_64"}:
87 |             arches.append("manylinux2010" + arch_sep + arch_suffix)
88 |             arches.append("manylinux1" + arch_sep + arch_suffix)
89 |     elif arch_prefix == "manylinux2010":
90 |         # manylinux1 wheels run on most manylinux2010 systems with the
91 |         # exception of wheels depending on ncurses. PEP 571 states
92 |         # manylinux1 wheels should be considered manylinux2010 wheels:
93 |         # https://www.python.org/dev/peps/pep-0571/#backwards-compatibility-with-manylinux1-wheels
94 |         arches.append("manylinux1" + arch_sep + arch_suffix)
95 |     return arches
96 | 
97 | 
98 | def _get_custom_platforms(arch: str) -> List[str]:
99 |     arch_prefix, arch_sep, arch_suffix = arch.partition("_")
100 |     if arch.startswith("macosx"):
101 |         arches = _mac_platforms(arch)
102 |     elif arch.startswith("ios"):
103 |         arches = _ios_platforms(arch)
104 |     elif arch_prefix == "android":
105 |         arches = _android_platforms(arch)
106 |     elif arch_prefix in ["manylinux2014", "manylinux2010"]:
107 |         arches = _custom_manylinux_platforms(arch)
108 |     else:
109 |         arches = [arch]
110 |     return arches
111 | 
112 | 
113 | def _expand_allowed_platforms(platforms: Optional[List[str]]) -> Optional[List[str]]:
114 |     if not platforms:
115 |         return None
116 | 
117 |     seen = set()
118 |     result = []
119 | 
120 |     for p in platforms:
121 |         if p in seen:
122 |             continue
123 |         additions = [c for c in _get_custom_platforms(p) if c not in seen]
124 |         seen.update(additions)
125 |         result.extend(additions)
126 | 
127 |     return result
128 | 
129 | 
130 | def _get_python_version(version: str) -> PythonVersion:
131 |     if len(version) > 1:
132 |         return int(version[0]), int(version[1:])
133 |     else:
134 |         return (int(version[0]),)
135 | 
136 | 
137 | def _get_custom_interpreter(
138 |     implementation: Optional[str] = None, version: Optional[str] = None
139 | ) -> str:
140 |     if implementation is None:
141 |         implementation = interpreter_name()
142 |     if version is None:
143 |         version = interpreter_version()
144 |     return f"{implementation}{version}"
145 | 
146 | 
147 | def get_supported(
148 |     version: Optional[str] = None,
149 |     platforms: Optional[List[str]] = None,
150 |     impl: Optional[str] = None,
151 |     abis: Optional[List[str]] = None,
152 | ) -> List[Tag]:
153 |     """Return a list of supported tags for each version specified in
154 |     `versions`.
155 | 
156 |     :param version: a string version, of the form "33" or "32",
157 |         or None. The version will be assumed to support our ABI.
158 |     :param platform: specify a list of platforms you want valid
159 |         tags for, or None. If None, use the local system platform.
160 |     :param impl: specify the exact implementation you want valid
161 |         tags for, or None. If None, use the local interpreter impl.
162 |     :param abis: specify a list of abis you want valid
163 |         tags for, or None. If None, use the local interpreter abi.
164 |     """
165 |     supported: List[Tag] = []
166 | 
167 |     python_version: Optional[PythonVersion] = None
168 |     if version is not None:
169 |         python_version = _get_python_version(version)
170 | 
171 |     interpreter = _get_custom_interpreter(impl, version)
172 | 
173 |     platforms = _expand_allowed_platforms(platforms)
174 | 
175 |     is_cpython = (impl or interpreter_name()) == "cp"
176 |     if is_cpython:
177 |         supported.extend(
178 |             cpython_tags(
179 |                 python_version=python_version,
180 |                 abis=abis,
181 |                 platforms=platforms,
182 |             )
183 |         )
184 |     else:
185 |         supported.extend(
186 |             generic_tags(
187 |                 interpreter=interpreter,
188 |                 abis=abis,
189 |                 platforms=platforms,
190 |             )
191 |         )
192 |     supported.extend(
193 |         compatible_tags(
194 |             python_version=python_version,
195 |             interpreter=interpreter,
196 |             platforms=platforms,
197 |         )
198 |     )
199 | 
200 |     return supported
```

.venv/lib/python3.13/site-packages/pip/_internal/utils/datetime.py
```
1 | """For when pip wants to check the date or time."""
2 | 
3 | import datetime
4 | 
5 | 
6 | def today_is_later_than(year: int, month: int, day: int) -> bool:
7 |     today = datetime.date.today()
8 |     given = datetime.date(year, month, day)
9 | 
10 |     return today > given
```

.venv/lib/python3.13/site-packages/pip/_internal/utils/deprecation.py
```
1 | """
2 | A module that implements tooling to enable easy warnings about deprecations.
3 | """
4 | 
5 | import logging
6 | import warnings
7 | from typing import Any, Optional, TextIO, Type, Union
8 | 
9 | from pip._vendor.packaging.version import parse
10 | 
11 | from pip import __version__ as current_version  # NOTE: tests patch this name.
12 | 
13 | DEPRECATION_MSG_PREFIX = "DEPRECATION: "
14 | 
15 | 
16 | class PipDeprecationWarning(Warning):
17 |     pass
18 | 
19 | 
20 | _original_showwarning: Any = None
21 | 
22 | 
23 | # Warnings <-> Logging Integration
24 | def _showwarning(
25 |     message: Union[Warning, str],
26 |     category: Type[Warning],
27 |     filename: str,
28 |     lineno: int,
29 |     file: Optional[TextIO] = None,
30 |     line: Optional[str] = None,
31 | ) -> None:
32 |     if file is not None:
33 |         if _original_showwarning is not None:
34 |             _original_showwarning(message, category, filename, lineno, file, line)
35 |     elif issubclass(category, PipDeprecationWarning):
36 |         # We use a specially named logger which will handle all of the
37 |         # deprecation messages for pip.
38 |         logger = logging.getLogger("pip._internal.deprecations")
39 |         logger.warning(message)
40 |     else:
41 |         _original_showwarning(message, category, filename, lineno, file, line)
42 | 
43 | 
44 | def install_warning_logger() -> None:
45 |     # Enable our Deprecation Warnings
46 |     warnings.simplefilter("default", PipDeprecationWarning, append=True)
47 | 
48 |     global _original_showwarning
49 | 
50 |     if _original_showwarning is None:
51 |         _original_showwarning = warnings.showwarning
52 |         warnings.showwarning = _showwarning
53 | 
54 | 
55 | def deprecated(
56 |     *,
57 |     reason: str,
58 |     replacement: Optional[str],
59 |     gone_in: Optional[str],
60 |     feature_flag: Optional[str] = None,
61 |     issue: Optional[int] = None,
62 | ) -> None:
63 |     """Helper to deprecate existing functionality.
64 | 
65 |     reason:
66 |         Textual reason shown to the user about why this functionality has
67 |         been deprecated. Should be a complete sentence.
68 |     replacement:
69 |         Textual suggestion shown to the user about what alternative
70 |         functionality they can use.
71 |     gone_in:
72 |         The version of pip does this functionality should get removed in.
73 |         Raises an error if pip's current version is greater than or equal to
74 |         this.
75 |     feature_flag:
76 |         Command-line flag of the form --use-feature={feature_flag} for testing
77 |         upcoming functionality.
78 |     issue:
79 |         Issue number on the tracker that would serve as a useful place for
80 |         users to find related discussion and provide feedback.
81 |     """
82 | 
83 |     # Determine whether or not the feature is already gone in this version.
84 |     is_gone = gone_in is not None and parse(current_version) >= parse(gone_in)
85 | 
86 |     message_parts = [
87 |         (reason, f"{DEPRECATION_MSG_PREFIX}{{}}"),
88 |         (
89 |             gone_in,
90 |             (
91 |                 "pip {} will enforce this behaviour change."
92 |                 if not is_gone
93 |                 else "Since pip {}, this is no longer supported."
94 |             ),
95 |         ),
96 |         (
97 |             replacement,
98 |             "A possible replacement is {}.",
99 |         ),
100 |         (
101 |             feature_flag,
102 |             (
103 |                 "You can use the flag --use-feature={} to test the upcoming behaviour."
104 |                 if not is_gone
105 |                 else None
106 |             ),
107 |         ),
108 |         (
109 |             issue,
110 |             "Discussion can be found at https://github.com/pypa/pip/issues/{}",
111 |         ),
112 |     ]
113 | 
114 |     message = " ".join(
115 |         format_str.format(value)
116 |         for value, format_str in message_parts
117 |         if format_str is not None and value is not None
118 |     )
119 | 
120 |     # Raise as an error if this behaviour is deprecated.
121 |     if is_gone:
122 |         raise PipDeprecationWarning(message)
123 | 
124 |     warnings.warn(message, category=PipDeprecationWarning, stacklevel=2)
```

.venv/lib/python3.13/site-packages/pip/_internal/utils/direct_url_helpers.py
```
1 | from typing import Optional
2 | 
3 | from pip._internal.models.direct_url import ArchiveInfo, DirectUrl, DirInfo, VcsInfo
4 | from pip._internal.models.link import Link
5 | from pip._internal.utils.urls import path_to_url
6 | from pip._internal.vcs import vcs
7 | 
8 | 
9 | def direct_url_as_pep440_direct_reference(direct_url: DirectUrl, name: str) -> str:
10 |     """Convert a DirectUrl to a pip requirement string."""
11 |     direct_url.validate()  # if invalid, this is a pip bug
12 |     requirement = name + " @ "
13 |     fragments = []
14 |     if isinstance(direct_url.info, VcsInfo):
15 |         requirement += (
16 |             f"{direct_url.info.vcs}+{direct_url.url}@{direct_url.info.commit_id}"
17 |         )
18 |     elif isinstance(direct_url.info, ArchiveInfo):
19 |         requirement += direct_url.url
20 |         if direct_url.info.hash:
21 |             fragments.append(direct_url.info.hash)
22 |     else:
23 |         assert isinstance(direct_url.info, DirInfo)
24 |         requirement += direct_url.url
25 |     if direct_url.subdirectory:
26 |         fragments.append("subdirectory=" + direct_url.subdirectory)
27 |     if fragments:
28 |         requirement += "#" + "&".join(fragments)
29 |     return requirement
30 | 
31 | 
32 | def direct_url_for_editable(source_dir: str) -> DirectUrl:
33 |     return DirectUrl(
34 |         url=path_to_url(source_dir),
35 |         info=DirInfo(editable=True),
36 |     )
37 | 
38 | 
39 | def direct_url_from_link(
40 |     link: Link, source_dir: Optional[str] = None, link_is_in_wheel_cache: bool = False
41 | ) -> DirectUrl:
42 |     if link.is_vcs:
43 |         vcs_backend = vcs.get_backend_for_scheme(link.scheme)
44 |         assert vcs_backend
45 |         url, requested_revision, _ = vcs_backend.get_url_rev_and_auth(
46 |             link.url_without_fragment
47 |         )
48 |         # For VCS links, we need to find out and add commit_id.
49 |         if link_is_in_wheel_cache:
50 |             # If the requested VCS link corresponds to a cached
51 |             # wheel, it means the requested revision was an
52 |             # immutable commit hash, otherwise it would not have
53 |             # been cached. In that case we don't have a source_dir
54 |             # with the VCS checkout.
55 |             assert requested_revision
56 |             commit_id = requested_revision
57 |         else:
58 |             # If the wheel was not in cache, it means we have
59 |             # had to checkout from VCS to build and we have a source_dir
60 |             # which we can inspect to find out the commit id.
61 |             assert source_dir
62 |             commit_id = vcs_backend.get_revision(source_dir)
63 |         return DirectUrl(
64 |             url=url,
65 |             info=VcsInfo(
66 |                 vcs=vcs_backend.name,
67 |                 commit_id=commit_id,
68 |                 requested_revision=requested_revision,
69 |             ),
70 |             subdirectory=link.subdirectory_fragment,
71 |         )
72 |     elif link.is_existing_dir():
73 |         return DirectUrl(
74 |             url=link.url_without_fragment,
75 |             info=DirInfo(),
76 |             subdirectory=link.subdirectory_fragment,
77 |         )
78 |     else:
79 |         hash = None
80 |         hash_name = link.hash_name
81 |         if hash_name:
82 |             hash = f"{hash_name}={link.hash}"
83 |         return DirectUrl(
84 |             url=link.url_without_fragment,
85 |             info=ArchiveInfo(hash=hash),
86 |             subdirectory=link.subdirectory_fragment,
87 |         )
```

.venv/lib/python3.13/site-packages/pip/_internal/utils/egg_link.py
```
1 | import os
2 | import re
3 | import sys
4 | from typing import List, Optional
5 | 
6 | from pip._internal.locations import site_packages, user_site
7 | from pip._internal.utils.virtualenv import (
8 |     running_under_virtualenv,
9 |     virtualenv_no_global,
10 | )
11 | 
12 | __all__ = [
13 |     "egg_link_path_from_sys_path",
14 |     "egg_link_path_from_location",
15 | ]
16 | 
17 | 
18 | def _egg_link_names(raw_name: str) -> List[str]:
19 |     """
20 |     Convert a Name metadata value to a .egg-link name, by applying
21 |     the same substitution as pkg_resources's safe_name function.
22 |     Note: we cannot use canonicalize_name because it has a different logic.
23 | 
24 |     We also look for the raw name (without normalization) as setuptools 69 changed
25 |     the way it names .egg-link files (https://github.com/pypa/setuptools/issues/4167).
26 |     """
27 |     return [
28 |         re.sub("[^A-Za-z0-9.]+", "-", raw_name) + ".egg-link",
29 |         f"{raw_name}.egg-link",
30 |     ]
31 | 
32 | 
33 | def egg_link_path_from_sys_path(raw_name: str) -> Optional[str]:
34 |     """
35 |     Look for a .egg-link file for project name, by walking sys.path.
36 |     """
37 |     egg_link_names = _egg_link_names(raw_name)
38 |     for path_item in sys.path:
39 |         for egg_link_name in egg_link_names:
40 |             egg_link = os.path.join(path_item, egg_link_name)
41 |             if os.path.isfile(egg_link):
42 |                 return egg_link
43 |     return None
44 | 
45 | 
46 | def egg_link_path_from_location(raw_name: str) -> Optional[str]:
47 |     """
48 |     Return the path for the .egg-link file if it exists, otherwise, None.
49 | 
50 |     There's 3 scenarios:
51 |     1) not in a virtualenv
52 |        try to find in site.USER_SITE, then site_packages
53 |     2) in a no-global virtualenv
54 |        try to find in site_packages
55 |     3) in a yes-global virtualenv
56 |        try to find in site_packages, then site.USER_SITE
57 |        (don't look in global location)
58 | 
59 |     For #1 and #3, there could be odd cases, where there's an egg-link in 2
60 |     locations.
61 | 
62 |     This method will just return the first one found.
63 |     """
64 |     sites: List[str] = []
65 |     if running_under_virtualenv():
66 |         sites.append(site_packages)
67 |         if not virtualenv_no_global() and user_site:
68 |             sites.append(user_site)
69 |     else:
70 |         if user_site:
71 |             sites.append(user_site)
72 |         sites.append(site_packages)
73 | 
74 |     egg_link_names = _egg_link_names(raw_name)
75 |     for site in sites:
76 |         for egg_link_name in egg_link_names:
77 |             egglink = os.path.join(site, egg_link_name)
78 |             if os.path.isfile(egglink):
79 |                 return egglink
80 |     return None
```

.venv/lib/python3.13/site-packages/pip/_internal/utils/entrypoints.py
```
1 | import itertools
2 | import os
3 | import shutil
4 | import sys
5 | from typing import List, Optional
6 | 
7 | from pip._internal.cli.main import main
8 | from pip._internal.utils.compat import WINDOWS
9 | 
10 | _EXECUTABLE_NAMES = [
11 |     "pip",
12 |     f"pip{sys.version_info.major}",
13 |     f"pip{sys.version_info.major}.{sys.version_info.minor}",
14 | ]
15 | if WINDOWS:
16 |     _allowed_extensions = {"", ".exe"}
17 |     _EXECUTABLE_NAMES = [
18 |         "".join(parts)
19 |         for parts in itertools.product(_EXECUTABLE_NAMES, _allowed_extensions)
20 |     ]
21 | 
22 | 
23 | def _wrapper(args: Optional[List[str]] = None) -> int:
24 |     """Central wrapper for all old entrypoints.
25 | 
26 |     Historically pip has had several entrypoints defined. Because of issues
27 |     arising from PATH, sys.path, multiple Pythons, their interactions, and most
28 |     of them having a pip installed, users suffer every time an entrypoint gets
29 |     moved.
30 | 
31 |     To alleviate this pain, and provide a mechanism for warning users and
32 |     directing them to an appropriate place for help, we now define all of
33 |     our old entrypoints as wrappers for the current one.
34 |     """
35 |     sys.stderr.write(
36 |         "WARNING: pip is being invoked by an old script wrapper. This will "
37 |         "fail in a future version of pip.\n"
38 |         "Please see https://github.com/pypa/pip/issues/5599 for advice on "
39 |         "fixing the underlying issue.\n"
40 |         "To avoid this problem you can invoke Python with '-m pip' instead of "
41 |         "running pip directly.\n"
42 |     )
43 |     return main(args)
44 | 
45 | 
46 | def get_best_invocation_for_this_pip() -> str:
47 |     """Try to figure out the best way to invoke pip in the current environment."""
48 |     binary_directory = "Scripts" if WINDOWS else "bin"
49 |     binary_prefix = os.path.join(sys.prefix, binary_directory)
50 | 
51 |     # Try to use pip[X[.Y]] names, if those executables for this environment are
52 |     # the first on PATH with that name.
53 |     path_parts = os.path.normcase(os.environ.get("PATH", "")).split(os.pathsep)
54 |     exe_are_in_PATH = os.path.normcase(binary_prefix) in path_parts
55 |     if exe_are_in_PATH:
56 |         for exe_name in _EXECUTABLE_NAMES:
57 |             found_executable = shutil.which(exe_name)
58 |             binary_executable = os.path.join(binary_prefix, exe_name)
59 |             if (
60 |                 found_executable
61 |                 and os.path.exists(binary_executable)
62 |                 and os.path.samefile(
63 |                     found_executable,
64 |                     binary_executable,
65 |                 )
66 |             ):
67 |                 return exe_name
68 | 
69 |     # Use the `-m` invocation, if there's no "nice" invocation.
70 |     return f"{get_best_invocation_for_this_python()} -m pip"
71 | 
72 | 
73 | def get_best_invocation_for_this_python() -> str:
74 |     """Try to figure out the best way to invoke the current Python."""
75 |     exe = sys.executable
76 |     exe_name = os.path.basename(exe)
77 | 
78 |     # Try to use the basename, if it's the first executable.
79 |     found_executable = shutil.which(exe_name)
80 |     # Virtual environments often symlink to their parent Python binaries, but we don't
81 |     # want to treat the Python binaries as equivalent when the environment's Python is
82 |     # not on PATH (not activated). Thus, we don't follow symlinks.
83 |     if found_executable and os.path.samestat(os.lstat(found_executable), os.lstat(exe)):
84 |         return exe_name
85 | 
86 |     # Use the full executable name, because we couldn't find something simpler.
87 |     return exe
```

.venv/lib/python3.13/site-packages/pip/_internal/utils/filesystem.py
```
1 | import fnmatch
2 | import os
3 | import os.path
4 | import random
5 | import sys
6 | from contextlib import contextmanager
7 | from tempfile import NamedTemporaryFile
8 | from typing import Any, BinaryIO, Generator, List, Union, cast
9 | 
10 | from pip._internal.utils.compat import get_path_uid
11 | from pip._internal.utils.misc import format_size
12 | from pip._internal.utils.retry import retry
13 | 
14 | 
15 | def check_path_owner(path: str) -> bool:
16 |     # If we don't have a way to check the effective uid of this process, then
17 |     # we'll just assume that we own the directory.
18 |     if sys.platform == "win32" or not hasattr(os, "geteuid"):
19 |         return True
20 | 
21 |     assert os.path.isabs(path)
22 | 
23 |     previous = None
24 |     while path != previous:
25 |         if os.path.lexists(path):
26 |             # Check if path is writable by current user.
27 |             if os.geteuid() == 0:
28 |                 # Special handling for root user in order to handle properly
29 |                 # cases where users use sudo without -H flag.
30 |                 try:
31 |                     path_uid = get_path_uid(path)
32 |                 except OSError:
33 |                     return False
34 |                 return path_uid == 0
35 |             else:
36 |                 return os.access(path, os.W_OK)
37 |         else:
38 |             previous, path = path, os.path.dirname(path)
39 |     return False  # assume we don't own the path
40 | 
41 | 
42 | @contextmanager
43 | def adjacent_tmp_file(path: str, **kwargs: Any) -> Generator[BinaryIO, None, None]:
44 |     """Return a file-like object pointing to a tmp file next to path.
45 | 
46 |     The file is created securely and is ensured to be written to disk
47 |     after the context reaches its end.
48 | 
49 |     kwargs will be passed to tempfile.NamedTemporaryFile to control
50 |     the way the temporary file will be opened.
51 |     """
52 |     with NamedTemporaryFile(
53 |         delete=False,
54 |         dir=os.path.dirname(path),
55 |         prefix=os.path.basename(path),
56 |         suffix=".tmp",
57 |         **kwargs,
58 |     ) as f:
59 |         result = cast(BinaryIO, f)
60 |         try:
61 |             yield result
62 |         finally:
63 |             result.flush()
64 |             os.fsync(result.fileno())
65 | 
66 | 
67 | replace = retry(stop_after_delay=1, wait=0.25)(os.replace)
68 | 
69 | 
70 | # test_writable_dir and _test_writable_dir_win are copied from Flit,
71 | # with the author's agreement to also place them under pip's license.
72 | def test_writable_dir(path: str) -> bool:
73 |     """Check if a directory is writable.
74 | 
75 |     Uses os.access() on POSIX, tries creating files on Windows.
76 |     """
77 |     # If the directory doesn't exist, find the closest parent that does.
78 |     while not os.path.isdir(path):
79 |         parent = os.path.dirname(path)
80 |         if parent == path:
81 |             break  # Should never get here, but infinite loops are bad
82 |         path = parent
83 | 
84 |     if os.name == "posix":
85 |         return os.access(path, os.W_OK)
86 | 
87 |     return _test_writable_dir_win(path)
88 | 
89 | 
90 | def _test_writable_dir_win(path: str) -> bool:
91 |     # os.access doesn't work on Windows: http://bugs.python.org/issue2528
92 |     # and we can't use tempfile: http://bugs.python.org/issue22107
93 |     basename = "accesstest_deleteme_fishfingers_custard_"
94 |     alphabet = "abcdefghijklmnopqrstuvwxyz0123456789"
95 |     for _ in range(10):
96 |         name = basename + "".join(random.choice(alphabet) for _ in range(6))
97 |         file = os.path.join(path, name)
98 |         try:
99 |             fd = os.open(file, os.O_RDWR | os.O_CREAT | os.O_EXCL)
100 |         except FileExistsError:
101 |             pass
102 |         except PermissionError:
103 |             # This could be because there's a directory with the same name.
104 |             # But it's highly unlikely there's a directory called that,
105 |             # so we'll assume it's because the parent dir is not writable.
106 |             # This could as well be because the parent dir is not readable,
107 |             # due to non-privileged user access.
108 |             return False
109 |         else:
110 |             os.close(fd)
111 |             os.unlink(file)
112 |             return True
113 | 
114 |     # This should never be reached
115 |     raise OSError("Unexpected condition testing for writable directory")
116 | 
117 | 
118 | def find_files(path: str, pattern: str) -> List[str]:
119 |     """Returns a list of absolute paths of files beneath path, recursively,
120 |     with filenames which match the UNIX-style shell glob pattern."""
121 |     result: List[str] = []
122 |     for root, _, files in os.walk(path):
123 |         matches = fnmatch.filter(files, pattern)
124 |         result.extend(os.path.join(root, f) for f in matches)
125 |     return result
126 | 
127 | 
128 | def file_size(path: str) -> Union[int, float]:
129 |     # If it's a symlink, return 0.
130 |     if os.path.islink(path):
131 |         return 0
132 |     return os.path.getsize(path)
133 | 
134 | 
135 | def format_file_size(path: str) -> str:
136 |     return format_size(file_size(path))
137 | 
138 | 
139 | def directory_size(path: str) -> Union[int, float]:
140 |     size = 0.0
141 |     for root, _dirs, files in os.walk(path):
142 |         for filename in files:
143 |             file_path = os.path.join(root, filename)
144 |             size += file_size(file_path)
145 |     return size
146 | 
147 | 
148 | def format_directory_size(path: str) -> str:
149 |     return format_size(directory_size(path))
```

.venv/lib/python3.13/site-packages/pip/_internal/utils/filetypes.py
```
1 | """Filetype information."""
2 | 
3 | from typing import Tuple
4 | 
5 | from pip._internal.utils.misc import splitext
6 | 
7 | WHEEL_EXTENSION = ".whl"
8 | BZ2_EXTENSIONS: Tuple[str, ...] = (".tar.bz2", ".tbz")
9 | XZ_EXTENSIONS: Tuple[str, ...] = (
10 |     ".tar.xz",
11 |     ".txz",
12 |     ".tlz",
13 |     ".tar.lz",
14 |     ".tar.lzma",
15 | )
16 | ZIP_EXTENSIONS: Tuple[str, ...] = (".zip", WHEEL_EXTENSION)
17 | TAR_EXTENSIONS: Tuple[str, ...] = (".tar.gz", ".tgz", ".tar")
18 | ARCHIVE_EXTENSIONS = ZIP_EXTENSIONS + BZ2_EXTENSIONS + TAR_EXTENSIONS + XZ_EXTENSIONS
19 | 
20 | 
21 | def is_archive_file(name: str) -> bool:
22 |     """Return True if `name` is a considered as an archive file."""
23 |     ext = splitext(name)[1].lower()
24 |     if ext in ARCHIVE_EXTENSIONS:
25 |         return True
26 |     return False
```

.venv/lib/python3.13/site-packages/pip/_internal/utils/glibc.py
```
1 | import os
2 | import sys
3 | from typing import Optional, Tuple
4 | 
5 | 
6 | def glibc_version_string() -> Optional[str]:
7 |     "Returns glibc version string, or None if not using glibc."
8 |     return glibc_version_string_confstr() or glibc_version_string_ctypes()
9 | 
10 | 
11 | def glibc_version_string_confstr() -> Optional[str]:
12 |     "Primary implementation of glibc_version_string using os.confstr."
13 |     # os.confstr is quite a bit faster than ctypes.DLL. It's also less likely
14 |     # to be broken or missing. This strategy is used in the standard library
15 |     # platform module:
16 |     # https://github.com/python/cpython/blob/fcf1d003bf4f0100c9d0921ff3d70e1127ca1b71/Lib/platform.py#L175-L183
17 |     if sys.platform == "win32":
18 |         return None
19 |     try:
20 |         gnu_libc_version = os.confstr("CS_GNU_LIBC_VERSION")
21 |         if gnu_libc_version is None:
22 |             return None
23 |         # os.confstr("CS_GNU_LIBC_VERSION") returns a string like "glibc 2.17":
24 |         _, version = gnu_libc_version.split()
25 |     except (AttributeError, OSError, ValueError):
26 |         # os.confstr() or CS_GNU_LIBC_VERSION not available (or a bad value)...
27 |         return None
28 |     return version
29 | 
30 | 
31 | def glibc_version_string_ctypes() -> Optional[str]:
32 |     "Fallback implementation of glibc_version_string using ctypes."
33 | 
34 |     try:
35 |         import ctypes
36 |     except ImportError:
37 |         return None
38 | 
39 |     # ctypes.CDLL(None) internally calls dlopen(NULL), and as the dlopen
40 |     # manpage says, "If filename is NULL, then the returned handle is for the
41 |     # main program". This way we can let the linker do the work to figure out
42 |     # which libc our process is actually using.
43 |     #
44 |     # We must also handle the special case where the executable is not a
45 |     # dynamically linked executable. This can occur when using musl libc,
46 |     # for example. In this situation, dlopen() will error, leading to an
47 |     # OSError. Interestingly, at least in the case of musl, there is no
48 |     # errno set on the OSError. The single string argument used to construct
49 |     # OSError comes from libc itself and is therefore not portable to
50 |     # hard code here. In any case, failure to call dlopen() means we
51 |     # can't proceed, so we bail on our attempt.
52 |     try:
53 |         process_namespace = ctypes.CDLL(None)
54 |     except OSError:
55 |         return None
56 | 
57 |     try:
58 |         gnu_get_libc_version = process_namespace.gnu_get_libc_version
59 |     except AttributeError:
60 |         # Symbol doesn't exist -> therefore, we are not linked to
61 |         # glibc.
62 |         return None
63 | 
64 |     # Call gnu_get_libc_version, which returns a string like "2.5"
65 |     gnu_get_libc_version.restype = ctypes.c_char_p
66 |     version_str: str = gnu_get_libc_version()
67 |     # py2 / py3 compatibility:
68 |     if not isinstance(version_str, str):
69 |         version_str = version_str.decode("ascii")
70 | 
71 |     return version_str
72 | 
73 | 
74 | # platform.libc_ver regularly returns completely nonsensical glibc
75 | # versions. E.g. on my computer, platform says:
76 | #
77 | #   ~$ python2.7 -c 'import platform; print(platform.libc_ver())'
78 | #   ('glibc', '2.7')
79 | #   ~$ python3.5 -c 'import platform; print(platform.libc_ver())'
80 | #   ('glibc', '2.9')
81 | #
82 | # But the truth is:
83 | #
84 | #   ~$ ldd --version
85 | #   ldd (Debian GLIBC 2.22-11) 2.22
86 | #
87 | # This is unfortunate, because it means that the linehaul data on libc
88 | # versions that was generated by pip 8.1.2 and earlier is useless and
89 | # misleading. Solution: instead of using platform, use our code that actually
90 | # works.
91 | def libc_ver() -> Tuple[str, str]:
92 |     """Try to determine the glibc version
93 | 
94 |     Returns a tuple of strings (lib, version) which default to empty strings
95 |     in case the lookup fails.
96 |     """
97 |     glibc_version = glibc_version_string()
98 |     if glibc_version is None:
99 |         return ("", "")
100 |     else:
101 |         return ("glibc", glibc_version)
```

.venv/lib/python3.13/site-packages/pip/_internal/utils/hashes.py
```
1 | import hashlib
2 | from typing import TYPE_CHECKING, BinaryIO, Dict, Iterable, List, NoReturn, Optional
3 | 
4 | from pip._internal.exceptions import HashMismatch, HashMissing, InstallationError
5 | from pip._internal.utils.misc import read_chunks
6 | 
7 | if TYPE_CHECKING:
8 |     from hashlib import _Hash
9 | 
10 | 
11 | # The recommended hash algo of the moment. Change this whenever the state of
12 | # the art changes; it won't hurt backward compatibility.
13 | FAVORITE_HASH = "sha256"
14 | 
15 | 
16 | # Names of hashlib algorithms allowed by the --hash option and ``pip hash``
17 | # Currently, those are the ones at least as collision-resistant as sha256.
18 | STRONG_HASHES = ["sha256", "sha384", "sha512"]
19 | 
20 | 
21 | class Hashes:
22 |     """A wrapper that builds multiple hashes at once and checks them against
23 |     known-good values
24 | 
25 |     """
26 | 
27 |     def __init__(self, hashes: Optional[Dict[str, List[str]]] = None) -> None:
28 |         """
29 |         :param hashes: A dict of algorithm names pointing to lists of allowed
30 |             hex digests
31 |         """
32 |         allowed = {}
33 |         if hashes is not None:
34 |             for alg, keys in hashes.items():
35 |                 # Make sure values are always sorted (to ease equality checks)
36 |                 allowed[alg] = [k.lower() for k in sorted(keys)]
37 |         self._allowed = allowed
38 | 
39 |     def __and__(self, other: "Hashes") -> "Hashes":
40 |         if not isinstance(other, Hashes):
41 |             return NotImplemented
42 | 
43 |         # If either of the Hashes object is entirely empty (i.e. no hash
44 |         # specified at all), all hashes from the other object are allowed.
45 |         if not other:
46 |             return self
47 |         if not self:
48 |             return other
49 | 
50 |         # Otherwise only hashes that present in both objects are allowed.
51 |         new = {}
52 |         for alg, values in other._allowed.items():
53 |             if alg not in self._allowed:
54 |                 continue
55 |             new[alg] = [v for v in values if v in self._allowed[alg]]
56 |         return Hashes(new)
57 | 
58 |     @property
59 |     def digest_count(self) -> int:
60 |         return sum(len(digests) for digests in self._allowed.values())
61 | 
62 |     def is_hash_allowed(self, hash_name: str, hex_digest: str) -> bool:
63 |         """Return whether the given hex digest is allowed."""
64 |         return hex_digest in self._allowed.get(hash_name, [])
65 | 
66 |     def check_against_chunks(self, chunks: Iterable[bytes]) -> None:
67 |         """Check good hashes against ones built from iterable of chunks of
68 |         data.
69 | 
70 |         Raise HashMismatch if none match.
71 | 
72 |         """
73 |         gots = {}
74 |         for hash_name in self._allowed.keys():
75 |             try:
76 |                 gots[hash_name] = hashlib.new(hash_name)
77 |             except (ValueError, TypeError):
78 |                 raise InstallationError(f"Unknown hash name: {hash_name}")
79 | 
80 |         for chunk in chunks:
81 |             for hash in gots.values():
82 |                 hash.update(chunk)
83 | 
84 |         for hash_name, got in gots.items():
85 |             if got.hexdigest() in self._allowed[hash_name]:
86 |                 return
87 |         self._raise(gots)
88 | 
89 |     def _raise(self, gots: Dict[str, "_Hash"]) -> "NoReturn":
90 |         raise HashMismatch(self._allowed, gots)
91 | 
92 |     def check_against_file(self, file: BinaryIO) -> None:
93 |         """Check good hashes against a file-like object
94 | 
95 |         Raise HashMismatch if none match.
96 | 
97 |         """
98 |         return self.check_against_chunks(read_chunks(file))
99 | 
100 |     def check_against_path(self, path: str) -> None:
101 |         with open(path, "rb") as file:
102 |             return self.check_against_file(file)
103 | 
104 |     def has_one_of(self, hashes: Dict[str, str]) -> bool:
105 |         """Return whether any of the given hashes are allowed."""
106 |         for hash_name, hex_digest in hashes.items():
107 |             if self.is_hash_allowed(hash_name, hex_digest):
108 |                 return True
109 |         return False
110 | 
111 |     def __bool__(self) -> bool:
112 |         """Return whether I know any known-good hashes."""
113 |         return bool(self._allowed)
114 | 
115 |     def __eq__(self, other: object) -> bool:
116 |         if not isinstance(other, Hashes):
117 |             return NotImplemented
118 |         return self._allowed == other._allowed
119 | 
120 |     def __hash__(self) -> int:
121 |         return hash(
122 |             ",".join(
123 |                 sorted(
124 |                     ":".join((alg, digest))
125 |                     for alg, digest_list in self._allowed.items()
126 |                     for digest in digest_list
127 |                 )
128 |             )
129 |         )
130 | 
131 | 
132 | class MissingHashes(Hashes):
133 |     """A workalike for Hashes used when we're missing a hash for a requirement
134 | 
135 |     It computes the actual hash of the requirement and raises a HashMissing
136 |     exception showing it to the user.
137 | 
138 |     """
139 | 
140 |     def __init__(self) -> None:
141 |         """Don't offer the ``hashes`` kwarg."""
142 |         # Pass our favorite hash in to generate a "gotten hash". With the
143 |         # empty list, it will never match, so an error will always raise.
144 |         super().__init__(hashes={FAVORITE_HASH: []})
145 | 
146 |     def _raise(self, gots: Dict[str, "_Hash"]) -> "NoReturn":
147 |         raise HashMissing(gots[FAVORITE_HASH].hexdigest())
```

.venv/lib/python3.13/site-packages/pip/_internal/utils/logging.py
```
1 | import contextlib
2 | import errno
3 | import logging
4 | import logging.handlers
5 | import os
6 | import sys
7 | import threading
8 | from dataclasses import dataclass
9 | from io import TextIOWrapper
10 | from logging import Filter
11 | from typing import Any, ClassVar, Generator, List, Optional, Type
12 | 
13 | from pip._vendor.rich.console import (
14 |     Console,
15 |     ConsoleOptions,
16 |     ConsoleRenderable,
17 |     RenderableType,
18 |     RenderResult,
19 |     RichCast,
20 | )
21 | from pip._vendor.rich.highlighter import NullHighlighter
22 | from pip._vendor.rich.logging import RichHandler
23 | from pip._vendor.rich.segment import Segment
24 | from pip._vendor.rich.style import Style
25 | 
26 | from pip._internal.utils._log import VERBOSE, getLogger
27 | from pip._internal.utils.compat import WINDOWS
28 | from pip._internal.utils.deprecation import DEPRECATION_MSG_PREFIX
29 | from pip._internal.utils.misc import ensure_dir
30 | 
31 | _log_state = threading.local()
32 | _stdout_console = None
33 | _stderr_console = None
34 | subprocess_logger = getLogger("pip.subprocessor")
35 | 
36 | 
37 | class BrokenStdoutLoggingError(Exception):
38 |     """
39 |     Raised if BrokenPipeError occurs for the stdout stream while logging.
40 |     """
41 | 
42 | 
43 | def _is_broken_pipe_error(exc_class: Type[BaseException], exc: BaseException) -> bool:
44 |     if exc_class is BrokenPipeError:
45 |         return True
46 | 
47 |     # On Windows, a broken pipe can show up as EINVAL rather than EPIPE:
48 |     # https://bugs.python.org/issue19612
49 |     # https://bugs.python.org/issue30418
50 |     if not WINDOWS:
51 |         return False
52 | 
53 |     return isinstance(exc, OSError) and exc.errno in (errno.EINVAL, errno.EPIPE)
54 | 
55 | 
56 | @contextlib.contextmanager
57 | def indent_log(num: int = 2) -> Generator[None, None, None]:
58 |     """
59 |     A context manager which will cause the log output to be indented for any
60 |     log messages emitted inside it.
61 |     """
62 |     # For thread-safety
63 |     _log_state.indentation = get_indentation()
64 |     _log_state.indentation += num
65 |     try:
66 |         yield
67 |     finally:
68 |         _log_state.indentation -= num
69 | 
70 | 
71 | def get_indentation() -> int:
72 |     return getattr(_log_state, "indentation", 0)
73 | 
74 | 
75 | class IndentingFormatter(logging.Formatter):
76 |     default_time_format = "%Y-%m-%dT%H:%M:%S"
77 | 
78 |     def __init__(
79 |         self,
80 |         *args: Any,
81 |         add_timestamp: bool = False,
82 |         **kwargs: Any,
83 |     ) -> None:
84 |         """
85 |         A logging.Formatter that obeys the indent_log() context manager.
86 | 
87 |         :param add_timestamp: A bool indicating output lines should be prefixed
88 |             with their record's timestamp.
89 |         """
90 |         self.add_timestamp = add_timestamp
91 |         super().__init__(*args, **kwargs)
92 | 
93 |     def get_message_start(self, formatted: str, levelno: int) -> str:
94 |         """
95 |         Return the start of the formatted log message (not counting the
96 |         prefix to add to each line).
97 |         """
98 |         if levelno < logging.WARNING:
99 |             return ""
100 |         if formatted.startswith(DEPRECATION_MSG_PREFIX):
101 |             # Then the message already has a prefix.  We don't want it to
102 |             # look like "WARNING: DEPRECATION: ...."
103 |             return ""
104 |         if levelno < logging.ERROR:
105 |             return "WARNING: "
106 | 
107 |         return "ERROR: "
108 | 
109 |     def format(self, record: logging.LogRecord) -> str:
110 |         """
111 |         Calls the standard formatter, but will indent all of the log message
112 |         lines by our current indentation level.
113 |         """
114 |         formatted = super().format(record)
115 |         message_start = self.get_message_start(formatted, record.levelno)
116 |         formatted = message_start + formatted
117 | 
118 |         prefix = ""
119 |         if self.add_timestamp:
120 |             prefix = f"{self.formatTime(record)} "
121 |         prefix += " " * get_indentation()
122 |         formatted = "".join([prefix + line for line in formatted.splitlines(True)])
123 |         return formatted
124 | 
125 | 
126 | @dataclass
127 | class IndentedRenderable:
128 |     renderable: RenderableType
129 |     indent: int
130 | 
131 |     def __rich_console__(
132 |         self, console: Console, options: ConsoleOptions
133 |     ) -> RenderResult:
134 |         segments = console.render(self.renderable, options)
135 |         lines = Segment.split_lines(segments)
136 |         for line in lines:
137 |             yield Segment(" " * self.indent)
138 |             yield from line
139 |             yield Segment("\n")
140 | 
141 | 
142 | class PipConsole(Console):
143 |     def on_broken_pipe(self) -> None:
144 |         # Reraise the original exception, rich 13.8.0+ exits by default
145 |         # instead, preventing our handler from firing.
146 |         raise BrokenPipeError() from None
147 | 
148 | 
149 | def get_console(*, stderr: bool = False) -> Console:
150 |     if stderr:
151 |         assert _stderr_console is not None, "stderr rich console is missing!"
152 |         return _stderr_console
153 |     else:
154 |         assert _stdout_console is not None, "stdout rich console is missing!"
155 |         return _stdout_console
156 | 
157 | 
158 | class RichPipStreamHandler(RichHandler):
159 |     KEYWORDS: ClassVar[Optional[List[str]]] = []
160 | 
161 |     def __init__(self, console: Console) -> None:
162 |         super().__init__(
163 |             console=console,
164 |             show_time=False,
165 |             show_level=False,
166 |             show_path=False,
167 |             highlighter=NullHighlighter(),
168 |         )
169 | 
170 |     # Our custom override on Rich's logger, to make things work as we need them to.
171 |     def emit(self, record: logging.LogRecord) -> None:
172 |         style: Optional[Style] = None
173 | 
174 |         # If we are given a diagnostic error to present, present it with indentation.
175 |         if getattr(record, "rich", False):
176 |             assert isinstance(record.args, tuple)
177 |             (rich_renderable,) = record.args
178 |             assert isinstance(
179 |                 rich_renderable, (ConsoleRenderable, RichCast, str)
180 |             ), f"{rich_renderable} is not rich-console-renderable"
181 | 
182 |             renderable: RenderableType = IndentedRenderable(
183 |                 rich_renderable, indent=get_indentation()
184 |             )
185 |         else:
186 |             message = self.format(record)
187 |             renderable = self.render_message(record, message)
188 |             if record.levelno is not None:
189 |                 if record.levelno >= logging.ERROR:
190 |                     style = Style(color="red")
191 |                 elif record.levelno >= logging.WARNING:
192 |                     style = Style(color="yellow")
193 | 
194 |         try:
195 |             self.console.print(renderable, overflow="ignore", crop=False, style=style)
196 |         except Exception:
197 |             self.handleError(record)
198 | 
199 |     def handleError(self, record: logging.LogRecord) -> None:
200 |         """Called when logging is unable to log some output."""
201 | 
202 |         exc_class, exc = sys.exc_info()[:2]
203 |         # If a broken pipe occurred while calling write() or flush() on the
204 |         # stdout stream in logging's Handler.emit(), then raise our special
205 |         # exception so we can handle it in main() instead of logging the
206 |         # broken pipe error and continuing.
207 |         if (
208 |             exc_class
209 |             and exc
210 |             and self.console.file is sys.stdout
211 |             and _is_broken_pipe_error(exc_class, exc)
212 |         ):
213 |             raise BrokenStdoutLoggingError()
214 | 
215 |         return super().handleError(record)
216 | 
217 | 
218 | class BetterRotatingFileHandler(logging.handlers.RotatingFileHandler):
219 |     def _open(self) -> TextIOWrapper:
220 |         ensure_dir(os.path.dirname(self.baseFilename))
221 |         return super()._open()
222 | 
223 | 
224 | class MaxLevelFilter(Filter):
225 |     def __init__(self, level: int) -> None:
226 |         self.level = level
227 | 
228 |     def filter(self, record: logging.LogRecord) -> bool:
229 |         return record.levelno < self.level
230 | 
231 | 
232 | class ExcludeLoggerFilter(Filter):
233 |     """
234 |     A logging Filter that excludes records from a logger (or its children).
235 |     """
236 | 
237 |     def filter(self, record: logging.LogRecord) -> bool:
238 |         # The base Filter class allows only records from a logger (or its
239 |         # children).
240 |         return not super().filter(record)
241 | 
242 | 
243 | def setup_logging(verbosity: int, no_color: bool, user_log_file: Optional[str]) -> int:
244 |     """Configures and sets up all of the logging
245 | 
246 |     Returns the requested logging level, as its integer value.
247 |     """
248 | 
249 |     # Determine the level to be logging at.
250 |     if verbosity >= 2:
251 |         level_number = logging.DEBUG
252 |     elif verbosity == 1:
253 |         level_number = VERBOSE
254 |     elif verbosity == -1:
255 |         level_number = logging.WARNING
256 |     elif verbosity == -2:
257 |         level_number = logging.ERROR
258 |     elif verbosity <= -3:
259 |         level_number = logging.CRITICAL
260 |     else:
261 |         level_number = logging.INFO
262 | 
263 |     level = logging.getLevelName(level_number)
264 | 
265 |     # The "root" logger should match the "console" level *unless* we also need
266 |     # to log to a user log file.
267 |     include_user_log = user_log_file is not None
268 |     if include_user_log:
269 |         additional_log_file = user_log_file
270 |         root_level = "DEBUG"
271 |     else:
272 |         additional_log_file = "/dev/null"
273 |         root_level = level
274 | 
275 |     # Disable any logging besides WARNING unless we have DEBUG level logging
276 |     # enabled for vendored libraries.
277 |     vendored_log_level = "WARNING" if level in ["INFO", "ERROR"] else "DEBUG"
278 | 
279 |     # Shorthands for clarity
280 |     handler_classes = {
281 |         "stream": "pip._internal.utils.logging.RichPipStreamHandler",
282 |         "file": "pip._internal.utils.logging.BetterRotatingFileHandler",
283 |     }
284 |     handlers = ["console", "console_errors", "console_subprocess"] + (
285 |         ["user_log"] if include_user_log else []
286 |     )
287 |     global _stdout_console, stderr_console
288 |     _stdout_console = PipConsole(file=sys.stdout, no_color=no_color, soft_wrap=True)
289 |     _stderr_console = PipConsole(file=sys.stderr, no_color=no_color, soft_wrap=True)
290 | 
291 |     logging.config.dictConfig(
292 |         {
293 |             "version": 1,
294 |             "disable_existing_loggers": False,
295 |             "filters": {
296 |                 "exclude_warnings": {
297 |                     "()": "pip._internal.utils.logging.MaxLevelFilter",
298 |                     "level": logging.WARNING,
299 |                 },
300 |                 "restrict_to_subprocess": {
301 |                     "()": "logging.Filter",
302 |                     "name": subprocess_logger.name,
303 |                 },
304 |                 "exclude_subprocess": {
305 |                     "()": "pip._internal.utils.logging.ExcludeLoggerFilter",
306 |                     "name": subprocess_logger.name,
307 |                 },
308 |             },
309 |             "formatters": {
310 |                 "indent": {
311 |                     "()": IndentingFormatter,
312 |                     "format": "%(message)s",
313 |                 },
314 |                 "indent_with_timestamp": {
315 |                     "()": IndentingFormatter,
316 |                     "format": "%(message)s",
317 |                     "add_timestamp": True,
318 |                 },
319 |             },
320 |             "handlers": {
321 |                 "console": {
322 |                     "level": level,
323 |                     "class": handler_classes["stream"],
324 |                     "console": _stdout_console,
325 |                     "filters": ["exclude_subprocess", "exclude_warnings"],
326 |                     "formatter": "indent",
327 |                 },
328 |                 "console_errors": {
329 |                     "level": "WARNING",
330 |                     "class": handler_classes["stream"],
331 |                     "console": _stderr_console,
332 |                     "filters": ["exclude_subprocess"],
333 |                     "formatter": "indent",
334 |                 },
335 |                 # A handler responsible for logging to the console messages
336 |                 # from the "subprocessor" logger.
337 |                 "console_subprocess": {
338 |                     "level": level,
339 |                     "class": handler_classes["stream"],
340 |                     "console": _stderr_console,
341 |                     "filters": ["restrict_to_subprocess"],
342 |                     "formatter": "indent",
343 |                 },
344 |                 "user_log": {
345 |                     "level": "DEBUG",
346 |                     "class": handler_classes["file"],
347 |                     "filename": additional_log_file,
348 |                     "encoding": "utf-8",
349 |                     "delay": True,
350 |                     "formatter": "indent_with_timestamp",
351 |                 },
352 |             },
353 |             "root": {
354 |                 "level": root_level,
355 |                 "handlers": handlers,
356 |             },
357 |             "loggers": {"pip._vendor": {"level": vendored_log_level}},
358 |         }
359 |     )
360 | 
361 |     return level_number
```

.venv/lib/python3.13/site-packages/pip/_internal/utils/misc.py
```
1 | import errno
2 | import getpass
3 | import hashlib
4 | import logging
5 | import os
6 | import posixpath
7 | import shutil
8 | import stat
9 | import sys
10 | import sysconfig
11 | import urllib.parse
12 | from dataclasses import dataclass
13 | from functools import partial
14 | from io import StringIO
15 | from itertools import filterfalse, tee, zip_longest
16 | from pathlib import Path
17 | from types import FunctionType, TracebackType
18 | from typing import (
19 |     Any,
20 |     BinaryIO,
21 |     Callable,
22 |     Generator,
23 |     Iterable,
24 |     Iterator,
25 |     List,
26 |     Mapping,
27 |     Optional,
28 |     Sequence,
29 |     TextIO,
30 |     Tuple,
31 |     Type,
32 |     TypeVar,
33 |     Union,
34 |     cast,
35 | )
36 | 
37 | from pip._vendor.packaging.requirements import Requirement
38 | from pip._vendor.pyproject_hooks import BuildBackendHookCaller
39 | 
40 | from pip import __version__
41 | from pip._internal.exceptions import CommandError, ExternallyManagedEnvironment
42 | from pip._internal.locations import get_major_minor_version
43 | from pip._internal.utils.compat import WINDOWS
44 | from pip._internal.utils.retry import retry
45 | from pip._internal.utils.virtualenv import running_under_virtualenv
46 | 
47 | __all__ = [
48 |     "rmtree",
49 |     "display_path",
50 |     "backup_dir",
51 |     "ask",
52 |     "splitext",
53 |     "format_size",
54 |     "is_installable_dir",
55 |     "normalize_path",
56 |     "renames",
57 |     "get_prog",
58 |     "ensure_dir",
59 |     "remove_auth_from_url",
60 |     "check_externally_managed",
61 |     "ConfiguredBuildBackendHookCaller",
62 | ]
63 | 
64 | logger = logging.getLogger(__name__)
65 | 
66 | T = TypeVar("T")
67 | ExcInfo = Tuple[Type[BaseException], BaseException, TracebackType]
68 | VersionInfo = Tuple[int, int, int]
69 | NetlocTuple = Tuple[str, Tuple[Optional[str], Optional[str]]]
70 | OnExc = Callable[[FunctionType, Path, BaseException], Any]
71 | OnErr = Callable[[FunctionType, Path, ExcInfo], Any]
72 | 
73 | FILE_CHUNK_SIZE = 1024 * 1024
74 | 
75 | 
76 | def get_pip_version() -> str:
77 |     pip_pkg_dir = os.path.join(os.path.dirname(__file__), "..", "..")
78 |     pip_pkg_dir = os.path.abspath(pip_pkg_dir)
79 | 
80 |     return f"pip {__version__} from {pip_pkg_dir} (python {get_major_minor_version()})"
81 | 
82 | 
83 | def normalize_version_info(py_version_info: Tuple[int, ...]) -> Tuple[int, int, int]:
84 |     """
85 |     Convert a tuple of ints representing a Python version to one of length
86 |     three.
87 | 
88 |     :param py_version_info: a tuple of ints representing a Python version,
89 |         or None to specify no version. The tuple can have any length.
90 | 
91 |     :return: a tuple of length three if `py_version_info` is non-None.
92 |         Otherwise, return `py_version_info` unchanged (i.e. None).
93 |     """
94 |     if len(py_version_info) < 3:
95 |         py_version_info += (3 - len(py_version_info)) * (0,)
96 |     elif len(py_version_info) > 3:
97 |         py_version_info = py_version_info[:3]
98 | 
99 |     return cast("VersionInfo", py_version_info)
100 | 
101 | 
102 | def ensure_dir(path: str) -> None:
103 |     """os.path.makedirs without EEXIST."""
104 |     try:
105 |         os.makedirs(path)
106 |     except OSError as e:
107 |         # Windows can raise spurious ENOTEMPTY errors. See #6426.
108 |         if e.errno != errno.EEXIST and e.errno != errno.ENOTEMPTY:
109 |             raise
110 | 
111 | 
112 | def get_prog() -> str:
113 |     try:
114 |         prog = os.path.basename(sys.argv[0])
115 |         if prog in ("__main__.py", "-c"):
116 |             return f"{sys.executable} -m pip"
117 |         else:
118 |             return prog
119 |     except (AttributeError, TypeError, IndexError):
120 |         pass
121 |     return "pip"
122 | 
123 | 
124 | # Retry every half second for up to 3 seconds
125 | @retry(stop_after_delay=3, wait=0.5)
126 | def rmtree(
127 |     dir: str, ignore_errors: bool = False, onexc: Optional[OnExc] = None
128 | ) -> None:
129 |     if ignore_errors:
130 |         onexc = _onerror_ignore
131 |     if onexc is None:
132 |         onexc = _onerror_reraise
133 |     handler: OnErr = partial(rmtree_errorhandler, onexc=onexc)
134 |     if sys.version_info >= (3, 12):
135 |         # See https://docs.python.org/3.12/whatsnew/3.12.html#shutil.
136 |         shutil.rmtree(dir, onexc=handler)  # type: ignore
137 |     else:
138 |         shutil.rmtree(dir, onerror=handler)  # type: ignore
139 | 
140 | 
141 | def _onerror_ignore(*_args: Any) -> None:
142 |     pass
143 | 
144 | 
145 | def _onerror_reraise(*_args: Any) -> None:
146 |     raise  # noqa: PLE0704 - Bare exception used to reraise existing exception
147 | 
148 | 
149 | def rmtree_errorhandler(
150 |     func: FunctionType,
151 |     path: Path,
152 |     exc_info: Union[ExcInfo, BaseException],
153 |     *,
154 |     onexc: OnExc = _onerror_reraise,
155 | ) -> None:
156 |     """
157 |     `rmtree` error handler to 'force' a file remove (i.e. like `rm -f`).
158 | 
159 |     * If a file is readonly then it's write flag is set and operation is
160 |       retried.
161 | 
162 |     * `onerror` is the original callback from `rmtree(... onerror=onerror)`
163 |       that is chained at the end if the "rm -f" still fails.
164 |     """
165 |     try:
166 |         st_mode = os.stat(path).st_mode
167 |     except OSError:
168 |         # it's equivalent to os.path.exists
169 |         return
170 | 
171 |     if not st_mode & stat.S_IWRITE:
172 |         # convert to read/write
173 |         try:
174 |             os.chmod(path, st_mode | stat.S_IWRITE)
175 |         except OSError:
176 |             pass
177 |         else:
178 |             # use the original function to repeat the operation
179 |             try:
180 |                 func(path)
181 |                 return
182 |             except OSError:
183 |                 pass
184 | 
185 |     if not isinstance(exc_info, BaseException):
186 |         _, exc_info, _ = exc_info
187 |     onexc(func, path, exc_info)
188 | 
189 | 
190 | def display_path(path: str) -> str:
191 |     """Gives the display value for a given path, making it relative to cwd
192 |     if possible."""
193 |     path = os.path.normcase(os.path.abspath(path))
194 |     if path.startswith(os.getcwd() + os.path.sep):
195 |         path = "." + path[len(os.getcwd()) :]
196 |     return path
197 | 
198 | 
199 | def backup_dir(dir: str, ext: str = ".bak") -> str:
200 |     """Figure out the name of a directory to back up the given dir to
201 |     (adding .bak, .bak2, etc)"""
202 |     n = 1
203 |     extension = ext
204 |     while os.path.exists(dir + extension):
205 |         n += 1
206 |         extension = ext + str(n)
207 |     return dir + extension
208 | 
209 | 
210 | def ask_path_exists(message: str, options: Iterable[str]) -> str:
211 |     for action in os.environ.get("PIP_EXISTS_ACTION", "").split():
212 |         if action in options:
213 |             return action
214 |     return ask(message, options)
215 | 
216 | 
217 | def _check_no_input(message: str) -> None:
218 |     """Raise an error if no input is allowed."""
219 |     if os.environ.get("PIP_NO_INPUT"):
220 |         raise Exception(
221 |             f"No input was expected ($PIP_NO_INPUT set); question: {message}"
222 |         )
223 | 
224 | 
225 | def ask(message: str, options: Iterable[str]) -> str:
226 |     """Ask the message interactively, with the given possible responses"""
227 |     while 1:
228 |         _check_no_input(message)
229 |         response = input(message)
230 |         response = response.strip().lower()
231 |         if response not in options:
232 |             print(
233 |                 "Your response ({!r}) was not one of the expected responses: "
234 |                 "{}".format(response, ", ".join(options))
235 |             )
236 |         else:
237 |             return response
238 | 
239 | 
240 | def ask_input(message: str) -> str:
241 |     """Ask for input interactively."""
242 |     _check_no_input(message)
243 |     return input(message)
244 | 
245 | 
246 | def ask_password(message: str) -> str:
247 |     """Ask for a password interactively."""
248 |     _check_no_input(message)
249 |     return getpass.getpass(message)
250 | 
251 | 
252 | def strtobool(val: str) -> int:
253 |     """Convert a string representation of truth to true (1) or false (0).
254 | 
255 |     True values are 'y', 'yes', 't', 'true', 'on', and '1'; false values
256 |     are 'n', 'no', 'f', 'false', 'off', and '0'.  Raises ValueError if
257 |     'val' is anything else.
258 |     """
259 |     val = val.lower()
260 |     if val in ("y", "yes", "t", "true", "on", "1"):
261 |         return 1
262 |     elif val in ("n", "no", "f", "false", "off", "0"):
263 |         return 0
264 |     else:
265 |         raise ValueError(f"invalid truth value {val!r}")
266 | 
267 | 
268 | def format_size(bytes: float) -> str:
269 |     if bytes > 1000 * 1000:
270 |         return f"{bytes / 1000.0 / 1000:.1f} MB"
271 |     elif bytes > 10 * 1000:
272 |         return f"{int(bytes / 1000)} kB"
273 |     elif bytes > 1000:
274 |         return f"{bytes / 1000.0:.1f} kB"
275 |     else:
276 |         return f"{int(bytes)} bytes"
277 | 
278 | 
279 | def tabulate(rows: Iterable[Iterable[Any]]) -> Tuple[List[str], List[int]]:
280 |     """Return a list of formatted rows and a list of column sizes.
281 | 
282 |     For example::
283 | 
284 |     >>> tabulate([['foobar', 2000], [0xdeadbeef]])
285 |     (['foobar     2000', '3735928559'], [10, 4])
286 |     """
287 |     rows = [tuple(map(str, row)) for row in rows]
288 |     sizes = [max(map(len, col)) for col in zip_longest(*rows, fillvalue="")]
289 |     table = [" ".join(map(str.ljust, row, sizes)).rstrip() for row in rows]
290 |     return table, sizes
291 | 
292 | 
293 | def is_installable_dir(path: str) -> bool:
294 |     """Is path is a directory containing pyproject.toml or setup.py?
295 | 
296 |     If pyproject.toml exists, this is a PEP 517 project. Otherwise we look for
297 |     a legacy setuptools layout by identifying setup.py. We don't check for the
298 |     setup.cfg because using it without setup.py is only available for PEP 517
299 |     projects, which are already covered by the pyproject.toml check.
300 |     """
301 |     if not os.path.isdir(path):
302 |         return False
303 |     if os.path.isfile(os.path.join(path, "pyproject.toml")):
304 |         return True
305 |     if os.path.isfile(os.path.join(path, "setup.py")):
306 |         return True
307 |     return False
308 | 
309 | 
310 | def read_chunks(
311 |     file: BinaryIO, size: int = FILE_CHUNK_SIZE
312 | ) -> Generator[bytes, None, None]:
313 |     """Yield pieces of data from a file-like object until EOF."""
314 |     while True:
315 |         chunk = file.read(size)
316 |         if not chunk:
317 |             break
318 |         yield chunk
319 | 
320 | 
321 | def normalize_path(path: str, resolve_symlinks: bool = True) -> str:
322 |     """
323 |     Convert a path to its canonical, case-normalized, absolute version.
324 | 
325 |     """
326 |     path = os.path.expanduser(path)
327 |     if resolve_symlinks:
328 |         path = os.path.realpath(path)
329 |     else:
330 |         path = os.path.abspath(path)
331 |     return os.path.normcase(path)
332 | 
333 | 
334 | def splitext(path: str) -> Tuple[str, str]:
335 |     """Like os.path.splitext, but take off .tar too"""
336 |     base, ext = posixpath.splitext(path)
337 |     if base.lower().endswith(".tar"):
338 |         ext = base[-4:] + ext
339 |         base = base[:-4]
340 |     return base, ext
341 | 
342 | 
343 | def renames(old: str, new: str) -> None:
344 |     """Like os.renames(), but handles renaming across devices."""
345 |     # Implementation borrowed from os.renames().
346 |     head, tail = os.path.split(new)
347 |     if head and tail and not os.path.exists(head):
348 |         os.makedirs(head)
349 | 
350 |     shutil.move(old, new)
351 | 
352 |     head, tail = os.path.split(old)
353 |     if head and tail:
354 |         try:
355 |             os.removedirs(head)
356 |         except OSError:
357 |             pass
358 | 
359 | 
360 | def is_local(path: str) -> bool:
361 |     """
362 |     Return True if path is within sys.prefix, if we're running in a virtualenv.
363 | 
364 |     If we're not in a virtualenv, all paths are considered "local."
365 | 
366 |     Caution: this function assumes the head of path has been normalized
367 |     with normalize_path.
368 |     """
[TRUNCATED]
```

.venv/lib/python3.13/site-packages/pip/_internal/utils/packaging.py
```
1 | import functools
2 | import logging
3 | from typing import Optional, Tuple
4 | 
5 | from pip._vendor.packaging import specifiers, version
6 | from pip._vendor.packaging.requirements import Requirement
7 | 
8 | logger = logging.getLogger(__name__)
9 | 
10 | 
11 | @functools.lru_cache(maxsize=32)
12 | def check_requires_python(
13 |     requires_python: Optional[str], version_info: Tuple[int, ...]
14 | ) -> bool:
15 |     """
16 |     Check if the given Python version matches a "Requires-Python" specifier.
17 | 
18 |     :param version_info: A 3-tuple of ints representing a Python
19 |         major-minor-micro version to check (e.g. `sys.version_info[:3]`).
20 | 
21 |     :return: `True` if the given Python version satisfies the requirement.
22 |         Otherwise, return `False`.
23 | 
24 |     :raises InvalidSpecifier: If `requires_python` has an invalid format.
25 |     """
26 |     if requires_python is None:
27 |         # The package provides no information
28 |         return True
29 |     requires_python_specifier = specifiers.SpecifierSet(requires_python)
30 | 
31 |     python_version = version.parse(".".join(map(str, version_info)))
32 |     return python_version in requires_python_specifier
33 | 
34 | 
35 | @functools.lru_cache(maxsize=10000)
36 | def get_requirement(req_string: str) -> Requirement:
37 |     """Construct a packaging.Requirement object with caching"""
38 |     # Parsing requirement strings is expensive, and is also expected to happen
39 |     # with a low diversity of different arguments (at least relative the number
40 |     # constructed). This method adds a cache to requirement object creation to
41 |     # minimize repeated parsing of the same string to construct equivalent
42 |     # Requirement objects.
43 |     return Requirement(req_string)
```

.venv/lib/python3.13/site-packages/pip/_internal/utils/retry.py
```
1 | import functools
2 | from time import perf_counter, sleep
3 | from typing import Callable, TypeVar
4 | 
5 | from pip._vendor.typing_extensions import ParamSpec
6 | 
7 | T = TypeVar("T")
8 | P = ParamSpec("P")
9 | 
10 | 
11 | def retry(
12 |     wait: float, stop_after_delay: float
13 | ) -> Callable[[Callable[P, T]], Callable[P, T]]:
14 |     """Decorator to automatically retry a function on error.
15 | 
16 |     If the function raises, the function is recalled with the same arguments
17 |     until it returns or the time limit is reached. When the time limit is
18 |     surpassed, the last exception raised is reraised.
19 | 
20 |     :param wait: The time to wait after an error before retrying, in seconds.
21 |     :param stop_after_delay: The time limit after which retries will cease,
22 |         in seconds.
23 |     """
24 | 
25 |     def wrapper(func: Callable[P, T]) -> Callable[P, T]:
26 | 
27 |         @functools.wraps(func)
28 |         def retry_wrapped(*args: P.args, **kwargs: P.kwargs) -> T:
29 |             # The performance counter is monotonic on all platforms we care
30 |             # about and has much better resolution than time.monotonic().
31 |             start_time = perf_counter()
32 |             while True:
33 |                 try:
34 |                     return func(*args, **kwargs)
35 |                 except Exception:
36 |                     if perf_counter() - start_time > stop_after_delay:
37 |                         raise
38 |                     sleep(wait)
39 | 
40 |         return retry_wrapped
41 | 
42 |     return wrapper
```

.venv/lib/python3.13/site-packages/pip/_internal/utils/setuptools_build.py
```
1 | import sys
2 | import textwrap
3 | from typing import List, Optional, Sequence
4 | 
5 | # Shim to wrap setup.py invocation with setuptools
6 | # Note that __file__ is handled via two {!r} *and* %r, to ensure that paths on
7 | # Windows are correctly handled (it should be "C:\\Users" not "C:\Users").
8 | _SETUPTOOLS_SHIM = textwrap.dedent(
9 |     """
10 |     exec(compile('''
11 |     # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py
12 |     #
13 |     # - It imports setuptools before invoking setup.py, to enable projects that directly
14 |     #   import from `distutils.core` to work with newer packaging standards.
15 |     # - It provides a clear error message when setuptools is not installed.
16 |     # - It sets `sys.argv[0]` to the underlying `setup.py`, when invoking `setup.py` so
17 |     #   setuptools doesn't think the script is `-c`. This avoids the following warning:
18 |     #     manifest_maker: standard file '-c' not found".
19 |     # - It generates a shim setup.py, for handling setup.cfg-only projects.
20 |     import os, sys, tokenize, traceback
21 | 
22 |     try:
23 |         import setuptools
24 |     except ImportError:
25 |         print(
26 |             "ERROR: Can not execute `setup.py` since setuptools failed to import in "
27 |             "the build environment with exception:",
28 |             file=sys.stderr,
29 |         )
30 |         traceback.print_exc()
31 |         sys.exit(1)
32 | 
33 |     __file__ = %r
34 |     sys.argv[0] = __file__
35 | 
36 |     if os.path.exists(__file__):
37 |         filename = __file__
38 |         with tokenize.open(__file__) as f:
39 |             setup_py_code = f.read()
40 |     else:
41 |         filename = "<auto-generated setuptools caller>"
42 |         setup_py_code = "from setuptools import setup; setup()"
43 | 
44 |     exec(compile(setup_py_code, filename, "exec"))
45 |     ''' % ({!r},), "<pip-setuptools-caller>", "exec"))
46 |     """
47 | ).rstrip()
48 | 
49 | 
50 | def make_setuptools_shim_args(
51 |     setup_py_path: str,
52 |     global_options: Optional[Sequence[str]] = None,
53 |     no_user_config: bool = False,
54 |     unbuffered_output: bool = False,
55 | ) -> List[str]:
56 |     """
57 |     Get setuptools command arguments with shim wrapped setup file invocation.
58 | 
59 |     :param setup_py_path: The path to setup.py to be wrapped.
60 |     :param global_options: Additional global options.
61 |     :param no_user_config: If True, disables personal user configuration.
62 |     :param unbuffered_output: If True, adds the unbuffered switch to the
63 |      argument list.
64 |     """
65 |     args = [sys.executable]
66 |     if unbuffered_output:
67 |         args += ["-u"]
68 |     args += ["-c", _SETUPTOOLS_SHIM.format(setup_py_path)]
69 |     if global_options:
70 |         args += global_options
71 |     if no_user_config:
72 |         args += ["--no-user-cfg"]
73 |     return args
74 | 
75 | 
76 | def make_setuptools_bdist_wheel_args(
77 |     setup_py_path: str,
78 |     global_options: Sequence[str],
79 |     build_options: Sequence[str],
80 |     destination_dir: str,
81 | ) -> List[str]:
82 |     # NOTE: Eventually, we'd want to also -S to the flags here, when we're
83 |     # isolating. Currently, it breaks Python in virtualenvs, because it
84 |     # relies on site.py to find parts of the standard library outside the
85 |     # virtualenv.
86 |     args = make_setuptools_shim_args(
87 |         setup_py_path, global_options=global_options, unbuffered_output=True
88 |     )
89 |     args += ["bdist_wheel", "-d", destination_dir]
90 |     args += build_options
91 |     return args
92 | 
93 | 
94 | def make_setuptools_clean_args(
95 |     setup_py_path: str,
96 |     global_options: Sequence[str],
97 | ) -> List[str]:
98 |     args = make_setuptools_shim_args(
99 |         setup_py_path, global_options=global_options, unbuffered_output=True
100 |     )
101 |     args += ["clean", "--all"]
102 |     return args
103 | 
104 | 
105 | def make_setuptools_develop_args(
106 |     setup_py_path: str,
107 |     *,
108 |     global_options: Sequence[str],
109 |     no_user_config: bool,
110 |     prefix: Optional[str],
111 |     home: Optional[str],
112 |     use_user_site: bool,
113 | ) -> List[str]:
114 |     assert not (use_user_site and prefix)
115 | 
116 |     args = make_setuptools_shim_args(
117 |         setup_py_path,
118 |         global_options=global_options,
119 |         no_user_config=no_user_config,
120 |     )
121 | 
122 |     args += ["develop", "--no-deps"]
123 | 
124 |     if prefix:
125 |         args += ["--prefix", prefix]
126 |     if home is not None:
127 |         args += ["--install-dir", home]
128 | 
129 |     if use_user_site:
130 |         args += ["--user", "--prefix="]
131 | 
132 |     return args
133 | 
134 | 
135 | def make_setuptools_egg_info_args(
136 |     setup_py_path: str,
137 |     egg_info_dir: Optional[str],
138 |     no_user_config: bool,
139 | ) -> List[str]:
140 |     args = make_setuptools_shim_args(setup_py_path, no_user_config=no_user_config)
141 | 
142 |     args += ["egg_info"]
143 | 
144 |     if egg_info_dir:
145 |         args += ["--egg-base", egg_info_dir]
146 | 
147 |     return args
```

.venv/lib/python3.13/site-packages/pip/_internal/utils/subprocess.py
```
1 | import logging
2 | import os
3 | import shlex
4 | import subprocess
5 | from typing import Any, Callable, Iterable, List, Literal, Mapping, Optional, Union
6 | 
7 | from pip._vendor.rich.markup import escape
8 | 
9 | from pip._internal.cli.spinners import SpinnerInterface, open_spinner
10 | from pip._internal.exceptions import InstallationSubprocessError
11 | from pip._internal.utils.logging import VERBOSE, subprocess_logger
12 | from pip._internal.utils.misc import HiddenText
13 | 
14 | CommandArgs = List[Union[str, HiddenText]]
15 | 
16 | 
17 | def make_command(*args: Union[str, HiddenText, CommandArgs]) -> CommandArgs:
18 |     """
19 |     Create a CommandArgs object.
20 |     """
21 |     command_args: CommandArgs = []
22 |     for arg in args:
23 |         # Check for list instead of CommandArgs since CommandArgs is
24 |         # only known during type-checking.
25 |         if isinstance(arg, list):
26 |             command_args.extend(arg)
27 |         else:
28 |             # Otherwise, arg is str or HiddenText.
29 |             command_args.append(arg)
30 | 
31 |     return command_args
32 | 
33 | 
34 | def format_command_args(args: Union[List[str], CommandArgs]) -> str:
35 |     """
36 |     Format command arguments for display.
37 |     """
38 |     # For HiddenText arguments, display the redacted form by calling str().
39 |     # Also, we don't apply str() to arguments that aren't HiddenText since
40 |     # this can trigger a UnicodeDecodeError in Python 2 if the argument
41 |     # has type unicode and includes a non-ascii character.  (The type
42 |     # checker doesn't ensure the annotations are correct in all cases.)
43 |     return " ".join(
44 |         shlex.quote(str(arg)) if isinstance(arg, HiddenText) else shlex.quote(arg)
45 |         for arg in args
46 |     )
47 | 
48 | 
49 | def reveal_command_args(args: Union[List[str], CommandArgs]) -> List[str]:
50 |     """
51 |     Return the arguments in their raw, unredacted form.
52 |     """
53 |     return [arg.secret if isinstance(arg, HiddenText) else arg for arg in args]
54 | 
55 | 
56 | def call_subprocess(
57 |     cmd: Union[List[str], CommandArgs],
58 |     show_stdout: bool = False,
59 |     cwd: Optional[str] = None,
60 |     on_returncode: 'Literal["raise", "warn", "ignore"]' = "raise",
61 |     extra_ok_returncodes: Optional[Iterable[int]] = None,
62 |     extra_environ: Optional[Mapping[str, Any]] = None,
63 |     unset_environ: Optional[Iterable[str]] = None,
64 |     spinner: Optional[SpinnerInterface] = None,
65 |     log_failed_cmd: Optional[bool] = True,
66 |     stdout_only: Optional[bool] = False,
67 |     *,
68 |     command_desc: str,
69 | ) -> str:
70 |     """
71 |     Args:
72 |       show_stdout: if true, use INFO to log the subprocess's stderr and
73 |         stdout streams.  Otherwise, use DEBUG.  Defaults to False.
74 |       extra_ok_returncodes: an iterable of integer return codes that are
75 |         acceptable, in addition to 0. Defaults to None, which means [].
76 |       unset_environ: an iterable of environment variable names to unset
77 |         prior to calling subprocess.Popen().
78 |       log_failed_cmd: if false, failed commands are not logged, only raised.
79 |       stdout_only: if true, return only stdout, else return both. When true,
80 |         logging of both stdout and stderr occurs when the subprocess has
81 |         terminated, else logging occurs as subprocess output is produced.
82 |     """
83 |     if extra_ok_returncodes is None:
84 |         extra_ok_returncodes = []
85 |     if unset_environ is None:
86 |         unset_environ = []
87 |     # Most places in pip use show_stdout=False. What this means is--
88 |     #
89 |     # - We connect the child's output (combined stderr and stdout) to a
90 |     #   single pipe, which we read.
91 |     # - We log this output to stderr at DEBUG level as it is received.
92 |     # - If DEBUG logging isn't enabled (e.g. if --verbose logging wasn't
93 |     #   requested), then we show a spinner so the user can still see the
94 |     #   subprocess is in progress.
95 |     # - If the subprocess exits with an error, we log the output to stderr
96 |     #   at ERROR level if it hasn't already been displayed to the console
97 |     #   (e.g. if --verbose logging wasn't enabled).  This way we don't log
98 |     #   the output to the console twice.
99 |     #
100 |     # If show_stdout=True, then the above is still done, but with DEBUG
101 |     # replaced by INFO.
102 |     if show_stdout:
103 |         # Then log the subprocess output at INFO level.
104 |         log_subprocess: Callable[..., None] = subprocess_logger.info
105 |         used_level = logging.INFO
106 |     else:
107 |         # Then log the subprocess output using VERBOSE.  This also ensures
108 |         # it will be logged to the log file (aka user_log), if enabled.
109 |         log_subprocess = subprocess_logger.verbose
110 |         used_level = VERBOSE
111 | 
112 |     # Whether the subprocess will be visible in the console.
113 |     showing_subprocess = subprocess_logger.getEffectiveLevel() <= used_level
114 | 
115 |     # Only use the spinner if we're not showing the subprocess output
116 |     # and we have a spinner.
117 |     use_spinner = not showing_subprocess and spinner is not None
118 | 
119 |     log_subprocess("Running command %s", command_desc)
120 |     env = os.environ.copy()
121 |     if extra_environ:
122 |         env.update(extra_environ)
123 |     for name in unset_environ:
124 |         env.pop(name, None)
125 |     try:
126 |         proc = subprocess.Popen(
127 |             # Convert HiddenText objects to the underlying str.
128 |             reveal_command_args(cmd),
129 |             stdin=subprocess.PIPE,
130 |             stdout=subprocess.PIPE,
131 |             stderr=subprocess.STDOUT if not stdout_only else subprocess.PIPE,
132 |             cwd=cwd,
133 |             env=env,
134 |             errors="backslashreplace",
135 |         )
136 |     except Exception as exc:
137 |         if log_failed_cmd:
138 |             subprocess_logger.critical(
139 |                 "Error %s while executing command %s",
140 |                 exc,
141 |                 command_desc,
142 |             )
143 |         raise
144 |     all_output = []
145 |     if not stdout_only:
146 |         assert proc.stdout
147 |         assert proc.stdin
148 |         proc.stdin.close()
149 |         # In this mode, stdout and stderr are in the same pipe.
150 |         while True:
151 |             line: str = proc.stdout.readline()
152 |             if not line:
153 |                 break
154 |             line = line.rstrip()
155 |             all_output.append(line + "\n")
156 | 
157 |             # Show the line immediately.
158 |             log_subprocess(line)
159 |             # Update the spinner.
160 |             if use_spinner:
161 |                 assert spinner
162 |                 spinner.spin()
163 |         try:
164 |             proc.wait()
165 |         finally:
166 |             if proc.stdout:
167 |                 proc.stdout.close()
168 |         output = "".join(all_output)
169 |     else:
170 |         # In this mode, stdout and stderr are in different pipes.
171 |         # We must use communicate() which is the only safe way to read both.
172 |         out, err = proc.communicate()
173 |         # log line by line to preserve pip log indenting
174 |         for out_line in out.splitlines():
175 |             log_subprocess(out_line)
176 |         all_output.append(out)
177 |         for err_line in err.splitlines():
178 |             log_subprocess(err_line)
179 |         all_output.append(err)
180 |         output = out
181 | 
182 |     proc_had_error = proc.returncode and proc.returncode not in extra_ok_returncodes
183 |     if use_spinner:
184 |         assert spinner
185 |         if proc_had_error:
186 |             spinner.finish("error")
187 |         else:
188 |             spinner.finish("done")
189 |     if proc_had_error:
190 |         if on_returncode == "raise":
191 |             error = InstallationSubprocessError(
192 |                 command_description=command_desc,
193 |                 exit_code=proc.returncode,
194 |                 output_lines=all_output if not showing_subprocess else None,
195 |             )
196 |             if log_failed_cmd:
197 |                 subprocess_logger.error("%s", error, extra={"rich": True})
198 |                 subprocess_logger.verbose(
199 |                     "[bold magenta]full command[/]: [blue]%s[/]",
200 |                     escape(format_command_args(cmd)),
201 |                     extra={"markup": True},
202 |                 )
203 |                 subprocess_logger.verbose(
204 |                     "[bold magenta]cwd[/]: %s",
205 |                     escape(cwd or "[inherit]"),
206 |                     extra={"markup": True},
207 |                 )
208 | 
209 |             raise error
210 |         elif on_returncode == "warn":
211 |             subprocess_logger.warning(
212 |                 'Command "%s" had error code %s in %s',
213 |                 command_desc,
214 |                 proc.returncode,
215 |                 cwd,
216 |             )
217 |         elif on_returncode == "ignore":
218 |             pass
219 |         else:
220 |             raise ValueError(f"Invalid value: on_returncode={on_returncode!r}")
221 |     return output
222 | 
223 | 
224 | def runner_with_spinner_message(message: str) -> Callable[..., None]:
225 |     """Provide a subprocess_runner that shows a spinner message.
226 | 
227 |     Intended for use with for BuildBackendHookCaller. Thus, the runner has
228 |     an API that matches what's expected by BuildBackendHookCaller.subprocess_runner.
229 |     """
230 | 
231 |     def runner(
232 |         cmd: List[str],
233 |         cwd: Optional[str] = None,
234 |         extra_environ: Optional[Mapping[str, Any]] = None,
235 |     ) -> None:
236 |         with open_spinner(message) as spinner:
237 |             call_subprocess(
238 |                 cmd,
239 |                 command_desc=message,
240 |                 cwd=cwd,
241 |                 extra_environ=extra_environ,
242 |                 spinner=spinner,
243 |             )
244 | 
245 |     return runner
```

.venv/lib/python3.13/site-packages/pip/_internal/utils/temp_dir.py
```
1 | import errno
2 | import itertools
3 | import logging
4 | import os.path
5 | import tempfile
6 | import traceback
7 | from contextlib import ExitStack, contextmanager
8 | from pathlib import Path
9 | from typing import (
10 |     Any,
11 |     Callable,
12 |     Dict,
13 |     Generator,
14 |     List,
15 |     Optional,
16 |     TypeVar,
17 |     Union,
18 | )
19 | 
20 | from pip._internal.utils.misc import enum, rmtree
21 | 
22 | logger = logging.getLogger(__name__)
23 | 
24 | _T = TypeVar("_T", bound="TempDirectory")
25 | 
26 | 
27 | # Kinds of temporary directories. Only needed for ones that are
28 | # globally-managed.
29 | tempdir_kinds = enum(
30 |     BUILD_ENV="build-env",
31 |     EPHEM_WHEEL_CACHE="ephem-wheel-cache",
32 |     REQ_BUILD="req-build",
33 | )
34 | 
35 | 
36 | _tempdir_manager: Optional[ExitStack] = None
37 | 
38 | 
39 | @contextmanager
40 | def global_tempdir_manager() -> Generator[None, None, None]:
41 |     global _tempdir_manager
42 |     with ExitStack() as stack:
43 |         old_tempdir_manager, _tempdir_manager = _tempdir_manager, stack
44 |         try:
45 |             yield
46 |         finally:
47 |             _tempdir_manager = old_tempdir_manager
48 | 
49 | 
50 | class TempDirectoryTypeRegistry:
51 |     """Manages temp directory behavior"""
52 | 
53 |     def __init__(self) -> None:
54 |         self._should_delete: Dict[str, bool] = {}
55 | 
56 |     def set_delete(self, kind: str, value: bool) -> None:
57 |         """Indicate whether a TempDirectory of the given kind should be
58 |         auto-deleted.
59 |         """
60 |         self._should_delete[kind] = value
61 | 
62 |     def get_delete(self, kind: str) -> bool:
63 |         """Get configured auto-delete flag for a given TempDirectory type,
64 |         default True.
65 |         """
66 |         return self._should_delete.get(kind, True)
67 | 
68 | 
69 | _tempdir_registry: Optional[TempDirectoryTypeRegistry] = None
70 | 
71 | 
72 | @contextmanager
73 | def tempdir_registry() -> Generator[TempDirectoryTypeRegistry, None, None]:
74 |     """Provides a scoped global tempdir registry that can be used to dictate
75 |     whether directories should be deleted.
76 |     """
77 |     global _tempdir_registry
78 |     old_tempdir_registry = _tempdir_registry
79 |     _tempdir_registry = TempDirectoryTypeRegistry()
80 |     try:
81 |         yield _tempdir_registry
82 |     finally:
83 |         _tempdir_registry = old_tempdir_registry
84 | 
85 | 
86 | class _Default:
87 |     pass
88 | 
89 | 
90 | _default = _Default()
91 | 
92 | 
93 | class TempDirectory:
94 |     """Helper class that owns and cleans up a temporary directory.
95 | 
96 |     This class can be used as a context manager or as an OO representation of a
97 |     temporary directory.
98 | 
99 |     Attributes:
100 |         path
101 |             Location to the created temporary directory
102 |         delete
103 |             Whether the directory should be deleted when exiting
104 |             (when used as a contextmanager)
105 | 
106 |     Methods:
107 |         cleanup()
108 |             Deletes the temporary directory
109 | 
110 |     When used as a context manager, if the delete attribute is True, on
111 |     exiting the context the temporary directory is deleted.
112 |     """
113 | 
114 |     def __init__(
115 |         self,
116 |         path: Optional[str] = None,
117 |         delete: Union[bool, None, _Default] = _default,
118 |         kind: str = "temp",
119 |         globally_managed: bool = False,
120 |         ignore_cleanup_errors: bool = True,
121 |     ):
122 |         super().__init__()
123 | 
124 |         if delete is _default:
125 |             if path is not None:
126 |                 # If we were given an explicit directory, resolve delete option
127 |                 # now.
128 |                 delete = False
129 |             else:
130 |                 # Otherwise, we wait until cleanup and see what
131 |                 # tempdir_registry says.
132 |                 delete = None
133 | 
134 |         # The only time we specify path is in for editables where it
135 |         # is the value of the --src option.
136 |         if path is None:
137 |             path = self._create(kind)
138 | 
139 |         self._path = path
140 |         self._deleted = False
141 |         self.delete = delete
142 |         self.kind = kind
143 |         self.ignore_cleanup_errors = ignore_cleanup_errors
144 | 
145 |         if globally_managed:
146 |             assert _tempdir_manager is not None
147 |             _tempdir_manager.enter_context(self)
148 | 
149 |     @property
150 |     def path(self) -> str:
151 |         assert not self._deleted, f"Attempted to access deleted path: {self._path}"
152 |         return self._path
153 | 
154 |     def __repr__(self) -> str:
155 |         return f"<{self.__class__.__name__} {self.path!r}>"
156 | 
157 |     def __enter__(self: _T) -> _T:
158 |         return self
159 | 
160 |     def __exit__(self, exc: Any, value: Any, tb: Any) -> None:
161 |         if self.delete is not None:
162 |             delete = self.delete
163 |         elif _tempdir_registry:
164 |             delete = _tempdir_registry.get_delete(self.kind)
165 |         else:
166 |             delete = True
167 | 
168 |         if delete:
169 |             self.cleanup()
170 | 
171 |     def _create(self, kind: str) -> str:
172 |         """Create a temporary directory and store its path in self.path"""
173 |         # We realpath here because some systems have their default tmpdir
174 |         # symlinked to another directory.  This tends to confuse build
175 |         # scripts, so we canonicalize the path by traversing potential
176 |         # symlinks here.
177 |         path = os.path.realpath(tempfile.mkdtemp(prefix=f"pip-{kind}-"))
178 |         logger.debug("Created temporary directory: %s", path)
179 |         return path
180 | 
181 |     def cleanup(self) -> None:
182 |         """Remove the temporary directory created and reset state"""
183 |         self._deleted = True
184 |         if not os.path.exists(self._path):
185 |             return
186 | 
187 |         errors: List[BaseException] = []
188 | 
189 |         def onerror(
190 |             func: Callable[..., Any],
191 |             path: Path,
192 |             exc_val: BaseException,
193 |         ) -> None:
194 |             """Log a warning for a `rmtree` error and continue"""
195 |             formatted_exc = "\n".join(
196 |                 traceback.format_exception_only(type(exc_val), exc_val)
197 |             )
198 |             formatted_exc = formatted_exc.rstrip()  # remove trailing new line
199 |             if func in (os.unlink, os.remove, os.rmdir):
200 |                 logger.debug(
201 |                     "Failed to remove a temporary file '%s' due to %s.\n",
202 |                     path,
203 |                     formatted_exc,
204 |                 )
205 |             else:
206 |                 logger.debug("%s failed with %s.", func.__qualname__, formatted_exc)
207 |             errors.append(exc_val)
208 | 
209 |         if self.ignore_cleanup_errors:
210 |             try:
211 |                 # first try with @retry; retrying to handle ephemeral errors
212 |                 rmtree(self._path, ignore_errors=False)
213 |             except OSError:
214 |                 # last pass ignore/log all errors
215 |                 rmtree(self._path, onexc=onerror)
216 |             if errors:
217 |                 logger.warning(
218 |                     "Failed to remove contents in a temporary directory '%s'.\n"
219 |                     "You can safely remove it manually.",
220 |                     self._path,
221 |                 )
222 |         else:
223 |             rmtree(self._path)
224 | 
225 | 
226 | class AdjacentTempDirectory(TempDirectory):
227 |     """Helper class that creates a temporary directory adjacent to a real one.
228 | 
229 |     Attributes:
230 |         original
231 |             The original directory to create a temp directory for.
232 |         path
233 |             After calling create() or entering, contains the full
234 |             path to the temporary directory.
235 |         delete
236 |             Whether the directory should be deleted when exiting
237 |             (when used as a contextmanager)
238 | 
239 |     """
240 | 
241 |     # The characters that may be used to name the temp directory
242 |     # We always prepend a ~ and then rotate through these until
243 |     # a usable name is found.
244 |     # pkg_resources raises a different error for .dist-info folder
245 |     # with leading '-' and invalid metadata
246 |     LEADING_CHARS = "-~.=%0123456789"
247 | 
248 |     def __init__(self, original: str, delete: Optional[bool] = None) -> None:
249 |         self.original = original.rstrip("/\\")
250 |         super().__init__(delete=delete)
251 | 
252 |     @classmethod
253 |     def _generate_names(cls, name: str) -> Generator[str, None, None]:
254 |         """Generates a series of temporary names.
255 | 
256 |         The algorithm replaces the leading characters in the name
257 |         with ones that are valid filesystem characters, but are not
258 |         valid package names (for both Python and pip definitions of
259 |         package).
260 |         """
261 |         for i in range(1, len(name)):
262 |             for candidate in itertools.combinations_with_replacement(
263 |                 cls.LEADING_CHARS, i - 1
264 |             ):
265 |                 new_name = "~" + "".join(candidate) + name[i:]
266 |                 if new_name != name:
267 |                     yield new_name
268 | 
269 |         # If we make it this far, we will have to make a longer name
270 |         for i in range(len(cls.LEADING_CHARS)):
271 |             for candidate in itertools.combinations_with_replacement(
272 |                 cls.LEADING_CHARS, i
273 |             ):
274 |                 new_name = "~" + "".join(candidate) + name
275 |                 if new_name != name:
276 |                     yield new_name
277 | 
278 |     def _create(self, kind: str) -> str:
279 |         root, name = os.path.split(self.original)
280 |         for candidate in self._generate_names(name):
281 |             path = os.path.join(root, candidate)
282 |             try:
283 |                 os.mkdir(path)
284 |             except OSError as ex:
285 |                 # Continue if the name exists already
286 |                 if ex.errno != errno.EEXIST:
287 |                     raise
288 |             else:
289 |                 path = os.path.realpath(path)
290 |                 break
291 |         else:
292 |             # Final fallback on the default behavior.
293 |             path = os.path.realpath(tempfile.mkdtemp(prefix=f"pip-{kind}-"))
294 | 
295 |         logger.debug("Created temporary directory: %s", path)
296 |         return path
```

.venv/lib/python3.13/site-packages/pip/_internal/utils/unpacking.py
```
1 | """Utilities related archives."""
2 | 
3 | import logging
4 | import os
5 | import shutil
6 | import stat
7 | import sys
8 | import tarfile
9 | import zipfile
10 | from typing import Iterable, List, Optional
11 | from zipfile import ZipInfo
12 | 
13 | from pip._internal.exceptions import InstallationError
14 | from pip._internal.utils.filetypes import (
15 |     BZ2_EXTENSIONS,
16 |     TAR_EXTENSIONS,
17 |     XZ_EXTENSIONS,
18 |     ZIP_EXTENSIONS,
19 | )
20 | from pip._internal.utils.misc import ensure_dir
21 | 
22 | logger = logging.getLogger(__name__)
23 | 
24 | 
25 | SUPPORTED_EXTENSIONS = ZIP_EXTENSIONS + TAR_EXTENSIONS
26 | 
27 | try:
28 |     import bz2  # noqa
29 | 
30 |     SUPPORTED_EXTENSIONS += BZ2_EXTENSIONS
31 | except ImportError:
32 |     logger.debug("bz2 module is not available")
33 | 
34 | try:
35 |     # Only for Python 3.3+
36 |     import lzma  # noqa
37 | 
38 |     SUPPORTED_EXTENSIONS += XZ_EXTENSIONS
39 | except ImportError:
40 |     logger.debug("lzma module is not available")
41 | 
42 | 
43 | def current_umask() -> int:
44 |     """Get the current umask which involves having to set it temporarily."""
45 |     mask = os.umask(0)
46 |     os.umask(mask)
47 |     return mask
48 | 
49 | 
50 | def split_leading_dir(path: str) -> List[str]:
51 |     path = path.lstrip("/").lstrip("\\")
52 |     if "/" in path and (
53 |         ("\\" in path and path.find("/") < path.find("\\")) or "\\" not in path
54 |     ):
55 |         return path.split("/", 1)
56 |     elif "\\" in path:
57 |         return path.split("\\", 1)
58 |     else:
59 |         return [path, ""]
60 | 
61 | 
62 | def has_leading_dir(paths: Iterable[str]) -> bool:
63 |     """Returns true if all the paths have the same leading path name
64 |     (i.e., everything is in one subdirectory in an archive)"""
65 |     common_prefix = None
66 |     for path in paths:
67 |         prefix, rest = split_leading_dir(path)
68 |         if not prefix:
69 |             return False
70 |         elif common_prefix is None:
71 |             common_prefix = prefix
72 |         elif prefix != common_prefix:
73 |             return False
74 |     return True
75 | 
76 | 
77 | def is_within_directory(directory: str, target: str) -> bool:
78 |     """
79 |     Return true if the absolute path of target is within the directory
80 |     """
81 |     abs_directory = os.path.abspath(directory)
82 |     abs_target = os.path.abspath(target)
83 | 
84 |     prefix = os.path.commonprefix([abs_directory, abs_target])
85 |     return prefix == abs_directory
86 | 
87 | 
88 | def _get_default_mode_plus_executable() -> int:
89 |     return 0o777 & ~current_umask() | 0o111
90 | 
91 | 
92 | def set_extracted_file_to_default_mode_plus_executable(path: str) -> None:
93 |     """
94 |     Make file present at path have execute for user/group/world
95 |     (chmod +x) is no-op on windows per python docs
96 |     """
97 |     os.chmod(path, _get_default_mode_plus_executable())
98 | 
99 | 
100 | def zip_item_is_executable(info: ZipInfo) -> bool:
101 |     mode = info.external_attr >> 16
102 |     # if mode and regular file and any execute permissions for
103 |     # user/group/world?
104 |     return bool(mode and stat.S_ISREG(mode) and mode & 0o111)
105 | 
106 | 
107 | def unzip_file(filename: str, location: str, flatten: bool = True) -> None:
108 |     """
109 |     Unzip the file (with path `filename`) to the destination `location`.  All
110 |     files are written based on system defaults and umask (i.e. permissions are
111 |     not preserved), except that regular file members with any execute
112 |     permissions (user, group, or world) have "chmod +x" applied after being
113 |     written. Note that for windows, any execute changes using os.chmod are
114 |     no-ops per the python docs.
115 |     """
116 |     ensure_dir(location)
117 |     zipfp = open(filename, "rb")
118 |     try:
119 |         zip = zipfile.ZipFile(zipfp, allowZip64=True)
120 |         leading = has_leading_dir(zip.namelist()) and flatten
121 |         for info in zip.infolist():
122 |             name = info.filename
123 |             fn = name
124 |             if leading:
125 |                 fn = split_leading_dir(name)[1]
126 |             fn = os.path.join(location, fn)
127 |             dir = os.path.dirname(fn)
128 |             if not is_within_directory(location, fn):
129 |                 message = (
130 |                     "The zip file ({}) has a file ({}) trying to install "
131 |                     "outside target directory ({})"
132 |                 )
133 |                 raise InstallationError(message.format(filename, fn, location))
134 |             if fn.endswith("/") or fn.endswith("\\"):
135 |                 # A directory
136 |                 ensure_dir(fn)
137 |             else:
138 |                 ensure_dir(dir)
139 |                 # Don't use read() to avoid allocating an arbitrarily large
140 |                 # chunk of memory for the file's content
141 |                 fp = zip.open(name)
142 |                 try:
143 |                     with open(fn, "wb") as destfp:
144 |                         shutil.copyfileobj(fp, destfp)
145 |                 finally:
146 |                     fp.close()
147 |                     if zip_item_is_executable(info):
148 |                         set_extracted_file_to_default_mode_plus_executable(fn)
149 |     finally:
150 |         zipfp.close()
151 | 
152 | 
153 | def untar_file(filename: str, location: str) -> None:
154 |     """
155 |     Untar the file (with path `filename`) to the destination `location`.
156 |     All files are written based on system defaults and umask (i.e. permissions
157 |     are not preserved), except that regular file members with any execute
158 |     permissions (user, group, or world) have "chmod +x" applied on top of the
159 |     default.  Note that for windows, any execute changes using os.chmod are
160 |     no-ops per the python docs.
161 |     """
162 |     ensure_dir(location)
163 |     if filename.lower().endswith(".gz") or filename.lower().endswith(".tgz"):
164 |         mode = "r:gz"
165 |     elif filename.lower().endswith(BZ2_EXTENSIONS):
166 |         mode = "r:bz2"
167 |     elif filename.lower().endswith(XZ_EXTENSIONS):
168 |         mode = "r:xz"
169 |     elif filename.lower().endswith(".tar"):
170 |         mode = "r"
171 |     else:
172 |         logger.warning(
173 |             "Cannot determine compression type for file %s",
174 |             filename,
175 |         )
176 |         mode = "r:*"
177 | 
178 |     tar = tarfile.open(filename, mode, encoding="utf-8")  # type: ignore
179 |     try:
180 |         leading = has_leading_dir([member.name for member in tar.getmembers()])
181 | 
182 |         # PEP 706 added `tarfile.data_filter`, and made some other changes to
183 |         # Python's tarfile module (see below). The features were backported to
184 |         # security releases.
185 |         try:
186 |             data_filter = tarfile.data_filter
187 |         except AttributeError:
188 |             _untar_without_filter(filename, location, tar, leading)
189 |         else:
190 |             default_mode_plus_executable = _get_default_mode_plus_executable()
191 | 
192 |             if leading:
193 |                 # Strip the leading directory from all files in the archive,
194 |                 # including hardlink targets (which are relative to the
195 |                 # unpack location).
196 |                 for member in tar.getmembers():
197 |                     name_lead, name_rest = split_leading_dir(member.name)
198 |                     member.name = name_rest
199 |                     if member.islnk():
200 |                         lnk_lead, lnk_rest = split_leading_dir(member.linkname)
201 |                         if lnk_lead == name_lead:
202 |                             member.linkname = lnk_rest
203 | 
204 |             def pip_filter(member: tarfile.TarInfo, path: str) -> tarfile.TarInfo:
205 |                 orig_mode = member.mode
206 |                 try:
207 |                     try:
208 |                         member = data_filter(member, location)
209 |                     except tarfile.LinkOutsideDestinationError:
210 |                         if sys.version_info[:3] in {
211 |                             (3, 9, 17),
212 |                             (3, 10, 12),
213 |                             (3, 11, 4),
214 |                         }:
215 |                             # The tarfile filter in specific Python versions
216 |                             # raises LinkOutsideDestinationError on valid input
217 |                             # (https://github.com/python/cpython/issues/107845)
218 |                             # Ignore the error there, but do use the
219 |                             # more lax `tar_filter`
220 |                             member = tarfile.tar_filter(member, location)
221 |                         else:
222 |                             raise
223 |                 except tarfile.TarError as exc:
224 |                     message = "Invalid member in the tar file {}: {}"
225 |                     # Filter error messages mention the member name.
226 |                     # No need to add it here.
227 |                     raise InstallationError(
228 |                         message.format(
229 |                             filename,
230 |                             exc,
231 |                         )
232 |                     )
233 |                 if member.isfile() and orig_mode & 0o111:
234 |                     member.mode = default_mode_plus_executable
235 |                 else:
236 |                     # See PEP 706 note above.
237 |                     # The PEP changed this from `int` to `Optional[int]`,
238 |                     # where None means "use the default". Mypy doesn't
239 |                     # know this yet.
240 |                     member.mode = None  # type: ignore [assignment]
241 |                 return member
242 | 
243 |             tar.extractall(location, filter=pip_filter)
244 | 
245 |     finally:
246 |         tar.close()
247 | 
248 | 
249 | def _untar_without_filter(
250 |     filename: str,
251 |     location: str,
252 |     tar: tarfile.TarFile,
253 |     leading: bool,
254 | ) -> None:
255 |     """Fallback for Python without tarfile.data_filter"""
256 |     for member in tar.getmembers():
257 |         fn = member.name
258 |         if leading:
259 |             fn = split_leading_dir(fn)[1]
260 |         path = os.path.join(location, fn)
261 |         if not is_within_directory(location, path):
262 |             message = (
263 |                 "The tar file ({}) has a file ({}) trying to install "
264 |                 "outside target directory ({})"
265 |             )
266 |             raise InstallationError(message.format(filename, path, location))
267 |         if member.isdir():
268 |             ensure_dir(path)
269 |         elif member.issym():
270 |             try:
271 |                 tar._extract_member(member, path)
272 |             except Exception as exc:
273 |                 # Some corrupt tar files seem to produce this
274 |                 # (specifically bad symlinks)
275 |                 logger.warning(
276 |                     "In the tar file %s the member %s is invalid: %s",
277 |                     filename,
278 |                     member.name,
279 |                     exc,
280 |                 )
281 |                 continue
282 |         else:
283 |             try:
284 |                 fp = tar.extractfile(member)
285 |             except (KeyError, AttributeError) as exc:
286 |                 # Some corrupt tar files seem to produce this
287 |                 # (specifically bad symlinks)
288 |                 logger.warning(
289 |                     "In the tar file %s the member %s is invalid: %s",
290 |                     filename,
291 |                     member.name,
292 |                     exc,
293 |                 )
294 |                 continue
295 |             ensure_dir(os.path.dirname(path))
296 |             assert fp is not None
297 |             with open(path, "wb") as destfp:
298 |                 shutil.copyfileobj(fp, destfp)
299 |             fp.close()
300 |             # Update the timestamp (useful for cython compiled files)
301 |             tar.utime(member, path)
302 |             # member have any execute permissions for user/group/world?
303 |             if member.mode & 0o111:
304 |                 set_extracted_file_to_default_mode_plus_executable(path)
305 | 
306 | 
307 | def unpack_file(
308 |     filename: str,
309 |     location: str,
310 |     content_type: Optional[str] = None,
311 | ) -> None:
312 |     filename = os.path.realpath(filename)
313 |     if (
314 |         content_type == "application/zip"
315 |         or filename.lower().endswith(ZIP_EXTENSIONS)
316 |         or zipfile.is_zipfile(filename)
317 |     ):
318 |         unzip_file(filename, location, flatten=not filename.endswith(".whl"))
319 |     elif (
320 |         content_type == "application/x-gzip"
321 |         or tarfile.is_tarfile(filename)
322 |         or filename.lower().endswith(TAR_EXTENSIONS + BZ2_EXTENSIONS + XZ_EXTENSIONS)
323 |     ):
324 |         untar_file(filename, location)
325 |     else:
326 |         # FIXME: handle?
327 |         # FIXME: magic signatures?
328 |         logger.critical(
329 |             "Cannot unpack file %s (downloaded from %s, content-type: %s); "
330 |             "cannot detect archive format",
331 |             filename,
332 |             location,
333 |             content_type,
334 |         )
335 |         raise InstallationError(f"Cannot determine archive format of {location}")
```

.venv/lib/python3.13/site-packages/pip/_internal/utils/urls.py
```
1 | import os
2 | import string
3 | import urllib.parse
4 | import urllib.request
5 | 
6 | from .compat import WINDOWS
7 | 
8 | 
9 | def path_to_url(path: str) -> str:
10 |     """
11 |     Convert a path to a file: URL.  The path will be made absolute and have
12 |     quoted path parts.
13 |     """
14 |     path = os.path.normpath(os.path.abspath(path))
15 |     url = urllib.parse.urljoin("file:", urllib.request.pathname2url(path))
16 |     return url
17 | 
18 | 
19 | def url_to_path(url: str) -> str:
20 |     """
21 |     Convert a file: URL to a path.
22 |     """
23 |     assert url.startswith(
24 |         "file:"
25 |     ), f"You can only turn file: urls into filenames (not {url!r})"
26 | 
27 |     _, netloc, path, _, _ = urllib.parse.urlsplit(url)
28 | 
29 |     if not netloc or netloc == "localhost":
30 |         # According to RFC 8089, same as empty authority.
31 |         netloc = ""
32 |     elif WINDOWS:
33 |         # If we have a UNC path, prepend UNC share notation.
34 |         netloc = "\\\\" + netloc
35 |     else:
36 |         raise ValueError(
37 |             f"non-local file URIs are not supported on this platform: {url!r}"
38 |         )
39 | 
40 |     path = urllib.request.url2pathname(netloc + path)
41 | 
42 |     # On Windows, urlsplit parses the path as something like "/C:/Users/foo".
43 |     # This creates issues for path-related functions like io.open(), so we try
44 |     # to detect and strip the leading slash.
45 |     if (
46 |         WINDOWS
47 |         and not netloc  # Not UNC.
48 |         and len(path) >= 3
49 |         and path[0] == "/"  # Leading slash to strip.
50 |         and path[1] in string.ascii_letters  # Drive letter.
51 |         and path[2:4] in (":", ":/")  # Colon + end of string, or colon + absolute path.
52 |     ):
53 |         path = path[1:]
54 | 
55 |     return path
```

.venv/lib/python3.13/site-packages/pip/_internal/utils/virtualenv.py
```
1 | import logging
2 | import os
3 | import re
4 | import site
5 | import sys
6 | from typing import List, Optional
7 | 
8 | logger = logging.getLogger(__name__)
9 | _INCLUDE_SYSTEM_SITE_PACKAGES_REGEX = re.compile(
10 |     r"include-system-site-packages\s*=\s*(?P<value>true|false)"
11 | )
12 | 
13 | 
14 | def _running_under_venv() -> bool:
15 |     """Checks if sys.base_prefix and sys.prefix match.
16 | 
17 |     This handles PEP 405 compliant virtual environments.
18 |     """
19 |     return sys.prefix != getattr(sys, "base_prefix", sys.prefix)
20 | 
21 | 
22 | def _running_under_legacy_virtualenv() -> bool:
23 |     """Checks if sys.real_prefix is set.
24 | 
25 |     This handles virtual environments created with pypa's virtualenv.
26 |     """
27 |     # pypa/virtualenv case
28 |     return hasattr(sys, "real_prefix")
29 | 
30 | 
31 | def running_under_virtualenv() -> bool:
32 |     """True if we're running inside a virtual environment, False otherwise."""
33 |     return _running_under_venv() or _running_under_legacy_virtualenv()
34 | 
35 | 
36 | def _get_pyvenv_cfg_lines() -> Optional[List[str]]:
37 |     """Reads {sys.prefix}/pyvenv.cfg and returns its contents as list of lines
38 | 
39 |     Returns None, if it could not read/access the file.
40 |     """
41 |     pyvenv_cfg_file = os.path.join(sys.prefix, "pyvenv.cfg")
42 |     try:
43 |         # Although PEP 405 does not specify, the built-in venv module always
44 |         # writes with UTF-8. (pypa/pip#8717)
45 |         with open(pyvenv_cfg_file, encoding="utf-8") as f:
46 |             return f.read().splitlines()  # avoids trailing newlines
47 |     except OSError:
48 |         return None
49 | 
50 | 
51 | def _no_global_under_venv() -> bool:
52 |     """Check `{sys.prefix}/pyvenv.cfg` for system site-packages inclusion
53 | 
54 |     PEP 405 specifies that when system site-packages are not supposed to be
55 |     visible from a virtual environment, `pyvenv.cfg` must contain the following
56 |     line:
57 | 
58 |         include-system-site-packages = false
59 | 
60 |     Additionally, log a warning if accessing the file fails.
61 |     """
62 |     cfg_lines = _get_pyvenv_cfg_lines()
63 |     if cfg_lines is None:
64 |         # We're not in a "sane" venv, so assume there is no system
65 |         # site-packages access (since that's PEP 405's default state).
66 |         logger.warning(
67 |             "Could not access 'pyvenv.cfg' despite a virtual environment "
68 |             "being active. Assuming global site-packages is not accessible "
69 |             "in this environment."
70 |         )
71 |         return True
72 | 
73 |     for line in cfg_lines:
74 |         match = _INCLUDE_SYSTEM_SITE_PACKAGES_REGEX.match(line)
75 |         if match is not None and match.group("value") == "false":
76 |             return True
77 |     return False
78 | 
79 | 
80 | def _no_global_under_legacy_virtualenv() -> bool:
81 |     """Check if "no-global-site-packages.txt" exists beside site.py
82 | 
83 |     This mirrors logic in pypa/virtualenv for determining whether system
84 |     site-packages are visible in the virtual environment.
85 |     """
86 |     site_mod_dir = os.path.dirname(os.path.abspath(site.__file__))
87 |     no_global_site_packages_file = os.path.join(
88 |         site_mod_dir,
89 |         "no-global-site-packages.txt",
90 |     )
91 |     return os.path.exists(no_global_site_packages_file)
92 | 
93 | 
94 | def virtualenv_no_global() -> bool:
95 |     """Returns a boolean, whether running in venv with no system site-packages."""
96 |     # PEP 405 compliance needs to be checked first since virtualenv >=20 would
97 |     # return True for both checks, but is only able to use the PEP 405 config.
98 |     if _running_under_venv():
99 |         return _no_global_under_venv()
100 | 
101 |     if _running_under_legacy_virtualenv():
102 |         return _no_global_under_legacy_virtualenv()
103 | 
104 |     return False
```

.venv/lib/python3.13/site-packages/pip/_internal/utils/wheel.py
```
1 | """Support functions for working with wheel files."""
2 | 
3 | import logging
4 | from email.message import Message
5 | from email.parser import Parser
6 | from typing import Tuple
7 | from zipfile import BadZipFile, ZipFile
8 | 
9 | from pip._vendor.packaging.utils import canonicalize_name
10 | 
11 | from pip._internal.exceptions import UnsupportedWheel
12 | 
13 | VERSION_COMPATIBLE = (1, 0)
14 | 
15 | 
16 | logger = logging.getLogger(__name__)
17 | 
18 | 
19 | def parse_wheel(wheel_zip: ZipFile, name: str) -> Tuple[str, Message]:
20 |     """Extract information from the provided wheel, ensuring it meets basic
21 |     standards.
22 | 
23 |     Returns the name of the .dist-info directory and the parsed WHEEL metadata.
24 |     """
25 |     try:
26 |         info_dir = wheel_dist_info_dir(wheel_zip, name)
27 |         metadata = wheel_metadata(wheel_zip, info_dir)
28 |         version = wheel_version(metadata)
29 |     except UnsupportedWheel as e:
30 |         raise UnsupportedWheel(f"{name} has an invalid wheel, {e}")
31 | 
32 |     check_compatibility(version, name)
33 | 
34 |     return info_dir, metadata
35 | 
36 | 
37 | def wheel_dist_info_dir(source: ZipFile, name: str) -> str:
38 |     """Returns the name of the contained .dist-info directory.
39 | 
40 |     Raises AssertionError or UnsupportedWheel if not found, >1 found, or
41 |     it doesn't match the provided name.
42 |     """
43 |     # Zip file path separators must be /
44 |     subdirs = {p.split("/", 1)[0] for p in source.namelist()}
45 | 
46 |     info_dirs = [s for s in subdirs if s.endswith(".dist-info")]
47 | 
48 |     if not info_dirs:
49 |         raise UnsupportedWheel(".dist-info directory not found")
50 | 
51 |     if len(info_dirs) > 1:
52 |         raise UnsupportedWheel(
53 |             "multiple .dist-info directories found: {}".format(", ".join(info_dirs))
54 |         )
55 | 
56 |     info_dir = info_dirs[0]
57 | 
58 |     info_dir_name = canonicalize_name(info_dir)
59 |     canonical_name = canonicalize_name(name)
60 |     if not info_dir_name.startswith(canonical_name):
61 |         raise UnsupportedWheel(
62 |             f".dist-info directory {info_dir!r} does not start with {canonical_name!r}"
63 |         )
64 | 
65 |     return info_dir
66 | 
67 | 
68 | def read_wheel_metadata_file(source: ZipFile, path: str) -> bytes:
69 |     try:
70 |         return source.read(path)
71 |         # BadZipFile for general corruption, KeyError for missing entry,
72 |         # and RuntimeError for password-protected files
73 |     except (BadZipFile, KeyError, RuntimeError) as e:
74 |         raise UnsupportedWheel(f"could not read {path!r} file: {e!r}")
75 | 
76 | 
77 | def wheel_metadata(source: ZipFile, dist_info_dir: str) -> Message:
78 |     """Return the WHEEL metadata of an extracted wheel, if possible.
79 |     Otherwise, raise UnsupportedWheel.
80 |     """
81 |     path = f"{dist_info_dir}/WHEEL"
82 |     # Zip file path separators must be /
83 |     wheel_contents = read_wheel_metadata_file(source, path)
84 | 
85 |     try:
86 |         wheel_text = wheel_contents.decode()
87 |     except UnicodeDecodeError as e:
88 |         raise UnsupportedWheel(f"error decoding {path!r}: {e!r}")
89 | 
90 |     # FeedParser (used by Parser) does not raise any exceptions. The returned
91 |     # message may have .defects populated, but for backwards-compatibility we
92 |     # currently ignore them.
93 |     return Parser().parsestr(wheel_text)
94 | 
95 | 
96 | def wheel_version(wheel_data: Message) -> Tuple[int, ...]:
97 |     """Given WHEEL metadata, return the parsed Wheel-Version.
98 |     Otherwise, raise UnsupportedWheel.
99 |     """
100 |     version_text = wheel_data["Wheel-Version"]
101 |     if version_text is None:
102 |         raise UnsupportedWheel("WHEEL is missing Wheel-Version")
103 | 
104 |     version = version_text.strip()
105 | 
106 |     try:
107 |         return tuple(map(int, version.split(".")))
108 |     except ValueError:
109 |         raise UnsupportedWheel(f"invalid Wheel-Version: {version!r}")
110 | 
111 | 
112 | def check_compatibility(version: Tuple[int, ...], name: str) -> None:
113 |     """Raises errors or warns if called with an incompatible Wheel-Version.
114 | 
115 |     pip should refuse to install a Wheel-Version that's a major series
116 |     ahead of what it's compatible with (e.g 2.0 > 1.1); and warn when
117 |     installing a version only minor version ahead (e.g 1.2 > 1.1).
118 | 
119 |     version: a 2-tuple representing a Wheel-Version (Major, Minor)
120 |     name: name of wheel or package to raise exception about
121 | 
122 |     :raises UnsupportedWheel: when an incompatible Wheel-Version is given
123 |     """
124 |     if version[0] > VERSION_COMPATIBLE[0]:
125 |         raise UnsupportedWheel(
126 |             "{}'s Wheel-Version ({}) is not compatible with this version "
127 |             "of pip".format(name, ".".join(map(str, version)))
128 |         )
129 |     elif version > VERSION_COMPATIBLE:
130 |         logger.warning(
131 |             "Installing from a newer Wheel-Version (%s)",
132 |             ".".join(map(str, version)),
133 |         )
```

.venv/lib/python3.13/site-packages/pip/_vendor/dependency_groups/__init__.py
```
1 | from ._implementation import (
2 |     CyclicDependencyError,
3 |     DependencyGroupInclude,
4 |     DependencyGroupResolver,
5 |     resolve,
6 | )
7 | 
8 | __all__ = (
9 |     "CyclicDependencyError",
10 |     "DependencyGroupInclude",
11 |     "DependencyGroupResolver",
12 |     "resolve",
13 | )
```

.venv/lib/python3.13/site-packages/pip/_vendor/dependency_groups/__main__.py
```
1 | import argparse
2 | import sys
3 | 
4 | from ._implementation import resolve
5 | from ._toml_compat import tomllib
6 | 
7 | 
8 | def main() -> None:
9 |     if tomllib is None:
10 |         print(
11 |             "Usage error: dependency-groups CLI requires tomli or Python 3.11+",
12 |             file=sys.stderr,
13 |         )
14 |         raise SystemExit(2)
15 | 
16 |     parser = argparse.ArgumentParser(
17 |         description=(
18 |             "A dependency-groups CLI. Prints out a resolved group, newline-delimited."
19 |         )
20 |     )
21 |     parser.add_argument(
22 |         "GROUP_NAME", nargs="*", help="The dependency group(s) to resolve."
23 |     )
24 |     parser.add_argument(
25 |         "-f",
26 |         "--pyproject-file",
27 |         default="pyproject.toml",
28 |         help="The pyproject.toml file. Defaults to trying in the current directory.",
29 |     )
30 |     parser.add_argument(
31 |         "-o",
32 |         "--output",
33 |         help="An output file. Defaults to stdout.",
34 |     )
35 |     parser.add_argument(
36 |         "-l",
37 |         "--list",
38 |         action="store_true",
39 |         help="List the available dependency groups",
40 |     )
41 |     args = parser.parse_args()
42 | 
43 |     with open(args.pyproject_file, "rb") as fp:
44 |         pyproject = tomllib.load(fp)
45 | 
46 |     dependency_groups_raw = pyproject.get("dependency-groups", {})
47 | 
48 |     if args.list:
49 |         print(*dependency_groups_raw.keys())
50 |         return
51 |     if not args.GROUP_NAME:
52 |         print("A GROUP_NAME is required", file=sys.stderr)
53 |         raise SystemExit(3)
54 | 
55 |     content = "\n".join(resolve(dependency_groups_raw, *args.GROUP_NAME))
56 | 
57 |     if args.output is None or args.output == "-":
58 |         print(content)
59 |     else:
60 |         with open(args.output, "w", encoding="utf-8") as fp:
61 |             print(content, file=fp)
62 | 
63 | 
64 | if __name__ == "__main__":
65 |     main()
```

.venv/lib/python3.13/site-packages/pip/_vendor/dependency_groups/_implementation.py
```
1 | from __future__ import annotations
2 | 
3 | import dataclasses
4 | import re
5 | from collections.abc import Mapping
6 | 
7 | from pip._vendor.packaging.requirements import Requirement
8 | 
9 | 
10 | def _normalize_name(name: str) -> str:
11 |     return re.sub(r"[-_.]+", "-", name).lower()
12 | 
13 | 
14 | def _normalize_group_names(
15 |     dependency_groups: Mapping[str, str | Mapping[str, str]],
16 | ) -> Mapping[str, str | Mapping[str, str]]:
17 |     original_names: dict[str, list[str]] = {}
18 |     normalized_groups = {}
19 | 
20 |     for group_name, value in dependency_groups.items():
21 |         normed_group_name = _normalize_name(group_name)
22 |         original_names.setdefault(normed_group_name, []).append(group_name)
23 |         normalized_groups[normed_group_name] = value
24 | 
25 |     errors = []
26 |     for normed_name, names in original_names.items():
27 |         if len(names) > 1:
28 |             errors.append(f"{normed_name} ({', '.join(names)})")
29 |     if errors:
30 |         raise ValueError(f"Duplicate dependency group names: {', '.join(errors)}")
31 | 
32 |     return normalized_groups
33 | 
34 | 
35 | @dataclasses.dataclass
36 | class DependencyGroupInclude:
37 |     include_group: str
38 | 
39 | 
40 | class CyclicDependencyError(ValueError):
41 |     """
42 |     An error representing the detection of a cycle.
43 |     """
44 | 
45 |     def __init__(self, requested_group: str, group: str, include_group: str) -> None:
46 |         self.requested_group = requested_group
47 |         self.group = group
48 |         self.include_group = include_group
49 | 
50 |         if include_group == group:
51 |             reason = f"{group} includes itself"
52 |         else:
53 |             reason = f"{include_group} -> {group}, {group} -> {include_group}"
54 |         super().__init__(
55 |             "Cyclic dependency group include while resolving "
56 |             f"{requested_group}: {reason}"
57 |         )
58 | 
59 | 
60 | class DependencyGroupResolver:
61 |     """
62 |     A resolver for Dependency Group data.
63 | 
64 |     This class handles caching, name normalization, cycle detection, and other
65 |     parsing requirements. There are only two public methods for exploring the data:
66 |     ``lookup()`` and ``resolve()``.
67 | 
68 |     :param dependency_groups: A mapping, as provided via pyproject
69 |         ``[dependency-groups]``.
70 |     """
71 | 
72 |     def __init__(
73 |         self,
74 |         dependency_groups: Mapping[str, str | Mapping[str, str]],
75 |     ) -> None:
76 |         if not isinstance(dependency_groups, Mapping):
77 |             raise TypeError("Dependency Groups table is not a mapping")
78 |         self.dependency_groups = _normalize_group_names(dependency_groups)
79 |         # a map of group names to parsed data
80 |         self._parsed_groups: dict[
81 |             str, tuple[Requirement | DependencyGroupInclude, ...]
82 |         ] = {}
83 |         # a map of group names to their ancestors, used for cycle detection
84 |         self._include_graph_ancestors: dict[str, tuple[str, ...]] = {}
85 |         # a cache of completed resolutions to Requirement lists
86 |         self._resolve_cache: dict[str, tuple[Requirement, ...]] = {}
87 | 
88 |     def lookup(self, group: str) -> tuple[Requirement | DependencyGroupInclude, ...]:
89 |         """
90 |         Lookup a group name, returning the parsed dependency data for that group.
91 |         This will not resolve includes.
92 | 
93 |         :param group: the name of the group to lookup
94 | 
95 |         :raises ValueError: if the data does not appear to be valid dependency group
96 |             data
97 |         :raises TypeError: if the data is not a string
98 |         :raises LookupError: if group name is absent
99 |         :raises packaging.requirements.InvalidRequirement: if a specifier is not valid
100 |         """
101 |         if not isinstance(group, str):
102 |             raise TypeError("Dependency group name is not a str")
103 |         group = _normalize_name(group)
104 |         return self._parse_group(group)
105 | 
106 |     def resolve(self, group: str) -> tuple[Requirement, ...]:
107 |         """
108 |         Resolve a dependency group to a list of requirements.
109 | 
110 |         :param group: the name of the group to resolve
111 | 
112 |         :raises TypeError: if the inputs appear to be the wrong types
113 |         :raises ValueError: if the data does not appear to be valid dependency group
114 |             data
115 |         :raises LookupError: if group name is absent
116 |         :raises packaging.requirements.InvalidRequirement: if a specifier is not valid
117 |         """
118 |         if not isinstance(group, str):
119 |             raise TypeError("Dependency group name is not a str")
120 |         group = _normalize_name(group)
121 |         return self._resolve(group, group)
122 | 
123 |     def _parse_group(
124 |         self, group: str
125 |     ) -> tuple[Requirement | DependencyGroupInclude, ...]:
126 |         # short circuit -- never do the work twice
127 |         if group in self._parsed_groups:
128 |             return self._parsed_groups[group]
129 | 
130 |         if group not in self.dependency_groups:
131 |             raise LookupError(f"Dependency group '{group}' not found")
132 | 
133 |         raw_group = self.dependency_groups[group]
134 |         if not isinstance(raw_group, list):
135 |             raise TypeError(f"Dependency group '{group}' is not a list")
136 | 
137 |         elements: list[Requirement | DependencyGroupInclude] = []
138 |         for item in raw_group:
139 |             if isinstance(item, str):
140 |                 # packaging.requirements.Requirement parsing ensures that this is a
141 |                 # valid PEP 508 Dependency Specifier
142 |                 # raises InvalidRequirement on failure
143 |                 elements.append(Requirement(item))
144 |             elif isinstance(item, dict):
145 |                 if tuple(item.keys()) != ("include-group",):
146 |                     raise ValueError(f"Invalid dependency group item: {item}")
147 | 
148 |                 include_group = next(iter(item.values()))
149 |                 elements.append(DependencyGroupInclude(include_group=include_group))
150 |             else:
151 |                 raise ValueError(f"Invalid dependency group item: {item}")
152 | 
153 |         self._parsed_groups[group] = tuple(elements)
154 |         return self._parsed_groups[group]
155 | 
156 |     def _resolve(self, group: str, requested_group: str) -> tuple[Requirement, ...]:
157 |         """
158 |         This is a helper for cached resolution to strings.
159 | 
160 |         :param group: The name of the group to resolve.
161 |         :param requested_group: The group which was used in the original, user-facing
162 |             request.
163 |         """
164 |         if group in self._resolve_cache:
165 |             return self._resolve_cache[group]
166 | 
167 |         parsed = self._parse_group(group)
168 | 
169 |         resolved_group = []
170 |         for item in parsed:
171 |             if isinstance(item, Requirement):
172 |                 resolved_group.append(item)
173 |             elif isinstance(item, DependencyGroupInclude):
174 |                 include_group = _normalize_name(item.include_group)
175 |                 if include_group in self._include_graph_ancestors.get(group, ()):
176 |                     raise CyclicDependencyError(
177 |                         requested_group, group, item.include_group
178 |                     )
179 |                 self._include_graph_ancestors[include_group] = (
180 |                     *self._include_graph_ancestors.get(group, ()),
181 |                     group,
182 |                 )
183 |                 resolved_group.extend(self._resolve(include_group, requested_group))
184 |             else:  # unreachable
185 |                 raise NotImplementedError(
186 |                     f"Invalid dependency group item after parse: {item}"
187 |                 )
188 | 
189 |         self._resolve_cache[group] = tuple(resolved_group)
190 |         return self._resolve_cache[group]
191 | 
192 | 
193 | def resolve(
194 |     dependency_groups: Mapping[str, str | Mapping[str, str]], /, *groups: str
195 | ) -> tuple[str, ...]:
196 |     """
197 |     Resolve a dependency group to a tuple of requirements, as strings.
198 | 
199 |     :param dependency_groups: the parsed contents of the ``[dependency-groups]`` table
200 |         from ``pyproject.toml``
201 |     :param groups: the name of the group(s) to resolve
202 | 
203 |     :raises TypeError: if the inputs appear to be the wrong types
204 |     :raises ValueError: if the data does not appear to be valid dependency group data
205 |     :raises LookupError: if group name is absent
206 |     :raises packaging.requirements.InvalidRequirement: if a specifier is not valid
207 |     """
208 |     resolver = DependencyGroupResolver(dependency_groups)
209 |     return tuple(str(r) for group in groups for r in resolver.resolve(group))
```

.venv/lib/python3.13/site-packages/pip/_vendor/dependency_groups/_lint_dependency_groups.py
```
1 | from __future__ import annotations
2 | 
3 | import argparse
4 | import sys
5 | 
6 | from ._implementation import DependencyGroupResolver
7 | from ._toml_compat import tomllib
8 | 
9 | 
10 | def main(*, argv: list[str] | None = None) -> None:
11 |     if tomllib is None:
12 |         print(
13 |             "Usage error: dependency-groups CLI requires tomli or Python 3.11+",
14 |             file=sys.stderr,
15 |         )
16 |         raise SystemExit(2)
17 | 
18 |     parser = argparse.ArgumentParser(
19 |         description=(
20 |             "Lint Dependency Groups for validity. "
21 |             "This will eagerly load and check all of your Dependency Groups."
22 |         )
23 |     )
24 |     parser.add_argument(
25 |         "-f",
26 |         "--pyproject-file",
27 |         default="pyproject.toml",
28 |         help="The pyproject.toml file. Defaults to trying in the current directory.",
29 |     )
30 |     args = parser.parse_args(argv if argv is not None else sys.argv[1:])
31 | 
32 |     with open(args.pyproject_file, "rb") as fp:
33 |         pyproject = tomllib.load(fp)
34 |     dependency_groups_raw = pyproject.get("dependency-groups", {})
35 | 
36 |     errors: list[str] = []
37 |     try:
38 |         resolver = DependencyGroupResolver(dependency_groups_raw)
39 |     except (ValueError, TypeError) as e:
40 |         errors.append(f"{type(e).__name__}: {e}")
41 |     else:
42 |         for groupname in resolver.dependency_groups:
43 |             try:
44 |                 resolver.resolve(groupname)
45 |             except (LookupError, ValueError, TypeError) as e:
46 |                 errors.append(f"{type(e).__name__}: {e}")
47 | 
48 |     if errors:
49 |         print("errors encountered while examining dependency groups:")
50 |         for msg in errors:
51 |             print(f"  {msg}")
52 |         sys.exit(1)
53 |     else:
54 |         print("ok")
55 |         sys.exit(0)
56 | 
57 | 
58 | if __name__ == "__main__":
59 |     main()
```

.venv/lib/python3.13/site-packages/pip/_vendor/dependency_groups/_pip_wrapper.py
```
1 | from __future__ import annotations
2 | 
3 | import argparse
4 | import subprocess
5 | import sys
6 | 
7 | from ._implementation import DependencyGroupResolver
8 | from ._toml_compat import tomllib
9 | 
10 | 
11 | def _invoke_pip(deps: list[str]) -> None:
12 |     subprocess.check_call([sys.executable, "-m", "pip", "install", *deps])
13 | 
14 | 
15 | def main(*, argv: list[str] | None = None) -> None:
16 |     if tomllib is None:
17 |         print(
18 |             "Usage error: dependency-groups CLI requires tomli or Python 3.11+",
19 |             file=sys.stderr,
20 |         )
21 |         raise SystemExit(2)
22 | 
23 |     parser = argparse.ArgumentParser(description="Install Dependency Groups.")
24 |     parser.add_argument(
25 |         "DEPENDENCY_GROUP", nargs="+", help="The dependency groups to install."
26 |     )
27 |     parser.add_argument(
28 |         "-f",
29 |         "--pyproject-file",
30 |         default="pyproject.toml",
31 |         help="The pyproject.toml file. Defaults to trying in the current directory.",
32 |     )
33 |     args = parser.parse_args(argv if argv is not None else sys.argv[1:])
34 | 
35 |     with open(args.pyproject_file, "rb") as fp:
36 |         pyproject = tomllib.load(fp)
37 |     dependency_groups_raw = pyproject.get("dependency-groups", {})
38 | 
39 |     errors: list[str] = []
40 |     resolved: list[str] = []
41 |     try:
42 |         resolver = DependencyGroupResolver(dependency_groups_raw)
43 |     except (ValueError, TypeError) as e:
44 |         errors.append(f"{type(e).__name__}: {e}")
45 |     else:
46 |         for groupname in args.DEPENDENCY_GROUP:
47 |             try:
48 |                 resolved.extend(str(r) for r in resolver.resolve(groupname))
49 |             except (LookupError, ValueError, TypeError) as e:
50 |                 errors.append(f"{type(e).__name__}: {e}")
51 | 
52 |     if errors:
53 |         print("errors encountered while examining dependency groups:")
54 |         for msg in errors:
55 |             print(f"  {msg}")
56 |         sys.exit(1)
57 | 
58 |     _invoke_pip(resolved)
59 | 
60 | 
61 | if __name__ == "__main__":
62 |     main()
```

.venv/lib/python3.13/site-packages/pip/_vendor/dependency_groups/_toml_compat.py
```
1 | try:
2 |     import tomllib
3 | except ImportError:
4 |     try:
5 |         from pip._vendor import tomli as tomllib  # type: ignore[no-redef, unused-ignore]
6 |     except ModuleNotFoundError:  # pragma: no cover
7 |         tomllib = None  # type: ignore[assignment, unused-ignore]
8 | 
9 | __all__ = ("tomllib",)
```

.venv/lib/python3.13/site-packages/pip/_vendor/dependency_groups/py.typed
```
```

.venv/lib/python3.13/site-packages/pip/_vendor/distlib/__init__.py
```
1 | # -*- coding: utf-8 -*-
2 | #
3 | # Copyright (C) 2012-2023 Vinay Sajip.
4 | # Licensed to the Python Software Foundation under a contributor agreement.
5 | # See LICENSE.txt and CONTRIBUTORS.txt.
6 | #
7 | import logging
8 | 
9 | __version__ = '0.3.9'
10 | 
11 | 
12 | class DistlibException(Exception):
13 |     pass
14 | 
15 | 
16 | try:
17 |     from logging import NullHandler
18 | except ImportError:  # pragma: no cover
19 | 
20 |     class NullHandler(logging.Handler):
21 | 
22 |         def handle(self, record):
23 |             pass
24 | 
25 |         def emit(self, record):
26 |             pass
27 | 
28 |         def createLock(self):
29 |             self.lock = None
30 | 
31 | 
32 | logger = logging.getLogger(__name__)
33 | logger.addHandler(NullHandler())
```

.venv/lib/python3.13/site-packages/pip/_vendor/distlib/compat.py
```
1 | # -*- coding: utf-8 -*-
2 | #
3 | # Copyright (C) 2013-2017 Vinay Sajip.
4 | # Licensed to the Python Software Foundation under a contributor agreement.
5 | # See LICENSE.txt and CONTRIBUTORS.txt.
6 | #
7 | from __future__ import absolute_import
8 | 
9 | import os
10 | import re
11 | import shutil
12 | import sys
13 | 
14 | try:
15 |     import ssl
16 | except ImportError:  # pragma: no cover
17 |     ssl = None
18 | 
19 | if sys.version_info[0] < 3:  # pragma: no cover
20 |     from StringIO import StringIO
21 |     string_types = basestring,
22 |     text_type = unicode
23 |     from types import FileType as file_type
24 |     import __builtin__ as builtins
25 |     import ConfigParser as configparser
26 |     from urlparse import urlparse, urlunparse, urljoin, urlsplit, urlunsplit
27 |     from urllib import (urlretrieve, quote as _quote, unquote, url2pathname,
28 |                         pathname2url, ContentTooShortError, splittype)
29 | 
30 |     def quote(s):
31 |         if isinstance(s, unicode):
32 |             s = s.encode('utf-8')
33 |         return _quote(s)
34 | 
35 |     import urllib2
36 |     from urllib2 import (Request, urlopen, URLError, HTTPError,
37 |                          HTTPBasicAuthHandler, HTTPPasswordMgr, HTTPHandler,
38 |                          HTTPRedirectHandler, build_opener)
39 |     if ssl:
40 |         from urllib2 import HTTPSHandler
41 |     import httplib
42 |     import xmlrpclib
43 |     import Queue as queue
44 |     from HTMLParser import HTMLParser
45 |     import htmlentitydefs
46 |     raw_input = raw_input
47 |     from itertools import ifilter as filter
48 |     from itertools import ifilterfalse as filterfalse
49 | 
50 |     # Leaving this around for now, in case it needs resurrecting in some way
51 |     # _userprog = None
52 |     # def splituser(host):
53 |     # """splituser('user[:passwd]@host[:port]') --> 'user[:passwd]', 'host[:port]'."""
54 |     # global _userprog
55 |     # if _userprog is None:
56 |     # import re
57 |     # _userprog = re.compile('^(.*)@(.*)$')
58 | 
59 |     # match = _userprog.match(host)
60 |     # if match: return match.group(1, 2)
61 |     # return None, host
62 | 
63 | else:  # pragma: no cover
64 |     from io import StringIO
65 |     string_types = str,
66 |     text_type = str
67 |     from io import TextIOWrapper as file_type
68 |     import builtins
69 |     import configparser
70 |     from urllib.parse import (urlparse, urlunparse, urljoin, quote, unquote,
71 |                               urlsplit, urlunsplit, splittype)
72 |     from urllib.request import (urlopen, urlretrieve, Request, url2pathname,
73 |                                 pathname2url, HTTPBasicAuthHandler,
74 |                                 HTTPPasswordMgr, HTTPHandler,
75 |                                 HTTPRedirectHandler, build_opener)
76 |     if ssl:
77 |         from urllib.request import HTTPSHandler
78 |     from urllib.error import HTTPError, URLError, ContentTooShortError
79 |     import http.client as httplib
80 |     import urllib.request as urllib2
81 |     import xmlrpc.client as xmlrpclib
82 |     import queue
83 |     from html.parser import HTMLParser
84 |     import html.entities as htmlentitydefs
85 |     raw_input = input
86 |     from itertools import filterfalse
87 |     filter = filter
88 | 
89 | try:
90 |     from ssl import match_hostname, CertificateError
91 | except ImportError:  # pragma: no cover
92 | 
93 |     class CertificateError(ValueError):
94 |         pass
95 | 
96 |     def _dnsname_match(dn, hostname, max_wildcards=1):
97 |         """Matching according to RFC 6125, section 6.4.3
98 | 
99 |         http://tools.ietf.org/html/rfc6125#section-6.4.3
100 |         """
101 |         pats = []
102 |         if not dn:
103 |             return False
104 | 
105 |         parts = dn.split('.')
106 |         leftmost, remainder = parts[0], parts[1:]
107 | 
108 |         wildcards = leftmost.count('*')
109 |         if wildcards > max_wildcards:
110 |             # Issue #17980: avoid denials of service by refusing more
111 |             # than one wildcard per fragment.  A survey of established
112 |             # policy among SSL implementations showed it to be a
113 |             # reasonable choice.
114 |             raise CertificateError(
115 |                 "too many wildcards in certificate DNS name: " + repr(dn))
116 | 
117 |         # speed up common case w/o wildcards
118 |         if not wildcards:
119 |             return dn.lower() == hostname.lower()
120 | 
121 |         # RFC 6125, section 6.4.3, subitem 1.
122 |         # The client SHOULD NOT attempt to match a presented identifier in which
123 |         # the wildcard character comprises a label other than the left-most label.
124 |         if leftmost == '*':
125 |             # When '*' is a fragment by itself, it matches a non-empty dotless
126 |             # fragment.
127 |             pats.append('[^.]+')
128 |         elif leftmost.startswith('xn--') or hostname.startswith('xn--'):
129 |             # RFC 6125, section 6.4.3, subitem 3.
130 |             # The client SHOULD NOT attempt to match a presented identifier
131 |             # where the wildcard character is embedded within an A-label or
132 |             # U-label of an internationalized domain name.
133 |             pats.append(re.escape(leftmost))
134 |         else:
135 |             # Otherwise, '*' matches any dotless string, e.g. www*
136 |             pats.append(re.escape(leftmost).replace(r'\*', '[^.]*'))
137 | 
138 |         # add the remaining fragments, ignore any wildcards
139 |         for frag in remainder:
140 |             pats.append(re.escape(frag))
141 | 
142 |         pat = re.compile(r'\A' + r'\.'.join(pats) + r'\Z', re.IGNORECASE)
143 |         return pat.match(hostname)
144 | 
145 |     def match_hostname(cert, hostname):
146 |         """Verify that *cert* (in decoded format as returned by
147 |         SSLSocket.getpeercert()) matches the *hostname*.  RFC 2818 and RFC 6125
148 |         rules are followed, but IP addresses are not accepted for *hostname*.
149 | 
150 |         CertificateError is raised on failure. On success, the function
151 |         returns nothing.
152 |         """
153 |         if not cert:
154 |             raise ValueError("empty or no certificate, match_hostname needs a "
155 |                              "SSL socket or SSL context with either "
156 |                              "CERT_OPTIONAL or CERT_REQUIRED")
157 |         dnsnames = []
158 |         san = cert.get('subjectAltName', ())
159 |         for key, value in san:
160 |             if key == 'DNS':
161 |                 if _dnsname_match(value, hostname):
162 |                     return
163 |                 dnsnames.append(value)
164 |         if not dnsnames:
165 |             # The subject is only checked when there is no dNSName entry
166 |             # in subjectAltName
167 |             for sub in cert.get('subject', ()):
168 |                 for key, value in sub:
169 |                     # XXX according to RFC 2818, the most specific Common Name
170 |                     # must be used.
171 |                     if key == 'commonName':
172 |                         if _dnsname_match(value, hostname):
173 |                             return
174 |                         dnsnames.append(value)
175 |         if len(dnsnames) > 1:
176 |             raise CertificateError("hostname %r "
177 |                                    "doesn't match either of %s" %
178 |                                    (hostname, ', '.join(map(repr, dnsnames))))
179 |         elif len(dnsnames) == 1:
180 |             raise CertificateError("hostname %r "
181 |                                    "doesn't match %r" %
182 |                                    (hostname, dnsnames[0]))
183 |         else:
184 |             raise CertificateError("no appropriate commonName or "
185 |                                    "subjectAltName fields were found")
186 | 
187 | 
188 | try:
189 |     from types import SimpleNamespace as Container
190 | except ImportError:  # pragma: no cover
191 | 
192 |     class Container(object):
193 |         """
194 |         A generic container for when multiple values need to be returned
195 |         """
196 | 
197 |         def __init__(self, **kwargs):
198 |             self.__dict__.update(kwargs)
199 | 
200 | 
201 | try:
202 |     from shutil import which
203 | except ImportError:  # pragma: no cover
204 |     # Implementation from Python 3.3
205 |     def which(cmd, mode=os.F_OK | os.X_OK, path=None):
206 |         """Given a command, mode, and a PATH string, return the path which
207 |         conforms to the given mode on the PATH, or None if there is no such
208 |         file.
209 | 
210 |         `mode` defaults to os.F_OK | os.X_OK. `path` defaults to the result
211 |         of os.environ.get("PATH"), or can be overridden with a custom search
212 |         path.
213 | 
214 |         """
215 | 
216 |         # Check that a given file can be accessed with the correct mode.
217 |         # Additionally check that `file` is not a directory, as on Windows
218 |         # directories pass the os.access check.
219 |         def _access_check(fn, mode):
220 |             return (os.path.exists(fn) and os.access(fn, mode) and not os.path.isdir(fn))
221 | 
222 |         # If we're given a path with a directory part, look it up directly rather
223 |         # than referring to PATH directories. This includes checking relative to the
224 |         # current directory, e.g. ./script
225 |         if os.path.dirname(cmd):
226 |             if _access_check(cmd, mode):
227 |                 return cmd
228 |             return None
229 | 
230 |         if path is None:
231 |             path = os.environ.get("PATH", os.defpath)
232 |         if not path:
233 |             return None
234 |         path = path.split(os.pathsep)
235 | 
236 |         if sys.platform == "win32":
237 |             # The current directory takes precedence on Windows.
238 |             if os.curdir not in path:
239 |                 path.insert(0, os.curdir)
240 | 
241 |             # PATHEXT is necessary to check on Windows.
242 |             pathext = os.environ.get("PATHEXT", "").split(os.pathsep)
243 |             # See if the given file matches any of the expected path extensions.
244 |             # This will allow us to short circuit when given "python.exe".
245 |             # If it does match, only test that one, otherwise we have to try
246 |             # others.
247 |             if any(cmd.lower().endswith(ext.lower()) for ext in pathext):
248 |                 files = [cmd]
249 |             else:
250 |                 files = [cmd + ext for ext in pathext]
251 |         else:
252 |             # On other platforms you don't have things like PATHEXT to tell you
253 |             # what file suffixes are executable, so just pass on cmd as-is.
254 |             files = [cmd]
255 | 
256 |         seen = set()
257 |         for dir in path:
258 |             normdir = os.path.normcase(dir)
259 |             if normdir not in seen:
260 |                 seen.add(normdir)
261 |                 for thefile in files:
262 |                     name = os.path.join(dir, thefile)
263 |                     if _access_check(name, mode):
264 |                         return name
265 |         return None
266 | 
267 | 
268 | # ZipFile is a context manager in 2.7, but not in 2.6
269 | 
270 | from zipfile import ZipFile as BaseZipFile
271 | 
272 | if hasattr(BaseZipFile, '__enter__'):  # pragma: no cover
273 |     ZipFile = BaseZipFile
274 | else:  # pragma: no cover
275 |     from zipfile import ZipExtFile as BaseZipExtFile
276 | 
277 |     class ZipExtFile(BaseZipExtFile):
278 | 
279 |         def __init__(self, base):
280 |             self.__dict__.update(base.__dict__)
281 | 
282 |         def __enter__(self):
283 |             return self
284 | 
285 |         def __exit__(self, *exc_info):
286 |             self.close()
287 |             # return None, so if an exception occurred, it will propagate
288 | 
289 |     class ZipFile(BaseZipFile):
290 | 
291 |         def __enter__(self):
292 |             return self
293 | 
294 |         def __exit__(self, *exc_info):
295 |             self.close()
296 |             # return None, so if an exception occurred, it will propagate
297 | 
298 |         def open(self, *args, **kwargs):
299 |             base = BaseZipFile.open(self, *args, **kwargs)
300 |             return ZipExtFile(base)
301 | 
302 | 
303 | try:
304 |     from platform import python_implementation
305 | except ImportError:  # pragma: no cover
306 | 
307 |     def python_implementation():
308 |         """Return a string identifying the Python implementation."""
309 |         if 'PyPy' in sys.version:
310 |             return 'PyPy'
311 |         if os.name == 'java':
312 |             return 'Jython'
313 |         if sys.version.startswith('IronPython'):
314 |             return 'IronPython'
315 |         return 'CPython'
316 | 
317 | 
318 | import sysconfig
319 | 
320 | try:
321 |     callable = callable
322 | except NameError:  # pragma: no cover
323 |     from collections.abc import Callable
324 | 
325 |     def callable(obj):
326 |         return isinstance(obj, Callable)
327 | 
328 | 
329 | try:
330 |     fsencode = os.fsencode
331 |     fsdecode = os.fsdecode
332 | except AttributeError:  # pragma: no cover
333 |     # Issue #99: on some systems (e.g. containerised),
334 |     # sys.getfilesystemencoding() returns None, and we need a real value,
335 |     # so fall back to utf-8. From the CPython 2.7 docs relating to Unix and
336 |     # sys.getfilesystemencoding(): the return value is "the users preference
337 |     # according to the result of nl_langinfo(CODESET), or None if the
338 |     # nl_langinfo(CODESET) failed."
339 |     _fsencoding = sys.getfilesystemencoding() or 'utf-8'
340 |     if _fsencoding == 'mbcs':
341 |         _fserrors = 'strict'
342 |     else:
343 |         _fserrors = 'surrogateescape'
344 | 
345 |     def fsencode(filename):
346 |         if isinstance(filename, bytes):
347 |             return filename
348 |         elif isinstance(filename, text_type):
349 |             return filename.encode(_fsencoding, _fserrors)
350 |         else:
351 |             raise TypeError("expect bytes or str, not %s" %
352 |                             type(filename).__name__)
353 | 
354 |     def fsdecode(filename):
355 |         if isinstance(filename, text_type):
356 |             return filename
[TRUNCATED]
```

.venv/lib/python3.13/site-packages/pip/_vendor/distlib/database.py
```
1 | # -*- coding: utf-8 -*-
2 | #
3 | # Copyright (C) 2012-2023 The Python Software Foundation.
4 | # See LICENSE.txt and CONTRIBUTORS.txt.
5 | #
6 | """PEP 376 implementation."""
7 | 
8 | from __future__ import unicode_literals
9 | 
10 | import base64
11 | import codecs
12 | import contextlib
13 | import hashlib
14 | import logging
15 | import os
16 | import posixpath
17 | import sys
18 | import zipimport
19 | 
20 | from . import DistlibException, resources
21 | from .compat import StringIO
22 | from .version import get_scheme, UnsupportedVersionError
23 | from .metadata import (Metadata, METADATA_FILENAME, WHEEL_METADATA_FILENAME, LEGACY_METADATA_FILENAME)
24 | from .util import (parse_requirement, cached_property, parse_name_and_version, read_exports, write_exports, CSVReader,
25 |                    CSVWriter)
26 | 
27 | __all__ = [
28 |     'Distribution', 'BaseInstalledDistribution', 'InstalledDistribution', 'EggInfoDistribution', 'DistributionPath'
29 | ]
30 | 
31 | logger = logging.getLogger(__name__)
32 | 
33 | EXPORTS_FILENAME = 'pydist-exports.json'
34 | COMMANDS_FILENAME = 'pydist-commands.json'
35 | 
36 | DIST_FILES = ('INSTALLER', METADATA_FILENAME, 'RECORD', 'REQUESTED', 'RESOURCES', EXPORTS_FILENAME, 'SHARED')
37 | 
38 | DISTINFO_EXT = '.dist-info'
39 | 
40 | 
41 | class _Cache(object):
42 |     """
43 |     A simple cache mapping names and .dist-info paths to distributions
44 |     """
45 | 
46 |     def __init__(self):
47 |         """
48 |         Initialise an instance. There is normally one for each DistributionPath.
49 |         """
50 |         self.name = {}
51 |         self.path = {}
52 |         self.generated = False
53 | 
54 |     def clear(self):
55 |         """
56 |         Clear the cache, setting it to its initial state.
57 |         """
58 |         self.name.clear()
59 |         self.path.clear()
60 |         self.generated = False
61 | 
62 |     def add(self, dist):
63 |         """
64 |         Add a distribution to the cache.
65 |         :param dist: The distribution to add.
66 |         """
67 |         if dist.path not in self.path:
68 |             self.path[dist.path] = dist
69 |             self.name.setdefault(dist.key, []).append(dist)
70 | 
71 | 
72 | class DistributionPath(object):
73 |     """
74 |     Represents a set of distributions installed on a path (typically sys.path).
75 |     """
76 | 
77 |     def __init__(self, path=None, include_egg=False):
78 |         """
79 |         Create an instance from a path, optionally including legacy (distutils/
80 |         setuptools/distribute) distributions.
81 |         :param path: The path to use, as a list of directories. If not specified,
82 |                      sys.path is used.
83 |         :param include_egg: If True, this instance will look for and return legacy
84 |                             distributions as well as those based on PEP 376.
85 |         """
86 |         if path is None:
87 |             path = sys.path
88 |         self.path = path
89 |         self._include_dist = True
90 |         self._include_egg = include_egg
91 | 
92 |         self._cache = _Cache()
93 |         self._cache_egg = _Cache()
94 |         self._cache_enabled = True
95 |         self._scheme = get_scheme('default')
96 | 
97 |     def _get_cache_enabled(self):
98 |         return self._cache_enabled
99 | 
100 |     def _set_cache_enabled(self, value):
101 |         self._cache_enabled = value
102 | 
103 |     cache_enabled = property(_get_cache_enabled, _set_cache_enabled)
104 | 
105 |     def clear_cache(self):
106 |         """
107 |         Clears the internal cache.
108 |         """
109 |         self._cache.clear()
110 |         self._cache_egg.clear()
111 | 
112 |     def _yield_distributions(self):
113 |         """
114 |         Yield .dist-info and/or .egg(-info) distributions.
115 |         """
116 |         # We need to check if we've seen some resources already, because on
117 |         # some Linux systems (e.g. some Debian/Ubuntu variants) there are
118 |         # symlinks which alias other files in the environment.
119 |         seen = set()
120 |         for path in self.path:
121 |             finder = resources.finder_for_path(path)
122 |             if finder is None:
123 |                 continue
124 |             r = finder.find('')
125 |             if not r or not r.is_container:
126 |                 continue
127 |             rset = sorted(r.resources)
128 |             for entry in rset:
129 |                 r = finder.find(entry)
130 |                 if not r or r.path in seen:
131 |                     continue
132 |                 try:
133 |                     if self._include_dist and entry.endswith(DISTINFO_EXT):
134 |                         possible_filenames = [METADATA_FILENAME, WHEEL_METADATA_FILENAME, LEGACY_METADATA_FILENAME]
135 |                         for metadata_filename in possible_filenames:
136 |                             metadata_path = posixpath.join(entry, metadata_filename)
137 |                             pydist = finder.find(metadata_path)
138 |                             if pydist:
139 |                                 break
140 |                         else:
141 |                             continue
142 | 
143 |                         with contextlib.closing(pydist.as_stream()) as stream:
144 |                             metadata = Metadata(fileobj=stream, scheme='legacy')
145 |                         logger.debug('Found %s', r.path)
146 |                         seen.add(r.path)
147 |                         yield new_dist_class(r.path, metadata=metadata, env=self)
148 |                     elif self._include_egg and entry.endswith(('.egg-info', '.egg')):
149 |                         logger.debug('Found %s', r.path)
150 |                         seen.add(r.path)
151 |                         yield old_dist_class(r.path, self)
152 |                 except Exception as e:
153 |                     msg = 'Unable to read distribution at %s, perhaps due to bad metadata: %s'
154 |                     logger.warning(msg, r.path, e)
155 |                     import warnings
156 |                     warnings.warn(msg % (r.path, e), stacklevel=2)
157 | 
158 |     def _generate_cache(self):
159 |         """
160 |         Scan the path for distributions and populate the cache with
161 |         those that are found.
162 |         """
163 |         gen_dist = not self._cache.generated
164 |         gen_egg = self._include_egg and not self._cache_egg.generated
165 |         if gen_dist or gen_egg:
166 |             for dist in self._yield_distributions():
167 |                 if isinstance(dist, InstalledDistribution):
168 |                     self._cache.add(dist)
169 |                 else:
170 |                     self._cache_egg.add(dist)
171 | 
172 |             if gen_dist:
173 |                 self._cache.generated = True
174 |             if gen_egg:
175 |                 self._cache_egg.generated = True
176 | 
177 |     @classmethod
178 |     def distinfo_dirname(cls, name, version):
179 |         """
180 |         The *name* and *version* parameters are converted into their
181 |         filename-escaped form, i.e. any ``'-'`` characters are replaced
182 |         with ``'_'`` other than the one in ``'dist-info'`` and the one
183 |         separating the name from the version number.
184 | 
185 |         :parameter name: is converted to a standard distribution name by replacing
186 |                          any runs of non- alphanumeric characters with a single
187 |                          ``'-'``.
188 |         :type name: string
189 |         :parameter version: is converted to a standard version string. Spaces
190 |                             become dots, and all other non-alphanumeric characters
191 |                             (except dots) become dashes, with runs of multiple
192 |                             dashes condensed to a single dash.
193 |         :type version: string
194 |         :returns: directory name
195 |         :rtype: string"""
196 |         name = name.replace('-', '_')
197 |         return '-'.join([name, version]) + DISTINFO_EXT
198 | 
199 |     def get_distributions(self):
200 |         """
201 |         Provides an iterator that looks for distributions and returns
202 |         :class:`InstalledDistribution` or
203 |         :class:`EggInfoDistribution` instances for each one of them.
204 | 
205 |         :rtype: iterator of :class:`InstalledDistribution` and
206 |                 :class:`EggInfoDistribution` instances
207 |         """
208 |         if not self._cache_enabled:
209 |             for dist in self._yield_distributions():
210 |                 yield dist
211 |         else:
212 |             self._generate_cache()
213 | 
214 |             for dist in self._cache.path.values():
215 |                 yield dist
216 | 
217 |             if self._include_egg:
218 |                 for dist in self._cache_egg.path.values():
219 |                     yield dist
220 | 
221 |     def get_distribution(self, name):
222 |         """
223 |         Looks for a named distribution on the path.
224 | 
225 |         This function only returns the first result found, as no more than one
226 |         value is expected. If nothing is found, ``None`` is returned.
227 | 
228 |         :rtype: :class:`InstalledDistribution`, :class:`EggInfoDistribution`
229 |                 or ``None``
230 |         """
231 |         result = None
232 |         name = name.lower()
233 |         if not self._cache_enabled:
234 |             for dist in self._yield_distributions():
235 |                 if dist.key == name:
236 |                     result = dist
237 |                     break
238 |         else:
239 |             self._generate_cache()
240 | 
241 |             if name in self._cache.name:
242 |                 result = self._cache.name[name][0]
243 |             elif self._include_egg and name in self._cache_egg.name:
244 |                 result = self._cache_egg.name[name][0]
245 |         return result
246 | 
247 |     def provides_distribution(self, name, version=None):
248 |         """
249 |         Iterates over all distributions to find which distributions provide *name*.
250 |         If a *version* is provided, it will be used to filter the results.
251 | 
252 |         This function only returns the first result found, since no more than
253 |         one values are expected. If the directory is not found, returns ``None``.
254 | 
255 |         :parameter version: a version specifier that indicates the version
256 |                             required, conforming to the format in ``PEP-345``
257 | 
258 |         :type name: string
259 |         :type version: string
260 |         """
261 |         matcher = None
262 |         if version is not None:
263 |             try:
264 |                 matcher = self._scheme.matcher('%s (%s)' % (name, version))
265 |             except ValueError:
266 |                 raise DistlibException('invalid name or version: %r, %r' % (name, version))
267 | 
268 |         for dist in self.get_distributions():
269 |             # We hit a problem on Travis where enum34 was installed and doesn't
270 |             # have a provides attribute ...
271 |             if not hasattr(dist, 'provides'):
272 |                 logger.debug('No "provides": %s', dist)
273 |             else:
274 |                 provided = dist.provides
275 | 
276 |                 for p in provided:
277 |                     p_name, p_ver = parse_name_and_version(p)
278 |                     if matcher is None:
279 |                         if p_name == name:
280 |                             yield dist
281 |                             break
282 |                     else:
283 |                         if p_name == name and matcher.match(p_ver):
284 |                             yield dist
285 |                             break
286 | 
287 |     def get_file_path(self, name, relative_path):
288 |         """
289 |         Return the path to a resource file.
290 |         """
291 |         dist = self.get_distribution(name)
292 |         if dist is None:
293 |             raise LookupError('no distribution named %r found' % name)
294 |         return dist.get_resource_path(relative_path)
295 | 
296 |     def get_exported_entries(self, category, name=None):
297 |         """
298 |         Return all of the exported entries in a particular category.
299 | 
300 |         :param category: The category to search for entries.
301 |         :param name: If specified, only entries with that name are returned.
302 |         """
303 |         for dist in self.get_distributions():
304 |             r = dist.exports
305 |             if category in r:
306 |                 d = r[category]
307 |                 if name is not None:
308 |                     if name in d:
309 |                         yield d[name]
310 |                 else:
311 |                     for v in d.values():
312 |                         yield v
313 | 
314 | 
315 | class Distribution(object):
316 |     """
317 |     A base class for distributions, whether installed or from indexes.
318 |     Either way, it must have some metadata, so that's all that's needed
319 |     for construction.
320 |     """
321 | 
322 |     build_time_dependency = False
323 |     """
324 |     Set to True if it's known to be only a build-time dependency (i.e.
325 |     not needed after installation).
326 |     """
327 | 
328 |     requested = False
329 |     """A boolean that indicates whether the ``REQUESTED`` metadata file is
330 |     present (in other words, whether the package was installed by user
331 |     request or it was installed as a dependency)."""
332 | 
333 |     def __init__(self, metadata):
334 |         """
335 |         Initialise an instance.
336 |         :param metadata: The instance of :class:`Metadata` describing this
337 |         distribution.
338 |         """
339 |         self.metadata = metadata
340 |         self.name = metadata.name
341 |         self.key = self.name.lower()  # for case-insensitive comparisons
342 |         self.version = metadata.version
343 |         self.locator = None
344 |         self.digest = None
345 |         self.extras = None  # additional features requested
346 |         self.context = None  # environment marker overrides
347 |         self.download_urls = set()
348 |         self.digests = {}
349 | 
350 |     @property
351 |     def source_url(self):
352 |         """
353 |         The source archive download URL for this distribution.
354 |         """
355 |         return self.metadata.source_url
356 | 
357 |     download_url = source_url  # Backward compatibility
358 | 
359 |     @property
360 |     def name_and_version(self):
361 |         """
362 |         A utility property which displays the name and version in parentheses.
363 |         """
364 |         return '%s (%s)' % (self.name, self.version)
365 | 
366 |     @property
[TRUNCATED]
```

.venv/lib/python3.13/site-packages/pip/_vendor/distlib/index.py
```
1 | # -*- coding: utf-8 -*-
2 | #
3 | # Copyright (C) 2013-2023 Vinay Sajip.
4 | # Licensed to the Python Software Foundation under a contributor agreement.
5 | # See LICENSE.txt and CONTRIBUTORS.txt.
6 | #
7 | import hashlib
8 | import logging
9 | import os
10 | import shutil
11 | import subprocess
12 | import tempfile
13 | try:
14 |     from threading import Thread
15 | except ImportError:  # pragma: no cover
16 |     from dummy_threading import Thread
17 | 
18 | from . import DistlibException
19 | from .compat import (HTTPBasicAuthHandler, Request, HTTPPasswordMgr,
20 |                      urlparse, build_opener, string_types)
21 | from .util import zip_dir, ServerProxy
22 | 
23 | logger = logging.getLogger(__name__)
24 | 
25 | DEFAULT_INDEX = 'https://pypi.org/pypi'
26 | DEFAULT_REALM = 'pypi'
27 | 
28 | 
29 | class PackageIndex(object):
30 |     """
31 |     This class represents a package index compatible with PyPI, the Python
32 |     Package Index.
33 |     """
34 | 
35 |     boundary = b'----------ThIs_Is_tHe_distlib_index_bouNdaRY_$'
36 | 
37 |     def __init__(self, url=None):
38 |         """
39 |         Initialise an instance.
40 | 
41 |         :param url: The URL of the index. If not specified, the URL for PyPI is
42 |                     used.
43 |         """
44 |         self.url = url or DEFAULT_INDEX
45 |         self.read_configuration()
46 |         scheme, netloc, path, params, query, frag = urlparse(self.url)
47 |         if params or query or frag or scheme not in ('http', 'https'):
48 |             raise DistlibException('invalid repository: %s' % self.url)
49 |         self.password_handler = None
50 |         self.ssl_verifier = None
51 |         self.gpg = None
52 |         self.gpg_home = None
53 |         with open(os.devnull, 'w') as sink:
54 |             # Use gpg by default rather than gpg2, as gpg2 insists on
55 |             # prompting for passwords
56 |             for s in ('gpg', 'gpg2'):
57 |                 try:
58 |                     rc = subprocess.check_call([s, '--version'], stdout=sink,
59 |                                                stderr=sink)
60 |                     if rc == 0:
61 |                         self.gpg = s
62 |                         break
63 |                 except OSError:
64 |                     pass
65 | 
66 |     def _get_pypirc_command(self):
67 |         """
68 |         Get the distutils command for interacting with PyPI configurations.
69 |         :return: the command.
70 |         """
71 |         from .util import _get_pypirc_command as cmd
72 |         return cmd()
73 | 
74 |     def read_configuration(self):
75 |         """
76 |         Read the PyPI access configuration as supported by distutils. This populates
77 |         ``username``, ``password``, ``realm`` and ``url`` attributes from the
78 |         configuration.
79 |         """
80 |         from .util import _load_pypirc
81 |         cfg = _load_pypirc(self)
82 |         self.username = cfg.get('username')
83 |         self.password = cfg.get('password')
84 |         self.realm = cfg.get('realm', 'pypi')
85 |         self.url = cfg.get('repository', self.url)
86 | 
87 |     def save_configuration(self):
88 |         """
89 |         Save the PyPI access configuration. You must have set ``username`` and
90 |         ``password`` attributes before calling this method.
91 |         """
92 |         self.check_credentials()
93 |         from .util import _store_pypirc
94 |         _store_pypirc(self)
95 | 
96 |     def check_credentials(self):
97 |         """
98 |         Check that ``username`` and ``password`` have been set, and raise an
99 |         exception if not.
100 |         """
101 |         if self.username is None or self.password is None:
102 |             raise DistlibException('username and password must be set')
103 |         pm = HTTPPasswordMgr()
104 |         _, netloc, _, _, _, _ = urlparse(self.url)
105 |         pm.add_password(self.realm, netloc, self.username, self.password)
106 |         self.password_handler = HTTPBasicAuthHandler(pm)
107 | 
108 |     def register(self, metadata):  # pragma: no cover
109 |         """
110 |         Register a distribution on PyPI, using the provided metadata.
111 | 
112 |         :param metadata: A :class:`Metadata` instance defining at least a name
113 |                          and version number for the distribution to be
114 |                          registered.
115 |         :return: The HTTP response received from PyPI upon submission of the
116 |                 request.
117 |         """
118 |         self.check_credentials()
119 |         metadata.validate()
120 |         d = metadata.todict()
121 |         d[':action'] = 'verify'
122 |         request = self.encode_request(d.items(), [])
123 |         self.send_request(request)
124 |         d[':action'] = 'submit'
125 |         request = self.encode_request(d.items(), [])
126 |         return self.send_request(request)
127 | 
128 |     def _reader(self, name, stream, outbuf):
129 |         """
130 |         Thread runner for reading lines of from a subprocess into a buffer.
131 | 
132 |         :param name: The logical name of the stream (used for logging only).
133 |         :param stream: The stream to read from. This will typically a pipe
134 |                        connected to the output stream of a subprocess.
135 |         :param outbuf: The list to append the read lines to.
136 |         """
137 |         while True:
138 |             s = stream.readline()
139 |             if not s:
140 |                 break
141 |             s = s.decode('utf-8').rstrip()
142 |             outbuf.append(s)
143 |             logger.debug('%s: %s' % (name, s))
144 |         stream.close()
145 | 
146 |     def get_sign_command(self, filename, signer, sign_password, keystore=None):  # pragma: no cover
147 |         """
148 |         Return a suitable command for signing a file.
149 | 
150 |         :param filename: The pathname to the file to be signed.
151 |         :param signer: The identifier of the signer of the file.
152 |         :param sign_password: The passphrase for the signer's
153 |                               private key used for signing.
154 |         :param keystore: The path to a directory which contains the keys
155 |                          used in verification. If not specified, the
156 |                          instance's ``gpg_home`` attribute is used instead.
157 |         :return: The signing command as a list suitable to be
158 |                  passed to :class:`subprocess.Popen`.
159 |         """
160 |         cmd = [self.gpg, '--status-fd', '2', '--no-tty']
161 |         if keystore is None:
162 |             keystore = self.gpg_home
163 |         if keystore:
164 |             cmd.extend(['--homedir', keystore])
165 |         if sign_password is not None:
166 |             cmd.extend(['--batch', '--passphrase-fd', '0'])
167 |         td = tempfile.mkdtemp()
168 |         sf = os.path.join(td, os.path.basename(filename) + '.asc')
169 |         cmd.extend(['--detach-sign', '--armor', '--local-user',
170 |                     signer, '--output', sf, filename])
171 |         logger.debug('invoking: %s', ' '.join(cmd))
172 |         return cmd, sf
173 | 
174 |     def run_command(self, cmd, input_data=None):
175 |         """
176 |         Run a command in a child process , passing it any input data specified.
177 | 
178 |         :param cmd: The command to run.
179 |         :param input_data: If specified, this must be a byte string containing
180 |                            data to be sent to the child process.
181 |         :return: A tuple consisting of the subprocess' exit code, a list of
182 |                  lines read from the subprocess' ``stdout``, and a list of
183 |                  lines read from the subprocess' ``stderr``.
184 |         """
185 |         kwargs = {
186 |             'stdout': subprocess.PIPE,
187 |             'stderr': subprocess.PIPE,
188 |         }
189 |         if input_data is not None:
190 |             kwargs['stdin'] = subprocess.PIPE
191 |         stdout = []
192 |         stderr = []
193 |         p = subprocess.Popen(cmd, **kwargs)
194 |         # We don't use communicate() here because we may need to
195 |         # get clever with interacting with the command
196 |         t1 = Thread(target=self._reader, args=('stdout', p.stdout, stdout))
197 |         t1.start()
198 |         t2 = Thread(target=self._reader, args=('stderr', p.stderr, stderr))
199 |         t2.start()
200 |         if input_data is not None:
201 |             p.stdin.write(input_data)
202 |             p.stdin.close()
203 | 
204 |         p.wait()
205 |         t1.join()
206 |         t2.join()
207 |         return p.returncode, stdout, stderr
208 | 
209 |     def sign_file(self, filename, signer, sign_password, keystore=None):  # pragma: no cover
210 |         """
211 |         Sign a file.
212 | 
213 |         :param filename: The pathname to the file to be signed.
214 |         :param signer: The identifier of the signer of the file.
215 |         :param sign_password: The passphrase for the signer's
216 |                               private key used for signing.
217 |         :param keystore: The path to a directory which contains the keys
218 |                          used in signing. If not specified, the instance's
219 |                          ``gpg_home`` attribute is used instead.
220 |         :return: The absolute pathname of the file where the signature is
221 |                  stored.
222 |         """
223 |         cmd, sig_file = self.get_sign_command(filename, signer, sign_password,
224 |                                               keystore)
225 |         rc, stdout, stderr = self.run_command(cmd,
226 |                                               sign_password.encode('utf-8'))
227 |         if rc != 0:
228 |             raise DistlibException('sign command failed with error '
229 |                                    'code %s' % rc)
230 |         return sig_file
231 | 
232 |     def upload_file(self, metadata, filename, signer=None, sign_password=None,
233 |                     filetype='sdist', pyversion='source', keystore=None):
234 |         """
235 |         Upload a release file to the index.
236 | 
237 |         :param metadata: A :class:`Metadata` instance defining at least a name
238 |                          and version number for the file to be uploaded.
239 |         :param filename: The pathname of the file to be uploaded.
240 |         :param signer: The identifier of the signer of the file.
241 |         :param sign_password: The passphrase for the signer's
242 |                               private key used for signing.
243 |         :param filetype: The type of the file being uploaded. This is the
244 |                         distutils command which produced that file, e.g.
245 |                         ``sdist`` or ``bdist_wheel``.
246 |         :param pyversion: The version of Python which the release relates
247 |                           to. For code compatible with any Python, this would
248 |                           be ``source``, otherwise it would be e.g. ``3.2``.
249 |         :param keystore: The path to a directory which contains the keys
250 |                          used in signing. If not specified, the instance's
251 |                          ``gpg_home`` attribute is used instead.
252 |         :return: The HTTP response received from PyPI upon submission of the
253 |                 request.
254 |         """
255 |         self.check_credentials()
256 |         if not os.path.exists(filename):
257 |             raise DistlibException('not found: %s' % filename)
258 |         metadata.validate()
259 |         d = metadata.todict()
260 |         sig_file = None
261 |         if signer:
262 |             if not self.gpg:
263 |                 logger.warning('no signing program available - not signed')
264 |             else:
265 |                 sig_file = self.sign_file(filename, signer, sign_password,
266 |                                           keystore)
267 |         with open(filename, 'rb') as f:
268 |             file_data = f.read()
269 |         md5_digest = hashlib.md5(file_data).hexdigest()
270 |         sha256_digest = hashlib.sha256(file_data).hexdigest()
271 |         d.update({
272 |             ':action': 'file_upload',
273 |             'protocol_version': '1',
274 |             'filetype': filetype,
275 |             'pyversion': pyversion,
276 |             'md5_digest': md5_digest,
277 |             'sha256_digest': sha256_digest,
278 |         })
279 |         files = [('content', os.path.basename(filename), file_data)]
280 |         if sig_file:
281 |             with open(sig_file, 'rb') as f:
282 |                 sig_data = f.read()
283 |             files.append(('gpg_signature', os.path.basename(sig_file),
284 |                          sig_data))
285 |             shutil.rmtree(os.path.dirname(sig_file))
286 |         request = self.encode_request(d.items(), files)
287 |         return self.send_request(request)
288 | 
289 |     def upload_documentation(self, metadata, doc_dir):  # pragma: no cover
290 |         """
291 |         Upload documentation to the index.
292 | 
293 |         :param metadata: A :class:`Metadata` instance defining at least a name
294 |                          and version number for the documentation to be
295 |                          uploaded.
296 |         :param doc_dir: The pathname of the directory which contains the
297 |                         documentation. This should be the directory that
298 |                         contains the ``index.html`` for the documentation.
299 |         :return: The HTTP response received from PyPI upon submission of the
300 |                 request.
301 |         """
302 |         self.check_credentials()
303 |         if not os.path.isdir(doc_dir):
304 |             raise DistlibException('not a directory: %r' % doc_dir)
305 |         fn = os.path.join(doc_dir, 'index.html')
306 |         if not os.path.exists(fn):
307 |             raise DistlibException('not found: %r' % fn)
308 |         metadata.validate()
309 |         name, version = metadata.name, metadata.version
310 |         zip_data = zip_dir(doc_dir).getvalue()
311 |         fields = [(':action', 'doc_upload'),
312 |                   ('name', name), ('version', version)]
313 |         files = [('content', name, zip_data)]
314 |         request = self.encode_request(fields, files)
315 |         return self.send_request(request)
316 | 
317 |     def get_verify_command(self, signature_filename, data_filename,
318 |                            keystore=None):
319 |         """
320 |         Return a suitable command for verifying a file.
321 | 
322 |         :param signature_filename: The pathname to the file containing the
323 |                                    signature.
324 |         :param data_filename: The pathname to the file containing the
325 |                               signed data.
326 |         :param keystore: The path to a directory which contains the keys
[TRUNCATED]
```

.venv/lib/python3.13/site-packages/pip/_vendor/distlib/locators.py
```
1 | # -*- coding: utf-8 -*-
2 | #
3 | # Copyright (C) 2012-2023 Vinay Sajip.
4 | # Licensed to the Python Software Foundation under a contributor agreement.
5 | # See LICENSE.txt and CONTRIBUTORS.txt.
6 | #
7 | 
8 | import gzip
9 | from io import BytesIO
10 | import json
11 | import logging
12 | import os
13 | import posixpath
14 | import re
15 | try:
16 |     import threading
17 | except ImportError:  # pragma: no cover
18 |     import dummy_threading as threading
19 | import zlib
20 | 
21 | from . import DistlibException
22 | from .compat import (urljoin, urlparse, urlunparse, url2pathname, pathname2url, queue, quote, unescape, build_opener,
23 |                      HTTPRedirectHandler as BaseRedirectHandler, text_type, Request, HTTPError, URLError)
24 | from .database import Distribution, DistributionPath, make_dist
25 | from .metadata import Metadata, MetadataInvalidError
26 | from .util import (cached_property, ensure_slash, split_filename, get_project_data, parse_requirement,
27 |                    parse_name_and_version, ServerProxy, normalize_name)
28 | from .version import get_scheme, UnsupportedVersionError
29 | from .wheel import Wheel, is_compatible
30 | 
31 | logger = logging.getLogger(__name__)
32 | 
33 | HASHER_HASH = re.compile(r'^(\w+)=([a-f0-9]+)')
34 | CHARSET = re.compile(r';\s*charset\s*=\s*(.*)\s*$', re.I)
35 | HTML_CONTENT_TYPE = re.compile('text/html|application/x(ht)?ml')
36 | DEFAULT_INDEX = 'https://pypi.org/pypi'
37 | 
38 | 
39 | def get_all_distribution_names(url=None):
40 |     """
41 |     Return all distribution names known by an index.
42 |     :param url: The URL of the index.
43 |     :return: A list of all known distribution names.
44 |     """
45 |     if url is None:
46 |         url = DEFAULT_INDEX
47 |     client = ServerProxy(url, timeout=3.0)
48 |     try:
49 |         return client.list_packages()
50 |     finally:
51 |         client('close')()
52 | 
53 | 
54 | class RedirectHandler(BaseRedirectHandler):
55 |     """
56 |     A class to work around a bug in some Python 3.2.x releases.
57 |     """
58 | 
59 |     # There's a bug in the base version for some 3.2.x
60 |     # (e.g. 3.2.2 on Ubuntu Oneiric). If a Location header
61 |     # returns e.g. /abc, it bails because it says the scheme ''
62 |     # is bogus, when actually it should use the request's
63 |     # URL for the scheme. See Python issue #13696.
64 |     def http_error_302(self, req, fp, code, msg, headers):
65 |         # Some servers (incorrectly) return multiple Location headers
66 |         # (so probably same goes for URI).  Use first header.
67 |         newurl = None
68 |         for key in ('location', 'uri'):
69 |             if key in headers:
70 |                 newurl = headers[key]
71 |                 break
72 |         if newurl is None:  # pragma: no cover
73 |             return
74 |         urlparts = urlparse(newurl)
75 |         if urlparts.scheme == '':
76 |             newurl = urljoin(req.get_full_url(), newurl)
77 |             if hasattr(headers, 'replace_header'):
78 |                 headers.replace_header(key, newurl)
79 |             else:
80 |                 headers[key] = newurl
81 |         return BaseRedirectHandler.http_error_302(self, req, fp, code, msg, headers)
82 | 
83 |     http_error_301 = http_error_303 = http_error_307 = http_error_302
84 | 
85 | 
86 | class Locator(object):
87 |     """
88 |     A base class for locators - things that locate distributions.
89 |     """
90 |     source_extensions = ('.tar.gz', '.tar.bz2', '.tar', '.zip', '.tgz', '.tbz')
91 |     binary_extensions = ('.egg', '.exe', '.whl')
92 |     excluded_extensions = ('.pdf', )
93 | 
94 |     # A list of tags indicating which wheels you want to match. The default
95 |     # value of None matches against the tags compatible with the running
96 |     # Python. If you want to match other values, set wheel_tags on a locator
97 |     # instance to a list of tuples (pyver, abi, arch) which you want to match.
98 |     wheel_tags = None
99 | 
100 |     downloadable_extensions = source_extensions + ('.whl', )
101 | 
102 |     def __init__(self, scheme='default'):
103 |         """
104 |         Initialise an instance.
105 |         :param scheme: Because locators look for most recent versions, they
106 |                        need to know the version scheme to use. This specifies
107 |                        the current PEP-recommended scheme - use ``'legacy'``
108 |                        if you need to support existing distributions on PyPI.
109 |         """
110 |         self._cache = {}
111 |         self.scheme = scheme
112 |         # Because of bugs in some of the handlers on some of the platforms,
113 |         # we use our own opener rather than just using urlopen.
114 |         self.opener = build_opener(RedirectHandler())
115 |         # If get_project() is called from locate(), the matcher instance
116 |         # is set from the requirement passed to locate(). See issue #18 for
117 |         # why this can be useful to know.
118 |         self.matcher = None
119 |         self.errors = queue.Queue()
120 | 
121 |     def get_errors(self):
122 |         """
123 |         Return any errors which have occurred.
124 |         """
125 |         result = []
126 |         while not self.errors.empty():  # pragma: no cover
127 |             try:
128 |                 e = self.errors.get(False)
129 |                 result.append(e)
130 |             except self.errors.Empty:
131 |                 continue
132 |             self.errors.task_done()
133 |         return result
134 | 
135 |     def clear_errors(self):
136 |         """
137 |         Clear any errors which may have been logged.
138 |         """
139 |         # Just get the errors and throw them away
140 |         self.get_errors()
141 | 
142 |     def clear_cache(self):
143 |         self._cache.clear()
144 | 
145 |     def _get_scheme(self):
146 |         return self._scheme
147 | 
148 |     def _set_scheme(self, value):
149 |         self._scheme = value
150 | 
151 |     scheme = property(_get_scheme, _set_scheme)
152 | 
153 |     def _get_project(self, name):
154 |         """
155 |         For a given project, get a dictionary mapping available versions to Distribution
156 |         instances.
157 | 
158 |         This should be implemented in subclasses.
159 | 
160 |         If called from a locate() request, self.matcher will be set to a
161 |         matcher for the requirement to satisfy, otherwise it will be None.
162 |         """
163 |         raise NotImplementedError('Please implement in the subclass')
164 | 
165 |     def get_distribution_names(self):
166 |         """
167 |         Return all the distribution names known to this locator.
168 |         """
169 |         raise NotImplementedError('Please implement in the subclass')
170 | 
171 |     def get_project(self, name):
172 |         """
173 |         For a given project, get a dictionary mapping available versions to Distribution
174 |         instances.
175 | 
176 |         This calls _get_project to do all the work, and just implements a caching layer on top.
177 |         """
178 |         if self._cache is None:  # pragma: no cover
179 |             result = self._get_project(name)
180 |         elif name in self._cache:
181 |             result = self._cache[name]
182 |         else:
183 |             self.clear_errors()
184 |             result = self._get_project(name)
185 |             self._cache[name] = result
186 |         return result
187 | 
188 |     def score_url(self, url):
189 |         """
190 |         Give an url a score which can be used to choose preferred URLs
191 |         for a given project release.
192 |         """
193 |         t = urlparse(url)
194 |         basename = posixpath.basename(t.path)
195 |         compatible = True
196 |         is_wheel = basename.endswith('.whl')
197 |         is_downloadable = basename.endswith(self.downloadable_extensions)
198 |         if is_wheel:
199 |             compatible = is_compatible(Wheel(basename), self.wheel_tags)
200 |         return (t.scheme == 'https', 'pypi.org' in t.netloc, is_downloadable, is_wheel, compatible, basename)
201 | 
202 |     def prefer_url(self, url1, url2):
203 |         """
204 |         Choose one of two URLs where both are candidates for distribution
205 |         archives for the same version of a distribution (for example,
206 |         .tar.gz vs. zip).
207 | 
208 |         The current implementation favours https:// URLs over http://, archives
209 |         from PyPI over those from other locations, wheel compatibility (if a
210 |         wheel) and then the archive name.
211 |         """
212 |         result = url2
213 |         if url1:
214 |             s1 = self.score_url(url1)
215 |             s2 = self.score_url(url2)
216 |             if s1 > s2:
217 |                 result = url1
218 |             if result != url2:
219 |                 logger.debug('Not replacing %r with %r', url1, url2)
220 |             else:
221 |                 logger.debug('Replacing %r with %r', url1, url2)
222 |         return result
223 | 
224 |     def split_filename(self, filename, project_name):
225 |         """
226 |         Attempt to split a filename in project name, version and Python version.
227 |         """
228 |         return split_filename(filename, project_name)
229 | 
230 |     def convert_url_to_download_info(self, url, project_name):
231 |         """
232 |         See if a URL is a candidate for a download URL for a project (the URL
233 |         has typically been scraped from an HTML page).
234 | 
235 |         If it is, a dictionary is returned with keys "name", "version",
236 |         "filename" and "url"; otherwise, None is returned.
237 |         """
238 | 
239 |         def same_project(name1, name2):
240 |             return normalize_name(name1) == normalize_name(name2)
241 | 
242 |         result = None
243 |         scheme, netloc, path, params, query, frag = urlparse(url)
244 |         if frag.lower().startswith('egg='):  # pragma: no cover
245 |             logger.debug('%s: version hint in fragment: %r', project_name, frag)
246 |         m = HASHER_HASH.match(frag)
247 |         if m:
248 |             algo, digest = m.groups()
249 |         else:
250 |             algo, digest = None, None
251 |         origpath = path
252 |         if path and path[-1] == '/':  # pragma: no cover
253 |             path = path[:-1]
254 |         if path.endswith('.whl'):
255 |             try:
256 |                 wheel = Wheel(path)
257 |                 if not is_compatible(wheel, self.wheel_tags):
258 |                     logger.debug('Wheel not compatible: %s', path)
259 |                 else:
260 |                     if project_name is None:
261 |                         include = True
262 |                     else:
263 |                         include = same_project(wheel.name, project_name)
264 |                     if include:
265 |                         result = {
266 |                             'name': wheel.name,
267 |                             'version': wheel.version,
268 |                             'filename': wheel.filename,
269 |                             'url': urlunparse((scheme, netloc, origpath, params, query, '')),
270 |                             'python-version': ', '.join(['.'.join(list(v[2:])) for v in wheel.pyver]),
271 |                         }
272 |             except Exception:  # pragma: no cover
273 |                 logger.warning('invalid path for wheel: %s', path)
274 |         elif not path.endswith(self.downloadable_extensions):  # pragma: no cover
275 |             logger.debug('Not downloadable: %s', path)
276 |         else:  # downloadable extension
277 |             path = filename = posixpath.basename(path)
278 |             for ext in self.downloadable_extensions:
279 |                 if path.endswith(ext):
280 |                     path = path[:-len(ext)]
281 |                     t = self.split_filename(path, project_name)
282 |                     if not t:  # pragma: no cover
283 |                         logger.debug('No match for project/version: %s', path)
284 |                     else:
285 |                         name, version, pyver = t
286 |                         if not project_name or same_project(project_name, name):
287 |                             result = {
288 |                                 'name': name,
289 |                                 'version': version,
290 |                                 'filename': filename,
291 |                                 'url': urlunparse((scheme, netloc, origpath, params, query, '')),
292 |                             }
293 |                             if pyver:  # pragma: no cover
294 |                                 result['python-version'] = pyver
295 |                     break
296 |         if result and algo:
297 |             result['%s_digest' % algo] = digest
298 |         return result
299 | 
300 |     def _get_digest(self, info):
301 |         """
302 |         Get a digest from a dictionary by looking at a "digests" dictionary
303 |         or keys of the form 'algo_digest'.
304 | 
305 |         Returns a 2-tuple (algo, digest) if found, else None. Currently
306 |         looks only for SHA256, then MD5.
307 |         """
308 |         result = None
309 |         if 'digests' in info:
310 |             digests = info['digests']
311 |             for algo in ('sha256', 'md5'):
312 |                 if algo in digests:
313 |                     result = (algo, digests[algo])
314 |                     break
315 |         if not result:
316 |             for algo in ('sha256', 'md5'):
317 |                 key = '%s_digest' % algo
318 |                 if key in info:
319 |                     result = (algo, info[key])
320 |                     break
321 |         return result
322 | 
323 |     def _update_version_data(self, result, info):
324 |         """
325 |         Update a result dictionary (the final result from _get_project) with a
326 |         dictionary for a specific version, which typically holds information
327 |         gleaned from a filename or URL for an archive for the distribution.
328 |         """
329 |         name = info.pop('name')
330 |         version = info.pop('version')
331 |         if version in result:
332 |             dist = result[version]
333 |             md = dist.metadata
334 |         else:
335 |             dist = make_dist(name, version, scheme=self.scheme)
[TRUNCATED]
```

.venv/lib/python3.13/site-packages/pip/_vendor/distlib/manifest.py
```
1 | # -*- coding: utf-8 -*-
2 | #
3 | # Copyright (C) 2012-2023 Python Software Foundation.
4 | # See LICENSE.txt and CONTRIBUTORS.txt.
5 | #
6 | """
7 | Class representing the list of files in a distribution.
8 | 
9 | Equivalent to distutils.filelist, but fixes some problems.
10 | """
11 | import fnmatch
12 | import logging
13 | import os
14 | import re
15 | import sys
16 | 
17 | from . import DistlibException
18 | from .compat import fsdecode
19 | from .util import convert_path
20 | 
21 | 
22 | __all__ = ['Manifest']
23 | 
24 | logger = logging.getLogger(__name__)
25 | 
26 | # a \ followed by some spaces + EOL
27 | _COLLAPSE_PATTERN = re.compile('\\\\w*\n', re.M)
28 | _COMMENTED_LINE = re.compile('#.*?(?=\n)|\n(?=$)', re.M | re.S)
29 | 
30 | #
31 | # Due to the different results returned by fnmatch.translate, we need
32 | # to do slightly different processing for Python 2.7 and 3.2 ... this needed
33 | # to be brought in for Python 3.6 onwards.
34 | #
35 | _PYTHON_VERSION = sys.version_info[:2]
36 | 
37 | 
38 | class Manifest(object):
39 |     """
40 |     A list of files built by exploring the filesystem and filtered by applying various
41 |     patterns to what we find there.
42 |     """
43 | 
44 |     def __init__(self, base=None):
45 |         """
46 |         Initialise an instance.
47 | 
48 |         :param base: The base directory to explore under.
49 |         """
50 |         self.base = os.path.abspath(os.path.normpath(base or os.getcwd()))
51 |         self.prefix = self.base + os.sep
52 |         self.allfiles = None
53 |         self.files = set()
54 | 
55 |     #
56 |     # Public API
57 |     #
58 | 
59 |     def findall(self):
60 |         """Find all files under the base and set ``allfiles`` to the absolute
61 |         pathnames of files found.
62 |         """
63 |         from stat import S_ISREG, S_ISDIR, S_ISLNK
64 | 
65 |         self.allfiles = allfiles = []
66 |         root = self.base
67 |         stack = [root]
68 |         pop = stack.pop
69 |         push = stack.append
70 | 
71 |         while stack:
72 |             root = pop()
73 |             names = os.listdir(root)
74 | 
75 |             for name in names:
76 |                 fullname = os.path.join(root, name)
77 | 
78 |                 # Avoid excess stat calls -- just one will do, thank you!
79 |                 stat = os.stat(fullname)
80 |                 mode = stat.st_mode
81 |                 if S_ISREG(mode):
82 |                     allfiles.append(fsdecode(fullname))
83 |                 elif S_ISDIR(mode) and not S_ISLNK(mode):
84 |                     push(fullname)
85 | 
86 |     def add(self, item):
87 |         """
88 |         Add a file to the manifest.
89 | 
90 |         :param item: The pathname to add. This can be relative to the base.
91 |         """
92 |         if not item.startswith(self.prefix):
93 |             item = os.path.join(self.base, item)
94 |         self.files.add(os.path.normpath(item))
95 | 
96 |     def add_many(self, items):
97 |         """
98 |         Add a list of files to the manifest.
99 | 
100 |         :param items: The pathnames to add. These can be relative to the base.
101 |         """
102 |         for item in items:
103 |             self.add(item)
104 | 
105 |     def sorted(self, wantdirs=False):
106 |         """
107 |         Return sorted files in directory order
108 |         """
109 | 
110 |         def add_dir(dirs, d):
111 |             dirs.add(d)
112 |             logger.debug('add_dir added %s', d)
113 |             if d != self.base:
114 |                 parent, _ = os.path.split(d)
115 |                 assert parent not in ('', '/')
116 |                 add_dir(dirs, parent)
117 | 
118 |         result = set(self.files)    # make a copy!
119 |         if wantdirs:
120 |             dirs = set()
121 |             for f in result:
122 |                 add_dir(dirs, os.path.dirname(f))
123 |             result |= dirs
124 |         return [os.path.join(*path_tuple) for path_tuple in
125 |                 sorted(os.path.split(path) for path in result)]
126 | 
127 |     def clear(self):
128 |         """Clear all collected files."""
129 |         self.files = set()
130 |         self.allfiles = []
131 | 
132 |     def process_directive(self, directive):
133 |         """
134 |         Process a directive which either adds some files from ``allfiles`` to
135 |         ``files``, or removes some files from ``files``.
136 | 
137 |         :param directive: The directive to process. This should be in a format
138 |                      compatible with distutils ``MANIFEST.in`` files:
139 | 
140 |                      http://docs.python.org/distutils/sourcedist.html#commands
141 |         """
142 |         # Parse the line: split it up, make sure the right number of words
143 |         # is there, and return the relevant words.  'action' is always
144 |         # defined: it's the first word of the line.  Which of the other
145 |         # three are defined depends on the action; it'll be either
146 |         # patterns, (dir and patterns), or (dirpattern).
147 |         action, patterns, thedir, dirpattern = self._parse_directive(directive)
148 | 
149 |         # OK, now we know that the action is valid and we have the
150 |         # right number of words on the line for that action -- so we
151 |         # can proceed with minimal error-checking.
152 |         if action == 'include':
153 |             for pattern in patterns:
154 |                 if not self._include_pattern(pattern, anchor=True):
155 |                     logger.warning('no files found matching %r', pattern)
156 | 
157 |         elif action == 'exclude':
158 |             for pattern in patterns:
159 |                 self._exclude_pattern(pattern, anchor=True)
160 | 
161 |         elif action == 'global-include':
162 |             for pattern in patterns:
163 |                 if not self._include_pattern(pattern, anchor=False):
164 |                     logger.warning('no files found matching %r '
165 |                                    'anywhere in distribution', pattern)
166 | 
167 |         elif action == 'global-exclude':
168 |             for pattern in patterns:
169 |                 self._exclude_pattern(pattern, anchor=False)
170 | 
171 |         elif action == 'recursive-include':
172 |             for pattern in patterns:
173 |                 if not self._include_pattern(pattern, prefix=thedir):
174 |                     logger.warning('no files found matching %r '
175 |                                    'under directory %r', pattern, thedir)
176 | 
177 |         elif action == 'recursive-exclude':
178 |             for pattern in patterns:
179 |                 self._exclude_pattern(pattern, prefix=thedir)
180 | 
181 |         elif action == 'graft':
182 |             if not self._include_pattern(None, prefix=dirpattern):
183 |                 logger.warning('no directories found matching %r',
184 |                                dirpattern)
185 | 
186 |         elif action == 'prune':
187 |             if not self._exclude_pattern(None, prefix=dirpattern):
188 |                 logger.warning('no previously-included directories found '
189 |                                'matching %r', dirpattern)
190 |         else:   # pragma: no cover
191 |             # This should never happen, as it should be caught in
192 |             # _parse_template_line
193 |             raise DistlibException(
194 |                 'invalid action %r' % action)
195 | 
196 |     #
197 |     # Private API
198 |     #
199 | 
200 |     def _parse_directive(self, directive):
201 |         """
202 |         Validate a directive.
203 |         :param directive: The directive to validate.
204 |         :return: A tuple of action, patterns, thedir, dir_patterns
205 |         """
206 |         words = directive.split()
207 |         if len(words) == 1 and words[0] not in ('include', 'exclude',
208 |                                                 'global-include',
209 |                                                 'global-exclude',
210 |                                                 'recursive-include',
211 |                                                 'recursive-exclude',
212 |                                                 'graft', 'prune'):
213 |             # no action given, let's use the default 'include'
214 |             words.insert(0, 'include')
215 | 
216 |         action = words[0]
217 |         patterns = thedir = dir_pattern = None
218 | 
219 |         if action in ('include', 'exclude',
220 |                       'global-include', 'global-exclude'):
221 |             if len(words) < 2:
222 |                 raise DistlibException(
223 |                     '%r expects <pattern1> <pattern2> ...' % action)
224 | 
225 |             patterns = [convert_path(word) for word in words[1:]]
226 | 
227 |         elif action in ('recursive-include', 'recursive-exclude'):
228 |             if len(words) < 3:
229 |                 raise DistlibException(
230 |                     '%r expects <dir> <pattern1> <pattern2> ...' % action)
231 | 
232 |             thedir = convert_path(words[1])
233 |             patterns = [convert_path(word) for word in words[2:]]
234 | 
235 |         elif action in ('graft', 'prune'):
236 |             if len(words) != 2:
237 |                 raise DistlibException(
238 |                     '%r expects a single <dir_pattern>' % action)
239 | 
240 |             dir_pattern = convert_path(words[1])
241 | 
242 |         else:
243 |             raise DistlibException('unknown action %r' % action)
244 | 
245 |         return action, patterns, thedir, dir_pattern
246 | 
247 |     def _include_pattern(self, pattern, anchor=True, prefix=None,
248 |                          is_regex=False):
249 |         """Select strings (presumably filenames) from 'self.files' that
250 |         match 'pattern', a Unix-style wildcard (glob) pattern.
251 | 
252 |         Patterns are not quite the same as implemented by the 'fnmatch'
253 |         module: '*' and '?'  match non-special characters, where "special"
254 |         is platform-dependent: slash on Unix; colon, slash, and backslash on
255 |         DOS/Windows; and colon on Mac OS.
256 | 
257 |         If 'anchor' is true (the default), then the pattern match is more
258 |         stringent: "*.py" will match "foo.py" but not "foo/bar.py".  If
259 |         'anchor' is false, both of these will match.
260 | 
261 |         If 'prefix' is supplied, then only filenames starting with 'prefix'
262 |         (itself a pattern) and ending with 'pattern', with anything in between
263 |         them, will match.  'anchor' is ignored in this case.
264 | 
265 |         If 'is_regex' is true, 'anchor' and 'prefix' are ignored, and
266 |         'pattern' is assumed to be either a string containing a regex or a
267 |         regex object -- no translation is done, the regex is just compiled
268 |         and used as-is.
269 | 
270 |         Selected strings will be added to self.files.
271 | 
272 |         Return True if files are found.
273 |         """
274 |         # XXX docstring lying about what the special chars are?
275 |         found = False
276 |         pattern_re = self._translate_pattern(pattern, anchor, prefix, is_regex)
277 | 
278 |         # delayed loading of allfiles list
279 |         if self.allfiles is None:
280 |             self.findall()
281 | 
282 |         for name in self.allfiles:
283 |             if pattern_re.search(name):
284 |                 self.files.add(name)
285 |                 found = True
286 |         return found
287 | 
288 |     def _exclude_pattern(self, pattern, anchor=True, prefix=None,
289 |                          is_regex=False):
290 |         """Remove strings (presumably filenames) from 'files' that match
291 |         'pattern'.
292 | 
293 |         Other parameters are the same as for 'include_pattern()', above.
294 |         The list 'self.files' is modified in place. Return True if files are
295 |         found.
296 | 
297 |         This API is public to allow e.g. exclusion of SCM subdirs, e.g. when
298 |         packaging source distributions
299 |         """
300 |         found = False
301 |         pattern_re = self._translate_pattern(pattern, anchor, prefix, is_regex)
302 |         for f in list(self.files):
303 |             if pattern_re.search(f):
304 |                 self.files.remove(f)
305 |                 found = True
306 |         return found
307 | 
308 |     def _translate_pattern(self, pattern, anchor=True, prefix=None,
309 |                            is_regex=False):
310 |         """Translate a shell-like wildcard pattern to a compiled regular
311 |         expression.
312 | 
313 |         Return the compiled regex.  If 'is_regex' true,
314 |         then 'pattern' is directly compiled to a regex (if it's a string)
315 |         or just returned as-is (assumes it's a regex object).
316 |         """
317 |         if is_regex:
318 |             if isinstance(pattern, str):
319 |                 return re.compile(pattern)
320 |             else:
321 |                 return pattern
322 | 
323 |         if _PYTHON_VERSION > (3, 2):
324 |             # ditch start and end characters
325 |             start, _, end = self._glob_to_re('_').partition('_')
326 | 
327 |         if pattern:
328 |             pattern_re = self._glob_to_re(pattern)
329 |             if _PYTHON_VERSION > (3, 2):
330 |                 assert pattern_re.startswith(start) and pattern_re.endswith(end)
331 |         else:
332 |             pattern_re = ''
333 | 
334 |         base = re.escape(os.path.join(self.base, ''))
335 |         if prefix is not None:
336 |             # ditch end of pattern character
337 |             if _PYTHON_VERSION <= (3, 2):
338 |                 empty_pattern = self._glob_to_re('')
339 |                 prefix_re = self._glob_to_re(prefix)[:-len(empty_pattern)]
340 |             else:
341 |                 prefix_re = self._glob_to_re(prefix)
342 |                 assert prefix_re.startswith(start) and prefix_re.endswith(end)
343 |                 prefix_re = prefix_re[len(start): len(prefix_re) - len(end)]
344 |             sep = os.sep
345 |             if os.sep == '\\':
346 |                 sep = r'\\'
347 |             if _PYTHON_VERSION <= (3, 2):
348 |                 pattern_re = '^' + base + sep.join((prefix_re,
349 |                                                     '.*' + pattern_re))
350 |             else:
[TRUNCATED]
```

.venv/lib/python3.13/site-packages/pip/_vendor/distlib/markers.py
```
1 | # -*- coding: utf-8 -*-
2 | #
3 | # Copyright (C) 2012-2023 Vinay Sajip.
4 | # Licensed to the Python Software Foundation under a contributor agreement.
5 | # See LICENSE.txt and CONTRIBUTORS.txt.
6 | #
7 | """
8 | Parser for the environment markers micro-language defined in PEP 508.
9 | """
10 | 
11 | # Note: In PEP 345, the micro-language was Python compatible, so the ast
12 | # module could be used to parse it. However, PEP 508 introduced operators such
13 | # as ~= and === which aren't in Python, necessitating a different approach.
14 | 
15 | import os
16 | import re
17 | import sys
18 | import platform
19 | 
20 | from .compat import string_types
21 | from .util import in_venv, parse_marker
22 | from .version import LegacyVersion as LV
23 | 
24 | __all__ = ['interpret']
25 | 
26 | _VERSION_PATTERN = re.compile(r'((\d+(\.\d+)*\w*)|\'(\d+(\.\d+)*\w*)\'|\"(\d+(\.\d+)*\w*)\")')
27 | _VERSION_MARKERS = {'python_version', 'python_full_version'}
28 | 
29 | 
30 | def _is_version_marker(s):
31 |     return isinstance(s, string_types) and s in _VERSION_MARKERS
32 | 
33 | 
34 | def _is_literal(o):
35 |     if not isinstance(o, string_types) or not o:
36 |         return False
37 |     return o[0] in '\'"'
38 | 
39 | 
40 | def _get_versions(s):
41 |     return {LV(m.groups()[0]) for m in _VERSION_PATTERN.finditer(s)}
42 | 
43 | 
44 | class Evaluator(object):
45 |     """
46 |     This class is used to evaluate marker expressions.
47 |     """
48 | 
49 |     operations = {
50 |         '==': lambda x, y: x == y,
51 |         '===': lambda x, y: x == y,
52 |         '~=': lambda x, y: x == y or x > y,
53 |         '!=': lambda x, y: x != y,
54 |         '<': lambda x, y: x < y,
55 |         '<=': lambda x, y: x == y or x < y,
56 |         '>': lambda x, y: x > y,
57 |         '>=': lambda x, y: x == y or x > y,
58 |         'and': lambda x, y: x and y,
59 |         'or': lambda x, y: x or y,
60 |         'in': lambda x, y: x in y,
61 |         'not in': lambda x, y: x not in y,
62 |     }
63 | 
64 |     def evaluate(self, expr, context):
65 |         """
66 |         Evaluate a marker expression returned by the :func:`parse_requirement`
67 |         function in the specified context.
68 |         """
69 |         if isinstance(expr, string_types):
70 |             if expr[0] in '\'"':
71 |                 result = expr[1:-1]
72 |             else:
73 |                 if expr not in context:
74 |                     raise SyntaxError('unknown variable: %s' % expr)
75 |                 result = context[expr]
76 |         else:
77 |             assert isinstance(expr, dict)
78 |             op = expr['op']
79 |             if op not in self.operations:
80 |                 raise NotImplementedError('op not implemented: %s' % op)
81 |             elhs = expr['lhs']
82 |             erhs = expr['rhs']
83 |             if _is_literal(expr['lhs']) and _is_literal(expr['rhs']):
84 |                 raise SyntaxError('invalid comparison: %s %s %s' % (elhs, op, erhs))
85 | 
86 |             lhs = self.evaluate(elhs, context)
87 |             rhs = self.evaluate(erhs, context)
88 |             if ((_is_version_marker(elhs) or _is_version_marker(erhs)) and
89 |                     op in ('<', '<=', '>', '>=', '===', '==', '!=', '~=')):
90 |                 lhs = LV(lhs)
91 |                 rhs = LV(rhs)
92 |             elif _is_version_marker(elhs) and op in ('in', 'not in'):
93 |                 lhs = LV(lhs)
94 |                 rhs = _get_versions(rhs)
95 |             result = self.operations[op](lhs, rhs)
96 |         return result
97 | 
98 | 
99 | _DIGITS = re.compile(r'\d+\.\d+')
100 | 
101 | 
102 | def default_context():
103 | 
104 |     def format_full_version(info):
105 |         version = '%s.%s.%s' % (info.major, info.minor, info.micro)
106 |         kind = info.releaselevel
107 |         if kind != 'final':
108 |             version += kind[0] + str(info.serial)
109 |         return version
110 | 
111 |     if hasattr(sys, 'implementation'):
112 |         implementation_version = format_full_version(sys.implementation.version)
113 |         implementation_name = sys.implementation.name
114 |     else:
115 |         implementation_version = '0'
116 |         implementation_name = ''
117 | 
118 |     ppv = platform.python_version()
119 |     m = _DIGITS.match(ppv)
120 |     pv = m.group(0)
121 |     result = {
122 |         'implementation_name': implementation_name,
123 |         'implementation_version': implementation_version,
124 |         'os_name': os.name,
125 |         'platform_machine': platform.machine(),
126 |         'platform_python_implementation': platform.python_implementation(),
127 |         'platform_release': platform.release(),
128 |         'platform_system': platform.system(),
129 |         'platform_version': platform.version(),
130 |         'platform_in_venv': str(in_venv()),
131 |         'python_full_version': ppv,
132 |         'python_version': pv,
133 |         'sys_platform': sys.platform,
134 |     }
135 |     return result
136 | 
137 | 
138 | DEFAULT_CONTEXT = default_context()
139 | del default_context
140 | 
141 | evaluator = Evaluator()
142 | 
143 | 
144 | def interpret(marker, execution_context=None):
145 |     """
146 |     Interpret a marker and return a result depending on environment.
147 | 
148 |     :param marker: The marker to interpret.
149 |     :type marker: str
150 |     :param execution_context: The context used for name lookup.
151 |     :type execution_context: mapping
152 |     """
153 |     try:
154 |         expr, rest = parse_marker(marker)
155 |     except Exception as e:
156 |         raise SyntaxError('Unable to interpret marker syntax: %s: %s' % (marker, e))
157 |     if rest and rest[0] != '#':
158 |         raise SyntaxError('unexpected trailing data in marker: %s: %s' % (marker, rest))
159 |     context = dict(DEFAULT_CONTEXT)
160 |     if execution_context:
161 |         context.update(execution_context)
162 |     return evaluator.evaluate(expr, context)
```

.venv/lib/python3.13/site-packages/pip/_vendor/distlib/metadata.py
```
1 | # -*- coding: utf-8 -*-
2 | #
3 | # Copyright (C) 2012 The Python Software Foundation.
4 | # See LICENSE.txt and CONTRIBUTORS.txt.
5 | #
6 | """Implementation of the Metadata for Python packages PEPs.
7 | 
8 | Supports all metadata formats (1.0, 1.1, 1.2, 1.3/2.1 and 2.2).
9 | """
10 | from __future__ import unicode_literals
11 | 
12 | import codecs
13 | from email import message_from_file
14 | import json
15 | import logging
16 | import re
17 | 
18 | from . import DistlibException, __version__
19 | from .compat import StringIO, string_types, text_type
20 | from .markers import interpret
21 | from .util import extract_by_key, get_extras
22 | from .version import get_scheme, PEP440_VERSION_RE
23 | 
24 | logger = logging.getLogger(__name__)
25 | 
26 | 
27 | class MetadataMissingError(DistlibException):
28 |     """A required metadata is missing"""
29 | 
30 | 
31 | class MetadataConflictError(DistlibException):
32 |     """Attempt to read or write metadata fields that are conflictual."""
33 | 
34 | 
35 | class MetadataUnrecognizedVersionError(DistlibException):
36 |     """Unknown metadata version number."""
37 | 
38 | 
39 | class MetadataInvalidError(DistlibException):
40 |     """A metadata value is invalid"""
41 | 
42 | 
43 | # public API of this module
44 | __all__ = ['Metadata', 'PKG_INFO_ENCODING', 'PKG_INFO_PREFERRED_VERSION']
45 | 
46 | # Encoding used for the PKG-INFO files
47 | PKG_INFO_ENCODING = 'utf-8'
48 | 
49 | # preferred version. Hopefully will be changed
50 | # to 1.2 once PEP 345 is supported everywhere
51 | PKG_INFO_PREFERRED_VERSION = '1.1'
52 | 
53 | _LINE_PREFIX_1_2 = re.compile('\n       \\|')
54 | _LINE_PREFIX_PRE_1_2 = re.compile('\n        ')
55 | _241_FIELDS = ('Metadata-Version', 'Name', 'Version', 'Platform', 'Summary', 'Description', 'Keywords', 'Home-page',
56 |                'Author', 'Author-email', 'License')
57 | 
58 | _314_FIELDS = ('Metadata-Version', 'Name', 'Version', 'Platform', 'Supported-Platform', 'Summary', 'Description',
59 |                'Keywords', 'Home-page', 'Author', 'Author-email', 'License', 'Classifier', 'Download-URL', 'Obsoletes',
60 |                'Provides', 'Requires')
61 | 
62 | _314_MARKERS = ('Obsoletes', 'Provides', 'Requires', 'Classifier', 'Download-URL')
63 | 
64 | _345_FIELDS = ('Metadata-Version', 'Name', 'Version', 'Platform', 'Supported-Platform', 'Summary', 'Description',
65 |                'Keywords', 'Home-page', 'Author', 'Author-email', 'Maintainer', 'Maintainer-email', 'License',
66 |                'Classifier', 'Download-URL', 'Obsoletes-Dist', 'Project-URL', 'Provides-Dist', 'Requires-Dist',
67 |                'Requires-Python', 'Requires-External')
68 | 
69 | _345_MARKERS = ('Provides-Dist', 'Requires-Dist', 'Requires-Python', 'Obsoletes-Dist', 'Requires-External',
70 |                 'Maintainer', 'Maintainer-email', 'Project-URL')
71 | 
72 | _426_FIELDS = ('Metadata-Version', 'Name', 'Version', 'Platform', 'Supported-Platform', 'Summary', 'Description',
73 |                'Keywords', 'Home-page', 'Author', 'Author-email', 'Maintainer', 'Maintainer-email', 'License',
74 |                'Classifier', 'Download-URL', 'Obsoletes-Dist', 'Project-URL', 'Provides-Dist', 'Requires-Dist',
75 |                'Requires-Python', 'Requires-External', 'Private-Version', 'Obsoleted-By', 'Setup-Requires-Dist',
76 |                'Extension', 'Provides-Extra')
77 | 
78 | _426_MARKERS = ('Private-Version', 'Provides-Extra', 'Obsoleted-By', 'Setup-Requires-Dist', 'Extension')
79 | 
80 | # See issue #106: Sometimes 'Requires' and 'Provides' occur wrongly in
81 | # the metadata. Include them in the tuple literal below to allow them
82 | # (for now).
83 | # Ditto for Obsoletes - see issue #140.
84 | _566_FIELDS = _426_FIELDS + ('Description-Content-Type', 'Requires', 'Provides', 'Obsoletes')
85 | 
86 | _566_MARKERS = ('Description-Content-Type', )
87 | 
88 | _643_MARKERS = ('Dynamic', 'License-File')
89 | 
90 | _643_FIELDS = _566_FIELDS + _643_MARKERS
91 | 
92 | _ALL_FIELDS = set()
93 | _ALL_FIELDS.update(_241_FIELDS)
94 | _ALL_FIELDS.update(_314_FIELDS)
95 | _ALL_FIELDS.update(_345_FIELDS)
96 | _ALL_FIELDS.update(_426_FIELDS)
97 | _ALL_FIELDS.update(_566_FIELDS)
98 | _ALL_FIELDS.update(_643_FIELDS)
99 | 
100 | EXTRA_RE = re.compile(r'''extra\s*==\s*("([^"]+)"|'([^']+)')''')
101 | 
102 | 
103 | def _version2fieldlist(version):
104 |     if version == '1.0':
105 |         return _241_FIELDS
106 |     elif version == '1.1':
107 |         return _314_FIELDS
108 |     elif version == '1.2':
109 |         return _345_FIELDS
110 |     elif version in ('1.3', '2.1'):
111 |         # avoid adding field names if already there
112 |         return _345_FIELDS + tuple(f for f in _566_FIELDS if f not in _345_FIELDS)
113 |     elif version == '2.0':
114 |         raise ValueError('Metadata 2.0 is withdrawn and not supported')
115 |         # return _426_FIELDS
116 |     elif version == '2.2':
117 |         return _643_FIELDS
118 |     raise MetadataUnrecognizedVersionError(version)
119 | 
120 | 
121 | def _best_version(fields):
122 |     """Detect the best version depending on the fields used."""
123 | 
124 |     def _has_marker(keys, markers):
125 |         return any(marker in keys for marker in markers)
126 | 
127 |     keys = [key for key, value in fields.items() if value not in ([], 'UNKNOWN', None)]
128 |     possible_versions = ['1.0', '1.1', '1.2', '1.3', '2.1', '2.2']  # 2.0 removed
129 | 
130 |     # first let's try to see if a field is not part of one of the version
131 |     for key in keys:
132 |         if key not in _241_FIELDS and '1.0' in possible_versions:
133 |             possible_versions.remove('1.0')
134 |             logger.debug('Removed 1.0 due to %s', key)
135 |         if key not in _314_FIELDS and '1.1' in possible_versions:
136 |             possible_versions.remove('1.1')
137 |             logger.debug('Removed 1.1 due to %s', key)
138 |         if key not in _345_FIELDS and '1.2' in possible_versions:
139 |             possible_versions.remove('1.2')
140 |             logger.debug('Removed 1.2 due to %s', key)
141 |         if key not in _566_FIELDS and '1.3' in possible_versions:
142 |             possible_versions.remove('1.3')
143 |             logger.debug('Removed 1.3 due to %s', key)
144 |         if key not in _566_FIELDS and '2.1' in possible_versions:
145 |             if key != 'Description':  # In 2.1, description allowed after headers
146 |                 possible_versions.remove('2.1')
147 |                 logger.debug('Removed 2.1 due to %s', key)
148 |         if key not in _643_FIELDS and '2.2' in possible_versions:
149 |             possible_versions.remove('2.2')
150 |             logger.debug('Removed 2.2 due to %s', key)
151 |         # if key not in _426_FIELDS and '2.0' in possible_versions:
152 |         # possible_versions.remove('2.0')
153 |         # logger.debug('Removed 2.0 due to %s', key)
154 | 
155 |     # possible_version contains qualified versions
156 |     if len(possible_versions) == 1:
157 |         return possible_versions[0]  # found !
158 |     elif len(possible_versions) == 0:
159 |         logger.debug('Out of options - unknown metadata set: %s', fields)
160 |         raise MetadataConflictError('Unknown metadata set')
161 | 
162 |     # let's see if one unique marker is found
163 |     is_1_1 = '1.1' in possible_versions and _has_marker(keys, _314_MARKERS)
164 |     is_1_2 = '1.2' in possible_versions and _has_marker(keys, _345_MARKERS)
165 |     is_2_1 = '2.1' in possible_versions and _has_marker(keys, _566_MARKERS)
166 |     # is_2_0 = '2.0' in possible_versions and _has_marker(keys, _426_MARKERS)
167 |     is_2_2 = '2.2' in possible_versions and _has_marker(keys, _643_MARKERS)
168 |     if int(is_1_1) + int(is_1_2) + int(is_2_1) + int(is_2_2) > 1:
169 |         raise MetadataConflictError('You used incompatible 1.1/1.2/2.1/2.2 fields')
170 | 
171 |     # we have the choice, 1.0, or 1.2, 2.1 or 2.2
172 |     #   - 1.0 has a broken Summary field but works with all tools
173 |     #   - 1.1 is to avoid
174 |     #   - 1.2 fixes Summary but has little adoption
175 |     #   - 2.1 adds more features
176 |     #   - 2.2 is the latest
177 |     if not is_1_1 and not is_1_2 and not is_2_1 and not is_2_2:
178 |         # we couldn't find any specific marker
179 |         if PKG_INFO_PREFERRED_VERSION in possible_versions:
180 |             return PKG_INFO_PREFERRED_VERSION
181 |     if is_1_1:
182 |         return '1.1'
183 |     if is_1_2:
184 |         return '1.2'
185 |     if is_2_1:
186 |         return '2.1'
187 |     # if is_2_2:
188 |     # return '2.2'
189 | 
190 |     return '2.2'
191 | 
192 | 
193 | # This follows the rules about transforming keys as described in
194 | # https://www.python.org/dev/peps/pep-0566/#id17
195 | _ATTR2FIELD = {name.lower().replace("-", "_"): name for name in _ALL_FIELDS}
196 | _FIELD2ATTR = {field: attr for attr, field in _ATTR2FIELD.items()}
197 | 
198 | _PREDICATE_FIELDS = ('Requires-Dist', 'Obsoletes-Dist', 'Provides-Dist')
199 | _VERSIONS_FIELDS = ('Requires-Python', )
200 | _VERSION_FIELDS = ('Version', )
201 | _LISTFIELDS = ('Platform', 'Classifier', 'Obsoletes', 'Requires', 'Provides', 'Obsoletes-Dist', 'Provides-Dist',
202 |                'Requires-Dist', 'Requires-External', 'Project-URL', 'Supported-Platform', 'Setup-Requires-Dist',
203 |                'Provides-Extra', 'Extension', 'License-File')
204 | _LISTTUPLEFIELDS = ('Project-URL', )
205 | 
206 | _ELEMENTSFIELD = ('Keywords', )
207 | 
208 | _UNICODEFIELDS = ('Author', 'Maintainer', 'Summary', 'Description')
209 | 
210 | _MISSING = object()
211 | 
212 | _FILESAFE = re.compile('[^A-Za-z0-9.]+')
213 | 
214 | 
215 | def _get_name_and_version(name, version, for_filename=False):
216 |     """Return the distribution name with version.
217 | 
218 |     If for_filename is true, return a filename-escaped form."""
219 |     if for_filename:
220 |         # For both name and version any runs of non-alphanumeric or '.'
221 |         # characters are replaced with a single '-'.  Additionally any
222 |         # spaces in the version string become '.'
223 |         name = _FILESAFE.sub('-', name)
224 |         version = _FILESAFE.sub('-', version.replace(' ', '.'))
225 |     return '%s-%s' % (name, version)
226 | 
227 | 
228 | class LegacyMetadata(object):
229 |     """The legacy metadata of a release.
230 | 
231 |     Supports versions 1.0, 1.1, 1.2, 2.0 and 1.3/2.1 (auto-detected). You can
232 |     instantiate the class with one of these arguments (or none):
233 |     - *path*, the path to a metadata file
234 |     - *fileobj* give a file-like object with metadata as content
235 |     - *mapping* is a dict-like object
236 |     - *scheme* is a version scheme name
237 |     """
238 | 
239 |     # TODO document the mapping API and UNKNOWN default key
240 | 
241 |     def __init__(self, path=None, fileobj=None, mapping=None, scheme='default'):
242 |         if [path, fileobj, mapping].count(None) < 2:
243 |             raise TypeError('path, fileobj and mapping are exclusive')
244 |         self._fields = {}
245 |         self.requires_files = []
246 |         self._dependencies = None
247 |         self.scheme = scheme
248 |         if path is not None:
249 |             self.read(path)
250 |         elif fileobj is not None:
251 |             self.read_file(fileobj)
252 |         elif mapping is not None:
253 |             self.update(mapping)
254 |             self.set_metadata_version()
255 | 
256 |     def set_metadata_version(self):
257 |         self._fields['Metadata-Version'] = _best_version(self._fields)
258 | 
259 |     def _write_field(self, fileobj, name, value):
260 |         fileobj.write('%s: %s\n' % (name, value))
261 | 
262 |     def __getitem__(self, name):
263 |         return self.get(name)
264 | 
265 |     def __setitem__(self, name, value):
266 |         return self.set(name, value)
267 | 
268 |     def __delitem__(self, name):
269 |         field_name = self._convert_name(name)
270 |         try:
271 |             del self._fields[field_name]
272 |         except KeyError:
273 |             raise KeyError(name)
274 | 
275 |     def __contains__(self, name):
276 |         return (name in self._fields or self._convert_name(name) in self._fields)
277 | 
278 |     def _convert_name(self, name):
279 |         if name in _ALL_FIELDS:
280 |             return name
281 |         name = name.replace('-', '_').lower()
282 |         return _ATTR2FIELD.get(name, name)
283 | 
284 |     def _default_value(self, name):
285 |         if name in _LISTFIELDS or name in _ELEMENTSFIELD:
286 |             return []
287 |         return 'UNKNOWN'
288 | 
289 |     def _remove_line_prefix(self, value):
290 |         if self.metadata_version in ('1.0', '1.1'):
291 |             return _LINE_PREFIX_PRE_1_2.sub('\n', value)
292 |         else:
293 |             return _LINE_PREFIX_1_2.sub('\n', value)
294 | 
295 |     def __getattr__(self, name):
296 |         if name in _ATTR2FIELD:
297 |             return self[name]
298 |         raise AttributeError(name)
299 | 
300 |     #
301 |     # Public API
302 |     #
303 | 
304 |     def get_fullname(self, filesafe=False):
305 |         """
306 |         Return the distribution name with version.
307 | 
[TRUNCATED]
```

.venv/lib/python3.13/site-packages/pip/_vendor/distlib/resources.py
```
1 | # -*- coding: utf-8 -*-
2 | #
3 | # Copyright (C) 2013-2017 Vinay Sajip.
4 | # Licensed to the Python Software Foundation under a contributor agreement.
5 | # See LICENSE.txt and CONTRIBUTORS.txt.
6 | #
7 | from __future__ import unicode_literals
8 | 
9 | import bisect
10 | import io
11 | import logging
12 | import os
13 | import pkgutil
14 | import sys
15 | import types
16 | import zipimport
17 | 
18 | from . import DistlibException
19 | from .util import cached_property, get_cache_base, Cache
20 | 
21 | logger = logging.getLogger(__name__)
22 | 
23 | 
24 | cache = None    # created when needed
25 | 
26 | 
27 | class ResourceCache(Cache):
28 |     def __init__(self, base=None):
29 |         if base is None:
30 |             # Use native string to avoid issues on 2.x: see Python #20140.
31 |             base = os.path.join(get_cache_base(), str('resource-cache'))
32 |         super(ResourceCache, self).__init__(base)
33 | 
34 |     def is_stale(self, resource, path):
35 |         """
36 |         Is the cache stale for the given resource?
37 | 
38 |         :param resource: The :class:`Resource` being cached.
39 |         :param path: The path of the resource in the cache.
40 |         :return: True if the cache is stale.
41 |         """
42 |         # Cache invalidation is a hard problem :-)
43 |         return True
44 | 
45 |     def get(self, resource):
46 |         """
47 |         Get a resource into the cache,
48 | 
49 |         :param resource: A :class:`Resource` instance.
50 |         :return: The pathname of the resource in the cache.
51 |         """
52 |         prefix, path = resource.finder.get_cache_info(resource)
53 |         if prefix is None:
54 |             result = path
55 |         else:
56 |             result = os.path.join(self.base, self.prefix_to_dir(prefix), path)
57 |             dirname = os.path.dirname(result)
58 |             if not os.path.isdir(dirname):
59 |                 os.makedirs(dirname)
60 |             if not os.path.exists(result):
61 |                 stale = True
62 |             else:
63 |                 stale = self.is_stale(resource, path)
64 |             if stale:
65 |                 # write the bytes of the resource to the cache location
66 |                 with open(result, 'wb') as f:
67 |                     f.write(resource.bytes)
68 |         return result
69 | 
70 | 
71 | class ResourceBase(object):
72 |     def __init__(self, finder, name):
73 |         self.finder = finder
74 |         self.name = name
75 | 
76 | 
77 | class Resource(ResourceBase):
78 |     """
79 |     A class representing an in-package resource, such as a data file. This is
80 |     not normally instantiated by user code, but rather by a
81 |     :class:`ResourceFinder` which manages the resource.
82 |     """
83 |     is_container = False        # Backwards compatibility
84 | 
85 |     def as_stream(self):
86 |         """
87 |         Get the resource as a stream.
88 | 
89 |         This is not a property to make it obvious that it returns a new stream
90 |         each time.
91 |         """
92 |         return self.finder.get_stream(self)
93 | 
94 |     @cached_property
95 |     def file_path(self):
96 |         global cache
97 |         if cache is None:
98 |             cache = ResourceCache()
99 |         return cache.get(self)
100 | 
101 |     @cached_property
102 |     def bytes(self):
103 |         return self.finder.get_bytes(self)
104 | 
105 |     @cached_property
106 |     def size(self):
107 |         return self.finder.get_size(self)
108 | 
109 | 
110 | class ResourceContainer(ResourceBase):
111 |     is_container = True     # Backwards compatibility
112 | 
113 |     @cached_property
114 |     def resources(self):
115 |         return self.finder.get_resources(self)
116 | 
117 | 
118 | class ResourceFinder(object):
119 |     """
120 |     Resource finder for file system resources.
121 |     """
122 | 
123 |     if sys.platform.startswith('java'):
124 |         skipped_extensions = ('.pyc', '.pyo', '.class')
125 |     else:
126 |         skipped_extensions = ('.pyc', '.pyo')
127 | 
128 |     def __init__(self, module):
129 |         self.module = module
130 |         self.loader = getattr(module, '__loader__', None)
131 |         self.base = os.path.dirname(getattr(module, '__file__', ''))
132 | 
133 |     def _adjust_path(self, path):
134 |         return os.path.realpath(path)
135 | 
136 |     def _make_path(self, resource_name):
137 |         # Issue #50: need to preserve type of path on Python 2.x
138 |         # like os.path._get_sep
139 |         if isinstance(resource_name, bytes):    # should only happen on 2.x
140 |             sep = b'/'
141 |         else:
142 |             sep = '/'
143 |         parts = resource_name.split(sep)
144 |         parts.insert(0, self.base)
145 |         result = os.path.join(*parts)
146 |         return self._adjust_path(result)
147 | 
148 |     def _find(self, path):
149 |         return os.path.exists(path)
150 | 
151 |     def get_cache_info(self, resource):
152 |         return None, resource.path
153 | 
154 |     def find(self, resource_name):
155 |         path = self._make_path(resource_name)
156 |         if not self._find(path):
157 |             result = None
158 |         else:
159 |             if self._is_directory(path):
160 |                 result = ResourceContainer(self, resource_name)
161 |             else:
162 |                 result = Resource(self, resource_name)
163 |             result.path = path
164 |         return result
165 | 
166 |     def get_stream(self, resource):
167 |         return open(resource.path, 'rb')
168 | 
169 |     def get_bytes(self, resource):
170 |         with open(resource.path, 'rb') as f:
171 |             return f.read()
172 | 
173 |     def get_size(self, resource):
174 |         return os.path.getsize(resource.path)
175 | 
176 |     def get_resources(self, resource):
177 |         def allowed(f):
178 |             return (f != '__pycache__' and not
179 |                     f.endswith(self.skipped_extensions))
180 |         return set([f for f in os.listdir(resource.path) if allowed(f)])
181 | 
182 |     def is_container(self, resource):
183 |         return self._is_directory(resource.path)
184 | 
185 |     _is_directory = staticmethod(os.path.isdir)
186 | 
187 |     def iterator(self, resource_name):
188 |         resource = self.find(resource_name)
189 |         if resource is not None:
190 |             todo = [resource]
191 |             while todo:
192 |                 resource = todo.pop(0)
193 |                 yield resource
194 |                 if resource.is_container:
195 |                     rname = resource.name
196 |                     for name in resource.resources:
197 |                         if not rname:
198 |                             new_name = name
199 |                         else:
200 |                             new_name = '/'.join([rname, name])
201 |                         child = self.find(new_name)
202 |                         if child.is_container:
203 |                             todo.append(child)
204 |                         else:
205 |                             yield child
206 | 
207 | 
208 | class ZipResourceFinder(ResourceFinder):
209 |     """
210 |     Resource finder for resources in .zip files.
211 |     """
212 |     def __init__(self, module):
213 |         super(ZipResourceFinder, self).__init__(module)
214 |         archive = self.loader.archive
215 |         self.prefix_len = 1 + len(archive)
216 |         # PyPy doesn't have a _files attr on zipimporter, and you can't set one
217 |         if hasattr(self.loader, '_files'):
218 |             self._files = self.loader._files
219 |         else:
220 |             self._files = zipimport._zip_directory_cache[archive]
221 |         self.index = sorted(self._files)
222 | 
223 |     def _adjust_path(self, path):
224 |         return path
225 | 
226 |     def _find(self, path):
227 |         path = path[self.prefix_len:]
228 |         if path in self._files:
229 |             result = True
230 |         else:
231 |             if path and path[-1] != os.sep:
232 |                 path = path + os.sep
233 |             i = bisect.bisect(self.index, path)
234 |             try:
235 |                 result = self.index[i].startswith(path)
236 |             except IndexError:
237 |                 result = False
238 |         if not result:
239 |             logger.debug('_find failed: %r %r', path, self.loader.prefix)
240 |         else:
241 |             logger.debug('_find worked: %r %r', path, self.loader.prefix)
242 |         return result
243 | 
244 |     def get_cache_info(self, resource):
245 |         prefix = self.loader.archive
246 |         path = resource.path[1 + len(prefix):]
247 |         return prefix, path
248 | 
249 |     def get_bytes(self, resource):
250 |         return self.loader.get_data(resource.path)
251 | 
252 |     def get_stream(self, resource):
253 |         return io.BytesIO(self.get_bytes(resource))
254 | 
255 |     def get_size(self, resource):
256 |         path = resource.path[self.prefix_len:]
257 |         return self._files[path][3]
258 | 
259 |     def get_resources(self, resource):
260 |         path = resource.path[self.prefix_len:]
261 |         if path and path[-1] != os.sep:
262 |             path += os.sep
263 |         plen = len(path)
264 |         result = set()
265 |         i = bisect.bisect(self.index, path)
266 |         while i < len(self.index):
267 |             if not self.index[i].startswith(path):
268 |                 break
269 |             s = self.index[i][plen:]
270 |             result.add(s.split(os.sep, 1)[0])   # only immediate children
271 |             i += 1
272 |         return result
273 | 
274 |     def _is_directory(self, path):
275 |         path = path[self.prefix_len:]
276 |         if path and path[-1] != os.sep:
277 |             path += os.sep
278 |         i = bisect.bisect(self.index, path)
279 |         try:
280 |             result = self.index[i].startswith(path)
281 |         except IndexError:
282 |             result = False
283 |         return result
284 | 
285 | 
286 | _finder_registry = {
287 |     type(None): ResourceFinder,
288 |     zipimport.zipimporter: ZipResourceFinder
289 | }
290 | 
291 | try:
292 |     # In Python 3.6, _frozen_importlib -> _frozen_importlib_external
293 |     try:
294 |         import _frozen_importlib_external as _fi
295 |     except ImportError:
296 |         import _frozen_importlib as _fi
297 |     _finder_registry[_fi.SourceFileLoader] = ResourceFinder
298 |     _finder_registry[_fi.FileFinder] = ResourceFinder
299 |     # See issue #146
300 |     _finder_registry[_fi.SourcelessFileLoader] = ResourceFinder
301 |     del _fi
302 | except (ImportError, AttributeError):
303 |     pass
304 | 
305 | 
306 | def register_finder(loader, finder_maker):
307 |     _finder_registry[type(loader)] = finder_maker
308 | 
309 | 
310 | _finder_cache = {}
311 | 
312 | 
313 | def finder(package):
314 |     """
315 |     Return a resource finder for a package.
316 |     :param package: The name of the package.
317 |     :return: A :class:`ResourceFinder` instance for the package.
318 |     """
319 |     if package in _finder_cache:
320 |         result = _finder_cache[package]
321 |     else:
322 |         if package not in sys.modules:
323 |             __import__(package)
324 |         module = sys.modules[package]
325 |         path = getattr(module, '__path__', None)
326 |         if path is None:
327 |             raise DistlibException('You cannot get a finder for a module, '
328 |                                    'only for a package')
329 |         loader = getattr(module, '__loader__', None)
330 |         finder_maker = _finder_registry.get(type(loader))
331 |         if finder_maker is None:
332 |             raise DistlibException('Unable to locate finder for %r' % package)
333 |         result = finder_maker(module)
334 |         _finder_cache[package] = result
335 |     return result
336 | 
337 | 
338 | _dummy_module = types.ModuleType(str('__dummy__'))
339 | 
340 | 
341 | def finder_for_path(path):
342 |     """
343 |     Return a resource finder for a path, which should represent a container.
344 | 
345 |     :param path: The path.
346 |     :return: A :class:`ResourceFinder` instance for the path.
347 |     """
348 |     result = None
349 |     # calls any path hooks, gets importer into cache
350 |     pkgutil.get_importer(path)
351 |     loader = sys.path_importer_cache.get(path)
352 |     finder = _finder_registry.get(type(loader))
353 |     if finder:
354 |         module = _dummy_module
355 |         module.__file__ = os.path.join(path, '')
356 |         module.__loader__ = loader
357 |         result = finder(module)
358 |     return result
```

.venv/lib/python3.13/site-packages/pip/_vendor/distlib/scripts.py
```
1 | # -*- coding: utf-8 -*-
2 | #
3 | # Copyright (C) 2013-2023 Vinay Sajip.
4 | # Licensed to the Python Software Foundation under a contributor agreement.
5 | # See LICENSE.txt and CONTRIBUTORS.txt.
6 | #
7 | from io import BytesIO
8 | import logging
9 | import os
10 | import re
11 | import struct
12 | import sys
13 | import time
14 | from zipfile import ZipInfo
15 | 
16 | from .compat import sysconfig, detect_encoding, ZipFile
17 | from .resources import finder
18 | from .util import (FileOperator, get_export_entry, convert_path, get_executable, get_platform, in_venv)
19 | 
20 | logger = logging.getLogger(__name__)
21 | 
22 | _DEFAULT_MANIFEST = '''
23 | <?xml version="1.0" encoding="UTF-8" standalone="yes"?>
24 | <assembly xmlns="urn:schemas-microsoft-com:asm.v1" manifestVersion="1.0">
25 |  <assemblyIdentity version="1.0.0.0"
26 |  processorArchitecture="X86"
27 |  name="%s"
28 |  type="win32"/>
29 | 
30 |  <!-- Identify the application security requirements. -->
31 |  <trustInfo xmlns="urn:schemas-microsoft-com:asm.v3">
32 |  <security>
33 |  <requestedPrivileges>
34 |  <requestedExecutionLevel level="asInvoker" uiAccess="false"/>
35 |  </requestedPrivileges>
36 |  </security>
37 |  </trustInfo>
38 | </assembly>'''.strip()
39 | 
40 | # check if Python is called on the first line with this expression
41 | FIRST_LINE_RE = re.compile(b'^#!.*pythonw?[0-9.]*([ \t].*)?$')
42 | SCRIPT_TEMPLATE = r'''# -*- coding: utf-8 -*-
43 | import re
44 | import sys
45 | from %(module)s import %(import_name)s
46 | if __name__ == '__main__':
47 |     sys.argv[0] = re.sub(r'(-script\.pyw|\.exe)?$', '', sys.argv[0])
48 |     sys.exit(%(func)s())
49 | '''
50 | 
51 | # Pre-fetch the contents of all executable wrapper stubs.
52 | # This is to address https://github.com/pypa/pip/issues/12666.
53 | # When updating pip, we rename the old pip in place before installing the
54 | # new version. If we try to fetch a wrapper *after* that rename, the finder
55 | # machinery will be confused as the package is no longer available at the
56 | # location where it was imported from. So we load everything into memory in
57 | # advance.
58 | 
59 | if os.name == 'nt' or (os.name == 'java' and os._name == 'nt'):
60 |     # Issue 31: don't hardcode an absolute package name, but
61 |     # determine it relative to the current package
62 |     DISTLIB_PACKAGE = __name__.rsplit('.', 1)[0]
63 | 
64 |     WRAPPERS = {
65 |         r.name: r.bytes
66 |         for r in finder(DISTLIB_PACKAGE).iterator("")
67 |         if r.name.endswith(".exe")
68 |     }
69 | 
70 | 
71 | def enquote_executable(executable):
72 |     if ' ' in executable:
73 |         # make sure we quote only the executable in case of env
74 |         # for example /usr/bin/env "/dir with spaces/bin/jython"
75 |         # instead of "/usr/bin/env /dir with spaces/bin/jython"
76 |         # otherwise whole
77 |         if executable.startswith('/usr/bin/env '):
78 |             env, _executable = executable.split(' ', 1)
79 |             if ' ' in _executable and not _executable.startswith('"'):
80 |                 executable = '%s "%s"' % (env, _executable)
81 |         else:
82 |             if not executable.startswith('"'):
83 |                 executable = '"%s"' % executable
84 |     return executable
85 | 
86 | 
87 | # Keep the old name around (for now), as there is at least one project using it!
88 | _enquote_executable = enquote_executable
89 | 
90 | 
91 | class ScriptMaker(object):
92 |     """
93 |     A class to copy or create scripts from source scripts or callable
94 |     specifications.
95 |     """
96 |     script_template = SCRIPT_TEMPLATE
97 | 
98 |     executable = None  # for shebangs
99 | 
100 |     def __init__(self, source_dir, target_dir, add_launchers=True, dry_run=False, fileop=None):
101 |         self.source_dir = source_dir
102 |         self.target_dir = target_dir
103 |         self.add_launchers = add_launchers
104 |         self.force = False
105 |         self.clobber = False
106 |         # It only makes sense to set mode bits on POSIX.
107 |         self.set_mode = (os.name == 'posix') or (os.name == 'java' and os._name == 'posix')
108 |         self.variants = set(('', 'X.Y'))
109 |         self._fileop = fileop or FileOperator(dry_run)
110 | 
111 |         self._is_nt = os.name == 'nt' or (os.name == 'java' and os._name == 'nt')
112 |         self.version_info = sys.version_info
113 | 
114 |     def _get_alternate_executable(self, executable, options):
115 |         if options.get('gui', False) and self._is_nt:  # pragma: no cover
116 |             dn, fn = os.path.split(executable)
117 |             fn = fn.replace('python', 'pythonw')
118 |             executable = os.path.join(dn, fn)
119 |         return executable
120 | 
121 |     if sys.platform.startswith('java'):  # pragma: no cover
122 | 
123 |         def _is_shell(self, executable):
124 |             """
125 |             Determine if the specified executable is a script
126 |             (contains a #! line)
127 |             """
128 |             try:
129 |                 with open(executable) as fp:
130 |                     return fp.read(2) == '#!'
131 |             except (OSError, IOError):
132 |                 logger.warning('Failed to open %s', executable)
133 |                 return False
134 | 
135 |         def _fix_jython_executable(self, executable):
136 |             if self._is_shell(executable):
137 |                 # Workaround for Jython is not needed on Linux systems.
138 |                 import java
139 | 
140 |                 if java.lang.System.getProperty('os.name') == 'Linux':
141 |                     return executable
142 |             elif executable.lower().endswith('jython.exe'):
143 |                 # Use wrapper exe for Jython on Windows
144 |                 return executable
145 |             return '/usr/bin/env %s' % executable
146 | 
147 |     def _build_shebang(self, executable, post_interp):
148 |         """
149 |         Build a shebang line. In the simple case (on Windows, or a shebang line
150 |         which is not too long or contains spaces) use a simple formulation for
151 |         the shebang. Otherwise, use /bin/sh as the executable, with a contrived
152 |         shebang which allows the script to run either under Python or sh, using
153 |         suitable quoting. Thanks to Harald Nordgren for his input.
154 | 
155 |         See also: http://www.in-ulm.de/~mascheck/various/shebang/#length
156 |                   https://hg.mozilla.org/mozilla-central/file/tip/mach
157 |         """
158 |         if os.name != 'posix':
159 |             simple_shebang = True
160 |         elif getattr(sys, "cross_compiling", False):
161 |             # In a cross-compiling environment, the shebang will likely be a
162 |             # script; this *must* be invoked with the "safe" version of the
163 |             # shebang, or else using os.exec() to run the entry script will
164 |             # fail, raising "OSError 8 [Errno 8] Exec format error".
165 |             simple_shebang = False
166 |         else:
167 |             # Add 3 for '#!' prefix and newline suffix.
168 |             shebang_length = len(executable) + len(post_interp) + 3
169 |             if sys.platform == 'darwin':
170 |                 max_shebang_length = 512
171 |             else:
172 |                 max_shebang_length = 127
173 |             simple_shebang = ((b' ' not in executable) and (shebang_length <= max_shebang_length))
174 | 
175 |         if simple_shebang:
176 |             result = b'#!' + executable + post_interp + b'\n'
177 |         else:
178 |             result = b'#!/bin/sh\n'
179 |             result += b"'''exec' " + executable + post_interp + b' "$0" "$@"\n'
180 |             result += b"' '''\n"
181 |         return result
182 | 
183 |     def _get_shebang(self, encoding, post_interp=b'', options=None):
184 |         enquote = True
185 |         if self.executable:
186 |             executable = self.executable
187 |             enquote = False  # assume this will be taken care of
188 |         elif not sysconfig.is_python_build():
189 |             executable = get_executable()
190 |         elif in_venv():  # pragma: no cover
191 |             executable = os.path.join(sysconfig.get_path('scripts'), 'python%s' % sysconfig.get_config_var('EXE'))
192 |         else:  # pragma: no cover
193 |             if os.name == 'nt':
194 |                 # for Python builds from source on Windows, no Python executables with
195 |                 # a version suffix are created, so we use python.exe
196 |                 executable = os.path.join(sysconfig.get_config_var('BINDIR'),
197 |                                           'python%s' % (sysconfig.get_config_var('EXE')))
198 |             else:
199 |                 executable = os.path.join(
200 |                     sysconfig.get_config_var('BINDIR'),
201 |                     'python%s%s' % (sysconfig.get_config_var('VERSION'), sysconfig.get_config_var('EXE')))
202 |         if options:
203 |             executable = self._get_alternate_executable(executable, options)
204 | 
205 |         if sys.platform.startswith('java'):  # pragma: no cover
206 |             executable = self._fix_jython_executable(executable)
207 | 
208 |         # Normalise case for Windows - COMMENTED OUT
209 |         # executable = os.path.normcase(executable)
210 |         # N.B. The normalising operation above has been commented out: See
211 |         # issue #124. Although paths in Windows are generally case-insensitive,
212 |         # they aren't always. For example, a path containing a  (which is a
213 |         # LATIN CAPITAL LETTER SHARP S - U+1E9E) is normcased to  (which is a
214 |         # LATIN SMALL LETTER SHARP S' - U+00DF). The two are not considered by
215 |         # Windows as equivalent in path names.
216 | 
217 |         # If the user didn't specify an executable, it may be necessary to
218 |         # cater for executable paths with spaces (not uncommon on Windows)
219 |         if enquote:
220 |             executable = enquote_executable(executable)
221 |         # Issue #51: don't use fsencode, since we later try to
222 |         # check that the shebang is decodable using utf-8.
223 |         executable = executable.encode('utf-8')
224 |         # in case of IronPython, play safe and enable frames support
225 |         if (sys.platform == 'cli' and '-X:Frames' not in post_interp and
226 |                 '-X:FullFrames' not in post_interp):  # pragma: no cover
227 |             post_interp += b' -X:Frames'
228 |         shebang = self._build_shebang(executable, post_interp)
229 |         # Python parser starts to read a script using UTF-8 until
230 |         # it gets a #coding:xxx cookie. The shebang has to be the
231 |         # first line of a file, the #coding:xxx cookie cannot be
232 |         # written before. So the shebang has to be decodable from
233 |         # UTF-8.
234 |         try:
235 |             shebang.decode('utf-8')
236 |         except UnicodeDecodeError:  # pragma: no cover
237 |             raise ValueError('The shebang (%r) is not decodable from utf-8' % shebang)
238 |         # If the script is encoded to a custom encoding (use a
239 |         # #coding:xxx cookie), the shebang has to be decodable from
240 |         # the script encoding too.
241 |         if encoding != 'utf-8':
242 |             try:
243 |                 shebang.decode(encoding)
244 |             except UnicodeDecodeError:  # pragma: no cover
245 |                 raise ValueError('The shebang (%r) is not decodable '
246 |                                  'from the script encoding (%r)' % (shebang, encoding))
247 |         return shebang
248 | 
249 |     def _get_script_text(self, entry):
250 |         return self.script_template % dict(
251 |             module=entry.prefix, import_name=entry.suffix.split('.')[0], func=entry.suffix)
252 | 
253 |     manifest = _DEFAULT_MANIFEST
254 | 
255 |     def get_manifest(self, exename):
256 |         base = os.path.basename(exename)
257 |         return self.manifest % base
258 | 
259 |     def _write_script(self, names, shebang, script_bytes, filenames, ext):
260 |         use_launcher = self.add_launchers and self._is_nt
261 |         if not use_launcher:
262 |             script_bytes = shebang + script_bytes
263 |         else:  # pragma: no cover
264 |             if ext == 'py':
265 |                 launcher = self._get_launcher('t')
266 |             else:
267 |                 launcher = self._get_launcher('w')
268 |             stream = BytesIO()
269 |             with ZipFile(stream, 'w') as zf:
270 |                 source_date_epoch = os.environ.get('SOURCE_DATE_EPOCH')
271 |                 if source_date_epoch:
272 |                     date_time = time.gmtime(int(source_date_epoch))[:6]
273 |                     zinfo = ZipInfo(filename='__main__.py', date_time=date_time)
274 |                     zf.writestr(zinfo, script_bytes)
275 |                 else:
276 |                     zf.writestr('__main__.py', script_bytes)
277 |             zip_data = stream.getvalue()
278 |             script_bytes = launcher + shebang + zip_data
279 |         for name in names:
280 |             outname = os.path.join(self.target_dir, name)
281 |             if use_launcher:  # pragma: no cover
282 |                 n, e = os.path.splitext(outname)
283 |                 if e.startswith('.py'):
284 |                     outname = n
285 |                 outname = '%s.exe' % outname
286 |                 try:
287 |                     self._fileop.write_binary_file(outname, script_bytes)
288 |                 except Exception:
289 |                     # Failed writing an executable - it might be in use.
290 |                     logger.warning('Failed to write executable - trying to '
291 |                                    'use .deleteme logic')
292 |                     dfname = '%s.deleteme' % outname
293 |                     if os.path.exists(dfname):
[TRUNCATED]
```

.venv/lib/python3.13/site-packages/pip/_vendor/distlib/util.py
```
1 | #
2 | # Copyright (C) 2012-2023 The Python Software Foundation.
3 | # See LICENSE.txt and CONTRIBUTORS.txt.
4 | #
5 | import codecs
6 | from collections import deque
7 | import contextlib
8 | import csv
9 | from glob import iglob as std_iglob
10 | import io
11 | import json
12 | import logging
13 | import os
14 | import py_compile
15 | import re
16 | import socket
17 | try:
18 |     import ssl
19 | except ImportError:  # pragma: no cover
20 |     ssl = None
21 | import subprocess
22 | import sys
23 | import tarfile
24 | import tempfile
25 | import textwrap
26 | 
27 | try:
28 |     import threading
29 | except ImportError:  # pragma: no cover
30 |     import dummy_threading as threading
31 | import time
32 | 
33 | from . import DistlibException
34 | from .compat import (string_types, text_type, shutil, raw_input, StringIO, cache_from_source, urlopen, urljoin, httplib,
35 |                      xmlrpclib, HTTPHandler, BaseConfigurator, valid_ident, Container, configparser, URLError, ZipFile,
36 |                      fsdecode, unquote, urlparse)
37 | 
38 | logger = logging.getLogger(__name__)
39 | 
40 | #
41 | # Requirement parsing code as per PEP 508
42 | #
43 | 
44 | IDENTIFIER = re.compile(r'^([\w\.-]+)\s*')
45 | VERSION_IDENTIFIER = re.compile(r'^([\w\.*+-]+)\s*')
46 | COMPARE_OP = re.compile(r'^(<=?|>=?|={2,3}|[~!]=)\s*')
47 | MARKER_OP = re.compile(r'^((<=?)|(>=?)|={2,3}|[~!]=|in|not\s+in)\s*')
48 | OR = re.compile(r'^or\b\s*')
49 | AND = re.compile(r'^and\b\s*')
50 | NON_SPACE = re.compile(r'(\S+)\s*')
51 | STRING_CHUNK = re.compile(r'([\s\w\.{}()*+#:;,/?!~`@$%^&=|<>\[\]-]+)')
52 | 
53 | 
54 | def parse_marker(marker_string):
55 |     """
56 |     Parse a marker string and return a dictionary containing a marker expression.
57 | 
58 |     The dictionary will contain keys "op", "lhs" and "rhs" for non-terminals in
59 |     the expression grammar, or strings. A string contained in quotes is to be
60 |     interpreted as a literal string, and a string not contained in quotes is a
61 |     variable (such as os_name).
62 |     """
63 | 
64 |     def marker_var(remaining):
65 |         # either identifier, or literal string
66 |         m = IDENTIFIER.match(remaining)
67 |         if m:
68 |             result = m.groups()[0]
69 |             remaining = remaining[m.end():]
70 |         elif not remaining:
71 |             raise SyntaxError('unexpected end of input')
72 |         else:
73 |             q = remaining[0]
74 |             if q not in '\'"':
75 |                 raise SyntaxError('invalid expression: %s' % remaining)
76 |             oq = '\'"'.replace(q, '')
77 |             remaining = remaining[1:]
78 |             parts = [q]
79 |             while remaining:
80 |                 # either a string chunk, or oq, or q to terminate
81 |                 if remaining[0] == q:
82 |                     break
83 |                 elif remaining[0] == oq:
84 |                     parts.append(oq)
85 |                     remaining = remaining[1:]
86 |                 else:
87 |                     m = STRING_CHUNK.match(remaining)
88 |                     if not m:
89 |                         raise SyntaxError('error in string literal: %s' % remaining)
90 |                     parts.append(m.groups()[0])
91 |                     remaining = remaining[m.end():]
92 |             else:
93 |                 s = ''.join(parts)
94 |                 raise SyntaxError('unterminated string: %s' % s)
95 |             parts.append(q)
96 |             result = ''.join(parts)
97 |             remaining = remaining[1:].lstrip()  # skip past closing quote
98 |         return result, remaining
99 | 
100 |     def marker_expr(remaining):
101 |         if remaining and remaining[0] == '(':
102 |             result, remaining = marker(remaining[1:].lstrip())
103 |             if remaining[0] != ')':
104 |                 raise SyntaxError('unterminated parenthesis: %s' % remaining)
105 |             remaining = remaining[1:].lstrip()
106 |         else:
107 |             lhs, remaining = marker_var(remaining)
108 |             while remaining:
109 |                 m = MARKER_OP.match(remaining)
110 |                 if not m:
111 |                     break
112 |                 op = m.groups()[0]
113 |                 remaining = remaining[m.end():]
114 |                 rhs, remaining = marker_var(remaining)
115 |                 lhs = {'op': op, 'lhs': lhs, 'rhs': rhs}
116 |             result = lhs
117 |         return result, remaining
118 | 
119 |     def marker_and(remaining):
120 |         lhs, remaining = marker_expr(remaining)
121 |         while remaining:
122 |             m = AND.match(remaining)
123 |             if not m:
124 |                 break
125 |             remaining = remaining[m.end():]
126 |             rhs, remaining = marker_expr(remaining)
127 |             lhs = {'op': 'and', 'lhs': lhs, 'rhs': rhs}
128 |         return lhs, remaining
129 | 
130 |     def marker(remaining):
131 |         lhs, remaining = marker_and(remaining)
132 |         while remaining:
133 |             m = OR.match(remaining)
134 |             if not m:
135 |                 break
136 |             remaining = remaining[m.end():]
137 |             rhs, remaining = marker_and(remaining)
138 |             lhs = {'op': 'or', 'lhs': lhs, 'rhs': rhs}
139 |         return lhs, remaining
140 | 
141 |     return marker(marker_string)
142 | 
143 | 
144 | def parse_requirement(req):
145 |     """
146 |     Parse a requirement passed in as a string. Return a Container
147 |     whose attributes contain the various parts of the requirement.
148 |     """
149 |     remaining = req.strip()
150 |     if not remaining or remaining.startswith('#'):
151 |         return None
152 |     m = IDENTIFIER.match(remaining)
153 |     if not m:
154 |         raise SyntaxError('name expected: %s' % remaining)
155 |     distname = m.groups()[0]
156 |     remaining = remaining[m.end():]
157 |     extras = mark_expr = versions = uri = None
158 |     if remaining and remaining[0] == '[':
159 |         i = remaining.find(']', 1)
160 |         if i < 0:
161 |             raise SyntaxError('unterminated extra: %s' % remaining)
162 |         s = remaining[1:i]
163 |         remaining = remaining[i + 1:].lstrip()
164 |         extras = []
165 |         while s:
166 |             m = IDENTIFIER.match(s)
167 |             if not m:
168 |                 raise SyntaxError('malformed extra: %s' % s)
169 |             extras.append(m.groups()[0])
170 |             s = s[m.end():]
171 |             if not s:
172 |                 break
173 |             if s[0] != ',':
174 |                 raise SyntaxError('comma expected in extras: %s' % s)
175 |             s = s[1:].lstrip()
176 |         if not extras:
177 |             extras = None
178 |     if remaining:
179 |         if remaining[0] == '@':
180 |             # it's a URI
181 |             remaining = remaining[1:].lstrip()
182 |             m = NON_SPACE.match(remaining)
183 |             if not m:
184 |                 raise SyntaxError('invalid URI: %s' % remaining)
185 |             uri = m.groups()[0]
186 |             t = urlparse(uri)
187 |             # there are issues with Python and URL parsing, so this test
188 |             # is a bit crude. See bpo-20271, bpo-23505. Python doesn't
189 |             # always parse invalid URLs correctly - it should raise
190 |             # exceptions for malformed URLs
191 |             if not (t.scheme and t.netloc):
192 |                 raise SyntaxError('Invalid URL: %s' % uri)
193 |             remaining = remaining[m.end():].lstrip()
194 |         else:
195 | 
196 |             def get_versions(ver_remaining):
197 |                 """
198 |                 Return a list of operator, version tuples if any are
199 |                 specified, else None.
200 |                 """
201 |                 m = COMPARE_OP.match(ver_remaining)
202 |                 versions = None
203 |                 if m:
204 |                     versions = []
205 |                     while True:
206 |                         op = m.groups()[0]
207 |                         ver_remaining = ver_remaining[m.end():]
208 |                         m = VERSION_IDENTIFIER.match(ver_remaining)
209 |                         if not m:
210 |                             raise SyntaxError('invalid version: %s' % ver_remaining)
211 |                         v = m.groups()[0]
212 |                         versions.append((op, v))
213 |                         ver_remaining = ver_remaining[m.end():]
214 |                         if not ver_remaining or ver_remaining[0] != ',':
215 |                             break
216 |                         ver_remaining = ver_remaining[1:].lstrip()
217 |                         # Some packages have a trailing comma which would break things
218 |                         # See issue #148
219 |                         if not ver_remaining:
220 |                             break
221 |                         m = COMPARE_OP.match(ver_remaining)
222 |                         if not m:
223 |                             raise SyntaxError('invalid constraint: %s' % ver_remaining)
224 |                     if not versions:
225 |                         versions = None
226 |                 return versions, ver_remaining
227 | 
228 |             if remaining[0] != '(':
229 |                 versions, remaining = get_versions(remaining)
230 |             else:
231 |                 i = remaining.find(')', 1)
232 |                 if i < 0:
233 |                     raise SyntaxError('unterminated parenthesis: %s' % remaining)
234 |                 s = remaining[1:i]
235 |                 remaining = remaining[i + 1:].lstrip()
236 |                 # As a special diversion from PEP 508, allow a version number
237 |                 # a.b.c in parentheses as a synonym for ~= a.b.c (because this
238 |                 # is allowed in earlier PEPs)
239 |                 if COMPARE_OP.match(s):
240 |                     versions, _ = get_versions(s)
241 |                 else:
242 |                     m = VERSION_IDENTIFIER.match(s)
243 |                     if not m:
244 |                         raise SyntaxError('invalid constraint: %s' % s)
245 |                     v = m.groups()[0]
246 |                     s = s[m.end():].lstrip()
247 |                     if s:
248 |                         raise SyntaxError('invalid constraint: %s' % s)
249 |                     versions = [('~=', v)]
250 | 
251 |     if remaining:
252 |         if remaining[0] != ';':
253 |             raise SyntaxError('invalid requirement: %s' % remaining)
254 |         remaining = remaining[1:].lstrip()
255 | 
256 |         mark_expr, remaining = parse_marker(remaining)
257 | 
258 |     if remaining and remaining[0] != '#':
259 |         raise SyntaxError('unexpected trailing data: %s' % remaining)
260 | 
261 |     if not versions:
262 |         rs = distname
263 |     else:
264 |         rs = '%s %s' % (distname, ', '.join(['%s %s' % con for con in versions]))
265 |     return Container(name=distname, extras=extras, constraints=versions, marker=mark_expr, url=uri, requirement=rs)
266 | 
267 | 
268 | def get_resources_dests(resources_root, rules):
269 |     """Find destinations for resources files"""
270 | 
271 |     def get_rel_path(root, path):
272 |         # normalizes and returns a lstripped-/-separated path
273 |         root = root.replace(os.path.sep, '/')
274 |         path = path.replace(os.path.sep, '/')
275 |         assert path.startswith(root)
276 |         return path[len(root):].lstrip('/')
277 | 
278 |     destinations = {}
279 |     for base, suffix, dest in rules:
280 |         prefix = os.path.join(resources_root, base)
281 |         for abs_base in iglob(prefix):
282 |             abs_glob = os.path.join(abs_base, suffix)
283 |             for abs_path in iglob(abs_glob):
284 |                 resource_file = get_rel_path(resources_root, abs_path)
285 |                 if dest is None:  # remove the entry if it was here
286 |                     destinations.pop(resource_file, None)
287 |                 else:
288 |                     rel_path = get_rel_path(abs_base, abs_path)
289 |                     rel_dest = dest.replace(os.path.sep, '/').rstrip('/')
290 |                     destinations[resource_file] = rel_dest + '/' + rel_path
291 |     return destinations
292 | 
293 | 
294 | def in_venv():
295 |     if hasattr(sys, 'real_prefix'):
296 |         # virtualenv venvs
297 |         result = True
298 |     else:
299 |         # PEP 405 venvs
300 |         result = sys.prefix != getattr(sys, 'base_prefix', sys.prefix)
301 |     return result
302 | 
303 | 
304 | def get_executable():
305 |     # The __PYVENV_LAUNCHER__ dance is apparently no longer needed, as
306 |     # changes to the stub launcher mean that sys.executable always points
307 |     # to the stub on OS X
308 |     #    if sys.platform == 'darwin' and ('__PYVENV_LAUNCHER__'
309 |     #                                     in os.environ):
310 |     #        result =  os.environ['__PYVENV_LAUNCHER__']
311 |     #    else:
312 |     #        result = sys.executable
313 |     #    return result
314 |     # Avoid normcasing: see issue #143
315 |     # result = os.path.normcase(sys.executable)
316 |     result = sys.executable
317 |     if not isinstance(result, text_type):
318 |         result = fsdecode(result)
319 |     return result
320 | 
321 | 
322 | def proceed(prompt, allowed_chars, error_prompt=None, default=None):
323 |     p = prompt
324 |     while True:
325 |         s = raw_input(p)
326 |         p = prompt
327 |         if not s and default:
328 |             s = default
329 |         if s:
330 |             c = s[0].lower()
331 |             if c in allowed_chars:
332 |                 break
333 |             if error_prompt:
334 |                 p = '%c: %s\n%s' % (c, error_prompt, prompt)
335 |     return c
336 | 
337 | 
338 | def extract_by_key(d, keys):
339 |     if isinstance(keys, string_types):
340 |         keys = keys.split()
341 |     result = {}
342 |     for key in keys:
343 |         if key in d:
344 |             result[key] = d[key]
345 |     return result
346 | 
347 | 
348 | def read_exports(stream):
349 |     if sys.version_info[0] >= 3:
350 |         # needs to be a text stream
[TRUNCATED]
```

.venv/lib/python3.13/site-packages/pip/_vendor/distlib/version.py
```
1 | # -*- coding: utf-8 -*-
2 | #
3 | # Copyright (C) 2012-2023 The Python Software Foundation.
4 | # See LICENSE.txt and CONTRIBUTORS.txt.
5 | #
6 | """
7 | Implementation of a flexible versioning scheme providing support for PEP-440,
8 | setuptools-compatible and semantic versioning.
9 | """
10 | 
11 | import logging
12 | import re
13 | 
14 | from .compat import string_types
15 | from .util import parse_requirement
16 | 
17 | __all__ = ['NormalizedVersion', 'NormalizedMatcher',
18 |            'LegacyVersion', 'LegacyMatcher',
19 |            'SemanticVersion', 'SemanticMatcher',
20 |            'UnsupportedVersionError', 'get_scheme']
21 | 
22 | logger = logging.getLogger(__name__)
23 | 
24 | 
25 | class UnsupportedVersionError(ValueError):
26 |     """This is an unsupported version."""
27 |     pass
28 | 
29 | 
30 | class Version(object):
31 |     def __init__(self, s):
32 |         self._string = s = s.strip()
33 |         self._parts = parts = self.parse(s)
34 |         assert isinstance(parts, tuple)
35 |         assert len(parts) > 0
36 | 
37 |     def parse(self, s):
38 |         raise NotImplementedError('please implement in a subclass')
39 | 
40 |     def _check_compatible(self, other):
41 |         if type(self) != type(other):
42 |             raise TypeError('cannot compare %r and %r' % (self, other))
43 | 
44 |     def __eq__(self, other):
45 |         self._check_compatible(other)
46 |         return self._parts == other._parts
47 | 
48 |     def __ne__(self, other):
49 |         return not self.__eq__(other)
50 | 
51 |     def __lt__(self, other):
52 |         self._check_compatible(other)
53 |         return self._parts < other._parts
54 | 
55 |     def __gt__(self, other):
56 |         return not (self.__lt__(other) or self.__eq__(other))
57 | 
58 |     def __le__(self, other):
59 |         return self.__lt__(other) or self.__eq__(other)
60 | 
61 |     def __ge__(self, other):
62 |         return self.__gt__(other) or self.__eq__(other)
63 | 
64 |     # See http://docs.python.org/reference/datamodel#object.__hash__
65 |     def __hash__(self):
66 |         return hash(self._parts)
67 | 
68 |     def __repr__(self):
69 |         return "%s('%s')" % (self.__class__.__name__, self._string)
70 | 
71 |     def __str__(self):
72 |         return self._string
73 | 
74 |     @property
75 |     def is_prerelease(self):
76 |         raise NotImplementedError('Please implement in subclasses.')
77 | 
78 | 
79 | class Matcher(object):
80 |     version_class = None
81 | 
82 |     # value is either a callable or the name of a method
83 |     _operators = {
84 |         '<': lambda v, c, p: v < c,
85 |         '>': lambda v, c, p: v > c,
86 |         '<=': lambda v, c, p: v == c or v < c,
87 |         '>=': lambda v, c, p: v == c or v > c,
88 |         '==': lambda v, c, p: v == c,
89 |         '===': lambda v, c, p: v == c,
90 |         # by default, compatible => >=.
91 |         '~=': lambda v, c, p: v == c or v > c,
92 |         '!=': lambda v, c, p: v != c,
93 |     }
94 | 
95 |     # this is a method only to support alternative implementations
96 |     # via overriding
97 |     def parse_requirement(self, s):
98 |         return parse_requirement(s)
99 | 
100 |     def __init__(self, s):
101 |         if self.version_class is None:
102 |             raise ValueError('Please specify a version class')
103 |         self._string = s = s.strip()
104 |         r = self.parse_requirement(s)
105 |         if not r:
106 |             raise ValueError('Not valid: %r' % s)
107 |         self.name = r.name
108 |         self.key = self.name.lower()    # for case-insensitive comparisons
109 |         clist = []
110 |         if r.constraints:
111 |             # import pdb; pdb.set_trace()
112 |             for op, s in r.constraints:
113 |                 if s.endswith('.*'):
114 |                     if op not in ('==', '!='):
115 |                         raise ValueError('\'.*\' not allowed for '
116 |                                          '%r constraints' % op)
117 |                     # Could be a partial version (e.g. for '2.*') which
118 |                     # won't parse as a version, so keep it as a string
119 |                     vn, prefix = s[:-2], True
120 |                     # Just to check that vn is a valid version
121 |                     self.version_class(vn)
122 |                 else:
123 |                     # Should parse as a version, so we can create an
124 |                     # instance for the comparison
125 |                     vn, prefix = self.version_class(s), False
126 |                 clist.append((op, vn, prefix))
127 |         self._parts = tuple(clist)
128 | 
129 |     def match(self, version):
130 |         """
131 |         Check if the provided version matches the constraints.
132 | 
133 |         :param version: The version to match against this instance.
134 |         :type version: String or :class:`Version` instance.
135 |         """
136 |         if isinstance(version, string_types):
137 |             version = self.version_class(version)
138 |         for operator, constraint, prefix in self._parts:
139 |             f = self._operators.get(operator)
140 |             if isinstance(f, string_types):
141 |                 f = getattr(self, f)
142 |             if not f:
143 |                 msg = ('%r not implemented '
144 |                        'for %s' % (operator, self.__class__.__name__))
145 |                 raise NotImplementedError(msg)
146 |             if not f(version, constraint, prefix):
147 |                 return False
148 |         return True
149 | 
150 |     @property
151 |     def exact_version(self):
152 |         result = None
153 |         if len(self._parts) == 1 and self._parts[0][0] in ('==', '==='):
154 |             result = self._parts[0][1]
155 |         return result
156 | 
157 |     def _check_compatible(self, other):
158 |         if type(self) != type(other) or self.name != other.name:
159 |             raise TypeError('cannot compare %s and %s' % (self, other))
160 | 
161 |     def __eq__(self, other):
162 |         self._check_compatible(other)
163 |         return self.key == other.key and self._parts == other._parts
164 | 
165 |     def __ne__(self, other):
166 |         return not self.__eq__(other)
167 | 
168 |     # See http://docs.python.org/reference/datamodel#object.__hash__
169 |     def __hash__(self):
170 |         return hash(self.key) + hash(self._parts)
171 | 
172 |     def __repr__(self):
173 |         return "%s(%r)" % (self.__class__.__name__, self._string)
174 | 
175 |     def __str__(self):
176 |         return self._string
177 | 
178 | 
179 | PEP440_VERSION_RE = re.compile(r'^v?(\d+!)?(\d+(\.\d+)*)((a|alpha|b|beta|c|rc|pre|preview)(\d+)?)?'
180 |                                r'(\.(post|r|rev)(\d+)?)?([._-]?(dev)(\d+)?)?'
181 |                                r'(\+([a-zA-Z\d]+(\.[a-zA-Z\d]+)?))?$', re.I)
182 | 
183 | 
184 | def _pep_440_key(s):
185 |     s = s.strip()
186 |     m = PEP440_VERSION_RE.match(s)
187 |     if not m:
188 |         raise UnsupportedVersionError('Not a valid version: %s' % s)
189 |     groups = m.groups()
190 |     nums = tuple(int(v) for v in groups[1].split('.'))
191 |     while len(nums) > 1 and nums[-1] == 0:
192 |         nums = nums[:-1]
193 | 
194 |     if not groups[0]:
195 |         epoch = 0
196 |     else:
197 |         epoch = int(groups[0][:-1])
198 |     pre = groups[4:6]
199 |     post = groups[7:9]
200 |     dev = groups[10:12]
201 |     local = groups[13]
202 |     if pre == (None, None):
203 |         pre = ()
204 |     else:
205 |         if pre[1] is None:
206 |             pre = pre[0], 0
207 |         else:
208 |             pre = pre[0], int(pre[1])
209 |     if post == (None, None):
210 |         post = ()
211 |     else:
212 |         if post[1] is None:
213 |             post = post[0], 0
214 |         else:
215 |             post = post[0], int(post[1])
216 |     if dev == (None, None):
217 |         dev = ()
218 |     else:
219 |         if dev[1] is None:
220 |             dev = dev[0], 0
221 |         else:
222 |             dev = dev[0], int(dev[1])
223 |     if local is None:
224 |         local = ()
225 |     else:
226 |         parts = []
227 |         for part in local.split('.'):
228 |             # to ensure that numeric compares as > lexicographic, avoid
229 |             # comparing them directly, but encode a tuple which ensures
230 |             # correct sorting
231 |             if part.isdigit():
232 |                 part = (1, int(part))
233 |             else:
234 |                 part = (0, part)
235 |             parts.append(part)
236 |         local = tuple(parts)
237 |     if not pre:
238 |         # either before pre-release, or final release and after
239 |         if not post and dev:
240 |             # before pre-release
241 |             pre = ('a', -1)     # to sort before a0
242 |         else:
243 |             pre = ('z',)        # to sort after all pre-releases
244 |     # now look at the state of post and dev.
245 |     if not post:
246 |         post = ('_',)   # sort before 'a'
247 |     if not dev:
248 |         dev = ('final',)
249 | 
250 |     return epoch, nums, pre, post, dev, local
251 | 
252 | 
253 | _normalized_key = _pep_440_key
254 | 
255 | 
256 | class NormalizedVersion(Version):
257 |     """A rational version.
258 | 
259 |     Good:
260 |         1.2         # equivalent to "1.2.0"
261 |         1.2.0
262 |         1.2a1
263 |         1.2.3a2
264 |         1.2.3b1
265 |         1.2.3c1
266 |         1.2.3.4
267 |         TODO: fill this out
268 | 
269 |     Bad:
270 |         1           # minimum two numbers
271 |         1.2a        # release level must have a release serial
272 |         1.2.3b
273 |     """
274 |     def parse(self, s):
275 |         result = _normalized_key(s)
276 |         # _normalized_key loses trailing zeroes in the release
277 |         # clause, since that's needed to ensure that X.Y == X.Y.0 == X.Y.0.0
278 |         # However, PEP 440 prefix matching needs it: for example,
279 |         # (~= 1.4.5.0) matches differently to (~= 1.4.5.0.0).
280 |         m = PEP440_VERSION_RE.match(s)      # must succeed
281 |         groups = m.groups()
282 |         self._release_clause = tuple(int(v) for v in groups[1].split('.'))
283 |         return result
284 | 
285 |     PREREL_TAGS = set(['a', 'b', 'c', 'rc', 'dev'])
286 | 
287 |     @property
288 |     def is_prerelease(self):
289 |         return any(t[0] in self.PREREL_TAGS for t in self._parts if t)
290 | 
291 | 
292 | def _match_prefix(x, y):
293 |     x = str(x)
294 |     y = str(y)
295 |     if x == y:
296 |         return True
297 |     if not x.startswith(y):
298 |         return False
299 |     n = len(y)
300 |     return x[n] == '.'
301 | 
302 | 
303 | class NormalizedMatcher(Matcher):
304 |     version_class = NormalizedVersion
305 | 
306 |     # value is either a callable or the name of a method
307 |     _operators = {
308 |         '~=': '_match_compatible',
309 |         '<': '_match_lt',
310 |         '>': '_match_gt',
311 |         '<=': '_match_le',
312 |         '>=': '_match_ge',
313 |         '==': '_match_eq',
314 |         '===': '_match_arbitrary',
315 |         '!=': '_match_ne',
316 |     }
317 | 
318 |     def _adjust_local(self, version, constraint, prefix):
319 |         if prefix:
320 |             strip_local = '+' not in constraint and version._parts[-1]
321 |         else:
322 |             # both constraint and version are
323 |             # NormalizedVersion instances.
324 |             # If constraint does not have a local component,
325 |             # ensure the version doesn't, either.
326 |             strip_local = not constraint._parts[-1] and version._parts[-1]
327 |         if strip_local:
328 |             s = version._string.split('+', 1)[0]
329 |             version = self.version_class(s)
330 |         return version, constraint
331 | 
332 |     def _match_lt(self, version, constraint, prefix):
333 |         version, constraint = self._adjust_local(version, constraint, prefix)
334 |         if version >= constraint:
335 |             return False
336 |         release_clause = constraint._release_clause
337 |         pfx = '.'.join([str(i) for i in release_clause])
338 |         return not _match_prefix(version, pfx)
339 | 
340 |     def _match_gt(self, version, constraint, prefix):
341 |         version, constraint = self._adjust_local(version, constraint, prefix)
342 |         if version <= constraint:
343 |             return False
344 |         release_clause = constraint._release_clause
345 |         pfx = '.'.join([str(i) for i in release_clause])
346 |         return not _match_prefix(version, pfx)
347 | 
348 |     def _match_le(self, version, constraint, prefix):
349 |         version, constraint = self._adjust_local(version, constraint, prefix)
350 |         return version <= constraint
351 | 
352 |     def _match_ge(self, version, constraint, prefix):
353 |         version, constraint = self._adjust_local(version, constraint, prefix)
354 |         return version >= constraint
355 | 
356 |     def _match_eq(self, version, constraint, prefix):
[TRUNCATED]
```

.venv/lib/python3.13/site-packages/pip/_vendor/distlib/wheel.py
```
1 | # -*- coding: utf-8 -*-
2 | #
3 | # Copyright (C) 2013-2023 Vinay Sajip.
4 | # Licensed to the Python Software Foundation under a contributor agreement.
5 | # See LICENSE.txt and CONTRIBUTORS.txt.
6 | #
7 | from __future__ import unicode_literals
8 | 
9 | import base64
10 | import codecs
11 | import datetime
12 | from email import message_from_file
13 | import hashlib
14 | import json
15 | import logging
16 | import os
17 | import posixpath
18 | import re
19 | import shutil
20 | import sys
21 | import tempfile
22 | import zipfile
23 | 
24 | from . import __version__, DistlibException
25 | from .compat import sysconfig, ZipFile, fsdecode, text_type, filter
26 | from .database import InstalledDistribution
27 | from .metadata import Metadata, WHEEL_METADATA_FILENAME, LEGACY_METADATA_FILENAME
28 | from .util import (FileOperator, convert_path, CSVReader, CSVWriter, Cache, cached_property, get_cache_base,
29 |                    read_exports, tempdir, get_platform)
30 | from .version import NormalizedVersion, UnsupportedVersionError
31 | 
32 | logger = logging.getLogger(__name__)
33 | 
34 | cache = None  # created when needed
35 | 
36 | if hasattr(sys, 'pypy_version_info'):  # pragma: no cover
37 |     IMP_PREFIX = 'pp'
38 | elif sys.platform.startswith('java'):  # pragma: no cover
39 |     IMP_PREFIX = 'jy'
40 | elif sys.platform == 'cli':  # pragma: no cover
41 |     IMP_PREFIX = 'ip'
42 | else:
43 |     IMP_PREFIX = 'cp'
44 | 
45 | VER_SUFFIX = sysconfig.get_config_var('py_version_nodot')
46 | if not VER_SUFFIX:  # pragma: no cover
47 |     VER_SUFFIX = '%s%s' % sys.version_info[:2]
48 | PYVER = 'py' + VER_SUFFIX
49 | IMPVER = IMP_PREFIX + VER_SUFFIX
50 | 
51 | ARCH = get_platform().replace('-', '_').replace('.', '_')
52 | 
53 | ABI = sysconfig.get_config_var('SOABI')
54 | if ABI and ABI.startswith('cpython-'):
55 |     ABI = ABI.replace('cpython-', 'cp').split('-')[0]
56 | else:
57 | 
58 |     def _derive_abi():
59 |         parts = ['cp', VER_SUFFIX]
60 |         if sysconfig.get_config_var('Py_DEBUG'):
61 |             parts.append('d')
62 |         if IMP_PREFIX == 'cp':
63 |             vi = sys.version_info[:2]
64 |             if vi < (3, 8):
65 |                 wpm = sysconfig.get_config_var('WITH_PYMALLOC')
66 |                 if wpm is None:
67 |                     wpm = True
68 |                 if wpm:
69 |                     parts.append('m')
70 |                 if vi < (3, 3):
71 |                     us = sysconfig.get_config_var('Py_UNICODE_SIZE')
72 |                     if us == 4 or (us is None and sys.maxunicode == 0x10FFFF):
73 |                         parts.append('u')
74 |         return ''.join(parts)
75 | 
76 |     ABI = _derive_abi()
77 |     del _derive_abi
78 | 
79 | FILENAME_RE = re.compile(
80 |     r'''
81 | (?P<nm>[^-]+)
82 | -(?P<vn>\d+[^-]*)
83 | (-(?P<bn>\d+[^-]*))?
84 | -(?P<py>\w+\d+(\.\w+\d+)*)
85 | -(?P<bi>\w+)
86 | -(?P<ar>\w+(\.\w+)*)
87 | \.whl$
88 | ''', re.IGNORECASE | re.VERBOSE)
89 | 
90 | NAME_VERSION_RE = re.compile(r'''
91 | (?P<nm>[^-]+)
92 | -(?P<vn>\d+[^-]*)
93 | (-(?P<bn>\d+[^-]*))?$
94 | ''', re.IGNORECASE | re.VERBOSE)
95 | 
96 | SHEBANG_RE = re.compile(br'\s*#![^\r\n]*')
97 | SHEBANG_DETAIL_RE = re.compile(br'^(\s*#!("[^"]+"|\S+))\s+(.*)$')
98 | SHEBANG_PYTHON = b'#!python'
99 | SHEBANG_PYTHONW = b'#!pythonw'
100 | 
101 | if os.sep == '/':
102 |     to_posix = lambda o: o
103 | else:
104 |     to_posix = lambda o: o.replace(os.sep, '/')
105 | 
106 | if sys.version_info[0] < 3:
107 |     import imp
108 | else:
109 |     imp = None
110 |     import importlib.machinery
111 |     import importlib.util
112 | 
113 | 
114 | def _get_suffixes():
115 |     if imp:
116 |         return [s[0] for s in imp.get_suffixes()]
117 |     else:
118 |         return importlib.machinery.EXTENSION_SUFFIXES
119 | 
120 | 
121 | def _load_dynamic(name, path):
122 |     # https://docs.python.org/3/library/importlib.html#importing-a-source-file-directly
123 |     if imp:
124 |         return imp.load_dynamic(name, path)
125 |     else:
126 |         spec = importlib.util.spec_from_file_location(name, path)
127 |         module = importlib.util.module_from_spec(spec)
128 |         sys.modules[name] = module
129 |         spec.loader.exec_module(module)
130 |         return module
131 | 
132 | 
133 | class Mounter(object):
134 | 
135 |     def __init__(self):
136 |         self.impure_wheels = {}
137 |         self.libs = {}
138 | 
139 |     def add(self, pathname, extensions):
140 |         self.impure_wheels[pathname] = extensions
141 |         self.libs.update(extensions)
142 | 
143 |     def remove(self, pathname):
144 |         extensions = self.impure_wheels.pop(pathname)
145 |         for k, v in extensions:
146 |             if k in self.libs:
147 |                 del self.libs[k]
148 | 
149 |     def find_module(self, fullname, path=None):
150 |         if fullname in self.libs:
151 |             result = self
152 |         else:
153 |             result = None
154 |         return result
155 | 
156 |     def load_module(self, fullname):
157 |         if fullname in sys.modules:
158 |             result = sys.modules[fullname]
159 |         else:
160 |             if fullname not in self.libs:
161 |                 raise ImportError('unable to find extension for %s' % fullname)
162 |             result = _load_dynamic(fullname, self.libs[fullname])
163 |             result.__loader__ = self
164 |             parts = fullname.rsplit('.', 1)
165 |             if len(parts) > 1:
166 |                 result.__package__ = parts[0]
167 |         return result
168 | 
169 | 
170 | _hook = Mounter()
171 | 
172 | 
173 | class Wheel(object):
174 |     """
175 |     Class to build and install from Wheel files (PEP 427).
176 |     """
177 | 
178 |     wheel_version = (1, 1)
179 |     hash_kind = 'sha256'
180 | 
181 |     def __init__(self, filename=None, sign=False, verify=False):
182 |         """
183 |         Initialise an instance using a (valid) filename.
184 |         """
185 |         self.sign = sign
186 |         self.should_verify = verify
187 |         self.buildver = ''
188 |         self.pyver = [PYVER]
189 |         self.abi = ['none']
190 |         self.arch = ['any']
191 |         self.dirname = os.getcwd()
192 |         if filename is None:
193 |             self.name = 'dummy'
194 |             self.version = '0.1'
195 |             self._filename = self.filename
196 |         else:
197 |             m = NAME_VERSION_RE.match(filename)
198 |             if m:
199 |                 info = m.groupdict('')
200 |                 self.name = info['nm']
201 |                 # Reinstate the local version separator
202 |                 self.version = info['vn'].replace('_', '-')
203 |                 self.buildver = info['bn']
204 |                 self._filename = self.filename
205 |             else:
206 |                 dirname, filename = os.path.split(filename)
207 |                 m = FILENAME_RE.match(filename)
208 |                 if not m:
209 |                     raise DistlibException('Invalid name or '
210 |                                            'filename: %r' % filename)
211 |                 if dirname:
212 |                     self.dirname = os.path.abspath(dirname)
213 |                 self._filename = filename
214 |                 info = m.groupdict('')
215 |                 self.name = info['nm']
216 |                 self.version = info['vn']
217 |                 self.buildver = info['bn']
218 |                 self.pyver = info['py'].split('.')
219 |                 self.abi = info['bi'].split('.')
220 |                 self.arch = info['ar'].split('.')
221 | 
222 |     @property
223 |     def filename(self):
224 |         """
225 |         Build and return a filename from the various components.
226 |         """
227 |         if self.buildver:
228 |             buildver = '-' + self.buildver
229 |         else:
230 |             buildver = ''
231 |         pyver = '.'.join(self.pyver)
232 |         abi = '.'.join(self.abi)
233 |         arch = '.'.join(self.arch)
234 |         # replace - with _ as a local version separator
235 |         version = self.version.replace('-', '_')
236 |         return '%s-%s%s-%s-%s-%s.whl' % (self.name, version, buildver, pyver, abi, arch)
237 | 
238 |     @property
239 |     def exists(self):
240 |         path = os.path.join(self.dirname, self.filename)
241 |         return os.path.isfile(path)
242 | 
243 |     @property
244 |     def tags(self):
245 |         for pyver in self.pyver:
246 |             for abi in self.abi:
247 |                 for arch in self.arch:
248 |                     yield pyver, abi, arch
249 | 
250 |     @cached_property
251 |     def metadata(self):
252 |         pathname = os.path.join(self.dirname, self.filename)
253 |         name_ver = '%s-%s' % (self.name, self.version)
254 |         info_dir = '%s.dist-info' % name_ver
255 |         wrapper = codecs.getreader('utf-8')
256 |         with ZipFile(pathname, 'r') as zf:
257 |             self.get_wheel_metadata(zf)
258 |             # wv = wheel_metadata['Wheel-Version'].split('.', 1)
259 |             # file_version = tuple([int(i) for i in wv])
260 |             # if file_version < (1, 1):
261 |             # fns = [WHEEL_METADATA_FILENAME, METADATA_FILENAME,
262 |             # LEGACY_METADATA_FILENAME]
263 |             # else:
264 |             # fns = [WHEEL_METADATA_FILENAME, METADATA_FILENAME]
265 |             fns = [WHEEL_METADATA_FILENAME, LEGACY_METADATA_FILENAME]
266 |             result = None
267 |             for fn in fns:
268 |                 try:
269 |                     metadata_filename = posixpath.join(info_dir, fn)
270 |                     with zf.open(metadata_filename) as bf:
271 |                         wf = wrapper(bf)
272 |                         result = Metadata(fileobj=wf)
273 |                         if result:
274 |                             break
275 |                 except KeyError:
276 |                     pass
277 |             if not result:
278 |                 raise ValueError('Invalid wheel, because metadata is '
279 |                                  'missing: looked in %s' % ', '.join(fns))
280 |         return result
281 | 
282 |     def get_wheel_metadata(self, zf):
283 |         name_ver = '%s-%s' % (self.name, self.version)
284 |         info_dir = '%s.dist-info' % name_ver
285 |         metadata_filename = posixpath.join(info_dir, 'WHEEL')
286 |         with zf.open(metadata_filename) as bf:
287 |             wf = codecs.getreader('utf-8')(bf)
288 |             message = message_from_file(wf)
289 |         return dict(message)
290 | 
291 |     @cached_property
292 |     def info(self):
293 |         pathname = os.path.join(self.dirname, self.filename)
294 |         with ZipFile(pathname, 'r') as zf:
295 |             result = self.get_wheel_metadata(zf)
296 |         return result
297 | 
298 |     def process_shebang(self, data):
299 |         m = SHEBANG_RE.match(data)
300 |         if m:
301 |             end = m.end()
302 |             shebang, data_after_shebang = data[:end], data[end:]
303 |             # Preserve any arguments after the interpreter
304 |             if b'pythonw' in shebang.lower():
305 |                 shebang_python = SHEBANG_PYTHONW
306 |             else:
307 |                 shebang_python = SHEBANG_PYTHON
308 |             m = SHEBANG_DETAIL_RE.match(shebang)
309 |             if m:
310 |                 args = b' ' + m.groups()[-1]
311 |             else:
312 |                 args = b''
313 |             shebang = shebang_python + args
314 |             data = shebang + data_after_shebang
315 |         else:
316 |             cr = data.find(b'\r')
317 |             lf = data.find(b'\n')
318 |             if cr < 0 or cr > lf:
319 |                 term = b'\n'
320 |             else:
321 |                 if data[cr:cr + 2] == b'\r\n':
322 |                     term = b'\r\n'
323 |                 else:
324 |                     term = b'\r'
325 |             data = SHEBANG_PYTHON + term + data
326 |         return data
327 | 
328 |     def get_hash(self, data, hash_kind=None):
329 |         if hash_kind is None:
330 |             hash_kind = self.hash_kind
331 |         try:
332 |             hasher = getattr(hashlib, hash_kind)
333 |         except AttributeError:
334 |             raise DistlibException('Unsupported hash algorithm: %r' % hash_kind)
335 |         result = hasher(data).digest()
336 |         result = base64.urlsafe_b64encode(result).rstrip(b'=').decode('ascii')
337 |         return hash_kind, result
338 | 
339 |     def write_record(self, records, record_path, archive_record_path):
340 |         records = list(records)  # make a copy, as mutated
341 |         records.append((archive_record_path, '', ''))
342 |         with CSVWriter(record_path) as writer:
343 |             for row in records:
344 |                 writer.writerow(row)
345 | 
346 |     def write_records(self, info, libdir, archive_paths):
347 |         records = []
348 |         distinfo, info_dir = info
349 |         # hasher = getattr(hashlib, self.hash_kind)
350 |         for ap, p in archive_paths:
351 |             with open(p, 'rb') as f:
352 |                 data = f.read()
353 |             digest = '%s=%s' % self.get_hash(data)
354 |             size = os.path.getsize(p)
355 |             records.append((ap, digest, size))
356 | 
357 |         p = os.path.join(distinfo, 'RECORD')
358 |         ap = to_posix(os.path.join(info_dir, 'RECORD'))
359 |         self.write_record(records, p, ap)
360 |         archive_paths.append((ap, p))
361 | 
[TRUNCATED]
```

.venv/lib/python3.13/site-packages/pip/_vendor/certifi/__init__.py
```
1 | from .core import contents, where
2 | 
3 | __all__ = ["contents", "where"]
4 | __version__ = "2025.01.31"
```

.venv/lib/python3.13/site-packages/pip/_vendor/certifi/__main__.py
```
1 | import argparse
2 | 
3 | from pip._vendor.certifi import contents, where
4 | 
5 | parser = argparse.ArgumentParser()
6 | parser.add_argument("-c", "--contents", action="store_true")
7 | args = parser.parse_args()
8 | 
9 | if args.contents:
10 |     print(contents())
11 | else:
12 |     print(where())
```

.venv/lib/python3.13/site-packages/pip/_vendor/certifi/core.py
```
1 | """
2 | certifi.py
3 | ~~~~~~~~~~
4 | 
5 | This module returns the installation location of cacert.pem or its contents.
6 | """
7 | import sys
8 | import atexit
9 | 
10 | def exit_cacert_ctx() -> None:
11 |     _CACERT_CTX.__exit__(None, None, None)  # type: ignore[union-attr]
12 | 
13 | 
14 | if sys.version_info >= (3, 11):
15 | 
16 |     from importlib.resources import as_file, files
17 | 
18 |     _CACERT_CTX = None
19 |     _CACERT_PATH = None
20 | 
21 |     def where() -> str:
22 |         # This is slightly terrible, but we want to delay extracting the file
23 |         # in cases where we're inside of a zipimport situation until someone
24 |         # actually calls where(), but we don't want to re-extract the file
25 |         # on every call of where(), so we'll do it once then store it in a
26 |         # global variable.
27 |         global _CACERT_CTX
28 |         global _CACERT_PATH
29 |         if _CACERT_PATH is None:
30 |             # This is slightly janky, the importlib.resources API wants you to
31 |             # manage the cleanup of this file, so it doesn't actually return a
32 |             # path, it returns a context manager that will give you the path
33 |             # when you enter it and will do any cleanup when you leave it. In
34 |             # the common case of not needing a temporary file, it will just
35 |             # return the file system location and the __exit__() is a no-op.
36 |             #
37 |             # We also have to hold onto the actual context manager, because
38 |             # it will do the cleanup whenever it gets garbage collected, so
39 |             # we will also store that at the global level as well.
40 |             _CACERT_CTX = as_file(files("pip._vendor.certifi").joinpath("cacert.pem"))
41 |             _CACERT_PATH = str(_CACERT_CTX.__enter__())
42 |             atexit.register(exit_cacert_ctx)
43 | 
44 |         return _CACERT_PATH
45 | 
46 |     def contents() -> str:
47 |         return files("pip._vendor.certifi").joinpath("cacert.pem").read_text(encoding="ascii")
48 | 
49 | elif sys.version_info >= (3, 7):
50 | 
51 |     from importlib.resources import path as get_path, read_text
52 | 
53 |     _CACERT_CTX = None
54 |     _CACERT_PATH = None
55 | 
56 |     def where() -> str:
57 |         # This is slightly terrible, but we want to delay extracting the
58 |         # file in cases where we're inside of a zipimport situation until
59 |         # someone actually calls where(), but we don't want to re-extract
60 |         # the file on every call of where(), so we'll do it once then store
61 |         # it in a global variable.
62 |         global _CACERT_CTX
63 |         global _CACERT_PATH
64 |         if _CACERT_PATH is None:
65 |             # This is slightly janky, the importlib.resources API wants you
66 |             # to manage the cleanup of this file, so it doesn't actually
67 |             # return a path, it returns a context manager that will give
68 |             # you the path when you enter it and will do any cleanup when
69 |             # you leave it. In the common case of not needing a temporary
70 |             # file, it will just return the file system location and the
71 |             # __exit__() is a no-op.
72 |             #
73 |             # We also have to hold onto the actual context manager, because
74 |             # it will do the cleanup whenever it gets garbage collected, so
75 |             # we will also store that at the global level as well.
76 |             _CACERT_CTX = get_path("pip._vendor.certifi", "cacert.pem")
77 |             _CACERT_PATH = str(_CACERT_CTX.__enter__())
78 |             atexit.register(exit_cacert_ctx)
79 | 
80 |         return _CACERT_PATH
81 | 
82 |     def contents() -> str:
83 |         return read_text("pip._vendor.certifi", "cacert.pem", encoding="ascii")
84 | 
85 | else:
86 |     import os
87 |     import types
88 |     from typing import Union
89 | 
90 |     Package = Union[types.ModuleType, str]
91 |     Resource = Union[str, "os.PathLike"]
92 | 
93 |     # This fallback will work for Python versions prior to 3.7 that lack the
94 |     # importlib.resources module but relies on the existing `where` function
95 |     # so won't address issues with environments like PyOxidizer that don't set
96 |     # __file__ on modules.
97 |     def read_text(
98 |         package: Package,
99 |         resource: Resource,
100 |         encoding: str = 'utf-8',
101 |         errors: str = 'strict'
102 |     ) -> str:
103 |         with open(where(), encoding=encoding) as data:
104 |             return data.read()
105 | 
106 |     # If we don't have importlib.resources, then we will just do the old logic
107 |     # of assuming we're on the filesystem and munge the path directly.
108 |     def where() -> str:
109 |         f = os.path.dirname(__file__)
110 | 
111 |         return os.path.join(f, "cacert.pem")
112 | 
113 |     def contents() -> str:
114 |         return read_text("pip._vendor.certifi", "cacert.pem", encoding="ascii")
```

.venv/lib/python3.13/site-packages/pip/_vendor/certifi/py.typed
```
```

.venv/lib/python3.13/site-packages/pip/_vendor/distro/__init__.py
```
1 | from .distro import (
2 |     NORMALIZED_DISTRO_ID,
3 |     NORMALIZED_LSB_ID,
4 |     NORMALIZED_OS_ID,
5 |     LinuxDistribution,
6 |     __version__,
7 |     build_number,
8 |     codename,
9 |     distro_release_attr,
10 |     distro_release_info,
11 |     id,
12 |     info,
13 |     like,
14 |     linux_distribution,
15 |     lsb_release_attr,
16 |     lsb_release_info,
17 |     major_version,
18 |     minor_version,
19 |     name,
20 |     os_release_attr,
21 |     os_release_info,
22 |     uname_attr,
23 |     uname_info,
24 |     version,
25 |     version_parts,
26 | )
27 | 
28 | __all__ = [
29 |     "NORMALIZED_DISTRO_ID",
30 |     "NORMALIZED_LSB_ID",
31 |     "NORMALIZED_OS_ID",
32 |     "LinuxDistribution",
33 |     "build_number",
34 |     "codename",
35 |     "distro_release_attr",
36 |     "distro_release_info",
37 |     "id",
38 |     "info",
39 |     "like",
40 |     "linux_distribution",
41 |     "lsb_release_attr",
42 |     "lsb_release_info",
43 |     "major_version",
44 |     "minor_version",
45 |     "name",
46 |     "os_release_attr",
47 |     "os_release_info",
48 |     "uname_attr",
49 |     "uname_info",
50 |     "version",
51 |     "version_parts",
52 | ]
53 | 
54 | __version__ = __version__
```

.venv/lib/python3.13/site-packages/pip/_vendor/distro/__main__.py
```
1 | from .distro import main
2 | 
3 | if __name__ == "__main__":
4 |     main()
```

.venv/lib/python3.13/site-packages/pip/_vendor/distro/distro.py
```
1 | #!/usr/bin/env python
2 | # Copyright 2015-2021 Nir Cohen
3 | #
4 | # Licensed under the Apache License, Version 2.0 (the "License");
5 | # you may not use this file except in compliance with the License.
6 | # You may obtain a copy of the License at
7 | #
8 | # http://www.apache.org/licenses/LICENSE-2.0
9 | #
10 | # Unless required by applicable law or agreed to in writing, software
11 | # distributed under the License is distributed on an "AS IS" BASIS,
12 | # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
13 | # See the License for the specific language governing permissions and
14 | # limitations under the License.
15 | 
16 | """
17 | The ``distro`` package (``distro`` stands for Linux Distribution) provides
18 | information about the Linux distribution it runs on, such as a reliable
19 | machine-readable distro ID, or version information.
20 | 
21 | It is the recommended replacement for Python's original
22 | :py:func:`platform.linux_distribution` function, but it provides much more
23 | functionality. An alternative implementation became necessary because Python
24 | 3.5 deprecated this function, and Python 3.8 removed it altogether. Its
25 | predecessor function :py:func:`platform.dist` was already deprecated since
26 | Python 2.6 and removed in Python 3.8. Still, there are many cases in which
27 | access to OS distribution information is needed. See `Python issue 1322
28 | <https://bugs.python.org/issue1322>`_ for more information.
29 | """
30 | 
31 | import argparse
32 | import json
33 | import logging
34 | import os
35 | import re
36 | import shlex
37 | import subprocess
38 | import sys
39 | import warnings
40 | from typing import (
41 |     Any,
42 |     Callable,
43 |     Dict,
44 |     Iterable,
45 |     Optional,
46 |     Sequence,
47 |     TextIO,
48 |     Tuple,
49 |     Type,
50 | )
51 | 
52 | try:
53 |     from typing import TypedDict
54 | except ImportError:
55 |     # Python 3.7
56 |     TypedDict = dict
57 | 
58 | __version__ = "1.9.0"
59 | 
60 | 
61 | class VersionDict(TypedDict):
62 |     major: str
63 |     minor: str
64 |     build_number: str
65 | 
66 | 
67 | class InfoDict(TypedDict):
68 |     id: str
69 |     version: str
70 |     version_parts: VersionDict
71 |     like: str
72 |     codename: str
73 | 
74 | 
75 | _UNIXCONFDIR = os.environ.get("UNIXCONFDIR", "/etc")
76 | _UNIXUSRLIBDIR = os.environ.get("UNIXUSRLIBDIR", "/usr/lib")
77 | _OS_RELEASE_BASENAME = "os-release"
78 | 
79 | #: Translation table for normalizing the "ID" attribute defined in os-release
80 | #: files, for use by the :func:`distro.id` method.
81 | #:
82 | #: * Key: Value as defined in the os-release file, translated to lower case,
83 | #:   with blanks translated to underscores.
84 | #:
85 | #: * Value: Normalized value.
86 | NORMALIZED_OS_ID = {
87 |     "ol": "oracle",  # Oracle Linux
88 |     "opensuse-leap": "opensuse",  # Newer versions of OpenSuSE report as opensuse-leap
89 | }
90 | 
91 | #: Translation table for normalizing the "Distributor ID" attribute returned by
92 | #: the lsb_release command, for use by the :func:`distro.id` method.
93 | #:
94 | #: * Key: Value as returned by the lsb_release command, translated to lower
95 | #:   case, with blanks translated to underscores.
96 | #:
97 | #: * Value: Normalized value.
98 | NORMALIZED_LSB_ID = {
99 |     "enterpriseenterpriseas": "oracle",  # Oracle Enterprise Linux 4
100 |     "enterpriseenterpriseserver": "oracle",  # Oracle Linux 5
101 |     "redhatenterpriseworkstation": "rhel",  # RHEL 6, 7 Workstation
102 |     "redhatenterpriseserver": "rhel",  # RHEL 6, 7 Server
103 |     "redhatenterprisecomputenode": "rhel",  # RHEL 6 ComputeNode
104 | }
105 | 
106 | #: Translation table for normalizing the distro ID derived from the file name
107 | #: of distro release files, for use by the :func:`distro.id` method.
108 | #:
109 | #: * Key: Value as derived from the file name of a distro release file,
110 | #:   translated to lower case, with blanks translated to underscores.
111 | #:
112 | #: * Value: Normalized value.
113 | NORMALIZED_DISTRO_ID = {
114 |     "redhat": "rhel",  # RHEL 6.x, 7.x
115 | }
116 | 
117 | # Pattern for content of distro release file (reversed)
118 | _DISTRO_RELEASE_CONTENT_REVERSED_PATTERN = re.compile(
119 |     r"(?:[^)]*\)(.*)\()? *(?:STL )?([\d.+\-a-z]*\d) *(?:esaeler *)?(.+)"
120 | )
121 | 
122 | # Pattern for base file name of distro release file
123 | _DISTRO_RELEASE_BASENAME_PATTERN = re.compile(r"(\w+)[-_](release|version)$")
124 | 
125 | # Base file names to be looked up for if _UNIXCONFDIR is not readable.
126 | _DISTRO_RELEASE_BASENAMES = [
127 |     "SuSE-release",
128 |     "altlinux-release",
129 |     "arch-release",
130 |     "base-release",
131 |     "centos-release",
132 |     "fedora-release",
133 |     "gentoo-release",
134 |     "mageia-release",
135 |     "mandrake-release",
136 |     "mandriva-release",
137 |     "mandrivalinux-release",
138 |     "manjaro-release",
139 |     "oracle-release",
140 |     "redhat-release",
141 |     "rocky-release",
142 |     "sl-release",
143 |     "slackware-version",
144 | ]
145 | 
146 | # Base file names to be ignored when searching for distro release file
147 | _DISTRO_RELEASE_IGNORE_BASENAMES = (
148 |     "debian_version",
149 |     "lsb-release",
150 |     "oem-release",
151 |     _OS_RELEASE_BASENAME,
152 |     "system-release",
153 |     "plesk-release",
154 |     "iredmail-release",
155 |     "board-release",
156 |     "ec2_version",
157 | )
158 | 
159 | 
160 | def linux_distribution(full_distribution_name: bool = True) -> Tuple[str, str, str]:
161 |     """
162 |     .. deprecated:: 1.6.0
163 | 
164 |         :func:`distro.linux_distribution()` is deprecated. It should only be
165 |         used as a compatibility shim with Python's
166 |         :py:func:`platform.linux_distribution()`. Please use :func:`distro.id`,
167 |         :func:`distro.version` and :func:`distro.name` instead.
168 | 
169 |     Return information about the current OS distribution as a tuple
170 |     ``(id_name, version, codename)`` with items as follows:
171 | 
172 |     * ``id_name``:  If *full_distribution_name* is false, the result of
173 |       :func:`distro.id`. Otherwise, the result of :func:`distro.name`.
174 | 
175 |     * ``version``:  The result of :func:`distro.version`.
176 | 
177 |     * ``codename``:  The extra item (usually in parentheses) after the
178 |       os-release version number, or the result of :func:`distro.codename`.
179 | 
180 |     The interface of this function is compatible with the original
181 |     :py:func:`platform.linux_distribution` function, supporting a subset of
182 |     its parameters.
183 | 
184 |     The data it returns may not exactly be the same, because it uses more data
185 |     sources than the original function, and that may lead to different data if
186 |     the OS distribution is not consistent across multiple data sources it
187 |     provides (there are indeed such distributions ...).
188 | 
189 |     Another reason for differences is the fact that the :func:`distro.id`
190 |     method normalizes the distro ID string to a reliable machine-readable value
191 |     for a number of popular OS distributions.
192 |     """
193 |     warnings.warn(
194 |         "distro.linux_distribution() is deprecated. It should only be used as a "
195 |         "compatibility shim with Python's platform.linux_distribution(). Please use "
196 |         "distro.id(), distro.version() and distro.name() instead.",
197 |         DeprecationWarning,
198 |         stacklevel=2,
199 |     )
200 |     return _distro.linux_distribution(full_distribution_name)
201 | 
202 | 
203 | def id() -> str:
204 |     """
205 |     Return the distro ID of the current distribution, as a
206 |     machine-readable string.
207 | 
208 |     For a number of OS distributions, the returned distro ID value is
209 |     *reliable*, in the sense that it is documented and that it does not change
210 |     across releases of the distribution.
211 | 
212 |     This package maintains the following reliable distro ID values:
213 | 
214 |     ==============  =========================================
215 |     Distro ID       Distribution
216 |     ==============  =========================================
217 |     "ubuntu"        Ubuntu
218 |     "debian"        Debian
219 |     "rhel"          RedHat Enterprise Linux
220 |     "centos"        CentOS
221 |     "fedora"        Fedora
222 |     "sles"          SUSE Linux Enterprise Server
223 |     "opensuse"      openSUSE
224 |     "amzn"          Amazon Linux
225 |     "arch"          Arch Linux
226 |     "buildroot"     Buildroot
227 |     "cloudlinux"    CloudLinux OS
228 |     "exherbo"       Exherbo Linux
229 |     "gentoo"        GenToo Linux
230 |     "ibm_powerkvm"  IBM PowerKVM
231 |     "kvmibm"        KVM for IBM z Systems
232 |     "linuxmint"     Linux Mint
233 |     "mageia"        Mageia
234 |     "mandriva"      Mandriva Linux
235 |     "parallels"     Parallels
236 |     "pidora"        Pidora
237 |     "raspbian"      Raspbian
238 |     "oracle"        Oracle Linux (and Oracle Enterprise Linux)
239 |     "scientific"    Scientific Linux
240 |     "slackware"     Slackware
241 |     "xenserver"     XenServer
242 |     "openbsd"       OpenBSD
243 |     "netbsd"        NetBSD
244 |     "freebsd"       FreeBSD
245 |     "midnightbsd"   MidnightBSD
246 |     "rocky"         Rocky Linux
247 |     "aix"           AIX
248 |     "guix"          Guix System
249 |     "altlinux"      ALT Linux
250 |     ==============  =========================================
251 | 
252 |     If you have a need to get distros for reliable IDs added into this set,
253 |     or if you find that the :func:`distro.id` function returns a different
254 |     distro ID for one of the listed distros, please create an issue in the
255 |     `distro issue tracker`_.
256 | 
257 |     **Lookup hierarchy and transformations:**
258 | 
259 |     First, the ID is obtained from the following sources, in the specified
260 |     order. The first available and non-empty value is used:
261 | 
262 |     * the value of the "ID" attribute of the os-release file,
263 | 
264 |     * the value of the "Distributor ID" attribute returned by the lsb_release
265 |       command,
266 | 
267 |     * the first part of the file name of the distro release file,
268 | 
269 |     The so determined ID value then passes the following transformations,
270 |     before it is returned by this method:
271 | 
272 |     * it is translated to lower case,
273 | 
274 |     * blanks (which should not be there anyway) are translated to underscores,
275 | 
276 |     * a normalization of the ID is performed, based upon
277 |       `normalization tables`_. The purpose of this normalization is to ensure
278 |       that the ID is as reliable as possible, even across incompatible changes
279 |       in the OS distributions. A common reason for an incompatible change is
280 |       the addition of an os-release file, or the addition of the lsb_release
281 |       command, with ID values that differ from what was previously determined
282 |       from the distro release file name.
283 |     """
284 |     return _distro.id()
285 | 
286 | 
287 | def name(pretty: bool = False) -> str:
288 |     """
289 |     Return the name of the current OS distribution, as a human-readable
290 |     string.
291 | 
292 |     If *pretty* is false, the name is returned without version or codename.
293 |     (e.g. "CentOS Linux")
294 | 
295 |     If *pretty* is true, the version and codename are appended.
296 |     (e.g. "CentOS Linux 7.1.1503 (Core)")
297 | 
298 |     **Lookup hierarchy:**
299 | 
300 |     The name is obtained from the following sources, in the specified order.
301 |     The first available and non-empty value is used:
302 | 
303 |     * If *pretty* is false:
304 | 
305 |       - the value of the "NAME" attribute of the os-release file,
306 | 
307 |       - the value of the "Distributor ID" attribute returned by the lsb_release
308 |         command,
309 | 
310 |       - the value of the "<name>" field of the distro release file.
311 | 
312 |     * If *pretty* is true:
313 | 
314 |       - the value of the "PRETTY_NAME" attribute of the os-release file,
315 | 
316 |       - the value of the "Description" attribute returned by the lsb_release
317 |         command,
318 | 
319 |       - the value of the "<name>" field of the distro release file, appended
320 |         with the value of the pretty version ("<version_id>" and "<codename>"
321 |         fields) of the distro release file, if available.
322 |     """
323 |     return _distro.name(pretty)
324 | 
325 | 
326 | def version(pretty: bool = False, best: bool = False) -> str:
327 |     """
328 |     Return the version of the current OS distribution, as a human-readable
329 |     string.
330 | 
331 |     If *pretty* is false, the version is returned without codename (e.g.
332 |     "7.0").
333 | 
334 |     If *pretty* is true, the codename in parenthesis is appended, if the
335 |     codename is non-empty (e.g. "7.0 (Maipo)").
336 | 
337 |     Some distributions provide version numbers with different precisions in
338 |     the different sources of distribution information. Examining the different
339 |     sources in a fixed priority order does not always yield the most precise
340 |     version (e.g. for Debian 8.2, or CentOS 7.1).
341 | 
[TRUNCATED]
```

.venv/lib/python3.13/site-packages/pip/_vendor/distro/py.typed
```
```

.venv/lib/python3.13/site-packages/pip/_vendor/pkg_resources/__init__.py
```
1 | # TODO: Add Generic type annotations to initialized collections.
2 | # For now we'd simply use implicit Any/Unknown which would add redundant annotations
3 | # mypy: disable-error-code="var-annotated"
4 | """
5 | Package resource API
6 | --------------------
7 | 
8 | A resource is a logical file contained within a package, or a logical
9 | subdirectory thereof.  The package resource API expects resource names
10 | to have their path parts separated with ``/``, *not* whatever the local
11 | path separator is.  Do not use os.path operations to manipulate resource
12 | names being passed into the API.
13 | 
14 | The package resource API is designed to work with normal filesystem packages,
15 | .egg files, and unpacked .egg files.  It can also work in a limited way with
16 | .zip files and with custom PEP 302 loaders that support the ``get_data()``
17 | method.
18 | 
19 | This module is deprecated. Users are directed to :mod:`importlib.resources`,
20 | :mod:`importlib.metadata` and :pypi:`packaging` instead.
21 | """
22 | 
23 | from __future__ import annotations
24 | 
25 | import sys
26 | 
27 | if sys.version_info < (3, 8):  # noqa: UP036 # Check for unsupported versions
28 |     raise RuntimeError("Python 3.8 or later is required")
29 | 
30 | import os
31 | import io
32 | import time
33 | import re
34 | import types
35 | from typing import (
36 |     Any,
37 |     Literal,
38 |     Dict,
39 |     Iterator,
40 |     Mapping,
41 |     MutableSequence,
42 |     NamedTuple,
43 |     NoReturn,
44 |     Tuple,
45 |     Union,
46 |     TYPE_CHECKING,
47 |     Protocol,
48 |     Callable,
49 |     Iterable,
50 |     TypeVar,
51 |     overload,
52 | )
53 | import zipfile
54 | import zipimport
55 | import warnings
56 | import stat
57 | import functools
58 | import pkgutil
59 | import operator
60 | import platform
61 | import collections
62 | import plistlib
63 | import email.parser
64 | import errno
65 | import tempfile
66 | import textwrap
67 | import inspect
68 | import ntpath
69 | import posixpath
70 | import importlib
71 | import importlib.abc
72 | import importlib.machinery
73 | from pkgutil import get_importer
74 | 
75 | import _imp
76 | 
77 | # capture these to bypass sandboxing
78 | from os import utime
79 | from os import open as os_open
80 | from os.path import isdir, split
81 | 
82 | try:
83 |     from os import mkdir, rename, unlink
84 | 
85 |     WRITE_SUPPORT = True
86 | except ImportError:
87 |     # no write support, probably under GAE
88 |     WRITE_SUPPORT = False
89 | 
90 | from pip._internal.utils._jaraco_text import (
91 |     yield_lines,
92 |     drop_comment,
93 |     join_continuation,
94 | )
95 | from pip._vendor.packaging import markers as _packaging_markers
96 | from pip._vendor.packaging import requirements as _packaging_requirements
97 | from pip._vendor.packaging import utils as _packaging_utils
98 | from pip._vendor.packaging import version as _packaging_version
99 | from pip._vendor.platformdirs import user_cache_dir as _user_cache_dir
100 | 
101 | if TYPE_CHECKING:
102 |     from _typeshed import BytesPath, StrPath, StrOrBytesPath
103 |     from pip._vendor.typing_extensions import Self
104 | 
105 | 
106 | # Patch: Remove deprecation warning from vendored pkg_resources.
107 | # Setting PYTHONWARNINGS=error to verify builds produce no warnings
108 | # causes immediate exceptions.
109 | # See https://github.com/pypa/pip/issues/12243
110 | 
111 | 
112 | _T = TypeVar("_T")
113 | _DistributionT = TypeVar("_DistributionT", bound="Distribution")
114 | # Type aliases
115 | _NestedStr = Union[str, Iterable[Union[str, Iterable["_NestedStr"]]]]
116 | _InstallerTypeT = Callable[["Requirement"], "_DistributionT"]
117 | _InstallerType = Callable[["Requirement"], Union["Distribution", None]]
118 | _PkgReqType = Union[str, "Requirement"]
119 | _EPDistType = Union["Distribution", _PkgReqType]
120 | _MetadataType = Union["IResourceProvider", None]
121 | _ResolvedEntryPoint = Any  # Can be any attribute in the module
122 | _ResourceStream = Any  # TODO / Incomplete: A readable file-like object
123 | # Any object works, but let's indicate we expect something like a module (optionally has __loader__ or __file__)
124 | _ModuleLike = Union[object, types.ModuleType]
125 | # Any: Should be _ModuleLike but we end up with issues where _ModuleLike doesn't have _ZipLoaderModule's __loader__
126 | _ProviderFactoryType = Callable[[Any], "IResourceProvider"]
127 | _DistFinderType = Callable[[_T, str, bool], Iterable["Distribution"]]
128 | _NSHandlerType = Callable[[_T, str, str, types.ModuleType], Union[str, None]]
129 | _AdapterT = TypeVar(
130 |     "_AdapterT", _DistFinderType[Any], _ProviderFactoryType, _NSHandlerType[Any]
131 | )
132 | 
133 | 
134 | # Use _typeshed.importlib.LoaderProtocol once available https://github.com/python/typeshed/pull/11890
135 | class _LoaderProtocol(Protocol):
136 |     def load_module(self, fullname: str, /) -> types.ModuleType: ...
137 | 
138 | 
139 | class _ZipLoaderModule(Protocol):
140 |     __loader__: zipimport.zipimporter
141 | 
142 | 
143 | _PEP440_FALLBACK = re.compile(r"^v?(?P<safe>(?:[0-9]+!)?[0-9]+(?:\.[0-9]+)*)", re.I)
144 | 
145 | 
146 | class PEP440Warning(RuntimeWarning):
147 |     """
148 |     Used when there is an issue with a version or specifier not complying with
149 |     PEP 440.
150 |     """
151 | 
152 | 
153 | parse_version = _packaging_version.Version
154 | 
155 | 
156 | _state_vars: dict[str, str] = {}
157 | 
158 | 
159 | def _declare_state(vartype: str, varname: str, initial_value: _T) -> _T:
160 |     _state_vars[varname] = vartype
161 |     return initial_value
162 | 
163 | 
164 | def __getstate__() -> dict[str, Any]:
165 |     state = {}
166 |     g = globals()
167 |     for k, v in _state_vars.items():
168 |         state[k] = g['_sget_' + v](g[k])
169 |     return state
170 | 
171 | 
172 | def __setstate__(state: dict[str, Any]) -> dict[str, Any]:
173 |     g = globals()
174 |     for k, v in state.items():
175 |         g['_sset_' + _state_vars[k]](k, g[k], v)
176 |     return state
177 | 
178 | 
179 | def _sget_dict(val):
180 |     return val.copy()
181 | 
182 | 
183 | def _sset_dict(key, ob, state):
184 |     ob.clear()
185 |     ob.update(state)
186 | 
187 | 
188 | def _sget_object(val):
189 |     return val.__getstate__()
190 | 
191 | 
192 | def _sset_object(key, ob, state):
193 |     ob.__setstate__(state)
194 | 
195 | 
196 | _sget_none = _sset_none = lambda *args: None
197 | 
198 | 
199 | def get_supported_platform():
200 |     """Return this platform's maximum compatible version.
201 | 
202 |     distutils.util.get_platform() normally reports the minimum version
203 |     of macOS that would be required to *use* extensions produced by
204 |     distutils.  But what we want when checking compatibility is to know the
205 |     version of macOS that we are *running*.  To allow usage of packages that
206 |     explicitly require a newer version of macOS, we must also know the
207 |     current version of the OS.
208 | 
209 |     If this condition occurs for any other platform with a version in its
210 |     platform strings, this function should be extended accordingly.
211 |     """
212 |     plat = get_build_platform()
213 |     m = macosVersionString.match(plat)
214 |     if m is not None and sys.platform == "darwin":
215 |         try:
216 |             plat = 'macosx-%s-%s' % ('.'.join(_macos_vers()[:2]), m.group(3))
217 |         except ValueError:
218 |             # not macOS
219 |             pass
220 |     return plat
221 | 
222 | 
223 | __all__ = [
224 |     # Basic resource access and distribution/entry point discovery
225 |     'require',
226 |     'run_script',
227 |     'get_provider',
228 |     'get_distribution',
229 |     'load_entry_point',
230 |     'get_entry_map',
231 |     'get_entry_info',
232 |     'iter_entry_points',
233 |     'resource_string',
234 |     'resource_stream',
235 |     'resource_filename',
236 |     'resource_listdir',
237 |     'resource_exists',
238 |     'resource_isdir',
239 |     # Environmental control
240 |     'declare_namespace',
241 |     'working_set',
242 |     'add_activation_listener',
243 |     'find_distributions',
244 |     'set_extraction_path',
245 |     'cleanup_resources',
246 |     'get_default_cache',
247 |     # Primary implementation classes
248 |     'Environment',
249 |     'WorkingSet',
250 |     'ResourceManager',
251 |     'Distribution',
252 |     'Requirement',
253 |     'EntryPoint',
254 |     # Exceptions
255 |     'ResolutionError',
256 |     'VersionConflict',
257 |     'DistributionNotFound',
258 |     'UnknownExtra',
259 |     'ExtractionError',
260 |     # Warnings
261 |     'PEP440Warning',
262 |     # Parsing functions and string utilities
263 |     'parse_requirements',
264 |     'parse_version',
265 |     'safe_name',
266 |     'safe_version',
267 |     'get_platform',
268 |     'compatible_platforms',
269 |     'yield_lines',
270 |     'split_sections',
271 |     'safe_extra',
272 |     'to_filename',
273 |     'invalid_marker',
274 |     'evaluate_marker',
275 |     # filesystem utilities
276 |     'ensure_directory',
277 |     'normalize_path',
278 |     # Distribution "precedence" constants
279 |     'EGG_DIST',
280 |     'BINARY_DIST',
281 |     'SOURCE_DIST',
282 |     'CHECKOUT_DIST',
283 |     'DEVELOP_DIST',
284 |     # "Provider" interfaces, implementations, and registration/lookup APIs
285 |     'IMetadataProvider',
286 |     'IResourceProvider',
287 |     'FileMetadata',
288 |     'PathMetadata',
289 |     'EggMetadata',
290 |     'EmptyProvider',
291 |     'empty_provider',
292 |     'NullProvider',
293 |     'EggProvider',
294 |     'DefaultProvider',
295 |     'ZipProvider',
296 |     'register_finder',
297 |     'register_namespace_handler',
298 |     'register_loader_type',
299 |     'fixup_namespace_packages',
300 |     'get_importer',
301 |     # Warnings
302 |     'PkgResourcesDeprecationWarning',
303 |     # Deprecated/backward compatibility only
304 |     'run_main',
305 |     'AvailableDistributions',
306 | ]
307 | 
308 | 
309 | class ResolutionError(Exception):
310 |     """Abstract base for dependency resolution errors"""
311 | 
312 |     def __repr__(self):
313 |         return self.__class__.__name__ + repr(self.args)
314 | 
315 | 
316 | class VersionConflict(ResolutionError):
317 |     """
318 |     An already-installed version conflicts with the requested version.
319 | 
320 |     Should be initialized with the installed Distribution and the requested
321 |     Requirement.
322 |     """
323 | 
324 |     _template = "{self.dist} is installed but {self.req} is required"
325 | 
326 |     @property
327 |     def dist(self) -> Distribution:
328 |         return self.args[0]
329 | 
330 |     @property
331 |     def req(self) -> Requirement:
332 |         return self.args[1]
333 | 
334 |     def report(self):
335 |         return self._template.format(**locals())
336 | 
337 |     def with_context(self, required_by: set[Distribution | str]):
338 |         """
339 |         If required_by is non-empty, return a version of self that is a
340 |         ContextualVersionConflict.
341 |         """
342 |         if not required_by:
343 |             return self
344 |         args = self.args + (required_by,)
345 |         return ContextualVersionConflict(*args)
346 | 
347 | 
348 | class ContextualVersionConflict(VersionConflict):
349 |     """
350 |     A VersionConflict that accepts a third parameter, the set of the
351 |     requirements that required the installed Distribution.
352 |     """
353 | 
354 |     _template = VersionConflict._template + ' by {self.required_by}'
355 | 
356 |     @property
357 |     def required_by(self) -> set[str]:
358 |         return self.args[2]
359 | 
360 | 
361 | class DistributionNotFound(ResolutionError):
362 |     """A requested distribution was not found"""
363 | 
364 |     _template = (
365 |         "The '{self.req}' distribution was not found "
366 |         "and is required by {self.requirers_str}"
367 |     )
368 | 
369 |     @property
370 |     def req(self) -> Requirement:
371 |         return self.args[0]
372 | 
373 |     @property
374 |     def requirers(self) -> set[str] | None:
375 |         return self.args[1]
376 | 
377 |     @property
378 |     def requirers_str(self):
379 |         if not self.requirers:
380 |             return 'the application'
381 |         return ', '.join(self.requirers)
382 | 
383 |     def report(self):
384 |         return self._template.format(**locals())
385 | 
386 |     def __str__(self):
387 |         return self.report()
388 | 
389 | 
390 | class UnknownExtra(ResolutionError):
391 |     """Distribution doesn't have an "extra feature" of the given name"""
392 | 
393 | 
394 | _provider_factories: dict[type[_ModuleLike], _ProviderFactoryType] = {}
395 | 
396 | PY_MAJOR = '{}.{}'.format(*sys.version_info)
397 | EGG_DIST = 3
398 | BINARY_DIST = 2
399 | SOURCE_DIST = 1
400 | CHECKOUT_DIST = 0
401 | DEVELOP_DIST = -1
402 | 
403 | 
404 | def register_loader_type(
405 |     loader_type: type[_ModuleLike], provider_factory: _ProviderFactoryType
406 | ):
407 |     """Register `provider_factory` to make providers for `loader_type`
408 | 
409 |     `loader_type` is the type or class of a PEP 302 ``module.__loader__``,
410 |     and `provider_factory` is a function that, passed a *module* object,
411 |     returns an ``IResourceProvider`` for that module.
412 |     """
413 |     _provider_factories[loader_type] = provider_factory
414 | 
415 | 
416 | @overload
417 | def get_provider(moduleOrReq: str) -> IResourceProvider: ...
418 | @overload
[TRUNCATED]
```

.venv/lib/python3.13/site-packages/pip/_vendor/platformdirs/__init__.py
```
1 | """
2 | Utilities for determining application-specific dirs.
3 | 
4 | See <https://github.com/platformdirs/platformdirs> for details and usage.
5 | 
6 | """
7 | 
8 | from __future__ import annotations
9 | 
10 | import os
11 | import sys
12 | from typing import TYPE_CHECKING
13 | 
14 | from .api import PlatformDirsABC
15 | from .version import __version__
16 | from .version import __version_tuple__ as __version_info__
17 | 
18 | if TYPE_CHECKING:
19 |     from pathlib import Path
20 |     from typing import Literal
21 | 
22 | if sys.platform == "win32":
23 |     from pip._vendor.platformdirs.windows import Windows as _Result
24 | elif sys.platform == "darwin":
25 |     from pip._vendor.platformdirs.macos import MacOS as _Result
26 | else:
27 |     from pip._vendor.platformdirs.unix import Unix as _Result
28 | 
29 | 
30 | def _set_platform_dir_class() -> type[PlatformDirsABC]:
31 |     if os.getenv("ANDROID_DATA") == "/data" and os.getenv("ANDROID_ROOT") == "/system":
32 |         if os.getenv("SHELL") or os.getenv("PREFIX"):
33 |             return _Result
34 | 
35 |         from pip._vendor.platformdirs.android import _android_folder  # noqa: PLC0415
36 | 
37 |         if _android_folder() is not None:
38 |             from pip._vendor.platformdirs.android import Android  # noqa: PLC0415
39 | 
40 |             return Android  # return to avoid redefinition of a result
41 | 
42 |     return _Result
43 | 
44 | 
45 | if TYPE_CHECKING:
46 |     # Work around mypy issue: https://github.com/python/mypy/issues/10962
47 |     PlatformDirs = _Result
48 | else:
49 |     PlatformDirs = _set_platform_dir_class()  #: Currently active platform
50 | AppDirs = PlatformDirs  #: Backwards compatibility with appdirs
51 | 
52 | 
53 | def user_data_dir(
54 |     appname: str | None = None,
55 |     appauthor: str | Literal[False] | None = None,
56 |     version: str | None = None,
57 |     roaming: bool = False,  # noqa: FBT001, FBT002
58 |     ensure_exists: bool = False,  # noqa: FBT001, FBT002
59 | ) -> str:
60 |     """
61 |     :param appname: See `appname <platformdirs.api.PlatformDirsABC.appname>`.
62 |     :param appauthor: See `appauthor <platformdirs.api.PlatformDirsABC.appauthor>`.
63 |     :param version: See `version <platformdirs.api.PlatformDirsABC.version>`.
64 |     :param roaming: See `roaming <platformdirs.api.PlatformDirsABC.roaming>`.
65 |     :param ensure_exists: See `ensure_exists <platformdirs.api.PlatformDirsABC.ensure_exists>`.
66 |     :returns: data directory tied to the user
67 |     """
68 |     return PlatformDirs(
69 |         appname=appname,
70 |         appauthor=appauthor,
71 |         version=version,
72 |         roaming=roaming,
73 |         ensure_exists=ensure_exists,
74 |     ).user_data_dir
75 | 
76 | 
77 | def site_data_dir(
78 |     appname: str | None = None,
79 |     appauthor: str | Literal[False] | None = None,
80 |     version: str | None = None,
81 |     multipath: bool = False,  # noqa: FBT001, FBT002
82 |     ensure_exists: bool = False,  # noqa: FBT001, FBT002
83 | ) -> str:
84 |     """
85 |     :param appname: See `appname <platformdirs.api.PlatformDirsABC.appname>`.
86 |     :param appauthor: See `appauthor <platformdirs.api.PlatformDirsABC.appauthor>`.
87 |     :param version: See `version <platformdirs.api.PlatformDirsABC.version>`.
88 |     :param multipath: See `roaming <platformdirs.api.PlatformDirsABC.multipath>`.
89 |     :param ensure_exists: See `ensure_exists <platformdirs.api.PlatformDirsABC.ensure_exists>`.
90 |     :returns: data directory shared by users
91 |     """
92 |     return PlatformDirs(
93 |         appname=appname,
94 |         appauthor=appauthor,
95 |         version=version,
96 |         multipath=multipath,
97 |         ensure_exists=ensure_exists,
98 |     ).site_data_dir
99 | 
100 | 
101 | def user_config_dir(
102 |     appname: str | None = None,
103 |     appauthor: str | Literal[False] | None = None,
104 |     version: str | None = None,
105 |     roaming: bool = False,  # noqa: FBT001, FBT002
106 |     ensure_exists: bool = False,  # noqa: FBT001, FBT002
107 | ) -> str:
108 |     """
109 |     :param appname: See `appname <platformdirs.api.PlatformDirsABC.appname>`.
110 |     :param appauthor: See `appauthor <platformdirs.api.PlatformDirsABC.appauthor>`.
111 |     :param version: See `version <platformdirs.api.PlatformDirsABC.version>`.
112 |     :param roaming: See `roaming <platformdirs.api.PlatformDirsABC.roaming>`.
113 |     :param ensure_exists: See `ensure_exists <platformdirs.api.PlatformDirsABC.ensure_exists>`.
114 |     :returns: config directory tied to the user
115 |     """
116 |     return PlatformDirs(
117 |         appname=appname,
118 |         appauthor=appauthor,
119 |         version=version,
120 |         roaming=roaming,
121 |         ensure_exists=ensure_exists,
122 |     ).user_config_dir
123 | 
124 | 
125 | def site_config_dir(
126 |     appname: str | None = None,
127 |     appauthor: str | Literal[False] | None = None,
128 |     version: str | None = None,
129 |     multipath: bool = False,  # noqa: FBT001, FBT002
130 |     ensure_exists: bool = False,  # noqa: FBT001, FBT002
131 | ) -> str:
132 |     """
133 |     :param appname: See `appname <platformdirs.api.PlatformDirsABC.appname>`.
134 |     :param appauthor: See `appauthor <platformdirs.api.PlatformDirsABC.appauthor>`.
135 |     :param version: See `version <platformdirs.api.PlatformDirsABC.version>`.
136 |     :param multipath: See `roaming <platformdirs.api.PlatformDirsABC.multipath>`.
137 |     :param ensure_exists: See `ensure_exists <platformdirs.api.PlatformDirsABC.ensure_exists>`.
138 |     :returns: config directory shared by the users
139 |     """
140 |     return PlatformDirs(
141 |         appname=appname,
142 |         appauthor=appauthor,
143 |         version=version,
144 |         multipath=multipath,
145 |         ensure_exists=ensure_exists,
146 |     ).site_config_dir
147 | 
148 | 
149 | def user_cache_dir(
150 |     appname: str | None = None,
151 |     appauthor: str | Literal[False] | None = None,
152 |     version: str | None = None,
153 |     opinion: bool = True,  # noqa: FBT001, FBT002
154 |     ensure_exists: bool = False,  # noqa: FBT001, FBT002
155 | ) -> str:
156 |     """
157 |     :param appname: See `appname <platformdirs.api.PlatformDirsABC.appname>`.
158 |     :param appauthor: See `appauthor <platformdirs.api.PlatformDirsABC.appauthor>`.
159 |     :param version: See `version <platformdirs.api.PlatformDirsABC.version>`.
160 |     :param opinion: See `roaming <platformdirs.api.PlatformDirsABC.opinion>`.
161 |     :param ensure_exists: See `ensure_exists <platformdirs.api.PlatformDirsABC.ensure_exists>`.
162 |     :returns: cache directory tied to the user
163 |     """
164 |     return PlatformDirs(
165 |         appname=appname,
166 |         appauthor=appauthor,
167 |         version=version,
168 |         opinion=opinion,
169 |         ensure_exists=ensure_exists,
170 |     ).user_cache_dir
171 | 
172 | 
173 | def site_cache_dir(
174 |     appname: str | None = None,
175 |     appauthor: str | Literal[False] | None = None,
176 |     version: str | None = None,
177 |     opinion: bool = True,  # noqa: FBT001, FBT002
178 |     ensure_exists: bool = False,  # noqa: FBT001, FBT002
179 | ) -> str:
180 |     """
181 |     :param appname: See `appname <platformdirs.api.PlatformDirsABC.appname>`.
182 |     :param appauthor: See `appauthor <platformdirs.api.PlatformDirsABC.appauthor>`.
183 |     :param version: See `version <platformdirs.api.PlatformDirsABC.version>`.
184 |     :param opinion: See `opinion <platformdirs.api.PlatformDirsABC.opinion>`.
185 |     :param ensure_exists: See `ensure_exists <platformdirs.api.PlatformDirsABC.ensure_exists>`.
186 |     :returns: cache directory tied to the user
187 |     """
188 |     return PlatformDirs(
189 |         appname=appname,
190 |         appauthor=appauthor,
191 |         version=version,
192 |         opinion=opinion,
193 |         ensure_exists=ensure_exists,
194 |     ).site_cache_dir
195 | 
196 | 
197 | def user_state_dir(
198 |     appname: str | None = None,
199 |     appauthor: str | Literal[False] | None = None,
200 |     version: str | None = None,
201 |     roaming: bool = False,  # noqa: FBT001, FBT002
202 |     ensure_exists: bool = False,  # noqa: FBT001, FBT002
203 | ) -> str:
204 |     """
205 |     :param appname: See `appname <platformdirs.api.PlatformDirsABC.appname>`.
206 |     :param appauthor: See `appauthor <platformdirs.api.PlatformDirsABC.appauthor>`.
207 |     :param version: See `version <platformdirs.api.PlatformDirsABC.version>`.
208 |     :param roaming: See `roaming <platformdirs.api.PlatformDirsABC.roaming>`.
209 |     :param ensure_exists: See `ensure_exists <platformdirs.api.PlatformDirsABC.ensure_exists>`.
210 |     :returns: state directory tied to the user
211 |     """
212 |     return PlatformDirs(
213 |         appname=appname,
214 |         appauthor=appauthor,
215 |         version=version,
216 |         roaming=roaming,
217 |         ensure_exists=ensure_exists,
218 |     ).user_state_dir
219 | 
220 | 
221 | def user_log_dir(
222 |     appname: str | None = None,
223 |     appauthor: str | Literal[False] | None = None,
224 |     version: str | None = None,
225 |     opinion: bool = True,  # noqa: FBT001, FBT002
226 |     ensure_exists: bool = False,  # noqa: FBT001, FBT002
227 | ) -> str:
228 |     """
229 |     :param appname: See `appname <platformdirs.api.PlatformDirsABC.appname>`.
230 |     :param appauthor: See `appauthor <platformdirs.api.PlatformDirsABC.appauthor>`.
231 |     :param version: See `version <platformdirs.api.PlatformDirsABC.version>`.
232 |     :param opinion: See `roaming <platformdirs.api.PlatformDirsABC.opinion>`.
233 |     :param ensure_exists: See `ensure_exists <platformdirs.api.PlatformDirsABC.ensure_exists>`.
234 |     :returns: log directory tied to the user
235 |     """
236 |     return PlatformDirs(
237 |         appname=appname,
238 |         appauthor=appauthor,
239 |         version=version,
240 |         opinion=opinion,
241 |         ensure_exists=ensure_exists,
242 |     ).user_log_dir
243 | 
244 | 
245 | def user_documents_dir() -> str:
246 |     """:returns: documents directory tied to the user"""
247 |     return PlatformDirs().user_documents_dir
248 | 
249 | 
250 | def user_downloads_dir() -> str:
251 |     """:returns: downloads directory tied to the user"""
252 |     return PlatformDirs().user_downloads_dir
253 | 
254 | 
255 | def user_pictures_dir() -> str:
256 |     """:returns: pictures directory tied to the user"""
257 |     return PlatformDirs().user_pictures_dir
258 | 
259 | 
260 | def user_videos_dir() -> str:
261 |     """:returns: videos directory tied to the user"""
262 |     return PlatformDirs().user_videos_dir
263 | 
264 | 
265 | def user_music_dir() -> str:
266 |     """:returns: music directory tied to the user"""
267 |     return PlatformDirs().user_music_dir
268 | 
269 | 
270 | def user_desktop_dir() -> str:
271 |     """:returns: desktop directory tied to the user"""
272 |     return PlatformDirs().user_desktop_dir
273 | 
274 | 
275 | def user_runtime_dir(
276 |     appname: str | None = None,
277 |     appauthor: str | Literal[False] | None = None,
278 |     version: str | None = None,
279 |     opinion: bool = True,  # noqa: FBT001, FBT002
280 |     ensure_exists: bool = False,  # noqa: FBT001, FBT002
281 | ) -> str:
282 |     """
283 |     :param appname: See `appname <platformdirs.api.PlatformDirsABC.appname>`.
284 |     :param appauthor: See `appauthor <platformdirs.api.PlatformDirsABC.appauthor>`.
285 |     :param version: See `version <platformdirs.api.PlatformDirsABC.version>`.
286 |     :param opinion: See `opinion <platformdirs.api.PlatformDirsABC.opinion>`.
287 |     :param ensure_exists: See `ensure_exists <platformdirs.api.PlatformDirsABC.ensure_exists>`.
288 |     :returns: runtime directory tied to the user
289 |     """
290 |     return PlatformDirs(
291 |         appname=appname,
292 |         appauthor=appauthor,
293 |         version=version,
294 |         opinion=opinion,
295 |         ensure_exists=ensure_exists,
296 |     ).user_runtime_dir
297 | 
298 | 
299 | def site_runtime_dir(
300 |     appname: str | None = None,
301 |     appauthor: str | Literal[False] | None = None,
302 |     version: str | None = None,
303 |     opinion: bool = True,  # noqa: FBT001, FBT002
304 |     ensure_exists: bool = False,  # noqa: FBT001, FBT002
305 | ) -> str:
306 |     """
307 |     :param appname: See `appname <platformdirs.api.PlatformDirsABC.appname>`.
308 |     :param appauthor: See `appauthor <platformdirs.api.PlatformDirsABC.appauthor>`.
309 |     :param version: See `version <platformdirs.api.PlatformDirsABC.version>`.
310 |     :param opinion: See `opinion <platformdirs.api.PlatformDirsABC.opinion>`.
311 |     :param ensure_exists: See `ensure_exists <platformdirs.api.PlatformDirsABC.ensure_exists>`.
312 |     :returns: runtime directory shared by users
313 |     """
314 |     return PlatformDirs(
315 |         appname=appname,
316 |         appauthor=appauthor,
317 |         version=version,
318 |         opinion=opinion,
319 |         ensure_exists=ensure_exists,
320 |     ).site_runtime_dir
321 | 
322 | 
323 | def user_data_path(
324 |     appname: str | None = None,
325 |     appauthor: str | Literal[False] | None = None,
326 |     version: str | None = None,
327 |     roaming: bool = False,  # noqa: FBT001, FBT002
328 |     ensure_exists: bool = False,  # noqa: FBT001, FBT002
329 | ) -> Path:
330 |     """
331 |     :param appname: See `appname <platformdirs.api.PlatformDirsABC.appname>`.
332 |     :param appauthor: See `appauthor <platformdirs.api.PlatformDirsABC.appauthor>`.
333 |     :param version: See `version <platformdirs.api.PlatformDirsABC.version>`.
334 |     :param roaming: See `roaming <platformdirs.api.PlatformDirsABC.roaming>`.
335 |     :param ensure_exists: See `ensure_exists <platformdirs.api.PlatformDirsABC.ensure_exists>`.
336 |     :returns: data path tied to the user
337 |     """
338 |     return PlatformDirs(
339 |         appname=appname,
340 |         appauthor=appauthor,
341 |         version=version,
342 |         roaming=roaming,
343 |         ensure_exists=ensure_exists,
344 |     ).user_data_path
345 | 
346 | 
347 | def site_data_path(
348 |     appname: str | None = None,
349 |     appauthor: str | Literal[False] | None = None,
350 |     version: str | None = None,
351 |     multipath: bool = False,  # noqa: FBT001, FBT002
352 |     ensure_exists: bool = False,  # noqa: FBT001, FBT002
353 | ) -> Path:
354 |     """
355 |     :param appname: See `appname <platformdirs.api.PlatformDirsABC.appname>`.
356 |     :param appauthor: See `appauthor <platformdirs.api.PlatformDirsABC.appauthor>`.
357 |     :param version: See `version <platformdirs.api.PlatformDirsABC.version>`.
358 |     :param multipath: See `multipath <platformdirs.api.PlatformDirsABC.multipath>`.
[TRUNCATED]
```

.venv/lib/python3.13/site-packages/pip/_vendor/platformdirs/__main__.py
```
1 | """Main entry point."""
2 | 
3 | from __future__ import annotations
4 | 
5 | from pip._vendor.platformdirs import PlatformDirs, __version__
6 | 
7 | PROPS = (
8 |     "user_data_dir",
9 |     "user_config_dir",
10 |     "user_cache_dir",
11 |     "user_state_dir",
12 |     "user_log_dir",
13 |     "user_documents_dir",
14 |     "user_downloads_dir",
15 |     "user_pictures_dir",
16 |     "user_videos_dir",
17 |     "user_music_dir",
18 |     "user_runtime_dir",
19 |     "site_data_dir",
20 |     "site_config_dir",
21 |     "site_cache_dir",
22 |     "site_runtime_dir",
23 | )
24 | 
25 | 
26 | def main() -> None:
27 |     """Run the main entry point."""
28 |     app_name = "MyApp"
29 |     app_author = "MyCompany"
30 | 
31 |     print(f"-- platformdirs {__version__} --")  # noqa: T201
32 | 
33 |     print("-- app dirs (with optional 'version')")  # noqa: T201
34 |     dirs = PlatformDirs(app_name, app_author, version="1.0")
35 |     for prop in PROPS:
36 |         print(f"{prop}: {getattr(dirs, prop)}")  # noqa: T201
37 | 
38 |     print("\n-- app dirs (without optional 'version')")  # noqa: T201
39 |     dirs = PlatformDirs(app_name, app_author)
40 |     for prop in PROPS:
41 |         print(f"{prop}: {getattr(dirs, prop)}")  # noqa: T201
42 | 
43 |     print("\n-- app dirs (without optional 'appauthor')")  # noqa: T201
44 |     dirs = PlatformDirs(app_name)
45 |     for prop in PROPS:
46 |         print(f"{prop}: {getattr(dirs, prop)}")  # noqa: T201
47 | 
48 |     print("\n-- app dirs (with disabled 'appauthor')")  # noqa: T201
49 |     dirs = PlatformDirs(app_name, appauthor=False)
50 |     for prop in PROPS:
51 |         print(f"{prop}: {getattr(dirs, prop)}")  # noqa: T201
52 | 
53 | 
54 | if __name__ == "__main__":
55 |     main()
```

.venv/lib/python3.13/site-packages/pip/_vendor/platformdirs/android.py
```
1 | """Android."""
2 | 
3 | from __future__ import annotations
4 | 
5 | import os
6 | import re
7 | import sys
8 | from functools import lru_cache
9 | from typing import TYPE_CHECKING, cast
10 | 
11 | from .api import PlatformDirsABC
12 | 
13 | 
14 | class Android(PlatformDirsABC):
15 |     """
16 |     Follows the guidance `from here <https://android.stackexchange.com/a/216132>`_.
17 | 
18 |     Makes use of the `appname <platformdirs.api.PlatformDirsABC.appname>`, `version
19 |     <platformdirs.api.PlatformDirsABC.version>`, `ensure_exists <platformdirs.api.PlatformDirsABC.ensure_exists>`.
20 | 
21 |     """
22 | 
23 |     @property
24 |     def user_data_dir(self) -> str:
25 |         """:return: data directory tied to the user, e.g. ``/data/user/<userid>/<packagename>/files/<AppName>``"""
26 |         return self._append_app_name_and_version(cast("str", _android_folder()), "files")
27 | 
28 |     @property
29 |     def site_data_dir(self) -> str:
30 |         """:return: data directory shared by users, same as `user_data_dir`"""
31 |         return self.user_data_dir
32 | 
33 |     @property
34 |     def user_config_dir(self) -> str:
35 |         """
36 |         :return: config directory tied to the user, e.g. \
37 |         ``/data/user/<userid>/<packagename>/shared_prefs/<AppName>``
38 |         """
39 |         return self._append_app_name_and_version(cast("str", _android_folder()), "shared_prefs")
40 | 
41 |     @property
42 |     def site_config_dir(self) -> str:
43 |         """:return: config directory shared by the users, same as `user_config_dir`"""
44 |         return self.user_config_dir
45 | 
46 |     @property
47 |     def user_cache_dir(self) -> str:
48 |         """:return: cache directory tied to the user, e.g.,``/data/user/<userid>/<packagename>/cache/<AppName>``"""
49 |         return self._append_app_name_and_version(cast("str", _android_folder()), "cache")
50 | 
51 |     @property
52 |     def site_cache_dir(self) -> str:
53 |         """:return: cache directory shared by users, same as `user_cache_dir`"""
54 |         return self.user_cache_dir
55 | 
56 |     @property
57 |     def user_state_dir(self) -> str:
58 |         """:return: state directory tied to the user, same as `user_data_dir`"""
59 |         return self.user_data_dir
60 | 
61 |     @property
62 |     def user_log_dir(self) -> str:
63 |         """
64 |         :return: log directory tied to the user, same as `user_cache_dir` if not opinionated else ``log`` in it,
65 |           e.g. ``/data/user/<userid>/<packagename>/cache/<AppName>/log``
66 |         """
67 |         path = self.user_cache_dir
68 |         if self.opinion:
69 |             path = os.path.join(path, "log")  # noqa: PTH118
70 |         return path
71 | 
72 |     @property
73 |     def user_documents_dir(self) -> str:
74 |         """:return: documents directory tied to the user e.g. ``/storage/emulated/0/Documents``"""
75 |         return _android_documents_folder()
76 | 
77 |     @property
78 |     def user_downloads_dir(self) -> str:
79 |         """:return: downloads directory tied to the user e.g. ``/storage/emulated/0/Downloads``"""
80 |         return _android_downloads_folder()
81 | 
82 |     @property
83 |     def user_pictures_dir(self) -> str:
84 |         """:return: pictures directory tied to the user e.g. ``/storage/emulated/0/Pictures``"""
85 |         return _android_pictures_folder()
86 | 
87 |     @property
88 |     def user_videos_dir(self) -> str:
89 |         """:return: videos directory tied to the user e.g. ``/storage/emulated/0/DCIM/Camera``"""
90 |         return _android_videos_folder()
91 | 
92 |     @property
93 |     def user_music_dir(self) -> str:
94 |         """:return: music directory tied to the user e.g. ``/storage/emulated/0/Music``"""
95 |         return _android_music_folder()
96 | 
97 |     @property
98 |     def user_desktop_dir(self) -> str:
99 |         """:return: desktop directory tied to the user e.g. ``/storage/emulated/0/Desktop``"""
100 |         return "/storage/emulated/0/Desktop"
101 | 
102 |     @property
103 |     def user_runtime_dir(self) -> str:
104 |         """
105 |         :return: runtime directory tied to the user, same as `user_cache_dir` if not opinionated else ``tmp`` in it,
106 |           e.g. ``/data/user/<userid>/<packagename>/cache/<AppName>/tmp``
107 |         """
108 |         path = self.user_cache_dir
109 |         if self.opinion:
110 |             path = os.path.join(path, "tmp")  # noqa: PTH118
111 |         return path
112 | 
113 |     @property
114 |     def site_runtime_dir(self) -> str:
115 |         """:return: runtime directory shared by users, same as `user_runtime_dir`"""
116 |         return self.user_runtime_dir
117 | 
118 | 
119 | @lru_cache(maxsize=1)
120 | def _android_folder() -> str | None:  # noqa: C901
121 |     """:return: base folder for the Android OS or None if it cannot be found"""
122 |     result: str | None = None
123 |     # type checker isn't happy with our "import android", just don't do this when type checking see
124 |     # https://stackoverflow.com/a/61394121
125 |     if not TYPE_CHECKING:
126 |         try:
127 |             # First try to get a path to android app using python4android (if available)...
128 |             from android import mActivity  # noqa: PLC0415
129 | 
130 |             context = cast("android.content.Context", mActivity.getApplicationContext())  # noqa: F821
131 |             result = context.getFilesDir().getParentFile().getAbsolutePath()
132 |         except Exception:  # noqa: BLE001
133 |             result = None
134 |     if result is None:
135 |         try:
136 |             # ...and fall back to using plain pyjnius, if python4android isn't available or doesn't deliver any useful
137 |             # result...
138 |             from jnius import autoclass  # noqa: PLC0415
139 | 
140 |             context = autoclass("android.content.Context")
141 |             result = context.getFilesDir().getParentFile().getAbsolutePath()
142 |         except Exception:  # noqa: BLE001
143 |             result = None
144 |     if result is None:
145 |         # and if that fails, too, find an android folder looking at path on the sys.path
146 |         # warning: only works for apps installed under /data, not adopted storage etc.
147 |         pattern = re.compile(r"/data/(data|user/\d+)/(.+)/files")
148 |         for path in sys.path:
149 |             if pattern.match(path):
150 |                 result = path.split("/files")[0]
151 |                 break
152 |         else:
153 |             result = None
154 |     if result is None:
155 |         # one last try: find an android folder looking at path on the sys.path taking adopted storage paths into
156 |         # account
157 |         pattern = re.compile(r"/mnt/expand/[a-fA-F0-9-]{36}/(data|user/\d+)/(.+)/files")
158 |         for path in sys.path:
159 |             if pattern.match(path):
160 |                 result = path.split("/files")[0]
161 |                 break
162 |         else:
163 |             result = None
164 |     return result
165 | 
166 | 
167 | @lru_cache(maxsize=1)
168 | def _android_documents_folder() -> str:
169 |     """:return: documents folder for the Android OS"""
170 |     # Get directories with pyjnius
171 |     try:
172 |         from jnius import autoclass  # noqa: PLC0415
173 | 
174 |         context = autoclass("android.content.Context")
175 |         environment = autoclass("android.os.Environment")
176 |         documents_dir: str = context.getExternalFilesDir(environment.DIRECTORY_DOCUMENTS).getAbsolutePath()
177 |     except Exception:  # noqa: BLE001
178 |         documents_dir = "/storage/emulated/0/Documents"
179 | 
180 |     return documents_dir
181 | 
182 | 
183 | @lru_cache(maxsize=1)
184 | def _android_downloads_folder() -> str:
185 |     """:return: downloads folder for the Android OS"""
186 |     # Get directories with pyjnius
187 |     try:
188 |         from jnius import autoclass  # noqa: PLC0415
189 | 
190 |         context = autoclass("android.content.Context")
191 |         environment = autoclass("android.os.Environment")
192 |         downloads_dir: str = context.getExternalFilesDir(environment.DIRECTORY_DOWNLOADS).getAbsolutePath()
193 |     except Exception:  # noqa: BLE001
194 |         downloads_dir = "/storage/emulated/0/Downloads"
195 | 
196 |     return downloads_dir
197 | 
198 | 
199 | @lru_cache(maxsize=1)
200 | def _android_pictures_folder() -> str:
201 |     """:return: pictures folder for the Android OS"""
202 |     # Get directories with pyjnius
203 |     try:
204 |         from jnius import autoclass  # noqa: PLC0415
205 | 
206 |         context = autoclass("android.content.Context")
207 |         environment = autoclass("android.os.Environment")
208 |         pictures_dir: str = context.getExternalFilesDir(environment.DIRECTORY_PICTURES).getAbsolutePath()
209 |     except Exception:  # noqa: BLE001
210 |         pictures_dir = "/storage/emulated/0/Pictures"
211 | 
212 |     return pictures_dir
213 | 
214 | 
215 | @lru_cache(maxsize=1)
216 | def _android_videos_folder() -> str:
217 |     """:return: videos folder for the Android OS"""
218 |     # Get directories with pyjnius
219 |     try:
220 |         from jnius import autoclass  # noqa: PLC0415
221 | 
222 |         context = autoclass("android.content.Context")
223 |         environment = autoclass("android.os.Environment")
224 |         videos_dir: str = context.getExternalFilesDir(environment.DIRECTORY_DCIM).getAbsolutePath()
225 |     except Exception:  # noqa: BLE001
226 |         videos_dir = "/storage/emulated/0/DCIM/Camera"
227 | 
228 |     return videos_dir
229 | 
230 | 
231 | @lru_cache(maxsize=1)
232 | def _android_music_folder() -> str:
233 |     """:return: music folder for the Android OS"""
234 |     # Get directories with pyjnius
235 |     try:
236 |         from jnius import autoclass  # noqa: PLC0415
237 | 
238 |         context = autoclass("android.content.Context")
239 |         environment = autoclass("android.os.Environment")
240 |         music_dir: str = context.getExternalFilesDir(environment.DIRECTORY_MUSIC).getAbsolutePath()
241 |     except Exception:  # noqa: BLE001
242 |         music_dir = "/storage/emulated/0/Music"
243 | 
244 |     return music_dir
245 | 
246 | 
247 | __all__ = [
248 |     "Android",
249 | ]
```

.venv/lib/python3.13/site-packages/pip/_vendor/platformdirs/api.py
```
1 | """Base API."""
2 | 
3 | from __future__ import annotations
4 | 
5 | import os
6 | from abc import ABC, abstractmethod
7 | from pathlib import Path
8 | from typing import TYPE_CHECKING
9 | 
10 | if TYPE_CHECKING:
11 |     from collections.abc import Iterator
12 |     from typing import Literal
13 | 
14 | 
15 | class PlatformDirsABC(ABC):  # noqa: PLR0904
16 |     """Abstract base class for platform directories."""
17 | 
18 |     def __init__(  # noqa: PLR0913, PLR0917
19 |         self,
20 |         appname: str | None = None,
21 |         appauthor: str | Literal[False] | None = None,
22 |         version: str | None = None,
23 |         roaming: bool = False,  # noqa: FBT001, FBT002
24 |         multipath: bool = False,  # noqa: FBT001, FBT002
25 |         opinion: bool = True,  # noqa: FBT001, FBT002
26 |         ensure_exists: bool = False,  # noqa: FBT001, FBT002
27 |     ) -> None:
28 |         """
29 |         Create a new platform directory.
30 | 
31 |         :param appname: See `appname`.
32 |         :param appauthor: See `appauthor`.
33 |         :param version: See `version`.
34 |         :param roaming: See `roaming`.
35 |         :param multipath: See `multipath`.
36 |         :param opinion: See `opinion`.
37 |         :param ensure_exists: See `ensure_exists`.
38 | 
39 |         """
40 |         self.appname = appname  #: The name of application.
41 |         self.appauthor = appauthor
42 |         """
43 |         The name of the app author or distributing body for this application.
44 | 
45 |         Typically, it is the owning company name. Defaults to `appname`. You may pass ``False`` to disable it.
46 | 
47 |         """
48 |         self.version = version
49 |         """
50 |         An optional version path element to append to the path.
51 | 
52 |         You might want to use this if you want multiple versions of your app to be able to run independently. If used,
53 |         this would typically be ``<major>.<minor>``.
54 | 
55 |         """
56 |         self.roaming = roaming
57 |         """
58 |         Whether to use the roaming appdata directory on Windows.
59 | 
60 |         That means that for users on a Windows network setup for roaming profiles, this user data will be synced on
61 |         login (see
62 |         `here <https://technet.microsoft.com/en-us/library/cc766489(WS.10).aspx>`_).
63 | 
64 |         """
65 |         self.multipath = multipath
66 |         """
67 |         An optional parameter which indicates that the entire list of data dirs should be returned.
68 | 
69 |         By default, the first item would only be returned.
70 | 
71 |         """
72 |         self.opinion = opinion  #: A flag to indicating to use opinionated values.
73 |         self.ensure_exists = ensure_exists
74 |         """
75 |         Optionally create the directory (and any missing parents) upon access if it does not exist.
76 | 
77 |         By default, no directories are created.
78 | 
79 |         """
80 | 
81 |     def _append_app_name_and_version(self, *base: str) -> str:
82 |         params = list(base[1:])
83 |         if self.appname:
84 |             params.append(self.appname)
85 |             if self.version:
86 |                 params.append(self.version)
87 |         path = os.path.join(base[0], *params)  # noqa: PTH118
88 |         self._optionally_create_directory(path)
89 |         return path
90 | 
91 |     def _optionally_create_directory(self, path: str) -> None:
92 |         if self.ensure_exists:
93 |             Path(path).mkdir(parents=True, exist_ok=True)
94 | 
95 |     def _first_item_as_path_if_multipath(self, directory: str) -> Path:
96 |         if self.multipath:
97 |             # If multipath is True, the first path is returned.
98 |             directory = directory.split(os.pathsep)[0]
99 |         return Path(directory)
100 | 
101 |     @property
102 |     @abstractmethod
103 |     def user_data_dir(self) -> str:
104 |         """:return: data directory tied to the user"""
105 | 
106 |     @property
107 |     @abstractmethod
108 |     def site_data_dir(self) -> str:
109 |         """:return: data directory shared by users"""
110 | 
111 |     @property
112 |     @abstractmethod
113 |     def user_config_dir(self) -> str:
114 |         """:return: config directory tied to the user"""
115 | 
116 |     @property
117 |     @abstractmethod
118 |     def site_config_dir(self) -> str:
119 |         """:return: config directory shared by the users"""
120 | 
121 |     @property
122 |     @abstractmethod
123 |     def user_cache_dir(self) -> str:
124 |         """:return: cache directory tied to the user"""
125 | 
126 |     @property
127 |     @abstractmethod
128 |     def site_cache_dir(self) -> str:
129 |         """:return: cache directory shared by users"""
130 | 
131 |     @property
132 |     @abstractmethod
133 |     def user_state_dir(self) -> str:
134 |         """:return: state directory tied to the user"""
135 | 
136 |     @property
137 |     @abstractmethod
138 |     def user_log_dir(self) -> str:
139 |         """:return: log directory tied to the user"""
140 | 
141 |     @property
142 |     @abstractmethod
143 |     def user_documents_dir(self) -> str:
144 |         """:return: documents directory tied to the user"""
145 | 
146 |     @property
147 |     @abstractmethod
148 |     def user_downloads_dir(self) -> str:
149 |         """:return: downloads directory tied to the user"""
150 | 
151 |     @property
152 |     @abstractmethod
153 |     def user_pictures_dir(self) -> str:
154 |         """:return: pictures directory tied to the user"""
155 | 
156 |     @property
157 |     @abstractmethod
158 |     def user_videos_dir(self) -> str:
159 |         """:return: videos directory tied to the user"""
160 | 
161 |     @property
162 |     @abstractmethod
163 |     def user_music_dir(self) -> str:
164 |         """:return: music directory tied to the user"""
165 | 
166 |     @property
167 |     @abstractmethod
168 |     def user_desktop_dir(self) -> str:
169 |         """:return: desktop directory tied to the user"""
170 | 
171 |     @property
172 |     @abstractmethod
173 |     def user_runtime_dir(self) -> str:
174 |         """:return: runtime directory tied to the user"""
175 | 
176 |     @property
177 |     @abstractmethod
178 |     def site_runtime_dir(self) -> str:
179 |         """:return: runtime directory shared by users"""
180 | 
181 |     @property
182 |     def user_data_path(self) -> Path:
183 |         """:return: data path tied to the user"""
184 |         return Path(self.user_data_dir)
185 | 
186 |     @property
187 |     def site_data_path(self) -> Path:
188 |         """:return: data path shared by users"""
189 |         return Path(self.site_data_dir)
190 | 
191 |     @property
192 |     def user_config_path(self) -> Path:
193 |         """:return: config path tied to the user"""
194 |         return Path(self.user_config_dir)
195 | 
196 |     @property
197 |     def site_config_path(self) -> Path:
198 |         """:return: config path shared by the users"""
199 |         return Path(self.site_config_dir)
200 | 
201 |     @property
202 |     def user_cache_path(self) -> Path:
203 |         """:return: cache path tied to the user"""
204 |         return Path(self.user_cache_dir)
205 | 
206 |     @property
207 |     def site_cache_path(self) -> Path:
208 |         """:return: cache path shared by users"""
209 |         return Path(self.site_cache_dir)
210 | 
211 |     @property
212 |     def user_state_path(self) -> Path:
213 |         """:return: state path tied to the user"""
214 |         return Path(self.user_state_dir)
215 | 
216 |     @property
217 |     def user_log_path(self) -> Path:
218 |         """:return: log path tied to the user"""
219 |         return Path(self.user_log_dir)
220 | 
221 |     @property
222 |     def user_documents_path(self) -> Path:
223 |         """:return: documents a path tied to the user"""
224 |         return Path(self.user_documents_dir)
225 | 
226 |     @property
227 |     def user_downloads_path(self) -> Path:
228 |         """:return: downloads path tied to the user"""
229 |         return Path(self.user_downloads_dir)
230 | 
231 |     @property
232 |     def user_pictures_path(self) -> Path:
233 |         """:return: pictures path tied to the user"""
234 |         return Path(self.user_pictures_dir)
235 | 
236 |     @property
237 |     def user_videos_path(self) -> Path:
238 |         """:return: videos path tied to the user"""
239 |         return Path(self.user_videos_dir)
240 | 
241 |     @property
242 |     def user_music_path(self) -> Path:
243 |         """:return: music path tied to the user"""
244 |         return Path(self.user_music_dir)
245 | 
246 |     @property
247 |     def user_desktop_path(self) -> Path:
248 |         """:return: desktop path tied to the user"""
249 |         return Path(self.user_desktop_dir)
250 | 
251 |     @property
252 |     def user_runtime_path(self) -> Path:
253 |         """:return: runtime path tied to the user"""
254 |         return Path(self.user_runtime_dir)
255 | 
256 |     @property
257 |     def site_runtime_path(self) -> Path:
258 |         """:return: runtime path shared by users"""
259 |         return Path(self.site_runtime_dir)
260 | 
261 |     def iter_config_dirs(self) -> Iterator[str]:
262 |         """:yield: all user and site configuration directories."""
263 |         yield self.user_config_dir
264 |         yield self.site_config_dir
265 | 
266 |     def iter_data_dirs(self) -> Iterator[str]:
267 |         """:yield: all user and site data directories."""
268 |         yield self.user_data_dir
269 |         yield self.site_data_dir
270 | 
271 |     def iter_cache_dirs(self) -> Iterator[str]:
272 |         """:yield: all user and site cache directories."""
273 |         yield self.user_cache_dir
274 |         yield self.site_cache_dir
275 | 
276 |     def iter_runtime_dirs(self) -> Iterator[str]:
277 |         """:yield: all user and site runtime directories."""
278 |         yield self.user_runtime_dir
279 |         yield self.site_runtime_dir
280 | 
281 |     def iter_config_paths(self) -> Iterator[Path]:
282 |         """:yield: all user and site configuration paths."""
283 |         for path in self.iter_config_dirs():
284 |             yield Path(path)
285 | 
286 |     def iter_data_paths(self) -> Iterator[Path]:
287 |         """:yield: all user and site data paths."""
288 |         for path in self.iter_data_dirs():
289 |             yield Path(path)
290 | 
291 |     def iter_cache_paths(self) -> Iterator[Path]:
292 |         """:yield: all user and site cache paths."""
293 |         for path in self.iter_cache_dirs():
294 |             yield Path(path)
295 | 
296 |     def iter_runtime_paths(self) -> Iterator[Path]:
297 |         """:yield: all user and site runtime paths."""
298 |         for path in self.iter_runtime_dirs():
299 |             yield Path(path)
```

.venv/lib/python3.13/site-packages/pip/_vendor/platformdirs/macos.py
```
1 | """macOS."""
2 | 
3 | from __future__ import annotations
4 | 
5 | import os.path
6 | import sys
7 | from typing import TYPE_CHECKING
8 | 
9 | from .api import PlatformDirsABC
10 | 
11 | if TYPE_CHECKING:
12 |     from pathlib import Path
13 | 
14 | 
15 | class MacOS(PlatformDirsABC):
16 |     """
17 |     Platform directories for the macOS operating system.
18 | 
19 |     Follows the guidance from
20 |     `Apple documentation <https://developer.apple.com/library/archive/documentation/FileManagement/Conceptual/FileSystemProgrammingGuide/MacOSXDirectories/MacOSXDirectories.html>`_.
21 |     Makes use of the `appname <platformdirs.api.PlatformDirsABC.appname>`,
22 |     `version <platformdirs.api.PlatformDirsABC.version>`,
23 |     `ensure_exists <platformdirs.api.PlatformDirsABC.ensure_exists>`.
24 | 
25 |     """
26 | 
27 |     @property
28 |     def user_data_dir(self) -> str:
29 |         """:return: data directory tied to the user, e.g. ``~/Library/Application Support/$appname/$version``"""
30 |         return self._append_app_name_and_version(os.path.expanduser("~/Library/Application Support"))  # noqa: PTH111
31 | 
32 |     @property
33 |     def site_data_dir(self) -> str:
34 |         """
35 |         :return: data directory shared by users, e.g. ``/Library/Application Support/$appname/$version``.
36 |           If we're using a Python binary managed by `Homebrew <https://brew.sh>`_, the directory
37 |           will be under the Homebrew prefix, e.g. ``/opt/homebrew/share/$appname/$version``.
38 |           If `multipath <platformdirs.api.PlatformDirsABC.multipath>` is enabled, and we're in Homebrew,
39 |           the response is a multi-path string separated by ":", e.g.
40 |           ``/opt/homebrew/share/$appname/$version:/Library/Application Support/$appname/$version``
41 |         """
42 |         is_homebrew = sys.prefix.startswith("/opt/homebrew")
43 |         path_list = [self._append_app_name_and_version("/opt/homebrew/share")] if is_homebrew else []
44 |         path_list.append(self._append_app_name_and_version("/Library/Application Support"))
45 |         if self.multipath:
46 |             return os.pathsep.join(path_list)
47 |         return path_list[0]
48 | 
49 |     @property
50 |     def site_data_path(self) -> Path:
51 |         """:return: data path shared by users. Only return the first item, even if ``multipath`` is set to ``True``"""
52 |         return self._first_item_as_path_if_multipath(self.site_data_dir)
53 | 
54 |     @property
55 |     def user_config_dir(self) -> str:
56 |         """:return: config directory tied to the user, same as `user_data_dir`"""
57 |         return self.user_data_dir
58 | 
59 |     @property
60 |     def site_config_dir(self) -> str:
61 |         """:return: config directory shared by the users, same as `site_data_dir`"""
62 |         return self.site_data_dir
63 | 
64 |     @property
65 |     def user_cache_dir(self) -> str:
66 |         """:return: cache directory tied to the user, e.g. ``~/Library/Caches/$appname/$version``"""
67 |         return self._append_app_name_and_version(os.path.expanduser("~/Library/Caches"))  # noqa: PTH111
68 | 
69 |     @property
70 |     def site_cache_dir(self) -> str:
71 |         """
72 |         :return: cache directory shared by users, e.g. ``/Library/Caches/$appname/$version``.
73 |           If we're using a Python binary managed by `Homebrew <https://brew.sh>`_, the directory
74 |           will be under the Homebrew prefix, e.g. ``/opt/homebrew/var/cache/$appname/$version``.
75 |           If `multipath <platformdirs.api.PlatformDirsABC.multipath>` is enabled, and we're in Homebrew,
76 |           the response is a multi-path string separated by ":", e.g.
77 |           ``/opt/homebrew/var/cache/$appname/$version:/Library/Caches/$appname/$version``
78 |         """
79 |         is_homebrew = sys.prefix.startswith("/opt/homebrew")
80 |         path_list = [self._append_app_name_and_version("/opt/homebrew/var/cache")] if is_homebrew else []
81 |         path_list.append(self._append_app_name_and_version("/Library/Caches"))
82 |         if self.multipath:
83 |             return os.pathsep.join(path_list)
84 |         return path_list[0]
85 | 
86 |     @property
87 |     def site_cache_path(self) -> Path:
88 |         """:return: cache path shared by users. Only return the first item, even if ``multipath`` is set to ``True``"""
89 |         return self._first_item_as_path_if_multipath(self.site_cache_dir)
90 | 
91 |     @property
92 |     def user_state_dir(self) -> str:
93 |         """:return: state directory tied to the user, same as `user_data_dir`"""
94 |         return self.user_data_dir
95 | 
96 |     @property
97 |     def user_log_dir(self) -> str:
98 |         """:return: log directory tied to the user, e.g. ``~/Library/Logs/$appname/$version``"""
99 |         return self._append_app_name_and_version(os.path.expanduser("~/Library/Logs"))  # noqa: PTH111
100 | 
101 |     @property
102 |     def user_documents_dir(self) -> str:
103 |         """:return: documents directory tied to the user, e.g. ``~/Documents``"""
104 |         return os.path.expanduser("~/Documents")  # noqa: PTH111
105 | 
106 |     @property
107 |     def user_downloads_dir(self) -> str:
108 |         """:return: downloads directory tied to the user, e.g. ``~/Downloads``"""
109 |         return os.path.expanduser("~/Downloads")  # noqa: PTH111
110 | 
111 |     @property
112 |     def user_pictures_dir(self) -> str:
113 |         """:return: pictures directory tied to the user, e.g. ``~/Pictures``"""
114 |         return os.path.expanduser("~/Pictures")  # noqa: PTH111
115 | 
116 |     @property
117 |     def user_videos_dir(self) -> str:
118 |         """:return: videos directory tied to the user, e.g. ``~/Movies``"""
119 |         return os.path.expanduser("~/Movies")  # noqa: PTH111
120 | 
121 |     @property
122 |     def user_music_dir(self) -> str:
123 |         """:return: music directory tied to the user, e.g. ``~/Music``"""
124 |         return os.path.expanduser("~/Music")  # noqa: PTH111
125 | 
126 |     @property
127 |     def user_desktop_dir(self) -> str:
128 |         """:return: desktop directory tied to the user, e.g. ``~/Desktop``"""
129 |         return os.path.expanduser("~/Desktop")  # noqa: PTH111
130 | 
131 |     @property
132 |     def user_runtime_dir(self) -> str:
133 |         """:return: runtime directory tied to the user, e.g. ``~/Library/Caches/TemporaryItems/$appname/$version``"""
134 |         return self._append_app_name_and_version(os.path.expanduser("~/Library/Caches/TemporaryItems"))  # noqa: PTH111
135 | 
136 |     @property
137 |     def site_runtime_dir(self) -> str:
138 |         """:return: runtime directory shared by users, same as `user_runtime_dir`"""
139 |         return self.user_runtime_dir
140 | 
141 | 
142 | __all__ = [
143 |     "MacOS",
144 | ]
```

.venv/lib/python3.13/site-packages/pip/_vendor/platformdirs/py.typed
```
```

.venv/lib/python3.13/site-packages/pip/_vendor/platformdirs/unix.py
```
1 | """Unix."""
2 | 
3 | from __future__ import annotations
4 | 
5 | import os
6 | import sys
7 | from configparser import ConfigParser
8 | from pathlib import Path
9 | from typing import TYPE_CHECKING, NoReturn
10 | 
11 | from .api import PlatformDirsABC
12 | 
13 | if TYPE_CHECKING:
14 |     from collections.abc import Iterator
15 | 
16 | if sys.platform == "win32":
17 | 
18 |     def getuid() -> NoReturn:
19 |         msg = "should only be used on Unix"
20 |         raise RuntimeError(msg)
21 | 
22 | else:
23 |     from os import getuid
24 | 
25 | 
26 | class Unix(PlatformDirsABC):  # noqa: PLR0904
27 |     """
28 |     On Unix/Linux, we follow the `XDG Basedir Spec <https://specifications.freedesktop.org/basedir-spec/basedir-spec-
29 |     latest.html>`_.
30 | 
31 |     The spec allows overriding directories with environment variables. The examples shown are the default values,
32 |     alongside the name of the environment variable that overrides them. Makes use of the `appname
33 |     <platformdirs.api.PlatformDirsABC.appname>`, `version <platformdirs.api.PlatformDirsABC.version>`, `multipath
34 |     <platformdirs.api.PlatformDirsABC.multipath>`, `opinion <platformdirs.api.PlatformDirsABC.opinion>`, `ensure_exists
35 |     <platformdirs.api.PlatformDirsABC.ensure_exists>`.
36 | 
37 |     """
38 | 
39 |     @property
40 |     def user_data_dir(self) -> str:
41 |         """
42 |         :return: data directory tied to the user, e.g. ``~/.local/share/$appname/$version`` or
43 |          ``$XDG_DATA_HOME/$appname/$version``
44 |         """
45 |         path = os.environ.get("XDG_DATA_HOME", "")
46 |         if not path.strip():
47 |             path = os.path.expanduser("~/.local/share")  # noqa: PTH111
48 |         return self._append_app_name_and_version(path)
49 | 
50 |     @property
51 |     def _site_data_dirs(self) -> list[str]:
52 |         path = os.environ.get("XDG_DATA_DIRS", "")
53 |         if not path.strip():
54 |             path = f"/usr/local/share{os.pathsep}/usr/share"
55 |         return [self._append_app_name_and_version(p) for p in path.split(os.pathsep)]
56 | 
57 |     @property
58 |     def site_data_dir(self) -> str:
59 |         """
60 |         :return: data directories shared by users (if `multipath <platformdirs.api.PlatformDirsABC.multipath>` is
61 |          enabled and ``XDG_DATA_DIRS`` is set and a multi path the response is also a multi path separated by the
62 |          OS path separator), e.g. ``/usr/local/share/$appname/$version`` or ``/usr/share/$appname/$version``
63 |         """
64 |         # XDG default for $XDG_DATA_DIRS; only first, if multipath is False
65 |         dirs = self._site_data_dirs
66 |         if not self.multipath:
67 |             return dirs[0]
68 |         return os.pathsep.join(dirs)
69 | 
70 |     @property
71 |     def user_config_dir(self) -> str:
72 |         """
73 |         :return: config directory tied to the user, e.g. ``~/.config/$appname/$version`` or
74 |          ``$XDG_CONFIG_HOME/$appname/$version``
75 |         """
76 |         path = os.environ.get("XDG_CONFIG_HOME", "")
77 |         if not path.strip():
78 |             path = os.path.expanduser("~/.config")  # noqa: PTH111
79 |         return self._append_app_name_and_version(path)
80 | 
81 |     @property
82 |     def _site_config_dirs(self) -> list[str]:
83 |         path = os.environ.get("XDG_CONFIG_DIRS", "")
84 |         if not path.strip():
85 |             path = "/etc/xdg"
86 |         return [self._append_app_name_and_version(p) for p in path.split(os.pathsep)]
87 | 
88 |     @property
89 |     def site_config_dir(self) -> str:
90 |         """
91 |         :return: config directories shared by users (if `multipath <platformdirs.api.PlatformDirsABC.multipath>`
92 |          is enabled and ``XDG_CONFIG_DIRS`` is set and a multi path the response is also a multi path separated by
93 |          the OS path separator), e.g. ``/etc/xdg/$appname/$version``
94 |         """
95 |         # XDG default for $XDG_CONFIG_DIRS only first, if multipath is False
96 |         dirs = self._site_config_dirs
97 |         if not self.multipath:
98 |             return dirs[0]
99 |         return os.pathsep.join(dirs)
100 | 
101 |     @property
102 |     def user_cache_dir(self) -> str:
103 |         """
104 |         :return: cache directory tied to the user, e.g. ``~/.cache/$appname/$version`` or
105 |          ``~/$XDG_CACHE_HOME/$appname/$version``
106 |         """
107 |         path = os.environ.get("XDG_CACHE_HOME", "")
108 |         if not path.strip():
109 |             path = os.path.expanduser("~/.cache")  # noqa: PTH111
110 |         return self._append_app_name_and_version(path)
111 | 
112 |     @property
113 |     def site_cache_dir(self) -> str:
114 |         """:return: cache directory shared by users, e.g. ``/var/cache/$appname/$version``"""
115 |         return self._append_app_name_and_version("/var/cache")
116 | 
117 |     @property
118 |     def user_state_dir(self) -> str:
119 |         """
120 |         :return: state directory tied to the user, e.g. ``~/.local/state/$appname/$version`` or
121 |          ``$XDG_STATE_HOME/$appname/$version``
122 |         """
123 |         path = os.environ.get("XDG_STATE_HOME", "")
124 |         if not path.strip():
125 |             path = os.path.expanduser("~/.local/state")  # noqa: PTH111
126 |         return self._append_app_name_and_version(path)
127 | 
128 |     @property
129 |     def user_log_dir(self) -> str:
130 |         """:return: log directory tied to the user, same as `user_state_dir` if not opinionated else ``log`` in it"""
131 |         path = self.user_state_dir
132 |         if self.opinion:
133 |             path = os.path.join(path, "log")  # noqa: PTH118
134 |             self._optionally_create_directory(path)
135 |         return path
136 | 
137 |     @property
138 |     def user_documents_dir(self) -> str:
139 |         """:return: documents directory tied to the user, e.g. ``~/Documents``"""
140 |         return _get_user_media_dir("XDG_DOCUMENTS_DIR", "~/Documents")
141 | 
142 |     @property
143 |     def user_downloads_dir(self) -> str:
144 |         """:return: downloads directory tied to the user, e.g. ``~/Downloads``"""
145 |         return _get_user_media_dir("XDG_DOWNLOAD_DIR", "~/Downloads")
146 | 
147 |     @property
148 |     def user_pictures_dir(self) -> str:
149 |         """:return: pictures directory tied to the user, e.g. ``~/Pictures``"""
150 |         return _get_user_media_dir("XDG_PICTURES_DIR", "~/Pictures")
151 | 
152 |     @property
153 |     def user_videos_dir(self) -> str:
154 |         """:return: videos directory tied to the user, e.g. ``~/Videos``"""
155 |         return _get_user_media_dir("XDG_VIDEOS_DIR", "~/Videos")
156 | 
157 |     @property
158 |     def user_music_dir(self) -> str:
159 |         """:return: music directory tied to the user, e.g. ``~/Music``"""
160 |         return _get_user_media_dir("XDG_MUSIC_DIR", "~/Music")
161 | 
162 |     @property
163 |     def user_desktop_dir(self) -> str:
164 |         """:return: desktop directory tied to the user, e.g. ``~/Desktop``"""
165 |         return _get_user_media_dir("XDG_DESKTOP_DIR", "~/Desktop")
166 | 
167 |     @property
168 |     def user_runtime_dir(self) -> str:
169 |         """
170 |         :return: runtime directory tied to the user, e.g. ``/run/user/$(id -u)/$appname/$version`` or
171 |          ``$XDG_RUNTIME_DIR/$appname/$version``.
172 | 
173 |          For FreeBSD/OpenBSD/NetBSD, it would return ``/var/run/user/$(id -u)/$appname/$version`` if
174 |          exists, otherwise ``/tmp/runtime-$(id -u)/$appname/$version``, if``$XDG_RUNTIME_DIR``
175 |          is not set.
176 |         """
177 |         path = os.environ.get("XDG_RUNTIME_DIR", "")
178 |         if not path.strip():
179 |             if sys.platform.startswith(("freebsd", "openbsd", "netbsd")):
180 |                 path = f"/var/run/user/{getuid()}"
181 |                 if not Path(path).exists():
182 |                     path = f"/tmp/runtime-{getuid()}"  # noqa: S108
183 |             else:
184 |                 path = f"/run/user/{getuid()}"
185 |         return self._append_app_name_and_version(path)
186 | 
187 |     @property
188 |     def site_runtime_dir(self) -> str:
189 |         """
190 |         :return: runtime directory shared by users, e.g. ``/run/$appname/$version`` or \
191 |         ``$XDG_RUNTIME_DIR/$appname/$version``.
192 | 
193 |         Note that this behaves almost exactly like `user_runtime_dir` if ``$XDG_RUNTIME_DIR`` is set, but will
194 |         fall back to paths associated to the root user instead of a regular logged-in user if it's not set.
195 | 
196 |         If you wish to ensure that a logged-in root user path is returned e.g. ``/run/user/0``, use `user_runtime_dir`
197 |         instead.
198 | 
199 |         For FreeBSD/OpenBSD/NetBSD, it would return ``/var/run/$appname/$version`` if ``$XDG_RUNTIME_DIR`` is not set.
200 |         """
201 |         path = os.environ.get("XDG_RUNTIME_DIR", "")
202 |         if not path.strip():
203 |             if sys.platform.startswith(("freebsd", "openbsd", "netbsd")):
204 |                 path = "/var/run"
205 |             else:
206 |                 path = "/run"
207 |         return self._append_app_name_and_version(path)
208 | 
209 |     @property
210 |     def site_data_path(self) -> Path:
211 |         """:return: data path shared by users. Only return the first item, even if ``multipath`` is set to ``True``"""
212 |         return self._first_item_as_path_if_multipath(self.site_data_dir)
213 | 
214 |     @property
215 |     def site_config_path(self) -> Path:
216 |         """:return: config path shared by the users, returns the first item, even if ``multipath`` is set to ``True``"""
217 |         return self._first_item_as_path_if_multipath(self.site_config_dir)
218 | 
219 |     @property
220 |     def site_cache_path(self) -> Path:
221 |         """:return: cache path shared by users. Only return the first item, even if ``multipath`` is set to ``True``"""
222 |         return self._first_item_as_path_if_multipath(self.site_cache_dir)
223 | 
224 |     def iter_config_dirs(self) -> Iterator[str]:
225 |         """:yield: all user and site configuration directories."""
226 |         yield self.user_config_dir
227 |         yield from self._site_config_dirs
228 | 
229 |     def iter_data_dirs(self) -> Iterator[str]:
230 |         """:yield: all user and site data directories."""
231 |         yield self.user_data_dir
232 |         yield from self._site_data_dirs
233 | 
234 | 
235 | def _get_user_media_dir(env_var: str, fallback_tilde_path: str) -> str:
236 |     media_dir = _get_user_dirs_folder(env_var)
237 |     if media_dir is None:
238 |         media_dir = os.environ.get(env_var, "").strip()
239 |         if not media_dir:
240 |             media_dir = os.path.expanduser(fallback_tilde_path)  # noqa: PTH111
241 | 
242 |     return media_dir
243 | 
244 | 
245 | def _get_user_dirs_folder(key: str) -> str | None:
246 |     """
247 |     Return directory from user-dirs.dirs config file.
248 | 
249 |     See https://freedesktop.org/wiki/Software/xdg-user-dirs/.
250 | 
251 |     """
252 |     user_dirs_config_path = Path(Unix().user_config_dir) / "user-dirs.dirs"
253 |     if user_dirs_config_path.exists():
254 |         parser = ConfigParser()
255 | 
256 |         with user_dirs_config_path.open() as stream:
257 |             # Add fake section header, so ConfigParser doesn't complain
258 |             parser.read_string(f"[top]\n{stream.read()}")
259 | 
260 |         if key not in parser["top"]:
261 |             return None
262 | 
263 |         path = parser["top"][key].strip('"')
264 |         # Handle relative home paths
265 |         return path.replace("$HOME", os.path.expanduser("~"))  # noqa: PTH111
266 | 
267 |     return None
268 | 
269 | 
270 | __all__ = [
271 |     "Unix",
272 | ]
```

.venv/lib/python3.13/site-packages/pip/_vendor/platformdirs/version.py
```
1 | # file generated by setuptools-scm
2 | # don't change, don't track in version control
3 | 
4 | __all__ = ["__version__", "__version_tuple__", "version", "version_tuple"]
5 | 
6 | TYPE_CHECKING = False
7 | if TYPE_CHECKING:
8 |     from typing import Tuple
9 |     from typing import Union
10 | 
11 |     VERSION_TUPLE = Tuple[Union[int, str], ...]
12 | else:
13 |     VERSION_TUPLE = object
14 | 
15 | version: str
16 | __version__: str
17 | __version_tuple__: VERSION_TUPLE
18 | version_tuple: VERSION_TUPLE
19 | 
20 | __version__ = version = '4.3.7'
21 | __version_tuple__ = version_tuple = (4, 3, 7)
```

.venv/lib/python3.13/site-packages/pip/_vendor/platformdirs/windows.py
```
1 | """Windows."""
2 | 
3 | from __future__ import annotations
4 | 
5 | import os
6 | import sys
7 | from functools import lru_cache
8 | from typing import TYPE_CHECKING
9 | 
10 | from .api import PlatformDirsABC
11 | 
12 | if TYPE_CHECKING:
13 |     from collections.abc import Callable
14 | 
15 | 
16 | class Windows(PlatformDirsABC):
17 |     """
18 |     `MSDN on where to store app data files <https://learn.microsoft.com/en-us/windows/win32/shell/knownfolderid>`_.
19 | 
20 |     Makes use of the `appname <platformdirs.api.PlatformDirsABC.appname>`, `appauthor
21 |     <platformdirs.api.PlatformDirsABC.appauthor>`, `version <platformdirs.api.PlatformDirsABC.version>`, `roaming
22 |     <platformdirs.api.PlatformDirsABC.roaming>`, `opinion <platformdirs.api.PlatformDirsABC.opinion>`, `ensure_exists
23 |     <platformdirs.api.PlatformDirsABC.ensure_exists>`.
24 | 
25 |     """
26 | 
27 |     @property
28 |     def user_data_dir(self) -> str:
29 |         """
30 |         :return: data directory tied to the user, e.g.
31 |          ``%USERPROFILE%\\AppData\\Local\\$appauthor\\$appname`` (not roaming) or
32 |          ``%USERPROFILE%\\AppData\\Roaming\\$appauthor\\$appname`` (roaming)
33 |         """
34 |         const = "CSIDL_APPDATA" if self.roaming else "CSIDL_LOCAL_APPDATA"
35 |         path = os.path.normpath(get_win_folder(const))
36 |         return self._append_parts(path)
37 | 
38 |     def _append_parts(self, path: str, *, opinion_value: str | None = None) -> str:
39 |         params = []
40 |         if self.appname:
41 |             if self.appauthor is not False:
42 |                 author = self.appauthor or self.appname
43 |                 params.append(author)
44 |             params.append(self.appname)
45 |             if opinion_value is not None and self.opinion:
46 |                 params.append(opinion_value)
47 |             if self.version:
48 |                 params.append(self.version)
49 |         path = os.path.join(path, *params)  # noqa: PTH118
50 |         self._optionally_create_directory(path)
51 |         return path
52 | 
53 |     @property
54 |     def site_data_dir(self) -> str:
55 |         """:return: data directory shared by users, e.g. ``C:\\ProgramData\\$appauthor\\$appname``"""
56 |         path = os.path.normpath(get_win_folder("CSIDL_COMMON_APPDATA"))
57 |         return self._append_parts(path)
58 | 
59 |     @property
60 |     def user_config_dir(self) -> str:
61 |         """:return: config directory tied to the user, same as `user_data_dir`"""
62 |         return self.user_data_dir
63 | 
64 |     @property
65 |     def site_config_dir(self) -> str:
66 |         """:return: config directory shared by the users, same as `site_data_dir`"""
67 |         return self.site_data_dir
68 | 
69 |     @property
70 |     def user_cache_dir(self) -> str:
71 |         """
72 |         :return: cache directory tied to the user (if opinionated with ``Cache`` folder within ``$appname``) e.g.
73 |          ``%USERPROFILE%\\AppData\\Local\\$appauthor\\$appname\\Cache\\$version``
74 |         """
75 |         path = os.path.normpath(get_win_folder("CSIDL_LOCAL_APPDATA"))
76 |         return self._append_parts(path, opinion_value="Cache")
77 | 
78 |     @property
79 |     def site_cache_dir(self) -> str:
80 |         """:return: cache directory shared by users, e.g. ``C:\\ProgramData\\$appauthor\\$appname\\Cache\\$version``"""
81 |         path = os.path.normpath(get_win_folder("CSIDL_COMMON_APPDATA"))
82 |         return self._append_parts(path, opinion_value="Cache")
83 | 
84 |     @property
85 |     def user_state_dir(self) -> str:
86 |         """:return: state directory tied to the user, same as `user_data_dir`"""
87 |         return self.user_data_dir
88 | 
89 |     @property
90 |     def user_log_dir(self) -> str:
91 |         """:return: log directory tied to the user, same as `user_data_dir` if not opinionated else ``Logs`` in it"""
92 |         path = self.user_data_dir
93 |         if self.opinion:
94 |             path = os.path.join(path, "Logs")  # noqa: PTH118
95 |             self._optionally_create_directory(path)
96 |         return path
97 | 
98 |     @property
99 |     def user_documents_dir(self) -> str:
100 |         """:return: documents directory tied to the user e.g. ``%USERPROFILE%\\Documents``"""
101 |         return os.path.normpath(get_win_folder("CSIDL_PERSONAL"))
102 | 
103 |     @property
104 |     def user_downloads_dir(self) -> str:
105 |         """:return: downloads directory tied to the user e.g. ``%USERPROFILE%\\Downloads``"""
106 |         return os.path.normpath(get_win_folder("CSIDL_DOWNLOADS"))
107 | 
108 |     @property
109 |     def user_pictures_dir(self) -> str:
110 |         """:return: pictures directory tied to the user e.g. ``%USERPROFILE%\\Pictures``"""
111 |         return os.path.normpath(get_win_folder("CSIDL_MYPICTURES"))
112 | 
113 |     @property
114 |     def user_videos_dir(self) -> str:
115 |         """:return: videos directory tied to the user e.g. ``%USERPROFILE%\\Videos``"""
116 |         return os.path.normpath(get_win_folder("CSIDL_MYVIDEO"))
117 | 
118 |     @property
119 |     def user_music_dir(self) -> str:
120 |         """:return: music directory tied to the user e.g. ``%USERPROFILE%\\Music``"""
121 |         return os.path.normpath(get_win_folder("CSIDL_MYMUSIC"))
122 | 
123 |     @property
124 |     def user_desktop_dir(self) -> str:
125 |         """:return: desktop directory tied to the user, e.g. ``%USERPROFILE%\\Desktop``"""
126 |         return os.path.normpath(get_win_folder("CSIDL_DESKTOPDIRECTORY"))
127 | 
128 |     @property
129 |     def user_runtime_dir(self) -> str:
130 |         """
131 |         :return: runtime directory tied to the user, e.g.
132 |          ``%USERPROFILE%\\AppData\\Local\\Temp\\$appauthor\\$appname``
133 |         """
134 |         path = os.path.normpath(os.path.join(get_win_folder("CSIDL_LOCAL_APPDATA"), "Temp"))  # noqa: PTH118
135 |         return self._append_parts(path)
136 | 
137 |     @property
138 |     def site_runtime_dir(self) -> str:
139 |         """:return: runtime directory shared by users, same as `user_runtime_dir`"""
140 |         return self.user_runtime_dir
141 | 
142 | 
143 | def get_win_folder_from_env_vars(csidl_name: str) -> str:
144 |     """Get folder from environment variables."""
145 |     result = get_win_folder_if_csidl_name_not_env_var(csidl_name)
146 |     if result is not None:
147 |         return result
148 | 
149 |     env_var_name = {
150 |         "CSIDL_APPDATA": "APPDATA",
151 |         "CSIDL_COMMON_APPDATA": "ALLUSERSPROFILE",
152 |         "CSIDL_LOCAL_APPDATA": "LOCALAPPDATA",
153 |     }.get(csidl_name)
154 |     if env_var_name is None:
155 |         msg = f"Unknown CSIDL name: {csidl_name}"
156 |         raise ValueError(msg)
157 |     result = os.environ.get(env_var_name)
158 |     if result is None:
159 |         msg = f"Unset environment variable: {env_var_name}"
160 |         raise ValueError(msg)
161 |     return result
162 | 
163 | 
164 | def get_win_folder_if_csidl_name_not_env_var(csidl_name: str) -> str | None:
165 |     """Get a folder for a CSIDL name that does not exist as an environment variable."""
166 |     if csidl_name == "CSIDL_PERSONAL":
167 |         return os.path.join(os.path.normpath(os.environ["USERPROFILE"]), "Documents")  # noqa: PTH118
168 | 
169 |     if csidl_name == "CSIDL_DOWNLOADS":
170 |         return os.path.join(os.path.normpath(os.environ["USERPROFILE"]), "Downloads")  # noqa: PTH118
171 | 
172 |     if csidl_name == "CSIDL_MYPICTURES":
173 |         return os.path.join(os.path.normpath(os.environ["USERPROFILE"]), "Pictures")  # noqa: PTH118
174 | 
175 |     if csidl_name == "CSIDL_MYVIDEO":
176 |         return os.path.join(os.path.normpath(os.environ["USERPROFILE"]), "Videos")  # noqa: PTH118
177 | 
178 |     if csidl_name == "CSIDL_MYMUSIC":
179 |         return os.path.join(os.path.normpath(os.environ["USERPROFILE"]), "Music")  # noqa: PTH118
180 |     return None
181 | 
182 | 
183 | def get_win_folder_from_registry(csidl_name: str) -> str:
184 |     """
185 |     Get folder from the registry.
186 | 
187 |     This is a fallback technique at best. I'm not sure if using the registry for these guarantees us the correct answer
188 |     for all CSIDL_* names.
189 | 
190 |     """
191 |     shell_folder_name = {
192 |         "CSIDL_APPDATA": "AppData",
193 |         "CSIDL_COMMON_APPDATA": "Common AppData",
194 |         "CSIDL_LOCAL_APPDATA": "Local AppData",
195 |         "CSIDL_PERSONAL": "Personal",
196 |         "CSIDL_DOWNLOADS": "{374DE290-123F-4565-9164-39C4925E467B}",
197 |         "CSIDL_MYPICTURES": "My Pictures",
198 |         "CSIDL_MYVIDEO": "My Video",
199 |         "CSIDL_MYMUSIC": "My Music",
200 |     }.get(csidl_name)
201 |     if shell_folder_name is None:
202 |         msg = f"Unknown CSIDL name: {csidl_name}"
203 |         raise ValueError(msg)
204 |     if sys.platform != "win32":  # only needed for mypy type checker to know that this code runs only on Windows
205 |         raise NotImplementedError
206 |     import winreg  # noqa: PLC0415
207 | 
208 |     key = winreg.OpenKey(winreg.HKEY_CURRENT_USER, r"Software\Microsoft\Windows\CurrentVersion\Explorer\Shell Folders")
209 |     directory, _ = winreg.QueryValueEx(key, shell_folder_name)
210 |     return str(directory)
211 | 
212 | 
213 | def get_win_folder_via_ctypes(csidl_name: str) -> str:
214 |     """Get folder with ctypes."""
215 |     # There is no 'CSIDL_DOWNLOADS'.
216 |     # Use 'CSIDL_PROFILE' (40) and append the default folder 'Downloads' instead.
217 |     # https://learn.microsoft.com/en-us/windows/win32/shell/knownfolderid
218 | 
219 |     import ctypes  # noqa: PLC0415
220 | 
221 |     csidl_const = {
222 |         "CSIDL_APPDATA": 26,
223 |         "CSIDL_COMMON_APPDATA": 35,
224 |         "CSIDL_LOCAL_APPDATA": 28,
225 |         "CSIDL_PERSONAL": 5,
226 |         "CSIDL_MYPICTURES": 39,
227 |         "CSIDL_MYVIDEO": 14,
228 |         "CSIDL_MYMUSIC": 13,
229 |         "CSIDL_DOWNLOADS": 40,
230 |         "CSIDL_DESKTOPDIRECTORY": 16,
231 |     }.get(csidl_name)
232 |     if csidl_const is None:
233 |         msg = f"Unknown CSIDL name: {csidl_name}"
234 |         raise ValueError(msg)
235 | 
236 |     buf = ctypes.create_unicode_buffer(1024)
237 |     windll = getattr(ctypes, "windll")  # noqa: B009 # using getattr to avoid false positive with mypy type checker
238 |     windll.shell32.SHGetFolderPathW(None, csidl_const, None, 0, buf)
239 | 
240 |     # Downgrade to short path name if it has high-bit chars.
241 |     if any(ord(c) > 255 for c in buf):  # noqa: PLR2004
242 |         buf2 = ctypes.create_unicode_buffer(1024)
243 |         if windll.kernel32.GetShortPathNameW(buf.value, buf2, 1024):
244 |             buf = buf2
245 | 
246 |     if csidl_name == "CSIDL_DOWNLOADS":
247 |         return os.path.join(buf.value, "Downloads")  # noqa: PTH118
248 | 
249 |     return buf.value
250 | 
251 | 
252 | def _pick_get_win_folder() -> Callable[[str], str]:
253 |     try:
254 |         import ctypes  # noqa: PLC0415
255 |     except ImportError:
256 |         pass
257 |     else:
258 |         if hasattr(ctypes, "windll"):
259 |             return get_win_folder_via_ctypes
260 |     try:
261 |         import winreg  # noqa: PLC0415, F401
262 |     except ImportError:
263 |         return get_win_folder_from_env_vars
264 |     else:
265 |         return get_win_folder_from_registry
266 | 
267 | 
268 | get_win_folder = lru_cache(maxsize=None)(_pick_get_win_folder())
269 | 
270 | __all__ = [
271 |     "Windows",
272 | ]
```

.venv/lib/python3.13/site-packages/pip/_vendor/packaging/__init__.py
```
1 | # This file is dual licensed under the terms of the Apache License, Version
2 | # 2.0, and the BSD License. See the LICENSE file in the root of this repository
3 | # for complete details.
4 | 
5 | __title__ = "packaging"
6 | __summary__ = "Core utilities for Python packages"
7 | __uri__ = "https://github.com/pypa/packaging"
8 | 
9 | __version__ = "25.0"
10 | 
11 | __author__ = "Donald Stufft and individual contributors"
12 | __email__ = "donald@stufft.io"
13 | 
14 | __license__ = "BSD-2-Clause or Apache-2.0"
15 | __copyright__ = f"2014 {__author__}"
```

.venv/lib/python3.13/site-packages/pip/_vendor/packaging/_elffile.py
```
1 | """
2 | ELF file parser.
3 | 
4 | This provides a class ``ELFFile`` that parses an ELF executable in a similar
5 | interface to ``ZipFile``. Only the read interface is implemented.
6 | 
7 | Based on: https://gist.github.com/lyssdod/f51579ae8d93c8657a5564aefc2ffbca
8 | ELF header: https://refspecs.linuxfoundation.org/elf/gabi4+/ch4.eheader.html
9 | """
10 | 
11 | from __future__ import annotations
12 | 
13 | import enum
14 | import os
15 | import struct
16 | from typing import IO
17 | 
18 | 
19 | class ELFInvalid(ValueError):
20 |     pass
21 | 
22 | 
23 | class EIClass(enum.IntEnum):
24 |     C32 = 1
25 |     C64 = 2
26 | 
27 | 
28 | class EIData(enum.IntEnum):
29 |     Lsb = 1
30 |     Msb = 2
31 | 
32 | 
33 | class EMachine(enum.IntEnum):
34 |     I386 = 3
35 |     S390 = 22
36 |     Arm = 40
37 |     X8664 = 62
38 |     AArc64 = 183
39 | 
40 | 
41 | class ELFFile:
42 |     """
43 |     Representation of an ELF executable.
44 |     """
45 | 
46 |     def __init__(self, f: IO[bytes]) -> None:
47 |         self._f = f
48 | 
49 |         try:
50 |             ident = self._read("16B")
51 |         except struct.error as e:
52 |             raise ELFInvalid("unable to parse identification") from e
53 |         magic = bytes(ident[:4])
54 |         if magic != b"\x7fELF":
55 |             raise ELFInvalid(f"invalid magic: {magic!r}")
56 | 
57 |         self.capacity = ident[4]  # Format for program header (bitness).
58 |         self.encoding = ident[5]  # Data structure encoding (endianness).
59 | 
60 |         try:
61 |             # e_fmt: Format for program header.
62 |             # p_fmt: Format for section header.
63 |             # p_idx: Indexes to find p_type, p_offset, and p_filesz.
64 |             e_fmt, self._p_fmt, self._p_idx = {
65 |                 (1, 1): ("<HHIIIIIHHH", "<IIIIIIII", (0, 1, 4)),  # 32-bit LSB.
66 |                 (1, 2): (">HHIIIIIHHH", ">IIIIIIII", (0, 1, 4)),  # 32-bit MSB.
67 |                 (2, 1): ("<HHIQQQIHHH", "<IIQQQQQQ", (0, 2, 5)),  # 64-bit LSB.
68 |                 (2, 2): (">HHIQQQIHHH", ">IIQQQQQQ", (0, 2, 5)),  # 64-bit MSB.
69 |             }[(self.capacity, self.encoding)]
70 |         except KeyError as e:
71 |             raise ELFInvalid(
72 |                 f"unrecognized capacity ({self.capacity}) or encoding ({self.encoding})"
73 |             ) from e
74 | 
75 |         try:
76 |             (
77 |                 _,
78 |                 self.machine,  # Architecture type.
79 |                 _,
80 |                 _,
81 |                 self._e_phoff,  # Offset of program header.
82 |                 _,
83 |                 self.flags,  # Processor-specific flags.
84 |                 _,
85 |                 self._e_phentsize,  # Size of section.
86 |                 self._e_phnum,  # Number of sections.
87 |             ) = self._read(e_fmt)
88 |         except struct.error as e:
89 |             raise ELFInvalid("unable to parse machine and section information") from e
90 | 
91 |     def _read(self, fmt: str) -> tuple[int, ...]:
92 |         return struct.unpack(fmt, self._f.read(struct.calcsize(fmt)))
93 | 
94 |     @property
95 |     def interpreter(self) -> str | None:
96 |         """
97 |         The path recorded in the ``PT_INTERP`` section header.
98 |         """
99 |         for index in range(self._e_phnum):
100 |             self._f.seek(self._e_phoff + self._e_phentsize * index)
101 |             try:
102 |                 data = self._read(self._p_fmt)
103 |             except struct.error:
104 |                 continue
105 |             if data[self._p_idx[0]] != 3:  # Not PT_INTERP.
106 |                 continue
107 |             self._f.seek(data[self._p_idx[1]])
108 |             return os.fsdecode(self._f.read(data[self._p_idx[2]])).strip("\0")
109 |         return None
```

.venv/lib/python3.13/site-packages/pip/_vendor/packaging/_manylinux.py
```
1 | from __future__ import annotations
2 | 
3 | import collections
4 | import contextlib
5 | import functools
6 | import os
7 | import re
8 | import sys
9 | import warnings
10 | from typing import Generator, Iterator, NamedTuple, Sequence
11 | 
12 | from ._elffile import EIClass, EIData, ELFFile, EMachine
13 | 
14 | EF_ARM_ABIMASK = 0xFF000000
15 | EF_ARM_ABI_VER5 = 0x05000000
16 | EF_ARM_ABI_FLOAT_HARD = 0x00000400
17 | 
18 | 
19 | # `os.PathLike` not a generic type until Python 3.9, so sticking with `str`
20 | # as the type for `path` until then.
21 | @contextlib.contextmanager
22 | def _parse_elf(path: str) -> Generator[ELFFile | None, None, None]:
23 |     try:
24 |         with open(path, "rb") as f:
25 |             yield ELFFile(f)
26 |     except (OSError, TypeError, ValueError):
27 |         yield None
28 | 
29 | 
30 | def _is_linux_armhf(executable: str) -> bool:
31 |     # hard-float ABI can be detected from the ELF header of the running
32 |     # process
33 |     # https://static.docs.arm.com/ihi0044/g/aaelf32.pdf
34 |     with _parse_elf(executable) as f:
35 |         return (
36 |             f is not None
37 |             and f.capacity == EIClass.C32
38 |             and f.encoding == EIData.Lsb
39 |             and f.machine == EMachine.Arm
40 |             and f.flags & EF_ARM_ABIMASK == EF_ARM_ABI_VER5
41 |             and f.flags & EF_ARM_ABI_FLOAT_HARD == EF_ARM_ABI_FLOAT_HARD
42 |         )
43 | 
44 | 
45 | def _is_linux_i686(executable: str) -> bool:
46 |     with _parse_elf(executable) as f:
47 |         return (
48 |             f is not None
49 |             and f.capacity == EIClass.C32
50 |             and f.encoding == EIData.Lsb
51 |             and f.machine == EMachine.I386
52 |         )
53 | 
54 | 
55 | def _have_compatible_abi(executable: str, archs: Sequence[str]) -> bool:
56 |     if "armv7l" in archs:
57 |         return _is_linux_armhf(executable)
58 |     if "i686" in archs:
59 |         return _is_linux_i686(executable)
60 |     allowed_archs = {
61 |         "x86_64",
62 |         "aarch64",
63 |         "ppc64",
64 |         "ppc64le",
65 |         "s390x",
66 |         "loongarch64",
67 |         "riscv64",
68 |     }
69 |     return any(arch in allowed_archs for arch in archs)
70 | 
71 | 
72 | # If glibc ever changes its major version, we need to know what the last
73 | # minor version was, so we can build the complete list of all versions.
74 | # For now, guess what the highest minor version might be, assume it will
75 | # be 50 for testing. Once this actually happens, update the dictionary
76 | # with the actual value.
77 | _LAST_GLIBC_MINOR: dict[int, int] = collections.defaultdict(lambda: 50)
78 | 
79 | 
80 | class _GLibCVersion(NamedTuple):
81 |     major: int
82 |     minor: int
83 | 
84 | 
85 | def _glibc_version_string_confstr() -> str | None:
86 |     """
87 |     Primary implementation of glibc_version_string using os.confstr.
88 |     """
89 |     # os.confstr is quite a bit faster than ctypes.DLL. It's also less likely
90 |     # to be broken or missing. This strategy is used in the standard library
91 |     # platform module.
92 |     # https://github.com/python/cpython/blob/fcf1d003bf4f0100c/Lib/platform.py#L175-L183
93 |     try:
94 |         # Should be a string like "glibc 2.17".
95 |         version_string: str | None = os.confstr("CS_GNU_LIBC_VERSION")
96 |         assert version_string is not None
97 |         _, version = version_string.rsplit()
98 |     except (AssertionError, AttributeError, OSError, ValueError):
99 |         # os.confstr() or CS_GNU_LIBC_VERSION not available (or a bad value)...
100 |         return None
101 |     return version
102 | 
103 | 
104 | def _glibc_version_string_ctypes() -> str | None:
105 |     """
106 |     Fallback implementation of glibc_version_string using ctypes.
107 |     """
108 |     try:
109 |         import ctypes
110 |     except ImportError:
111 |         return None
112 | 
113 |     # ctypes.CDLL(None) internally calls dlopen(NULL), and as the dlopen
114 |     # manpage says, "If filename is NULL, then the returned handle is for the
115 |     # main program". This way we can let the linker do the work to figure out
116 |     # which libc our process is actually using.
117 |     #
118 |     # We must also handle the special case where the executable is not a
119 |     # dynamically linked executable. This can occur when using musl libc,
120 |     # for example. In this situation, dlopen() will error, leading to an
121 |     # OSError. Interestingly, at least in the case of musl, there is no
122 |     # errno set on the OSError. The single string argument used to construct
123 |     # OSError comes from libc itself and is therefore not portable to
124 |     # hard code here. In any case, failure to call dlopen() means we
125 |     # can proceed, so we bail on our attempt.
126 |     try:
127 |         process_namespace = ctypes.CDLL(None)
128 |     except OSError:
129 |         return None
130 | 
131 |     try:
132 |         gnu_get_libc_version = process_namespace.gnu_get_libc_version
133 |     except AttributeError:
134 |         # Symbol doesn't exist -> therefore, we are not linked to
135 |         # glibc.
136 |         return None
137 | 
138 |     # Call gnu_get_libc_version, which returns a string like "2.5"
139 |     gnu_get_libc_version.restype = ctypes.c_char_p
140 |     version_str: str = gnu_get_libc_version()
141 |     # py2 / py3 compatibility:
142 |     if not isinstance(version_str, str):
143 |         version_str = version_str.decode("ascii")
144 | 
145 |     return version_str
146 | 
147 | 
148 | def _glibc_version_string() -> str | None:
149 |     """Returns glibc version string, or None if not using glibc."""
150 |     return _glibc_version_string_confstr() or _glibc_version_string_ctypes()
151 | 
152 | 
153 | def _parse_glibc_version(version_str: str) -> tuple[int, int]:
154 |     """Parse glibc version.
155 | 
156 |     We use a regexp instead of str.split because we want to discard any
157 |     random junk that might come after the minor version -- this might happen
158 |     in patched/forked versions of glibc (e.g. Linaro's version of glibc
159 |     uses version strings like "2.20-2014.11"). See gh-3588.
160 |     """
161 |     m = re.match(r"(?P<major>[0-9]+)\.(?P<minor>[0-9]+)", version_str)
162 |     if not m:
163 |         warnings.warn(
164 |             f"Expected glibc version with 2 components major.minor, got: {version_str}",
165 |             RuntimeWarning,
166 |             stacklevel=2,
167 |         )
168 |         return -1, -1
169 |     return int(m.group("major")), int(m.group("minor"))
170 | 
171 | 
172 | @functools.lru_cache
173 | def _get_glibc_version() -> tuple[int, int]:
174 |     version_str = _glibc_version_string()
175 |     if version_str is None:
176 |         return (-1, -1)
177 |     return _parse_glibc_version(version_str)
178 | 
179 | 
180 | # From PEP 513, PEP 600
181 | def _is_compatible(arch: str, version: _GLibCVersion) -> bool:
182 |     sys_glibc = _get_glibc_version()
183 |     if sys_glibc < version:
184 |         return False
185 |     # Check for presence of _manylinux module.
186 |     try:
187 |         import _manylinux
188 |     except ImportError:
189 |         return True
190 |     if hasattr(_manylinux, "manylinux_compatible"):
191 |         result = _manylinux.manylinux_compatible(version[0], version[1], arch)
192 |         if result is not None:
193 |             return bool(result)
194 |         return True
195 |     if version == _GLibCVersion(2, 5):
196 |         if hasattr(_manylinux, "manylinux1_compatible"):
197 |             return bool(_manylinux.manylinux1_compatible)
198 |     if version == _GLibCVersion(2, 12):
199 |         if hasattr(_manylinux, "manylinux2010_compatible"):
200 |             return bool(_manylinux.manylinux2010_compatible)
201 |     if version == _GLibCVersion(2, 17):
202 |         if hasattr(_manylinux, "manylinux2014_compatible"):
203 |             return bool(_manylinux.manylinux2014_compatible)
204 |     return True
205 | 
206 | 
207 | _LEGACY_MANYLINUX_MAP = {
208 |     # CentOS 7 w/ glibc 2.17 (PEP 599)
209 |     (2, 17): "manylinux2014",
210 |     # CentOS 6 w/ glibc 2.12 (PEP 571)
211 |     (2, 12): "manylinux2010",
212 |     # CentOS 5 w/ glibc 2.5 (PEP 513)
213 |     (2, 5): "manylinux1",
214 | }
215 | 
216 | 
217 | def platform_tags(archs: Sequence[str]) -> Iterator[str]:
218 |     """Generate manylinux tags compatible to the current platform.
219 | 
220 |     :param archs: Sequence of compatible architectures.
221 |         The first one shall be the closest to the actual architecture and be the part of
222 |         platform tag after the ``linux_`` prefix, e.g. ``x86_64``.
223 |         The ``linux_`` prefix is assumed as a prerequisite for the current platform to
224 |         be manylinux-compatible.
225 | 
226 |     :returns: An iterator of compatible manylinux tags.
227 |     """
228 |     if not _have_compatible_abi(sys.executable, archs):
229 |         return
230 |     # Oldest glibc to be supported regardless of architecture is (2, 17).
231 |     too_old_glibc2 = _GLibCVersion(2, 16)
232 |     if set(archs) & {"x86_64", "i686"}:
233 |         # On x86/i686 also oldest glibc to be supported is (2, 5).
234 |         too_old_glibc2 = _GLibCVersion(2, 4)
235 |     current_glibc = _GLibCVersion(*_get_glibc_version())
236 |     glibc_max_list = [current_glibc]
237 |     # We can assume compatibility across glibc major versions.
238 |     # https://sourceware.org/bugzilla/show_bug.cgi?id=24636
239 |     #
240 |     # Build a list of maximum glibc versions so that we can
241 |     # output the canonical list of all glibc from current_glibc
242 |     # down to too_old_glibc2, including all intermediary versions.
243 |     for glibc_major in range(current_glibc.major - 1, 1, -1):
244 |         glibc_minor = _LAST_GLIBC_MINOR[glibc_major]
245 |         glibc_max_list.append(_GLibCVersion(glibc_major, glibc_minor))
246 |     for arch in archs:
247 |         for glibc_max in glibc_max_list:
248 |             if glibc_max.major == too_old_glibc2.major:
249 |                 min_minor = too_old_glibc2.minor
250 |             else:
251 |                 # For other glibc major versions oldest supported is (x, 0).
252 |                 min_minor = -1
253 |             for glibc_minor in range(glibc_max.minor, min_minor, -1):
254 |                 glibc_version = _GLibCVersion(glibc_max.major, glibc_minor)
255 |                 tag = "manylinux_{}_{}".format(*glibc_version)
256 |                 if _is_compatible(arch, glibc_version):
257 |                     yield f"{tag}_{arch}"
258 |                 # Handle the legacy manylinux1, manylinux2010, manylinux2014 tags.
259 |                 if glibc_version in _LEGACY_MANYLINUX_MAP:
260 |                     legacy_tag = _LEGACY_MANYLINUX_MAP[glibc_version]
261 |                     if _is_compatible(arch, glibc_version):
262 |                         yield f"{legacy_tag}_{arch}"
```

.venv/lib/python3.13/site-packages/pip/_vendor/packaging/_musllinux.py
```
1 | """PEP 656 support.
2 | 
3 | This module implements logic to detect if the currently running Python is
4 | linked against musl, and what musl version is used.
5 | """
6 | 
7 | from __future__ import annotations
8 | 
9 | import functools
10 | import re
11 | import subprocess
12 | import sys
13 | from typing import Iterator, NamedTuple, Sequence
14 | 
15 | from ._elffile import ELFFile
16 | 
17 | 
18 | class _MuslVersion(NamedTuple):
19 |     major: int
20 |     minor: int
21 | 
22 | 
23 | def _parse_musl_version(output: str) -> _MuslVersion | None:
24 |     lines = [n for n in (n.strip() for n in output.splitlines()) if n]
25 |     if len(lines) < 2 or lines[0][:4] != "musl":
26 |         return None
27 |     m = re.match(r"Version (\d+)\.(\d+)", lines[1])
28 |     if not m:
29 |         return None
30 |     return _MuslVersion(major=int(m.group(1)), minor=int(m.group(2)))
31 | 
32 | 
33 | @functools.lru_cache
34 | def _get_musl_version(executable: str) -> _MuslVersion | None:
35 |     """Detect currently-running musl runtime version.
36 | 
37 |     This is done by checking the specified executable's dynamic linking
38 |     information, and invoking the loader to parse its output for a version
39 |     string. If the loader is musl, the output would be something like::
40 | 
41 |         musl libc (x86_64)
42 |         Version 1.2.2
43 |         Dynamic Program Loader
44 |     """
45 |     try:
46 |         with open(executable, "rb") as f:
47 |             ld = ELFFile(f).interpreter
48 |     except (OSError, TypeError, ValueError):
49 |         return None
50 |     if ld is None or "musl" not in ld:
51 |         return None
52 |     proc = subprocess.run([ld], stderr=subprocess.PIPE, text=True)
53 |     return _parse_musl_version(proc.stderr)
54 | 
55 | 
56 | def platform_tags(archs: Sequence[str]) -> Iterator[str]:
57 |     """Generate musllinux tags compatible to the current platform.
58 | 
59 |     :param archs: Sequence of compatible architectures.
60 |         The first one shall be the closest to the actual architecture and be the part of
61 |         platform tag after the ``linux_`` prefix, e.g. ``x86_64``.
62 |         The ``linux_`` prefix is assumed as a prerequisite for the current platform to
63 |         be musllinux-compatible.
64 | 
65 |     :returns: An iterator of compatible musllinux tags.
66 |     """
67 |     sys_musl = _get_musl_version(sys.executable)
68 |     if sys_musl is None:  # Python not dynamically linked against musl.
69 |         return
70 |     for arch in archs:
71 |         for minor in range(sys_musl.minor, -1, -1):
72 |             yield f"musllinux_{sys_musl.major}_{minor}_{arch}"
73 | 
74 | 
75 | if __name__ == "__main__":  # pragma: no cover
76 |     import sysconfig
77 | 
78 |     plat = sysconfig.get_platform()
79 |     assert plat.startswith("linux-"), "not linux"
80 | 
81 |     print("plat:", plat)
82 |     print("musl:", _get_musl_version(sys.executable))
83 |     print("tags:", end=" ")
84 |     for t in platform_tags(re.sub(r"[.-]", "_", plat.split("-", 1)[-1])):
85 |         print(t, end="\n      ")
```

.venv/lib/python3.13/site-packages/pip/_vendor/packaging/_parser.py
```
1 | """Handwritten parser of dependency specifiers.
2 | 
3 | The docstring for each __parse_* function contains EBNF-inspired grammar representing
4 | the implementation.
5 | """
6 | 
7 | from __future__ import annotations
8 | 
9 | import ast
10 | from typing import NamedTuple, Sequence, Tuple, Union
11 | 
12 | from ._tokenizer import DEFAULT_RULES, Tokenizer
13 | 
14 | 
15 | class Node:
16 |     def __init__(self, value: str) -> None:
17 |         self.value = value
18 | 
19 |     def __str__(self) -> str:
20 |         return self.value
21 | 
22 |     def __repr__(self) -> str:
23 |         return f"<{self.__class__.__name__}('{self}')>"
24 | 
25 |     def serialize(self) -> str:
26 |         raise NotImplementedError
27 | 
28 | 
29 | class Variable(Node):
30 |     def serialize(self) -> str:
31 |         return str(self)
32 | 
33 | 
34 | class Value(Node):
35 |     def serialize(self) -> str:
36 |         return f'"{self}"'
37 | 
38 | 
39 | class Op(Node):
40 |     def serialize(self) -> str:
41 |         return str(self)
42 | 
43 | 
44 | MarkerVar = Union[Variable, Value]
45 | MarkerItem = Tuple[MarkerVar, Op, MarkerVar]
46 | MarkerAtom = Union[MarkerItem, Sequence["MarkerAtom"]]
47 | MarkerList = Sequence[Union["MarkerList", MarkerAtom, str]]
48 | 
49 | 
50 | class ParsedRequirement(NamedTuple):
51 |     name: str
52 |     url: str
53 |     extras: list[str]
54 |     specifier: str
55 |     marker: MarkerList | None
56 | 
57 | 
58 | # --------------------------------------------------------------------------------------
59 | # Recursive descent parser for dependency specifier
60 | # --------------------------------------------------------------------------------------
61 | def parse_requirement(source: str) -> ParsedRequirement:
62 |     return _parse_requirement(Tokenizer(source, rules=DEFAULT_RULES))
63 | 
64 | 
65 | def _parse_requirement(tokenizer: Tokenizer) -> ParsedRequirement:
66 |     """
67 |     requirement = WS? IDENTIFIER WS? extras WS? requirement_details
68 |     """
69 |     tokenizer.consume("WS")
70 | 
71 |     name_token = tokenizer.expect(
72 |         "IDENTIFIER", expected="package name at the start of dependency specifier"
73 |     )
74 |     name = name_token.text
75 |     tokenizer.consume("WS")
76 | 
77 |     extras = _parse_extras(tokenizer)
78 |     tokenizer.consume("WS")
79 | 
80 |     url, specifier, marker = _parse_requirement_details(tokenizer)
81 |     tokenizer.expect("END", expected="end of dependency specifier")
82 | 
83 |     return ParsedRequirement(name, url, extras, specifier, marker)
84 | 
85 | 
86 | def _parse_requirement_details(
87 |     tokenizer: Tokenizer,
88 | ) -> tuple[str, str, MarkerList | None]:
89 |     """
90 |     requirement_details = AT URL (WS requirement_marker?)?
91 |                         | specifier WS? (requirement_marker)?
92 |     """
93 | 
94 |     specifier = ""
95 |     url = ""
96 |     marker = None
97 | 
98 |     if tokenizer.check("AT"):
99 |         tokenizer.read()
100 |         tokenizer.consume("WS")
101 | 
102 |         url_start = tokenizer.position
103 |         url = tokenizer.expect("URL", expected="URL after @").text
104 |         if tokenizer.check("END", peek=True):
105 |             return (url, specifier, marker)
106 | 
107 |         tokenizer.expect("WS", expected="whitespace after URL")
108 | 
109 |         # The input might end after whitespace.
110 |         if tokenizer.check("END", peek=True):
111 |             return (url, specifier, marker)
112 | 
113 |         marker = _parse_requirement_marker(
114 |             tokenizer, span_start=url_start, after="URL and whitespace"
115 |         )
116 |     else:
117 |         specifier_start = tokenizer.position
118 |         specifier = _parse_specifier(tokenizer)
119 |         tokenizer.consume("WS")
120 | 
121 |         if tokenizer.check("END", peek=True):
122 |             return (url, specifier, marker)
123 | 
124 |         marker = _parse_requirement_marker(
125 |             tokenizer,
126 |             span_start=specifier_start,
127 |             after=(
128 |                 "version specifier"
129 |                 if specifier
130 |                 else "name and no valid version specifier"
131 |             ),
132 |         )
133 | 
134 |     return (url, specifier, marker)
135 | 
136 | 
137 | def _parse_requirement_marker(
138 |     tokenizer: Tokenizer, *, span_start: int, after: str
139 | ) -> MarkerList:
140 |     """
141 |     requirement_marker = SEMICOLON marker WS?
142 |     """
143 | 
144 |     if not tokenizer.check("SEMICOLON"):
145 |         tokenizer.raise_syntax_error(
146 |             f"Expected end or semicolon (after {after})",
147 |             span_start=span_start,
148 |         )
149 |     tokenizer.read()
150 | 
151 |     marker = _parse_marker(tokenizer)
152 |     tokenizer.consume("WS")
153 | 
154 |     return marker
155 | 
156 | 
157 | def _parse_extras(tokenizer: Tokenizer) -> list[str]:
158 |     """
159 |     extras = (LEFT_BRACKET wsp* extras_list? wsp* RIGHT_BRACKET)?
160 |     """
161 |     if not tokenizer.check("LEFT_BRACKET", peek=True):
162 |         return []
163 | 
164 |     with tokenizer.enclosing_tokens(
165 |         "LEFT_BRACKET",
166 |         "RIGHT_BRACKET",
167 |         around="extras",
168 |     ):
169 |         tokenizer.consume("WS")
170 |         extras = _parse_extras_list(tokenizer)
171 |         tokenizer.consume("WS")
172 | 
173 |     return extras
174 | 
175 | 
176 | def _parse_extras_list(tokenizer: Tokenizer) -> list[str]:
177 |     """
178 |     extras_list = identifier (wsp* ',' wsp* identifier)*
179 |     """
180 |     extras: list[str] = []
181 | 
182 |     if not tokenizer.check("IDENTIFIER"):
183 |         return extras
184 | 
185 |     extras.append(tokenizer.read().text)
186 | 
187 |     while True:
188 |         tokenizer.consume("WS")
189 |         if tokenizer.check("IDENTIFIER", peek=True):
190 |             tokenizer.raise_syntax_error("Expected comma between extra names")
191 |         elif not tokenizer.check("COMMA"):
192 |             break
193 | 
194 |         tokenizer.read()
195 |         tokenizer.consume("WS")
196 | 
197 |         extra_token = tokenizer.expect("IDENTIFIER", expected="extra name after comma")
198 |         extras.append(extra_token.text)
199 | 
200 |     return extras
201 | 
202 | 
203 | def _parse_specifier(tokenizer: Tokenizer) -> str:
204 |     """
205 |     specifier = LEFT_PARENTHESIS WS? version_many WS? RIGHT_PARENTHESIS
206 |               | WS? version_many WS?
207 |     """
208 |     with tokenizer.enclosing_tokens(
209 |         "LEFT_PARENTHESIS",
210 |         "RIGHT_PARENTHESIS",
211 |         around="version specifier",
212 |     ):
213 |         tokenizer.consume("WS")
214 |         parsed_specifiers = _parse_version_many(tokenizer)
215 |         tokenizer.consume("WS")
216 | 
217 |     return parsed_specifiers
218 | 
219 | 
220 | def _parse_version_many(tokenizer: Tokenizer) -> str:
221 |     """
222 |     version_many = (SPECIFIER (WS? COMMA WS? SPECIFIER)*)?
223 |     """
224 |     parsed_specifiers = ""
225 |     while tokenizer.check("SPECIFIER"):
226 |         span_start = tokenizer.position
227 |         parsed_specifiers += tokenizer.read().text
228 |         if tokenizer.check("VERSION_PREFIX_TRAIL", peek=True):
229 |             tokenizer.raise_syntax_error(
230 |                 ".* suffix can only be used with `==` or `!=` operators",
231 |                 span_start=span_start,
232 |                 span_end=tokenizer.position + 1,
233 |             )
234 |         if tokenizer.check("VERSION_LOCAL_LABEL_TRAIL", peek=True):
235 |             tokenizer.raise_syntax_error(
236 |                 "Local version label can only be used with `==` or `!=` operators",
237 |                 span_start=span_start,
238 |                 span_end=tokenizer.position,
239 |             )
240 |         tokenizer.consume("WS")
241 |         if not tokenizer.check("COMMA"):
242 |             break
243 |         parsed_specifiers += tokenizer.read().text
244 |         tokenizer.consume("WS")
245 | 
246 |     return parsed_specifiers
247 | 
248 | 
249 | # --------------------------------------------------------------------------------------
250 | # Recursive descent parser for marker expression
251 | # --------------------------------------------------------------------------------------
252 | def parse_marker(source: str) -> MarkerList:
253 |     return _parse_full_marker(Tokenizer(source, rules=DEFAULT_RULES))
254 | 
255 | 
256 | def _parse_full_marker(tokenizer: Tokenizer) -> MarkerList:
257 |     retval = _parse_marker(tokenizer)
258 |     tokenizer.expect("END", expected="end of marker expression")
259 |     return retval
260 | 
261 | 
262 | def _parse_marker(tokenizer: Tokenizer) -> MarkerList:
263 |     """
264 |     marker = marker_atom (BOOLOP marker_atom)+
265 |     """
266 |     expression = [_parse_marker_atom(tokenizer)]
267 |     while tokenizer.check("BOOLOP"):
268 |         token = tokenizer.read()
269 |         expr_right = _parse_marker_atom(tokenizer)
270 |         expression.extend((token.text, expr_right))
271 |     return expression
272 | 
273 | 
274 | def _parse_marker_atom(tokenizer: Tokenizer) -> MarkerAtom:
275 |     """
276 |     marker_atom = WS? LEFT_PARENTHESIS WS? marker WS? RIGHT_PARENTHESIS WS?
277 |                 | WS? marker_item WS?
278 |     """
279 | 
280 |     tokenizer.consume("WS")
281 |     if tokenizer.check("LEFT_PARENTHESIS", peek=True):
282 |         with tokenizer.enclosing_tokens(
283 |             "LEFT_PARENTHESIS",
284 |             "RIGHT_PARENTHESIS",
285 |             around="marker expression",
286 |         ):
287 |             tokenizer.consume("WS")
288 |             marker: MarkerAtom = _parse_marker(tokenizer)
289 |             tokenizer.consume("WS")
290 |     else:
291 |         marker = _parse_marker_item(tokenizer)
292 |     tokenizer.consume("WS")
293 |     return marker
294 | 
295 | 
296 | def _parse_marker_item(tokenizer: Tokenizer) -> MarkerItem:
297 |     """
298 |     marker_item = WS? marker_var WS? marker_op WS? marker_var WS?
299 |     """
300 |     tokenizer.consume("WS")
301 |     marker_var_left = _parse_marker_var(tokenizer)
302 |     tokenizer.consume("WS")
303 |     marker_op = _parse_marker_op(tokenizer)
304 |     tokenizer.consume("WS")
305 |     marker_var_right = _parse_marker_var(tokenizer)
306 |     tokenizer.consume("WS")
307 |     return (marker_var_left, marker_op, marker_var_right)
308 | 
309 | 
310 | def _parse_marker_var(tokenizer: Tokenizer) -> MarkerVar:
311 |     """
312 |     marker_var = VARIABLE | QUOTED_STRING
313 |     """
314 |     if tokenizer.check("VARIABLE"):
315 |         return process_env_var(tokenizer.read().text.replace(".", "_"))
316 |     elif tokenizer.check("QUOTED_STRING"):
317 |         return process_python_str(tokenizer.read().text)
318 |     else:
319 |         tokenizer.raise_syntax_error(
320 |             message="Expected a marker variable or quoted string"
321 |         )
322 | 
323 | 
324 | def process_env_var(env_var: str) -> Variable:
325 |     if env_var in ("platform_python_implementation", "python_implementation"):
326 |         return Variable("platform_python_implementation")
327 |     else:
328 |         return Variable(env_var)
329 | 
330 | 
331 | def process_python_str(python_str: str) -> Value:
332 |     value = ast.literal_eval(python_str)
333 |     return Value(str(value))
334 | 
335 | 
336 | def _parse_marker_op(tokenizer: Tokenizer) -> Op:
337 |     """
338 |     marker_op = IN | NOT IN | OP
339 |     """
340 |     if tokenizer.check("IN"):
341 |         tokenizer.read()
342 |         return Op("in")
343 |     elif tokenizer.check("NOT"):
344 |         tokenizer.read()
345 |         tokenizer.expect("WS", expected="whitespace after 'not'")
346 |         tokenizer.expect("IN", expected="'in' after 'not'")
347 |         return Op("not in")
348 |     elif tokenizer.check("OP"):
349 |         return Op(tokenizer.read().text)
350 |     else:
351 |         return tokenizer.raise_syntax_error(
352 |             "Expected marker operator, one of <=, <, !=, ==, >=, >, ~=, ===, in, not in"
353 |         )
```

.venv/lib/python3.13/site-packages/pip/_vendor/packaging/_structures.py
```
1 | # This file is dual licensed under the terms of the Apache License, Version
2 | # 2.0, and the BSD License. See the LICENSE file in the root of this repository
3 | # for complete details.
4 | 
5 | 
6 | class InfinityType:
7 |     def __repr__(self) -> str:
8 |         return "Infinity"
9 | 
10 |     def __hash__(self) -> int:
11 |         return hash(repr(self))
12 | 
13 |     def __lt__(self, other: object) -> bool:
14 |         return False
15 | 
16 |     def __le__(self, other: object) -> bool:
17 |         return False
18 | 
19 |     def __eq__(self, other: object) -> bool:
20 |         return isinstance(other, self.__class__)
21 | 
22 |     def __gt__(self, other: object) -> bool:
23 |         return True
24 | 
25 |     def __ge__(self, other: object) -> bool:
26 |         return True
27 | 
28 |     def __neg__(self: object) -> "NegativeInfinityType":
29 |         return NegativeInfinity
30 | 
31 | 
32 | Infinity = InfinityType()
33 | 
34 | 
35 | class NegativeInfinityType:
36 |     def __repr__(self) -> str:
37 |         return "-Infinity"
38 | 
39 |     def __hash__(self) -> int:
40 |         return hash(repr(self))
41 | 
42 |     def __lt__(self, other: object) -> bool:
43 |         return True
44 | 
45 |     def __le__(self, other: object) -> bool:
46 |         return True
47 | 
48 |     def __eq__(self, other: object) -> bool:
49 |         return isinstance(other, self.__class__)
50 | 
51 |     def __gt__(self, other: object) -> bool:
52 |         return False
53 | 
54 |     def __ge__(self, other: object) -> bool:
55 |         return False
56 | 
57 |     def __neg__(self: object) -> InfinityType:
58 |         return Infinity
59 | 
60 | 
61 | NegativeInfinity = NegativeInfinityType()
```

.venv/lib/python3.13/site-packages/pip/_vendor/packaging/markers.py
```
1 | # This file is dual licensed under the terms of the Apache License, Version
2 | # 2.0, and the BSD License. See the LICENSE file in the root of this repository
3 | # for complete details.
4 | 
5 | from __future__ import annotations
6 | 
7 | import operator
8 | import os
9 | import platform
10 | import sys
11 | from typing import AbstractSet, Any, Callable, Literal, TypedDict, Union, cast
12 | 
13 | from ._parser import MarkerAtom, MarkerList, Op, Value, Variable
14 | from ._parser import parse_marker as _parse_marker
15 | from ._tokenizer import ParserSyntaxError
16 | from .specifiers import InvalidSpecifier, Specifier
17 | from .utils import canonicalize_name
18 | 
19 | __all__ = [
20 |     "EvaluateContext",
21 |     "InvalidMarker",
22 |     "Marker",
23 |     "UndefinedComparison",
24 |     "UndefinedEnvironmentName",
25 |     "default_environment",
26 | ]
27 | 
28 | Operator = Callable[[str, Union[str, AbstractSet[str]]], bool]
29 | EvaluateContext = Literal["metadata", "lock_file", "requirement"]
30 | MARKERS_ALLOWING_SET = {"extras", "dependency_groups"}
31 | 
32 | 
33 | class InvalidMarker(ValueError):
34 |     """
35 |     An invalid marker was found, users should refer to PEP 508.
36 |     """
37 | 
38 | 
39 | class UndefinedComparison(ValueError):
40 |     """
41 |     An invalid operation was attempted on a value that doesn't support it.
42 |     """
43 | 
44 | 
45 | class UndefinedEnvironmentName(ValueError):
46 |     """
47 |     A name was attempted to be used that does not exist inside of the
48 |     environment.
49 |     """
50 | 
51 | 
52 | class Environment(TypedDict):
53 |     implementation_name: str
54 |     """The implementation's identifier, e.g. ``'cpython'``."""
55 | 
56 |     implementation_version: str
57 |     """
58 |     The implementation's version, e.g. ``'3.13.0a2'`` for CPython 3.13.0a2, or
59 |     ``'7.3.13'`` for PyPy3.10 v7.3.13.
60 |     """
61 | 
62 |     os_name: str
63 |     """
64 |     The value of :py:data:`os.name`. The name of the operating system dependent module
65 |     imported, e.g. ``'posix'``.
66 |     """
67 | 
68 |     platform_machine: str
69 |     """
70 |     Returns the machine type, e.g. ``'i386'``.
71 | 
72 |     An empty string if the value cannot be determined.
73 |     """
74 | 
75 |     platform_release: str
76 |     """
77 |     The system's release, e.g. ``'2.2.0'`` or ``'NT'``.
78 | 
79 |     An empty string if the value cannot be determined.
80 |     """
81 | 
82 |     platform_system: str
83 |     """
84 |     The system/OS name, e.g. ``'Linux'``, ``'Windows'`` or ``'Java'``.
85 | 
86 |     An empty string if the value cannot be determined.
87 |     """
88 | 
89 |     platform_version: str
90 |     """
91 |     The system's release version, e.g. ``'#3 on degas'``.
92 | 
93 |     An empty string if the value cannot be determined.
94 |     """
95 | 
96 |     python_full_version: str
97 |     """
98 |     The Python version as string ``'major.minor.patchlevel'``.
99 | 
100 |     Note that unlike the Python :py:data:`sys.version`, this value will always include
101 |     the patchlevel (it defaults to 0).
102 |     """
103 | 
104 |     platform_python_implementation: str
105 |     """
106 |     A string identifying the Python implementation, e.g. ``'CPython'``.
107 |     """
108 | 
109 |     python_version: str
110 |     """The Python version as string ``'major.minor'``."""
111 | 
112 |     sys_platform: str
113 |     """
114 |     This string contains a platform identifier that can be used to append
115 |     platform-specific components to :py:data:`sys.path`, for instance.
116 | 
117 |     For Unix systems, except on Linux and AIX, this is the lowercased OS name as
118 |     returned by ``uname -s`` with the first part of the version as returned by
119 |     ``uname -r`` appended, e.g. ``'sunos5'`` or ``'freebsd8'``, at the time when Python
120 |     was built.
121 |     """
122 | 
123 | 
124 | def _normalize_extra_values(results: Any) -> Any:
125 |     """
126 |     Normalize extra values.
127 |     """
128 |     if isinstance(results[0], tuple):
129 |         lhs, op, rhs = results[0]
130 |         if isinstance(lhs, Variable) and lhs.value == "extra":
131 |             normalized_extra = canonicalize_name(rhs.value)
132 |             rhs = Value(normalized_extra)
133 |         elif isinstance(rhs, Variable) and rhs.value == "extra":
134 |             normalized_extra = canonicalize_name(lhs.value)
135 |             lhs = Value(normalized_extra)
136 |         results[0] = lhs, op, rhs
137 |     return results
138 | 
139 | 
140 | def _format_marker(
141 |     marker: list[str] | MarkerAtom | str, first: bool | None = True
142 | ) -> str:
143 |     assert isinstance(marker, (list, tuple, str))
144 | 
145 |     # Sometimes we have a structure like [[...]] which is a single item list
146 |     # where the single item is itself it's own list. In that case we want skip
147 |     # the rest of this function so that we don't get extraneous () on the
148 |     # outside.
149 |     if (
150 |         isinstance(marker, list)
151 |         and len(marker) == 1
152 |         and isinstance(marker[0], (list, tuple))
153 |     ):
154 |         return _format_marker(marker[0])
155 | 
156 |     if isinstance(marker, list):
157 |         inner = (_format_marker(m, first=False) for m in marker)
158 |         if first:
159 |             return " ".join(inner)
160 |         else:
161 |             return "(" + " ".join(inner) + ")"
162 |     elif isinstance(marker, tuple):
163 |         return " ".join([m.serialize() for m in marker])
164 |     else:
165 |         return marker
166 | 
167 | 
168 | _operators: dict[str, Operator] = {
169 |     "in": lambda lhs, rhs: lhs in rhs,
170 |     "not in": lambda lhs, rhs: lhs not in rhs,
171 |     "<": operator.lt,
172 |     "<=": operator.le,
173 |     "==": operator.eq,
174 |     "!=": operator.ne,
175 |     ">=": operator.ge,
176 |     ">": operator.gt,
177 | }
178 | 
179 | 
180 | def _eval_op(lhs: str, op: Op, rhs: str | AbstractSet[str]) -> bool:
181 |     if isinstance(rhs, str):
182 |         try:
183 |             spec = Specifier("".join([op.serialize(), rhs]))
184 |         except InvalidSpecifier:
185 |             pass
186 |         else:
187 |             return spec.contains(lhs, prereleases=True)
188 | 
189 |     oper: Operator | None = _operators.get(op.serialize())
190 |     if oper is None:
191 |         raise UndefinedComparison(f"Undefined {op!r} on {lhs!r} and {rhs!r}.")
192 | 
193 |     return oper(lhs, rhs)
194 | 
195 | 
196 | def _normalize(
197 |     lhs: str, rhs: str | AbstractSet[str], key: str
198 | ) -> tuple[str, str | AbstractSet[str]]:
199 |     # PEP 685  Comparison of extra names for optional distribution dependencies
200 |     # https://peps.python.org/pep-0685/
201 |     # > When comparing extra names, tools MUST normalize the names being
202 |     # > compared using the semantics outlined in PEP 503 for names
203 |     if key == "extra":
204 |         assert isinstance(rhs, str), "extra value must be a string"
205 |         return (canonicalize_name(lhs), canonicalize_name(rhs))
206 |     if key in MARKERS_ALLOWING_SET:
207 |         if isinstance(rhs, str):  # pragma: no cover
208 |             return (canonicalize_name(lhs), canonicalize_name(rhs))
209 |         else:
210 |             return (canonicalize_name(lhs), {canonicalize_name(v) for v in rhs})
211 | 
212 |     # other environment markers don't have such standards
213 |     return lhs, rhs
214 | 
215 | 
216 | def _evaluate_markers(
217 |     markers: MarkerList, environment: dict[str, str | AbstractSet[str]]
218 | ) -> bool:
219 |     groups: list[list[bool]] = [[]]
220 | 
221 |     for marker in markers:
222 |         assert isinstance(marker, (list, tuple, str))
223 | 
224 |         if isinstance(marker, list):
225 |             groups[-1].append(_evaluate_markers(marker, environment))
226 |         elif isinstance(marker, tuple):
227 |             lhs, op, rhs = marker
228 | 
229 |             if isinstance(lhs, Variable):
230 |                 environment_key = lhs.value
231 |                 lhs_value = environment[environment_key]
232 |                 rhs_value = rhs.value
233 |             else:
234 |                 lhs_value = lhs.value
235 |                 environment_key = rhs.value
236 |                 rhs_value = environment[environment_key]
237 |             assert isinstance(lhs_value, str), "lhs must be a string"
238 |             lhs_value, rhs_value = _normalize(lhs_value, rhs_value, key=environment_key)
239 |             groups[-1].append(_eval_op(lhs_value, op, rhs_value))
240 |         else:
241 |             assert marker in ["and", "or"]
242 |             if marker == "or":
243 |                 groups.append([])
244 | 
245 |     return any(all(item) for item in groups)
246 | 
247 | 
248 | def format_full_version(info: sys._version_info) -> str:
249 |     version = f"{info.major}.{info.minor}.{info.micro}"
250 |     kind = info.releaselevel
251 |     if kind != "final":
252 |         version += kind[0] + str(info.serial)
253 |     return version
254 | 
255 | 
256 | def default_environment() -> Environment:
257 |     iver = format_full_version(sys.implementation.version)
258 |     implementation_name = sys.implementation.name
259 |     return {
260 |         "implementation_name": implementation_name,
261 |         "implementation_version": iver,
262 |         "os_name": os.name,
263 |         "platform_machine": platform.machine(),
264 |         "platform_release": platform.release(),
265 |         "platform_system": platform.system(),
266 |         "platform_version": platform.version(),
267 |         "python_full_version": platform.python_version(),
268 |         "platform_python_implementation": platform.python_implementation(),
269 |         "python_version": ".".join(platform.python_version_tuple()[:2]),
270 |         "sys_platform": sys.platform,
271 |     }
272 | 
273 | 
274 | class Marker:
275 |     def __init__(self, marker: str) -> None:
276 |         # Note: We create a Marker object without calling this constructor in
277 |         #       packaging.requirements.Requirement. If any additional logic is
278 |         #       added here, make sure to mirror/adapt Requirement.
279 |         try:
280 |             self._markers = _normalize_extra_values(_parse_marker(marker))
281 |             # The attribute `_markers` can be described in terms of a recursive type:
282 |             # MarkerList = List[Union[Tuple[Node, ...], str, MarkerList]]
283 |             #
284 |             # For example, the following expression:
285 |             # python_version > "3.6" or (python_version == "3.6" and os_name == "unix")
286 |             #
287 |             # is parsed into:
288 |             # [
289 |             #     (<Variable('python_version')>, <Op('>')>, <Value('3.6')>),
290 |             #     'and',
291 |             #     [
292 |             #         (<Variable('python_version')>, <Op('==')>, <Value('3.6')>),
293 |             #         'or',
294 |             #         (<Variable('os_name')>, <Op('==')>, <Value('unix')>)
295 |             #     ]
296 |             # ]
297 |         except ParserSyntaxError as e:
298 |             raise InvalidMarker(str(e)) from e
299 | 
300 |     def __str__(self) -> str:
301 |         return _format_marker(self._markers)
302 | 
303 |     def __repr__(self) -> str:
304 |         return f"<Marker('{self}')>"
305 | 
306 |     def __hash__(self) -> int:
307 |         return hash((self.__class__.__name__, str(self)))
308 | 
309 |     def __eq__(self, other: Any) -> bool:
310 |         if not isinstance(other, Marker):
311 |             return NotImplemented
312 | 
313 |         return str(self) == str(other)
314 | 
315 |     def evaluate(
316 |         self,
317 |         environment: dict[str, str] | None = None,
318 |         context: EvaluateContext = "metadata",
319 |     ) -> bool:
320 |         """Evaluate a marker.
321 | 
322 |         Return the boolean from evaluating the given marker against the
323 |         environment. environment is an optional argument to override all or
324 |         part of the determined environment. The *context* parameter specifies what
325 |         context the markers are being evaluated for, which influences what markers
326 |         are considered valid. Acceptable values are "metadata" (for core metadata;
327 |         default), "lock_file", and "requirement" (i.e. all other situations).
328 | 
329 |         The environment is determined from the current Python process.
330 |         """
331 |         current_environment = cast(
332 |             "dict[str, str | AbstractSet[str]]", default_environment()
333 |         )
334 |         if context == "lock_file":
335 |             current_environment.update(
336 |                 extras=frozenset(), dependency_groups=frozenset()
337 |             )
338 |         elif context == "metadata":
339 |             current_environment["extra"] = ""
340 |         if environment is not None:
341 |             current_environment.update(environment)
342 |             # The API used to allow setting extra to None. We need to handle this
343 |             # case for backwards compatibility.
344 |             if "extra" in current_environment and current_environment["extra"] is None:
345 |                 current_environment["extra"] = ""
346 | 
347 |         return _evaluate_markers(
348 |             self._markers, _repair_python_full_version(current_environment)
349 |         )
350 | 
351 | 
352 | def _repair_python_full_version(
353 |     env: dict[str, str | AbstractSet[str]],
354 | ) -> dict[str, str | AbstractSet[str]]:
355 |     """
356 |     Work around platform.python_version() returning something that is not PEP 440
[TRUNCATED]
```

.venv/lib/python3.13/site-packages/pip/_vendor/packaging/metadata.py
```
1 | from __future__ import annotations
2 | 
3 | import email.feedparser
4 | import email.header
5 | import email.message
6 | import email.parser
7 | import email.policy
8 | import pathlib
9 | import sys
10 | import typing
11 | from typing import (
12 |     Any,
13 |     Callable,
14 |     Generic,
15 |     Literal,
16 |     TypedDict,
17 |     cast,
18 | )
19 | 
20 | from . import licenses, requirements, specifiers, utils
21 | from . import version as version_module
22 | from .licenses import NormalizedLicenseExpression
23 | 
24 | T = typing.TypeVar("T")
25 | 
26 | 
27 | if sys.version_info >= (3, 11):  # pragma: no cover
28 |     ExceptionGroup = ExceptionGroup
29 | else:  # pragma: no cover
30 | 
31 |     class ExceptionGroup(Exception):
32 |         """A minimal implementation of :external:exc:`ExceptionGroup` from Python 3.11.
33 | 
34 |         If :external:exc:`ExceptionGroup` is already defined by Python itself,
35 |         that version is used instead.
36 |         """
37 | 
38 |         message: str
39 |         exceptions: list[Exception]
40 | 
41 |         def __init__(self, message: str, exceptions: list[Exception]) -> None:
42 |             self.message = message
43 |             self.exceptions = exceptions
44 | 
45 |         def __repr__(self) -> str:
46 |             return f"{self.__class__.__name__}({self.message!r}, {self.exceptions!r})"
47 | 
48 | 
49 | class InvalidMetadata(ValueError):
50 |     """A metadata field contains invalid data."""
51 | 
52 |     field: str
53 |     """The name of the field that contains invalid data."""
54 | 
55 |     def __init__(self, field: str, message: str) -> None:
56 |         self.field = field
57 |         super().__init__(message)
58 | 
59 | 
60 | # The RawMetadata class attempts to make as few assumptions about the underlying
61 | # serialization formats as possible. The idea is that as long as a serialization
62 | # formats offer some very basic primitives in *some* way then we can support
63 | # serializing to and from that format.
64 | class RawMetadata(TypedDict, total=False):
65 |     """A dictionary of raw core metadata.
66 | 
67 |     Each field in core metadata maps to a key of this dictionary (when data is
68 |     provided). The key is lower-case and underscores are used instead of dashes
69 |     compared to the equivalent core metadata field. Any core metadata field that
70 |     can be specified multiple times or can hold multiple values in a single
71 |     field have a key with a plural name. See :class:`Metadata` whose attributes
72 |     match the keys of this dictionary.
73 | 
74 |     Core metadata fields that can be specified multiple times are stored as a
75 |     list or dict depending on which is appropriate for the field. Any fields
76 |     which hold multiple values in a single field are stored as a list.
77 | 
78 |     """
79 | 
80 |     # Metadata 1.0 - PEP 241
81 |     metadata_version: str
82 |     name: str
83 |     version: str
84 |     platforms: list[str]
85 |     summary: str
86 |     description: str
87 |     keywords: list[str]
88 |     home_page: str
89 |     author: str
90 |     author_email: str
91 |     license: str
92 | 
93 |     # Metadata 1.1 - PEP 314
94 |     supported_platforms: list[str]
95 |     download_url: str
96 |     classifiers: list[str]
97 |     requires: list[str]
98 |     provides: list[str]
99 |     obsoletes: list[str]
100 | 
101 |     # Metadata 1.2 - PEP 345
102 |     maintainer: str
103 |     maintainer_email: str
104 |     requires_dist: list[str]
105 |     provides_dist: list[str]
106 |     obsoletes_dist: list[str]
107 |     requires_python: str
108 |     requires_external: list[str]
109 |     project_urls: dict[str, str]
110 | 
111 |     # Metadata 2.0
112 |     # PEP 426 attempted to completely revamp the metadata format
113 |     # but got stuck without ever being able to build consensus on
114 |     # it and ultimately ended up withdrawn.
115 |     #
116 |     # However, a number of tools had started emitting METADATA with
117 |     # `2.0` Metadata-Version, so for historical reasons, this version
118 |     # was skipped.
119 | 
120 |     # Metadata 2.1 - PEP 566
121 |     description_content_type: str
122 |     provides_extra: list[str]
123 | 
124 |     # Metadata 2.2 - PEP 643
125 |     dynamic: list[str]
126 | 
127 |     # Metadata 2.3 - PEP 685
128 |     # No new fields were added in PEP 685, just some edge case were
129 |     # tightened up to provide better interoptability.
130 | 
131 |     # Metadata 2.4 - PEP 639
132 |     license_expression: str
133 |     license_files: list[str]
134 | 
135 | 
136 | _STRING_FIELDS = {
137 |     "author",
138 |     "author_email",
139 |     "description",
140 |     "description_content_type",
141 |     "download_url",
142 |     "home_page",
143 |     "license",
144 |     "license_expression",
145 |     "maintainer",
146 |     "maintainer_email",
147 |     "metadata_version",
148 |     "name",
149 |     "requires_python",
150 |     "summary",
151 |     "version",
152 | }
153 | 
154 | _LIST_FIELDS = {
155 |     "classifiers",
156 |     "dynamic",
157 |     "license_files",
158 |     "obsoletes",
159 |     "obsoletes_dist",
160 |     "platforms",
161 |     "provides",
162 |     "provides_dist",
163 |     "provides_extra",
164 |     "requires",
165 |     "requires_dist",
166 |     "requires_external",
167 |     "supported_platforms",
168 | }
169 | 
170 | _DICT_FIELDS = {
171 |     "project_urls",
172 | }
173 | 
174 | 
175 | def _parse_keywords(data: str) -> list[str]:
176 |     """Split a string of comma-separated keywords into a list of keywords."""
177 |     return [k.strip() for k in data.split(",")]
178 | 
179 | 
180 | def _parse_project_urls(data: list[str]) -> dict[str, str]:
181 |     """Parse a list of label/URL string pairings separated by a comma."""
182 |     urls = {}
183 |     for pair in data:
184 |         # Our logic is slightly tricky here as we want to try and do
185 |         # *something* reasonable with malformed data.
186 |         #
187 |         # The main thing that we have to worry about, is data that does
188 |         # not have a ',' at all to split the label from the Value. There
189 |         # isn't a singular right answer here, and we will fail validation
190 |         # later on (if the caller is validating) so it doesn't *really*
191 |         # matter, but since the missing value has to be an empty str
192 |         # and our return value is dict[str, str], if we let the key
193 |         # be the missing value, then they'd have multiple '' values that
194 |         # overwrite each other in a accumulating dict.
195 |         #
196 |         # The other potentional issue is that it's possible to have the
197 |         # same label multiple times in the metadata, with no solid "right"
198 |         # answer with what to do in that case. As such, we'll do the only
199 |         # thing we can, which is treat the field as unparseable and add it
200 |         # to our list of unparsed fields.
201 |         parts = [p.strip() for p in pair.split(",", 1)]
202 |         parts.extend([""] * (max(0, 2 - len(parts))))  # Ensure 2 items
203 | 
204 |         # TODO: The spec doesn't say anything about if the keys should be
205 |         #       considered case sensitive or not... logically they should
206 |         #       be case-preserving and case-insensitive, but doing that
207 |         #       would open up more cases where we might have duplicate
208 |         #       entries.
209 |         label, url = parts
210 |         if label in urls:
211 |             # The label already exists in our set of urls, so this field
212 |             # is unparseable, and we can just add the whole thing to our
213 |             # unparseable data and stop processing it.
214 |             raise KeyError("duplicate labels in project urls")
215 |         urls[label] = url
216 | 
217 |     return urls
218 | 
219 | 
220 | def _get_payload(msg: email.message.Message, source: bytes | str) -> str:
221 |     """Get the body of the message."""
222 |     # If our source is a str, then our caller has managed encodings for us,
223 |     # and we don't need to deal with it.
224 |     if isinstance(source, str):
225 |         payload = msg.get_payload()
226 |         assert isinstance(payload, str)
227 |         return payload
228 |     # If our source is a bytes, then we're managing the encoding and we need
229 |     # to deal with it.
230 |     else:
231 |         bpayload = msg.get_payload(decode=True)
232 |         assert isinstance(bpayload, bytes)
233 |         try:
234 |             return bpayload.decode("utf8", "strict")
235 |         except UnicodeDecodeError as exc:
236 |             raise ValueError("payload in an invalid encoding") from exc
237 | 
238 | 
239 | # The various parse_FORMAT functions here are intended to be as lenient as
240 | # possible in their parsing, while still returning a correctly typed
241 | # RawMetadata.
242 | #
243 | # To aid in this, we also generally want to do as little touching of the
244 | # data as possible, except where there are possibly some historic holdovers
245 | # that make valid data awkward to work with.
246 | #
247 | # While this is a lower level, intermediate format than our ``Metadata``
248 | # class, some light touch ups can make a massive difference in usability.
249 | 
250 | # Map METADATA fields to RawMetadata.
251 | _EMAIL_TO_RAW_MAPPING = {
252 |     "author": "author",
253 |     "author-email": "author_email",
254 |     "classifier": "classifiers",
255 |     "description": "description",
256 |     "description-content-type": "description_content_type",
257 |     "download-url": "download_url",
258 |     "dynamic": "dynamic",
259 |     "home-page": "home_page",
260 |     "keywords": "keywords",
261 |     "license": "license",
262 |     "license-expression": "license_expression",
263 |     "license-file": "license_files",
264 |     "maintainer": "maintainer",
265 |     "maintainer-email": "maintainer_email",
266 |     "metadata-version": "metadata_version",
267 |     "name": "name",
268 |     "obsoletes": "obsoletes",
269 |     "obsoletes-dist": "obsoletes_dist",
270 |     "platform": "platforms",
271 |     "project-url": "project_urls",
272 |     "provides": "provides",
273 |     "provides-dist": "provides_dist",
274 |     "provides-extra": "provides_extra",
275 |     "requires": "requires",
276 |     "requires-dist": "requires_dist",
277 |     "requires-external": "requires_external",
278 |     "requires-python": "requires_python",
279 |     "summary": "summary",
280 |     "supported-platform": "supported_platforms",
281 |     "version": "version",
282 | }
283 | _RAW_TO_EMAIL_MAPPING = {raw: email for email, raw in _EMAIL_TO_RAW_MAPPING.items()}
284 | 
285 | 
286 | def parse_email(data: bytes | str) -> tuple[RawMetadata, dict[str, list[str]]]:
287 |     """Parse a distribution's metadata stored as email headers (e.g. from ``METADATA``).
288 | 
289 |     This function returns a two-item tuple of dicts. The first dict is of
290 |     recognized fields from the core metadata specification. Fields that can be
291 |     parsed and translated into Python's built-in types are converted
292 |     appropriately. All other fields are left as-is. Fields that are allowed to
293 |     appear multiple times are stored as lists.
294 | 
295 |     The second dict contains all other fields from the metadata. This includes
296 |     any unrecognized fields. It also includes any fields which are expected to
297 |     be parsed into a built-in type but were not formatted appropriately. Finally,
298 |     any fields that are expected to appear only once but are repeated are
299 |     included in this dict.
300 | 
301 |     """
302 |     raw: dict[str, str | list[str] | dict[str, str]] = {}
303 |     unparsed: dict[str, list[str]] = {}
304 | 
305 |     if isinstance(data, str):
306 |         parsed = email.parser.Parser(policy=email.policy.compat32).parsestr(data)
307 |     else:
308 |         parsed = email.parser.BytesParser(policy=email.policy.compat32).parsebytes(data)
309 | 
310 |     # We have to wrap parsed.keys() in a set, because in the case of multiple
311 |     # values for a key (a list), the key will appear multiple times in the
312 |     # list of keys, but we're avoiding that by using get_all().
313 |     for name in frozenset(parsed.keys()):
314 |         # Header names in RFC are case insensitive, so we'll normalize to all
315 |         # lower case to make comparisons easier.
316 |         name = name.lower()
317 | 
318 |         # We use get_all() here, even for fields that aren't multiple use,
319 |         # because otherwise someone could have e.g. two Name fields, and we
320 |         # would just silently ignore it rather than doing something about it.
321 |         headers = parsed.get_all(name) or []
322 | 
323 |         # The way the email module works when parsing bytes is that it
324 |         # unconditionally decodes the bytes as ascii using the surrogateescape
325 |         # handler. When you pull that data back out (such as with get_all() ),
326 |         # it looks to see if the str has any surrogate escapes, and if it does
327 |         # it wraps it in a Header object instead of returning the string.
[TRUNCATED]
```

.venv/lib/python3.13/site-packages/pip/_vendor/packaging/py.typed
```
```

.venv/lib/python3.13/site-packages/pip/_vendor/packaging/requirements.py
```
1 | # This file is dual licensed under the terms of the Apache License, Version
2 | # 2.0, and the BSD License. See the LICENSE file in the root of this repository
3 | # for complete details.
4 | from __future__ import annotations
5 | 
6 | from typing import Any, Iterator
7 | 
8 | from ._parser import parse_requirement as _parse_requirement
9 | from ._tokenizer import ParserSyntaxError
10 | from .markers import Marker, _normalize_extra_values
11 | from .specifiers import SpecifierSet
12 | from .utils import canonicalize_name
13 | 
14 | 
15 | class InvalidRequirement(ValueError):
16 |     """
17 |     An invalid requirement was found, users should refer to PEP 508.
18 |     """
19 | 
20 | 
21 | class Requirement:
22 |     """Parse a requirement.
23 | 
24 |     Parse a given requirement string into its parts, such as name, specifier,
25 |     URL, and extras. Raises InvalidRequirement on a badly-formed requirement
26 |     string.
27 |     """
28 | 
29 |     # TODO: Can we test whether something is contained within a requirement?
30 |     #       If so how do we do that? Do we need to test against the _name_ of
31 |     #       the thing as well as the version? What about the markers?
32 |     # TODO: Can we normalize the name and extra name?
33 | 
34 |     def __init__(self, requirement_string: str) -> None:
35 |         try:
36 |             parsed = _parse_requirement(requirement_string)
37 |         except ParserSyntaxError as e:
38 |             raise InvalidRequirement(str(e)) from e
39 | 
40 |         self.name: str = parsed.name
41 |         self.url: str | None = parsed.url or None
42 |         self.extras: set[str] = set(parsed.extras or [])
43 |         self.specifier: SpecifierSet = SpecifierSet(parsed.specifier)
44 |         self.marker: Marker | None = None
45 |         if parsed.marker is not None:
46 |             self.marker = Marker.__new__(Marker)
47 |             self.marker._markers = _normalize_extra_values(parsed.marker)
48 | 
49 |     def _iter_parts(self, name: str) -> Iterator[str]:
50 |         yield name
51 | 
52 |         if self.extras:
53 |             formatted_extras = ",".join(sorted(self.extras))
54 |             yield f"[{formatted_extras}]"
55 | 
56 |         if self.specifier:
57 |             yield str(self.specifier)
58 | 
59 |         if self.url:
60 |             yield f"@ {self.url}"
61 |             if self.marker:
62 |                 yield " "
63 | 
64 |         if self.marker:
65 |             yield f"; {self.marker}"
66 | 
67 |     def __str__(self) -> str:
68 |         return "".join(self._iter_parts(self.name))
69 | 
70 |     def __repr__(self) -> str:
71 |         return f"<Requirement('{self}')>"
72 | 
73 |     def __hash__(self) -> int:
74 |         return hash(
75 |             (
76 |                 self.__class__.__name__,
77 |                 *self._iter_parts(canonicalize_name(self.name)),
78 |             )
79 |         )
80 | 
81 |     def __eq__(self, other: Any) -> bool:
82 |         if not isinstance(other, Requirement):
83 |             return NotImplemented
84 | 
85 |         return (
86 |             canonicalize_name(self.name) == canonicalize_name(other.name)
87 |             and self.extras == other.extras
88 |             and self.specifier == other.specifier
89 |             and self.url == other.url
90 |             and self.marker == other.marker
91 |         )
```

.venv/lib/python3.13/site-packages/pip/_vendor/packaging/specifiers.py
```
1 | # This file is dual licensed under the terms of the Apache License, Version
2 | # 2.0, and the BSD License. See the LICENSE file in the root of this repository
3 | # for complete details.
4 | """
5 | .. testsetup::
6 | 
7 |     from pip._vendor.packaging.specifiers import Specifier, SpecifierSet, InvalidSpecifier
8 |     from pip._vendor.packaging.version import Version
9 | """
10 | 
11 | from __future__ import annotations
12 | 
13 | import abc
14 | import itertools
15 | import re
16 | from typing import Callable, Iterable, Iterator, TypeVar, Union
17 | 
18 | from .utils import canonicalize_version
19 | from .version import Version
20 | 
21 | UnparsedVersion = Union[Version, str]
22 | UnparsedVersionVar = TypeVar("UnparsedVersionVar", bound=UnparsedVersion)
23 | CallableOperator = Callable[[Version, str], bool]
24 | 
25 | 
26 | def _coerce_version(version: UnparsedVersion) -> Version:
27 |     if not isinstance(version, Version):
28 |         version = Version(version)
29 |     return version
30 | 
31 | 
32 | class InvalidSpecifier(ValueError):
33 |     """
34 |     Raised when attempting to create a :class:`Specifier` with a specifier
35 |     string that is invalid.
36 | 
37 |     >>> Specifier("lolwat")
38 |     Traceback (most recent call last):
39 |         ...
40 |     packaging.specifiers.InvalidSpecifier: Invalid specifier: 'lolwat'
41 |     """
42 | 
43 | 
44 | class BaseSpecifier(metaclass=abc.ABCMeta):
45 |     @abc.abstractmethod
46 |     def __str__(self) -> str:
47 |         """
48 |         Returns the str representation of this Specifier-like object. This
49 |         should be representative of the Specifier itself.
50 |         """
51 | 
52 |     @abc.abstractmethod
53 |     def __hash__(self) -> int:
54 |         """
55 |         Returns a hash value for this Specifier-like object.
56 |         """
57 | 
58 |     @abc.abstractmethod
59 |     def __eq__(self, other: object) -> bool:
60 |         """
61 |         Returns a boolean representing whether or not the two Specifier-like
62 |         objects are equal.
63 | 
64 |         :param other: The other object to check against.
65 |         """
66 | 
67 |     @property
68 |     @abc.abstractmethod
69 |     def prereleases(self) -> bool | None:
70 |         """Whether or not pre-releases as a whole are allowed.
71 | 
72 |         This can be set to either ``True`` or ``False`` to explicitly enable or disable
73 |         prereleases or it can be set to ``None`` (the default) to use default semantics.
74 |         """
75 | 
76 |     @prereleases.setter
77 |     def prereleases(self, value: bool) -> None:
78 |         """Setter for :attr:`prereleases`.
79 | 
80 |         :param value: The value to set.
81 |         """
82 | 
83 |     @abc.abstractmethod
84 |     def contains(self, item: str, prereleases: bool | None = None) -> bool:
85 |         """
86 |         Determines if the given item is contained within this specifier.
87 |         """
88 | 
89 |     @abc.abstractmethod
90 |     def filter(
91 |         self, iterable: Iterable[UnparsedVersionVar], prereleases: bool | None = None
92 |     ) -> Iterator[UnparsedVersionVar]:
93 |         """
94 |         Takes an iterable of items and filters them so that only items which
95 |         are contained within this specifier are allowed in it.
96 |         """
97 | 
98 | 
99 | class Specifier(BaseSpecifier):
100 |     """This class abstracts handling of version specifiers.
101 | 
102 |     .. tip::
103 | 
104 |         It is generally not required to instantiate this manually. You should instead
105 |         prefer to work with :class:`SpecifierSet` instead, which can parse
106 |         comma-separated version specifiers (which is what package metadata contains).
107 |     """
108 | 
109 |     _operator_regex_str = r"""
110 |         (?P<operator>(~=|==|!=|<=|>=|<|>|===))
111 |         """
112 |     _version_regex_str = r"""
113 |         (?P<version>
114 |             (?:
115 |                 # The identity operators allow for an escape hatch that will
116 |                 # do an exact string match of the version you wish to install.
117 |                 # This will not be parsed by PEP 440 and we cannot determine
118 |                 # any semantic meaning from it. This operator is discouraged
119 |                 # but included entirely as an escape hatch.
120 |                 (?<====)  # Only match for the identity operator
121 |                 \s*
122 |                 [^\s;)]*  # The arbitrary version can be just about anything,
123 |                           # we match everything except for whitespace, a
124 |                           # semi-colon for marker support, and a closing paren
125 |                           # since versions can be enclosed in them.
126 |             )
127 |             |
128 |             (?:
129 |                 # The (non)equality operators allow for wild card and local
130 |                 # versions to be specified so we have to define these two
131 |                 # operators separately to enable that.
132 |                 (?<===|!=)            # Only match for equals and not equals
133 | 
134 |                 \s*
135 |                 v?
136 |                 (?:[0-9]+!)?          # epoch
137 |                 [0-9]+(?:\.[0-9]+)*   # release
138 | 
139 |                 # You cannot use a wild card and a pre-release, post-release, a dev or
140 |                 # local version together so group them with a | and make them optional.
141 |                 (?:
142 |                     \.\*  # Wild card syntax of .*
143 |                     |
144 |                     (?:                                  # pre release
145 |                         [-_\.]?
146 |                         (alpha|beta|preview|pre|a|b|c|rc)
147 |                         [-_\.]?
148 |                         [0-9]*
149 |                     )?
150 |                     (?:                                  # post release
151 |                         (?:-[0-9]+)|(?:[-_\.]?(post|rev|r)[-_\.]?[0-9]*)
152 |                     )?
153 |                     (?:[-_\.]?dev[-_\.]?[0-9]*)?         # dev release
154 |                     (?:\+[a-z0-9]+(?:[-_\.][a-z0-9]+)*)? # local
155 |                 )?
156 |             )
157 |             |
158 |             (?:
159 |                 # The compatible operator requires at least two digits in the
160 |                 # release segment.
161 |                 (?<=~=)               # Only match for the compatible operator
162 | 
163 |                 \s*
164 |                 v?
165 |                 (?:[0-9]+!)?          # epoch
166 |                 [0-9]+(?:\.[0-9]+)+   # release  (We have a + instead of a *)
167 |                 (?:                   # pre release
168 |                     [-_\.]?
169 |                     (alpha|beta|preview|pre|a|b|c|rc)
170 |                     [-_\.]?
171 |                     [0-9]*
172 |                 )?
173 |                 (?:                                   # post release
174 |                     (?:-[0-9]+)|(?:[-_\.]?(post|rev|r)[-_\.]?[0-9]*)
175 |                 )?
176 |                 (?:[-_\.]?dev[-_\.]?[0-9]*)?          # dev release
177 |             )
178 |             |
179 |             (?:
180 |                 # All other operators only allow a sub set of what the
181 |                 # (non)equality operators do. Specifically they do not allow
182 |                 # local versions to be specified nor do they allow the prefix
183 |                 # matching wild cards.
184 |                 (?<!==|!=|~=)         # We have special cases for these
185 |                                       # operators so we want to make sure they
186 |                                       # don't match here.
187 | 
188 |                 \s*
189 |                 v?
190 |                 (?:[0-9]+!)?          # epoch
191 |                 [0-9]+(?:\.[0-9]+)*   # release
192 |                 (?:                   # pre release
193 |                     [-_\.]?
194 |                     (alpha|beta|preview|pre|a|b|c|rc)
195 |                     [-_\.]?
196 |                     [0-9]*
197 |                 )?
198 |                 (?:                                   # post release
199 |                     (?:-[0-9]+)|(?:[-_\.]?(post|rev|r)[-_\.]?[0-9]*)
200 |                 )?
201 |                 (?:[-_\.]?dev[-_\.]?[0-9]*)?          # dev release
202 |             )
203 |         )
204 |         """
205 | 
206 |     _regex = re.compile(
207 |         r"^\s*" + _operator_regex_str + _version_regex_str + r"\s*$",
208 |         re.VERBOSE | re.IGNORECASE,
209 |     )
210 | 
211 |     _operators = {
212 |         "~=": "compatible",
213 |         "==": "equal",
214 |         "!=": "not_equal",
215 |         "<=": "less_than_equal",
216 |         ">=": "greater_than_equal",
217 |         "<": "less_than",
218 |         ">": "greater_than",
219 |         "===": "arbitrary",
220 |     }
221 | 
222 |     def __init__(self, spec: str = "", prereleases: bool | None = None) -> None:
223 |         """Initialize a Specifier instance.
224 | 
225 |         :param spec:
226 |             The string representation of a specifier which will be parsed and
227 |             normalized before use.
228 |         :param prereleases:
229 |             This tells the specifier if it should accept prerelease versions if
230 |             applicable or not. The default of ``None`` will autodetect it from the
231 |             given specifiers.
232 |         :raises InvalidSpecifier:
233 |             If the given specifier is invalid (i.e. bad syntax).
234 |         """
235 |         match = self._regex.search(spec)
236 |         if not match:
237 |             raise InvalidSpecifier(f"Invalid specifier: {spec!r}")
238 | 
239 |         self._spec: tuple[str, str] = (
240 |             match.group("operator").strip(),
241 |             match.group("version").strip(),
242 |         )
243 | 
244 |         # Store whether or not this Specifier should accept prereleases
245 |         self._prereleases = prereleases
246 | 
247 |     # https://github.com/python/mypy/pull/13475#pullrequestreview-1079784515
248 |     @property  # type: ignore[override]
249 |     def prereleases(self) -> bool:
250 |         # If there is an explicit prereleases set for this, then we'll just
251 |         # blindly use that.
252 |         if self._prereleases is not None:
253 |             return self._prereleases
254 | 
255 |         # Look at all of our specifiers and determine if they are inclusive
256 |         # operators, and if they are if they are including an explicit
257 |         # prerelease.
258 |         operator, version = self._spec
259 |         if operator in ["==", ">=", "<=", "~=", "===", ">", "<"]:
260 |             # The == specifier can include a trailing .*, if it does we
261 |             # want to remove before parsing.
262 |             if operator == "==" and version.endswith(".*"):
263 |                 version = version[:-2]
264 | 
265 |             # Parse the version, and if it is a pre-release than this
266 |             # specifier allows pre-releases.
267 |             if Version(version).is_prerelease:
268 |                 return True
269 | 
270 |         return False
271 | 
272 |     @prereleases.setter
273 |     def prereleases(self, value: bool) -> None:
274 |         self._prereleases = value
275 | 
276 |     @property
277 |     def operator(self) -> str:
278 |         """The operator of this specifier.
279 | 
280 |         >>> Specifier("==1.2.3").operator
281 |         '=='
282 |         """
283 |         return self._spec[0]
284 | 
285 |     @property
286 |     def version(self) -> str:
287 |         """The version of this specifier.
288 | 
289 |         >>> Specifier("==1.2.3").version
290 |         '1.2.3'
291 |         """
292 |         return self._spec[1]
293 | 
294 |     def __repr__(self) -> str:
295 |         """A representation of the Specifier that shows all internal state.
296 | 
297 |         >>> Specifier('>=1.0.0')
298 |         <Specifier('>=1.0.0')>
299 |         >>> Specifier('>=1.0.0', prereleases=False)
300 |         <Specifier('>=1.0.0', prereleases=False)>
301 |         >>> Specifier('>=1.0.0', prereleases=True)
302 |         <Specifier('>=1.0.0', prereleases=True)>
303 |         """
304 |         pre = (
305 |             f", prereleases={self.prereleases!r}"
306 |             if self._prereleases is not None
307 |             else ""
308 |         )
309 | 
310 |         return f"<{self.__class__.__name__}({str(self)!r}{pre})>"
311 | 
312 |     def __str__(self) -> str:
313 |         """A string representation of the Specifier that can be round-tripped.
314 | 
315 |         >>> str(Specifier('>=1.0.0'))
316 |         '>=1.0.0'
317 |         >>> str(Specifier('>=1.0.0', prereleases=False))
318 |         '>=1.0.0'
319 |         """
320 |         return "{}{}".format(*self._spec)
321 | 
322 |     @property
323 |     def _canonical_spec(self) -> tuple[str, str]:
324 |         canonical_version = canonicalize_version(
325 |             self._spec[1],
326 |             strip_trailing_zero=(self._spec[0] != "~="),
327 |         )
328 |         return self._spec[0], canonical_version
329 | 
330 |     def __hash__(self) -> int:
331 |         return hash(self._canonical_spec)
332 | 
333 |     def __eq__(self, other: object) -> bool:
334 |         """Whether or not the two Specifier-like objects are equal.
335 | 
336 |         :param other: The other object to check against.
337 | 
338 |         The value of :attr:`prereleases` is ignored.
339 | 
340 |         >>> Specifier("==1.2.3") == Specifier("== 1.2.3.0")
341 |         True
342 |         >>> (Specifier("==1.2.3", prereleases=False) ==
343 |         ...  Specifier("==1.2.3", prereleases=True))
344 |         True
345 |         >>> Specifier("==1.2.3") == "==1.2.3"
346 |         True
347 |         >>> Specifier("==1.2.3") == Specifier("==1.2.4")
348 |         False
349 |         >>> Specifier("==1.2.3") == Specifier("~=1.2.3")
350 |         False
351 |         """
352 |         if isinstance(other, str):
353 |             try:
354 |                 other = self.__class__(str(other))
355 |             except InvalidSpecifier:
356 |                 return NotImplemented
357 |         elif not isinstance(other, self.__class__):
358 |             return NotImplemented
359 | 
360 |         return self._canonical_spec == other._canonical_spec
361 | 
362 |     def _get_operator(self, op: str) -> CallableOperator:
363 |         operator_callable: CallableOperator = getattr(
364 |             self, f"_compare_{self._operators[op]}"
365 |         )
366 |         return operator_callable
367 | 
368 |     def _compare_compatible(self, prospective: Version, spec: str) -> bool:
369 |         # Compatible releases have an equivalent combination of >= and ==. That
370 |         # is that ~=2.2 is equivalent to >=2.2,==2.*. This allows us to
371 |         # implement this in terms of the other specifiers instead of
372 |         # implementing it ourselves. The only thing we need to do is construct
373 |         # the other specifiers.
374 | 
375 |         # We want everything but the last item in the version, but we want to
376 |         # ignore suffix segments.
377 |         prefix = _version_join(
[TRUNCATED]
```

.venv/lib/python3.13/site-packages/pip/_vendor/packaging/tags.py
```
1 | # This file is dual licensed under the terms of the Apache License, Version
2 | # 2.0, and the BSD License. See the LICENSE file in the root of this repository
3 | # for complete details.
4 | 
5 | from __future__ import annotations
6 | 
7 | import logging
8 | import platform
9 | import re
10 | import struct
11 | import subprocess
12 | import sys
13 | import sysconfig
14 | from importlib.machinery import EXTENSION_SUFFIXES
15 | from typing import (
16 |     Iterable,
17 |     Iterator,
18 |     Sequence,
19 |     Tuple,
20 |     cast,
21 | )
22 | 
23 | from . import _manylinux, _musllinux
24 | 
25 | logger = logging.getLogger(__name__)
26 | 
27 | PythonVersion = Sequence[int]
28 | AppleVersion = Tuple[int, int]
29 | 
30 | INTERPRETER_SHORT_NAMES: dict[str, str] = {
31 |     "python": "py",  # Generic.
32 |     "cpython": "cp",
33 |     "pypy": "pp",
34 |     "ironpython": "ip",
35 |     "jython": "jy",
36 | }
37 | 
38 | 
39 | _32_BIT_INTERPRETER = struct.calcsize("P") == 4
40 | 
41 | 
42 | class Tag:
43 |     """
44 |     A representation of the tag triple for a wheel.
45 | 
46 |     Instances are considered immutable and thus are hashable. Equality checking
47 |     is also supported.
48 |     """
49 | 
50 |     __slots__ = ["_abi", "_hash", "_interpreter", "_platform"]
51 | 
52 |     def __init__(self, interpreter: str, abi: str, platform: str) -> None:
53 |         self._interpreter = interpreter.lower()
54 |         self._abi = abi.lower()
55 |         self._platform = platform.lower()
56 |         # The __hash__ of every single element in a Set[Tag] will be evaluated each time
57 |         # that a set calls its `.disjoint()` method, which may be called hundreds of
58 |         # times when scanning a page of links for packages with tags matching that
59 |         # Set[Tag]. Pre-computing the value here produces significant speedups for
60 |         # downstream consumers.
61 |         self._hash = hash((self._interpreter, self._abi, self._platform))
62 | 
63 |     @property
64 |     def interpreter(self) -> str:
65 |         return self._interpreter
66 | 
67 |     @property
68 |     def abi(self) -> str:
69 |         return self._abi
70 | 
71 |     @property
72 |     def platform(self) -> str:
73 |         return self._platform
74 | 
75 |     def __eq__(self, other: object) -> bool:
76 |         if not isinstance(other, Tag):
77 |             return NotImplemented
78 | 
79 |         return (
80 |             (self._hash == other._hash)  # Short-circuit ASAP for perf reasons.
81 |             and (self._platform == other._platform)
82 |             and (self._abi == other._abi)
83 |             and (self._interpreter == other._interpreter)
84 |         )
85 | 
86 |     def __hash__(self) -> int:
87 |         return self._hash
88 | 
89 |     def __str__(self) -> str:
90 |         return f"{self._interpreter}-{self._abi}-{self._platform}"
91 | 
92 |     def __repr__(self) -> str:
93 |         return f"<{self} @ {id(self)}>"
94 | 
95 | 
96 | def parse_tag(tag: str) -> frozenset[Tag]:
97 |     """
98 |     Parses the provided tag (e.g. `py3-none-any`) into a frozenset of Tag instances.
99 | 
100 |     Returning a set is required due to the possibility that the tag is a
101 |     compressed tag set.
102 |     """
103 |     tags = set()
104 |     interpreters, abis, platforms = tag.split("-")
105 |     for interpreter in interpreters.split("."):
106 |         for abi in abis.split("."):
107 |             for platform_ in platforms.split("."):
108 |                 tags.add(Tag(interpreter, abi, platform_))
109 |     return frozenset(tags)
110 | 
111 | 
112 | def _get_config_var(name: str, warn: bool = False) -> int | str | None:
113 |     value: int | str | None = sysconfig.get_config_var(name)
114 |     if value is None and warn:
115 |         logger.debug(
116 |             "Config variable '%s' is unset, Python ABI tag may be incorrect", name
117 |         )
118 |     return value
119 | 
120 | 
121 | def _normalize_string(string: str) -> str:
122 |     return string.replace(".", "_").replace("-", "_").replace(" ", "_")
123 | 
124 | 
125 | def _is_threaded_cpython(abis: list[str]) -> bool:
126 |     """
127 |     Determine if the ABI corresponds to a threaded (`--disable-gil`) build.
128 | 
129 |     The threaded builds are indicated by a "t" in the abiflags.
130 |     """
131 |     if len(abis) == 0:
132 |         return False
133 |     # expect e.g., cp313
134 |     m = re.match(r"cp\d+(.*)", abis[0])
135 |     if not m:
136 |         return False
137 |     abiflags = m.group(1)
138 |     return "t" in abiflags
139 | 
140 | 
141 | def _abi3_applies(python_version: PythonVersion, threading: bool) -> bool:
142 |     """
143 |     Determine if the Python version supports abi3.
144 | 
145 |     PEP 384 was first implemented in Python 3.2. The threaded (`--disable-gil`)
146 |     builds do not support abi3.
147 |     """
148 |     return len(python_version) > 1 and tuple(python_version) >= (3, 2) and not threading
149 | 
150 | 
151 | def _cpython_abis(py_version: PythonVersion, warn: bool = False) -> list[str]:
152 |     py_version = tuple(py_version)  # To allow for version comparison.
153 |     abis = []
154 |     version = _version_nodot(py_version[:2])
155 |     threading = debug = pymalloc = ucs4 = ""
156 |     with_debug = _get_config_var("Py_DEBUG", warn)
157 |     has_refcount = hasattr(sys, "gettotalrefcount")
158 |     # Windows doesn't set Py_DEBUG, so checking for support of debug-compiled
159 |     # extension modules is the best option.
160 |     # https://github.com/pypa/pip/issues/3383#issuecomment-173267692
161 |     has_ext = "_d.pyd" in EXTENSION_SUFFIXES
162 |     if with_debug or (with_debug is None and (has_refcount or has_ext)):
163 |         debug = "d"
164 |     if py_version >= (3, 13) and _get_config_var("Py_GIL_DISABLED", warn):
165 |         threading = "t"
166 |     if py_version < (3, 8):
167 |         with_pymalloc = _get_config_var("WITH_PYMALLOC", warn)
168 |         if with_pymalloc or with_pymalloc is None:
169 |             pymalloc = "m"
170 |         if py_version < (3, 3):
171 |             unicode_size = _get_config_var("Py_UNICODE_SIZE", warn)
172 |             if unicode_size == 4 or (
173 |                 unicode_size is None and sys.maxunicode == 0x10FFFF
174 |             ):
175 |                 ucs4 = "u"
176 |     elif debug:
177 |         # Debug builds can also load "normal" extension modules.
178 |         # We can also assume no UCS-4 or pymalloc requirement.
179 |         abis.append(f"cp{version}{threading}")
180 |     abis.insert(0, f"cp{version}{threading}{debug}{pymalloc}{ucs4}")
181 |     return abis
182 | 
183 | 
184 | def cpython_tags(
185 |     python_version: PythonVersion | None = None,
186 |     abis: Iterable[str] | None = None,
187 |     platforms: Iterable[str] | None = None,
188 |     *,
189 |     warn: bool = False,
190 | ) -> Iterator[Tag]:
191 |     """
192 |     Yields the tags for a CPython interpreter.
193 | 
194 |     The tags consist of:
195 |     - cp<python_version>-<abi>-<platform>
196 |     - cp<python_version>-abi3-<platform>
197 |     - cp<python_version>-none-<platform>
198 |     - cp<less than python_version>-abi3-<platform>  # Older Python versions down to 3.2.
199 | 
200 |     If python_version only specifies a major version then user-provided ABIs and
201 |     the 'none' ABItag will be used.
202 | 
203 |     If 'abi3' or 'none' are specified in 'abis' then they will be yielded at
204 |     their normal position and not at the beginning.
205 |     """
206 |     if not python_version:
207 |         python_version = sys.version_info[:2]
208 | 
209 |     interpreter = f"cp{_version_nodot(python_version[:2])}"
210 | 
211 |     if abis is None:
212 |         if len(python_version) > 1:
213 |             abis = _cpython_abis(python_version, warn)
214 |         else:
215 |             abis = []
216 |     abis = list(abis)
217 |     # 'abi3' and 'none' are explicitly handled later.
218 |     for explicit_abi in ("abi3", "none"):
219 |         try:
220 |             abis.remove(explicit_abi)
221 |         except ValueError:
222 |             pass
223 | 
224 |     platforms = list(platforms or platform_tags())
225 |     for abi in abis:
226 |         for platform_ in platforms:
227 |             yield Tag(interpreter, abi, platform_)
228 | 
229 |     threading = _is_threaded_cpython(abis)
230 |     use_abi3 = _abi3_applies(python_version, threading)
231 |     if use_abi3:
232 |         yield from (Tag(interpreter, "abi3", platform_) for platform_ in platforms)
233 |     yield from (Tag(interpreter, "none", platform_) for platform_ in platforms)
234 | 
235 |     if use_abi3:
236 |         for minor_version in range(python_version[1] - 1, 1, -1):
237 |             for platform_ in platforms:
238 |                 version = _version_nodot((python_version[0], minor_version))
239 |                 interpreter = f"cp{version}"
240 |                 yield Tag(interpreter, "abi3", platform_)
241 | 
242 | 
243 | def _generic_abi() -> list[str]:
244 |     """
245 |     Return the ABI tag based on EXT_SUFFIX.
246 |     """
247 |     # The following are examples of `EXT_SUFFIX`.
248 |     # We want to keep the parts which are related to the ABI and remove the
249 |     # parts which are related to the platform:
250 |     # - linux:   '.cpython-310-x86_64-linux-gnu.so' => cp310
251 |     # - mac:     '.cpython-310-darwin.so'           => cp310
252 |     # - win:     '.cp310-win_amd64.pyd'             => cp310
253 |     # - win:     '.pyd'                             => cp37 (uses _cpython_abis())
254 |     # - pypy:    '.pypy38-pp73-x86_64-linux-gnu.so' => pypy38_pp73
255 |     # - graalpy: '.graalpy-38-native-x86_64-darwin.dylib'
256 |     #                                               => graalpy_38_native
257 | 
258 |     ext_suffix = _get_config_var("EXT_SUFFIX", warn=True)
259 |     if not isinstance(ext_suffix, str) or ext_suffix[0] != ".":
260 |         raise SystemError("invalid sysconfig.get_config_var('EXT_SUFFIX')")
261 |     parts = ext_suffix.split(".")
262 |     if len(parts) < 3:
263 |         # CPython3.7 and earlier uses ".pyd" on Windows.
264 |         return _cpython_abis(sys.version_info[:2])
265 |     soabi = parts[1]
266 |     if soabi.startswith("cpython"):
267 |         # non-windows
268 |         abi = "cp" + soabi.split("-")[1]
269 |     elif soabi.startswith("cp"):
270 |         # windows
271 |         abi = soabi.split("-")[0]
272 |     elif soabi.startswith("pypy"):
273 |         abi = "-".join(soabi.split("-")[:2])
274 |     elif soabi.startswith("graalpy"):
275 |         abi = "-".join(soabi.split("-")[:3])
276 |     elif soabi:
277 |         # pyston, ironpython, others?
278 |         abi = soabi
279 |     else:
280 |         return []
281 |     return [_normalize_string(abi)]
282 | 
283 | 
284 | def generic_tags(
285 |     interpreter: str | None = None,
286 |     abis: Iterable[str] | None = None,
287 |     platforms: Iterable[str] | None = None,
288 |     *,
289 |     warn: bool = False,
290 | ) -> Iterator[Tag]:
291 |     """
292 |     Yields the tags for a generic interpreter.
293 | 
294 |     The tags consist of:
295 |     - <interpreter>-<abi>-<platform>
296 | 
297 |     The "none" ABI will be added if it was not explicitly provided.
298 |     """
299 |     if not interpreter:
300 |         interp_name = interpreter_name()
301 |         interp_version = interpreter_version(warn=warn)
302 |         interpreter = "".join([interp_name, interp_version])
303 |     if abis is None:
304 |         abis = _generic_abi()
305 |     else:
306 |         abis = list(abis)
307 |     platforms = list(platforms or platform_tags())
308 |     if "none" not in abis:
309 |         abis.append("none")
310 |     for abi in abis:
311 |         for platform_ in platforms:
312 |             yield Tag(interpreter, abi, platform_)
313 | 
314 | 
315 | def _py_interpreter_range(py_version: PythonVersion) -> Iterator[str]:
316 |     """
317 |     Yields Python versions in descending order.
318 | 
319 |     After the latest version, the major-only version will be yielded, and then
320 |     all previous versions of that major version.
321 |     """
322 |     if len(py_version) > 1:
323 |         yield f"py{_version_nodot(py_version[:2])}"
324 |     yield f"py{py_version[0]}"
325 |     if len(py_version) > 1:
326 |         for minor in range(py_version[1] - 1, -1, -1):
327 |             yield f"py{_version_nodot((py_version[0], minor))}"
328 | 
329 | 
330 | def compatible_tags(
331 |     python_version: PythonVersion | None = None,
332 |     interpreter: str | None = None,
333 |     platforms: Iterable[str] | None = None,
334 | ) -> Iterator[Tag]:
335 |     """
336 |     Yields the sequence of tags that are compatible with a specific version of Python.
337 | 
338 |     The tags consist of:
339 |     - py*-none-<platform>
340 |     - <interpreter>-none-any  # ... if `interpreter` is provided.
341 |     - py*-none-any
342 |     """
343 |     if not python_version:
344 |         python_version = sys.version_info[:2]
[TRUNCATED]
```

.venv/lib/python3.13/site-packages/pip/_vendor/packaging/utils.py
```
1 | # This file is dual licensed under the terms of the Apache License, Version
2 | # 2.0, and the BSD License. See the LICENSE file in the root of this repository
3 | # for complete details.
4 | 
5 | from __future__ import annotations
6 | 
7 | import functools
8 | import re
9 | from typing import NewType, Tuple, Union, cast
10 | 
11 | from .tags import Tag, parse_tag
12 | from .version import InvalidVersion, Version, _TrimmedRelease
13 | 
14 | BuildTag = Union[Tuple[()], Tuple[int, str]]
15 | NormalizedName = NewType("NormalizedName", str)
16 | 
17 | 
18 | class InvalidName(ValueError):
19 |     """
20 |     An invalid distribution name; users should refer to the packaging user guide.
21 |     """
22 | 
23 | 
24 | class InvalidWheelFilename(ValueError):
25 |     """
26 |     An invalid wheel filename was found, users should refer to PEP 427.
27 |     """
28 | 
29 | 
30 | class InvalidSdistFilename(ValueError):
31 |     """
32 |     An invalid sdist filename was found, users should refer to the packaging user guide.
33 |     """
34 | 
35 | 
36 | # Core metadata spec for `Name`
37 | _validate_regex = re.compile(
38 |     r"^([A-Z0-9]|[A-Z0-9][A-Z0-9._-]*[A-Z0-9])$", re.IGNORECASE
39 | )
40 | _canonicalize_regex = re.compile(r"[-_.]+")
41 | _normalized_regex = re.compile(r"^([a-z0-9]|[a-z0-9]([a-z0-9-](?!--))*[a-z0-9])$")
42 | # PEP 427: The build number must start with a digit.
43 | _build_tag_regex = re.compile(r"(\d+)(.*)")
44 | 
45 | 
46 | def canonicalize_name(name: str, *, validate: bool = False) -> NormalizedName:
47 |     if validate and not _validate_regex.match(name):
48 |         raise InvalidName(f"name is invalid: {name!r}")
49 |     # This is taken from PEP 503.
50 |     value = _canonicalize_regex.sub("-", name).lower()
51 |     return cast(NormalizedName, value)
52 | 
53 | 
54 | def is_normalized_name(name: str) -> bool:
55 |     return _normalized_regex.match(name) is not None
56 | 
57 | 
58 | @functools.singledispatch
59 | def canonicalize_version(
60 |     version: Version | str, *, strip_trailing_zero: bool = True
61 | ) -> str:
62 |     """
63 |     Return a canonical form of a version as a string.
64 | 
65 |     >>> canonicalize_version('1.0.1')
66 |     '1.0.1'
67 | 
68 |     Per PEP 625, versions may have multiple canonical forms, differing
69 |     only by trailing zeros.
70 | 
71 |     >>> canonicalize_version('1.0.0')
72 |     '1'
73 |     >>> canonicalize_version('1.0.0', strip_trailing_zero=False)
74 |     '1.0.0'
75 | 
76 |     Invalid versions are returned unaltered.
77 | 
78 |     >>> canonicalize_version('foo bar baz')
79 |     'foo bar baz'
80 |     """
81 |     return str(_TrimmedRelease(str(version)) if strip_trailing_zero else version)
82 | 
83 | 
84 | @canonicalize_version.register
85 | def _(version: str, *, strip_trailing_zero: bool = True) -> str:
86 |     try:
87 |         parsed = Version(version)
88 |     except InvalidVersion:
89 |         # Legacy versions cannot be normalized
90 |         return version
91 |     return canonicalize_version(parsed, strip_trailing_zero=strip_trailing_zero)
92 | 
93 | 
94 | def parse_wheel_filename(
95 |     filename: str,
96 | ) -> tuple[NormalizedName, Version, BuildTag, frozenset[Tag]]:
97 |     if not filename.endswith(".whl"):
98 |         raise InvalidWheelFilename(
99 |             f"Invalid wheel filename (extension must be '.whl'): {filename!r}"
100 |         )
101 | 
102 |     filename = filename[:-4]
103 |     dashes = filename.count("-")
104 |     if dashes not in (4, 5):
105 |         raise InvalidWheelFilename(
106 |             f"Invalid wheel filename (wrong number of parts): {filename!r}"
107 |         )
108 | 
109 |     parts = filename.split("-", dashes - 2)
110 |     name_part = parts[0]
111 |     # See PEP 427 for the rules on escaping the project name.
112 |     if "__" in name_part or re.match(r"^[\w\d._]*$", name_part, re.UNICODE) is None:
113 |         raise InvalidWheelFilename(f"Invalid project name: {filename!r}")
114 |     name = canonicalize_name(name_part)
115 | 
116 |     try:
117 |         version = Version(parts[1])
118 |     except InvalidVersion as e:
119 |         raise InvalidWheelFilename(
120 |             f"Invalid wheel filename (invalid version): {filename!r}"
121 |         ) from e
122 | 
123 |     if dashes == 5:
124 |         build_part = parts[2]
125 |         build_match = _build_tag_regex.match(build_part)
126 |         if build_match is None:
127 |             raise InvalidWheelFilename(
128 |                 f"Invalid build number: {build_part} in {filename!r}"
129 |             )
130 |         build = cast(BuildTag, (int(build_match.group(1)), build_match.group(2)))
131 |     else:
132 |         build = ()
133 |     tags = parse_tag(parts[-1])
134 |     return (name, version, build, tags)
135 | 
136 | 
137 | def parse_sdist_filename(filename: str) -> tuple[NormalizedName, Version]:
138 |     if filename.endswith(".tar.gz"):
139 |         file_stem = filename[: -len(".tar.gz")]
140 |     elif filename.endswith(".zip"):
141 |         file_stem = filename[: -len(".zip")]
142 |     else:
143 |         raise InvalidSdistFilename(
144 |             f"Invalid sdist filename (extension must be '.tar.gz' or '.zip'):"
145 |             f" {filename!r}"
146 |         )
147 | 
148 |     # We are requiring a PEP 440 version, which cannot contain dashes,
149 |     # so we split on the last dash.
150 |     name_part, sep, version_part = file_stem.rpartition("-")
151 |     if not sep:
152 |         raise InvalidSdistFilename(f"Invalid sdist filename: {filename!r}")
153 | 
154 |     name = canonicalize_name(name_part)
155 | 
156 |     try:
157 |         version = Version(version_part)
158 |     except InvalidVersion as e:
159 |         raise InvalidSdistFilename(
160 |             f"Invalid sdist filename (invalid version): {filename!r}"
161 |         ) from e
162 | 
163 |     return (name, version)
```

.venv/lib/python3.13/site-packages/pip/_vendor/packaging/version.py
```
1 | # This file is dual licensed under the terms of the Apache License, Version
2 | # 2.0, and the BSD License. See the LICENSE file in the root of this repository
3 | # for complete details.
4 | """
5 | .. testsetup::
6 | 
7 |     from pip._vendor.packaging.version import parse, Version
8 | """
9 | 
10 | from __future__ import annotations
11 | 
12 | import itertools
13 | import re
14 | from typing import Any, Callable, NamedTuple, SupportsInt, Tuple, Union
15 | 
16 | from ._structures import Infinity, InfinityType, NegativeInfinity, NegativeInfinityType
17 | 
18 | __all__ = ["VERSION_PATTERN", "InvalidVersion", "Version", "parse"]
19 | 
20 | LocalType = Tuple[Union[int, str], ...]
21 | 
22 | CmpPrePostDevType = Union[InfinityType, NegativeInfinityType, Tuple[str, int]]
23 | CmpLocalType = Union[
24 |     NegativeInfinityType,
25 |     Tuple[Union[Tuple[int, str], Tuple[NegativeInfinityType, Union[int, str]]], ...],
26 | ]
27 | CmpKey = Tuple[
28 |     int,
29 |     Tuple[int, ...],
30 |     CmpPrePostDevType,
31 |     CmpPrePostDevType,
32 |     CmpPrePostDevType,
33 |     CmpLocalType,
34 | ]
35 | VersionComparisonMethod = Callable[[CmpKey, CmpKey], bool]
36 | 
37 | 
38 | class _Version(NamedTuple):
39 |     epoch: int
40 |     release: tuple[int, ...]
41 |     dev: tuple[str, int] | None
42 |     pre: tuple[str, int] | None
43 |     post: tuple[str, int] | None
44 |     local: LocalType | None
45 | 
46 | 
47 | def parse(version: str) -> Version:
48 |     """Parse the given version string.
49 | 
50 |     >>> parse('1.0.dev1')
51 |     <Version('1.0.dev1')>
52 | 
53 |     :param version: The version string to parse.
54 |     :raises InvalidVersion: When the version string is not a valid version.
55 |     """
56 |     return Version(version)
57 | 
58 | 
59 | class InvalidVersion(ValueError):
60 |     """Raised when a version string is not a valid version.
61 | 
62 |     >>> Version("invalid")
63 |     Traceback (most recent call last):
64 |         ...
65 |     packaging.version.InvalidVersion: Invalid version: 'invalid'
66 |     """
67 | 
68 | 
69 | class _BaseVersion:
70 |     _key: tuple[Any, ...]
71 | 
72 |     def __hash__(self) -> int:
73 |         return hash(self._key)
74 | 
75 |     # Please keep the duplicated `isinstance` check
76 |     # in the six comparisons hereunder
77 |     # unless you find a way to avoid adding overhead function calls.
78 |     def __lt__(self, other: _BaseVersion) -> bool:
79 |         if not isinstance(other, _BaseVersion):
80 |             return NotImplemented
81 | 
82 |         return self._key < other._key
83 | 
84 |     def __le__(self, other: _BaseVersion) -> bool:
85 |         if not isinstance(other, _BaseVersion):
86 |             return NotImplemented
87 | 
88 |         return self._key <= other._key
89 | 
90 |     def __eq__(self, other: object) -> bool:
91 |         if not isinstance(other, _BaseVersion):
92 |             return NotImplemented
93 | 
94 |         return self._key == other._key
95 | 
96 |     def __ge__(self, other: _BaseVersion) -> bool:
97 |         if not isinstance(other, _BaseVersion):
98 |             return NotImplemented
99 | 
100 |         return self._key >= other._key
101 | 
102 |     def __gt__(self, other: _BaseVersion) -> bool:
103 |         if not isinstance(other, _BaseVersion):
104 |             return NotImplemented
105 | 
106 |         return self._key > other._key
107 | 
108 |     def __ne__(self, other: object) -> bool:
109 |         if not isinstance(other, _BaseVersion):
110 |             return NotImplemented
111 | 
112 |         return self._key != other._key
113 | 
114 | 
115 | # Deliberately not anchored to the start and end of the string, to make it
116 | # easier for 3rd party code to reuse
117 | _VERSION_PATTERN = r"""
118 |     v?
119 |     (?:
120 |         (?:(?P<epoch>[0-9]+)!)?                           # epoch
121 |         (?P<release>[0-9]+(?:\.[0-9]+)*)                  # release segment
122 |         (?P<pre>                                          # pre-release
123 |             [-_\.]?
124 |             (?P<pre_l>alpha|a|beta|b|preview|pre|c|rc)
125 |             [-_\.]?
126 |             (?P<pre_n>[0-9]+)?
127 |         )?
128 |         (?P<post>                                         # post release
129 |             (?:-(?P<post_n1>[0-9]+))
130 |             |
131 |             (?:
132 |                 [-_\.]?
133 |                 (?P<post_l>post|rev|r)
134 |                 [-_\.]?
135 |                 (?P<post_n2>[0-9]+)?
136 |             )
137 |         )?
138 |         (?P<dev>                                          # dev release
139 |             [-_\.]?
140 |             (?P<dev_l>dev)
141 |             [-_\.]?
142 |             (?P<dev_n>[0-9]+)?
143 |         )?
144 |     )
145 |     (?:\+(?P<local>[a-z0-9]+(?:[-_\.][a-z0-9]+)*))?       # local version
146 | """
147 | 
148 | VERSION_PATTERN = _VERSION_PATTERN
149 | """
150 | A string containing the regular expression used to match a valid version.
151 | 
152 | The pattern is not anchored at either end, and is intended for embedding in larger
153 | expressions (for example, matching a version number as part of a file name). The
154 | regular expression should be compiled with the ``re.VERBOSE`` and ``re.IGNORECASE``
155 | flags set.
156 | 
157 | :meta hide-value:
158 | """
159 | 
160 | 
161 | class Version(_BaseVersion):
162 |     """This class abstracts handling of a project's versions.
163 | 
164 |     A :class:`Version` instance is comparison aware and can be compared and
165 |     sorted using the standard Python interfaces.
166 | 
167 |     >>> v1 = Version("1.0a5")
168 |     >>> v2 = Version("1.0")
169 |     >>> v1
170 |     <Version('1.0a5')>
171 |     >>> v2
172 |     <Version('1.0')>
173 |     >>> v1 < v2
174 |     True
175 |     >>> v1 == v2
176 |     False
177 |     >>> v1 > v2
178 |     False
179 |     >>> v1 >= v2
180 |     False
181 |     >>> v1 <= v2
182 |     True
183 |     """
184 | 
185 |     _regex = re.compile(r"^\s*" + VERSION_PATTERN + r"\s*$", re.VERBOSE | re.IGNORECASE)
186 |     _key: CmpKey
187 | 
188 |     def __init__(self, version: str) -> None:
189 |         """Initialize a Version object.
190 | 
191 |         :param version:
192 |             The string representation of a version which will be parsed and normalized
193 |             before use.
194 |         :raises InvalidVersion:
195 |             If the ``version`` does not conform to PEP 440 in any way then this
196 |             exception will be raised.
197 |         """
198 | 
199 |         # Validate the version and parse it into pieces
200 |         match = self._regex.search(version)
201 |         if not match:
202 |             raise InvalidVersion(f"Invalid version: {version!r}")
203 | 
204 |         # Store the parsed out pieces of the version
205 |         self._version = _Version(
206 |             epoch=int(match.group("epoch")) if match.group("epoch") else 0,
207 |             release=tuple(int(i) for i in match.group("release").split(".")),
208 |             pre=_parse_letter_version(match.group("pre_l"), match.group("pre_n")),
209 |             post=_parse_letter_version(
210 |                 match.group("post_l"), match.group("post_n1") or match.group("post_n2")
211 |             ),
212 |             dev=_parse_letter_version(match.group("dev_l"), match.group("dev_n")),
213 |             local=_parse_local_version(match.group("local")),
214 |         )
215 | 
216 |         # Generate a key which will be used for sorting
217 |         self._key = _cmpkey(
218 |             self._version.epoch,
219 |             self._version.release,
220 |             self._version.pre,
221 |             self._version.post,
222 |             self._version.dev,
223 |             self._version.local,
224 |         )
225 | 
226 |     def __repr__(self) -> str:
227 |         """A representation of the Version that shows all internal state.
228 | 
229 |         >>> Version('1.0.0')
230 |         <Version('1.0.0')>
231 |         """
232 |         return f"<Version('{self}')>"
233 | 
234 |     def __str__(self) -> str:
235 |         """A string representation of the version that can be round-tripped.
236 | 
237 |         >>> str(Version("1.0a5"))
238 |         '1.0a5'
239 |         """
240 |         parts = []
241 | 
242 |         # Epoch
243 |         if self.epoch != 0:
244 |             parts.append(f"{self.epoch}!")
245 | 
246 |         # Release segment
247 |         parts.append(".".join(str(x) for x in self.release))
248 | 
249 |         # Pre-release
250 |         if self.pre is not None:
251 |             parts.append("".join(str(x) for x in self.pre))
252 | 
253 |         # Post-release
254 |         if self.post is not None:
255 |             parts.append(f".post{self.post}")
256 | 
257 |         # Development release
258 |         if self.dev is not None:
259 |             parts.append(f".dev{self.dev}")
260 | 
261 |         # Local version segment
262 |         if self.local is not None:
263 |             parts.append(f"+{self.local}")
264 | 
265 |         return "".join(parts)
266 | 
267 |     @property
268 |     def epoch(self) -> int:
269 |         """The epoch of the version.
270 | 
271 |         >>> Version("2.0.0").epoch
272 |         0
273 |         >>> Version("1!2.0.0").epoch
274 |         1
275 |         """
276 |         return self._version.epoch
277 | 
278 |     @property
279 |     def release(self) -> tuple[int, ...]:
280 |         """The components of the "release" segment of the version.
281 | 
282 |         >>> Version("1.2.3").release
283 |         (1, 2, 3)
284 |         >>> Version("2.0.0").release
285 |         (2, 0, 0)
286 |         >>> Version("1!2.0.0.post0").release
287 |         (2, 0, 0)
288 | 
289 |         Includes trailing zeroes but not the epoch or any pre-release / development /
290 |         post-release suffixes.
291 |         """
292 |         return self._version.release
293 | 
294 |     @property
295 |     def pre(self) -> tuple[str, int] | None:
296 |         """The pre-release segment of the version.
297 | 
298 |         >>> print(Version("1.2.3").pre)
299 |         None
300 |         >>> Version("1.2.3a1").pre
301 |         ('a', 1)
302 |         >>> Version("1.2.3b1").pre
303 |         ('b', 1)
304 |         >>> Version("1.2.3rc1").pre
305 |         ('rc', 1)
306 |         """
307 |         return self._version.pre
308 | 
309 |     @property
310 |     def post(self) -> int | None:
311 |         """The post-release number of the version.
312 | 
313 |         >>> print(Version("1.2.3").post)
314 |         None
315 |         >>> Version("1.2.3.post1").post
316 |         1
317 |         """
318 |         return self._version.post[1] if self._version.post else None
319 | 
320 |     @property
321 |     def dev(self) -> int | None:
322 |         """The development number of the version.
323 | 
324 |         >>> print(Version("1.2.3").dev)
325 |         None
326 |         >>> Version("1.2.3.dev1").dev
327 |         1
328 |         """
329 |         return self._version.dev[1] if self._version.dev else None
330 | 
331 |     @property
332 |     def local(self) -> str | None:
333 |         """The local version segment of the version.
334 | 
335 |         >>> print(Version("1.2.3").local)
336 |         None
337 |         >>> Version("1.2.3+abc").local
338 |         'abc'
339 |         """
340 |         if self._version.local:
341 |             return ".".join(str(x) for x in self._version.local)
342 |         else:
343 |             return None
344 | 
345 |     @property
346 |     def public(self) -> str:
347 |         """The public portion of the version.
348 | 
349 |         >>> Version("1.2.3").public
350 |         '1.2.3'
351 |         >>> Version("1.2.3+abc").public
352 |         '1.2.3'
353 |         >>> Version("1!1.2.3dev1+abc").public
354 |         '1!1.2.3.dev1'
355 |         """
356 |         return str(self).split("+", 1)[0]
357 | 
358 |     @property
359 |     def base_version(self) -> str:
360 |         """The "base version" of the version.
361 | 
362 |         >>> Version("1.2.3").base_version
363 |         '1.2.3'
364 |         >>> Version("1.2.3+abc").base_version
365 |         '1.2.3'
366 |         >>> Version("1!1.2.3dev1+abc").base_version
367 |         '1!1.2.3'
368 | 
369 |         The "base version" is the public version of the project without any pre or post
370 |         release markers.
371 |         """
372 |         parts = []
373 | 
374 |         # Epoch
375 |         if self.epoch != 0:
376 |             parts.append(f"{self.epoch}!")
377 | 
378 |         # Release segment
379 |         parts.append(".".join(str(x) for x in self.release))
380 | 
381 |         return "".join(parts)
382 | 
383 |     @property
384 |     def is_prerelease(self) -> bool:
385 |         """Whether this version is a pre-release.
386 | 
387 |         >>> Version("1.2.3").is_prerelease
388 |         False
389 |         >>> Version("1.2.3a1").is_prerelease
390 |         True
391 |         >>> Version("1.2.3b1").is_prerelease
392 |         True
393 |         >>> Version("1.2.3rc1").is_prerelease
394 |         True
395 |         >>> Version("1.2.3dev1").is_prerelease
396 |         True
397 |         """
398 |         return self.dev is not None or self.pre is not None
399 | 
400 |     @property
401 |     def is_postrelease(self) -> bool:
402 |         """Whether this version is a post-release.
[TRUNCATED]
```

.venv/lib/python3.13/site-packages/pip/_vendor/idna/__init__.py
```
1 | from .core import (
2 |     IDNABidiError,
3 |     IDNAError,
4 |     InvalidCodepoint,
5 |     InvalidCodepointContext,
6 |     alabel,
7 |     check_bidi,
8 |     check_hyphen_ok,
9 |     check_initial_combiner,
10 |     check_label,
11 |     check_nfc,
12 |     decode,
13 |     encode,
14 |     ulabel,
15 |     uts46_remap,
16 |     valid_contextj,
17 |     valid_contexto,
18 |     valid_label_length,
19 |     valid_string_length,
20 | )
21 | from .intranges import intranges_contain
22 | from .package_data import __version__
23 | 
24 | __all__ = [
25 |     "__version__",
26 |     "IDNABidiError",
27 |     "IDNAError",
28 |     "InvalidCodepoint",
29 |     "InvalidCodepointContext",
30 |     "alabel",
31 |     "check_bidi",
32 |     "check_hyphen_ok",
33 |     "check_initial_combiner",
34 |     "check_label",
35 |     "check_nfc",
36 |     "decode",
37 |     "encode",
38 |     "intranges_contain",
39 |     "ulabel",
40 |     "uts46_remap",
41 |     "valid_contextj",
42 |     "valid_contexto",
43 |     "valid_label_length",
44 |     "valid_string_length",
45 | ]
```

.venv/lib/python3.13/site-packages/pip/_vendor/idna/codec.py
```
1 | import codecs
2 | import re
3 | from typing import Any, Optional, Tuple
4 | 
5 | from .core import IDNAError, alabel, decode, encode, ulabel
6 | 
7 | _unicode_dots_re = re.compile("[\u002e\u3002\uff0e\uff61]")
8 | 
9 | 
10 | class Codec(codecs.Codec):
11 |     def encode(self, data: str, errors: str = "strict") -> Tuple[bytes, int]:
12 |         if errors != "strict":
13 |             raise IDNAError('Unsupported error handling "{}"'.format(errors))
14 | 
15 |         if not data:
16 |             return b"", 0
17 | 
18 |         return encode(data), len(data)
19 | 
20 |     def decode(self, data: bytes, errors: str = "strict") -> Tuple[str, int]:
21 |         if errors != "strict":
22 |             raise IDNAError('Unsupported error handling "{}"'.format(errors))
23 | 
24 |         if not data:
25 |             return "", 0
26 | 
27 |         return decode(data), len(data)
28 | 
29 | 
30 | class IncrementalEncoder(codecs.BufferedIncrementalEncoder):
31 |     def _buffer_encode(self, data: str, errors: str, final: bool) -> Tuple[bytes, int]:
32 |         if errors != "strict":
33 |             raise IDNAError('Unsupported error handling "{}"'.format(errors))
34 | 
35 |         if not data:
36 |             return b"", 0
37 | 
38 |         labels = _unicode_dots_re.split(data)
39 |         trailing_dot = b""
40 |         if labels:
41 |             if not labels[-1]:
42 |                 trailing_dot = b"."
43 |                 del labels[-1]
44 |             elif not final:
45 |                 # Keep potentially unfinished label until the next call
46 |                 del labels[-1]
47 |                 if labels:
48 |                     trailing_dot = b"."
49 | 
50 |         result = []
51 |         size = 0
52 |         for label in labels:
53 |             result.append(alabel(label))
54 |             if size:
55 |                 size += 1
56 |             size += len(label)
57 | 
58 |         # Join with U+002E
59 |         result_bytes = b".".join(result) + trailing_dot
60 |         size += len(trailing_dot)
61 |         return result_bytes, size
62 | 
63 | 
64 | class IncrementalDecoder(codecs.BufferedIncrementalDecoder):
65 |     def _buffer_decode(self, data: Any, errors: str, final: bool) -> Tuple[str, int]:
66 |         if errors != "strict":
67 |             raise IDNAError('Unsupported error handling "{}"'.format(errors))
68 | 
69 |         if not data:
70 |             return ("", 0)
71 | 
72 |         if not isinstance(data, str):
73 |             data = str(data, "ascii")
74 | 
75 |         labels = _unicode_dots_re.split(data)
76 |         trailing_dot = ""
77 |         if labels:
78 |             if not labels[-1]:
79 |                 trailing_dot = "."
80 |                 del labels[-1]
81 |             elif not final:
82 |                 # Keep potentially unfinished label until the next call
83 |                 del labels[-1]
84 |                 if labels:
85 |                     trailing_dot = "."
86 | 
87 |         result = []
88 |         size = 0
89 |         for label in labels:
90 |             result.append(ulabel(label))
91 |             if size:
92 |                 size += 1
93 |             size += len(label)
94 | 
95 |         result_str = ".".join(result) + trailing_dot
96 |         size += len(trailing_dot)
97 |         return (result_str, size)
98 | 
99 | 
100 | class StreamWriter(Codec, codecs.StreamWriter):
101 |     pass
102 | 
103 | 
104 | class StreamReader(Codec, codecs.StreamReader):
105 |     pass
106 | 
107 | 
108 | def search_function(name: str) -> Optional[codecs.CodecInfo]:
109 |     if name != "idna2008":
110 |         return None
111 |     return codecs.CodecInfo(
112 |         name=name,
113 |         encode=Codec().encode,
114 |         decode=Codec().decode,
115 |         incrementalencoder=IncrementalEncoder,
116 |         incrementaldecoder=IncrementalDecoder,
117 |         streamwriter=StreamWriter,
118 |         streamreader=StreamReader,
119 |     )
120 | 
121 | 
122 | codecs.register(search_function)
```

.venv/lib/python3.13/site-packages/pip/_vendor/idna/compat.py
```
1 | from typing import Any, Union
2 | 
3 | from .core import decode, encode
4 | 
5 | 
6 | def ToASCII(label: str) -> bytes:
7 |     return encode(label)
8 | 
9 | 
10 | def ToUnicode(label: Union[bytes, bytearray]) -> str:
11 |     return decode(label)
12 | 
13 | 
14 | def nameprep(s: Any) -> None:
15 |     raise NotImplementedError("IDNA 2008 does not utilise nameprep protocol")
```

.venv/lib/python3.13/site-packages/pip/_vendor/idna/core.py
```
1 | import bisect
2 | import re
3 | import unicodedata
4 | from typing import Optional, Union
5 | 
6 | from . import idnadata
7 | from .intranges import intranges_contain
8 | 
9 | _virama_combining_class = 9
10 | _alabel_prefix = b"xn--"
11 | _unicode_dots_re = re.compile("[\u002e\u3002\uff0e\uff61]")
12 | 
13 | 
14 | class IDNAError(UnicodeError):
15 |     """Base exception for all IDNA-encoding related problems"""
16 | 
17 |     pass
18 | 
19 | 
20 | class IDNABidiError(IDNAError):
21 |     """Exception when bidirectional requirements are not satisfied"""
22 | 
23 |     pass
24 | 
25 | 
26 | class InvalidCodepoint(IDNAError):
27 |     """Exception when a disallowed or unallocated codepoint is used"""
28 | 
29 |     pass
30 | 
31 | 
32 | class InvalidCodepointContext(IDNAError):
33 |     """Exception when the codepoint is not valid in the context it is used"""
34 | 
35 |     pass
36 | 
37 | 
38 | def _combining_class(cp: int) -> int:
39 |     v = unicodedata.combining(chr(cp))
40 |     if v == 0:
41 |         if not unicodedata.name(chr(cp)):
42 |             raise ValueError("Unknown character in unicodedata")
43 |     return v
44 | 
45 | 
46 | def _is_script(cp: str, script: str) -> bool:
47 |     return intranges_contain(ord(cp), idnadata.scripts[script])
48 | 
49 | 
50 | def _punycode(s: str) -> bytes:
51 |     return s.encode("punycode")
52 | 
53 | 
54 | def _unot(s: int) -> str:
55 |     return "U+{:04X}".format(s)
56 | 
57 | 
58 | def valid_label_length(label: Union[bytes, str]) -> bool:
59 |     if len(label) > 63:
60 |         return False
61 |     return True
62 | 
63 | 
64 | def valid_string_length(label: Union[bytes, str], trailing_dot: bool) -> bool:
65 |     if len(label) > (254 if trailing_dot else 253):
66 |         return False
67 |     return True
68 | 
69 | 
70 | def check_bidi(label: str, check_ltr: bool = False) -> bool:
71 |     # Bidi rules should only be applied if string contains RTL characters
72 |     bidi_label = False
73 |     for idx, cp in enumerate(label, 1):
74 |         direction = unicodedata.bidirectional(cp)
75 |         if direction == "":
76 |             # String likely comes from a newer version of Unicode
77 |             raise IDNABidiError("Unknown directionality in label {} at position {}".format(repr(label), idx))
78 |         if direction in ["R", "AL", "AN"]:
79 |             bidi_label = True
80 |     if not bidi_label and not check_ltr:
81 |         return True
82 | 
83 |     # Bidi rule 1
84 |     direction = unicodedata.bidirectional(label[0])
85 |     if direction in ["R", "AL"]:
86 |         rtl = True
87 |     elif direction == "L":
88 |         rtl = False
89 |     else:
90 |         raise IDNABidiError("First codepoint in label {} must be directionality L, R or AL".format(repr(label)))
91 | 
92 |     valid_ending = False
93 |     number_type: Optional[str] = None
94 |     for idx, cp in enumerate(label, 1):
95 |         direction = unicodedata.bidirectional(cp)
96 | 
97 |         if rtl:
98 |             # Bidi rule 2
99 |             if direction not in [
100 |                 "R",
101 |                 "AL",
102 |                 "AN",
103 |                 "EN",
104 |                 "ES",
105 |                 "CS",
106 |                 "ET",
107 |                 "ON",
108 |                 "BN",
109 |                 "NSM",
110 |             ]:
111 |                 raise IDNABidiError("Invalid direction for codepoint at position {} in a right-to-left label".format(idx))
112 |             # Bidi rule 3
113 |             if direction in ["R", "AL", "EN", "AN"]:
114 |                 valid_ending = True
115 |             elif direction != "NSM":
116 |                 valid_ending = False
117 |             # Bidi rule 4
118 |             if direction in ["AN", "EN"]:
119 |                 if not number_type:
120 |                     number_type = direction
121 |                 else:
122 |                     if number_type != direction:
123 |                         raise IDNABidiError("Can not mix numeral types in a right-to-left label")
124 |         else:
125 |             # Bidi rule 5
126 |             if direction not in ["L", "EN", "ES", "CS", "ET", "ON", "BN", "NSM"]:
127 |                 raise IDNABidiError("Invalid direction for codepoint at position {} in a left-to-right label".format(idx))
128 |             # Bidi rule 6
129 |             if direction in ["L", "EN"]:
130 |                 valid_ending = True
131 |             elif direction != "NSM":
132 |                 valid_ending = False
133 | 
134 |     if not valid_ending:
135 |         raise IDNABidiError("Label ends with illegal codepoint directionality")
136 | 
137 |     return True
138 | 
139 | 
140 | def check_initial_combiner(label: str) -> bool:
141 |     if unicodedata.category(label[0])[0] == "M":
142 |         raise IDNAError("Label begins with an illegal combining character")
143 |     return True
144 | 
145 | 
146 | def check_hyphen_ok(label: str) -> bool:
147 |     if label[2:4] == "--":
148 |         raise IDNAError("Label has disallowed hyphens in 3rd and 4th position")
149 |     if label[0] == "-" or label[-1] == "-":
150 |         raise IDNAError("Label must not start or end with a hyphen")
151 |     return True
152 | 
153 | 
154 | def check_nfc(label: str) -> None:
155 |     if unicodedata.normalize("NFC", label) != label:
156 |         raise IDNAError("Label must be in Normalization Form C")
157 | 
158 | 
159 | def valid_contextj(label: str, pos: int) -> bool:
160 |     cp_value = ord(label[pos])
161 | 
162 |     if cp_value == 0x200C:
163 |         if pos > 0:
164 |             if _combining_class(ord(label[pos - 1])) == _virama_combining_class:
165 |                 return True
166 | 
167 |         ok = False
168 |         for i in range(pos - 1, -1, -1):
169 |             joining_type = idnadata.joining_types.get(ord(label[i]))
170 |             if joining_type == ord("T"):
171 |                 continue
172 |             elif joining_type in [ord("L"), ord("D")]:
173 |                 ok = True
174 |                 break
175 |             else:
176 |                 break
177 | 
178 |         if not ok:
179 |             return False
180 | 
181 |         ok = False
182 |         for i in range(pos + 1, len(label)):
183 |             joining_type = idnadata.joining_types.get(ord(label[i]))
184 |             if joining_type == ord("T"):
185 |                 continue
186 |             elif joining_type in [ord("R"), ord("D")]:
187 |                 ok = True
188 |                 break
189 |             else:
190 |                 break
191 |         return ok
192 | 
193 |     if cp_value == 0x200D:
194 |         if pos > 0:
195 |             if _combining_class(ord(label[pos - 1])) == _virama_combining_class:
196 |                 return True
197 |         return False
198 | 
199 |     else:
200 |         return False
201 | 
202 | 
203 | def valid_contexto(label: str, pos: int, exception: bool = False) -> bool:
204 |     cp_value = ord(label[pos])
205 | 
206 |     if cp_value == 0x00B7:
207 |         if 0 < pos < len(label) - 1:
208 |             if ord(label[pos - 1]) == 0x006C and ord(label[pos + 1]) == 0x006C:
209 |                 return True
210 |         return False
211 | 
212 |     elif cp_value == 0x0375:
213 |         if pos < len(label) - 1 and len(label) > 1:
214 |             return _is_script(label[pos + 1], "Greek")
215 |         return False
216 | 
217 |     elif cp_value == 0x05F3 or cp_value == 0x05F4:
218 |         if pos > 0:
219 |             return _is_script(label[pos - 1], "Hebrew")
220 |         return False
221 | 
222 |     elif cp_value == 0x30FB:
223 |         for cp in label:
224 |             if cp == "\u30fb":
225 |                 continue
226 |             if _is_script(cp, "Hiragana") or _is_script(cp, "Katakana") or _is_script(cp, "Han"):
227 |                 return True
228 |         return False
229 | 
230 |     elif 0x660 <= cp_value <= 0x669:
231 |         for cp in label:
232 |             if 0x6F0 <= ord(cp) <= 0x06F9:
233 |                 return False
234 |         return True
235 | 
236 |     elif 0x6F0 <= cp_value <= 0x6F9:
237 |         for cp in label:
238 |             if 0x660 <= ord(cp) <= 0x0669:
239 |                 return False
240 |         return True
241 | 
242 |     return False
243 | 
244 | 
245 | def check_label(label: Union[str, bytes, bytearray]) -> None:
246 |     if isinstance(label, (bytes, bytearray)):
247 |         label = label.decode("utf-8")
248 |     if len(label) == 0:
249 |         raise IDNAError("Empty Label")
250 | 
251 |     check_nfc(label)
252 |     check_hyphen_ok(label)
253 |     check_initial_combiner(label)
254 | 
255 |     for pos, cp in enumerate(label):
256 |         cp_value = ord(cp)
257 |         if intranges_contain(cp_value, idnadata.codepoint_classes["PVALID"]):
258 |             continue
259 |         elif intranges_contain(cp_value, idnadata.codepoint_classes["CONTEXTJ"]):
260 |             try:
261 |                 if not valid_contextj(label, pos):
262 |                     raise InvalidCodepointContext(
263 |                         "Joiner {} not allowed at position {} in {}".format(_unot(cp_value), pos + 1, repr(label))
264 |                     )
265 |             except ValueError:
266 |                 raise IDNAError(
267 |                     "Unknown codepoint adjacent to joiner {} at position {} in {}".format(
268 |                         _unot(cp_value), pos + 1, repr(label)
269 |                     )
270 |                 )
271 |         elif intranges_contain(cp_value, idnadata.codepoint_classes["CONTEXTO"]):
272 |             if not valid_contexto(label, pos):
273 |                 raise InvalidCodepointContext(
274 |                     "Codepoint {} not allowed at position {} in {}".format(_unot(cp_value), pos + 1, repr(label))
275 |                 )
276 |         else:
277 |             raise InvalidCodepoint(
278 |                 "Codepoint {} at position {} of {} not allowed".format(_unot(cp_value), pos + 1, repr(label))
279 |             )
280 | 
281 |     check_bidi(label)
282 | 
283 | 
284 | def alabel(label: str) -> bytes:
285 |     try:
286 |         label_bytes = label.encode("ascii")
287 |         ulabel(label_bytes)
288 |         if not valid_label_length(label_bytes):
289 |             raise IDNAError("Label too long")
290 |         return label_bytes
291 |     except UnicodeEncodeError:
292 |         pass
293 | 
294 |     check_label(label)
295 |     label_bytes = _alabel_prefix + _punycode(label)
296 | 
297 |     if not valid_label_length(label_bytes):
298 |         raise IDNAError("Label too long")
299 | 
300 |     return label_bytes
301 | 
302 | 
303 | def ulabel(label: Union[str, bytes, bytearray]) -> str:
304 |     if not isinstance(label, (bytes, bytearray)):
305 |         try:
306 |             label_bytes = label.encode("ascii")
307 |         except UnicodeEncodeError:
308 |             check_label(label)
309 |             return label
310 |     else:
311 |         label_bytes = label
312 | 
313 |     label_bytes = label_bytes.lower()
314 |     if label_bytes.startswith(_alabel_prefix):
315 |         label_bytes = label_bytes[len(_alabel_prefix) :]
316 |         if not label_bytes:
317 |             raise IDNAError("Malformed A-label, no Punycode eligible content found")
318 |         if label_bytes.decode("ascii")[-1] == "-":
319 |             raise IDNAError("A-label must not end with a hyphen")
320 |     else:
321 |         check_label(label_bytes)
322 |         return label_bytes.decode("ascii")
323 | 
324 |     try:
325 |         label = label_bytes.decode("punycode")
326 |     except UnicodeError:
327 |         raise IDNAError("Invalid A-label")
328 |     check_label(label)
329 |     return label
330 | 
331 | 
332 | def uts46_remap(domain: str, std3_rules: bool = True, transitional: bool = False) -> str:
333 |     """Re-map the characters in the string according to UTS46 processing."""
334 |     from .uts46data import uts46data
335 | 
336 |     output = ""
337 | 
338 |     for pos, char in enumerate(domain):
339 |         code_point = ord(char)
340 |         try:
341 |             uts46row = uts46data[code_point if code_point < 256 else bisect.bisect_left(uts46data, (code_point, "Z")) - 1]
342 |             status = uts46row[1]
343 |             replacement: Optional[str] = None
344 |             if len(uts46row) == 3:
345 |                 replacement = uts46row[2]
346 |             if (
347 |                 status == "V"
348 |                 or (status == "D" and not transitional)
349 |                 or (status == "3" and not std3_rules and replacement is None)
350 |             ):
351 |                 output += char
352 |             elif replacement is not None and (
353 |                 status == "M" or (status == "3" and not std3_rules) or (status == "D" and transitional)
354 |             ):
355 |                 output += replacement
356 |             elif status != "I":
357 |                 raise IndexError()
358 |         except IndexError:
359 |             raise InvalidCodepoint(
360 |                 "Codepoint {} not allowed at position {} in {}".format(_unot(code_point), pos + 1, repr(domain))
361 |             )
362 | 
363 |     return unicodedata.normalize("NFC", output)
364 | 
365 | 
366 | def encode(
367 |     s: Union[str, bytes, bytearray],
368 |     strict: bool = False,
369 |     uts46: bool = False,
370 |     std3_rules: bool = False,
371 |     transitional: bool = False,
372 | ) -> bytes:
373 |     if not isinstance(s, str):
374 |         try:
375 |             s = str(s, "ascii")
376 |         except UnicodeDecodeError:
[TRUNCATED]
```

.venv/lib/python3.13/site-packages/pip/_vendor/idna/idnadata.py
```
1 | # This file is automatically generated by tools/idna-data
2 | 
3 | __version__ = "15.1.0"
4 | scripts = {
5 |     "Greek": (
6 |         0x37000000374,
7 |         0x37500000378,
8 |         0x37A0000037E,
9 |         0x37F00000380,
10 |         0x38400000385,
11 |         0x38600000387,
12 |         0x3880000038B,
13 |         0x38C0000038D,
14 |         0x38E000003A2,
15 |         0x3A3000003E2,
16 |         0x3F000000400,
17 |         0x1D2600001D2B,
18 |         0x1D5D00001D62,
19 |         0x1D6600001D6B,
20 |         0x1DBF00001DC0,
21 |         0x1F0000001F16,
22 |         0x1F1800001F1E,
23 |         0x1F2000001F46,
24 |         0x1F4800001F4E,
25 |         0x1F5000001F58,
26 |         0x1F5900001F5A,
27 |         0x1F5B00001F5C,
28 |         0x1F5D00001F5E,
29 |         0x1F5F00001F7E,
30 |         0x1F8000001FB5,
31 |         0x1FB600001FC5,
32 |         0x1FC600001FD4,
33 |         0x1FD600001FDC,
34 |         0x1FDD00001FF0,
35 |         0x1FF200001FF5,
36 |         0x1FF600001FFF,
37 |         0x212600002127,
38 |         0xAB650000AB66,
39 |         0x101400001018F,
40 |         0x101A0000101A1,
41 |         0x1D2000001D246,
42 |     ),
43 |     "Han": (
44 |         0x2E8000002E9A,
45 |         0x2E9B00002EF4,
46 |         0x2F0000002FD6,
47 |         0x300500003006,
48 |         0x300700003008,
49 |         0x30210000302A,
50 |         0x30380000303C,
51 |         0x340000004DC0,
52 |         0x4E000000A000,
53 |         0xF9000000FA6E,
54 |         0xFA700000FADA,
55 |         0x16FE200016FE4,
56 |         0x16FF000016FF2,
57 |         0x200000002A6E0,
58 |         0x2A7000002B73A,
59 |         0x2B7400002B81E,
60 |         0x2B8200002CEA2,
61 |         0x2CEB00002EBE1,
62 |         0x2EBF00002EE5E,
63 |         0x2F8000002FA1E,
64 |         0x300000003134B,
65 |         0x31350000323B0,
66 |     ),
67 |     "Hebrew": (
68 |         0x591000005C8,
69 |         0x5D0000005EB,
70 |         0x5EF000005F5,
71 |         0xFB1D0000FB37,
72 |         0xFB380000FB3D,
73 |         0xFB3E0000FB3F,
74 |         0xFB400000FB42,
75 |         0xFB430000FB45,
76 |         0xFB460000FB50,
77 |     ),
78 |     "Hiragana": (
79 |         0x304100003097,
80 |         0x309D000030A0,
81 |         0x1B0010001B120,
82 |         0x1B1320001B133,
83 |         0x1B1500001B153,
84 |         0x1F2000001F201,
85 |     ),
86 |     "Katakana": (
87 |         0x30A1000030FB,
88 |         0x30FD00003100,
89 |         0x31F000003200,
90 |         0x32D0000032FF,
91 |         0x330000003358,
92 |         0xFF660000FF70,
93 |         0xFF710000FF9E,
94 |         0x1AFF00001AFF4,
95 |         0x1AFF50001AFFC,
96 |         0x1AFFD0001AFFF,
97 |         0x1B0000001B001,
98 |         0x1B1200001B123,
99 |         0x1B1550001B156,
100 |         0x1B1640001B168,
101 |     ),
102 | }
103 | joining_types = {
104 |     0xAD: 84,
105 |     0x300: 84,
106 |     0x301: 84,
107 |     0x302: 84,
108 |     0x303: 84,
109 |     0x304: 84,
110 |     0x305: 84,
111 |     0x306: 84,
112 |     0x307: 84,
113 |     0x308: 84,
114 |     0x309: 84,
115 |     0x30A: 84,
116 |     0x30B: 84,
117 |     0x30C: 84,
118 |     0x30D: 84,
119 |     0x30E: 84,
120 |     0x30F: 84,
121 |     0x310: 84,
122 |     0x311: 84,
123 |     0x312: 84,
124 |     0x313: 84,
125 |     0x314: 84,
126 |     0x315: 84,
127 |     0x316: 84,
128 |     0x317: 84,
129 |     0x318: 84,
130 |     0x319: 84,
131 |     0x31A: 84,
132 |     0x31B: 84,
133 |     0x31C: 84,
134 |     0x31D: 84,
135 |     0x31E: 84,
136 |     0x31F: 84,
137 |     0x320: 84,
138 |     0x321: 84,
139 |     0x322: 84,
140 |     0x323: 84,
141 |     0x324: 84,
142 |     0x325: 84,
143 |     0x326: 84,
144 |     0x327: 84,
145 |     0x328: 84,
146 |     0x329: 84,
147 |     0x32A: 84,
148 |     0x32B: 84,
149 |     0x32C: 84,
150 |     0x32D: 84,
151 |     0x32E: 84,
152 |     0x32F: 84,
153 |     0x330: 84,
154 |     0x331: 84,
155 |     0x332: 84,
156 |     0x333: 84,
157 |     0x334: 84,
158 |     0x335: 84,
159 |     0x336: 84,
160 |     0x337: 84,
161 |     0x338: 84,
162 |     0x339: 84,
163 |     0x33A: 84,
164 |     0x33B: 84,
165 |     0x33C: 84,
166 |     0x33D: 84,
167 |     0x33E: 84,
168 |     0x33F: 84,
169 |     0x340: 84,
170 |     0x341: 84,
171 |     0x342: 84,
172 |     0x343: 84,
173 |     0x344: 84,
174 |     0x345: 84,
175 |     0x346: 84,
176 |     0x347: 84,
177 |     0x348: 84,
178 |     0x349: 84,
179 |     0x34A: 84,
180 |     0x34B: 84,
181 |     0x34C: 84,
182 |     0x34D: 84,
183 |     0x34E: 84,
184 |     0x34F: 84,
185 |     0x350: 84,
186 |     0x351: 84,
187 |     0x352: 84,
188 |     0x353: 84,
189 |     0x354: 84,
190 |     0x355: 84,
191 |     0x356: 84,
192 |     0x357: 84,
193 |     0x358: 84,
194 |     0x359: 84,
195 |     0x35A: 84,
196 |     0x35B: 84,
197 |     0x35C: 84,
198 |     0x35D: 84,
199 |     0x35E: 84,
200 |     0x35F: 84,
201 |     0x360: 84,
202 |     0x361: 84,
203 |     0x362: 84,
204 |     0x363: 84,
205 |     0x364: 84,
206 |     0x365: 84,
207 |     0x366: 84,
208 |     0x367: 84,
209 |     0x368: 84,
210 |     0x369: 84,
211 |     0x36A: 84,
212 |     0x36B: 84,
213 |     0x36C: 84,
214 |     0x36D: 84,
215 |     0x36E: 84,
216 |     0x36F: 84,
217 |     0x483: 84,
218 |     0x484: 84,
219 |     0x485: 84,
220 |     0x486: 84,
221 |     0x487: 84,
222 |     0x488: 84,
223 |     0x489: 84,
224 |     0x591: 84,
225 |     0x592: 84,
226 |     0x593: 84,
227 |     0x594: 84,
228 |     0x595: 84,
229 |     0x596: 84,
230 |     0x597: 84,
231 |     0x598: 84,
232 |     0x599: 84,
233 |     0x59A: 84,
234 |     0x59B: 84,
235 |     0x59C: 84,
236 |     0x59D: 84,
237 |     0x59E: 84,
238 |     0x59F: 84,
239 |     0x5A0: 84,
240 |     0x5A1: 84,
241 |     0x5A2: 84,
242 |     0x5A3: 84,
243 |     0x5A4: 84,
244 |     0x5A5: 84,
245 |     0x5A6: 84,
246 |     0x5A7: 84,
247 |     0x5A8: 84,
248 |     0x5A9: 84,
249 |     0x5AA: 84,
250 |     0x5AB: 84,
251 |     0x5AC: 84,
252 |     0x5AD: 84,
253 |     0x5AE: 84,
254 |     0x5AF: 84,
255 |     0x5B0: 84,
256 |     0x5B1: 84,
257 |     0x5B2: 84,
258 |     0x5B3: 84,
259 |     0x5B4: 84,
260 |     0x5B5: 84,
261 |     0x5B6: 84,
262 |     0x5B7: 84,
263 |     0x5B8: 84,
264 |     0x5B9: 84,
265 |     0x5BA: 84,
266 |     0x5BB: 84,
267 |     0x5BC: 84,
268 |     0x5BD: 84,
269 |     0x5BF: 84,
270 |     0x5C1: 84,
271 |     0x5C2: 84,
272 |     0x5C4: 84,
273 |     0x5C5: 84,
274 |     0x5C7: 84,
275 |     0x610: 84,
276 |     0x611: 84,
277 |     0x612: 84,
278 |     0x613: 84,
279 |     0x614: 84,
280 |     0x615: 84,
281 |     0x616: 84,
282 |     0x617: 84,
283 |     0x618: 84,
284 |     0x619: 84,
285 |     0x61A: 84,
286 |     0x61C: 84,
287 |     0x620: 68,
288 |     0x622: 82,
289 |     0x623: 82,
290 |     0x624: 82,
291 |     0x625: 82,
292 |     0x626: 68,
293 |     0x627: 82,
294 |     0x628: 68,
295 |     0x629: 82,
296 |     0x62A: 68,
297 |     0x62B: 68,
298 |     0x62C: 68,
299 |     0x62D: 68,
300 |     0x62E: 68,
301 |     0x62F: 82,
302 |     0x630: 82,
303 |     0x631: 82,
304 |     0x632: 82,
305 |     0x633: 68,
306 |     0x634: 68,
307 |     0x635: 68,
308 |     0x636: 68,
309 |     0x637: 68,
310 |     0x638: 68,
311 |     0x639: 68,
312 |     0x63A: 68,
313 |     0x63B: 68,
314 |     0x63C: 68,
315 |     0x63D: 68,
316 |     0x63E: 68,
317 |     0x63F: 68,
318 |     0x640: 67,
319 |     0x641: 68,
320 |     0x642: 68,
321 |     0x643: 68,
322 |     0x644: 68,
323 |     0x645: 68,
324 |     0x646: 68,
325 |     0x647: 68,
326 |     0x648: 82,
327 |     0x649: 68,
328 |     0x64A: 68,
329 |     0x64B: 84,
330 |     0x64C: 84,
331 |     0x64D: 84,
332 |     0x64E: 84,
333 |     0x64F: 84,
334 |     0x650: 84,
335 |     0x651: 84,
336 |     0x652: 84,
337 |     0x653: 84,
338 |     0x654: 84,
339 |     0x655: 84,
340 |     0x656: 84,
341 |     0x657: 84,
342 |     0x658: 84,
343 |     0x659: 84,
344 |     0x65A: 84,
345 |     0x65B: 84,
346 |     0x65C: 84,
347 |     0x65D: 84,
348 |     0x65E: 84,
349 |     0x65F: 84,
350 |     0x66E: 68,
351 |     0x66F: 68,
352 |     0x670: 84,
353 |     0x671: 82,
354 |     0x672: 82,
355 |     0x673: 82,
356 |     0x675: 82,
357 |     0x676: 82,
358 |     0x677: 82,
359 |     0x678: 68,
360 |     0x679: 68,
361 |     0x67A: 68,
362 |     0x67B: 68,
363 |     0x67C: 68,
364 |     0x67D: 68,
365 |     0x67E: 68,
366 |     0x67F: 68,
367 |     0x680: 68,
368 |     0x681: 68,
369 |     0x682: 68,
370 |     0x683: 68,
371 |     0x684: 68,
372 |     0x685: 68,
373 |     0x686: 68,
374 |     0x687: 68,
375 |     0x688: 82,
376 |     0x689: 82,
377 |     0x68A: 82,
378 |     0x68B: 82,
379 |     0x68C: 82,
380 |     0x68D: 82,
381 |     0x68E: 82,
382 |     0x68F: 82,
383 |     0x690: 82,
384 |     0x691: 82,
385 |     0x692: 82,
386 |     0x693: 82,
387 |     0x694: 82,
388 |     0x695: 82,
389 |     0x696: 82,
390 |     0x697: 82,
391 |     0x698: 82,
392 |     0x699: 82,
393 |     0x69A: 68,
394 |     0x69B: 68,
395 |     0x69C: 68,
396 |     0x69D: 68,
397 |     0x69E: 68,
398 |     0x69F: 68,
399 |     0x6A0: 68,
400 |     0x6A1: 68,
401 |     0x6A2: 68,
402 |     0x6A3: 68,
403 |     0x6A4: 68,
404 |     0x6A5: 68,
405 |     0x6A6: 68,
406 |     0x6A7: 68,
407 |     0x6A8: 68,
408 |     0x6A9: 68,
409 |     0x6AA: 68,
410 |     0x6AB: 68,
411 |     0x6AC: 68,
412 |     0x6AD: 68,
413 |     0x6AE: 68,
414 |     0x6AF: 68,
415 |     0x6B0: 68,
416 |     0x6B1: 68,
417 |     0x6B2: 68,
418 |     0x6B3: 68,
419 |     0x6B4: 68,
420 |     0x6B5: 68,
421 |     0x6B6: 68,
422 |     0x6B7: 68,
423 |     0x6B8: 68,
424 |     0x6B9: 68,
425 |     0x6BA: 68,
426 |     0x6BB: 68,
427 |     0x6BC: 68,
428 |     0x6BD: 68,
429 |     0x6BE: 68,
430 |     0x6BF: 68,
431 |     0x6C0: 82,
432 |     0x6C1: 68,
433 |     0x6C2: 68,
434 |     0x6C3: 82,
435 |     0x6C4: 82,
436 |     0x6C5: 82,
437 |     0x6C6: 82,
438 |     0x6C7: 82,
439 |     0x6C8: 82,
440 |     0x6C9: 82,
441 |     0x6CA: 82,
442 |     0x6CB: 82,
443 |     0x6CC: 68,
444 |     0x6CD: 82,
445 |     0x6CE: 68,
446 |     0x6CF: 82,
447 |     0x6D0: 68,
448 |     0x6D1: 68,
449 |     0x6D2: 82,
450 |     0x6D3: 82,
451 |     0x6D5: 82,
452 |     0x6D6: 84,
453 |     0x6D7: 84,
454 |     0x6D8: 84,
455 |     0x6D9: 84,
456 |     0x6DA: 84,
457 |     0x6DB: 84,
458 |     0x6DC: 84,
459 |     0x6DF: 84,
460 |     0x6E0: 84,
461 |     0x6E1: 84,
462 |     0x6E2: 84,
463 |     0x6E3: 84,
464 |     0x6E4: 84,
465 |     0x6E7: 84,
466 |     0x6E8: 84,
467 |     0x6EA: 84,
468 |     0x6EB: 84,
469 |     0x6EC: 84,
470 |     0x6ED: 84,
471 |     0x6EE: 82,
472 |     0x6EF: 82,
473 |     0x6FA: 68,
474 |     0x6FB: 68,
475 |     0x6FC: 68,
476 |     0x6FF: 68,
477 |     0x70F: 84,
478 |     0x710: 82,
479 |     0x711: 84,
480 |     0x712: 68,
481 |     0x713: 68,
482 |     0x714: 68,
483 |     0x715: 82,
484 |     0x716: 82,
485 |     0x717: 82,
486 |     0x718: 82,
487 |     0x719: 82,
488 |     0x71A: 68,
489 |     0x71B: 68,
490 |     0x71C: 68,
491 |     0x71D: 68,
492 |     0x71E: 82,
493 |     0x71F: 68,
494 |     0x720: 68,
495 |     0x721: 68,
496 |     0x722: 68,
497 |     0x723: 68,
498 |     0x724: 68,
499 |     0x725: 68,
500 |     0x726: 68,
501 |     0x727: 68,
502 |     0x728: 82,
503 |     0x729: 68,
504 |     0x72A: 82,
505 |     0x72B: 68,
506 |     0x72C: 82,
507 |     0x72D: 68,
508 |     0x72E: 68,
509 |     0x72F: 82,
510 |     0x730: 84,
511 |     0x731: 84,
512 |     0x732: 84,
513 |     0x733: 84,
514 |     0x734: 84,
515 |     0x735: 84,
516 |     0x736: 84,
517 |     0x737: 84,
518 |     0x738: 84,
519 |     0x739: 84,
520 |     0x73A: 84,
521 |     0x73B: 84,
522 |     0x73C: 84,
523 |     0x73D: 84,
524 |     0x73E: 84,
525 |     0x73F: 84,
526 |     0x740: 84,
527 |     0x741: 84,
528 |     0x742: 84,
529 |     0x743: 84,
530 |     0x744: 84,
531 |     0x745: 84,
532 |     0x746: 84,
533 |     0x747: 84,
534 |     0x748: 84,
535 |     0x749: 84,
536 |     0x74A: 84,
537 |     0x74D: 82,
538 |     0x74E: 68,
539 |     0x74F: 68,
540 |     0x750: 68,
541 |     0x751: 68,
542 |     0x752: 68,
543 |     0x753: 68,
544 |     0x754: 68,
545 |     0x755: 68,
546 |     0x756: 68,
547 |     0x757: 68,
548 |     0x758: 68,
549 |     0x759: 82,
550 |     0x75A: 82,
551 |     0x75B: 82,
552 |     0x75C: 68,
553 |     0x75D: 68,
554 |     0x75E: 68,
555 |     0x75F: 68,
556 |     0x760: 68,
557 |     0x761: 68,
558 |     0x762: 68,
559 |     0x763: 68,
560 |     0x764: 68,
561 |     0x765: 68,
562 |     0x766: 68,
563 |     0x767: 68,
564 |     0x768: 68,
565 |     0x769: 68,
566 |     0x76A: 68,
567 |     0x76B: 82,
568 |     0x76C: 82,
569 |     0x76D: 68,
570 |     0x76E: 68,
571 |     0x76F: 68,
572 |     0x770: 68,
573 |     0x771: 82,
574 |     0x772: 68,
575 |     0x773: 82,
576 |     0x774: 82,
577 |     0x775: 68,
578 |     0x776: 68,
579 |     0x777: 68,
580 |     0x778: 82,
581 |     0x779: 82,
582 |     0x77A: 68,
583 |     0x77B: 68,
584 |     0x77C: 68,
585 |     0x77D: 68,
[TRUNCATED]
```

.venv/lib/python3.13/site-packages/pip/_vendor/idna/intranges.py
```
1 | """
2 | Given a list of integers, made up of (hopefully) a small number of long runs
3 | of consecutive integers, compute a representation of the form
4 | ((start1, end1), (start2, end2) ...). Then answer the question "was x present
5 | in the original list?" in time O(log(# runs)).
6 | """
7 | 
8 | import bisect
9 | from typing import List, Tuple
10 | 
11 | 
12 | def intranges_from_list(list_: List[int]) -> Tuple[int, ...]:
13 |     """Represent a list of integers as a sequence of ranges:
14 |     ((start_0, end_0), (start_1, end_1), ...), such that the original
15 |     integers are exactly those x such that start_i <= x < end_i for some i.
16 | 
17 |     Ranges are encoded as single integers (start << 32 | end), not as tuples.
18 |     """
19 | 
20 |     sorted_list = sorted(list_)
21 |     ranges = []
22 |     last_write = -1
23 |     for i in range(len(sorted_list)):
24 |         if i + 1 < len(sorted_list):
25 |             if sorted_list[i] == sorted_list[i + 1] - 1:
26 |                 continue
27 |         current_range = sorted_list[last_write + 1 : i + 1]
28 |         ranges.append(_encode_range(current_range[0], current_range[-1] + 1))
29 |         last_write = i
30 | 
31 |     return tuple(ranges)
32 | 
33 | 
34 | def _encode_range(start: int, end: int) -> int:
35 |     return (start << 32) | end
36 | 
37 | 
38 | def _decode_range(r: int) -> Tuple[int, int]:
39 |     return (r >> 32), (r & ((1 << 32) - 1))
40 | 
41 | 
42 | def intranges_contain(int_: int, ranges: Tuple[int, ...]) -> bool:
43 |     """Determine if `int_` falls into one of the ranges in `ranges`."""
44 |     tuple_ = _encode_range(int_, 0)
45 |     pos = bisect.bisect_left(ranges, tuple_)
46 |     # we could be immediately ahead of a tuple (start, end)
47 |     # with start < int_ <= end
48 |     if pos > 0:
49 |         left, right = _decode_range(ranges[pos - 1])
50 |         if left <= int_ < right:
51 |             return True
52 |     # or we could be immediately behind a tuple (int_, end)
53 |     if pos < len(ranges):
54 |         left, _ = _decode_range(ranges[pos])
55 |         if left == int_:
56 |             return True
57 |     return False
```

.venv/lib/python3.13/site-packages/pip/_vendor/idna/package_data.py
```
1 | __version__ = "3.10"
```

.venv/lib/python3.13/site-packages/pip/_vendor/idna/py.typed
```
```

.venv/lib/python3.13/site-packages/pip/_vendor/idna/uts46data.py
```
1 | # This file is automatically generated by tools/idna-data
2 | # vim: set fileencoding=utf-8 :
3 | 
4 | from typing import List, Tuple, Union
5 | 
6 | """IDNA Mapping Table from UTS46."""
7 | 
8 | 
9 | __version__ = "15.1.0"
10 | 
11 | 
12 | def _seg_0() -> List[Union[Tuple[int, str], Tuple[int, str, str]]]:
13 |     return [
14 |         (0x0, "3"),
15 |         (0x1, "3"),
16 |         (0x2, "3"),
17 |         (0x3, "3"),
18 |         (0x4, "3"),
19 |         (0x5, "3"),
20 |         (0x6, "3"),
21 |         (0x7, "3"),
22 |         (0x8, "3"),
23 |         (0x9, "3"),
24 |         (0xA, "3"),
25 |         (0xB, "3"),
26 |         (0xC, "3"),
27 |         (0xD, "3"),
28 |         (0xE, "3"),
29 |         (0xF, "3"),
30 |         (0x10, "3"),
31 |         (0x11, "3"),
32 |         (0x12, "3"),
33 |         (0x13, "3"),
34 |         (0x14, "3"),
35 |         (0x15, "3"),
36 |         (0x16, "3"),
37 |         (0x17, "3"),
38 |         (0x18, "3"),
39 |         (0x19, "3"),
40 |         (0x1A, "3"),
41 |         (0x1B, "3"),
42 |         (0x1C, "3"),
43 |         (0x1D, "3"),
44 |         (0x1E, "3"),
45 |         (0x1F, "3"),
46 |         (0x20, "3"),
47 |         (0x21, "3"),
48 |         (0x22, "3"),
49 |         (0x23, "3"),
50 |         (0x24, "3"),
51 |         (0x25, "3"),
52 |         (0x26, "3"),
53 |         (0x27, "3"),
54 |         (0x28, "3"),
55 |         (0x29, "3"),
56 |         (0x2A, "3"),
57 |         (0x2B, "3"),
58 |         (0x2C, "3"),
59 |         (0x2D, "V"),
60 |         (0x2E, "V"),
61 |         (0x2F, "3"),
62 |         (0x30, "V"),
63 |         (0x31, "V"),
64 |         (0x32, "V"),
65 |         (0x33, "V"),
66 |         (0x34, "V"),
67 |         (0x35, "V"),
68 |         (0x36, "V"),
69 |         (0x37, "V"),
70 |         (0x38, "V"),
71 |         (0x39, "V"),
72 |         (0x3A, "3"),
73 |         (0x3B, "3"),
74 |         (0x3C, "3"),
75 |         (0x3D, "3"),
76 |         (0x3E, "3"),
77 |         (0x3F, "3"),
78 |         (0x40, "3"),
79 |         (0x41, "M", "a"),
80 |         (0x42, "M", "b"),
81 |         (0x43, "M", "c"),
82 |         (0x44, "M", "d"),
83 |         (0x45, "M", "e"),
84 |         (0x46, "M", "f"),
85 |         (0x47, "M", "g"),
86 |         (0x48, "M", "h"),
87 |         (0x49, "M", "i"),
88 |         (0x4A, "M", "j"),
89 |         (0x4B, "M", "k"),
90 |         (0x4C, "M", "l"),
91 |         (0x4D, "M", "m"),
92 |         (0x4E, "M", "n"),
93 |         (0x4F, "M", "o"),
94 |         (0x50, "M", "p"),
95 |         (0x51, "M", "q"),
96 |         (0x52, "M", "r"),
97 |         (0x53, "M", "s"),
98 |         (0x54, "M", "t"),
99 |         (0x55, "M", "u"),
100 |         (0x56, "M", "v"),
101 |         (0x57, "M", "w"),
102 |         (0x58, "M", "x"),
103 |         (0x59, "M", "y"),
104 |         (0x5A, "M", "z"),
105 |         (0x5B, "3"),
106 |         (0x5C, "3"),
107 |         (0x5D, "3"),
108 |         (0x5E, "3"),
109 |         (0x5F, "3"),
110 |         (0x60, "3"),
111 |         (0x61, "V"),
112 |         (0x62, "V"),
113 |         (0x63, "V"),
114 |     ]
115 | 
116 | 
117 | def _seg_1() -> List[Union[Tuple[int, str], Tuple[int, str, str]]]:
118 |     return [
119 |         (0x64, "V"),
120 |         (0x65, "V"),
121 |         (0x66, "V"),
122 |         (0x67, "V"),
123 |         (0x68, "V"),
124 |         (0x69, "V"),
125 |         (0x6A, "V"),
126 |         (0x6B, "V"),
127 |         (0x6C, "V"),
128 |         (0x6D, "V"),
129 |         (0x6E, "V"),
130 |         (0x6F, "V"),
131 |         (0x70, "V"),
132 |         (0x71, "V"),
133 |         (0x72, "V"),
134 |         (0x73, "V"),
135 |         (0x74, "V"),
136 |         (0x75, "V"),
137 |         (0x76, "V"),
138 |         (0x77, "V"),
139 |         (0x78, "V"),
140 |         (0x79, "V"),
141 |         (0x7A, "V"),
142 |         (0x7B, "3"),
143 |         (0x7C, "3"),
144 |         (0x7D, "3"),
145 |         (0x7E, "3"),
146 |         (0x7F, "3"),
147 |         (0x80, "X"),
148 |         (0x81, "X"),
149 |         (0x82, "X"),
150 |         (0x83, "X"),
151 |         (0x84, "X"),
152 |         (0x85, "X"),
153 |         (0x86, "X"),
154 |         (0x87, "X"),
155 |         (0x88, "X"),
156 |         (0x89, "X"),
157 |         (0x8A, "X"),
158 |         (0x8B, "X"),
159 |         (0x8C, "X"),
160 |         (0x8D, "X"),
161 |         (0x8E, "X"),
162 |         (0x8F, "X"),
163 |         (0x90, "X"),
164 |         (0x91, "X"),
165 |         (0x92, "X"),
166 |         (0x93, "X"),
167 |         (0x94, "X"),
168 |         (0x95, "X"),
169 |         (0x96, "X"),
170 |         (0x97, "X"),
171 |         (0x98, "X"),
172 |         (0x99, "X"),
173 |         (0x9A, "X"),
174 |         (0x9B, "X"),
175 |         (0x9C, "X"),
176 |         (0x9D, "X"),
177 |         (0x9E, "X"),
178 |         (0x9F, "X"),
179 |         (0xA0, "3", " "),
180 |         (0xA1, "V"),
181 |         (0xA2, "V"),
182 |         (0xA3, "V"),
183 |         (0xA4, "V"),
184 |         (0xA5, "V"),
185 |         (0xA6, "V"),
186 |         (0xA7, "V"),
187 |         (0xA8, "3", " "),
188 |         (0xA9, "V"),
189 |         (0xAA, "M", "a"),
190 |         (0xAB, "V"),
191 |         (0xAC, "V"),
192 |         (0xAD, "I"),
193 |         (0xAE, "V"),
194 |         (0xAF, "3", " "),
195 |         (0xB0, "V"),
196 |         (0xB1, "V"),
197 |         (0xB2, "M", "2"),
198 |         (0xB3, "M", "3"),
199 |         (0xB4, "3", " "),
200 |         (0xB5, "M", ""),
201 |         (0xB6, "V"),
202 |         (0xB7, "V"),
203 |         (0xB8, "3", " "),
204 |         (0xB9, "M", "1"),
205 |         (0xBA, "M", "o"),
206 |         (0xBB, "V"),
207 |         (0xBC, "M", "14"),
208 |         (0xBD, "M", "12"),
209 |         (0xBE, "M", "34"),
210 |         (0xBF, "V"),
211 |         (0xC0, "M", ""),
212 |         (0xC1, "M", ""),
213 |         (0xC2, "M", ""),
214 |         (0xC3, "M", ""),
215 |         (0xC4, "M", ""),
216 |         (0xC5, "M", ""),
217 |         (0xC6, "M", ""),
218 |         (0xC7, "M", ""),
219 |     ]
220 | 
221 | 
222 | def _seg_2() -> List[Union[Tuple[int, str], Tuple[int, str, str]]]:
223 |     return [
224 |         (0xC8, "M", ""),
225 |         (0xC9, "M", ""),
226 |         (0xCA, "M", ""),
227 |         (0xCB, "M", ""),
228 |         (0xCC, "M", ""),
229 |         (0xCD, "M", ""),
230 |         (0xCE, "M", ""),
231 |         (0xCF, "M", ""),
232 |         (0xD0, "M", ""),
233 |         (0xD1, "M", ""),
234 |         (0xD2, "M", ""),
235 |         (0xD3, "M", ""),
236 |         (0xD4, "M", ""),
237 |         (0xD5, "M", ""),
238 |         (0xD6, "M", ""),
239 |         (0xD7, "V"),
240 |         (0xD8, "M", ""),
241 |         (0xD9, "M", ""),
242 |         (0xDA, "M", ""),
243 |         (0xDB, "M", ""),
244 |         (0xDC, "M", ""),
245 |         (0xDD, "M", ""),
246 |         (0xDE, "M", ""),
247 |         (0xDF, "D", "ss"),
248 |         (0xE0, "V"),
249 |         (0xE1, "V"),
250 |         (0xE2, "V"),
251 |         (0xE3, "V"),
252 |         (0xE4, "V"),
253 |         (0xE5, "V"),
254 |         (0xE6, "V"),
255 |         (0xE7, "V"),
256 |         (0xE8, "V"),
257 |         (0xE9, "V"),
258 |         (0xEA, "V"),
259 |         (0xEB, "V"),
260 |         (0xEC, "V"),
261 |         (0xED, "V"),
262 |         (0xEE, "V"),
263 |         (0xEF, "V"),
264 |         (0xF0, "V"),
265 |         (0xF1, "V"),
266 |         (0xF2, "V"),
267 |         (0xF3, "V"),
268 |         (0xF4, "V"),
269 |         (0xF5, "V"),
270 |         (0xF6, "V"),
271 |         (0xF7, "V"),
272 |         (0xF8, "V"),
273 |         (0xF9, "V"),
274 |         (0xFA, "V"),
275 |         (0xFB, "V"),
276 |         (0xFC, "V"),
277 |         (0xFD, "V"),
278 |         (0xFE, "V"),
279 |         (0xFF, "V"),
280 |         (0x100, "M", ""),
281 |         (0x101, "V"),
282 |         (0x102, "M", ""),
283 |         (0x103, "V"),
284 |         (0x104, "M", ""),
285 |         (0x105, "V"),
286 |         (0x106, "M", ""),
287 |         (0x107, "V"),
288 |         (0x108, "M", ""),
289 |         (0x109, "V"),
290 |         (0x10A, "M", ""),
291 |         (0x10B, "V"),
292 |         (0x10C, "M", ""),
293 |         (0x10D, "V"),
294 |         (0x10E, "M", ""),
295 |         (0x10F, "V"),
296 |         (0x110, "M", ""),
297 |         (0x111, "V"),
298 |         (0x112, "M", ""),
299 |         (0x113, "V"),
300 |         (0x114, "M", ""),
301 |         (0x115, "V"),
302 |         (0x116, "M", ""),
303 |         (0x117, "V"),
304 |         (0x118, "M", ""),
305 |         (0x119, "V"),
306 |         (0x11A, "M", ""),
307 |         (0x11B, "V"),
308 |         (0x11C, "M", ""),
309 |         (0x11D, "V"),
310 |         (0x11E, "M", ""),
311 |         (0x11F, "V"),
312 |         (0x120, "M", ""),
313 |         (0x121, "V"),
314 |         (0x122, "M", ""),
315 |         (0x123, "V"),
316 |         (0x124, "M", ""),
317 |         (0x125, "V"),
318 |         (0x126, "M", ""),
319 |         (0x127, "V"),
320 |         (0x128, "M", ""),
321 |         (0x129, "V"),
322 |         (0x12A, "M", ""),
323 |         (0x12B, "V"),
324 |     ]
325 | 
326 | 
327 | def _seg_3() -> List[Union[Tuple[int, str], Tuple[int, str, str]]]:
328 |     return [
329 |         (0x12C, "M", ""),
330 |         (0x12D, "V"),
331 |         (0x12E, "M", ""),
332 |         (0x12F, "V"),
333 |         (0x130, "M", "i"),
334 |         (0x131, "V"),
335 |         (0x132, "M", "ij"),
336 |         (0x134, "M", ""),
337 |         (0x135, "V"),
338 |         (0x136, "M", ""),
339 |         (0x137, "V"),
340 |         (0x139, "M", ""),
341 |         (0x13A, "V"),
342 |         (0x13B, "M", ""),
343 |         (0x13C, "V"),
344 |         (0x13D, "M", ""),
345 |         (0x13E, "V"),
346 |         (0x13F, "M", "l"),
347 |         (0x141, "M", ""),
348 |         (0x142, "V"),
349 |         (0x143, "M", ""),
350 |         (0x144, "V"),
351 |         (0x145, "M", ""),
352 |         (0x146, "V"),
353 |         (0x147, "M", ""),
354 |         (0x148, "V"),
355 |         (0x149, "M", "n"),
356 |         (0x14A, "M", ""),
357 |         (0x14B, "V"),
358 |         (0x14C, "M", ""),
359 |         (0x14D, "V"),
360 |         (0x14E, "M", ""),
361 |         (0x14F, "V"),
362 |         (0x150, "M", ""),
363 |         (0x151, "V"),
364 |         (0x152, "M", ""),
365 |         (0x153, "V"),
366 |         (0x154, "M", ""),
367 |         (0x155, "V"),
368 |         (0x156, "M", ""),
369 |         (0x157, "V"),
370 |         (0x158, "M", ""),
371 |         (0x159, "V"),
372 |         (0x15A, "M", ""),
373 |         (0x15B, "V"),
374 |         (0x15C, "M", ""),
375 |         (0x15D, "V"),
376 |         (0x15E, "M", ""),
377 |         (0x15F, "V"),
378 |         (0x160, "M", ""),
379 |         (0x161, "V"),
380 |         (0x162, "M", ""),
381 |         (0x163, "V"),
382 |         (0x164, "M", ""),
383 |         (0x165, "V"),
384 |         (0x166, "M", ""),
385 |         (0x167, "V"),
386 |         (0x168, "M", ""),
387 |         (0x169, "V"),
388 |         (0x16A, "M", ""),
389 |         (0x16B, "V"),
390 |         (0x16C, "M", ""),
391 |         (0x16D, "V"),
392 |         (0x16E, "M", ""),
393 |         (0x16F, "V"),
394 |         (0x170, "M", ""),
395 |         (0x171, "V"),
396 |         (0x172, "M", ""),
397 |         (0x173, "V"),
398 |         (0x174, "M", ""),
399 |         (0x175, "V"),
400 |         (0x176, "M", ""),
401 |         (0x177, "V"),
402 |         (0x178, "M", ""),
403 |         (0x179, "M", ""),
404 |         (0x17A, "V"),
405 |         (0x17B, "M", ""),
406 |         (0x17C, "V"),
407 |         (0x17D, "M", ""),
408 |         (0x17E, "V"),
409 |         (0x17F, "M", "s"),
410 |         (0x180, "V"),
411 |         (0x181, "M", ""),
412 |         (0x182, "M", ""),
413 |         (0x183, "V"),
414 |         (0x184, "M", ""),
415 |         (0x185, "V"),
416 |         (0x186, "M", ""),
417 |         (0x187, "M", ""),
418 |         (0x188, "V"),
419 |         (0x189, "M", ""),
420 |         (0x18A, "M", ""),
421 |         (0x18B, "M", ""),
422 |         (0x18C, "V"),
423 |         (0x18E, "M", ""),
424 |         (0x18F, "M", ""),
425 |         (0x190, "M", ""),
426 |         (0x191, "M", ""),
427 |         (0x192, "V"),
428 |         (0x193, "M", ""),
429 |     ]
430 | 
431 | 
432 | def _seg_4() -> List[Union[Tuple[int, str], Tuple[int, str, str]]]:
433 |     return [
434 |         (0x194, "M", ""),
435 |         (0x195, "V"),
436 |         (0x196, "M", ""),
437 |         (0x197, "M", ""),
438 |         (0x198, "M", ""),
439 |         (0x199, "V"),
440 |         (0x19C, "M", ""),
441 |         (0x19D, "M", ""),
442 |         (0x19E, "V"),
443 |         (0x19F, "M", ""),
444 |         (0x1A0, "M", ""),
445 |         (0x1A1, "V"),
446 |         (0x1A2, "M", ""),
447 |         (0x1A3, "V"),
448 |         (0x1A4, "M", ""),
449 |         (0x1A5, "V"),
450 |         (0x1A6, "M", ""),
451 |         (0x1A7, "M", ""),
452 |         (0x1A8, "V"),
453 |         (0x1A9, "M", ""),
454 |         (0x1AA, "V"),
455 |         (0x1AC, "M", ""),
456 |         (0x1AD, "V"),
457 |         (0x1AE, "M", ""),
458 |         (0x1AF, "M", ""),
459 |         (0x1B0, "V"),
460 |         (0x1B1, "M", ""),
461 |         (0x1B2, "M", ""),
462 |         (0x1B3, "M", ""),
463 |         (0x1B4, "V"),
464 |         (0x1B5, "M", ""),
465 |         (0x1B6, "V"),
466 |         (0x1B7, "M", ""),
467 |         (0x1B8, "M", ""),
468 |         (0x1B9, "V"),
469 |         (0x1BC, "M", ""),
470 |         (0x1BD, "V"),
471 |         (0x1C4, "M", "d"),
472 |         (0x1C7, "M", "lj"),
473 |         (0x1CA, "M", "nj"),
474 |         (0x1CD, "M", ""),
475 |         (0x1CE, "V"),
476 |         (0x1CF, "M", ""),
477 |         (0x1D0, "V"),
478 |         (0x1D1, "M", ""),
479 |         (0x1D2, "V"),
480 |         (0x1D3, "M", ""),
481 |         (0x1D4, "V"),
482 |         (0x1D5, "M", ""),
483 |         (0x1D6, "V"),
484 |         (0x1D7, "M", ""),
485 |         (0x1D8, "V"),
486 |         (0x1D9, "M", ""),
487 |         (0x1DA, "V"),
488 |         (0x1DB, "M", ""),
489 |         (0x1DC, "V"),
490 |         (0x1DE, "M", ""),
491 |         (0x1DF, "V"),
492 |         (0x1E0, "M", ""),
493 |         (0x1E1, "V"),
494 |         (0x1E2, "M", ""),
495 |         (0x1E3, "V"),
496 |         (0x1E4, "M", ""),
497 |         (0x1E5, "V"),
498 |         (0x1E6, "M", ""),
499 |         (0x1E7, "V"),
500 |         (0x1E8, "M", ""),
501 |         (0x1E9, "V"),
502 |         (0x1EA, "M", ""),
503 |         (0x1EB, "V"),
504 |         (0x1EC, "M", ""),
505 |         (0x1ED, "V"),
[TRUNCATED]
```

.venv/lib/python3.13/site-packages/pip/_vendor/msgpack/__init__.py
```
1 | # ruff: noqa: F401
2 | import os
3 | 
4 | from .exceptions import *  # noqa: F403
5 | from .ext import ExtType, Timestamp
6 | 
7 | version = (1, 1, 0)
8 | __version__ = "1.1.0"
9 | 
10 | 
11 | if os.environ.get("MSGPACK_PUREPYTHON"):
12 |     from .fallback import Packer, Unpacker, unpackb
13 | else:
14 |     try:
15 |         from ._cmsgpack import Packer, Unpacker, unpackb
16 |     except ImportError:
17 |         from .fallback import Packer, Unpacker, unpackb
18 | 
19 | 
20 | def pack(o, stream, **kwargs):
21 |     """
22 |     Pack object `o` and write it to `stream`
23 | 
24 |     See :class:`Packer` for options.
25 |     """
26 |     packer = Packer(**kwargs)
27 |     stream.write(packer.pack(o))
28 | 
29 | 
30 | def packb(o, **kwargs):
31 |     """
32 |     Pack object `o` and return packed bytes
33 | 
34 |     See :class:`Packer` for options.
35 |     """
36 |     return Packer(**kwargs).pack(o)
37 | 
38 | 
39 | def unpack(stream, **kwargs):
40 |     """
41 |     Unpack an object from `stream`.
42 | 
43 |     Raises `ExtraData` when `stream` contains extra bytes.
44 |     See :class:`Unpacker` for options.
45 |     """
46 |     data = stream.read()
47 |     return unpackb(data, **kwargs)
48 | 
49 | 
50 | # alias for compatibility to simplejson/marshal/pickle.
51 | load = unpack
52 | loads = unpackb
53 | 
54 | dump = pack
55 | dumps = packb
```

.venv/lib/python3.13/site-packages/pip/_vendor/msgpack/exceptions.py
```
1 | class UnpackException(Exception):
2 |     """Base class for some exceptions raised while unpacking.
3 | 
4 |     NOTE: unpack may raise exception other than subclass of
5 |     UnpackException.  If you want to catch all error, catch
6 |     Exception instead.
7 |     """
8 | 
9 | 
10 | class BufferFull(UnpackException):
11 |     pass
12 | 
13 | 
14 | class OutOfData(UnpackException):
15 |     pass
16 | 
17 | 
18 | class FormatError(ValueError, UnpackException):
19 |     """Invalid msgpack format"""
20 | 
21 | 
22 | class StackError(ValueError, UnpackException):
23 |     """Too nested"""
24 | 
25 | 
26 | # Deprecated.  Use ValueError instead
27 | UnpackValueError = ValueError
28 | 
29 | 
30 | class ExtraData(UnpackValueError):
31 |     """ExtraData is raised when there is trailing data.
32 | 
33 |     This exception is raised while only one-shot (not streaming)
34 |     unpack.
35 |     """
36 | 
37 |     def __init__(self, unpacked, extra):
38 |         self.unpacked = unpacked
39 |         self.extra = extra
40 | 
41 |     def __str__(self):
42 |         return "unpack(b) received extra data."
43 | 
44 | 
45 | # Deprecated.  Use Exception instead to catch all exception during packing.
46 | PackException = Exception
47 | PackValueError = ValueError
48 | PackOverflowError = OverflowError
```

.venv/lib/python3.13/site-packages/pip/_vendor/msgpack/ext.py
```
1 | import datetime
2 | import struct
3 | from collections import namedtuple
4 | 
5 | 
6 | class ExtType(namedtuple("ExtType", "code data")):
7 |     """ExtType represents ext type in msgpack."""
8 | 
9 |     def __new__(cls, code, data):
10 |         if not isinstance(code, int):
11 |             raise TypeError("code must be int")
12 |         if not isinstance(data, bytes):
13 |             raise TypeError("data must be bytes")
14 |         if not 0 <= code <= 127:
15 |             raise ValueError("code must be 0~127")
16 |         return super().__new__(cls, code, data)
17 | 
18 | 
19 | class Timestamp:
20 |     """Timestamp represents the Timestamp extension type in msgpack.
21 | 
22 |     When built with Cython, msgpack uses C methods to pack and unpack `Timestamp`.
23 |     When using pure-Python msgpack, :func:`to_bytes` and :func:`from_bytes` are used to pack and
24 |     unpack `Timestamp`.
25 | 
26 |     This class is immutable: Do not override seconds and nanoseconds.
27 |     """
28 | 
29 |     __slots__ = ["seconds", "nanoseconds"]
30 | 
31 |     def __init__(self, seconds, nanoseconds=0):
32 |         """Initialize a Timestamp object.
33 | 
34 |         :param int seconds:
35 |             Number of seconds since the UNIX epoch (00:00:00 UTC Jan 1 1970, minus leap seconds).
36 |             May be negative.
37 | 
38 |         :param int nanoseconds:
39 |             Number of nanoseconds to add to `seconds` to get fractional time.
40 |             Maximum is 999_999_999.  Default is 0.
41 | 
42 |         Note: Negative times (before the UNIX epoch) are represented as neg. seconds + pos. ns.
43 |         """
44 |         if not isinstance(seconds, int):
45 |             raise TypeError("seconds must be an integer")
46 |         if not isinstance(nanoseconds, int):
47 |             raise TypeError("nanoseconds must be an integer")
48 |         if not (0 <= nanoseconds < 10**9):
49 |             raise ValueError("nanoseconds must be a non-negative integer less than 999999999.")
50 |         self.seconds = seconds
51 |         self.nanoseconds = nanoseconds
52 | 
53 |     def __repr__(self):
54 |         """String representation of Timestamp."""
55 |         return f"Timestamp(seconds={self.seconds}, nanoseconds={self.nanoseconds})"
56 | 
57 |     def __eq__(self, other):
58 |         """Check for equality with another Timestamp object"""
59 |         if type(other) is self.__class__:
60 |             return self.seconds == other.seconds and self.nanoseconds == other.nanoseconds
61 |         return False
62 | 
63 |     def __ne__(self, other):
64 |         """not-equals method (see :func:`__eq__()`)"""
65 |         return not self.__eq__(other)
66 | 
67 |     def __hash__(self):
68 |         return hash((self.seconds, self.nanoseconds))
69 | 
70 |     @staticmethod
71 |     def from_bytes(b):
72 |         """Unpack bytes into a `Timestamp` object.
73 | 
74 |         Used for pure-Python msgpack unpacking.
75 | 
76 |         :param b: Payload from msgpack ext message with code -1
77 |         :type b: bytes
78 | 
79 |         :returns: Timestamp object unpacked from msgpack ext payload
80 |         :rtype: Timestamp
81 |         """
82 |         if len(b) == 4:
83 |             seconds = struct.unpack("!L", b)[0]
84 |             nanoseconds = 0
85 |         elif len(b) == 8:
86 |             data64 = struct.unpack("!Q", b)[0]
87 |             seconds = data64 & 0x00000003FFFFFFFF
88 |             nanoseconds = data64 >> 34
89 |         elif len(b) == 12:
90 |             nanoseconds, seconds = struct.unpack("!Iq", b)
91 |         else:
92 |             raise ValueError(
93 |                 "Timestamp type can only be created from 32, 64, or 96-bit byte objects"
94 |             )
95 |         return Timestamp(seconds, nanoseconds)
96 | 
97 |     def to_bytes(self):
98 |         """Pack this Timestamp object into bytes.
99 | 
100 |         Used for pure-Python msgpack packing.
101 | 
102 |         :returns data: Payload for EXT message with code -1 (timestamp type)
103 |         :rtype: bytes
104 |         """
105 |         if (self.seconds >> 34) == 0:  # seconds is non-negative and fits in 34 bits
106 |             data64 = self.nanoseconds << 34 | self.seconds
107 |             if data64 & 0xFFFFFFFF00000000 == 0:
108 |                 # nanoseconds is zero and seconds < 2**32, so timestamp 32
109 |                 data = struct.pack("!L", data64)
110 |             else:
111 |                 # timestamp 64
112 |                 data = struct.pack("!Q", data64)
113 |         else:
114 |             # timestamp 96
115 |             data = struct.pack("!Iq", self.nanoseconds, self.seconds)
116 |         return data
117 | 
118 |     @staticmethod
119 |     def from_unix(unix_sec):
120 |         """Create a Timestamp from posix timestamp in seconds.
121 | 
122 |         :param unix_float: Posix timestamp in seconds.
123 |         :type unix_float: int or float
124 |         """
125 |         seconds = int(unix_sec // 1)
126 |         nanoseconds = int((unix_sec % 1) * 10**9)
127 |         return Timestamp(seconds, nanoseconds)
128 | 
129 |     def to_unix(self):
130 |         """Get the timestamp as a floating-point value.
131 | 
132 |         :returns: posix timestamp
133 |         :rtype: float
134 |         """
135 |         return self.seconds + self.nanoseconds / 1e9
136 | 
137 |     @staticmethod
138 |     def from_unix_nano(unix_ns):
139 |         """Create a Timestamp from posix timestamp in nanoseconds.
140 | 
141 |         :param int unix_ns: Posix timestamp in nanoseconds.
142 |         :rtype: Timestamp
143 |         """
144 |         return Timestamp(*divmod(unix_ns, 10**9))
145 | 
146 |     def to_unix_nano(self):
147 |         """Get the timestamp as a unixtime in nanoseconds.
148 | 
149 |         :returns: posix timestamp in nanoseconds
150 |         :rtype: int
151 |         """
152 |         return self.seconds * 10**9 + self.nanoseconds
153 | 
154 |     def to_datetime(self):
155 |         """Get the timestamp as a UTC datetime.
156 | 
157 |         :rtype: `datetime.datetime`
158 |         """
159 |         utc = datetime.timezone.utc
160 |         return datetime.datetime.fromtimestamp(0, utc) + datetime.timedelta(
161 |             seconds=self.seconds, microseconds=self.nanoseconds // 1000
162 |         )
163 | 
164 |     @staticmethod
165 |     def from_datetime(dt):
166 |         """Create a Timestamp from datetime with tzinfo.
167 | 
168 |         :rtype: Timestamp
169 |         """
170 |         return Timestamp(seconds=int(dt.timestamp()), nanoseconds=dt.microsecond * 1000)
```

.venv/lib/python3.13/site-packages/pip/_vendor/msgpack/fallback.py
```
1 | """Fallback pure Python implementation of msgpack"""
2 | 
3 | import struct
4 | import sys
5 | from datetime import datetime as _DateTime
6 | 
7 | if hasattr(sys, "pypy_version_info"):
8 |     from __pypy__ import newlist_hint
9 |     from __pypy__.builders import BytesBuilder
10 | 
11 |     _USING_STRINGBUILDER = True
12 | 
13 |     class BytesIO:
14 |         def __init__(self, s=b""):
15 |             if s:
16 |                 self.builder = BytesBuilder(len(s))
17 |                 self.builder.append(s)
18 |             else:
19 |                 self.builder = BytesBuilder()
20 | 
21 |         def write(self, s):
22 |             if isinstance(s, memoryview):
23 |                 s = s.tobytes()
24 |             elif isinstance(s, bytearray):
25 |                 s = bytes(s)
26 |             self.builder.append(s)
27 | 
28 |         def getvalue(self):
29 |             return self.builder.build()
30 | 
31 | else:
32 |     from io import BytesIO
33 | 
34 |     _USING_STRINGBUILDER = False
35 | 
36 |     def newlist_hint(size):
37 |         return []
38 | 
39 | 
40 | from .exceptions import BufferFull, ExtraData, FormatError, OutOfData, StackError
41 | from .ext import ExtType, Timestamp
42 | 
43 | EX_SKIP = 0
44 | EX_CONSTRUCT = 1
45 | EX_READ_ARRAY_HEADER = 2
46 | EX_READ_MAP_HEADER = 3
47 | 
48 | TYPE_IMMEDIATE = 0
49 | TYPE_ARRAY = 1
50 | TYPE_MAP = 2
51 | TYPE_RAW = 3
52 | TYPE_BIN = 4
53 | TYPE_EXT = 5
54 | 
55 | DEFAULT_RECURSE_LIMIT = 511
56 | 
57 | 
58 | def _check_type_strict(obj, t, type=type, tuple=tuple):
59 |     if type(t) is tuple:
60 |         return type(obj) in t
61 |     else:
62 |         return type(obj) is t
63 | 
64 | 
65 | def _get_data_from_buffer(obj):
66 |     view = memoryview(obj)
67 |     if view.itemsize != 1:
68 |         raise ValueError("cannot unpack from multi-byte object")
69 |     return view
70 | 
71 | 
72 | def unpackb(packed, **kwargs):
73 |     """
74 |     Unpack an object from `packed`.
75 | 
76 |     Raises ``ExtraData`` when *packed* contains extra bytes.
77 |     Raises ``ValueError`` when *packed* is incomplete.
78 |     Raises ``FormatError`` when *packed* is not valid msgpack.
79 |     Raises ``StackError`` when *packed* contains too nested.
80 |     Other exceptions can be raised during unpacking.
81 | 
82 |     See :class:`Unpacker` for options.
83 |     """
84 |     unpacker = Unpacker(None, max_buffer_size=len(packed), **kwargs)
85 |     unpacker.feed(packed)
86 |     try:
87 |         ret = unpacker._unpack()
88 |     except OutOfData:
89 |         raise ValueError("Unpack failed: incomplete input")
90 |     except RecursionError:
91 |         raise StackError
92 |     if unpacker._got_extradata():
93 |         raise ExtraData(ret, unpacker._get_extradata())
94 |     return ret
95 | 
96 | 
97 | _NO_FORMAT_USED = ""
98 | _MSGPACK_HEADERS = {
99 |     0xC4: (1, _NO_FORMAT_USED, TYPE_BIN),
100 |     0xC5: (2, ">H", TYPE_BIN),
101 |     0xC6: (4, ">I", TYPE_BIN),
102 |     0xC7: (2, "Bb", TYPE_EXT),
103 |     0xC8: (3, ">Hb", TYPE_EXT),
104 |     0xC9: (5, ">Ib", TYPE_EXT),
105 |     0xCA: (4, ">f"),
106 |     0xCB: (8, ">d"),
107 |     0xCC: (1, _NO_FORMAT_USED),
108 |     0xCD: (2, ">H"),
109 |     0xCE: (4, ">I"),
110 |     0xCF: (8, ">Q"),
111 |     0xD0: (1, "b"),
112 |     0xD1: (2, ">h"),
113 |     0xD2: (4, ">i"),
114 |     0xD3: (8, ">q"),
115 |     0xD4: (1, "b1s", TYPE_EXT),
116 |     0xD5: (2, "b2s", TYPE_EXT),
117 |     0xD6: (4, "b4s", TYPE_EXT),
118 |     0xD7: (8, "b8s", TYPE_EXT),
119 |     0xD8: (16, "b16s", TYPE_EXT),
120 |     0xD9: (1, _NO_FORMAT_USED, TYPE_RAW),
121 |     0xDA: (2, ">H", TYPE_RAW),
122 |     0xDB: (4, ">I", TYPE_RAW),
123 |     0xDC: (2, ">H", TYPE_ARRAY),
124 |     0xDD: (4, ">I", TYPE_ARRAY),
125 |     0xDE: (2, ">H", TYPE_MAP),
126 |     0xDF: (4, ">I", TYPE_MAP),
127 | }
128 | 
129 | 
130 | class Unpacker:
131 |     """Streaming unpacker.
132 | 
133 |     Arguments:
134 | 
135 |     :param file_like:
136 |         File-like object having `.read(n)` method.
137 |         If specified, unpacker reads serialized data from it and `.feed()` is not usable.
138 | 
139 |     :param int read_size:
140 |         Used as `file_like.read(read_size)`. (default: `min(16*1024, max_buffer_size)`)
141 | 
142 |     :param bool use_list:
143 |         If true, unpack msgpack array to Python list.
144 |         Otherwise, unpack to Python tuple. (default: True)
145 | 
146 |     :param bool raw:
147 |         If true, unpack msgpack raw to Python bytes.
148 |         Otherwise, unpack to Python str by decoding with UTF-8 encoding (default).
149 | 
150 |     :param int timestamp:
151 |         Control how timestamp type is unpacked:
152 | 
153 |             0 - Timestamp
154 |             1 - float  (Seconds from the EPOCH)
155 |             2 - int  (Nanoseconds from the EPOCH)
156 |             3 - datetime.datetime  (UTC).
157 | 
158 |     :param bool strict_map_key:
159 |         If true (default), only str or bytes are accepted for map (dict) keys.
160 | 
161 |     :param object_hook:
162 |         When specified, it should be callable.
163 |         Unpacker calls it with a dict argument after unpacking msgpack map.
164 |         (See also simplejson)
165 | 
166 |     :param object_pairs_hook:
167 |         When specified, it should be callable.
168 |         Unpacker calls it with a list of key-value pairs after unpacking msgpack map.
169 |         (See also simplejson)
170 | 
171 |     :param str unicode_errors:
172 |         The error handler for decoding unicode. (default: 'strict')
173 |         This option should be used only when you have msgpack data which
174 |         contains invalid UTF-8 string.
175 | 
176 |     :param int max_buffer_size:
177 |         Limits size of data waiting unpacked.  0 means 2**32-1.
178 |         The default value is 100*1024*1024 (100MiB).
179 |         Raises `BufferFull` exception when it is insufficient.
180 |         You should set this parameter when unpacking data from untrusted source.
181 | 
182 |     :param int max_str_len:
183 |         Deprecated, use *max_buffer_size* instead.
184 |         Limits max length of str. (default: max_buffer_size)
185 | 
186 |     :param int max_bin_len:
187 |         Deprecated, use *max_buffer_size* instead.
188 |         Limits max length of bin. (default: max_buffer_size)
189 | 
190 |     :param int max_array_len:
191 |         Limits max length of array.
192 |         (default: max_buffer_size)
193 | 
194 |     :param int max_map_len:
195 |         Limits max length of map.
196 |         (default: max_buffer_size//2)
197 | 
198 |     :param int max_ext_len:
199 |         Deprecated, use *max_buffer_size* instead.
200 |         Limits max size of ext type.  (default: max_buffer_size)
201 | 
202 |     Example of streaming deserialize from file-like object::
203 | 
204 |         unpacker = Unpacker(file_like)
205 |         for o in unpacker:
206 |             process(o)
207 | 
208 |     Example of streaming deserialize from socket::
209 | 
210 |         unpacker = Unpacker()
211 |         while True:
212 |             buf = sock.recv(1024**2)
213 |             if not buf:
214 |                 break
215 |             unpacker.feed(buf)
216 |             for o in unpacker:
217 |                 process(o)
218 | 
219 |     Raises ``ExtraData`` when *packed* contains extra bytes.
220 |     Raises ``OutOfData`` when *packed* is incomplete.
221 |     Raises ``FormatError`` when *packed* is not valid msgpack.
222 |     Raises ``StackError`` when *packed* contains too nested.
223 |     Other exceptions can be raised during unpacking.
224 |     """
225 | 
226 |     def __init__(
227 |         self,
228 |         file_like=None,
229 |         *,
230 |         read_size=0,
231 |         use_list=True,
232 |         raw=False,
233 |         timestamp=0,
234 |         strict_map_key=True,
235 |         object_hook=None,
236 |         object_pairs_hook=None,
237 |         list_hook=None,
238 |         unicode_errors=None,
239 |         max_buffer_size=100 * 1024 * 1024,
240 |         ext_hook=ExtType,
241 |         max_str_len=-1,
242 |         max_bin_len=-1,
243 |         max_array_len=-1,
244 |         max_map_len=-1,
245 |         max_ext_len=-1,
246 |     ):
247 |         if unicode_errors is None:
248 |             unicode_errors = "strict"
249 | 
250 |         if file_like is None:
251 |             self._feeding = True
252 |         else:
253 |             if not callable(file_like.read):
254 |                 raise TypeError("`file_like.read` must be callable")
255 |             self.file_like = file_like
256 |             self._feeding = False
257 | 
258 |         #: array of bytes fed.
259 |         self._buffer = bytearray()
260 |         #: Which position we currently reads
261 |         self._buff_i = 0
262 | 
263 |         # When Unpacker is used as an iterable, between the calls to next(),
264 |         # the buffer is not "consumed" completely, for efficiency sake.
265 |         # Instead, it is done sloppily.  To make sure we raise BufferFull at
266 |         # the correct moments, we have to keep track of how sloppy we were.
267 |         # Furthermore, when the buffer is incomplete (that is: in the case
268 |         # we raise an OutOfData) we need to rollback the buffer to the correct
269 |         # state, which _buf_checkpoint records.
270 |         self._buf_checkpoint = 0
271 | 
272 |         if not max_buffer_size:
273 |             max_buffer_size = 2**31 - 1
274 |         if max_str_len == -1:
275 |             max_str_len = max_buffer_size
276 |         if max_bin_len == -1:
277 |             max_bin_len = max_buffer_size
278 |         if max_array_len == -1:
279 |             max_array_len = max_buffer_size
280 |         if max_map_len == -1:
281 |             max_map_len = max_buffer_size // 2
282 |         if max_ext_len == -1:
283 |             max_ext_len = max_buffer_size
284 | 
285 |         self._max_buffer_size = max_buffer_size
286 |         if read_size > self._max_buffer_size:
287 |             raise ValueError("read_size must be smaller than max_buffer_size")
288 |         self._read_size = read_size or min(self._max_buffer_size, 16 * 1024)
289 |         self._raw = bool(raw)
290 |         self._strict_map_key = bool(strict_map_key)
291 |         self._unicode_errors = unicode_errors
292 |         self._use_list = use_list
293 |         if not (0 <= timestamp <= 3):
294 |             raise ValueError("timestamp must be 0..3")
295 |         self._timestamp = timestamp
296 |         self._list_hook = list_hook
297 |         self._object_hook = object_hook
298 |         self._object_pairs_hook = object_pairs_hook
299 |         self._ext_hook = ext_hook
300 |         self._max_str_len = max_str_len
301 |         self._max_bin_len = max_bin_len
302 |         self._max_array_len = max_array_len
303 |         self._max_map_len = max_map_len
304 |         self._max_ext_len = max_ext_len
305 |         self._stream_offset = 0
306 | 
307 |         if list_hook is not None and not callable(list_hook):
308 |             raise TypeError("`list_hook` is not callable")
309 |         if object_hook is not None and not callable(object_hook):
310 |             raise TypeError("`object_hook` is not callable")
311 |         if object_pairs_hook is not None and not callable(object_pairs_hook):
312 |             raise TypeError("`object_pairs_hook` is not callable")
313 |         if object_hook is not None and object_pairs_hook is not None:
314 |             raise TypeError("object_pairs_hook and object_hook are mutually exclusive")
315 |         if not callable(ext_hook):
316 |             raise TypeError("`ext_hook` is not callable")
317 | 
318 |     def feed(self, next_bytes):
319 |         assert self._feeding
320 |         view = _get_data_from_buffer(next_bytes)
321 |         if len(self._buffer) - self._buff_i + len(view) > self._max_buffer_size:
322 |             raise BufferFull
323 | 
324 |         # Strip buffer before checkpoint before reading file.
325 |         if self._buf_checkpoint > 0:
326 |             del self._buffer[: self._buf_checkpoint]
327 |             self._buff_i -= self._buf_checkpoint
328 |             self._buf_checkpoint = 0
329 | 
330 |         # Use extend here: INPLACE_ADD += doesn't reliably typecast memoryview in jython
331 |         self._buffer.extend(view)
332 |         view.release()
333 | 
334 |     def _consume(self):
335 |         """Gets rid of the used parts of the buffer."""
336 |         self._stream_offset += self._buff_i - self._buf_checkpoint
337 |         self._buf_checkpoint = self._buff_i
338 | 
339 |     def _got_extradata(self):
340 |         return self._buff_i < len(self._buffer)
341 | 
342 |     def _get_extradata(self):
343 |         return self._buffer[self._buff_i :]
344 | 
345 |     def read_bytes(self, n):
346 |         ret = self._read(n, raise_outofdata=False)
347 |         self._consume()
348 |         return ret
349 | 
350 |     def _read(self, n, raise_outofdata=True):
[TRUNCATED]
```

.venv/lib/python3.13/site-packages/pip/_vendor/pyproject_hooks/__init__.py
```
1 | """Wrappers to call pyproject.toml-based build backend hooks.
2 | """
3 | 
4 | from typing import TYPE_CHECKING
5 | 
6 | from ._impl import (
7 |     BackendUnavailable,
8 |     BuildBackendHookCaller,
9 |     HookMissing,
10 |     UnsupportedOperation,
11 |     default_subprocess_runner,
12 |     quiet_subprocess_runner,
13 | )
14 | 
15 | __version__ = "1.2.0"
16 | __all__ = [
17 |     "BackendUnavailable",
18 |     "BackendInvalid",
19 |     "HookMissing",
20 |     "UnsupportedOperation",
21 |     "default_subprocess_runner",
22 |     "quiet_subprocess_runner",
23 |     "BuildBackendHookCaller",
24 | ]
25 | 
26 | BackendInvalid = BackendUnavailable  # Deprecated alias, previously a separate exception
27 | 
28 | if TYPE_CHECKING:
29 |     from ._impl import SubprocessRunner
30 | 
31 |     __all__ += ["SubprocessRunner"]
```

.venv/lib/python3.13/site-packages/pip/_vendor/pyproject_hooks/_impl.py
```
1 | import json
2 | import os
3 | import sys
4 | import tempfile
5 | from contextlib import contextmanager
6 | from os.path import abspath
7 | from os.path import join as pjoin
8 | from subprocess import STDOUT, check_call, check_output
9 | from typing import TYPE_CHECKING, Any, Iterator, Mapping, Optional, Sequence
10 | 
11 | from ._in_process import _in_proc_script_path
12 | 
13 | if TYPE_CHECKING:
14 |     from typing import Protocol
15 | 
16 |     class SubprocessRunner(Protocol):
17 |         """A protocol for the subprocess runner."""
18 | 
19 |         def __call__(
20 |             self,
21 |             cmd: Sequence[str],
22 |             cwd: Optional[str] = None,
23 |             extra_environ: Optional[Mapping[str, str]] = None,
24 |         ) -> None:
25 |             ...
26 | 
27 | 
28 | def write_json(obj: Mapping[str, Any], path: str, **kwargs) -> None:
29 |     with open(path, "w", encoding="utf-8") as f:
30 |         json.dump(obj, f, **kwargs)
31 | 
32 | 
33 | def read_json(path: str) -> Mapping[str, Any]:
34 |     with open(path, encoding="utf-8") as f:
35 |         return json.load(f)
36 | 
37 | 
38 | class BackendUnavailable(Exception):
39 |     """Will be raised if the backend cannot be imported in the hook process."""
40 | 
41 |     def __init__(
42 |         self,
43 |         traceback: str,
44 |         message: Optional[str] = None,
45 |         backend_name: Optional[str] = None,
46 |         backend_path: Optional[Sequence[str]] = None,
47 |     ) -> None:
48 |         # Preserving arg order for the sake of API backward compatibility.
49 |         self.backend_name = backend_name
50 |         self.backend_path = backend_path
51 |         self.traceback = traceback
52 |         super().__init__(message or "Error while importing backend")
53 | 
54 | 
55 | class HookMissing(Exception):
56 |     """Will be raised on missing hooks (if a fallback can't be used)."""
57 | 
58 |     def __init__(self, hook_name: str) -> None:
59 |         super().__init__(hook_name)
60 |         self.hook_name = hook_name
61 | 
62 | 
63 | class UnsupportedOperation(Exception):
64 |     """May be raised by build_sdist if the backend indicates that it can't."""
65 | 
66 |     def __init__(self, traceback: str) -> None:
67 |         self.traceback = traceback
68 | 
69 | 
70 | def default_subprocess_runner(
71 |     cmd: Sequence[str],
72 |     cwd: Optional[str] = None,
73 |     extra_environ: Optional[Mapping[str, str]] = None,
74 | ) -> None:
75 |     """The default method of calling the wrapper subprocess.
76 | 
77 |     This uses :func:`subprocess.check_call` under the hood.
78 |     """
79 |     env = os.environ.copy()
80 |     if extra_environ:
81 |         env.update(extra_environ)
82 | 
83 |     check_call(cmd, cwd=cwd, env=env)
84 | 
85 | 
86 | def quiet_subprocess_runner(
87 |     cmd: Sequence[str],
88 |     cwd: Optional[str] = None,
89 |     extra_environ: Optional[Mapping[str, str]] = None,
90 | ) -> None:
91 |     """Call the subprocess while suppressing output.
92 | 
93 |     This uses :func:`subprocess.check_output` under the hood.
94 |     """
95 |     env = os.environ.copy()
96 |     if extra_environ:
97 |         env.update(extra_environ)
98 | 
99 |     check_output(cmd, cwd=cwd, env=env, stderr=STDOUT)
100 | 
101 | 
102 | def norm_and_check(source_tree: str, requested: str) -> str:
103 |     """Normalise and check a backend path.
104 | 
105 |     Ensure that the requested backend path is specified as a relative path,
106 |     and resolves to a location under the given source tree.
107 | 
108 |     Return an absolute version of the requested path.
109 |     """
110 |     if os.path.isabs(requested):
111 |         raise ValueError("paths must be relative")
112 | 
113 |     abs_source = os.path.abspath(source_tree)
114 |     abs_requested = os.path.normpath(os.path.join(abs_source, requested))
115 |     # We have to use commonprefix for Python 2.7 compatibility. So we
116 |     # normalise case to avoid problems because commonprefix is a character
117 |     # based comparison :-(
118 |     norm_source = os.path.normcase(abs_source)
119 |     norm_requested = os.path.normcase(abs_requested)
120 |     if os.path.commonprefix([norm_source, norm_requested]) != norm_source:
121 |         raise ValueError("paths must be inside source tree")
122 | 
123 |     return abs_requested
124 | 
125 | 
126 | class BuildBackendHookCaller:
127 |     """A wrapper to call the build backend hooks for a source directory."""
128 | 
129 |     def __init__(
130 |         self,
131 |         source_dir: str,
132 |         build_backend: str,
133 |         backend_path: Optional[Sequence[str]] = None,
134 |         runner: Optional["SubprocessRunner"] = None,
135 |         python_executable: Optional[str] = None,
136 |     ) -> None:
137 |         """
138 |         :param source_dir: The source directory to invoke the build backend for
139 |         :param build_backend: The build backend spec
140 |         :param backend_path: Additional path entries for the build backend spec
141 |         :param runner: The :ref:`subprocess runner <Subprocess Runners>` to use
142 |         :param python_executable:
143 |             The Python executable used to invoke the build backend
144 |         """
145 |         if runner is None:
146 |             runner = default_subprocess_runner
147 | 
148 |         self.source_dir = abspath(source_dir)
149 |         self.build_backend = build_backend
150 |         if backend_path:
151 |             backend_path = [norm_and_check(self.source_dir, p) for p in backend_path]
152 |         self.backend_path = backend_path
153 |         self._subprocess_runner = runner
154 |         if not python_executable:
155 |             python_executable = sys.executable
156 |         self.python_executable = python_executable
157 | 
158 |     @contextmanager
159 |     def subprocess_runner(self, runner: "SubprocessRunner") -> Iterator[None]:
160 |         """A context manager for temporarily overriding the default
161 |         :ref:`subprocess runner <Subprocess Runners>`.
162 | 
163 |         :param runner: The new subprocess runner to use within the context.
164 | 
165 |         .. code-block:: python
166 | 
167 |             hook_caller = BuildBackendHookCaller(...)
168 |             with hook_caller.subprocess_runner(quiet_subprocess_runner):
169 |                 ...
170 |         """
171 |         prev = self._subprocess_runner
172 |         self._subprocess_runner = runner
173 |         try:
174 |             yield
175 |         finally:
176 |             self._subprocess_runner = prev
177 | 
178 |     def _supported_features(self) -> Sequence[str]:
179 |         """Return the list of optional features supported by the backend."""
180 |         return self._call_hook("_supported_features", {})
181 | 
182 |     def get_requires_for_build_wheel(
183 |         self,
184 |         config_settings: Optional[Mapping[str, Any]] = None,
185 |     ) -> Sequence[str]:
186 |         """Get additional dependencies required for building a wheel.
187 | 
188 |         :param config_settings: The configuration settings for the build backend
189 |         :returns: A list of :pep:`dependency specifiers <508>`.
190 | 
191 |         .. admonition:: Fallback
192 | 
193 |             If the build backend does not defined a hook with this name, an
194 |             empty list will be returned.
195 |         """
196 |         return self._call_hook(
197 |             "get_requires_for_build_wheel", {"config_settings": config_settings}
198 |         )
199 | 
200 |     def prepare_metadata_for_build_wheel(
201 |         self,
202 |         metadata_directory: str,
203 |         config_settings: Optional[Mapping[str, Any]] = None,
204 |         _allow_fallback: bool = True,
205 |     ) -> str:
206 |         """Prepare a ``*.dist-info`` folder with metadata for this project.
207 | 
208 |         :param metadata_directory: The directory to write the metadata to
209 |         :param config_settings: The configuration settings for the build backend
210 |         :param _allow_fallback:
211 |             Whether to allow the fallback to building a wheel and extracting
212 |             the metadata from it. Should be passed as a keyword argument only.
213 | 
214 |         :returns: Name of the newly created subfolder within
215 |                   ``metadata_directory``, containing the metadata.
216 | 
217 |         .. admonition:: Fallback
218 | 
219 |             If the build backend does not define a hook with this name and
220 |             ``_allow_fallback`` is truthy, the backend will be asked to build a
221 |             wheel via the ``build_wheel`` hook and the dist-info extracted from
222 |             that will be returned.
223 |         """
224 |         return self._call_hook(
225 |             "prepare_metadata_for_build_wheel",
226 |             {
227 |                 "metadata_directory": abspath(metadata_directory),
228 |                 "config_settings": config_settings,
229 |                 "_allow_fallback": _allow_fallback,
230 |             },
231 |         )
232 | 
233 |     def build_wheel(
234 |         self,
235 |         wheel_directory: str,
236 |         config_settings: Optional[Mapping[str, Any]] = None,
237 |         metadata_directory: Optional[str] = None,
238 |     ) -> str:
239 |         """Build a wheel from this project.
240 | 
241 |         :param wheel_directory: The directory to write the wheel to
242 |         :param config_settings: The configuration settings for the build backend
243 |         :param metadata_directory: The directory to reuse existing metadata from
244 |         :returns:
245 |             The name of the newly created wheel within ``wheel_directory``.
246 | 
247 |         .. admonition:: Interaction with fallback
248 | 
249 |             If the ``build_wheel`` hook was called in the fallback for
250 |             :meth:`prepare_metadata_for_build_wheel`, the build backend would
251 |             not be invoked. Instead, the previously built wheel will be copied
252 |             to ``wheel_directory`` and the name of that file will be returned.
253 |         """
254 |         if metadata_directory is not None:
255 |             metadata_directory = abspath(metadata_directory)
256 |         return self._call_hook(
257 |             "build_wheel",
258 |             {
259 |                 "wheel_directory": abspath(wheel_directory),
260 |                 "config_settings": config_settings,
261 |                 "metadata_directory": metadata_directory,
262 |             },
263 |         )
264 | 
265 |     def get_requires_for_build_editable(
266 |         self,
267 |         config_settings: Optional[Mapping[str, Any]] = None,
268 |     ) -> Sequence[str]:
269 |         """Get additional dependencies required for building an editable wheel.
270 | 
271 |         :param config_settings: The configuration settings for the build backend
272 |         :returns: A list of :pep:`dependency specifiers <508>`.
273 | 
274 |         .. admonition:: Fallback
275 | 
276 |             If the build backend does not defined a hook with this name, an
277 |             empty list will be returned.
278 |         """
279 |         return self._call_hook(
280 |             "get_requires_for_build_editable", {"config_settings": config_settings}
281 |         )
282 | 
283 |     def prepare_metadata_for_build_editable(
284 |         self,
285 |         metadata_directory: str,
286 |         config_settings: Optional[Mapping[str, Any]] = None,
287 |         _allow_fallback: bool = True,
288 |     ) -> Optional[str]:
289 |         """Prepare a ``*.dist-info`` folder with metadata for this project.
290 | 
291 |         :param metadata_directory: The directory to write the metadata to
292 |         :param config_settings: The configuration settings for the build backend
293 |         :param _allow_fallback:
294 |             Whether to allow the fallback to building a wheel and extracting
295 |             the metadata from it. Should be passed as a keyword argument only.
296 |         :returns: Name of the newly created subfolder within
297 |                   ``metadata_directory``, containing the metadata.
298 | 
299 |         .. admonition:: Fallback
300 | 
301 |             If the build backend does not define a hook with this name and
302 |             ``_allow_fallback`` is truthy, the backend will be asked to build a
303 |             wheel via the ``build_editable`` hook and the dist-info
304 |             extracted from that will be returned.
305 |         """
306 |         return self._call_hook(
307 |             "prepare_metadata_for_build_editable",
308 |             {
309 |                 "metadata_directory": abspath(metadata_directory),
310 |                 "config_settings": config_settings,
311 |                 "_allow_fallback": _allow_fallback,
312 |             },
313 |         )
314 | 
315 |     def build_editable(
316 |         self,
317 |         wheel_directory: str,
318 |         config_settings: Optional[Mapping[str, Any]] = None,
319 |         metadata_directory: Optional[str] = None,
320 |     ) -> str:
321 |         """Build an editable wheel from this project.
322 | 
323 |         :param wheel_directory: The directory to write the wheel to
324 |         :param config_settings: The configuration settings for the build backend
325 |         :param metadata_directory: The directory to reuse existing metadata from
326 |         :returns:
327 |             The name of the newly created wheel within ``wheel_directory``.
328 | 
329 |         .. admonition:: Interaction with fallback
330 | 
331 |             If the ``build_editable`` hook was called in the fallback for
332 |             :meth:`prepare_metadata_for_build_editable`, the build backend
333 |             would not be invoked. Instead, the previously built wheel will be
334 |             copied to ``wheel_directory`` and the name of that file will be
335 |             returned.
336 |         """
337 |         if metadata_directory is not None:
338 |             metadata_directory = abspath(metadata_directory)
339 |         return self._call_hook(
340 |             "build_editable",
341 |             {
342 |                 "wheel_directory": abspath(wheel_directory),
343 |                 "config_settings": config_settings,
344 |                 "metadata_directory": metadata_directory,
345 |             },
346 |         )
347 | 
[TRUNCATED]
```

.venv/lib/python3.13/site-packages/pip/_vendor/pyproject_hooks/py.typed
```
```

.venv/lib/python3.13/site-packages/pip/_vendor/requests/__init__.py
```
1 | #   __
2 | #  /__)  _  _     _   _ _/   _
3 | # / (   (- (/ (/ (- _)  /  _)
4 | #          /
5 | 
6 | """
7 | Requests HTTP Library
8 | ~~~~~~~~~~~~~~~~~~~~~
9 | 
10 | Requests is an HTTP library, written in Python, for human beings.
11 | Basic GET usage:
12 | 
13 |    >>> import requests
14 |    >>> r = requests.get('https://www.python.org')
15 |    >>> r.status_code
16 |    200
17 |    >>> b'Python is a programming language' in r.content
18 |    True
19 | 
20 | ... or POST:
21 | 
22 |    >>> payload = dict(key1='value1', key2='value2')
23 |    >>> r = requests.post('https://httpbin.org/post', data=payload)
24 |    >>> print(r.text)
25 |    {
26 |      ...
27 |      "form": {
28 |        "key1": "value1",
29 |        "key2": "value2"
30 |      },
31 |      ...
32 |    }
33 | 
34 | The other HTTP methods are supported - see `requests.api`. Full documentation
35 | is at <https://requests.readthedocs.io>.
36 | 
37 | :copyright: (c) 2017 by Kenneth Reitz.
38 | :license: Apache 2.0, see LICENSE for more details.
39 | """
40 | 
41 | import warnings
42 | 
43 | from pip._vendor import urllib3
44 | 
45 | from .exceptions import RequestsDependencyWarning
46 | 
47 | charset_normalizer_version = None
48 | chardet_version = None
49 | 
50 | 
51 | def check_compatibility(urllib3_version, chardet_version, charset_normalizer_version):
52 |     urllib3_version = urllib3_version.split(".")
53 |     assert urllib3_version != ["dev"]  # Verify urllib3 isn't installed from git.
54 | 
55 |     # Sometimes, urllib3 only reports its version as 16.1.
56 |     if len(urllib3_version) == 2:
57 |         urllib3_version.append("0")
58 | 
59 |     # Check urllib3 for compatibility.
60 |     major, minor, patch = urllib3_version  # noqa: F811
61 |     major, minor, patch = int(major), int(minor), int(patch)
62 |     # urllib3 >= 1.21.1
63 |     assert major >= 1
64 |     if major == 1:
65 |         assert minor >= 21
66 | 
67 |     # Check charset_normalizer for compatibility.
68 |     if chardet_version:
69 |         major, minor, patch = chardet_version.split(".")[:3]
70 |         major, minor, patch = int(major), int(minor), int(patch)
71 |         # chardet_version >= 3.0.2, < 6.0.0
72 |         assert (3, 0, 2) <= (major, minor, patch) < (6, 0, 0)
73 |     elif charset_normalizer_version:
74 |         major, minor, patch = charset_normalizer_version.split(".")[:3]
75 |         major, minor, patch = int(major), int(minor), int(patch)
76 |         # charset_normalizer >= 2.0.0 < 4.0.0
77 |         assert (2, 0, 0) <= (major, minor, patch) < (4, 0, 0)
78 |     else:
79 |         # pip does not need or use character detection
80 |         pass
81 | 
82 | 
83 | def _check_cryptography(cryptography_version):
84 |     # cryptography < 1.3.4
85 |     try:
86 |         cryptography_version = list(map(int, cryptography_version.split(".")))
87 |     except ValueError:
88 |         return
89 | 
90 |     if cryptography_version < [1, 3, 4]:
91 |         warning = "Old version of cryptography ({}) may cause slowdown.".format(
92 |             cryptography_version
93 |         )
94 |         warnings.warn(warning, RequestsDependencyWarning)
95 | 
96 | 
97 | # Check imported dependencies for compatibility.
98 | try:
99 |     check_compatibility(
100 |         urllib3.__version__, chardet_version, charset_normalizer_version
101 |     )
102 | except (AssertionError, ValueError):
103 |     warnings.warn(
104 |         "urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported "
105 |         "version!".format(
106 |             urllib3.__version__, chardet_version, charset_normalizer_version
107 |         ),
108 |         RequestsDependencyWarning,
109 |     )
110 | 
111 | # Attempt to enable urllib3's fallback for SNI support
112 | # if the standard library doesn't support SNI or the
113 | # 'ssl' library isn't available.
114 | try:
115 |     # Note: This logic prevents upgrading cryptography on Windows, if imported
116 |     #       as part of pip.
117 |     from pip._internal.utils.compat import WINDOWS
118 |     if not WINDOWS:
119 |         raise ImportError("pip internals: don't import cryptography on Windows")
120 |     try:
121 |         import ssl
122 |     except ImportError:
123 |         ssl = None
124 | 
125 |     if not getattr(ssl, "HAS_SNI", False):
126 |         from pip._vendor.urllib3.contrib import pyopenssl
127 | 
128 |         pyopenssl.inject_into_urllib3()
129 | 
130 |         # Check cryptography version
131 |         from cryptography import __version__ as cryptography_version
132 | 
133 |         _check_cryptography(cryptography_version)
134 | except ImportError:
135 |     pass
136 | 
137 | # urllib3's DependencyWarnings should be silenced.
138 | from pip._vendor.urllib3.exceptions import DependencyWarning
139 | 
140 | warnings.simplefilter("ignore", DependencyWarning)
141 | 
142 | # Set default logging handler to avoid "No handler found" warnings.
143 | import logging
144 | from logging import NullHandler
145 | 
146 | from . import packages, utils
147 | from .__version__ import (
148 |     __author__,
149 |     __author_email__,
150 |     __build__,
151 |     __cake__,
152 |     __copyright__,
153 |     __description__,
154 |     __license__,
155 |     __title__,
156 |     __url__,
157 |     __version__,
158 | )
159 | from .api import delete, get, head, options, patch, post, put, request
160 | from .exceptions import (
161 |     ConnectionError,
162 |     ConnectTimeout,
163 |     FileModeWarning,
164 |     HTTPError,
165 |     JSONDecodeError,
166 |     ReadTimeout,
167 |     RequestException,
168 |     Timeout,
169 |     TooManyRedirects,
170 |     URLRequired,
171 | )
172 | from .models import PreparedRequest, Request, Response
173 | from .sessions import Session, session
174 | from .status_codes import codes
175 | 
176 | logging.getLogger(__name__).addHandler(NullHandler())
177 | 
178 | # FileModeWarnings go off per the default.
179 | warnings.simplefilter("default", FileModeWarning, append=True)
```

.venv/lib/python3.13/site-packages/pip/_vendor/requests/__version__.py
```
1 | # .-. .-. .-. . . .-. .-. .-. .-.
2 | # |(  |-  |.| | | |-  `-.  |  `-.
3 | # ' ' `-' `-`.`-' `-' `-'  '  `-'
4 | 
5 | __title__ = "requests"
6 | __description__ = "Python HTTP for Humans."
7 | __url__ = "https://requests.readthedocs.io"
8 | __version__ = "2.32.3"
9 | __build__ = 0x023203
10 | __author__ = "Kenneth Reitz"
11 | __author_email__ = "me@kennethreitz.org"
12 | __license__ = "Apache-2.0"
13 | __copyright__ = "Copyright Kenneth Reitz"
14 | __cake__ = "\u2728 \U0001f370 \u2728"
```

.venv/lib/python3.13/site-packages/pip/_vendor/requests/_internal_utils.py
```
1 | """
2 | requests._internal_utils
3 | ~~~~~~~~~~~~~~
4 | 
5 | Provides utility functions that are consumed internally by Requests
6 | which depend on extremely few external helpers (such as compat)
7 | """
8 | import re
9 | 
10 | from .compat import builtin_str
11 | 
12 | _VALID_HEADER_NAME_RE_BYTE = re.compile(rb"^[^:\s][^:\r\n]*$")
13 | _VALID_HEADER_NAME_RE_STR = re.compile(r"^[^:\s][^:\r\n]*$")
14 | _VALID_HEADER_VALUE_RE_BYTE = re.compile(rb"^\S[^\r\n]*$|^$")
15 | _VALID_HEADER_VALUE_RE_STR = re.compile(r"^\S[^\r\n]*$|^$")
16 | 
17 | _HEADER_VALIDATORS_STR = (_VALID_HEADER_NAME_RE_STR, _VALID_HEADER_VALUE_RE_STR)
18 | _HEADER_VALIDATORS_BYTE = (_VALID_HEADER_NAME_RE_BYTE, _VALID_HEADER_VALUE_RE_BYTE)
19 | HEADER_VALIDATORS = {
20 |     bytes: _HEADER_VALIDATORS_BYTE,
21 |     str: _HEADER_VALIDATORS_STR,
22 | }
23 | 
24 | 
25 | def to_native_string(string, encoding="ascii"):
26 |     """Given a string object, regardless of type, returns a representation of
27 |     that string in the native string type, encoding and decoding where
28 |     necessary. This assumes ASCII unless told otherwise.
29 |     """
30 |     if isinstance(string, builtin_str):
31 |         out = string
32 |     else:
33 |         out = string.decode(encoding)
34 | 
35 |     return out
36 | 
37 | 
38 | def unicode_is_ascii(u_string):
39 |     """Determine if unicode string only contains ASCII characters.
40 | 
41 |     :param str u_string: unicode string to check. Must be unicode
42 |         and not Python 2 `str`.
43 |     :rtype: bool
44 |     """
45 |     assert isinstance(u_string, str)
46 |     try:
47 |         u_string.encode("ascii")
48 |         return True
49 |     except UnicodeEncodeError:
50 |         return False
```

.venv/lib/python3.13/site-packages/pip/_vendor/requests/adapters.py
```
1 | """
2 | requests.adapters
3 | ~~~~~~~~~~~~~~~~~
4 | 
5 | This module contains the transport adapters that Requests uses to define
6 | and maintain connections.
7 | """
8 | 
9 | import os.path
10 | import socket  # noqa: F401
11 | import typing
12 | import warnings
13 | 
14 | from pip._vendor.urllib3.exceptions import ClosedPoolError, ConnectTimeoutError
15 | from pip._vendor.urllib3.exceptions import HTTPError as _HTTPError
16 | from pip._vendor.urllib3.exceptions import InvalidHeader as _InvalidHeader
17 | from pip._vendor.urllib3.exceptions import (
18 |     LocationValueError,
19 |     MaxRetryError,
20 |     NewConnectionError,
21 |     ProtocolError,
22 | )
23 | from pip._vendor.urllib3.exceptions import ProxyError as _ProxyError
24 | from pip._vendor.urllib3.exceptions import ReadTimeoutError, ResponseError
25 | from pip._vendor.urllib3.exceptions import SSLError as _SSLError
26 | from pip._vendor.urllib3.poolmanager import PoolManager, proxy_from_url
27 | from pip._vendor.urllib3.util import Timeout as TimeoutSauce
28 | from pip._vendor.urllib3.util import parse_url
29 | from pip._vendor.urllib3.util.retry import Retry
30 | from pip._vendor.urllib3.util.ssl_ import create_urllib3_context
31 | 
32 | from .auth import _basic_auth_str
33 | from .compat import basestring, urlparse
34 | from .cookies import extract_cookies_to_jar
35 | from .exceptions import (
36 |     ConnectionError,
37 |     ConnectTimeout,
38 |     InvalidHeader,
39 |     InvalidProxyURL,
40 |     InvalidSchema,
41 |     InvalidURL,
42 |     ProxyError,
43 |     ReadTimeout,
44 |     RetryError,
45 |     SSLError,
46 | )
47 | from .models import Response
48 | from .structures import CaseInsensitiveDict
49 | from .utils import (
50 |     DEFAULT_CA_BUNDLE_PATH,
51 |     extract_zipped_paths,
52 |     get_auth_from_url,
53 |     get_encoding_from_headers,
54 |     prepend_scheme_if_needed,
55 |     select_proxy,
56 |     urldefragauth,
57 | )
58 | 
59 | try:
60 |     from pip._vendor.urllib3.contrib.socks import SOCKSProxyManager
61 | except ImportError:
62 | 
63 |     def SOCKSProxyManager(*args, **kwargs):
64 |         raise InvalidSchema("Missing dependencies for SOCKS support.")
65 | 
66 | 
67 | if typing.TYPE_CHECKING:
68 |     from .models import PreparedRequest
69 | 
70 | 
71 | DEFAULT_POOLBLOCK = False
72 | DEFAULT_POOLSIZE = 10
73 | DEFAULT_RETRIES = 0
74 | DEFAULT_POOL_TIMEOUT = None
75 | 
76 | 
77 | try:
78 |     import ssl  # noqa: F401
79 | 
80 |     _preloaded_ssl_context = create_urllib3_context()
81 |     _preloaded_ssl_context.load_verify_locations(
82 |         extract_zipped_paths(DEFAULT_CA_BUNDLE_PATH)
83 |     )
84 | except ImportError:
85 |     # Bypass default SSLContext creation when Python
86 |     # interpreter isn't built with the ssl module.
87 |     _preloaded_ssl_context = None
88 | 
89 | 
90 | def _urllib3_request_context(
91 |     request: "PreparedRequest",
92 |     verify: "bool | str | None",
93 |     client_cert: "typing.Tuple[str, str] | str | None",
94 |     poolmanager: "PoolManager",
95 | ) -> "(typing.Dict[str, typing.Any], typing.Dict[str, typing.Any])":
96 |     host_params = {}
97 |     pool_kwargs = {}
98 |     parsed_request_url = urlparse(request.url)
99 |     scheme = parsed_request_url.scheme.lower()
100 |     port = parsed_request_url.port
101 | 
102 |     # Determine if we have and should use our default SSLContext
103 |     # to optimize performance on standard requests.
104 |     poolmanager_kwargs = getattr(poolmanager, "connection_pool_kw", {})
105 |     has_poolmanager_ssl_context = poolmanager_kwargs.get("ssl_context")
106 |     should_use_default_ssl_context = (
107 |         _preloaded_ssl_context is not None and not has_poolmanager_ssl_context
108 |     )
109 | 
110 |     cert_reqs = "CERT_REQUIRED"
111 |     if verify is False:
112 |         cert_reqs = "CERT_NONE"
113 |     elif verify is True and should_use_default_ssl_context:
114 |         pool_kwargs["ssl_context"] = _preloaded_ssl_context
115 |     elif isinstance(verify, str):
116 |         if not os.path.isdir(verify):
117 |             pool_kwargs["ca_certs"] = verify
118 |         else:
119 |             pool_kwargs["ca_cert_dir"] = verify
120 |     pool_kwargs["cert_reqs"] = cert_reqs
121 |     if client_cert is not None:
122 |         if isinstance(client_cert, tuple) and len(client_cert) == 2:
123 |             pool_kwargs["cert_file"] = client_cert[0]
124 |             pool_kwargs["key_file"] = client_cert[1]
125 |         else:
126 |             # According to our docs, we allow users to specify just the client
127 |             # cert path
128 |             pool_kwargs["cert_file"] = client_cert
129 |     host_params = {
130 |         "scheme": scheme,
131 |         "host": parsed_request_url.hostname,
132 |         "port": port,
133 |     }
134 |     return host_params, pool_kwargs
135 | 
136 | 
137 | class BaseAdapter:
138 |     """The Base Transport Adapter"""
139 | 
140 |     def __init__(self):
141 |         super().__init__()
142 | 
143 |     def send(
144 |         self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None
145 |     ):
146 |         """Sends PreparedRequest object. Returns Response object.
147 | 
148 |         :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.
149 |         :param stream: (optional) Whether to stream the request content.
150 |         :param timeout: (optional) How long to wait for the server to send
151 |             data before giving up, as a float, or a :ref:`(connect timeout,
152 |             read timeout) <timeouts>` tuple.
153 |         :type timeout: float or tuple
154 |         :param verify: (optional) Either a boolean, in which case it controls whether we verify
155 |             the server's TLS certificate, or a string, in which case it must be a path
156 |             to a CA bundle to use
157 |         :param cert: (optional) Any user-provided SSL certificate to be trusted.
158 |         :param proxies: (optional) The proxies dictionary to apply to the request.
159 |         """
160 |         raise NotImplementedError
161 | 
162 |     def close(self):
163 |         """Cleans up adapter specific items."""
164 |         raise NotImplementedError
165 | 
166 | 
167 | class HTTPAdapter(BaseAdapter):
168 |     """The built-in HTTP Adapter for urllib3.
169 | 
170 |     Provides a general-case interface for Requests sessions to contact HTTP and
171 |     HTTPS urls by implementing the Transport Adapter interface. This class will
172 |     usually be created by the :class:`Session <Session>` class under the
173 |     covers.
174 | 
175 |     :param pool_connections: The number of urllib3 connection pools to cache.
176 |     :param pool_maxsize: The maximum number of connections to save in the pool.
177 |     :param max_retries: The maximum number of retries each connection
178 |         should attempt. Note, this applies only to failed DNS lookups, socket
179 |         connections and connection timeouts, never to requests where data has
180 |         made it to the server. By default, Requests does not retry failed
181 |         connections. If you need granular control over the conditions under
182 |         which we retry a request, import urllib3's ``Retry`` class and pass
183 |         that instead.
184 |     :param pool_block: Whether the connection pool should block for connections.
185 | 
186 |     Usage::
187 | 
188 |       >>> import requests
189 |       >>> s = requests.Session()
190 |       >>> a = requests.adapters.HTTPAdapter(max_retries=3)
191 |       >>> s.mount('http://', a)
192 |     """
193 | 
194 |     __attrs__ = [
195 |         "max_retries",
196 |         "config",
197 |         "_pool_connections",
198 |         "_pool_maxsize",
199 |         "_pool_block",
200 |     ]
201 | 
202 |     def __init__(
203 |         self,
204 |         pool_connections=DEFAULT_POOLSIZE,
205 |         pool_maxsize=DEFAULT_POOLSIZE,
206 |         max_retries=DEFAULT_RETRIES,
207 |         pool_block=DEFAULT_POOLBLOCK,
208 |     ):
209 |         if max_retries == DEFAULT_RETRIES:
210 |             self.max_retries = Retry(0, read=False)
211 |         else:
212 |             self.max_retries = Retry.from_int(max_retries)
213 |         self.config = {}
214 |         self.proxy_manager = {}
215 | 
216 |         super().__init__()
217 | 
218 |         self._pool_connections = pool_connections
219 |         self._pool_maxsize = pool_maxsize
220 |         self._pool_block = pool_block
221 | 
222 |         self.init_poolmanager(pool_connections, pool_maxsize, block=pool_block)
223 | 
224 |     def __getstate__(self):
225 |         return {attr: getattr(self, attr, None) for attr in self.__attrs__}
226 | 
227 |     def __setstate__(self, state):
228 |         # Can't handle by adding 'proxy_manager' to self.__attrs__ because
229 |         # self.poolmanager uses a lambda function, which isn't pickleable.
230 |         self.proxy_manager = {}
231 |         self.config = {}
232 | 
233 |         for attr, value in state.items():
234 |             setattr(self, attr, value)
235 | 
236 |         self.init_poolmanager(
237 |             self._pool_connections, self._pool_maxsize, block=self._pool_block
238 |         )
239 | 
240 |     def init_poolmanager(
241 |         self, connections, maxsize, block=DEFAULT_POOLBLOCK, **pool_kwargs
242 |     ):
243 |         """Initializes a urllib3 PoolManager.
244 | 
245 |         This method should not be called from user code, and is only
246 |         exposed for use when subclassing the
247 |         :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.
248 | 
249 |         :param connections: The number of urllib3 connection pools to cache.
250 |         :param maxsize: The maximum number of connections to save in the pool.
251 |         :param block: Block when no free connections are available.
252 |         :param pool_kwargs: Extra keyword arguments used to initialize the Pool Manager.
253 |         """
254 |         # save these values for pickling
255 |         self._pool_connections = connections
256 |         self._pool_maxsize = maxsize
257 |         self._pool_block = block
258 | 
259 |         self.poolmanager = PoolManager(
260 |             num_pools=connections,
261 |             maxsize=maxsize,
262 |             block=block,
263 |             **pool_kwargs,
264 |         )
265 | 
266 |     def proxy_manager_for(self, proxy, **proxy_kwargs):
267 |         """Return urllib3 ProxyManager for the given proxy.
268 | 
269 |         This method should not be called from user code, and is only
270 |         exposed for use when subclassing the
271 |         :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.
272 | 
273 |         :param proxy: The proxy to return a urllib3 ProxyManager for.
274 |         :param proxy_kwargs: Extra keyword arguments used to configure the Proxy Manager.
275 |         :returns: ProxyManager
276 |         :rtype: urllib3.ProxyManager
277 |         """
278 |         if proxy in self.proxy_manager:
279 |             manager = self.proxy_manager[proxy]
280 |         elif proxy.lower().startswith("socks"):
281 |             username, password = get_auth_from_url(proxy)
282 |             manager = self.proxy_manager[proxy] = SOCKSProxyManager(
283 |                 proxy,
284 |                 username=username,
285 |                 password=password,
286 |                 num_pools=self._pool_connections,
287 |                 maxsize=self._pool_maxsize,
288 |                 block=self._pool_block,
289 |                 **proxy_kwargs,
290 |             )
291 |         else:
292 |             proxy_headers = self.proxy_headers(proxy)
293 |             manager = self.proxy_manager[proxy] = proxy_from_url(
294 |                 proxy,
295 |                 proxy_headers=proxy_headers,
296 |                 num_pools=self._pool_connections,
297 |                 maxsize=self._pool_maxsize,
298 |                 block=self._pool_block,
299 |                 **proxy_kwargs,
300 |             )
301 | 
302 |         return manager
303 | 
304 |     def cert_verify(self, conn, url, verify, cert):
305 |         """Verify a SSL certificate. This method should not be called from user
306 |         code, and is only exposed for use when subclassing the
307 |         :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.
308 | 
309 |         :param conn: The urllib3 connection object associated with the cert.
310 |         :param url: The requested URL.
311 |         :param verify: Either a boolean, in which case it controls whether we verify
312 |             the server's TLS certificate, or a string, in which case it must be a path
313 |             to a CA bundle to use
314 |         :param cert: The SSL certificate to verify.
315 |         """
316 |         if url.lower().startswith("https") and verify:
317 |             conn.cert_reqs = "CERT_REQUIRED"
318 | 
319 |             # Only load the CA certificates if 'verify' is a string indicating the CA bundle to use.
320 |             # Otherwise, if verify is a boolean, we don't load anything since
321 |             # the connection will be using a context with the default certificates already loaded,
322 |             # and this avoids a call to the slow load_verify_locations()
323 |             if verify is not True:
324 |                 # `verify` must be a str with a path then
325 |                 cert_loc = verify
326 | 
327 |                 if not os.path.exists(cert_loc):
328 |                     raise OSError(
329 |                         f"Could not find a suitable TLS CA certificate bundle, "
330 |                         f"invalid path: {cert_loc}"
331 |                     )
332 | 
333 |                 if not os.path.isdir(cert_loc):
334 |                     conn.ca_certs = cert_loc
335 |                 else:
336 |                     conn.ca_cert_dir = cert_loc
337 |         else:
338 |             conn.cert_reqs = "CERT_NONE"
339 |             conn.ca_certs = None
340 |             conn.ca_cert_dir = None
341 | 
342 |         if cert:
343 |             if not isinstance(cert, basestring):
344 |                 conn.cert_file = cert[0]
345 |                 conn.key_file = cert[1]
346 |             else:
347 |                 conn.cert_file = cert
348 |                 conn.key_file = None
349 |             if conn.cert_file and not os.path.exists(conn.cert_file):
[TRUNCATED]
```

.venv/lib/python3.13/site-packages/pip/_vendor/requests/api.py
```
1 | """
2 | requests.api
3 | ~~~~~~~~~~~~
4 | 
5 | This module implements the Requests API.
6 | 
7 | :copyright: (c) 2012 by Kenneth Reitz.
8 | :license: Apache2, see LICENSE for more details.
9 | """
10 | 
11 | from . import sessions
12 | 
13 | 
14 | def request(method, url, **kwargs):
15 |     """Constructs and sends a :class:`Request <Request>`.
16 | 
17 |     :param method: method for the new :class:`Request` object: ``GET``, ``OPTIONS``, ``HEAD``, ``POST``, ``PUT``, ``PATCH``, or ``DELETE``.
18 |     :param url: URL for the new :class:`Request` object.
19 |     :param params: (optional) Dictionary, list of tuples or bytes to send
20 |         in the query string for the :class:`Request`.
21 |     :param data: (optional) Dictionary, list of tuples, bytes, or file-like
22 |         object to send in the body of the :class:`Request`.
23 |     :param json: (optional) A JSON serializable Python object to send in the body of the :class:`Request`.
24 |     :param headers: (optional) Dictionary of HTTP Headers to send with the :class:`Request`.
25 |     :param cookies: (optional) Dict or CookieJar object to send with the :class:`Request`.
26 |     :param files: (optional) Dictionary of ``'name': file-like-objects`` (or ``{'name': file-tuple}``) for multipart encoding upload.
27 |         ``file-tuple`` can be a 2-tuple ``('filename', fileobj)``, 3-tuple ``('filename', fileobj, 'content_type')``
28 |         or a 4-tuple ``('filename', fileobj, 'content_type', custom_headers)``, where ``'content_type'`` is a string
29 |         defining the content type of the given file and ``custom_headers`` a dict-like object containing additional headers
30 |         to add for the file.
31 |     :param auth: (optional) Auth tuple to enable Basic/Digest/Custom HTTP Auth.
32 |     :param timeout: (optional) How many seconds to wait for the server to send data
33 |         before giving up, as a float, or a :ref:`(connect timeout, read
34 |         timeout) <timeouts>` tuple.
35 |     :type timeout: float or tuple
36 |     :param allow_redirects: (optional) Boolean. Enable/disable GET/OPTIONS/POST/PUT/PATCH/DELETE/HEAD redirection. Defaults to ``True``.
37 |     :type allow_redirects: bool
38 |     :param proxies: (optional) Dictionary mapping protocol to the URL of the proxy.
39 |     :param verify: (optional) Either a boolean, in which case it controls whether we verify
40 |             the server's TLS certificate, or a string, in which case it must be a path
41 |             to a CA bundle to use. Defaults to ``True``.
42 |     :param stream: (optional) if ``False``, the response content will be immediately downloaded.
43 |     :param cert: (optional) if String, path to ssl client cert file (.pem). If Tuple, ('cert', 'key') pair.
44 |     :return: :class:`Response <Response>` object
45 |     :rtype: requests.Response
46 | 
47 |     Usage::
48 | 
49 |       >>> import requests
50 |       >>> req = requests.request('GET', 'https://httpbin.org/get')
51 |       >>> req
52 |       <Response [200]>
53 |     """
54 | 
55 |     # By using the 'with' statement we are sure the session is closed, thus we
56 |     # avoid leaving sockets open which can trigger a ResourceWarning in some
57 |     # cases, and look like a memory leak in others.
58 |     with sessions.Session() as session:
59 |         return session.request(method=method, url=url, **kwargs)
60 | 
61 | 
62 | def get(url, params=None, **kwargs):
63 |     r"""Sends a GET request.
64 | 
65 |     :param url: URL for the new :class:`Request` object.
66 |     :param params: (optional) Dictionary, list of tuples or bytes to send
67 |         in the query string for the :class:`Request`.
68 |     :param \*\*kwargs: Optional arguments that ``request`` takes.
69 |     :return: :class:`Response <Response>` object
70 |     :rtype: requests.Response
71 |     """
72 | 
73 |     return request("get", url, params=params, **kwargs)
74 | 
75 | 
76 | def options(url, **kwargs):
77 |     r"""Sends an OPTIONS request.
78 | 
79 |     :param url: URL for the new :class:`Request` object.
80 |     :param \*\*kwargs: Optional arguments that ``request`` takes.
81 |     :return: :class:`Response <Response>` object
82 |     :rtype: requests.Response
83 |     """
84 | 
85 |     return request("options", url, **kwargs)
86 | 
87 | 
88 | def head(url, **kwargs):
89 |     r"""Sends a HEAD request.
90 | 
91 |     :param url: URL for the new :class:`Request` object.
92 |     :param \*\*kwargs: Optional arguments that ``request`` takes. If
93 |         `allow_redirects` is not provided, it will be set to `False` (as
94 |         opposed to the default :meth:`request` behavior).
95 |     :return: :class:`Response <Response>` object
96 |     :rtype: requests.Response
97 |     """
98 | 
99 |     kwargs.setdefault("allow_redirects", False)
100 |     return request("head", url, **kwargs)
101 | 
102 | 
103 | def post(url, data=None, json=None, **kwargs):
104 |     r"""Sends a POST request.
105 | 
106 |     :param url: URL for the new :class:`Request` object.
107 |     :param data: (optional) Dictionary, list of tuples, bytes, or file-like
108 |         object to send in the body of the :class:`Request`.
109 |     :param json: (optional) A JSON serializable Python object to send in the body of the :class:`Request`.
110 |     :param \*\*kwargs: Optional arguments that ``request`` takes.
111 |     :return: :class:`Response <Response>` object
112 |     :rtype: requests.Response
113 |     """
114 | 
115 |     return request("post", url, data=data, json=json, **kwargs)
116 | 
117 | 
118 | def put(url, data=None, **kwargs):
119 |     r"""Sends a PUT request.
120 | 
121 |     :param url: URL for the new :class:`Request` object.
122 |     :param data: (optional) Dictionary, list of tuples, bytes, or file-like
123 |         object to send in the body of the :class:`Request`.
124 |     :param json: (optional) A JSON serializable Python object to send in the body of the :class:`Request`.
125 |     :param \*\*kwargs: Optional arguments that ``request`` takes.
126 |     :return: :class:`Response <Response>` object
127 |     :rtype: requests.Response
128 |     """
129 | 
130 |     return request("put", url, data=data, **kwargs)
131 | 
132 | 
133 | def patch(url, data=None, **kwargs):
134 |     r"""Sends a PATCH request.
135 | 
136 |     :param url: URL for the new :class:`Request` object.
137 |     :param data: (optional) Dictionary, list of tuples, bytes, or file-like
138 |         object to send in the body of the :class:`Request`.
139 |     :param json: (optional) A JSON serializable Python object to send in the body of the :class:`Request`.
140 |     :param \*\*kwargs: Optional arguments that ``request`` takes.
141 |     :return: :class:`Response <Response>` object
142 |     :rtype: requests.Response
143 |     """
144 | 
145 |     return request("patch", url, data=data, **kwargs)
146 | 
147 | 
148 | def delete(url, **kwargs):
149 |     r"""Sends a DELETE request.
150 | 
151 |     :param url: URL for the new :class:`Request` object.
152 |     :param \*\*kwargs: Optional arguments that ``request`` takes.
153 |     :return: :class:`Response <Response>` object
154 |     :rtype: requests.Response
155 |     """
156 | 
157 |     return request("delete", url, **kwargs)
```

.venv/lib/python3.13/site-packages/pip/_vendor/requests/auth.py
```
1 | """
2 | requests.auth
3 | ~~~~~~~~~~~~~
4 | 
5 | This module contains the authentication handlers for Requests.
6 | """
7 | 
8 | import hashlib
9 | import os
10 | import re
11 | import threading
12 | import time
13 | import warnings
14 | from base64 import b64encode
15 | 
16 | from ._internal_utils import to_native_string
17 | from .compat import basestring, str, urlparse
18 | from .cookies import extract_cookies_to_jar
19 | from .utils import parse_dict_header
20 | 
21 | CONTENT_TYPE_FORM_URLENCODED = "application/x-www-form-urlencoded"
22 | CONTENT_TYPE_MULTI_PART = "multipart/form-data"
23 | 
24 | 
25 | def _basic_auth_str(username, password):
26 |     """Returns a Basic Auth string."""
27 | 
28 |     # "I want us to put a big-ol' comment on top of it that
29 |     # says that this behaviour is dumb but we need to preserve
30 |     # it because people are relying on it."
31 |     #    - Lukasa
32 |     #
33 |     # These are here solely to maintain backwards compatibility
34 |     # for things like ints. This will be removed in 3.0.0.
35 |     if not isinstance(username, basestring):
36 |         warnings.warn(
37 |             "Non-string usernames will no longer be supported in Requests "
38 |             "3.0.0. Please convert the object you've passed in ({!r}) to "
39 |             "a string or bytes object in the near future to avoid "
40 |             "problems.".format(username),
41 |             category=DeprecationWarning,
42 |         )
43 |         username = str(username)
44 | 
45 |     if not isinstance(password, basestring):
46 |         warnings.warn(
47 |             "Non-string passwords will no longer be supported in Requests "
48 |             "3.0.0. Please convert the object you've passed in ({!r}) to "
49 |             "a string or bytes object in the near future to avoid "
50 |             "problems.".format(type(password)),
51 |             category=DeprecationWarning,
52 |         )
53 |         password = str(password)
54 |     # -- End Removal --
55 | 
56 |     if isinstance(username, str):
57 |         username = username.encode("latin1")
58 | 
59 |     if isinstance(password, str):
60 |         password = password.encode("latin1")
61 | 
62 |     authstr = "Basic " + to_native_string(
63 |         b64encode(b":".join((username, password))).strip()
64 |     )
65 | 
66 |     return authstr
67 | 
68 | 
69 | class AuthBase:
70 |     """Base class that all auth implementations derive from"""
71 | 
72 |     def __call__(self, r):
73 |         raise NotImplementedError("Auth hooks must be callable.")
74 | 
75 | 
76 | class HTTPBasicAuth(AuthBase):
77 |     """Attaches HTTP Basic Authentication to the given Request object."""
78 | 
79 |     def __init__(self, username, password):
80 |         self.username = username
81 |         self.password = password
82 | 
83 |     def __eq__(self, other):
84 |         return all(
85 |             [
86 |                 self.username == getattr(other, "username", None),
87 |                 self.password == getattr(other, "password", None),
88 |             ]
89 |         )
90 | 
91 |     def __ne__(self, other):
92 |         return not self == other
93 | 
94 |     def __call__(self, r):
95 |         r.headers["Authorization"] = _basic_auth_str(self.username, self.password)
96 |         return r
97 | 
98 | 
99 | class HTTPProxyAuth(HTTPBasicAuth):
100 |     """Attaches HTTP Proxy Authentication to a given Request object."""
101 | 
102 |     def __call__(self, r):
103 |         r.headers["Proxy-Authorization"] = _basic_auth_str(self.username, self.password)
104 |         return r
105 | 
106 | 
107 | class HTTPDigestAuth(AuthBase):
108 |     """Attaches HTTP Digest Authentication to the given Request object."""
109 | 
110 |     def __init__(self, username, password):
111 |         self.username = username
112 |         self.password = password
113 |         # Keep state in per-thread local storage
114 |         self._thread_local = threading.local()
115 | 
116 |     def init_per_thread_state(self):
117 |         # Ensure state is initialized just once per-thread
118 |         if not hasattr(self._thread_local, "init"):
119 |             self._thread_local.init = True
120 |             self._thread_local.last_nonce = ""
121 |             self._thread_local.nonce_count = 0
122 |             self._thread_local.chal = {}
123 |             self._thread_local.pos = None
124 |             self._thread_local.num_401_calls = None
125 | 
126 |     def build_digest_header(self, method, url):
127 |         """
128 |         :rtype: str
129 |         """
130 | 
131 |         realm = self._thread_local.chal["realm"]
132 |         nonce = self._thread_local.chal["nonce"]
133 |         qop = self._thread_local.chal.get("qop")
134 |         algorithm = self._thread_local.chal.get("algorithm")
135 |         opaque = self._thread_local.chal.get("opaque")
136 |         hash_utf8 = None
137 | 
138 |         if algorithm is None:
139 |             _algorithm = "MD5"
140 |         else:
141 |             _algorithm = algorithm.upper()
142 |         # lambdas assume digest modules are imported at the top level
143 |         if _algorithm == "MD5" or _algorithm == "MD5-SESS":
144 | 
145 |             def md5_utf8(x):
146 |                 if isinstance(x, str):
147 |                     x = x.encode("utf-8")
148 |                 return hashlib.md5(x).hexdigest()
149 | 
150 |             hash_utf8 = md5_utf8
151 |         elif _algorithm == "SHA":
152 | 
153 |             def sha_utf8(x):
154 |                 if isinstance(x, str):
155 |                     x = x.encode("utf-8")
156 |                 return hashlib.sha1(x).hexdigest()
157 | 
158 |             hash_utf8 = sha_utf8
159 |         elif _algorithm == "SHA-256":
160 | 
161 |             def sha256_utf8(x):
162 |                 if isinstance(x, str):
163 |                     x = x.encode("utf-8")
164 |                 return hashlib.sha256(x).hexdigest()
165 | 
166 |             hash_utf8 = sha256_utf8
167 |         elif _algorithm == "SHA-512":
168 | 
169 |             def sha512_utf8(x):
170 |                 if isinstance(x, str):
171 |                     x = x.encode("utf-8")
172 |                 return hashlib.sha512(x).hexdigest()
173 | 
174 |             hash_utf8 = sha512_utf8
175 | 
176 |         KD = lambda s, d: hash_utf8(f"{s}:{d}")  # noqa:E731
177 | 
178 |         if hash_utf8 is None:
179 |             return None
180 | 
181 |         # XXX not implemented yet
182 |         entdig = None
183 |         p_parsed = urlparse(url)
184 |         #: path is request-uri defined in RFC 2616 which should not be empty
185 |         path = p_parsed.path or "/"
186 |         if p_parsed.query:
187 |             path += f"?{p_parsed.query}"
188 | 
189 |         A1 = f"{self.username}:{realm}:{self.password}"
190 |         A2 = f"{method}:{path}"
191 | 
192 |         HA1 = hash_utf8(A1)
193 |         HA2 = hash_utf8(A2)
194 | 
195 |         if nonce == self._thread_local.last_nonce:
196 |             self._thread_local.nonce_count += 1
197 |         else:
198 |             self._thread_local.nonce_count = 1
199 |         ncvalue = f"{self._thread_local.nonce_count:08x}"
200 |         s = str(self._thread_local.nonce_count).encode("utf-8")
201 |         s += nonce.encode("utf-8")
202 |         s += time.ctime().encode("utf-8")
203 |         s += os.urandom(8)
204 | 
205 |         cnonce = hashlib.sha1(s).hexdigest()[:16]
206 |         if _algorithm == "MD5-SESS":
207 |             HA1 = hash_utf8(f"{HA1}:{nonce}:{cnonce}")
208 | 
209 |         if not qop:
210 |             respdig = KD(HA1, f"{nonce}:{HA2}")
211 |         elif qop == "auth" or "auth" in qop.split(","):
212 |             noncebit = f"{nonce}:{ncvalue}:{cnonce}:auth:{HA2}"
213 |             respdig = KD(HA1, noncebit)
214 |         else:
215 |             # XXX handle auth-int.
216 |             return None
217 | 
218 |         self._thread_local.last_nonce = nonce
219 | 
220 |         # XXX should the partial digests be encoded too?
221 |         base = (
222 |             f'username="{self.username}", realm="{realm}", nonce="{nonce}", '
223 |             f'uri="{path}", response="{respdig}"'
224 |         )
225 |         if opaque:
226 |             base += f', opaque="{opaque}"'
227 |         if algorithm:
228 |             base += f', algorithm="{algorithm}"'
229 |         if entdig:
230 |             base += f', digest="{entdig}"'
231 |         if qop:
232 |             base += f', qop="auth", nc={ncvalue}, cnonce="{cnonce}"'
233 | 
234 |         return f"Digest {base}"
235 | 
236 |     def handle_redirect(self, r, **kwargs):
237 |         """Reset num_401_calls counter on redirects."""
238 |         if r.is_redirect:
239 |             self._thread_local.num_401_calls = 1
240 | 
241 |     def handle_401(self, r, **kwargs):
242 |         """
243 |         Takes the given response and tries digest-auth, if needed.
244 | 
245 |         :rtype: requests.Response
246 |         """
247 | 
248 |         # If response is not 4xx, do not auth
249 |         # See https://github.com/psf/requests/issues/3772
250 |         if not 400 <= r.status_code < 500:
251 |             self._thread_local.num_401_calls = 1
252 |             return r
253 | 
254 |         if self._thread_local.pos is not None:
255 |             # Rewind the file position indicator of the body to where
256 |             # it was to resend the request.
257 |             r.request.body.seek(self._thread_local.pos)
258 |         s_auth = r.headers.get("www-authenticate", "")
259 | 
260 |         if "digest" in s_auth.lower() and self._thread_local.num_401_calls < 2:
261 |             self._thread_local.num_401_calls += 1
262 |             pat = re.compile(r"digest ", flags=re.IGNORECASE)
263 |             self._thread_local.chal = parse_dict_header(pat.sub("", s_auth, count=1))
264 | 
265 |             # Consume content and release the original connection
266 |             # to allow our new request to reuse the same one.
267 |             r.content
268 |             r.close()
269 |             prep = r.request.copy()
270 |             extract_cookies_to_jar(prep._cookies, r.request, r.raw)
271 |             prep.prepare_cookies(prep._cookies)
272 | 
273 |             prep.headers["Authorization"] = self.build_digest_header(
274 |                 prep.method, prep.url
275 |             )
276 |             _r = r.connection.send(prep, **kwargs)
277 |             _r.history.append(r)
278 |             _r.request = prep
279 | 
280 |             return _r
281 | 
282 |         self._thread_local.num_401_calls = 1
283 |         return r
284 | 
285 |     def __call__(self, r):
286 |         # Initialize per-thread state, if needed
287 |         self.init_per_thread_state()
288 |         # If we have a saved nonce, skip the 401
289 |         if self._thread_local.last_nonce:
290 |             r.headers["Authorization"] = self.build_digest_header(r.method, r.url)
291 |         try:
292 |             self._thread_local.pos = r.body.tell()
293 |         except AttributeError:
294 |             # In the case of HTTPDigestAuth being reused and the body of
295 |             # the previous request was a file-like object, pos has the
296 |             # file position of the previous body. Ensure it's set to
297 |             # None.
298 |             self._thread_local.pos = None
299 |         r.register_hook("response", self.handle_401)
300 |         r.register_hook("response", self.handle_redirect)
301 |         self._thread_local.num_401_calls = 1
302 | 
303 |         return r
304 | 
305 |     def __eq__(self, other):
306 |         return all(
307 |             [
308 |                 self.username == getattr(other, "username", None),
309 |                 self.password == getattr(other, "password", None),
310 |             ]
311 |         )
312 | 
313 |     def __ne__(self, other):
314 |         return not self == other
```

.venv/lib/python3.13/site-packages/pip/_vendor/requests/certs.py
```
1 | #!/usr/bin/env python
2 | 
3 | """
4 | requests.certs
5 | ~~~~~~~~~~~~~~
6 | 
7 | This module returns the preferred default CA certificate bundle. There is
8 | only one  the one from the certifi package.
9 | 
10 | If you are packaging Requests, e.g., for a Linux distribution or a managed
11 | environment, you can change the definition of where() to return a separately
12 | packaged CA bundle.
13 | """
14 | from pip._vendor.certifi import where
15 | 
16 | if __name__ == "__main__":
17 |     print(where())
```

.venv/lib/python3.13/site-packages/pip/_vendor/requests/compat.py
```
1 | """
2 | requests.compat
3 | ~~~~~~~~~~~~~~~
4 | 
5 | This module previously handled import compatibility issues
6 | between Python 2 and Python 3. It remains for backwards
7 | compatibility until the next major version.
8 | """
9 | 
10 | import sys
11 | 
12 | # -------------------
13 | # Character Detection
14 | # -------------------
15 | 
16 | 
17 | def _resolve_char_detection():
18 |     """Find supported character detection libraries."""
19 |     chardet = None
20 |     return chardet
21 | 
22 | 
23 | chardet = _resolve_char_detection()
24 | 
25 | # -------
26 | # Pythons
27 | # -------
28 | 
29 | # Syntax sugar.
30 | _ver = sys.version_info
31 | 
32 | #: Python 2.x?
33 | is_py2 = _ver[0] == 2
34 | 
35 | #: Python 3.x?
36 | is_py3 = _ver[0] == 3
37 | 
38 | # Note: We've patched out simplejson support in pip because it prevents
39 | #       upgrading simplejson on Windows.
40 | import json
41 | from json import JSONDecodeError
42 | 
43 | # Keep OrderedDict for backwards compatibility.
44 | from collections import OrderedDict
45 | from collections.abc import Callable, Mapping, MutableMapping
46 | from http import cookiejar as cookielib
47 | from http.cookies import Morsel
48 | from io import StringIO
49 | 
50 | # --------------
51 | # Legacy Imports
52 | # --------------
53 | from urllib.parse import (
54 |     quote,
55 |     quote_plus,
56 |     unquote,
57 |     unquote_plus,
58 |     urldefrag,
59 |     urlencode,
60 |     urljoin,
61 |     urlparse,
62 |     urlsplit,
63 |     urlunparse,
64 | )
65 | from urllib.request import (
66 |     getproxies,
67 |     getproxies_environment,
68 |     parse_http_list,
69 |     proxy_bypass,
70 |     proxy_bypass_environment,
71 | )
72 | 
73 | builtin_str = str
74 | str = str
75 | bytes = bytes
76 | basestring = (str, bytes)
77 | numeric_types = (int, float)
78 | integer_types = (int,)
```

.venv/lib/python3.13/site-packages/pip/_vendor/requests/cookies.py
```
1 | """
2 | requests.cookies
3 | ~~~~~~~~~~~~~~~~
4 | 
5 | Compatibility code to be able to use `http.cookiejar.CookieJar` with requests.
6 | 
7 | requests.utils imports from here, so be careful with imports.
8 | """
9 | 
10 | import calendar
11 | import copy
12 | import time
13 | 
14 | from ._internal_utils import to_native_string
15 | from .compat import Morsel, MutableMapping, cookielib, urlparse, urlunparse
16 | 
17 | try:
18 |     import threading
19 | except ImportError:
20 |     import dummy_threading as threading
21 | 
22 | 
23 | class MockRequest:
24 |     """Wraps a `requests.Request` to mimic a `urllib2.Request`.
25 | 
26 |     The code in `http.cookiejar.CookieJar` expects this interface in order to correctly
27 |     manage cookie policies, i.e., determine whether a cookie can be set, given the
28 |     domains of the request and the cookie.
29 | 
30 |     The original request object is read-only. The client is responsible for collecting
31 |     the new headers via `get_new_headers()` and interpreting them appropriately. You
32 |     probably want `get_cookie_header`, defined below.
33 |     """
34 | 
35 |     def __init__(self, request):
36 |         self._r = request
37 |         self._new_headers = {}
38 |         self.type = urlparse(self._r.url).scheme
39 | 
40 |     def get_type(self):
41 |         return self.type
42 | 
43 |     def get_host(self):
44 |         return urlparse(self._r.url).netloc
45 | 
46 |     def get_origin_req_host(self):
47 |         return self.get_host()
48 | 
49 |     def get_full_url(self):
50 |         # Only return the response's URL if the user hadn't set the Host
51 |         # header
52 |         if not self._r.headers.get("Host"):
53 |             return self._r.url
54 |         # If they did set it, retrieve it and reconstruct the expected domain
55 |         host = to_native_string(self._r.headers["Host"], encoding="utf-8")
56 |         parsed = urlparse(self._r.url)
57 |         # Reconstruct the URL as we expect it
58 |         return urlunparse(
59 |             [
60 |                 parsed.scheme,
61 |                 host,
62 |                 parsed.path,
63 |                 parsed.params,
64 |                 parsed.query,
65 |                 parsed.fragment,
66 |             ]
67 |         )
68 | 
69 |     def is_unverifiable(self):
70 |         return True
71 | 
72 |     def has_header(self, name):
73 |         return name in self._r.headers or name in self._new_headers
74 | 
75 |     def get_header(self, name, default=None):
76 |         return self._r.headers.get(name, self._new_headers.get(name, default))
77 | 
78 |     def add_header(self, key, val):
79 |         """cookiejar has no legitimate use for this method; add it back if you find one."""
80 |         raise NotImplementedError(
81 |             "Cookie headers should be added with add_unredirected_header()"
82 |         )
83 | 
84 |     def add_unredirected_header(self, name, value):
85 |         self._new_headers[name] = value
86 | 
87 |     def get_new_headers(self):
88 |         return self._new_headers
89 | 
90 |     @property
91 |     def unverifiable(self):
92 |         return self.is_unverifiable()
93 | 
94 |     @property
95 |     def origin_req_host(self):
96 |         return self.get_origin_req_host()
97 | 
98 |     @property
99 |     def host(self):
100 |         return self.get_host()
101 | 
102 | 
103 | class MockResponse:
104 |     """Wraps a `httplib.HTTPMessage` to mimic a `urllib.addinfourl`.
105 | 
106 |     ...what? Basically, expose the parsed HTTP headers from the server response
107 |     the way `http.cookiejar` expects to see them.
108 |     """
109 | 
110 |     def __init__(self, headers):
111 |         """Make a MockResponse for `cookiejar` to read.
112 | 
113 |         :param headers: a httplib.HTTPMessage or analogous carrying the headers
114 |         """
115 |         self._headers = headers
116 | 
117 |     def info(self):
118 |         return self._headers
119 | 
120 |     def getheaders(self, name):
121 |         self._headers.getheaders(name)
122 | 
123 | 
124 | def extract_cookies_to_jar(jar, request, response):
125 |     """Extract the cookies from the response into a CookieJar.
126 | 
127 |     :param jar: http.cookiejar.CookieJar (not necessarily a RequestsCookieJar)
128 |     :param request: our own requests.Request object
129 |     :param response: urllib3.HTTPResponse object
130 |     """
131 |     if not (hasattr(response, "_original_response") and response._original_response):
132 |         return
133 |     # the _original_response field is the wrapped httplib.HTTPResponse object,
134 |     req = MockRequest(request)
135 |     # pull out the HTTPMessage with the headers and put it in the mock:
136 |     res = MockResponse(response._original_response.msg)
137 |     jar.extract_cookies(res, req)
138 | 
139 | 
140 | def get_cookie_header(jar, request):
141 |     """
142 |     Produce an appropriate Cookie header string to be sent with `request`, or None.
143 | 
144 |     :rtype: str
145 |     """
146 |     r = MockRequest(request)
147 |     jar.add_cookie_header(r)
148 |     return r.get_new_headers().get("Cookie")
149 | 
150 | 
151 | def remove_cookie_by_name(cookiejar, name, domain=None, path=None):
152 |     """Unsets a cookie by name, by default over all domains and paths.
153 | 
154 |     Wraps CookieJar.clear(), is O(n).
155 |     """
156 |     clearables = []
157 |     for cookie in cookiejar:
158 |         if cookie.name != name:
159 |             continue
160 |         if domain is not None and domain != cookie.domain:
161 |             continue
162 |         if path is not None and path != cookie.path:
163 |             continue
164 |         clearables.append((cookie.domain, cookie.path, cookie.name))
165 | 
166 |     for domain, path, name in clearables:
167 |         cookiejar.clear(domain, path, name)
168 | 
169 | 
170 | class CookieConflictError(RuntimeError):
171 |     """There are two cookies that meet the criteria specified in the cookie jar.
172 |     Use .get and .set and include domain and path args in order to be more specific.
173 |     """
174 | 
175 | 
176 | class RequestsCookieJar(cookielib.CookieJar, MutableMapping):
177 |     """Compatibility class; is a http.cookiejar.CookieJar, but exposes a dict
178 |     interface.
179 | 
180 |     This is the CookieJar we create by default for requests and sessions that
181 |     don't specify one, since some clients may expect response.cookies and
182 |     session.cookies to support dict operations.
183 | 
184 |     Requests does not use the dict interface internally; it's just for
185 |     compatibility with external client code. All requests code should work
186 |     out of the box with externally provided instances of ``CookieJar``, e.g.
187 |     ``LWPCookieJar`` and ``FileCookieJar``.
188 | 
189 |     Unlike a regular CookieJar, this class is pickleable.
190 | 
191 |     .. warning:: dictionary operations that are normally O(1) may be O(n).
192 |     """
193 | 
194 |     def get(self, name, default=None, domain=None, path=None):
195 |         """Dict-like get() that also supports optional domain and path args in
196 |         order to resolve naming collisions from using one cookie jar over
197 |         multiple domains.
198 | 
199 |         .. warning:: operation is O(n), not O(1).
200 |         """
201 |         try:
202 |             return self._find_no_duplicates(name, domain, path)
203 |         except KeyError:
204 |             return default
205 | 
206 |     def set(self, name, value, **kwargs):
207 |         """Dict-like set() that also supports optional domain and path args in
208 |         order to resolve naming collisions from using one cookie jar over
209 |         multiple domains.
210 |         """
211 |         # support client code that unsets cookies by assignment of a None value:
212 |         if value is None:
213 |             remove_cookie_by_name(
214 |                 self, name, domain=kwargs.get("domain"), path=kwargs.get("path")
215 |             )
216 |             return
217 | 
218 |         if isinstance(value, Morsel):
219 |             c = morsel_to_cookie(value)
220 |         else:
221 |             c = create_cookie(name, value, **kwargs)
222 |         self.set_cookie(c)
223 |         return c
224 | 
225 |     def iterkeys(self):
226 |         """Dict-like iterkeys() that returns an iterator of names of cookies
227 |         from the jar.
228 | 
229 |         .. seealso:: itervalues() and iteritems().
230 |         """
231 |         for cookie in iter(self):
232 |             yield cookie.name
233 | 
234 |     def keys(self):
235 |         """Dict-like keys() that returns a list of names of cookies from the
236 |         jar.
237 | 
238 |         .. seealso:: values() and items().
239 |         """
240 |         return list(self.iterkeys())
241 | 
242 |     def itervalues(self):
243 |         """Dict-like itervalues() that returns an iterator of values of cookies
244 |         from the jar.
245 | 
246 |         .. seealso:: iterkeys() and iteritems().
247 |         """
248 |         for cookie in iter(self):
249 |             yield cookie.value
250 | 
251 |     def values(self):
252 |         """Dict-like values() that returns a list of values of cookies from the
253 |         jar.
254 | 
255 |         .. seealso:: keys() and items().
256 |         """
257 |         return list(self.itervalues())
258 | 
259 |     def iteritems(self):
260 |         """Dict-like iteritems() that returns an iterator of name-value tuples
261 |         from the jar.
262 | 
263 |         .. seealso:: iterkeys() and itervalues().
264 |         """
265 |         for cookie in iter(self):
266 |             yield cookie.name, cookie.value
267 | 
268 |     def items(self):
269 |         """Dict-like items() that returns a list of name-value tuples from the
270 |         jar. Allows client-code to call ``dict(RequestsCookieJar)`` and get a
271 |         vanilla python dict of key value pairs.
272 | 
273 |         .. seealso:: keys() and values().
274 |         """
275 |         return list(self.iteritems())
276 | 
277 |     def list_domains(self):
278 |         """Utility method to list all the domains in the jar."""
279 |         domains = []
280 |         for cookie in iter(self):
281 |             if cookie.domain not in domains:
282 |                 domains.append(cookie.domain)
283 |         return domains
284 | 
285 |     def list_paths(self):
286 |         """Utility method to list all the paths in the jar."""
287 |         paths = []
288 |         for cookie in iter(self):
289 |             if cookie.path not in paths:
290 |                 paths.append(cookie.path)
291 |         return paths
292 | 
293 |     def multiple_domains(self):
294 |         """Returns True if there are multiple domains in the jar.
295 |         Returns False otherwise.
296 | 
297 |         :rtype: bool
298 |         """
299 |         domains = []
300 |         for cookie in iter(self):
301 |             if cookie.domain is not None and cookie.domain in domains:
302 |                 return True
303 |             domains.append(cookie.domain)
304 |         return False  # there is only one domain in jar
305 | 
306 |     def get_dict(self, domain=None, path=None):
307 |         """Takes as an argument an optional domain and path and returns a plain
308 |         old Python dict of name-value pairs of cookies that meet the
309 |         requirements.
310 | 
311 |         :rtype: dict
312 |         """
313 |         dictionary = {}
314 |         for cookie in iter(self):
315 |             if (domain is None or cookie.domain == domain) and (
316 |                 path is None or cookie.path == path
317 |             ):
318 |                 dictionary[cookie.name] = cookie.value
319 |         return dictionary
320 | 
321 |     def __contains__(self, name):
322 |         try:
323 |             return super().__contains__(name)
324 |         except CookieConflictError:
325 |             return True
326 | 
327 |     def __getitem__(self, name):
328 |         """Dict-like __getitem__() for compatibility with client code. Throws
329 |         exception if there are more than one cookie with name. In that case,
330 |         use the more explicit get() method instead.
331 | 
332 |         .. warning:: operation is O(n), not O(1).
333 |         """
334 |         return self._find_no_duplicates(name)
335 | 
336 |     def __setitem__(self, name, value):
337 |         """Dict-like __setitem__ for compatibility with client code. Throws
338 |         exception if there is already a cookie of that name in the jar. In that
339 |         case, use the more explicit set() method instead.
340 |         """
341 |         self.set(name, value)
342 | 
343 |     def __delitem__(self, name):
344 |         """Deletes a cookie given a name. Wraps ``http.cookiejar.CookieJar``'s
345 |         ``remove_cookie_by_name()``.
346 |         """
347 |         remove_cookie_by_name(self, name)
348 | 
349 |     def set_cookie(self, cookie, *args, **kwargs):
350 |         if (
351 |             hasattr(cookie.value, "startswith")
352 |             and cookie.value.startswith('"')
353 |             and cookie.value.endswith('"')
354 |         ):
355 |             cookie.value = cookie.value.replace('\\"', "")
356 |         return super().set_cookie(cookie, *args, **kwargs)
357 | 
358 |     def update(self, other):
359 |         """Updates this jar with cookies from another CookieJar or dict-like"""
360 |         if isinstance(other, cookielib.CookieJar):
361 |             for cookie in other:
362 |                 self.set_cookie(copy.copy(cookie))
363 |         else:
364 |             super().update(other)
365 | 
366 |     def _find(self, name, domain=None, path=None):
367 |         """Requests uses this method internally to get cookie values.
368 | 
[TRUNCATED]
```

.venv/lib/python3.13/site-packages/pip/_vendor/requests/exceptions.py
```
1 | """
2 | requests.exceptions
3 | ~~~~~~~~~~~~~~~~~~~
4 | 
5 | This module contains the set of Requests' exceptions.
6 | """
7 | from pip._vendor.urllib3.exceptions import HTTPError as BaseHTTPError
8 | 
9 | from .compat import JSONDecodeError as CompatJSONDecodeError
10 | 
11 | 
12 | class RequestException(IOError):
13 |     """There was an ambiguous exception that occurred while handling your
14 |     request.
15 |     """
16 | 
17 |     def __init__(self, *args, **kwargs):
18 |         """Initialize RequestException with `request` and `response` objects."""
19 |         response = kwargs.pop("response", None)
20 |         self.response = response
21 |         self.request = kwargs.pop("request", None)
22 |         if response is not None and not self.request and hasattr(response, "request"):
23 |             self.request = self.response.request
24 |         super().__init__(*args, **kwargs)
25 | 
26 | 
27 | class InvalidJSONError(RequestException):
28 |     """A JSON error occurred."""
29 | 
30 | 
31 | class JSONDecodeError(InvalidJSONError, CompatJSONDecodeError):
32 |     """Couldn't decode the text into json"""
33 | 
34 |     def __init__(self, *args, **kwargs):
35 |         """
36 |         Construct the JSONDecodeError instance first with all
37 |         args. Then use it's args to construct the IOError so that
38 |         the json specific args aren't used as IOError specific args
39 |         and the error message from JSONDecodeError is preserved.
40 |         """
41 |         CompatJSONDecodeError.__init__(self, *args)
42 |         InvalidJSONError.__init__(self, *self.args, **kwargs)
43 | 
44 |     def __reduce__(self):
45 |         """
46 |         The __reduce__ method called when pickling the object must
47 |         be the one from the JSONDecodeError (be it json/simplejson)
48 |         as it expects all the arguments for instantiation, not just
49 |         one like the IOError, and the MRO would by default call the
50 |         __reduce__ method from the IOError due to the inheritance order.
51 |         """
52 |         return CompatJSONDecodeError.__reduce__(self)
53 | 
54 | 
55 | class HTTPError(RequestException):
56 |     """An HTTP error occurred."""
57 | 
58 | 
59 | class ConnectionError(RequestException):
60 |     """A Connection error occurred."""
61 | 
62 | 
63 | class ProxyError(ConnectionError):
64 |     """A proxy error occurred."""
65 | 
66 | 
67 | class SSLError(ConnectionError):
68 |     """An SSL error occurred."""
69 | 
70 | 
71 | class Timeout(RequestException):
72 |     """The request timed out.
73 | 
74 |     Catching this error will catch both
75 |     :exc:`~requests.exceptions.ConnectTimeout` and
76 |     :exc:`~requests.exceptions.ReadTimeout` errors.
77 |     """
78 | 
79 | 
80 | class ConnectTimeout(ConnectionError, Timeout):
81 |     """The request timed out while trying to connect to the remote server.
82 | 
83 |     Requests that produced this error are safe to retry.
84 |     """
85 | 
86 | 
87 | class ReadTimeout(Timeout):
88 |     """The server did not send any data in the allotted amount of time."""
89 | 
90 | 
91 | class URLRequired(RequestException):
92 |     """A valid URL is required to make a request."""
93 | 
94 | 
95 | class TooManyRedirects(RequestException):
96 |     """Too many redirects."""
97 | 
98 | 
99 | class MissingSchema(RequestException, ValueError):
100 |     """The URL scheme (e.g. http or https) is missing."""
101 | 
102 | 
103 | class InvalidSchema(RequestException, ValueError):
104 |     """The URL scheme provided is either invalid or unsupported."""
105 | 
106 | 
107 | class InvalidURL(RequestException, ValueError):
108 |     """The URL provided was somehow invalid."""
109 | 
110 | 
111 | class InvalidHeader(RequestException, ValueError):
112 |     """The header value provided was somehow invalid."""
113 | 
114 | 
115 | class InvalidProxyURL(InvalidURL):
116 |     """The proxy URL provided is invalid."""
117 | 
118 | 
119 | class ChunkedEncodingError(RequestException):
120 |     """The server declared chunked encoding but sent an invalid chunk."""
121 | 
122 | 
123 | class ContentDecodingError(RequestException, BaseHTTPError):
124 |     """Failed to decode response content."""
125 | 
126 | 
127 | class StreamConsumedError(RequestException, TypeError):
128 |     """The content for this response was already consumed."""
129 | 
130 | 
131 | class RetryError(RequestException):
132 |     """Custom retries logic failed"""
133 | 
134 | 
135 | class UnrewindableBodyError(RequestException):
136 |     """Requests encountered an error when trying to rewind a body."""
137 | 
138 | 
139 | # Warnings
140 | 
141 | 
142 | class RequestsWarning(Warning):
143 |     """Base warning for Requests."""
144 | 
145 | 
146 | class FileModeWarning(RequestsWarning, DeprecationWarning):
147 |     """A file was opened in text mode, but Requests determined its binary length."""
148 | 
149 | 
150 | class RequestsDependencyWarning(RequestsWarning):
151 |     """An imported dependency doesn't match the expected version range."""
```

.venv/lib/python3.13/site-packages/pip/_vendor/requests/help.py
```
1 | """Module containing bug report helper(s)."""
2 | 
3 | import json
4 | import platform
5 | import ssl
6 | import sys
7 | 
8 | from pip._vendor import idna
9 | from pip._vendor import urllib3
10 | 
11 | from . import __version__ as requests_version
12 | 
13 | charset_normalizer = None
14 | chardet = None
15 | 
16 | try:
17 |     from pip._vendor.urllib3.contrib import pyopenssl
18 | except ImportError:
19 |     pyopenssl = None
20 |     OpenSSL = None
21 |     cryptography = None
22 | else:
23 |     import cryptography
24 |     import OpenSSL
25 | 
26 | 
27 | def _implementation():
28 |     """Return a dict with the Python implementation and version.
29 | 
30 |     Provide both the name and the version of the Python implementation
31 |     currently running. For example, on CPython 3.10.3 it will return
32 |     {'name': 'CPython', 'version': '3.10.3'}.
33 | 
34 |     This function works best on CPython and PyPy: in particular, it probably
35 |     doesn't work for Jython or IronPython. Future investigation should be done
36 |     to work out the correct shape of the code for those platforms.
37 |     """
38 |     implementation = platform.python_implementation()
39 | 
40 |     if implementation == "CPython":
41 |         implementation_version = platform.python_version()
42 |     elif implementation == "PyPy":
43 |         implementation_version = "{}.{}.{}".format(
44 |             sys.pypy_version_info.major,
45 |             sys.pypy_version_info.minor,
46 |             sys.pypy_version_info.micro,
47 |         )
48 |         if sys.pypy_version_info.releaselevel != "final":
49 |             implementation_version = "".join(
50 |                 [implementation_version, sys.pypy_version_info.releaselevel]
51 |             )
52 |     elif implementation == "Jython":
53 |         implementation_version = platform.python_version()  # Complete Guess
54 |     elif implementation == "IronPython":
55 |         implementation_version = platform.python_version()  # Complete Guess
56 |     else:
57 |         implementation_version = "Unknown"
58 | 
59 |     return {"name": implementation, "version": implementation_version}
60 | 
61 | 
62 | def info():
63 |     """Generate information for a bug report."""
64 |     try:
65 |         platform_info = {
66 |             "system": platform.system(),
67 |             "release": platform.release(),
68 |         }
69 |     except OSError:
70 |         platform_info = {
71 |             "system": "Unknown",
72 |             "release": "Unknown",
73 |         }
74 | 
75 |     implementation_info = _implementation()
76 |     urllib3_info = {"version": urllib3.__version__}
77 |     charset_normalizer_info = {"version": None}
78 |     chardet_info = {"version": None}
79 |     if charset_normalizer:
80 |         charset_normalizer_info = {"version": charset_normalizer.__version__}
81 |     if chardet:
82 |         chardet_info = {"version": chardet.__version__}
83 | 
84 |     pyopenssl_info = {
85 |         "version": None,
86 |         "openssl_version": "",
87 |     }
88 |     if OpenSSL:
89 |         pyopenssl_info = {
90 |             "version": OpenSSL.__version__,
91 |             "openssl_version": f"{OpenSSL.SSL.OPENSSL_VERSION_NUMBER:x}",
92 |         }
93 |     cryptography_info = {
94 |         "version": getattr(cryptography, "__version__", ""),
95 |     }
96 |     idna_info = {
97 |         "version": getattr(idna, "__version__", ""),
98 |     }
99 | 
100 |     system_ssl = ssl.OPENSSL_VERSION_NUMBER
101 |     system_ssl_info = {"version": f"{system_ssl:x}" if system_ssl is not None else ""}
102 | 
103 |     return {
104 |         "platform": platform_info,
105 |         "implementation": implementation_info,
106 |         "system_ssl": system_ssl_info,
107 |         "using_pyopenssl": pyopenssl is not None,
108 |         "using_charset_normalizer": chardet is None,
109 |         "pyOpenSSL": pyopenssl_info,
110 |         "urllib3": urllib3_info,
111 |         "chardet": chardet_info,
112 |         "charset_normalizer": charset_normalizer_info,
113 |         "cryptography": cryptography_info,
114 |         "idna": idna_info,
115 |         "requests": {
116 |             "version": requests_version,
117 |         },
118 |     }
119 | 
120 | 
121 | def main():
122 |     """Pretty-print the bug information as JSON."""
123 |     print(json.dumps(info(), sort_keys=True, indent=2))
124 | 
125 | 
126 | if __name__ == "__main__":
127 |     main()
```

.venv/lib/python3.13/site-packages/pip/_vendor/requests/hooks.py
```
1 | """
2 | requests.hooks
3 | ~~~~~~~~~~~~~~
4 | 
5 | This module provides the capabilities for the Requests hooks system.
6 | 
7 | Available hooks:
8 | 
9 | ``response``:
10 |     The response generated from a Request.
11 | """
12 | HOOKS = ["response"]
13 | 
14 | 
15 | def default_hooks():
16 |     return {event: [] for event in HOOKS}
17 | 
18 | 
19 | # TODO: response is the only one
20 | 
21 | 
22 | def dispatch_hook(key, hooks, hook_data, **kwargs):
23 |     """Dispatches a hook dictionary on a given piece of data."""
24 |     hooks = hooks or {}
25 |     hooks = hooks.get(key)
26 |     if hooks:
27 |         if hasattr(hooks, "__call__"):
28 |             hooks = [hooks]
29 |         for hook in hooks:
30 |             _hook_data = hook(hook_data, **kwargs)
31 |             if _hook_data is not None:
32 |                 hook_data = _hook_data
33 |     return hook_data
```

.venv/lib/python3.13/site-packages/pip/_vendor/requests/models.py
```
1 | """
2 | requests.models
3 | ~~~~~~~~~~~~~~~
4 | 
5 | This module contains the primary objects that power Requests.
6 | """
7 | 
8 | import datetime
9 | 
10 | # Import encoding now, to avoid implicit import later.
11 | # Implicit import within threads may cause LookupError when standard library is in a ZIP,
12 | # such as in Embedded Python. See https://github.com/psf/requests/issues/3578.
13 | import encodings.idna  # noqa: F401
14 | from io import UnsupportedOperation
15 | 
16 | from pip._vendor.urllib3.exceptions import (
17 |     DecodeError,
18 |     LocationParseError,
19 |     ProtocolError,
20 |     ReadTimeoutError,
21 |     SSLError,
22 | )
23 | from pip._vendor.urllib3.fields import RequestField
24 | from pip._vendor.urllib3.filepost import encode_multipart_formdata
25 | from pip._vendor.urllib3.util import parse_url
26 | 
27 | from ._internal_utils import to_native_string, unicode_is_ascii
28 | from .auth import HTTPBasicAuth
29 | from .compat import (
30 |     Callable,
31 |     JSONDecodeError,
32 |     Mapping,
33 |     basestring,
34 |     builtin_str,
35 |     chardet,
36 |     cookielib,
37 | )
38 | from .compat import json as complexjson
39 | from .compat import urlencode, urlsplit, urlunparse
40 | from .cookies import _copy_cookie_jar, cookiejar_from_dict, get_cookie_header
41 | from .exceptions import (
42 |     ChunkedEncodingError,
43 |     ConnectionError,
44 |     ContentDecodingError,
45 |     HTTPError,
46 |     InvalidJSONError,
47 |     InvalidURL,
48 | )
49 | from .exceptions import JSONDecodeError as RequestsJSONDecodeError
50 | from .exceptions import MissingSchema
51 | from .exceptions import SSLError as RequestsSSLError
52 | from .exceptions import StreamConsumedError
53 | from .hooks import default_hooks
54 | from .status_codes import codes
55 | from .structures import CaseInsensitiveDict
56 | from .utils import (
57 |     check_header_validity,
58 |     get_auth_from_url,
59 |     guess_filename,
60 |     guess_json_utf,
61 |     iter_slices,
62 |     parse_header_links,
63 |     requote_uri,
64 |     stream_decode_response_unicode,
65 |     super_len,
66 |     to_key_val_list,
67 | )
68 | 
69 | #: The set of HTTP status codes that indicate an automatically
70 | #: processable redirect.
71 | REDIRECT_STATI = (
72 |     codes.moved,  # 301
73 |     codes.found,  # 302
74 |     codes.other,  # 303
75 |     codes.temporary_redirect,  # 307
76 |     codes.permanent_redirect,  # 308
77 | )
78 | 
79 | DEFAULT_REDIRECT_LIMIT = 30
80 | CONTENT_CHUNK_SIZE = 10 * 1024
81 | ITER_CHUNK_SIZE = 512
82 | 
83 | 
84 | class RequestEncodingMixin:
85 |     @property
86 |     def path_url(self):
87 |         """Build the path URL to use."""
88 | 
89 |         url = []
90 | 
91 |         p = urlsplit(self.url)
92 | 
93 |         path = p.path
94 |         if not path:
95 |             path = "/"
96 | 
97 |         url.append(path)
98 | 
99 |         query = p.query
100 |         if query:
101 |             url.append("?")
102 |             url.append(query)
103 | 
104 |         return "".join(url)
105 | 
106 |     @staticmethod
107 |     def _encode_params(data):
108 |         """Encode parameters in a piece of data.
109 | 
110 |         Will successfully encode parameters when passed as a dict or a list of
111 |         2-tuples. Order is retained if data is a list of 2-tuples but arbitrary
112 |         if parameters are supplied as a dict.
113 |         """
114 | 
115 |         if isinstance(data, (str, bytes)):
116 |             return data
117 |         elif hasattr(data, "read"):
118 |             return data
119 |         elif hasattr(data, "__iter__"):
120 |             result = []
121 |             for k, vs in to_key_val_list(data):
122 |                 if isinstance(vs, basestring) or not hasattr(vs, "__iter__"):
123 |                     vs = [vs]
124 |                 for v in vs:
125 |                     if v is not None:
126 |                         result.append(
127 |                             (
128 |                                 k.encode("utf-8") if isinstance(k, str) else k,
129 |                                 v.encode("utf-8") if isinstance(v, str) else v,
130 |                             )
131 |                         )
132 |             return urlencode(result, doseq=True)
133 |         else:
134 |             return data
135 | 
136 |     @staticmethod
137 |     def _encode_files(files, data):
138 |         """Build the body for a multipart/form-data request.
139 | 
140 |         Will successfully encode files when passed as a dict or a list of
141 |         tuples. Order is retained if data is a list of tuples but arbitrary
142 |         if parameters are supplied as a dict.
143 |         The tuples may be 2-tuples (filename, fileobj), 3-tuples (filename, fileobj, contentype)
144 |         or 4-tuples (filename, fileobj, contentype, custom_headers).
145 |         """
146 |         if not files:
147 |             raise ValueError("Files must be provided.")
148 |         elif isinstance(data, basestring):
149 |             raise ValueError("Data must not be a string.")
150 | 
151 |         new_fields = []
152 |         fields = to_key_val_list(data or {})
153 |         files = to_key_val_list(files or {})
154 | 
155 |         for field, val in fields:
156 |             if isinstance(val, basestring) or not hasattr(val, "__iter__"):
157 |                 val = [val]
158 |             for v in val:
159 |                 if v is not None:
160 |                     # Don't call str() on bytestrings: in Py3 it all goes wrong.
161 |                     if not isinstance(v, bytes):
162 |                         v = str(v)
163 | 
164 |                     new_fields.append(
165 |                         (
166 |                             field.decode("utf-8")
167 |                             if isinstance(field, bytes)
168 |                             else field,
169 |                             v.encode("utf-8") if isinstance(v, str) else v,
170 |                         )
171 |                     )
172 | 
173 |         for k, v in files:
174 |             # support for explicit filename
175 |             ft = None
176 |             fh = None
177 |             if isinstance(v, (tuple, list)):
178 |                 if len(v) == 2:
179 |                     fn, fp = v
180 |                 elif len(v) == 3:
181 |                     fn, fp, ft = v
182 |                 else:
183 |                     fn, fp, ft, fh = v
184 |             else:
185 |                 fn = guess_filename(v) or k
186 |                 fp = v
187 | 
188 |             if isinstance(fp, (str, bytes, bytearray)):
189 |                 fdata = fp
190 |             elif hasattr(fp, "read"):
191 |                 fdata = fp.read()
192 |             elif fp is None:
193 |                 continue
194 |             else:
195 |                 fdata = fp
196 | 
197 |             rf = RequestField(name=k, data=fdata, filename=fn, headers=fh)
198 |             rf.make_multipart(content_type=ft)
199 |             new_fields.append(rf)
200 | 
201 |         body, content_type = encode_multipart_formdata(new_fields)
202 | 
203 |         return body, content_type
204 | 
205 | 
206 | class RequestHooksMixin:
207 |     def register_hook(self, event, hook):
208 |         """Properly register a hook."""
209 | 
210 |         if event not in self.hooks:
211 |             raise ValueError(f'Unsupported event specified, with event name "{event}"')
212 | 
213 |         if isinstance(hook, Callable):
214 |             self.hooks[event].append(hook)
215 |         elif hasattr(hook, "__iter__"):
216 |             self.hooks[event].extend(h for h in hook if isinstance(h, Callable))
217 | 
218 |     def deregister_hook(self, event, hook):
219 |         """Deregister a previously registered hook.
220 |         Returns True if the hook existed, False if not.
221 |         """
222 | 
223 |         try:
224 |             self.hooks[event].remove(hook)
225 |             return True
226 |         except ValueError:
227 |             return False
228 | 
229 | 
230 | class Request(RequestHooksMixin):
231 |     """A user-created :class:`Request <Request>` object.
232 | 
233 |     Used to prepare a :class:`PreparedRequest <PreparedRequest>`, which is sent to the server.
234 | 
235 |     :param method: HTTP method to use.
236 |     :param url: URL to send.
237 |     :param headers: dictionary of headers to send.
238 |     :param files: dictionary of {filename: fileobject} files to multipart upload.
239 |     :param data: the body to attach to the request. If a dictionary or
240 |         list of tuples ``[(key, value)]`` is provided, form-encoding will
241 |         take place.
242 |     :param json: json for the body to attach to the request (if files or data is not specified).
243 |     :param params: URL parameters to append to the URL. If a dictionary or
244 |         list of tuples ``[(key, value)]`` is provided, form-encoding will
245 |         take place.
246 |     :param auth: Auth handler or (user, pass) tuple.
247 |     :param cookies: dictionary or CookieJar of cookies to attach to this request.
248 |     :param hooks: dictionary of callback hooks, for internal usage.
249 | 
250 |     Usage::
251 | 
252 |       >>> import requests
253 |       >>> req = requests.Request('GET', 'https://httpbin.org/get')
254 |       >>> req.prepare()
255 |       <PreparedRequest [GET]>
256 |     """
257 | 
258 |     def __init__(
259 |         self,
260 |         method=None,
261 |         url=None,
262 |         headers=None,
263 |         files=None,
264 |         data=None,
265 |         params=None,
266 |         auth=None,
267 |         cookies=None,
268 |         hooks=None,
269 |         json=None,
270 |     ):
271 |         # Default empty dicts for dict params.
272 |         data = [] if data is None else data
273 |         files = [] if files is None else files
274 |         headers = {} if headers is None else headers
275 |         params = {} if params is None else params
276 |         hooks = {} if hooks is None else hooks
277 | 
278 |         self.hooks = default_hooks()
279 |         for k, v in list(hooks.items()):
280 |             self.register_hook(event=k, hook=v)
281 | 
282 |         self.method = method
283 |         self.url = url
284 |         self.headers = headers
285 |         self.files = files
286 |         self.data = data
287 |         self.json = json
288 |         self.params = params
289 |         self.auth = auth
290 |         self.cookies = cookies
291 | 
292 |     def __repr__(self):
293 |         return f"<Request [{self.method}]>"
294 | 
295 |     def prepare(self):
296 |         """Constructs a :class:`PreparedRequest <PreparedRequest>` for transmission and returns it."""
297 |         p = PreparedRequest()
298 |         p.prepare(
299 |             method=self.method,
300 |             url=self.url,
301 |             headers=self.headers,
302 |             files=self.files,
303 |             data=self.data,
304 |             json=self.json,
305 |             params=self.params,
306 |             auth=self.auth,
307 |             cookies=self.cookies,
308 |             hooks=self.hooks,
309 |         )
310 |         return p
311 | 
312 | 
313 | class PreparedRequest(RequestEncodingMixin, RequestHooksMixin):
314 |     """The fully mutable :class:`PreparedRequest <PreparedRequest>` object,
315 |     containing the exact bytes that will be sent to the server.
316 | 
317 |     Instances are generated from a :class:`Request <Request>` object, and
318 |     should not be instantiated manually; doing so may produce undesirable
319 |     effects.
320 | 
321 |     Usage::
322 | 
323 |       >>> import requests
324 |       >>> req = requests.Request('GET', 'https://httpbin.org/get')
325 |       >>> r = req.prepare()
326 |       >>> r
327 |       <PreparedRequest [GET]>
328 | 
329 |       >>> s = requests.Session()
330 |       >>> s.send(r)
331 |       <Response [200]>
332 |     """
333 | 
334 |     def __init__(self):
335 |         #: HTTP verb to send to the server.
336 |         self.method = None
337 |         #: HTTP URL to send the request to.
338 |         self.url = None
339 |         #: dictionary of HTTP headers.
340 |         self.headers = None
341 |         # The `CookieJar` used to create the Cookie header will be stored here
342 |         # after prepare_cookies is called
343 |         self._cookies = None
344 |         #: request body to send to the server.
345 |         self.body = None
346 |         #: dictionary of callback hooks, for internal usage.
347 |         self.hooks = default_hooks()
348 |         #: integer denoting starting position of a readable file-like body.
349 |         self._body_position = None
350 | 
351 |     def prepare(
352 |         self,
353 |         method=None,
354 |         url=None,
355 |         headers=None,
356 |         files=None,
357 |         data=None,
358 |         params=None,
359 |         auth=None,
360 |         cookies=None,
361 |         hooks=None,
362 |         json=None,
363 |     ):
364 |         """Prepares the entire request with the given parameters."""
365 | 
366 |         self.prepare_method(method)
367 |         self.prepare_url(url, params)
368 |         self.prepare_headers(headers)
369 |         self.prepare_cookies(cookies)
370 |         self.prepare_body(data, files, json)
371 |         self.prepare_auth(auth, url)
372 | 
373 |         # Note that prepare_auth must be last to enable authentication schemes
374 |         # such as OAuth to work on a fully prepared request.
375 | 
376 |         # This MUST go after prepare_auth. Authenticators could add a hook
377 |         self.prepare_hooks(hooks)
378 | 
379 |     def __repr__(self):
380 |         return f"<PreparedRequest [{self.method}]>"
381 | 
382 |     def copy(self):
383 |         p = PreparedRequest()
384 |         p.method = self.method
385 |         p.url = self.url
386 |         p.headers = self.headers.copy() if self.headers is not None else None
387 |         p._cookies = _copy_cookie_jar(self._cookies)
388 |         p.body = self.body
389 |         p.hooks = self.hooks
390 |         p._body_position = self._body_position
[TRUNCATED]
```

.venv/lib/python3.13/site-packages/pip/_vendor/requests/packages.py
```
1 | import sys
2 | 
3 | from .compat import chardet
4 | 
5 | # This code exists for backwards compatibility reasons.
6 | # I don't like it either. Just look the other way. :)
7 | 
8 | for package in ("urllib3", "idna"):
9 |     vendored_package = "pip._vendor." + package
10 |     locals()[package] = __import__(vendored_package)
11 |     # This traversal is apparently necessary such that the identities are
12 |     # preserved (requests.packages.urllib3.* is urllib3.*)
13 |     for mod in list(sys.modules):
14 |         if mod == vendored_package or mod.startswith(vendored_package + '.'):
15 |             unprefixed_mod = mod[len("pip._vendor."):]
16 |             sys.modules['pip._vendor.requests.packages.' + unprefixed_mod] = sys.modules[mod]
17 | 
18 | if chardet is not None:
19 |     target = chardet.__name__
20 |     for mod in list(sys.modules):
21 |         if mod == target or mod.startswith(f"{target}."):
22 |             imported_mod = sys.modules[mod]
23 |             sys.modules[f"requests.packages.{mod}"] = imported_mod
24 |             mod = mod.replace(target, "chardet")
25 |             sys.modules[f"requests.packages.{mod}"] = imported_mod
```

.venv/lib/python3.13/site-packages/pip/_vendor/requests/sessions.py
```
1 | """
2 | requests.sessions
3 | ~~~~~~~~~~~~~~~~~
4 | 
5 | This module provides a Session object to manage and persist settings across
6 | requests (cookies, auth, proxies).
7 | """
8 | import os
9 | import sys
10 | import time
11 | from collections import OrderedDict
12 | from datetime import timedelta
13 | 
14 | from ._internal_utils import to_native_string
15 | from .adapters import HTTPAdapter
16 | from .auth import _basic_auth_str
17 | from .compat import Mapping, cookielib, urljoin, urlparse
18 | from .cookies import (
19 |     RequestsCookieJar,
20 |     cookiejar_from_dict,
21 |     extract_cookies_to_jar,
22 |     merge_cookies,
23 | )
24 | from .exceptions import (
25 |     ChunkedEncodingError,
26 |     ContentDecodingError,
27 |     InvalidSchema,
28 |     TooManyRedirects,
29 | )
30 | from .hooks import default_hooks, dispatch_hook
31 | 
32 | # formerly defined here, reexposed here for backward compatibility
33 | from .models import (  # noqa: F401
34 |     DEFAULT_REDIRECT_LIMIT,
35 |     REDIRECT_STATI,
36 |     PreparedRequest,
37 |     Request,
38 | )
39 | from .status_codes import codes
40 | from .structures import CaseInsensitiveDict
41 | from .utils import (  # noqa: F401
42 |     DEFAULT_PORTS,
43 |     default_headers,
44 |     get_auth_from_url,
45 |     get_environ_proxies,
46 |     get_netrc_auth,
47 |     requote_uri,
48 |     resolve_proxies,
49 |     rewind_body,
50 |     should_bypass_proxies,
51 |     to_key_val_list,
52 | )
53 | 
54 | # Preferred clock, based on which one is more accurate on a given system.
55 | if sys.platform == "win32":
56 |     preferred_clock = time.perf_counter
57 | else:
58 |     preferred_clock = time.time
59 | 
60 | 
61 | def merge_setting(request_setting, session_setting, dict_class=OrderedDict):
62 |     """Determines appropriate setting for a given request, taking into account
63 |     the explicit setting on that request, and the setting in the session. If a
64 |     setting is a dictionary, they will be merged together using `dict_class`
65 |     """
66 | 
67 |     if session_setting is None:
68 |         return request_setting
69 | 
70 |     if request_setting is None:
71 |         return session_setting
72 | 
73 |     # Bypass if not a dictionary (e.g. verify)
74 |     if not (
75 |         isinstance(session_setting, Mapping) and isinstance(request_setting, Mapping)
76 |     ):
77 |         return request_setting
78 | 
79 |     merged_setting = dict_class(to_key_val_list(session_setting))
80 |     merged_setting.update(to_key_val_list(request_setting))
81 | 
82 |     # Remove keys that are set to None. Extract keys first to avoid altering
83 |     # the dictionary during iteration.
84 |     none_keys = [k for (k, v) in merged_setting.items() if v is None]
85 |     for key in none_keys:
86 |         del merged_setting[key]
87 | 
88 |     return merged_setting
89 | 
90 | 
91 | def merge_hooks(request_hooks, session_hooks, dict_class=OrderedDict):
92 |     """Properly merges both requests and session hooks.
93 | 
94 |     This is necessary because when request_hooks == {'response': []}, the
95 |     merge breaks Session hooks entirely.
96 |     """
97 |     if session_hooks is None or session_hooks.get("response") == []:
98 |         return request_hooks
99 | 
100 |     if request_hooks is None or request_hooks.get("response") == []:
101 |         return session_hooks
102 | 
103 |     return merge_setting(request_hooks, session_hooks, dict_class)
104 | 
105 | 
106 | class SessionRedirectMixin:
107 |     def get_redirect_target(self, resp):
108 |         """Receives a Response. Returns a redirect URI or ``None``"""
109 |         # Due to the nature of how requests processes redirects this method will
110 |         # be called at least once upon the original response and at least twice
111 |         # on each subsequent redirect response (if any).
112 |         # If a custom mixin is used to handle this logic, it may be advantageous
113 |         # to cache the redirect location onto the response object as a private
114 |         # attribute.
115 |         if resp.is_redirect:
116 |             location = resp.headers["location"]
117 |             # Currently the underlying http module on py3 decode headers
118 |             # in latin1, but empirical evidence suggests that latin1 is very
119 |             # rarely used with non-ASCII characters in HTTP headers.
120 |             # It is more likely to get UTF8 header rather than latin1.
121 |             # This causes incorrect handling of UTF8 encoded location headers.
122 |             # To solve this, we re-encode the location in latin1.
123 |             location = location.encode("latin1")
124 |             return to_native_string(location, "utf8")
125 |         return None
126 | 
127 |     def should_strip_auth(self, old_url, new_url):
128 |         """Decide whether Authorization header should be removed when redirecting"""
129 |         old_parsed = urlparse(old_url)
130 |         new_parsed = urlparse(new_url)
131 |         if old_parsed.hostname != new_parsed.hostname:
132 |             return True
133 |         # Special case: allow http -> https redirect when using the standard
134 |         # ports. This isn't specified by RFC 7235, but is kept to avoid
135 |         # breaking backwards compatibility with older versions of requests
136 |         # that allowed any redirects on the same host.
137 |         if (
138 |             old_parsed.scheme == "http"
139 |             and old_parsed.port in (80, None)
140 |             and new_parsed.scheme == "https"
141 |             and new_parsed.port in (443, None)
142 |         ):
143 |             return False
144 | 
145 |         # Handle default port usage corresponding to scheme.
146 |         changed_port = old_parsed.port != new_parsed.port
147 |         changed_scheme = old_parsed.scheme != new_parsed.scheme
148 |         default_port = (DEFAULT_PORTS.get(old_parsed.scheme, None), None)
149 |         if (
150 |             not changed_scheme
151 |             and old_parsed.port in default_port
152 |             and new_parsed.port in default_port
153 |         ):
154 |             return False
155 | 
156 |         # Standard case: root URI must match
157 |         return changed_port or changed_scheme
158 | 
159 |     def resolve_redirects(
160 |         self,
161 |         resp,
162 |         req,
163 |         stream=False,
164 |         timeout=None,
165 |         verify=True,
166 |         cert=None,
167 |         proxies=None,
168 |         yield_requests=False,
169 |         **adapter_kwargs,
170 |     ):
171 |         """Receives a Response. Returns a generator of Responses or Requests."""
172 | 
173 |         hist = []  # keep track of history
174 | 
175 |         url = self.get_redirect_target(resp)
176 |         previous_fragment = urlparse(req.url).fragment
177 |         while url:
178 |             prepared_request = req.copy()
179 | 
180 |             # Update history and keep track of redirects.
181 |             # resp.history must ignore the original request in this loop
182 |             hist.append(resp)
183 |             resp.history = hist[1:]
184 | 
185 |             try:
186 |                 resp.content  # Consume socket so it can be released
187 |             except (ChunkedEncodingError, ContentDecodingError, RuntimeError):
188 |                 resp.raw.read(decode_content=False)
189 | 
190 |             if len(resp.history) >= self.max_redirects:
191 |                 raise TooManyRedirects(
192 |                     f"Exceeded {self.max_redirects} redirects.", response=resp
193 |                 )
194 | 
195 |             # Release the connection back into the pool.
196 |             resp.close()
197 | 
198 |             # Handle redirection without scheme (see: RFC 1808 Section 4)
199 |             if url.startswith("//"):
200 |                 parsed_rurl = urlparse(resp.url)
201 |                 url = ":".join([to_native_string(parsed_rurl.scheme), url])
202 | 
203 |             # Normalize url case and attach previous fragment if needed (RFC 7231 7.1.2)
204 |             parsed = urlparse(url)
205 |             if parsed.fragment == "" and previous_fragment:
206 |                 parsed = parsed._replace(fragment=previous_fragment)
207 |             elif parsed.fragment:
208 |                 previous_fragment = parsed.fragment
209 |             url = parsed.geturl()
210 | 
211 |             # Facilitate relative 'location' headers, as allowed by RFC 7231.
212 |             # (e.g. '/path/to/resource' instead of 'http://domain.tld/path/to/resource')
213 |             # Compliant with RFC3986, we percent encode the url.
214 |             if not parsed.netloc:
215 |                 url = urljoin(resp.url, requote_uri(url))
216 |             else:
217 |                 url = requote_uri(url)
218 | 
219 |             prepared_request.url = to_native_string(url)
220 | 
221 |             self.rebuild_method(prepared_request, resp)
222 | 
223 |             # https://github.com/psf/requests/issues/1084
224 |             if resp.status_code not in (
225 |                 codes.temporary_redirect,
226 |                 codes.permanent_redirect,
227 |             ):
228 |                 # https://github.com/psf/requests/issues/3490
229 |                 purged_headers = ("Content-Length", "Content-Type", "Transfer-Encoding")
230 |                 for header in purged_headers:
231 |                     prepared_request.headers.pop(header, None)
232 |                 prepared_request.body = None
233 | 
234 |             headers = prepared_request.headers
235 |             headers.pop("Cookie", None)
236 | 
237 |             # Extract any cookies sent on the response to the cookiejar
238 |             # in the new request. Because we've mutated our copied prepared
239 |             # request, use the old one that we haven't yet touched.
240 |             extract_cookies_to_jar(prepared_request._cookies, req, resp.raw)
241 |             merge_cookies(prepared_request._cookies, self.cookies)
242 |             prepared_request.prepare_cookies(prepared_request._cookies)
243 | 
244 |             # Rebuild auth and proxy information.
245 |             proxies = self.rebuild_proxies(prepared_request, proxies)
246 |             self.rebuild_auth(prepared_request, resp)
247 | 
248 |             # A failed tell() sets `_body_position` to `object()`. This non-None
249 |             # value ensures `rewindable` will be True, allowing us to raise an
250 |             # UnrewindableBodyError, instead of hanging the connection.
251 |             rewindable = prepared_request._body_position is not None and (
252 |                 "Content-Length" in headers or "Transfer-Encoding" in headers
253 |             )
254 | 
255 |             # Attempt to rewind consumed file-like object.
256 |             if rewindable:
257 |                 rewind_body(prepared_request)
258 | 
259 |             # Override the original request.
260 |             req = prepared_request
261 | 
262 |             if yield_requests:
263 |                 yield req
264 |             else:
265 |                 resp = self.send(
266 |                     req,
267 |                     stream=stream,
268 |                     timeout=timeout,
269 |                     verify=verify,
270 |                     cert=cert,
271 |                     proxies=proxies,
272 |                     allow_redirects=False,
273 |                     **adapter_kwargs,
274 |                 )
275 | 
276 |                 extract_cookies_to_jar(self.cookies, prepared_request, resp.raw)
277 | 
278 |                 # extract redirect url, if any, for the next loop
279 |                 url = self.get_redirect_target(resp)
280 |                 yield resp
281 | 
282 |     def rebuild_auth(self, prepared_request, response):
283 |         """When being redirected we may want to strip authentication from the
284 |         request to avoid leaking credentials. This method intelligently removes
285 |         and reapplies authentication where possible to avoid credential loss.
286 |         """
287 |         headers = prepared_request.headers
288 |         url = prepared_request.url
289 | 
290 |         if "Authorization" in headers and self.should_strip_auth(
291 |             response.request.url, url
292 |         ):
293 |             # If we get redirected to a new host, we should strip out any
294 |             # authentication headers.
295 |             del headers["Authorization"]
296 | 
297 |         # .netrc might have more auth for us on our new host.
298 |         new_auth = get_netrc_auth(url) if self.trust_env else None
299 |         if new_auth is not None:
300 |             prepared_request.prepare_auth(new_auth)
301 | 
302 |     def rebuild_proxies(self, prepared_request, proxies):
303 |         """This method re-evaluates the proxy configuration by considering the
304 |         environment variables. If we are redirected to a URL covered by
305 |         NO_PROXY, we strip the proxy configuration. Otherwise, we set missing
306 |         proxy keys for this URL (in case they were stripped by a previous
307 |         redirect).
308 | 
309 |         This method also replaces the Proxy-Authorization header where
310 |         necessary.
311 | 
312 |         :rtype: dict
313 |         """
314 |         headers = prepared_request.headers
315 |         scheme = urlparse(prepared_request.url).scheme
316 |         new_proxies = resolve_proxies(prepared_request, proxies, self.trust_env)
317 | 
318 |         if "Proxy-Authorization" in headers:
319 |             del headers["Proxy-Authorization"]
320 | 
321 |         try:
322 |             username, password = get_auth_from_url(new_proxies[scheme])
323 |         except KeyError:
324 |             username, password = None, None
325 | 
326 |         # urllib3 handles proxy authorization for us in the standard adapter.
327 |         # Avoid appending this to TLS tunneled requests where it may be leaked.
328 |         if not scheme.startswith("https") and username and password:
329 |             headers["Proxy-Authorization"] = _basic_auth_str(username, password)
330 | 
331 |         return new_proxies
332 | 
333 |     def rebuild_method(self, prepared_request, response):
334 |         """When being redirected we may want to change the method of the request
335 |         based on certain specs or browser behavior.
336 |         """
337 |         method = prepared_request.method
338 | 
339 |         # https://tools.ietf.org/html/rfc7231#section-6.4.4
340 |         if response.status_code == codes.see_other and method != "HEAD":
341 |             method = "GET"
342 | 
[TRUNCATED]
```

.venv/lib/python3.13/site-packages/pip/_vendor/requests/status_codes.py
```
1 | r"""
2 | The ``codes`` object defines a mapping from common names for HTTP statuses
3 | to their numerical codes, accessible either as attributes or as dictionary
4 | items.
5 | 
6 | Example::
7 | 
8 |     >>> import requests
9 |     >>> requests.codes['temporary_redirect']
10 |     307
11 |     >>> requests.codes.teapot
12 |     418
13 |     >>> requests.codes['\o/']
14 |     200
15 | 
16 | Some codes have multiple names, and both upper- and lower-case versions of
17 | the names are allowed. For example, ``codes.ok``, ``codes.OK``, and
18 | ``codes.okay`` all correspond to the HTTP status code 200.
19 | """
20 | 
21 | from .structures import LookupDict
22 | 
23 | _codes = {
24 |     # Informational.
25 |     100: ("continue",),
26 |     101: ("switching_protocols",),
27 |     102: ("processing", "early-hints"),
28 |     103: ("checkpoint",),
29 |     122: ("uri_too_long", "request_uri_too_long"),
30 |     200: ("ok", "okay", "all_ok", "all_okay", "all_good", "\\o/", ""),
31 |     201: ("created",),
32 |     202: ("accepted",),
33 |     203: ("non_authoritative_info", "non_authoritative_information"),
34 |     204: ("no_content",),
35 |     205: ("reset_content", "reset"),
36 |     206: ("partial_content", "partial"),
37 |     207: ("multi_status", "multiple_status", "multi_stati", "multiple_stati"),
38 |     208: ("already_reported",),
39 |     226: ("im_used",),
40 |     # Redirection.
41 |     300: ("multiple_choices",),
42 |     301: ("moved_permanently", "moved", "\\o-"),
43 |     302: ("found",),
44 |     303: ("see_other", "other"),
45 |     304: ("not_modified",),
46 |     305: ("use_proxy",),
47 |     306: ("switch_proxy",),
48 |     307: ("temporary_redirect", "temporary_moved", "temporary"),
49 |     308: (
50 |         "permanent_redirect",
51 |         "resume_incomplete",
52 |         "resume",
53 |     ),  # "resume" and "resume_incomplete" to be removed in 3.0
54 |     # Client Error.
55 |     400: ("bad_request", "bad"),
56 |     401: ("unauthorized",),
57 |     402: ("payment_required", "payment"),
58 |     403: ("forbidden",),
59 |     404: ("not_found", "-o-"),
60 |     405: ("method_not_allowed", "not_allowed"),
61 |     406: ("not_acceptable",),
62 |     407: ("proxy_authentication_required", "proxy_auth", "proxy_authentication"),
63 |     408: ("request_timeout", "timeout"),
64 |     409: ("conflict",),
65 |     410: ("gone",),
66 |     411: ("length_required",),
67 |     412: ("precondition_failed", "precondition"),
68 |     413: ("request_entity_too_large", "content_too_large"),
69 |     414: ("request_uri_too_large", "uri_too_long"),
70 |     415: ("unsupported_media_type", "unsupported_media", "media_type"),
71 |     416: (
72 |         "requested_range_not_satisfiable",
73 |         "requested_range",
74 |         "range_not_satisfiable",
75 |     ),
76 |     417: ("expectation_failed",),
77 |     418: ("im_a_teapot", "teapot", "i_am_a_teapot"),
78 |     421: ("misdirected_request",),
79 |     422: ("unprocessable_entity", "unprocessable", "unprocessable_content"),
80 |     423: ("locked",),
81 |     424: ("failed_dependency", "dependency"),
82 |     425: ("unordered_collection", "unordered", "too_early"),
83 |     426: ("upgrade_required", "upgrade"),
84 |     428: ("precondition_required", "precondition"),
85 |     429: ("too_many_requests", "too_many"),
86 |     431: ("header_fields_too_large", "fields_too_large"),
87 |     444: ("no_response", "none"),
88 |     449: ("retry_with", "retry"),
89 |     450: ("blocked_by_windows_parental_controls", "parental_controls"),
90 |     451: ("unavailable_for_legal_reasons", "legal_reasons"),
91 |     499: ("client_closed_request",),
92 |     # Server Error.
93 |     500: ("internal_server_error", "server_error", "/o\\", ""),
94 |     501: ("not_implemented",),
95 |     502: ("bad_gateway",),
96 |     503: ("service_unavailable", "unavailable"),
97 |     504: ("gateway_timeout",),
98 |     505: ("http_version_not_supported", "http_version"),
99 |     506: ("variant_also_negotiates",),
100 |     507: ("insufficient_storage",),
101 |     509: ("bandwidth_limit_exceeded", "bandwidth"),
102 |     510: ("not_extended",),
103 |     511: ("network_authentication_required", "network_auth", "network_authentication"),
104 | }
105 | 
106 | codes = LookupDict(name="status_codes")
107 | 
108 | 
109 | def _init():
110 |     for code, titles in _codes.items():
111 |         for title in titles:
112 |             setattr(codes, title, code)
113 |             if not title.startswith(("\\", "/")):
114 |                 setattr(codes, title.upper(), code)
115 | 
116 |     def doc(code):
117 |         names = ", ".join(f"``{n}``" for n in _codes[code])
118 |         return "* %d: %s" % (code, names)
119 | 
120 |     global __doc__
121 |     __doc__ = (
122 |         __doc__ + "\n" + "\n".join(doc(code) for code in sorted(_codes))
123 |         if __doc__ is not None
124 |         else None
125 |     )
126 | 
127 | 
128 | _init()
```

.venv/lib/python3.13/site-packages/pip/_vendor/requests/structures.py
```
1 | """
2 | requests.structures
3 | ~~~~~~~~~~~~~~~~~~~
4 | 
5 | Data structures that power Requests.
6 | """
7 | 
8 | from collections import OrderedDict
9 | 
10 | from .compat import Mapping, MutableMapping
11 | 
12 | 
13 | class CaseInsensitiveDict(MutableMapping):
14 |     """A case-insensitive ``dict``-like object.
15 | 
16 |     Implements all methods and operations of
17 |     ``MutableMapping`` as well as dict's ``copy``. Also
18 |     provides ``lower_items``.
19 | 
20 |     All keys are expected to be strings. The structure remembers the
21 |     case of the last key to be set, and ``iter(instance)``,
22 |     ``keys()``, ``items()``, ``iterkeys()``, and ``iteritems()``
23 |     will contain case-sensitive keys. However, querying and contains
24 |     testing is case insensitive::
25 | 
26 |         cid = CaseInsensitiveDict()
27 |         cid['Accept'] = 'application/json'
28 |         cid['aCCEPT'] == 'application/json'  # True
29 |         list(cid) == ['Accept']  # True
30 | 
31 |     For example, ``headers['content-encoding']`` will return the
32 |     value of a ``'Content-Encoding'`` response header, regardless
33 |     of how the header name was originally stored.
34 | 
35 |     If the constructor, ``.update``, or equality comparison
36 |     operations are given keys that have equal ``.lower()``s, the
37 |     behavior is undefined.
38 |     """
39 | 
40 |     def __init__(self, data=None, **kwargs):
41 |         self._store = OrderedDict()
42 |         if data is None:
43 |             data = {}
44 |         self.update(data, **kwargs)
45 | 
46 |     def __setitem__(self, key, value):
47 |         # Use the lowercased key for lookups, but store the actual
48 |         # key alongside the value.
49 |         self._store[key.lower()] = (key, value)
50 | 
51 |     def __getitem__(self, key):
52 |         return self._store[key.lower()][1]
53 | 
54 |     def __delitem__(self, key):
55 |         del self._store[key.lower()]
56 | 
57 |     def __iter__(self):
58 |         return (casedkey for casedkey, mappedvalue in self._store.values())
59 | 
60 |     def __len__(self):
61 |         return len(self._store)
62 | 
63 |     def lower_items(self):
64 |         """Like iteritems(), but with all lowercase keys."""
65 |         return ((lowerkey, keyval[1]) for (lowerkey, keyval) in self._store.items())
66 | 
67 |     def __eq__(self, other):
68 |         if isinstance(other, Mapping):
69 |             other = CaseInsensitiveDict(other)
70 |         else:
71 |             return NotImplemented
72 |         # Compare insensitively
73 |         return dict(self.lower_items()) == dict(other.lower_items())
74 | 
75 |     # Copy is required
76 |     def copy(self):
77 |         return CaseInsensitiveDict(self._store.values())
78 | 
79 |     def __repr__(self):
80 |         return str(dict(self.items()))
81 | 
82 | 
83 | class LookupDict(dict):
84 |     """Dictionary lookup object."""
85 | 
86 |     def __init__(self, name=None):
87 |         self.name = name
88 |         super().__init__()
89 | 
90 |     def __repr__(self):
91 |         return f"<lookup '{self.name}'>"
92 | 
93 |     def __getitem__(self, key):
94 |         # We allow fall-through here, so values default to None
95 | 
96 |         return self.__dict__.get(key, None)
97 | 
98 |     def get(self, key, default=None):
99 |         return self.__dict__.get(key, default)
```

.venv/lib/python3.13/site-packages/pip/_vendor/requests/utils.py
```
1 | """
2 | requests.utils
3 | ~~~~~~~~~~~~~~
4 | 
5 | This module provides utility functions that are used within Requests
6 | that are also useful for external consumption.
7 | """
8 | 
9 | import codecs
10 | import contextlib
11 | import io
12 | import os
13 | import re
14 | import socket
15 | import struct
16 | import sys
17 | import tempfile
18 | import warnings
19 | import zipfile
20 | from collections import OrderedDict
21 | 
22 | from pip._vendor.urllib3.util import make_headers, parse_url
23 | 
24 | from . import certs
25 | from .__version__ import __version__
26 | 
27 | # to_native_string is unused here, but imported here for backwards compatibility
28 | from ._internal_utils import (  # noqa: F401
29 |     _HEADER_VALIDATORS_BYTE,
30 |     _HEADER_VALIDATORS_STR,
31 |     HEADER_VALIDATORS,
32 |     to_native_string,
33 | )
34 | from .compat import (
35 |     Mapping,
36 |     basestring,
37 |     bytes,
38 |     getproxies,
39 |     getproxies_environment,
40 |     integer_types,
41 | )
42 | from .compat import parse_http_list as _parse_list_header
43 | from .compat import (
44 |     proxy_bypass,
45 |     proxy_bypass_environment,
46 |     quote,
47 |     str,
48 |     unquote,
49 |     urlparse,
50 |     urlunparse,
51 | )
52 | from .cookies import cookiejar_from_dict
53 | from .exceptions import (
54 |     FileModeWarning,
55 |     InvalidHeader,
56 |     InvalidURL,
57 |     UnrewindableBodyError,
58 | )
59 | from .structures import CaseInsensitiveDict
60 | 
61 | NETRC_FILES = (".netrc", "_netrc")
62 | 
63 | DEFAULT_CA_BUNDLE_PATH = certs.where()
64 | 
65 | DEFAULT_PORTS = {"http": 80, "https": 443}
66 | 
67 | # Ensure that ', ' is used to preserve previous delimiter behavior.
68 | DEFAULT_ACCEPT_ENCODING = ", ".join(
69 |     re.split(r",\s*", make_headers(accept_encoding=True)["accept-encoding"])
70 | )
71 | 
72 | 
73 | if sys.platform == "win32":
74 |     # provide a proxy_bypass version on Windows without DNS lookups
75 | 
76 |     def proxy_bypass_registry(host):
77 |         try:
78 |             import winreg
79 |         except ImportError:
80 |             return False
81 | 
82 |         try:
83 |             internetSettings = winreg.OpenKey(
84 |                 winreg.HKEY_CURRENT_USER,
85 |                 r"Software\Microsoft\Windows\CurrentVersion\Internet Settings",
86 |             )
87 |             # ProxyEnable could be REG_SZ or REG_DWORD, normalizing it
88 |             proxyEnable = int(winreg.QueryValueEx(internetSettings, "ProxyEnable")[0])
89 |             # ProxyOverride is almost always a string
90 |             proxyOverride = winreg.QueryValueEx(internetSettings, "ProxyOverride")[0]
91 |         except (OSError, ValueError):
92 |             return False
93 |         if not proxyEnable or not proxyOverride:
94 |             return False
95 | 
96 |         # make a check value list from the registry entry: replace the
97 |         # '<local>' string by the localhost entry and the corresponding
98 |         # canonical entry.
99 |         proxyOverride = proxyOverride.split(";")
100 |         # filter out empty strings to avoid re.match return true in the following code.
101 |         proxyOverride = filter(None, proxyOverride)
102 |         # now check if we match one of the registry values.
103 |         for test in proxyOverride:
104 |             if test == "<local>":
105 |                 if "." not in host:
106 |                     return True
107 |             test = test.replace(".", r"\.")  # mask dots
108 |             test = test.replace("*", r".*")  # change glob sequence
109 |             test = test.replace("?", r".")  # change glob char
110 |             if re.match(test, host, re.I):
111 |                 return True
112 |         return False
113 | 
114 |     def proxy_bypass(host):  # noqa
115 |         """Return True, if the host should be bypassed.
116 | 
117 |         Checks proxy settings gathered from the environment, if specified,
118 |         or the registry.
119 |         """
120 |         if getproxies_environment():
121 |             return proxy_bypass_environment(host)
122 |         else:
123 |             return proxy_bypass_registry(host)
124 | 
125 | 
126 | def dict_to_sequence(d):
127 |     """Returns an internal sequence dictionary update."""
128 | 
129 |     if hasattr(d, "items"):
130 |         d = d.items()
131 | 
132 |     return d
133 | 
134 | 
135 | def super_len(o):
136 |     total_length = None
137 |     current_position = 0
138 | 
139 |     if isinstance(o, str):
140 |         o = o.encode("utf-8")
141 | 
142 |     if hasattr(o, "__len__"):
143 |         total_length = len(o)
144 | 
145 |     elif hasattr(o, "len"):
146 |         total_length = o.len
147 | 
148 |     elif hasattr(o, "fileno"):
149 |         try:
150 |             fileno = o.fileno()
151 |         except (io.UnsupportedOperation, AttributeError):
152 |             # AttributeError is a surprising exception, seeing as how we've just checked
153 |             # that `hasattr(o, 'fileno')`.  It happens for objects obtained via
154 |             # `Tarfile.extractfile()`, per issue 5229.
155 |             pass
156 |         else:
157 |             total_length = os.fstat(fileno).st_size
158 | 
159 |             # Having used fstat to determine the file length, we need to
160 |             # confirm that this file was opened up in binary mode.
161 |             if "b" not in o.mode:
162 |                 warnings.warn(
163 |                     (
164 |                         "Requests has determined the content-length for this "
165 |                         "request using the binary size of the file: however, the "
166 |                         "file has been opened in text mode (i.e. without the 'b' "
167 |                         "flag in the mode). This may lead to an incorrect "
168 |                         "content-length. In Requests 3.0, support will be removed "
169 |                         "for files in text mode."
170 |                     ),
171 |                     FileModeWarning,
172 |                 )
173 | 
174 |     if hasattr(o, "tell"):
175 |         try:
176 |             current_position = o.tell()
177 |         except OSError:
178 |             # This can happen in some weird situations, such as when the file
179 |             # is actually a special file descriptor like stdin. In this
180 |             # instance, we don't know what the length is, so set it to zero and
181 |             # let requests chunk it instead.
182 |             if total_length is not None:
183 |                 current_position = total_length
184 |         else:
185 |             if hasattr(o, "seek") and total_length is None:
186 |                 # StringIO and BytesIO have seek but no usable fileno
187 |                 try:
188 |                     # seek to end of file
189 |                     o.seek(0, 2)
190 |                     total_length = o.tell()
191 | 
192 |                     # seek back to current position to support
193 |                     # partially read file-like objects
194 |                     o.seek(current_position or 0)
195 |                 except OSError:
196 |                     total_length = 0
197 | 
198 |     if total_length is None:
199 |         total_length = 0
200 | 
201 |     return max(0, total_length - current_position)
202 | 
203 | 
204 | def get_netrc_auth(url, raise_errors=False):
205 |     """Returns the Requests tuple auth for a given url from netrc."""
206 | 
207 |     netrc_file = os.environ.get("NETRC")
208 |     if netrc_file is not None:
209 |         netrc_locations = (netrc_file,)
210 |     else:
211 |         netrc_locations = (f"~/{f}" for f in NETRC_FILES)
212 | 
213 |     try:
214 |         from netrc import NetrcParseError, netrc
215 | 
216 |         netrc_path = None
217 | 
218 |         for f in netrc_locations:
219 |             try:
220 |                 loc = os.path.expanduser(f)
221 |             except KeyError:
222 |                 # os.path.expanduser can fail when $HOME is undefined and
223 |                 # getpwuid fails. See https://bugs.python.org/issue20164 &
224 |                 # https://github.com/psf/requests/issues/1846
225 |                 return
226 | 
227 |             if os.path.exists(loc):
228 |                 netrc_path = loc
229 |                 break
230 | 
231 |         # Abort early if there isn't one.
232 |         if netrc_path is None:
233 |             return
234 | 
235 |         ri = urlparse(url)
236 | 
237 |         # Strip port numbers from netloc. This weird `if...encode`` dance is
238 |         # used for Python 3.2, which doesn't support unicode literals.
239 |         splitstr = b":"
240 |         if isinstance(url, str):
241 |             splitstr = splitstr.decode("ascii")
242 |         host = ri.netloc.split(splitstr)[0]
243 | 
244 |         try:
245 |             _netrc = netrc(netrc_path).authenticators(host)
246 |             if _netrc:
247 |                 # Return with login / password
248 |                 login_i = 0 if _netrc[0] else 1
249 |                 return (_netrc[login_i], _netrc[2])
250 |         except (NetrcParseError, OSError):
251 |             # If there was a parsing error or a permissions issue reading the file,
252 |             # we'll just skip netrc auth unless explicitly asked to raise errors.
253 |             if raise_errors:
254 |                 raise
255 | 
256 |     # App Engine hackiness.
257 |     except (ImportError, AttributeError):
258 |         pass
259 | 
260 | 
261 | def guess_filename(obj):
262 |     """Tries to guess the filename of the given object."""
263 |     name = getattr(obj, "name", None)
264 |     if name and isinstance(name, basestring) and name[0] != "<" and name[-1] != ">":
265 |         return os.path.basename(name)
266 | 
267 | 
268 | def extract_zipped_paths(path):
269 |     """Replace nonexistent paths that look like they refer to a member of a zip
270 |     archive with the location of an extracted copy of the target, or else
271 |     just return the provided path unchanged.
272 |     """
273 |     if os.path.exists(path):
274 |         # this is already a valid path, no need to do anything further
275 |         return path
276 | 
277 |     # find the first valid part of the provided path and treat that as a zip archive
278 |     # assume the rest of the path is the name of a member in the archive
279 |     archive, member = os.path.split(path)
280 |     while archive and not os.path.exists(archive):
281 |         archive, prefix = os.path.split(archive)
282 |         if not prefix:
283 |             # If we don't check for an empty prefix after the split (in other words, archive remains unchanged after the split),
284 |             # we _can_ end up in an infinite loop on a rare corner case affecting a small number of users
285 |             break
286 |         member = "/".join([prefix, member])
287 | 
288 |     if not zipfile.is_zipfile(archive):
289 |         return path
290 | 
291 |     zip_file = zipfile.ZipFile(archive)
292 |     if member not in zip_file.namelist():
293 |         return path
294 | 
295 |     # we have a valid zip archive and a valid member of that archive
296 |     tmp = tempfile.gettempdir()
297 |     extracted_path = os.path.join(tmp, member.split("/")[-1])
298 |     if not os.path.exists(extracted_path):
299 |         # use read + write to avoid the creating nested folders, we only want the file, avoids mkdir racing condition
300 |         with atomic_open(extracted_path) as file_handler:
301 |             file_handler.write(zip_file.read(member))
302 |     return extracted_path
303 | 
304 | 
305 | @contextlib.contextmanager
306 | def atomic_open(filename):
307 |     """Write a file to the disk in an atomic fashion"""
308 |     tmp_descriptor, tmp_name = tempfile.mkstemp(dir=os.path.dirname(filename))
309 |     try:
310 |         with os.fdopen(tmp_descriptor, "wb") as tmp_handler:
311 |             yield tmp_handler
312 |         os.replace(tmp_name, filename)
313 |     except BaseException:
314 |         os.remove(tmp_name)
315 |         raise
316 | 
317 | 
318 | def from_key_val_list(value):
319 |     """Take an object and test to see if it can be represented as a
320 |     dictionary. Unless it can not be represented as such, return an
321 |     OrderedDict, e.g.,
322 | 
323 |     ::
324 | 
325 |         >>> from_key_val_list([('key', 'val')])
326 |         OrderedDict([('key', 'val')])
327 |         >>> from_key_val_list('string')
328 |         Traceback (most recent call last):
329 |         ...
330 |         ValueError: cannot encode objects that are not 2-tuples
331 |         >>> from_key_val_list({'key': 'val'})
332 |         OrderedDict([('key', 'val')])
333 | 
334 |     :rtype: OrderedDict
335 |     """
336 |     if value is None:
337 |         return None
338 | 
339 |     if isinstance(value, (str, bytes, bool, int)):
340 |         raise ValueError("cannot encode objects that are not 2-tuples")
341 | 
342 |     return OrderedDict(value)
343 | 
344 | 
345 | def to_key_val_list(value):
346 |     """Take an object and test to see if it can be represented as a
347 |     dictionary. If it can be, return a list of tuples, e.g.,
348 | 
349 |     ::
350 | 
351 |         >>> to_key_val_list([('key', 'val')])
352 |         [('key', 'val')]
353 |         >>> to_key_val_list({'key': 'val'})
354 |         [('key', 'val')]
355 |         >>> to_key_val_list('string')
356 |         Traceback (most recent call last):
357 |         ...
358 |         ValueError: cannot encode objects that are not 2-tuples
359 | 
360 |     :rtype: list
361 |     """
362 |     if value is None:
363 |         return None
364 | 
[TRUNCATED]
```

.venv/lib/python3.13/site-packages/pip/_vendor/resolvelib/__init__.py
```
1 | __all__ = [
2 |     "__version__",
3 |     "AbstractProvider",
4 |     "AbstractResolver",
5 |     "BaseReporter",
6 |     "InconsistentCandidate",
7 |     "Resolver",
8 |     "RequirementsConflicted",
9 |     "ResolutionError",
10 |     "ResolutionImpossible",
11 |     "ResolutionTooDeep",
12 | ]
13 | 
14 | __version__ = "1.1.0"
15 | 
16 | 
17 | from .providers import AbstractProvider
18 | from .reporters import BaseReporter
19 | from .resolvers import (
20 |     AbstractResolver,
21 |     InconsistentCandidate,
22 |     RequirementsConflicted,
23 |     ResolutionError,
24 |     ResolutionImpossible,
25 |     ResolutionTooDeep,
26 |     Resolver,
27 | )
```

.venv/lib/python3.13/site-packages/pip/_vendor/resolvelib/providers.py
```
1 | from __future__ import annotations
2 | 
3 | from typing import (
4 |     TYPE_CHECKING,
5 |     Generic,
6 |     Iterable,
7 |     Iterator,
8 |     Mapping,
9 |     Sequence,
10 | )
11 | 
12 | from .structs import CT, KT, RT, Matches, RequirementInformation
13 | 
14 | if TYPE_CHECKING:
15 |     from typing import Any, Protocol
16 | 
17 |     class Preference(Protocol):
18 |         def __lt__(self, __other: Any) -> bool: ...
19 | 
20 | 
21 | class AbstractProvider(Generic[RT, CT, KT]):
22 |     """Delegate class to provide the required interface for the resolver."""
23 | 
24 |     def identify(self, requirement_or_candidate: RT | CT) -> KT:
25 |         """Given a requirement or candidate, return an identifier for it.
26 | 
27 |         This is used to identify, e.g. whether two requirements
28 |         should have their specifier parts merged or a candidate matches a
29 |         requirement via ``find_matches()``.
30 |         """
31 |         raise NotImplementedError
32 | 
33 |     def get_preference(
34 |         self,
35 |         identifier: KT,
36 |         resolutions: Mapping[KT, CT],
37 |         candidates: Mapping[KT, Iterator[CT]],
38 |         information: Mapping[KT, Iterator[RequirementInformation[RT, CT]]],
39 |         backtrack_causes: Sequence[RequirementInformation[RT, CT]],
40 |     ) -> Preference:
41 |         """Produce a sort key for given requirement based on preference.
42 | 
43 |         As this is a sort key it will be called O(n) times per backtrack
44 |         step, where n is the number of `identifier`s, if you have a check
45 |         which is expensive in some sense. E.g. It needs to make O(n) checks
46 |         per call or takes significant wall clock time, consider using
47 |         `narrow_requirement_selection` to filter the `identifier`s, which
48 |         is applied before this sort key is called.
49 | 
50 |         The preference is defined as "I think this requirement should be
51 |         resolved first". The lower the return value is, the more preferred
52 |         this group of arguments is.
53 | 
54 |         :param identifier: An identifier as returned by ``identify()``. This
55 |             identifies the requirement being considered.
56 |         :param resolutions: Mapping of candidates currently pinned by the
57 |             resolver. Each key is an identifier, and the value is a candidate.
58 |             The candidate may conflict with requirements from ``information``.
59 |         :param candidates: Mapping of each dependency's possible candidates.
60 |             Each value is an iterator of candidates.
61 |         :param information: Mapping of requirement information of each package.
62 |             Each value is an iterator of *requirement information*.
63 |         :param backtrack_causes: Sequence of *requirement information* that are
64 |             the requirements that caused the resolver to most recently
65 |             backtrack.
66 | 
67 |         A *requirement information* instance is a named tuple with two members:
68 | 
69 |         * ``requirement`` specifies a requirement contributing to the current
70 |           list of candidates.
71 |         * ``parent`` specifies the candidate that provides (depended on) the
72 |           requirement, or ``None`` to indicate a root requirement.
73 | 
74 |         The preference could depend on various issues, including (not
75 |         necessarily in this order):
76 | 
77 |         * Is this package pinned in the current resolution result?
78 |         * How relaxed is the requirement? Stricter ones should probably be
79 |           worked on first? (I don't know, actually.)
80 |         * How many possibilities are there to satisfy this requirement? Those
81 |           with few left should likely be worked on first, I guess?
82 |         * Are there any known conflicts for this requirement? We should
83 |           probably work on those with the most known conflicts.
84 | 
85 |         A sortable value should be returned (this will be used as the ``key``
86 |         parameter of the built-in sorting function). The smaller the value is,
87 |         the more preferred this requirement is (i.e. the sorting function
88 |         is called with ``reverse=False``).
89 |         """
90 |         raise NotImplementedError
91 | 
92 |     def find_matches(
93 |         self,
94 |         identifier: KT,
95 |         requirements: Mapping[KT, Iterator[RT]],
96 |         incompatibilities: Mapping[KT, Iterator[CT]],
97 |     ) -> Matches[CT]:
98 |         """Find all possible candidates that satisfy the given constraints.
99 | 
100 |         :param identifier: An identifier as returned by ``identify()``. All
101 |             candidates returned by this method should produce the same
102 |             identifier.
103 |         :param requirements: A mapping of requirements that all returned
104 |             candidates must satisfy. Each key is an identifier, and the value
105 |             an iterator of requirements for that dependency.
106 |         :param incompatibilities: A mapping of known incompatibile candidates of
107 |             each dependency. Each key is an identifier, and the value an
108 |             iterator of incompatibilities known to the resolver. All
109 |             incompatibilities *must* be excluded from the return value.
110 | 
111 |         This should try to get candidates based on the requirements' types.
112 |         For VCS, local, and archive requirements, the one-and-only match is
113 |         returned, and for a "named" requirement, the index(es) should be
114 |         consulted to find concrete candidates for this requirement.
115 | 
116 |         The return value should produce candidates ordered by preference; the
117 |         most preferred candidate should come first. The return type may be one
118 |         of the following:
119 | 
120 |         * A callable that returns an iterator that yields candidates.
121 |         * An collection of candidates.
122 |         * An iterable of candidates. This will be consumed immediately into a
123 |           list of candidates.
124 |         """
125 |         raise NotImplementedError
126 | 
127 |     def is_satisfied_by(self, requirement: RT, candidate: CT) -> bool:
128 |         """Whether the given requirement can be satisfied by a candidate.
129 | 
130 |         The candidate is guaranteed to have been generated from the
131 |         requirement.
132 | 
133 |         A boolean should be returned to indicate whether ``candidate`` is a
134 |         viable solution to the requirement.
135 |         """
136 |         raise NotImplementedError
137 | 
138 |     def get_dependencies(self, candidate: CT) -> Iterable[RT]:
139 |         """Get dependencies of a candidate.
140 | 
141 |         This should return a collection of requirements that `candidate`
142 |         specifies as its dependencies.
143 |         """
144 |         raise NotImplementedError
145 | 
146 |     def narrow_requirement_selection(
147 |         self,
148 |         identifiers: Iterable[KT],
149 |         resolutions: Mapping[KT, CT],
150 |         candidates: Mapping[KT, Iterator[CT]],
151 |         information: Mapping[KT, Iterator[RequirementInformation[RT, CT]]],
152 |         backtrack_causes: Sequence[RequirementInformation[RT, CT]],
153 |     ) -> Iterable[KT]:
154 |         """
155 |         An optional method to narrow the selection of requirements being
156 |         considered during resolution. This method is called O(1) time per
157 |         backtrack step.
158 | 
159 |         :param identifiers: An iterable of `identifiers` as returned by
160 |             ``identify()``. These identify all requirements currently being
161 |             considered.
162 |         :param resolutions: A mapping of candidates currently pinned by the
163 |             resolver. Each key is an identifier, and the value is a candidate
164 |             that may conflict with requirements from ``information``.
165 |         :param candidates: A mapping of each dependency's possible candidates.
166 |             Each value is an iterator of candidates.
167 |         :param information: A mapping of requirement information for each package.
168 |             Each value is an iterator of *requirement information*.
169 |         :param backtrack_causes: A sequence of *requirement information* that are
170 |             the requirements causing the resolver to most recently
171 |             backtrack.
172 | 
173 |         A *requirement information* instance is a named tuple with two members:
174 | 
175 |         * ``requirement`` specifies a requirement contributing to the current
176 |           list of candidates.
177 |         * ``parent`` specifies the candidate that provides (is depended on for)
178 |           the requirement, or ``None`` to indicate a root requirement.
179 | 
180 |         Must return a non-empty subset of `identifiers`, with the default
181 |         implementation being to return `identifiers` unchanged. Those `identifiers`
182 |         will then be passed to the sort key `get_preference` to pick the most
183 |         prefered requirement to attempt to pin, unless `narrow_requirement_selection`
184 |         returns only 1 requirement, in which case that will be used without
185 |         calling the sort key `get_preference`.
186 | 
187 |         This method is designed to be used by the provider to optimize the
188 |         dependency resolution, e.g. if a check cost is O(m) and it can be done
189 |         against all identifiers at once then filtering the requirement selection
190 |         here will cost O(m) but making it part of the sort key in `get_preference`
191 |         will cost O(m*n), where n is the number of `identifiers`.
192 | 
193 |         Returns:
194 |             Iterable[KT]: A non-empty subset of `identifiers`.
195 |         """
196 |         return identifiers
```

.venv/lib/python3.13/site-packages/pip/_vendor/resolvelib/py.typed
```
```

.venv/lib/python3.13/site-packages/pip/_vendor/resolvelib/reporters.py
```
1 | from __future__ import annotations
2 | 
3 | from typing import TYPE_CHECKING, Collection, Generic
4 | 
5 | from .structs import CT, KT, RT, RequirementInformation, State
6 | 
7 | if TYPE_CHECKING:
8 |     from .resolvers import Criterion
9 | 
10 | 
11 | class BaseReporter(Generic[RT, CT, KT]):
12 |     """Delegate class to provider progress reporting for the resolver."""
13 | 
14 |     def starting(self) -> None:
15 |         """Called before the resolution actually starts."""
16 | 
17 |     def starting_round(self, index: int) -> None:
18 |         """Called before each round of resolution starts.
19 | 
20 |         The index is zero-based.
21 |         """
22 | 
23 |     def ending_round(self, index: int, state: State[RT, CT, KT]) -> None:
24 |         """Called before each round of resolution ends.
25 | 
26 |         This is NOT called if the resolution ends at this round. Use `ending`
27 |         if you want to report finalization. The index is zero-based.
28 |         """
29 | 
30 |     def ending(self, state: State[RT, CT, KT]) -> None:
31 |         """Called before the resolution ends successfully."""
32 | 
33 |     def adding_requirement(self, requirement: RT, parent: CT | None) -> None:
34 |         """Called when adding a new requirement into the resolve criteria.
35 | 
36 |         :param requirement: The additional requirement to be applied to filter
37 |             the available candidaites.
38 |         :param parent: The candidate that requires ``requirement`` as a
39 |             dependency, or None if ``requirement`` is one of the root
40 |             requirements passed in from ``Resolver.resolve()``.
41 |         """
42 | 
43 |     def resolving_conflicts(
44 |         self, causes: Collection[RequirementInformation[RT, CT]]
45 |     ) -> None:
46 |         """Called when starting to attempt requirement conflict resolution.
47 | 
48 |         :param causes: The information on the collision that caused the backtracking.
49 |         """
50 | 
51 |     def rejecting_candidate(self, criterion: Criterion[RT, CT], candidate: CT) -> None:
52 |         """Called when rejecting a candidate during backtracking."""
53 | 
54 |     def pinning(self, candidate: CT) -> None:
55 |         """Called when adding a candidate to the potential solution."""
```

.venv/lib/python3.13/site-packages/pip/_vendor/resolvelib/structs.py
```
1 | from __future__ import annotations
2 | 
3 | import itertools
4 | from collections import namedtuple
5 | from typing import (
6 |     TYPE_CHECKING,
7 |     Callable,
8 |     Generic,
9 |     Iterable,
10 |     Iterator,
11 |     Mapping,
12 |     NamedTuple,
13 |     Sequence,
14 |     TypeVar,
15 |     Union,
16 | )
17 | 
18 | KT = TypeVar("KT")  # Identifier.
19 | RT = TypeVar("RT")  # Requirement.
20 | CT = TypeVar("CT")  # Candidate.
21 | 
22 | Matches = Union[Iterable[CT], Callable[[], Iterable[CT]]]
23 | 
24 | if TYPE_CHECKING:
25 |     from .resolvers.criterion import Criterion
26 | 
27 |     class RequirementInformation(NamedTuple, Generic[RT, CT]):
28 |         requirement: RT
29 |         parent: CT | None
30 | 
31 |     class State(NamedTuple, Generic[RT, CT, KT]):
32 |         """Resolution state in a round."""
33 | 
34 |         mapping: dict[KT, CT]
35 |         criteria: dict[KT, Criterion[RT, CT]]
36 |         backtrack_causes: list[RequirementInformation[RT, CT]]
37 | 
38 | else:
39 |     RequirementInformation = namedtuple(
40 |         "RequirementInformation", ["requirement", "parent"]
41 |     )
42 |     State = namedtuple("State", ["mapping", "criteria", "backtrack_causes"])
43 | 
44 | 
45 | class DirectedGraph(Generic[KT]):
46 |     """A graph structure with directed edges."""
47 | 
48 |     def __init__(self) -> None:
49 |         self._vertices: set[KT] = set()
50 |         self._forwards: dict[KT, set[KT]] = {}  # <key> -> Set[<key>]
51 |         self._backwards: dict[KT, set[KT]] = {}  # <key> -> Set[<key>]
52 | 
53 |     def __iter__(self) -> Iterator[KT]:
54 |         return iter(self._vertices)
55 | 
56 |     def __len__(self) -> int:
57 |         return len(self._vertices)
58 | 
59 |     def __contains__(self, key: KT) -> bool:
60 |         return key in self._vertices
61 | 
62 |     def copy(self) -> DirectedGraph[KT]:
63 |         """Return a shallow copy of this graph."""
64 |         other = type(self)()
65 |         other._vertices = set(self._vertices)
66 |         other._forwards = {k: set(v) for k, v in self._forwards.items()}
67 |         other._backwards = {k: set(v) for k, v in self._backwards.items()}
68 |         return other
69 | 
70 |     def add(self, key: KT) -> None:
71 |         """Add a new vertex to the graph."""
72 |         if key in self._vertices:
73 |             raise ValueError("vertex exists")
74 |         self._vertices.add(key)
75 |         self._forwards[key] = set()
76 |         self._backwards[key] = set()
77 | 
78 |     def remove(self, key: KT) -> None:
79 |         """Remove a vertex from the graph, disconnecting all edges from/to it."""
80 |         self._vertices.remove(key)
81 |         for f in self._forwards.pop(key):
82 |             self._backwards[f].remove(key)
83 |         for t in self._backwards.pop(key):
84 |             self._forwards[t].remove(key)
85 | 
86 |     def connected(self, f: KT, t: KT) -> bool:
87 |         return f in self._backwards[t] and t in self._forwards[f]
88 | 
89 |     def connect(self, f: KT, t: KT) -> None:
90 |         """Connect two existing vertices.
91 | 
92 |         Nothing happens if the vertices are already connected.
93 |         """
94 |         if t not in self._vertices:
95 |             raise KeyError(t)
96 |         self._forwards[f].add(t)
97 |         self._backwards[t].add(f)
98 | 
99 |     def iter_edges(self) -> Iterator[tuple[KT, KT]]:
100 |         for f, children in self._forwards.items():
101 |             for t in children:
102 |                 yield f, t
103 | 
104 |     def iter_children(self, key: KT) -> Iterator[KT]:
105 |         return iter(self._forwards[key])
106 | 
107 |     def iter_parents(self, key: KT) -> Iterator[KT]:
108 |         return iter(self._backwards[key])
109 | 
110 | 
111 | class IteratorMapping(Mapping[KT, Iterator[CT]], Generic[RT, CT, KT]):
112 |     def __init__(
113 |         self,
114 |         mapping: Mapping[KT, RT],
115 |         accessor: Callable[[RT], Iterable[CT]],
116 |         appends: Mapping[KT, Iterable[CT]] | None = None,
117 |     ) -> None:
118 |         self._mapping = mapping
119 |         self._accessor = accessor
120 |         self._appends: Mapping[KT, Iterable[CT]] = appends or {}
121 | 
122 |     def __repr__(self) -> str:
123 |         return "IteratorMapping({!r}, {!r}, {!r})".format(
124 |             self._mapping,
125 |             self._accessor,
126 |             self._appends,
127 |         )
128 | 
129 |     def __bool__(self) -> bool:
130 |         return bool(self._mapping or self._appends)
131 | 
132 |     def __contains__(self, key: object) -> bool:
133 |         return key in self._mapping or key in self._appends
134 | 
135 |     def __getitem__(self, k: KT) -> Iterator[CT]:
136 |         try:
137 |             v = self._mapping[k]
138 |         except KeyError:
139 |             return iter(self._appends[k])
140 |         return itertools.chain(self._accessor(v), self._appends.get(k, ()))
141 | 
142 |     def __iter__(self) -> Iterator[KT]:
143 |         more = (k for k in self._appends if k not in self._mapping)
144 |         return itertools.chain(self._mapping, more)
145 | 
146 |     def __len__(self) -> int:
147 |         more = sum(1 for k in self._appends if k not in self._mapping)
148 |         return len(self._mapping) + more
149 | 
150 | 
151 | class _FactoryIterableView(Iterable[RT]):
152 |     """Wrap an iterator factory returned by `find_matches()`.
153 | 
154 |     Calling `iter()` on this class would invoke the underlying iterator
155 |     factory, making it a "collection with ordering" that can be iterated
156 |     through multiple times, but lacks random access methods presented in
157 |     built-in Python sequence types.
158 |     """
159 | 
160 |     def __init__(self, factory: Callable[[], Iterable[RT]]) -> None:
161 |         self._factory = factory
162 |         self._iterable: Iterable[RT] | None = None
163 | 
164 |     def __repr__(self) -> str:
165 |         return f"{type(self).__name__}({list(self)})"
166 | 
167 |     def __bool__(self) -> bool:
168 |         try:
169 |             next(iter(self))
170 |         except StopIteration:
171 |             return False
172 |         return True
173 | 
174 |     def __iter__(self) -> Iterator[RT]:
175 |         iterable = self._factory() if self._iterable is None else self._iterable
176 |         self._iterable, current = itertools.tee(iterable)
177 |         return current
178 | 
179 | 
180 | class _SequenceIterableView(Iterable[RT]):
181 |     """Wrap an iterable returned by find_matches().
182 | 
183 |     This is essentially just a proxy to the underlying sequence that provides
184 |     the same interface as `_FactoryIterableView`.
185 |     """
186 | 
187 |     def __init__(self, sequence: Sequence[RT]):
188 |         self._sequence = sequence
189 | 
190 |     def __repr__(self) -> str:
191 |         return f"{type(self).__name__}({self._sequence})"
192 | 
193 |     def __bool__(self) -> bool:
194 |         return bool(self._sequence)
195 | 
196 |     def __iter__(self) -> Iterator[RT]:
197 |         return iter(self._sequence)
198 | 
199 | 
200 | def build_iter_view(matches: Matches[CT]) -> Iterable[CT]:
201 |     """Build an iterable view from the value returned by `find_matches()`."""
202 |     if callable(matches):
203 |         return _FactoryIterableView(matches)
204 |     if not isinstance(matches, Sequence):
205 |         matches = list(matches)
206 |     return _SequenceIterableView(matches)
207 | 
208 | 
209 | IterableView = Iterable
```

.venv/lib/python3.13/site-packages/pip/_vendor/pygments/__init__.py
```
1 | """
2 |     Pygments
3 |     ~~~~~~~~
4 | 
5 |     Pygments is a syntax highlighting package written in Python.
6 | 
7 |     It is a generic syntax highlighter for general use in all kinds of software
8 |     such as forum systems, wikis or other applications that need to prettify
9 |     source code. Highlights are:
10 | 
11 |     * a wide range of common languages and markup formats is supported
12 |     * special attention is paid to details, increasing quality by a fair amount
13 |     * support for new languages and formats are added easily
14 |     * a number of output formats, presently HTML, LaTeX, RTF, SVG, all image
15 |       formats that PIL supports, and ANSI sequences
16 |     * it is usable as a command-line tool and as a library
17 |     * ... and it highlights even Brainfuck!
18 | 
19 |     The `Pygments master branch`_ is installable with ``easy_install Pygments==dev``.
20 | 
21 |     .. _Pygments master branch:
22 |        https://github.com/pygments/pygments/archive/master.zip#egg=Pygments-dev
23 | 
24 |     :copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
25 |     :license: BSD, see LICENSE for details.
26 | """
27 | from io import StringIO, BytesIO
28 | 
29 | __version__ = '2.19.1'
30 | __docformat__ = 'restructuredtext'
31 | 
32 | __all__ = ['lex', 'format', 'highlight']
33 | 
34 | 
35 | def lex(code, lexer):
36 |     """
37 |     Lex `code` with the `lexer` (must be a `Lexer` instance)
38 |     and return an iterable of tokens. Currently, this only calls
39 |     `lexer.get_tokens()`.
40 |     """
41 |     try:
42 |         return lexer.get_tokens(code)
43 |     except TypeError:
44 |         # Heuristic to catch a common mistake.
45 |         from pip._vendor.pygments.lexer import RegexLexer
46 |         if isinstance(lexer, type) and issubclass(lexer, RegexLexer):
47 |             raise TypeError('lex() argument must be a lexer instance, '
48 |                             'not a class')
49 |         raise
50 | 
51 | 
52 | def format(tokens, formatter, outfile=None):  # pylint: disable=redefined-builtin
53 |     """
54 |     Format ``tokens`` (an iterable of tokens) with the formatter ``formatter``
55 |     (a `Formatter` instance).
56 | 
57 |     If ``outfile`` is given and a valid file object (an object with a
58 |     ``write`` method), the result will be written to it, otherwise it
59 |     is returned as a string.
60 |     """
61 |     try:
62 |         if not outfile:
63 |             realoutfile = getattr(formatter, 'encoding', None) and BytesIO() or StringIO()
64 |             formatter.format(tokens, realoutfile)
65 |             return realoutfile.getvalue()
66 |         else:
67 |             formatter.format(tokens, outfile)
68 |     except TypeError:
69 |         # Heuristic to catch a common mistake.
70 |         from pip._vendor.pygments.formatter import Formatter
71 |         if isinstance(formatter, type) and issubclass(formatter, Formatter):
72 |             raise TypeError('format() argument must be a formatter instance, '
73 |                             'not a class')
74 |         raise
75 | 
76 | 
77 | def highlight(code, lexer, formatter, outfile=None):
78 |     """
79 |     This is the most high-level highlighting function. It combines `lex` and
80 |     `format` in one function.
81 |     """
82 |     return format(lex(code, lexer), formatter, outfile)
```

.venv/lib/python3.13/site-packages/pip/_vendor/pygments/__main__.py
```
1 | """
2 |     pygments.__main__
3 |     ~~~~~~~~~~~~~~~~~
4 | 
5 |     Main entry point for ``python -m pygments``.
6 | 
7 |     :copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
8 |     :license: BSD, see LICENSE for details.
9 | """
10 | 
11 | import sys
12 | from pip._vendor.pygments.cmdline import main
13 | 
14 | try:
15 |     sys.exit(main(sys.argv))
16 | except KeyboardInterrupt:
17 |     sys.exit(1)
```

.venv/lib/python3.13/site-packages/pip/_vendor/pygments/console.py
```
1 | """
2 |     pygments.console
3 |     ~~~~~~~~~~~~~~~~
4 | 
5 |     Format colored console output.
6 | 
7 |     :copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
8 |     :license: BSD, see LICENSE for details.
9 | """
10 | 
11 | esc = "\x1b["
12 | 
13 | codes = {}
14 | codes[""] = ""
15 | codes["reset"] = esc + "39;49;00m"
16 | 
17 | codes["bold"] = esc + "01m"
18 | codes["faint"] = esc + "02m"
19 | codes["standout"] = esc + "03m"
20 | codes["underline"] = esc + "04m"
21 | codes["blink"] = esc + "05m"
22 | codes["overline"] = esc + "06m"
23 | 
24 | dark_colors = ["black", "red", "green", "yellow", "blue",
25 |                "magenta", "cyan", "gray"]
26 | light_colors = ["brightblack", "brightred", "brightgreen", "brightyellow", "brightblue",
27 |                 "brightmagenta", "brightcyan", "white"]
28 | 
29 | x = 30
30 | for dark, light in zip(dark_colors, light_colors):
31 |     codes[dark] = esc + "%im" % x
32 |     codes[light] = esc + "%im" % (60 + x)
33 |     x += 1
34 | 
35 | del dark, light, x
36 | 
37 | codes["white"] = codes["bold"]
38 | 
39 | 
40 | def reset_color():
41 |     return codes["reset"]
42 | 
43 | 
44 | def colorize(color_key, text):
45 |     return codes[color_key] + text + codes["reset"]
46 | 
47 | 
48 | def ansiformat(attr, text):
49 |     """
50 |     Format ``text`` with a color and/or some attributes::
51 | 
52 |         color       normal color
53 |         *color*     bold color
54 |         _color_     underlined color
55 |         +color+     blinking color
56 |     """
57 |     result = []
58 |     if attr[:1] == attr[-1:] == '+':
59 |         result.append(codes['blink'])
60 |         attr = attr[1:-1]
61 |     if attr[:1] == attr[-1:] == '*':
62 |         result.append(codes['bold'])
63 |         attr = attr[1:-1]
64 |     if attr[:1] == attr[-1:] == '_':
65 |         result.append(codes['underline'])
66 |         attr = attr[1:-1]
67 |     result.append(codes[attr])
68 |     result.append(text)
69 |     result.append(codes['reset'])
70 |     return ''.join(result)
```

.venv/lib/python3.13/site-packages/pip/_vendor/pygments/filter.py
```
1 | """
2 |     pygments.filter
3 |     ~~~~~~~~~~~~~~~
4 | 
5 |     Module that implements the default filter.
6 | 
7 |     :copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
8 |     :license: BSD, see LICENSE for details.
9 | """
10 | 
11 | 
12 | def apply_filters(stream, filters, lexer=None):
13 |     """
14 |     Use this method to apply an iterable of filters to
15 |     a stream. If lexer is given it's forwarded to the
16 |     filter, otherwise the filter receives `None`.
17 |     """
18 |     def _apply(filter_, stream):
19 |         yield from filter_.filter(lexer, stream)
20 |     for filter_ in filters:
21 |         stream = _apply(filter_, stream)
22 |     return stream
23 | 
24 | 
25 | def simplefilter(f):
26 |     """
27 |     Decorator that converts a function into a filter::
28 | 
29 |         @simplefilter
30 |         def lowercase(self, lexer, stream, options):
31 |             for ttype, value in stream:
32 |                 yield ttype, value.lower()
33 |     """
34 |     return type(f.__name__, (FunctionFilter,), {
35 |         '__module__': getattr(f, '__module__'),
36 |         '__doc__': f.__doc__,
37 |         'function': f,
38 |     })
39 | 
40 | 
41 | class Filter:
42 |     """
43 |     Default filter. Subclass this class or use the `simplefilter`
44 |     decorator to create own filters.
45 |     """
46 | 
47 |     def __init__(self, **options):
48 |         self.options = options
49 | 
50 |     def filter(self, lexer, stream):
51 |         raise NotImplementedError()
52 | 
53 | 
54 | class FunctionFilter(Filter):
55 |     """
56 |     Abstract class used by `simplefilter` to create simple
57 |     function filters on the fly. The `simplefilter` decorator
58 |     automatically creates subclasses of this class for
59 |     functions passed to it.
60 |     """
61 |     function = None
62 | 
63 |     def __init__(self, **options):
64 |         if not hasattr(self, 'function'):
65 |             raise TypeError(f'{self.__class__.__name__!r} used without bound function')
66 |         Filter.__init__(self, **options)
67 | 
68 |     def filter(self, lexer, stream):
69 |         # pylint: disable=not-callable
70 |         yield from self.function(lexer, stream, self.options)
```

.venv/lib/python3.13/site-packages/pip/_vendor/pygments/formatter.py
```
1 | """
2 |     pygments.formatter
3 |     ~~~~~~~~~~~~~~~~~~
4 | 
5 |     Base formatter class.
6 | 
7 |     :copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
8 |     :license: BSD, see LICENSE for details.
9 | """
10 | 
11 | import codecs
12 | 
13 | from pip._vendor.pygments.util import get_bool_opt
14 | from pip._vendor.pygments.styles import get_style_by_name
15 | 
16 | __all__ = ['Formatter']
17 | 
18 | 
19 | def _lookup_style(style):
20 |     if isinstance(style, str):
21 |         return get_style_by_name(style)
22 |     return style
23 | 
24 | 
25 | class Formatter:
26 |     """
27 |     Converts a token stream to text.
28 | 
29 |     Formatters should have attributes to help selecting them. These
30 |     are similar to the corresponding :class:`~pygments.lexer.Lexer`
31 |     attributes.
32 | 
33 |     .. autoattribute:: name
34 |        :no-value:
35 | 
36 |     .. autoattribute:: aliases
37 |        :no-value:
38 | 
39 |     .. autoattribute:: filenames
40 |        :no-value:
41 | 
42 |     You can pass options as keyword arguments to the constructor.
43 |     All formatters accept these basic options:
44 | 
45 |     ``style``
46 |         The style to use, can be a string or a Style subclass
47 |         (default: "default"). Not used by e.g. the
48 |         TerminalFormatter.
49 |     ``full``
50 |         Tells the formatter to output a "full" document, i.e.
51 |         a complete self-contained document. This doesn't have
52 |         any effect for some formatters (default: false).
53 |     ``title``
54 |         If ``full`` is true, the title that should be used to
55 |         caption the document (default: '').
56 |     ``encoding``
57 |         If given, must be an encoding name. This will be used to
58 |         convert the Unicode token strings to byte strings in the
59 |         output. If it is "" or None, Unicode strings will be written
60 |         to the output file, which most file-like objects do not
61 |         support (default: None).
62 |     ``outencoding``
63 |         Overrides ``encoding`` if given.
64 | 
65 |     """
66 | 
67 |     #: Full name for the formatter, in human-readable form.
68 |     name = None
69 | 
70 |     #: A list of short, unique identifiers that can be used to lookup
71 |     #: the formatter from a list, e.g. using :func:`.get_formatter_by_name()`.
72 |     aliases = []
73 | 
74 |     #: A list of fnmatch patterns that match filenames for which this
75 |     #: formatter can produce output. The patterns in this list should be unique
76 |     #: among all formatters.
77 |     filenames = []
78 | 
79 |     #: If True, this formatter outputs Unicode strings when no encoding
80 |     #: option is given.
81 |     unicodeoutput = True
82 | 
83 |     def __init__(self, **options):
84 |         """
85 |         As with lexers, this constructor takes arbitrary optional arguments,
86 |         and if you override it, you should first process your own options, then
87 |         call the base class implementation.
88 |         """
89 |         self.style = _lookup_style(options.get('style', 'default'))
90 |         self.full = get_bool_opt(options, 'full', False)
91 |         self.title = options.get('title', '')
92 |         self.encoding = options.get('encoding', None) or None
93 |         if self.encoding in ('guess', 'chardet'):
94 |             # can happen for e.g. pygmentize -O encoding=guess
95 |             self.encoding = 'utf-8'
96 |         self.encoding = options.get('outencoding') or self.encoding
97 |         self.options = options
98 | 
99 |     def get_style_defs(self, arg=''):
100 |         """
101 |         This method must return statements or declarations suitable to define
102 |         the current style for subsequent highlighted text (e.g. CSS classes
103 |         in the `HTMLFormatter`).
104 | 
105 |         The optional argument `arg` can be used to modify the generation and
106 |         is formatter dependent (it is standardized because it can be given on
107 |         the command line).
108 | 
109 |         This method is called by the ``-S`` :doc:`command-line option <cmdline>`,
110 |         the `arg` is then given by the ``-a`` option.
111 |         """
112 |         return ''
113 | 
114 |     def format(self, tokensource, outfile):
115 |         """
116 |         This method must format the tokens from the `tokensource` iterable and
117 |         write the formatted version to the file object `outfile`.
118 | 
119 |         Formatter options can control how exactly the tokens are converted.
120 |         """
121 |         if self.encoding:
122 |             # wrap the outfile in a StreamWriter
123 |             outfile = codecs.lookup(self.encoding)[3](outfile)
124 |         return self.format_unencoded(tokensource, outfile)
125 | 
126 |     # Allow writing Formatter[str] or Formatter[bytes]. That's equivalent to
127 |     # Formatter. This helps when using third-party type stubs from typeshed.
128 |     def __class_getitem__(cls, name):
129 |         return cls
```

.venv/lib/python3.13/site-packages/pip/_vendor/pygments/lexer.py
```
1 | """
2 |     pygments.lexer
3 |     ~~~~~~~~~~~~~~
4 | 
5 |     Base lexer classes.
6 | 
7 |     :copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
8 |     :license: BSD, see LICENSE for details.
9 | """
10 | 
11 | import re
12 | import sys
13 | import time
14 | 
15 | from pip._vendor.pygments.filter import apply_filters, Filter
16 | from pip._vendor.pygments.filters import get_filter_by_name
17 | from pip._vendor.pygments.token import Error, Text, Other, Whitespace, _TokenType
18 | from pip._vendor.pygments.util import get_bool_opt, get_int_opt, get_list_opt, \
19 |     make_analysator, Future, guess_decode
20 | from pip._vendor.pygments.regexopt import regex_opt
21 | 
22 | __all__ = ['Lexer', 'RegexLexer', 'ExtendedRegexLexer', 'DelegatingLexer',
23 |            'LexerContext', 'include', 'inherit', 'bygroups', 'using', 'this',
24 |            'default', 'words', 'line_re']
25 | 
26 | line_re = re.compile('.*?\n')
27 | 
28 | _encoding_map = [(b'\xef\xbb\xbf', 'utf-8'),
29 |                  (b'\xff\xfe\0\0', 'utf-32'),
30 |                  (b'\0\0\xfe\xff', 'utf-32be'),
31 |                  (b'\xff\xfe', 'utf-16'),
32 |                  (b'\xfe\xff', 'utf-16be')]
33 | 
34 | _default_analyse = staticmethod(lambda x: 0.0)
35 | 
36 | 
37 | class LexerMeta(type):
38 |     """
39 |     This metaclass automagically converts ``analyse_text`` methods into
40 |     static methods which always return float values.
41 |     """
42 | 
43 |     def __new__(mcs, name, bases, d):
44 |         if 'analyse_text' in d:
45 |             d['analyse_text'] = make_analysator(d['analyse_text'])
46 |         return type.__new__(mcs, name, bases, d)
47 | 
48 | 
49 | class Lexer(metaclass=LexerMeta):
50 |     """
51 |     Lexer for a specific language.
52 | 
53 |     See also :doc:`lexerdevelopment`, a high-level guide to writing
54 |     lexers.
55 | 
56 |     Lexer classes have attributes used for choosing the most appropriate
57 |     lexer based on various criteria.
58 | 
59 |     .. autoattribute:: name
60 |        :no-value:
61 |     .. autoattribute:: aliases
62 |        :no-value:
63 |     .. autoattribute:: filenames
64 |        :no-value:
65 |     .. autoattribute:: alias_filenames
66 |     .. autoattribute:: mimetypes
67 |        :no-value:
68 |     .. autoattribute:: priority
69 | 
70 |     Lexers included in Pygments should have two additional attributes:
71 | 
72 |     .. autoattribute:: url
73 |        :no-value:
74 |     .. autoattribute:: version_added
75 |        :no-value:
76 | 
77 |     Lexers included in Pygments may have additional attributes:
78 | 
79 |     .. autoattribute:: _example
80 |        :no-value:
81 | 
82 |     You can pass options to the constructor. The basic options recognized
83 |     by all lexers and processed by the base `Lexer` class are:
84 | 
85 |     ``stripnl``
86 |         Strip leading and trailing newlines from the input (default: True).
87 |     ``stripall``
88 |         Strip all leading and trailing whitespace from the input
89 |         (default: False).
90 |     ``ensurenl``
91 |         Make sure that the input ends with a newline (default: True).  This
92 |         is required for some lexers that consume input linewise.
93 | 
94 |         .. versionadded:: 1.3
95 | 
96 |     ``tabsize``
97 |         If given and greater than 0, expand tabs in the input (default: 0).
98 |     ``encoding``
99 |         If given, must be an encoding name. This encoding will be used to
100 |         convert the input string to Unicode, if it is not already a Unicode
101 |         string (default: ``'guess'``, which uses a simple UTF-8 / Locale /
102 |         Latin1 detection.  Can also be ``'chardet'`` to use the chardet
103 |         library, if it is installed.
104 |     ``inencoding``
105 |         Overrides the ``encoding`` if given.
106 |     """
107 | 
108 |     #: Full name of the lexer, in human-readable form
109 |     name = None
110 | 
111 |     #: A list of short, unique identifiers that can be used to look
112 |     #: up the lexer from a list, e.g., using `get_lexer_by_name()`.
113 |     aliases = []
114 | 
115 |     #: A list of `fnmatch` patterns that match filenames which contain
116 |     #: content for this lexer. The patterns in this list should be unique among
117 |     #: all lexers.
118 |     filenames = []
119 | 
120 |     #: A list of `fnmatch` patterns that match filenames which may or may not
121 |     #: contain content for this lexer. This list is used by the
122 |     #: :func:`.guess_lexer_for_filename()` function, to determine which lexers
123 |     #: are then included in guessing the correct one. That means that
124 |     #: e.g. every lexer for HTML and a template language should include
125 |     #: ``\*.html`` in this list.
126 |     alias_filenames = []
127 | 
128 |     #: A list of MIME types for content that can be lexed with this lexer.
129 |     mimetypes = []
130 | 
131 |     #: Priority, should multiple lexers match and no content is provided
132 |     priority = 0
133 | 
134 |     #: URL of the language specification/definition. Used in the Pygments
135 |     #: documentation. Set to an empty string to disable.
136 |     url = None
137 | 
138 |     #: Version of Pygments in which the lexer was added.
139 |     version_added = None
140 | 
141 |     #: Example file name. Relative to the ``tests/examplefiles`` directory.
142 |     #: This is used by the documentation generator to show an example.
143 |     _example = None
144 | 
145 |     def __init__(self, **options):
146 |         """
147 |         This constructor takes arbitrary options as keyword arguments.
148 |         Every subclass must first process its own options and then call
149 |         the `Lexer` constructor, since it processes the basic
150 |         options like `stripnl`.
151 | 
152 |         An example looks like this:
153 | 
154 |         .. sourcecode:: python
155 | 
156 |            def __init__(self, **options):
157 |                self.compress = options.get('compress', '')
158 |                Lexer.__init__(self, **options)
159 | 
160 |         As these options must all be specifiable as strings (due to the
161 |         command line usage), there are various utility functions
162 |         available to help with that, see `Utilities`_.
163 |         """
164 |         self.options = options
165 |         self.stripnl = get_bool_opt(options, 'stripnl', True)
166 |         self.stripall = get_bool_opt(options, 'stripall', False)
167 |         self.ensurenl = get_bool_opt(options, 'ensurenl', True)
168 |         self.tabsize = get_int_opt(options, 'tabsize', 0)
169 |         self.encoding = options.get('encoding', 'guess')
170 |         self.encoding = options.get('inencoding') or self.encoding
171 |         self.filters = []
172 |         for filter_ in get_list_opt(options, 'filters', ()):
173 |             self.add_filter(filter_)
174 | 
175 |     def __repr__(self):
176 |         if self.options:
177 |             return f'<pygments.lexers.{self.__class__.__name__} with {self.options!r}>'
178 |         else:
179 |             return f'<pygments.lexers.{self.__class__.__name__}>'
180 | 
181 |     def add_filter(self, filter_, **options):
182 |         """
183 |         Add a new stream filter to this lexer.
184 |         """
185 |         if not isinstance(filter_, Filter):
186 |             filter_ = get_filter_by_name(filter_, **options)
187 |         self.filters.append(filter_)
188 | 
189 |     def analyse_text(text):
190 |         """
191 |         A static method which is called for lexer guessing.
192 | 
193 |         It should analyse the text and return a float in the range
194 |         from ``0.0`` to ``1.0``.  If it returns ``0.0``, the lexer
195 |         will not be selected as the most probable one, if it returns
196 |         ``1.0``, it will be selected immediately.  This is used by
197 |         `guess_lexer`.
198 | 
199 |         The `LexerMeta` metaclass automatically wraps this function so
200 |         that it works like a static method (no ``self`` or ``cls``
201 |         parameter) and the return value is automatically converted to
202 |         `float`. If the return value is an object that is boolean `False`
203 |         it's the same as if the return values was ``0.0``.
204 |         """
205 | 
206 |     def _preprocess_lexer_input(self, text):
207 |         """Apply preprocessing such as decoding the input, removing BOM and normalizing newlines."""
208 | 
209 |         if not isinstance(text, str):
210 |             if self.encoding == 'guess':
211 |                 text, _ = guess_decode(text)
212 |             elif self.encoding == 'chardet':
213 |                 try:
214 |                     # pip vendoring note: this code is not reachable by pip,
215 |                     # removed import of chardet to make it clear.
216 |                     raise ImportError('chardet is not vendored by pip')
217 |                 except ImportError as e:
218 |                     raise ImportError('To enable chardet encoding guessing, '
219 |                                       'please install the chardet library '
220 |                                       'from http://chardet.feedparser.org/') from e
221 |                 # check for BOM first
222 |                 decoded = None
223 |                 for bom, encoding in _encoding_map:
224 |                     if text.startswith(bom):
225 |                         decoded = text[len(bom):].decode(encoding, 'replace')
226 |                         break
227 |                 # no BOM found, so use chardet
228 |                 if decoded is None:
229 |                     enc = chardet.detect(text[:1024])  # Guess using first 1KB
230 |                     decoded = text.decode(enc.get('encoding') or 'utf-8',
231 |                                           'replace')
232 |                 text = decoded
233 |             else:
234 |                 text = text.decode(self.encoding)
235 |                 if text.startswith('\ufeff'):
236 |                     text = text[len('\ufeff'):]
237 |         else:
238 |             if text.startswith('\ufeff'):
239 |                 text = text[len('\ufeff'):]
240 | 
241 |         # text now *is* a unicode string
242 |         text = text.replace('\r\n', '\n')
243 |         text = text.replace('\r', '\n')
244 |         if self.stripall:
245 |             text = text.strip()
246 |         elif self.stripnl:
247 |             text = text.strip('\n')
248 |         if self.tabsize > 0:
249 |             text = text.expandtabs(self.tabsize)
250 |         if self.ensurenl and not text.endswith('\n'):
251 |             text += '\n'
252 | 
253 |         return text
254 | 
255 |     def get_tokens(self, text, unfiltered=False):
256 |         """
257 |         This method is the basic interface of a lexer. It is called by
258 |         the `highlight()` function. It must process the text and return an
259 |         iterable of ``(tokentype, value)`` pairs from `text`.
260 | 
261 |         Normally, you don't need to override this method. The default
262 |         implementation processes the options recognized by all lexers
263 |         (`stripnl`, `stripall` and so on), and then yields all tokens
264 |         from `get_tokens_unprocessed()`, with the ``index`` dropped.
265 | 
266 |         If `unfiltered` is set to `True`, the filtering mechanism is
267 |         bypassed even if filters are defined.
268 |         """
269 |         text = self._preprocess_lexer_input(text)
270 | 
271 |         def streamer():
272 |             for _, t, v in self.get_tokens_unprocessed(text):
273 |                 yield t, v
274 |         stream = streamer()
275 |         if not unfiltered:
276 |             stream = apply_filters(stream, self.filters, self)
277 |         return stream
278 | 
279 |     def get_tokens_unprocessed(self, text):
280 |         """
281 |         This method should process the text and return an iterable of
282 |         ``(index, tokentype, value)`` tuples where ``index`` is the starting
283 |         position of the token within the input text.
284 | 
285 |         It must be overridden by subclasses. It is recommended to
286 |         implement it as a generator to maximize effectiveness.
287 |         """
288 |         raise NotImplementedError
289 | 
290 | 
291 | class DelegatingLexer(Lexer):
292 |     """
293 |     This lexer takes two lexer as arguments. A root lexer and
294 |     a language lexer. First everything is scanned using the language
295 |     lexer, afterwards all ``Other`` tokens are lexed using the root
296 |     lexer.
297 | 
298 |     The lexers from the ``template`` lexer package use this base lexer.
299 |     """
300 | 
301 |     def __init__(self, _root_lexer, _language_lexer, _needle=Other, **options):
302 |         self.root_lexer = _root_lexer(**options)
303 |         self.language_lexer = _language_lexer(**options)
304 |         self.needle = _needle
305 |         Lexer.__init__(self, **options)
306 | 
307 |     def get_tokens_unprocessed(self, text):
308 |         buffered = ''
309 |         insertions = []
310 |         lng_buffer = []
311 |         for i, t, v in self.language_lexer.get_tokens_unprocessed(text):
312 |             if t is self.needle:
313 |                 if lng_buffer:
314 |                     insertions.append((len(buffered), lng_buffer))
315 |                     lng_buffer = []
316 |                 buffered += v
317 |             else:
318 |                 lng_buffer.append((i, t, v))
319 |         if lng_buffer:
320 |             insertions.append((len(buffered), lng_buffer))
321 |         return do_insertions(insertions,
322 |                              self.root_lexer.get_tokens_unprocessed(buffered))
323 | 
324 | 
325 | # ------------------------------------------------------------------------------
326 | # RegexLexer and ExtendedRegexLexer
327 | #
328 | 
329 | 
330 | class include(str):  # pylint: disable=invalid-name
331 |     """
332 |     Indicates that a state should include rules from another state.
333 |     """
334 |     pass
335 | 
336 | 
337 | class _inherit:
338 |     """
[TRUNCATED]
```

.venv/lib/python3.13/site-packages/pip/_vendor/pygments/modeline.py
```
1 | """
2 |     pygments.modeline
3 |     ~~~~~~~~~~~~~~~~~
4 | 
5 |     A simple modeline parser (based on pymodeline).
6 | 
7 |     :copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
8 |     :license: BSD, see LICENSE for details.
9 | """
10 | 
11 | import re
12 | 
13 | __all__ = ['get_filetype_from_buffer']
14 | 
15 | 
16 | modeline_re = re.compile(r'''
17 |     (?: vi | vim | ex ) (?: [<=>]? \d* )? :
18 |     .* (?: ft | filetype | syn | syntax ) = ( [^:\s]+ )
19 | ''', re.VERBOSE)
20 | 
21 | 
22 | def get_filetype_from_line(l): # noqa: E741
23 |     m = modeline_re.search(l)
24 |     if m:
25 |         return m.group(1)
26 | 
27 | 
28 | def get_filetype_from_buffer(buf, max_lines=5):
29 |     """
30 |     Scan the buffer for modelines and return filetype if one is found.
31 |     """
32 |     lines = buf.splitlines()
33 |     for line in lines[-1:-max_lines-1:-1]:
34 |         ret = get_filetype_from_line(line)
35 |         if ret:
36 |             return ret
37 |     for i in range(max_lines, -1, -1):
38 |         if i < len(lines):
39 |             ret = get_filetype_from_line(lines[i])
40 |             if ret:
41 |                 return ret
42 | 
43 |     return None
```

.venv/lib/python3.13/site-packages/pip/_vendor/pygments/plugin.py
```
1 | """
2 |     pygments.plugin
3 |     ~~~~~~~~~~~~~~~
4 | 
5 |     Pygments plugin interface.
6 | 
7 |     lexer plugins::
8 | 
9 |         [pygments.lexers]
10 |         yourlexer = yourmodule:YourLexer
11 | 
12 |     formatter plugins::
13 | 
14 |         [pygments.formatters]
15 |         yourformatter = yourformatter:YourFormatter
16 |         /.ext = yourformatter:YourFormatter
17 | 
18 |     As you can see, you can define extensions for the formatter
19 |     with a leading slash.
20 | 
21 |     syntax plugins::
22 | 
23 |         [pygments.styles]
24 |         yourstyle = yourstyle:YourStyle
25 | 
26 |     filter plugin::
27 | 
28 |         [pygments.filter]
29 |         yourfilter = yourfilter:YourFilter
30 | 
31 | 
32 |     :copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
33 |     :license: BSD, see LICENSE for details.
34 | """
35 | from importlib.metadata import entry_points
36 | 
37 | LEXER_ENTRY_POINT = 'pygments.lexers'
38 | FORMATTER_ENTRY_POINT = 'pygments.formatters'
39 | STYLE_ENTRY_POINT = 'pygments.styles'
40 | FILTER_ENTRY_POINT = 'pygments.filters'
41 | 
42 | 
43 | def iter_entry_points(group_name):
44 |     groups = entry_points()
45 |     if hasattr(groups, 'select'):
46 |         # New interface in Python 3.10 and newer versions of the
47 |         # importlib_metadata backport.
48 |         return groups.select(group=group_name)
49 |     else:
50 |         # Older interface, deprecated in Python 3.10 and recent
51 |         # importlib_metadata, but we need it in Python 3.8 and 3.9.
52 |         return groups.get(group_name, [])
53 | 
54 | 
55 | def find_plugin_lexers():
56 |     for entrypoint in iter_entry_points(LEXER_ENTRY_POINT):
57 |         yield entrypoint.load()
58 | 
59 | 
60 | def find_plugin_formatters():
61 |     for entrypoint in iter_entry_points(FORMATTER_ENTRY_POINT):
62 |         yield entrypoint.name, entrypoint.load()
63 | 
64 | 
65 | def find_plugin_styles():
66 |     for entrypoint in iter_entry_points(STYLE_ENTRY_POINT):
67 |         yield entrypoint.name, entrypoint.load()
68 | 
69 | 
70 | def find_plugin_filters():
71 |     for entrypoint in iter_entry_points(FILTER_ENTRY_POINT):
72 |         yield entrypoint.name, entrypoint.load()
```

.venv/lib/python3.13/site-packages/pip/_vendor/pygments/regexopt.py
```
1 | """
2 |     pygments.regexopt
3 |     ~~~~~~~~~~~~~~~~~
4 | 
5 |     An algorithm that generates optimized regexes for matching long lists of
6 |     literal strings.
7 | 
8 |     :copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
9 |     :license: BSD, see LICENSE for details.
10 | """
11 | 
12 | import re
13 | from re import escape
14 | from os.path import commonprefix
15 | from itertools import groupby
16 | from operator import itemgetter
17 | 
18 | CS_ESCAPE = re.compile(r'[\[\^\\\-\]]')
19 | FIRST_ELEMENT = itemgetter(0)
20 | 
21 | 
22 | def make_charset(letters):
23 |     return '[' + CS_ESCAPE.sub(lambda m: '\\' + m.group(), ''.join(letters)) + ']'
24 | 
25 | 
26 | def regex_opt_inner(strings, open_paren):
27 |     """Return a regex that matches any string in the sorted list of strings."""
28 |     close_paren = open_paren and ')' or ''
29 |     # print strings, repr(open_paren)
30 |     if not strings:
31 |         # print '-> nothing left'
32 |         return ''
33 |     first = strings[0]
34 |     if len(strings) == 1:
35 |         # print '-> only 1 string'
36 |         return open_paren + escape(first) + close_paren
37 |     if not first:
38 |         # print '-> first string empty'
39 |         return open_paren + regex_opt_inner(strings[1:], '(?:') \
40 |             + '?' + close_paren
41 |     if len(first) == 1:
42 |         # multiple one-char strings? make a charset
43 |         oneletter = []
44 |         rest = []
45 |         for s in strings:
46 |             if len(s) == 1:
47 |                 oneletter.append(s)
48 |             else:
49 |                 rest.append(s)
50 |         if len(oneletter) > 1:  # do we have more than one oneletter string?
51 |             if rest:
52 |                 # print '-> 1-character + rest'
53 |                 return open_paren + regex_opt_inner(rest, '') + '|' \
54 |                     + make_charset(oneletter) + close_paren
55 |             # print '-> only 1-character'
56 |             return open_paren + make_charset(oneletter) + close_paren
57 |     prefix = commonprefix(strings)
58 |     if prefix:
59 |         plen = len(prefix)
60 |         # we have a prefix for all strings
61 |         # print '-> prefix:', prefix
62 |         return open_paren + escape(prefix) \
63 |             + regex_opt_inner([s[plen:] for s in strings], '(?:') \
64 |             + close_paren
65 |     # is there a suffix?
66 |     strings_rev = [s[::-1] for s in strings]
67 |     suffix = commonprefix(strings_rev)
68 |     if suffix:
69 |         slen = len(suffix)
70 |         # print '-> suffix:', suffix[::-1]
71 |         return open_paren \
72 |             + regex_opt_inner(sorted(s[:-slen] for s in strings), '(?:') \
73 |             + escape(suffix[::-1]) + close_paren
74 |     # recurse on common 1-string prefixes
75 |     # print '-> last resort'
76 |     return open_paren + \
77 |         '|'.join(regex_opt_inner(list(group[1]), '')
78 |                  for group in groupby(strings, lambda s: s[0] == first[0])) \
79 |         + close_paren
80 | 
81 | 
82 | def regex_opt(strings, prefix='', suffix=''):
83 |     """Return a compiled regex that matches any string in the given list.
84 | 
85 |     The strings to match must be literal strings, not regexes.  They will be
86 |     regex-escaped.
87 | 
88 |     *prefix* and *suffix* are pre- and appended to the final regex.
89 |     """
90 |     strings = sorted(strings)
91 |     return prefix + regex_opt_inner(strings, '(') + suffix
```

.venv/lib/python3.13/site-packages/pip/_vendor/pygments/scanner.py
```
1 | """
2 |     pygments.scanner
3 |     ~~~~~~~~~~~~~~~~
4 | 
5 |     This library implements a regex based scanner. Some languages
6 |     like Pascal are easy to parse but have some keywords that
7 |     depend on the context. Because of this it's impossible to lex
8 |     that just by using a regular expression lexer like the
9 |     `RegexLexer`.
10 | 
11 |     Have a look at the `DelphiLexer` to get an idea of how to use
12 |     this scanner.
13 | 
14 |     :copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
15 |     :license: BSD, see LICENSE for details.
16 | """
17 | import re
18 | 
19 | 
20 | class EndOfText(RuntimeError):
21 |     """
22 |     Raise if end of text is reached and the user
23 |     tried to call a match function.
24 |     """
25 | 
26 | 
27 | class Scanner:
28 |     """
29 |     Simple scanner
30 | 
31 |     All method patterns are regular expression strings (not
32 |     compiled expressions!)
33 |     """
34 | 
35 |     def __init__(self, text, flags=0):
36 |         """
37 |         :param text:    The text which should be scanned
38 |         :param flags:   default regular expression flags
39 |         """
40 |         self.data = text
41 |         self.data_length = len(text)
42 |         self.start_pos = 0
43 |         self.pos = 0
44 |         self.flags = flags
45 |         self.last = None
46 |         self.match = None
47 |         self._re_cache = {}
48 | 
49 |     def eos(self):
50 |         """`True` if the scanner reached the end of text."""
51 |         return self.pos >= self.data_length
52 |     eos = property(eos, eos.__doc__)
53 | 
54 |     def check(self, pattern):
55 |         """
56 |         Apply `pattern` on the current position and return
57 |         the match object. (Doesn't touch pos). Use this for
58 |         lookahead.
59 |         """
60 |         if self.eos:
61 |             raise EndOfText()
62 |         if pattern not in self._re_cache:
63 |             self._re_cache[pattern] = re.compile(pattern, self.flags)
64 |         return self._re_cache[pattern].match(self.data, self.pos)
65 | 
66 |     def test(self, pattern):
67 |         """Apply a pattern on the current position and check
68 |         if it patches. Doesn't touch pos.
69 |         """
70 |         return self.check(pattern) is not None
71 | 
72 |     def scan(self, pattern):
73 |         """
74 |         Scan the text for the given pattern and update pos/match
75 |         and related fields. The return value is a boolean that
76 |         indicates if the pattern matched. The matched value is
77 |         stored on the instance as ``match``, the last value is
78 |         stored as ``last``. ``start_pos`` is the position of the
79 |         pointer before the pattern was matched, ``pos`` is the
80 |         end position.
81 |         """
82 |         if self.eos:
83 |             raise EndOfText()
84 |         if pattern not in self._re_cache:
85 |             self._re_cache[pattern] = re.compile(pattern, self.flags)
86 |         self.last = self.match
87 |         m = self._re_cache[pattern].match(self.data, self.pos)
88 |         if m is None:
89 |             return False
90 |         self.start_pos = m.start()
91 |         self.pos = m.end()
92 |         self.match = m.group()
93 |         return True
94 | 
95 |     def get_char(self):
96 |         """Scan exactly one char."""
97 |         self.scan('.')
98 | 
99 |     def __repr__(self):
100 |         return '<%s %d/%d>' % (
101 |             self.__class__.__name__,
102 |             self.pos,
103 |             self.data_length
104 |         )
```

.venv/lib/python3.13/site-packages/pip/_vendor/pygments/sphinxext.py
```
1 | """
2 |     pygments.sphinxext
3 |     ~~~~~~~~~~~~~~~~~~
4 | 
5 |     Sphinx extension to generate automatic documentation of lexers,
6 |     formatters and filters.
7 | 
8 |     :copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
9 |     :license: BSD, see LICENSE for details.
10 | """
11 | 
12 | import sys
13 | 
14 | from docutils import nodes
15 | from docutils.statemachine import ViewList
16 | from docutils.parsers.rst import Directive
17 | from sphinx.util.nodes import nested_parse_with_titles
18 | 
19 | 
20 | MODULEDOC = '''
21 | .. module:: %s
22 | 
23 | %s
24 | %s
25 | '''
26 | 
27 | LEXERDOC = '''
28 | .. class:: %s
29 | 
30 |     :Short names: %s
31 |     :Filenames:   %s
32 |     :MIME types:  %s
33 | 
34 |     %s
35 | 
36 |     %s
37 | 
38 | '''
39 | 
40 | FMTERDOC = '''
41 | .. class:: %s
42 | 
43 |     :Short names: %s
44 |     :Filenames: %s
45 | 
46 |     %s
47 | 
48 | '''
49 | 
50 | FILTERDOC = '''
51 | .. class:: %s
52 | 
53 |     :Name: %s
54 | 
55 |     %s
56 | 
57 | '''
58 | 
59 | 
60 | class PygmentsDoc(Directive):
61 |     """
62 |     A directive to collect all lexers/formatters/filters and generate
63 |     autoclass directives for them.
64 |     """
65 |     has_content = False
66 |     required_arguments = 1
67 |     optional_arguments = 0
68 |     final_argument_whitespace = False
69 |     option_spec = {}
70 | 
71 |     def run(self):
72 |         self.filenames = set()
73 |         if self.arguments[0] == 'lexers':
74 |             out = self.document_lexers()
75 |         elif self.arguments[0] == 'formatters':
76 |             out = self.document_formatters()
77 |         elif self.arguments[0] == 'filters':
78 |             out = self.document_filters()
79 |         elif self.arguments[0] == 'lexers_overview':
80 |             out = self.document_lexers_overview()
81 |         else:
82 |             raise Exception('invalid argument for "pygmentsdoc" directive')
83 |         node = nodes.compound()
84 |         vl = ViewList(out.split('\n'), source='')
85 |         nested_parse_with_titles(self.state, vl, node)
86 |         for fn in self.filenames:
87 |             self.state.document.settings.record_dependencies.add(fn)
88 |         return node.children
89 | 
90 |     def document_lexers_overview(self):
91 |         """Generate a tabular overview of all lexers.
92 | 
93 |         The columns are the lexer name, the extensions handled by this lexer
94 |         (or "None"), the aliases and a link to the lexer class."""
95 |         from pip._vendor.pygments.lexers._mapping import LEXERS
96 |         from pip._vendor.pygments.lexers import find_lexer_class
97 |         out = []
98 | 
99 |         table = []
100 | 
101 |         def format_link(name, url):
102 |             if url:
103 |                 return f'`{name} <{url}>`_'
104 |             return name
105 | 
106 |         for classname, data in sorted(LEXERS.items(), key=lambda x: x[1][1].lower()):
107 |             lexer_cls = find_lexer_class(data[1])
108 |             extensions = lexer_cls.filenames + lexer_cls.alias_filenames
109 | 
110 |             table.append({
111 |                 'name': format_link(data[1], lexer_cls.url),
112 |                 'extensions': ', '.join(extensions).replace('*', '\\*').replace('_', '\\') or 'None',
113 |                 'aliases': ', '.join(data[2]),
114 |                 'class': f'{data[0]}.{classname}'
115 |             })
116 | 
117 |         column_names = ['name', 'extensions', 'aliases', 'class']
118 |         column_lengths = [max([len(row[column]) for row in table if row[column]])
119 |                           for column in column_names]
120 | 
121 |         def write_row(*columns):
122 |             """Format a table row"""
123 |             out = []
124 |             for length, col in zip(column_lengths, columns):
125 |                 if col:
126 |                     out.append(col.ljust(length))
127 |                 else:
128 |                     out.append(' '*length)
129 | 
130 |             return ' '.join(out)
131 | 
132 |         def write_seperator():
133 |             """Write a table separator row"""
134 |             sep = ['='*c for c in column_lengths]
135 |             return write_row(*sep)
136 | 
137 |         out.append(write_seperator())
138 |         out.append(write_row('Name', 'Extension(s)', 'Short name(s)', 'Lexer class'))
139 |         out.append(write_seperator())
140 |         for row in table:
141 |             out.append(write_row(
142 |                 row['name'],
143 |                 row['extensions'],
144 |                 row['aliases'],
145 |                 f':class:`~{row["class"]}`'))
146 |         out.append(write_seperator())
147 | 
148 |         return '\n'.join(out)
149 | 
150 |     def document_lexers(self):
151 |         from pip._vendor.pygments.lexers._mapping import LEXERS
152 |         from pip._vendor import pygments
153 |         import inspect
154 |         import pathlib
155 | 
156 |         out = []
157 |         modules = {}
158 |         moduledocstrings = {}
159 |         for classname, data in sorted(LEXERS.items(), key=lambda x: x[0]):
160 |             module = data[0]
161 |             mod = __import__(module, None, None, [classname])
162 |             self.filenames.add(mod.__file__)
163 |             cls = getattr(mod, classname)
164 |             if not cls.__doc__:
165 |                 print(f"Warning: {classname} does not have a docstring.")
166 |             docstring = cls.__doc__
167 |             if isinstance(docstring, bytes):
168 |                 docstring = docstring.decode('utf8')
169 | 
170 |             example_file = getattr(cls, '_example', None)
171 |             if example_file:
172 |                 p = pathlib.Path(inspect.getabsfile(pygments)).parent.parent /\
173 |                     'tests' / 'examplefiles' / example_file
174 |                 content = p.read_text(encoding='utf-8')
175 |                 if not content:
176 |                     raise Exception(
177 |                         f"Empty example file '{example_file}' for lexer "
178 |                         f"{classname}")
179 | 
180 |                 if data[2]:
181 |                     lexer_name = data[2][0]
182 |                     docstring += '\n\n    .. admonition:: Example\n'
183 |                     docstring += f'\n      .. code-block:: {lexer_name}\n\n'
184 |                     for line in content.splitlines():
185 |                         docstring += f'          {line}\n'
186 | 
187 |             if cls.version_added:
188 |                 version_line = f'.. versionadded:: {cls.version_added}'
189 |             else:
190 |                 version_line = ''
191 | 
192 |             modules.setdefault(module, []).append((
193 |                 classname,
194 |                 ', '.join(data[2]) or 'None',
195 |                 ', '.join(data[3]).replace('*', '\\*').replace('_', '\\') or 'None',
196 |                 ', '.join(data[4]) or 'None',
197 |                 docstring,
198 |                 version_line))
199 |             if module not in moduledocstrings:
200 |                 moddoc = mod.__doc__
201 |                 if isinstance(moddoc, bytes):
202 |                     moddoc = moddoc.decode('utf8')
203 |                 moduledocstrings[module] = moddoc
204 | 
205 |         for module, lexers in sorted(modules.items(), key=lambda x: x[0]):
206 |             if moduledocstrings[module] is None:
207 |                 raise Exception(f"Missing docstring for {module}")
208 |             heading = moduledocstrings[module].splitlines()[4].strip().rstrip('.')
209 |             out.append(MODULEDOC % (module, heading, '-'*len(heading)))
210 |             for data in lexers:
211 |                 out.append(LEXERDOC % data)
212 | 
213 |         return ''.join(out)
214 | 
215 |     def document_formatters(self):
216 |         from pip._vendor.pygments.formatters import FORMATTERS
217 | 
218 |         out = []
219 |         for classname, data in sorted(FORMATTERS.items(), key=lambda x: x[0]):
220 |             module = data[0]
221 |             mod = __import__(module, None, None, [classname])
222 |             self.filenames.add(mod.__file__)
223 |             cls = getattr(mod, classname)
224 |             docstring = cls.__doc__
225 |             if isinstance(docstring, bytes):
226 |                 docstring = docstring.decode('utf8')
227 |             heading = cls.__name__
228 |             out.append(FMTERDOC % (heading, ', '.join(data[2]) or 'None',
229 |                                    ', '.join(data[3]).replace('*', '\\*') or 'None',
230 |                                    docstring))
231 |         return ''.join(out)
232 | 
233 |     def document_filters(self):
234 |         from pip._vendor.pygments.filters import FILTERS
235 | 
236 |         out = []
237 |         for name, cls in FILTERS.items():
238 |             self.filenames.add(sys.modules[cls.__module__].__file__)
239 |             docstring = cls.__doc__
240 |             if isinstance(docstring, bytes):
241 |                 docstring = docstring.decode('utf8')
242 |             out.append(FILTERDOC % (cls.__name__, name, docstring))
243 |         return ''.join(out)
244 | 
245 | 
246 | def setup(app):
247 |     app.add_directive('pygmentsdoc', PygmentsDoc)
```

.venv/lib/python3.13/site-packages/pip/_vendor/pygments/style.py
```
1 | """
2 |     pygments.style
3 |     ~~~~~~~~~~~~~~
4 | 
5 |     Basic style object.
6 | 
7 |     :copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
8 |     :license: BSD, see LICENSE for details.
9 | """
10 | 
11 | from pip._vendor.pygments.token import Token, STANDARD_TYPES
12 | 
13 | # Default mapping of ansixxx to RGB colors.
14 | _ansimap = {
15 |     # dark
16 |     'ansiblack': '000000',
17 |     'ansired': '7f0000',
18 |     'ansigreen': '007f00',
19 |     'ansiyellow': '7f7fe0',
20 |     'ansiblue': '00007f',
21 |     'ansimagenta': '7f007f',
22 |     'ansicyan': '007f7f',
23 |     'ansigray': 'e5e5e5',
24 |     # normal
25 |     'ansibrightblack': '555555',
26 |     'ansibrightred': 'ff0000',
27 |     'ansibrightgreen': '00ff00',
28 |     'ansibrightyellow': 'ffff00',
29 |     'ansibrightblue': '0000ff',
30 |     'ansibrightmagenta': 'ff00ff',
31 |     'ansibrightcyan': '00ffff',
32 |     'ansiwhite': 'ffffff',
33 | }
34 | # mapping of deprecated #ansixxx colors to new color names
35 | _deprecated_ansicolors = {
36 |     # dark
37 |     '#ansiblack': 'ansiblack',
38 |     '#ansidarkred': 'ansired',
39 |     '#ansidarkgreen': 'ansigreen',
40 |     '#ansibrown': 'ansiyellow',
41 |     '#ansidarkblue': 'ansiblue',
42 |     '#ansipurple': 'ansimagenta',
43 |     '#ansiteal': 'ansicyan',
44 |     '#ansilightgray': 'ansigray',
45 |     # normal
46 |     '#ansidarkgray': 'ansibrightblack',
47 |     '#ansired': 'ansibrightred',
48 |     '#ansigreen': 'ansibrightgreen',
49 |     '#ansiyellow': 'ansibrightyellow',
50 |     '#ansiblue': 'ansibrightblue',
51 |     '#ansifuchsia': 'ansibrightmagenta',
52 |     '#ansiturquoise': 'ansibrightcyan',
53 |     '#ansiwhite': 'ansiwhite',
54 | }
55 | ansicolors = set(_ansimap)
56 | 
57 | 
58 | class StyleMeta(type):
59 | 
60 |     def __new__(mcs, name, bases, dct):
61 |         obj = type.__new__(mcs, name, bases, dct)
62 |         for token in STANDARD_TYPES:
63 |             if token not in obj.styles:
64 |                 obj.styles[token] = ''
65 | 
66 |         def colorformat(text):
67 |             if text in ansicolors:
68 |                 return text
69 |             if text[0:1] == '#':
70 |                 col = text[1:]
71 |                 if len(col) == 6:
72 |                     return col
73 |                 elif len(col) == 3:
74 |                     return col[0] * 2 + col[1] * 2 + col[2] * 2
75 |             elif text == '':
76 |                 return ''
77 |             elif text.startswith('var') or text.startswith('calc'):
78 |                 return text
79 |             assert False, f"wrong color format {text!r}"
80 | 
81 |         _styles = obj._styles = {}
82 | 
83 |         for ttype in obj.styles:
84 |             for token in ttype.split():
85 |                 if token in _styles:
86 |                     continue
87 |                 ndef = _styles.get(token.parent, None)
88 |                 styledefs = obj.styles.get(token, '').split()
89 |                 if not ndef or token is None:
90 |                     ndef = ['', 0, 0, 0, '', '', 0, 0, 0]
91 |                 elif 'noinherit' in styledefs and token is not Token:
92 |                     ndef = _styles[Token][:]
93 |                 else:
94 |                     ndef = ndef[:]
95 |                 _styles[token] = ndef
96 |                 for styledef in obj.styles.get(token, '').split():
97 |                     if styledef == 'noinherit':
98 |                         pass
99 |                     elif styledef == 'bold':
100 |                         ndef[1] = 1
101 |                     elif styledef == 'nobold':
102 |                         ndef[1] = 0
103 |                     elif styledef == 'italic':
104 |                         ndef[2] = 1
105 |                     elif styledef == 'noitalic':
106 |                         ndef[2] = 0
107 |                     elif styledef == 'underline':
108 |                         ndef[3] = 1
109 |                     elif styledef == 'nounderline':
110 |                         ndef[3] = 0
111 |                     elif styledef[:3] == 'bg:':
112 |                         ndef[4] = colorformat(styledef[3:])
113 |                     elif styledef[:7] == 'border:':
114 |                         ndef[5] = colorformat(styledef[7:])
115 |                     elif styledef == 'roman':
116 |                         ndef[6] = 1
117 |                     elif styledef == 'sans':
118 |                         ndef[7] = 1
119 |                     elif styledef == 'mono':
120 |                         ndef[8] = 1
121 |                     else:
122 |                         ndef[0] = colorformat(styledef)
123 | 
124 |         return obj
125 | 
126 |     def style_for_token(cls, token):
127 |         t = cls._styles[token]
128 |         ansicolor = bgansicolor = None
129 |         color = t[0]
130 |         if color in _deprecated_ansicolors:
131 |             color = _deprecated_ansicolors[color]
132 |         if color in ansicolors:
133 |             ansicolor = color
134 |             color = _ansimap[color]
135 |         bgcolor = t[4]
136 |         if bgcolor in _deprecated_ansicolors:
137 |             bgcolor = _deprecated_ansicolors[bgcolor]
138 |         if bgcolor in ansicolors:
139 |             bgansicolor = bgcolor
140 |             bgcolor = _ansimap[bgcolor]
141 | 
142 |         return {
143 |             'color':        color or None,
144 |             'bold':         bool(t[1]),
145 |             'italic':       bool(t[2]),
146 |             'underline':    bool(t[3]),
147 |             'bgcolor':      bgcolor or None,
148 |             'border':       t[5] or None,
149 |             'roman':        bool(t[6]) or None,
150 |             'sans':         bool(t[7]) or None,
151 |             'mono':         bool(t[8]) or None,
152 |             'ansicolor':    ansicolor,
153 |             'bgansicolor':  bgansicolor,
154 |         }
155 | 
156 |     def list_styles(cls):
157 |         return list(cls)
158 | 
159 |     def styles_token(cls, ttype):
160 |         return ttype in cls._styles
161 | 
162 |     def __iter__(cls):
163 |         for token in cls._styles:
164 |             yield token, cls.style_for_token(token)
165 | 
166 |     def __len__(cls):
167 |         return len(cls._styles)
168 | 
169 | 
170 | class Style(metaclass=StyleMeta):
171 | 
172 |     #: overall background color (``None`` means transparent)
173 |     background_color = '#ffffff'
174 | 
175 |     #: highlight background color
176 |     highlight_color = '#ffffcc'
177 | 
178 |     #: line number font color
179 |     line_number_color = 'inherit'
180 | 
181 |     #: line number background color
182 |     line_number_background_color = 'transparent'
183 | 
184 |     #: special line number font color
185 |     line_number_special_color = '#000000'
186 | 
187 |     #: special line number background color
188 |     line_number_special_background_color = '#ffffc0'
189 | 
190 |     #: Style definitions for individual token types.
191 |     styles = {}
192 | 
193 |     #: user-friendly style name (used when selecting the style, so this
194 |     # should be all-lowercase, no spaces, hyphens)
195 |     name = 'unnamed'
196 | 
197 |     aliases = []
198 | 
199 |     # Attribute for lexers defined within Pygments. If set
200 |     # to True, the style is not shown in the style gallery
201 |     # on the website. This is intended for language-specific
202 |     # styles.
203 |     web_style_gallery_exclude = False
```

.venv/lib/python3.13/site-packages/pip/_vendor/pygments/unistring.py
```
1 | """
2 |     pygments.unistring
3 |     ~~~~~~~~~~~~~~~~~~
4 | 
5 |     Strings of all Unicode characters of a certain category.
6 |     Used for matching in Unicode-aware languages. Run to regenerate.
7 | 
8 |     Inspired by chartypes_create.py from the MoinMoin project.
9 | 
10 |     :copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
11 |     :license: BSD, see LICENSE for details.
12 | """
13 | 
14 | Cc = '\x00-\x1f\x7f-\x9f'
15 | 
16 | Cf = '\xad\u0600-\u0605\u061c\u06dd\u070f\u08e2\u180e\u200b-\u200f\u202a-\u202e\u2060-\u2064\u2066-\u206f\ufeff\ufff9-\ufffb\U000110bd\U000110cd\U0001bca0-\U0001bca3\U0001d173-\U0001d17a\U000e0001\U000e0020-\U000e007f'
17 | 
18 | Cn = '\u0378-\u0379\u0380-\u0383\u038b\u038d\u03a2\u0530\u0557-\u0558\u058b-\u058c\u0590\u05c8-\u05cf\u05eb-\u05ee\u05f5-\u05ff\u061d\u070e\u074b-\u074c\u07b2-\u07bf\u07fb-\u07fc\u082e-\u082f\u083f\u085c-\u085d\u085f\u086b-\u089f\u08b5\u08be-\u08d2\u0984\u098d-\u098e\u0991-\u0992\u09a9\u09b1\u09b3-\u09b5\u09ba-\u09bb\u09c5-\u09c6\u09c9-\u09ca\u09cf-\u09d6\u09d8-\u09db\u09de\u09e4-\u09e5\u09ff-\u0a00\u0a04\u0a0b-\u0a0e\u0a11-\u0a12\u0a29\u0a31\u0a34\u0a37\u0a3a-\u0a3b\u0a3d\u0a43-\u0a46\u0a49-\u0a4a\u0a4e-\u0a50\u0a52-\u0a58\u0a5d\u0a5f-\u0a65\u0a77-\u0a80\u0a84\u0a8e\u0a92\u0aa9\u0ab1\u0ab4\u0aba-\u0abb\u0ac6\u0aca\u0ace-\u0acf\u0ad1-\u0adf\u0ae4-\u0ae5\u0af2-\u0af8\u0b00\u0b04\u0b0d-\u0b0e\u0b11-\u0b12\u0b29\u0b31\u0b34\u0b3a-\u0b3b\u0b45-\u0b46\u0b49-\u0b4a\u0b4e-\u0b55\u0b58-\u0b5b\u0b5e\u0b64-\u0b65\u0b78-\u0b81\u0b84\u0b8b-\u0b8d\u0b91\u0b96-\u0b98\u0b9b\u0b9d\u0ba0-\u0ba2\u0ba5-\u0ba7\u0bab-\u0bad\u0bba-\u0bbd\u0bc3-\u0bc5\u0bc9\u0bce-\u0bcf\u0bd1-\u0bd6\u0bd8-\u0be5\u0bfb-\u0bff\u0c0d\u0c11\u0c29\u0c3a-\u0c3c\u0c45\u0c49\u0c4e-\u0c54\u0c57\u0c5b-\u0c5f\u0c64-\u0c65\u0c70-\u0c77\u0c8d\u0c91\u0ca9\u0cb4\u0cba-\u0cbb\u0cc5\u0cc9\u0cce-\u0cd4\u0cd7-\u0cdd\u0cdf\u0ce4-\u0ce5\u0cf0\u0cf3-\u0cff\u0d04\u0d0d\u0d11\u0d45\u0d49\u0d50-\u0d53\u0d64-\u0d65\u0d80-\u0d81\u0d84\u0d97-\u0d99\u0db2\u0dbc\u0dbe-\u0dbf\u0dc7-\u0dc9\u0dcb-\u0dce\u0dd5\u0dd7\u0de0-\u0de5\u0df0-\u0df1\u0df5-\u0e00\u0e3b-\u0e3e\u0e5c-\u0e80\u0e83\u0e85-\u0e86\u0e89\u0e8b-\u0e8c\u0e8e-\u0e93\u0e98\u0ea0\u0ea4\u0ea6\u0ea8-\u0ea9\u0eac\u0eba\u0ebe-\u0ebf\u0ec5\u0ec7\u0ece-\u0ecf\u0eda-\u0edb\u0ee0-\u0eff\u0f48\u0f6d-\u0f70\u0f98\u0fbd\u0fcd\u0fdb-\u0fff\u10c6\u10c8-\u10cc\u10ce-\u10cf\u1249\u124e-\u124f\u1257\u1259\u125e-\u125f\u1289\u128e-\u128f\u12b1\u12b6-\u12b7\u12bf\u12c1\u12c6-\u12c7\u12d7\u1311\u1316-\u1317\u135b-\u135c\u137d-\u137f\u139a-\u139f\u13f6-\u13f7\u13fe-\u13ff\u169d-\u169f\u16f9-\u16ff\u170d\u1715-\u171f\u1737-\u173f\u1754-\u175f\u176d\u1771\u1774-\u177f\u17de-\u17df\u17ea-\u17ef\u17fa-\u17ff\u180f\u181a-\u181f\u1879-\u187f\u18ab-\u18af\u18f6-\u18ff\u191f\u192c-\u192f\u193c-\u193f\u1941-\u1943\u196e-\u196f\u1975-\u197f\u19ac-\u19af\u19ca-\u19cf\u19db-\u19dd\u1a1c-\u1a1d\u1a5f\u1a7d-\u1a7e\u1a8a-\u1a8f\u1a9a-\u1a9f\u1aae-\u1aaf\u1abf-\u1aff\u1b4c-\u1b4f\u1b7d-\u1b7f\u1bf4-\u1bfb\u1c38-\u1c3a\u1c4a-\u1c4c\u1c89-\u1c8f\u1cbb-\u1cbc\u1cc8-\u1ccf\u1cfa-\u1cff\u1dfa\u1f16-\u1f17\u1f1e-\u1f1f\u1f46-\u1f47\u1f4e-\u1f4f\u1f58\u1f5a\u1f5c\u1f5e\u1f7e-\u1f7f\u1fb5\u1fc5\u1fd4-\u1fd5\u1fdc\u1ff0-\u1ff1\u1ff5\u1fff\u2065\u2072-\u2073\u208f\u209d-\u209f\u20c0-\u20cf\u20f1-\u20ff\u218c-\u218f\u2427-\u243f\u244b-\u245f\u2b74-\u2b75\u2b96-\u2b97\u2bc9\u2bff\u2c2f\u2c5f\u2cf4-\u2cf8\u2d26\u2d28-\u2d2c\u2d2e-\u2d2f\u2d68-\u2d6e\u2d71-\u2d7e\u2d97-\u2d9f\u2da7\u2daf\u2db7\u2dbf\u2dc7\u2dcf\u2dd7\u2ddf\u2e4f-\u2e7f\u2e9a\u2ef4-\u2eff\u2fd6-\u2fef\u2ffc-\u2fff\u3040\u3097-\u3098\u3100-\u3104\u3130\u318f\u31bb-\u31bf\u31e4-\u31ef\u321f\u32ff\u4db6-\u4dbf\u9ff0-\u9fff\ua48d-\ua48f\ua4c7-\ua4cf\ua62c-\ua63f\ua6f8-\ua6ff\ua7ba-\ua7f6\ua82c-\ua82f\ua83a-\ua83f\ua878-\ua87f\ua8c6-\ua8cd\ua8da-\ua8df\ua954-\ua95e\ua97d-\ua97f\ua9ce\ua9da-\ua9dd\ua9ff\uaa37-\uaa3f\uaa4e-\uaa4f\uaa5a-\uaa5b\uaac3-\uaada\uaaf7-\uab00\uab07-\uab08\uab0f-\uab10\uab17-\uab1f\uab27\uab2f\uab66-\uab6f\uabee-\uabef\uabfa-\uabff\ud7a4-\ud7af\ud7c7-\ud7ca\ud7fc-\ud7ff\ufa6e-\ufa6f\ufada-\ufaff\ufb07-\ufb12\ufb18-\ufb1c\ufb37\ufb3d\ufb3f\ufb42\ufb45\ufbc2-\ufbd2\ufd40-\ufd4f\ufd90-\ufd91\ufdc8-\ufdef\ufdfe-\ufdff\ufe1a-\ufe1f\ufe53\ufe67\ufe6c-\ufe6f\ufe75\ufefd-\ufefe\uff00\uffbf-\uffc1\uffc8-\uffc9\uffd0-\uffd1\uffd8-\uffd9\uffdd-\uffdf\uffe7\uffef-\ufff8\ufffe-\uffff\U0001000c\U00010027\U0001003b\U0001003e\U0001004e-\U0001004f\U0001005e-\U0001007f\U000100fb-\U000100ff\U00010103-\U00010106\U00010134-\U00010136\U0001018f\U0001019c-\U0001019f\U000101a1-\U000101cf\U000101fe-\U0001027f\U0001029d-\U0001029f\U000102d1-\U000102df\U000102fc-\U000102ff\U00010324-\U0001032c\U0001034b-\U0001034f\U0001037b-\U0001037f\U0001039e\U000103c4-\U000103c7\U000103d6-\U000103ff\U0001049e-\U0001049f\U000104aa-\U000104af\U000104d4-\U000104d7\U000104fc-\U000104ff\U00010528-\U0001052f\U00010564-\U0001056e\U00010570-\U000105ff\U00010737-\U0001073f\U00010756-\U0001075f\U00010768-\U000107ff\U00010806-\U00010807\U00010809\U00010836\U00010839-\U0001083b\U0001083d-\U0001083e\U00010856\U0001089f-\U000108a6\U000108b0-\U000108df\U000108f3\U000108f6-\U000108fa\U0001091c-\U0001091e\U0001093a-\U0001093e\U00010940-\U0001097f\U000109b8-\U000109bb\U000109d0-\U000109d1\U00010a04\U00010a07-\U00010a0b\U00010a14\U00010a18\U00010a36-\U00010a37\U00010a3b-\U00010a3e\U00010a49-\U00010a4f\U00010a59-\U00010a5f\U00010aa0-\U00010abf\U00010ae7-\U00010aea\U00010af7-\U00010aff\U00010b36-\U00010b38\U00010b56-\U00010b57\U00010b73-\U00010b77\U00010b92-\U00010b98\U00010b9d-\U00010ba8\U00010bb0-\U00010bff\U00010c49-\U00010c7f\U00010cb3-\U00010cbf\U00010cf3-\U00010cf9\U00010d28-\U00010d2f\U00010d3a-\U00010e5f\U00010e7f-\U00010eff\U00010f28-\U00010f2f\U00010f5a-\U00010fff\U0001104e-\U00011051\U00011070-\U0001107e\U000110c2-\U000110cc\U000110ce-\U000110cf\U000110e9-\U000110ef\U000110fa-\U000110ff\U00011135\U00011147-\U0001114f\U00011177-\U0001117f\U000111ce-\U000111cf\U000111e0\U000111f5-\U000111ff\U00011212\U0001123f-\U0001127f\U00011287\U00011289\U0001128e\U0001129e\U000112aa-\U000112af\U000112eb-\U000112ef\U000112fa-\U000112ff\U00011304\U0001130d-\U0001130e\U00011311-\U00011312\U00011329\U00011331\U00011334\U0001133a\U00011345-\U00011346\U00011349-\U0001134a\U0001134e-\U0001134f\U00011351-\U00011356\U00011358-\U0001135c\U00011364-\U00011365\U0001136d-\U0001136f\U00011375-\U000113ff\U0001145a\U0001145c\U0001145f-\U0001147f\U000114c8-\U000114cf\U000114da-\U0001157f\U000115b6-\U000115b7\U000115de-\U000115ff\U00011645-\U0001164f\U0001165a-\U0001165f\U0001166d-\U0001167f\U000116b8-\U000116bf\U000116ca-\U000116ff\U0001171b-\U0001171c\U0001172c-\U0001172f\U00011740-\U000117ff\U0001183c-\U0001189f\U000118f3-\U000118fe\U00011900-\U000119ff\U00011a48-\U00011a4f\U00011a84-\U00011a85\U00011aa3-\U00011abf\U00011af9-\U00011bff\U00011c09\U00011c37\U00011c46-\U00011c4f\U00011c6d-\U00011c6f\U00011c90-\U00011c91\U00011ca8\U00011cb7-\U00011cff\U00011d07\U00011d0a\U00011d37-\U00011d39\U00011d3b\U00011d3e\U00011d48-\U00011d4f\U00011d5a-\U00011d5f\U00011d66\U00011d69\U00011d8f\U00011d92\U00011d99-\U00011d9f\U00011daa-\U00011edf\U00011ef9-\U00011fff\U0001239a-\U000123ff\U0001246f\U00012475-\U0001247f\U00012544-\U00012fff\U0001342f-\U000143ff\U00014647-\U000167ff\U00016a39-\U00016a3f\U00016a5f\U00016a6a-\U00016a6d\U00016a70-\U00016acf\U00016aee-\U00016aef\U00016af6-\U00016aff\U00016b46-\U00016b4f\U00016b5a\U00016b62\U00016b78-\U00016b7c\U00016b90-\U00016e3f\U00016e9b-\U00016eff\U00016f45-\U00016f4f\U00016f7f-\U00016f8e\U00016fa0-\U00016fdf\U00016fe2-\U00016fff\U000187f2-\U000187ff\U00018af3-\U0001afff\U0001b11f-\U0001b16f\U0001b2fc-\U0001bbff\U0001bc6b-\U0001bc6f\U0001bc7d-\U0001bc7f\U0001bc89-\U0001bc8f\U0001bc9a-\U0001bc9b\U0001bca4-\U0001cfff\U0001d0f6-\U0001d0ff\U0001d127-\U0001d128\U0001d1e9-\U0001d1ff\U0001d246-\U0001d2df\U0001d2f4-\U0001d2ff\U0001d357-\U0001d35f\U0001d379-\U0001d3ff\U0001d455\U0001d49d\U0001d4a0-\U0001d4a1\U0001d4a3-\U0001d4a4\U0001d4a7-\U0001d4a8\U0001d4ad\U0001d4ba\U0001d4bc\U0001d4c4\U0001d506\U0001d50b-\U0001d50c\U0001d515\U0001d51d\U0001d53a\U0001d53f\U0001d545\U0001d547-\U0001d549\U0001d551\U0001d6a6-\U0001d6a7\U0001d7cc-\U0001d7cd\U0001da8c-\U0001da9a\U0001daa0\U0001dab0-\U0001dfff\U0001e007\U0001e019-\U0001e01a\U0001e022\U0001e025\U0001e02b-\U0001e7ff\U0001e8c5-\U0001e8c6\U0001e8d7-\U0001e8ff\U0001e94b-\U0001e94f\U0001e95a-\U0001e95d\U0001e960-\U0001ec70\U0001ecb5-\U0001edff\U0001ee04\U0001ee20\U0001ee23\U0001ee25-\U0001ee26\U0001ee28\U0001ee33\U0001ee38\U0001ee3a\U0001ee3c-\U0001ee41\U0001ee43-\U0001ee46\U0001ee48\U0001ee4a\U0001ee4c\U0001ee50\U0001ee53\U0001ee55-\U0001ee56\U0001ee58\U0001ee5a\U0001ee5c\U0001ee5e\U0001ee60\U0001ee63\U0001ee65-\U0001ee66\U0001ee6b\U0001ee73\U0001ee78\U0001ee7d\U0001ee7f\U0001ee8a\U0001ee9c-\U0001eea0\U0001eea4\U0001eeaa\U0001eebc-\U0001eeef\U0001eef2-\U0001efff\U0001f02c-\U0001f02f\U0001f094-\U0001f09f\U0001f0af-\U0001f0b0\U0001f0c0\U0001f0d0\U0001f0f6-\U0001f0ff\U0001f10d-\U0001f10f\U0001f16c-\U0001f16f\U0001f1ad-\U0001f1e5\U0001f203-\U0001f20f\U0001f23c-\U0001f23f\U0001f249-\U0001f24f\U0001f252-\U0001f25f\U0001f266-\U0001f2ff\U0001f6d5-\U0001f6df\U0001f6ed-\U0001f6ef\U0001f6fa-\U0001f6ff\U0001f774-\U0001f77f\U0001f7d9-\U0001f7ff\U0001f80c-\U0001f80f\U0001f848-\U0001f84f\U0001f85a-\U0001f85f\U0001f888-\U0001f88f\U0001f8ae-\U0001f8ff\U0001f90c-\U0001f90f\U0001f93f\U0001f971-\U0001f972\U0001f977-\U0001f979\U0001f97b\U0001f9a3-\U0001f9af\U0001f9ba-\U0001f9bf\U0001f9c3-\U0001f9cf\U0001fa00-\U0001fa5f\U0001fa6e-\U0001ffff\U0002a6d7-\U0002a6ff\U0002b735-\U0002b73f\U0002b81e-\U0002b81f\U0002cea2-\U0002ceaf\U0002ebe1-\U0002f7ff\U0002fa1e-\U000e0000\U000e0002-\U000e001f\U000e0080-\U000e00ff\U000e01f0-\U000effff\U000ffffe-\U000fffff\U0010fffe-\U0010ffff'
19 | 
20 | Co = '\ue000-\uf8ff\U000f0000-\U000ffffd\U00100000-\U0010fffd'
21 | 
22 | Cs = '\ud800-\udbff\\\udc00\udc01-\udfff'
23 | 
24 | Ll = 'a-z\xb5\xdf-\xf6\xf8-\xff\u0101\u0103\u0105\u0107\u0109\u010b\u010d\u010f\u0111\u0113\u0115\u0117\u0119\u011b\u011d\u011f\u0121\u0123\u0125\u0127\u0129\u012b\u012d\u012f\u0131\u0133\u0135\u0137-\u0138\u013a\u013c\u013e\u0140\u0142\u0144\u0146\u0148-\u0149\u014b\u014d\u014f\u0151\u0153\u0155\u0157\u0159\u015b\u015d\u015f\u0161\u0163\u0165\u0167\u0169\u016b\u016d\u016f\u0171\u0173\u0175\u0177\u017a\u017c\u017e-\u0180\u0183\u0185\u0188\u018c-\u018d\u0192\u0195\u0199-\u019b\u019e\u01a1\u01a3\u01a5\u01a8\u01aa-\u01ab\u01ad\u01b0\u01b4\u01b6\u01b9-\u01ba\u01bd-\u01bf\u01c6\u01c9\u01cc\u01ce\u01d0\u01d2\u01d4\u01d6\u01d8\u01da\u01dc-\u01dd\u01df\u01e1\u01e3\u01e5\u01e7\u01e9\u01eb\u01ed\u01ef-\u01f0\u01f3\u01f5\u01f9\u01fb\u01fd\u01ff\u0201\u0203\u0205\u0207\u0209\u020b\u020d\u020f\u0211\u0213\u0215\u0217\u0219\u021b\u021d\u021f\u0221\u0223\u0225\u0227\u0229\u022b\u022d\u022f\u0231\u0233-\u0239\u023c\u023f-\u0240\u0242\u0247\u0249\u024b\u024d\u024f-\u0293\u0295-\u02af\u0371\u0373\u0377\u037b-\u037d\u0390\u03ac-\u03ce\u03d0-\u03d1\u03d5-\u03d7\u03d9\u03db\u03dd\u03df\u03e1\u03e3\u03e5\u03e7\u03e9\u03eb\u03ed\u03ef-\u03f3\u03f5\u03f8\u03fb-\u03fc\u0430-\u045f\u0461\u0463\u0465\u0467\u0469\u046b\u046d\u046f\u0471\u0473\u0475\u0477\u0479\u047b\u047d\u047f\u0481\u048b\u048d\u048f\u0491\u0493\u0495\u0497\u0499\u049b\u049d\u049f\u04a1\u04a3\u04a5\u04a7\u04a9\u04ab\u04ad\u04af\u04b1\u04b3\u04b5\u04b7\u04b9\u04bb\u04bd\u04bf\u04c2\u04c4\u04c6\u04c8\u04ca\u04cc\u04ce-\u04cf\u04d1\u04d3\u04d5\u04d7\u04d9\u04db\u04dd\u04df\u04e1\u04e3\u04e5\u04e7\u04e9\u04eb\u04ed\u04ef\u04f1\u04f3\u04f5\u04f7\u04f9\u04fb\u04fd\u04ff\u0501\u0503\u0505\u0507\u0509\u050b\u050d\u050f\u0511\u0513\u0515\u0517\u0519\u051b\u051d\u051f\u0521\u0523\u0525\u0527\u0529\u052b\u052d\u052f\u0560-\u0588\u10d0-\u10fa\u10fd-\u10ff\u13f8-\u13fd\u1c80-\u1c88\u1d00-\u1d2b\u1d6b-\u1d77\u1d79-\u1d9a\u1e01\u1e03\u1e05\u1e07\u1e09\u1e0b\u1e0d\u1e0f\u1e11\u1e13\u1e15\u1e17\u1e19\u1e1b\u1e1d\u1e1f\u1e21\u1e23\u1e25\u1e27\u1e29\u1e2b\u1e2d\u1e2f\u1e31\u1e33\u1e35\u1e37\u1e39\u1e3b\u1e3d\u1e3f\u1e41\u1e43\u1e45\u1e47\u1e49\u1e4b\u1e4d\u1e4f\u1e51\u1e53\u1e55\u1e57\u1e59\u1e5b\u1e5d\u1e5f\u1e61\u1e63\u1e65\u1e67\u1e69\u1e6b\u1e6d\u1e6f\u1e71\u1e73\u1e75\u1e77\u1e79\u1e7b\u1e7d\u1e7f\u1e81\u1e83\u1e85\u1e87\u1e89\u1e8b\u1e8d\u1e8f\u1e91\u1e93\u1e95-\u1e9d\u1e9f\u1ea1\u1ea3\u1ea5\u1ea7\u1ea9\u1eab\u1ead\u1eaf\u1eb1\u1eb3\u1eb5\u1eb7\u1eb9\u1ebb\u1ebd\u1ebf\u1ec1\u1ec3\u1ec5\u1ec7\u1ec9\u1ecb\u1ecd\u1ecf\u1ed1\u1ed3\u1ed5\u1ed7\u1ed9\u1edb\u1edd\u1edf\u1ee1\u1ee3\u1ee5\u1ee7\u1ee9\u1eeb\u1eed\u1eef\u1ef1\u1ef3\u1ef5\u1ef7\u1ef9\u1efb\u1efd\u1eff-\u1f07\u1f10-\u1f15\u1f20-\u1f27\u1f30-\u1f37\u1f40-\u1f45\u1f50-\u1f57\u1f60-\u1f67\u1f70-\u1f7d\u1f80-\u1f87\u1f90-\u1f97\u1fa0-\u1fa7\u1fb0-\u1fb4\u1fb6-\u1fb7\u1fbe\u1fc2-\u1fc4\u1fc6-\u1fc7\u1fd0-\u1fd3\u1fd6-\u1fd7\u1fe0-\u1fe7\u1ff2-\u1ff4\u1ff6-\u1ff7\u210a\u210e-\u210f\u2113\u212f\u2134\u2139\u213c-\u213d\u2146-\u2149\u214e\u2184\u2c30-\u2c5e\u2c61\u2c65-\u2c66\u2c68\u2c6a\u2c6c\u2c71\u2c73-\u2c74\u2c76-\u2c7b\u2c81\u2c83\u2c85\u2c87\u2c89\u2c8b\u2c8d\u2c8f\u2c91\u2c93\u2c95\u2c97\u2c99\u2c9b\u2c9d\u2c9f\u2ca1\u2ca3\u2ca5\u2ca7\u2ca9\u2cab\u2cad\u2caf\u2cb1\u2cb3\u2cb5\u2cb7\u2cb9\u2cbb\u2cbd\u2cbf\u2cc1\u2cc3\u2cc5\u2cc7\u2cc9\u2ccb\u2ccd\u2ccf\u2cd1\u2cd3\u2cd5\u2cd7\u2cd9\u2cdb\u2cdd\u2cdf\u2ce1\u2ce3-\u2ce4\u2cec\u2cee\u2cf3\u2d00-\u2d25\u2d27\u2d2d\ua641\ua643\ua645\ua647\ua649\ua64b\ua64d\ua64f\ua651\ua653\ua655\ua657\ua659\ua65b\ua65d\ua65f\ua661\ua663\ua665\ua667\ua669\ua66b\ua66d\ua681\ua683\ua685\ua687\ua689\ua68b\ua68d\ua68f\ua691\ua693\ua695\ua697\ua699\ua69b\ua723\ua725\ua727\ua729\ua72b\ua72d\ua72f-\ua731\ua733\ua735\ua737\ua739\ua73b\ua73d\ua73f\ua741\ua743\ua745\ua747\ua749\ua74b\ua74d\ua74f\ua751\ua753\ua755\ua757\ua759\ua75b\ua75d\ua75f\ua761\ua763\ua765\ua767\ua769\ua76b\ua76d\ua76f\ua771-\ua778\ua77a\ua77c\ua77f\ua781\ua783\ua785\ua787\ua78c\ua78e\ua791\ua793-\ua795\ua797\ua799\ua79b\ua79d\ua79f\ua7a1\ua7a3\ua7a5\ua7a7\ua7a9\ua7af\ua7b5\ua7b7\ua7b9\ua7fa\uab30-\uab5a\uab60-\uab65\uab70-\uabbf\ufb00-\ufb06\ufb13-\ufb17\uff41-\uff5a\U00010428-\U0001044f\U000104d8-\U000104fb\U00010cc0-\U00010cf2\U000118c0-\U000118df\U00016e60-\U00016e7f\U0001d41a-\U0001d433\U0001d44e-\U0001d454\U0001d456-\U0001d467\U0001d482-\U0001d49b\U0001d4b6-\U0001d4b9\U0001d4bb\U0001d4bd-\U0001d4c3\U0001d4c5-\U0001d4cf\U0001d4ea-\U0001d503\U0001d51e-\U0001d537\U0001d552-\U0001d56b\U0001d586-\U0001d59f\U0001d5ba-\U0001d5d3\U0001d5ee-\U0001d607\U0001d622-\U0001d63b\U0001d656-\U0001d66f\U0001d68a-\U0001d6a5\U0001d6c2-\U0001d6da\U0001d6dc-\U0001d6e1\U0001d6fc-\U0001d714\U0001d716-\U0001d71b\U0001d736-\U0001d74e\U0001d750-\U0001d755\U0001d770-\U0001d788\U0001d78a-\U0001d78f\U0001d7aa-\U0001d7c2\U0001d7c4-\U0001d7c9\U0001d7cb\U0001e922-\U0001e943'
25 | 
26 | Lm = '\u02b0-\u02c1\u02c6-\u02d1\u02e0-\u02e4\u02ec\u02ee\u0374\u037a\u0559\u0640\u06e5-\u06e6\u07f4-\u07f5\u07fa\u081a\u0824\u0828\u0971\u0e46\u0ec6\u10fc\u17d7\u1843\u1aa7\u1c78-\u1c7d\u1d2c-\u1d6a\u1d78\u1d9b-\u1dbf\u2071\u207f\u2090-\u209c\u2c7c-\u2c7d\u2d6f\u2e2f\u3005\u3031-\u3035\u303b\u309d-\u309e\u30fc-\u30fe\ua015\ua4f8-\ua4fd\ua60c\ua67f\ua69c-\ua69d\ua717-\ua71f\ua770\ua788\ua7f8-\ua7f9\ua9cf\ua9e6\uaa70\uaadd\uaaf3-\uaaf4\uab5c-\uab5f\uff70\uff9e-\uff9f\U00016b40-\U00016b43\U00016f93-\U00016f9f\U00016fe0-\U00016fe1'
27 | 
[TRUNCATED]
```

.venv/lib/python3.13/site-packages/pip/_vendor/pygments/util.py
```
1 | """
2 |     pygments.util
3 |     ~~~~~~~~~~~~~
4 | 
5 |     Utility functions.
6 | 
7 |     :copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
8 |     :license: BSD, see LICENSE for details.
9 | """
10 | 
11 | import re
12 | from io import TextIOWrapper
13 | 
14 | 
15 | split_path_re = re.compile(r'[/\\ ]')
16 | doctype_lookup_re = re.compile(r'''
17 |     <!DOCTYPE\s+(
18 |      [a-zA-Z_][a-zA-Z0-9]*
19 |      (?: \s+      # optional in HTML5
20 |      [a-zA-Z_][a-zA-Z0-9]*\s+
21 |      "[^"]*")?
22 |      )
23 |      [^>]*>
24 | ''', re.DOTALL | re.MULTILINE | re.VERBOSE)
25 | tag_re = re.compile(r'<(.+?)(\s.*?)?>.*?</.+?>',
26 |                     re.IGNORECASE | re.DOTALL | re.MULTILINE)
27 | xml_decl_re = re.compile(r'\s*<\?xml[^>]*\?>', re.I)
28 | 
29 | 
30 | class ClassNotFound(ValueError):
31 |     """Raised if one of the lookup functions didn't find a matching class."""
32 | 
33 | 
34 | class OptionError(Exception):
35 |     """
36 |     This exception will be raised by all option processing functions if
37 |     the type or value of the argument is not correct.
38 |     """
39 | 
40 | def get_choice_opt(options, optname, allowed, default=None, normcase=False):
41 |     """
42 |     If the key `optname` from the dictionary is not in the sequence
43 |     `allowed`, raise an error, otherwise return it.
44 |     """
45 |     string = options.get(optname, default)
46 |     if normcase:
47 |         string = string.lower()
48 |     if string not in allowed:
49 |         raise OptionError('Value for option {} must be one of {}'.format(optname, ', '.join(map(str, allowed))))
50 |     return string
51 | 
52 | 
53 | def get_bool_opt(options, optname, default=None):
54 |     """
55 |     Intuitively, this is `options.get(optname, default)`, but restricted to
56 |     Boolean value. The Booleans can be represented as string, in order to accept
57 |     Boolean value from the command line arguments. If the key `optname` is
58 |     present in the dictionary `options` and is not associated with a Boolean,
59 |     raise an `OptionError`. If it is absent, `default` is returned instead.
60 | 
61 |     The valid string values for ``True`` are ``1``, ``yes``, ``true`` and
62 |     ``on``, the ones for ``False`` are ``0``, ``no``, ``false`` and ``off``
63 |     (matched case-insensitively).
64 |     """
65 |     string = options.get(optname, default)
66 |     if isinstance(string, bool):
67 |         return string
68 |     elif isinstance(string, int):
69 |         return bool(string)
70 |     elif not isinstance(string, str):
71 |         raise OptionError(f'Invalid type {string!r} for option {optname}; use '
72 |                           '1/0, yes/no, true/false, on/off')
73 |     elif string.lower() in ('1', 'yes', 'true', 'on'):
74 |         return True
75 |     elif string.lower() in ('0', 'no', 'false', 'off'):
76 |         return False
77 |     else:
78 |         raise OptionError(f'Invalid value {string!r} for option {optname}; use '
79 |                           '1/0, yes/no, true/false, on/off')
80 | 
81 | 
82 | def get_int_opt(options, optname, default=None):
83 |     """As :func:`get_bool_opt`, but interpret the value as an integer."""
84 |     string = options.get(optname, default)
85 |     try:
86 |         return int(string)
87 |     except TypeError:
88 |         raise OptionError(f'Invalid type {string!r} for option {optname}; you '
89 |                           'must give an integer value')
90 |     except ValueError:
91 |         raise OptionError(f'Invalid value {string!r} for option {optname}; you '
92 |                           'must give an integer value')
93 | 
94 | def get_list_opt(options, optname, default=None):
95 |     """
96 |     If the key `optname` from the dictionary `options` is a string,
97 |     split it at whitespace and return it. If it is already a list
98 |     or a tuple, it is returned as a list.
99 |     """
100 |     val = options.get(optname, default)
101 |     if isinstance(val, str):
102 |         return val.split()
103 |     elif isinstance(val, (list, tuple)):
104 |         return list(val)
105 |     else:
106 |         raise OptionError(f'Invalid type {val!r} for option {optname}; you '
107 |                           'must give a list value')
108 | 
109 | 
110 | def docstring_headline(obj):
111 |     if not obj.__doc__:
112 |         return ''
113 |     res = []
114 |     for line in obj.__doc__.strip().splitlines():
115 |         if line.strip():
116 |             res.append(" " + line.strip())
117 |         else:
118 |             break
119 |     return ''.join(res).lstrip()
120 | 
121 | 
122 | def make_analysator(f):
123 |     """Return a static text analyser function that returns float values."""
124 |     def text_analyse(text):
125 |         try:
126 |             rv = f(text)
127 |         except Exception:
128 |             return 0.0
129 |         if not rv:
130 |             return 0.0
131 |         try:
132 |             return min(1.0, max(0.0, float(rv)))
133 |         except (ValueError, TypeError):
134 |             return 0.0
135 |     text_analyse.__doc__ = f.__doc__
136 |     return staticmethod(text_analyse)
137 | 
138 | 
139 | def shebang_matches(text, regex):
140 |     r"""Check if the given regular expression matches the last part of the
141 |     shebang if one exists.
142 | 
143 |         >>> from pygments.util import shebang_matches
144 |         >>> shebang_matches('#!/usr/bin/env python', r'python(2\.\d)?')
145 |         True
146 |         >>> shebang_matches('#!/usr/bin/python2.4', r'python(2\.\d)?')
147 |         True
148 |         >>> shebang_matches('#!/usr/bin/python-ruby', r'python(2\.\d)?')
149 |         False
150 |         >>> shebang_matches('#!/usr/bin/python/ruby', r'python(2\.\d)?')
151 |         False
152 |         >>> shebang_matches('#!/usr/bin/startsomethingwith python',
153 |         ...                 r'python(2\.\d)?')
154 |         True
155 | 
156 |     It also checks for common windows executable file extensions::
157 | 
158 |         >>> shebang_matches('#!C:\\Python2.4\\Python.exe', r'python(2\.\d)?')
159 |         True
160 | 
161 |     Parameters (``'-f'`` or ``'--foo'`` are ignored so ``'perl'`` does
162 |     the same as ``'perl -e'``)
163 | 
164 |     Note that this method automatically searches the whole string (eg:
165 |     the regular expression is wrapped in ``'^$'``)
166 |     """
167 |     index = text.find('\n')
168 |     if index >= 0:
169 |         first_line = text[:index].lower()
170 |     else:
171 |         first_line = text.lower()
172 |     if first_line.startswith('#!'):
173 |         try:
174 |             found = [x for x in split_path_re.split(first_line[2:].strip())
175 |                      if x and not x.startswith('-')][-1]
176 |         except IndexError:
177 |             return False
178 |         regex = re.compile(rf'^{regex}(\.(exe|cmd|bat|bin))?$', re.IGNORECASE)
179 |         if regex.search(found) is not None:
180 |             return True
181 |     return False
182 | 
183 | 
184 | def doctype_matches(text, regex):
185 |     """Check if the doctype matches a regular expression (if present).
186 | 
187 |     Note that this method only checks the first part of a DOCTYPE.
188 |     eg: 'html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"'
189 |     """
190 |     m = doctype_lookup_re.search(text)
191 |     if m is None:
192 |         return False
193 |     doctype = m.group(1)
194 |     return re.compile(regex, re.I).match(doctype.strip()) is not None
195 | 
196 | 
197 | def html_doctype_matches(text):
198 |     """Check if the file looks like it has a html doctype."""
199 |     return doctype_matches(text, r'html')
200 | 
201 | 
202 | _looks_like_xml_cache = {}
203 | 
204 | 
205 | def looks_like_xml(text):
206 |     """Check if a doctype exists or if we have some tags."""
207 |     if xml_decl_re.match(text):
208 |         return True
209 |     key = hash(text)
210 |     try:
211 |         return _looks_like_xml_cache[key]
212 |     except KeyError:
213 |         m = doctype_lookup_re.search(text)
214 |         if m is not None:
215 |             return True
216 |         rv = tag_re.search(text[:1000]) is not None
217 |         _looks_like_xml_cache[key] = rv
218 |         return rv
219 | 
220 | 
221 | def surrogatepair(c):
222 |     """Given a unicode character code with length greater than 16 bits,
223 |     return the two 16 bit surrogate pair.
224 |     """
225 |     # From example D28 of:
226 |     # http://www.unicode.org/book/ch03.pdf
227 |     return (0xd7c0 + (c >> 10), (0xdc00 + (c & 0x3ff)))
228 | 
229 | 
230 | def format_lines(var_name, seq, raw=False, indent_level=0):
231 |     """Formats a sequence of strings for output."""
232 |     lines = []
233 |     base_indent = ' ' * indent_level * 4
234 |     inner_indent = ' ' * (indent_level + 1) * 4
235 |     lines.append(base_indent + var_name + ' = (')
236 |     if raw:
237 |         # These should be preformatted reprs of, say, tuples.
238 |         for i in seq:
239 |             lines.append(inner_indent + i + ',')
240 |     else:
241 |         for i in seq:
242 |             # Force use of single quotes
243 |             r = repr(i + '"')
244 |             lines.append(inner_indent + r[:-2] + r[-1] + ',')
245 |     lines.append(base_indent + ')')
246 |     return '\n'.join(lines)
247 | 
248 | 
249 | def duplicates_removed(it, already_seen=()):
250 |     """
251 |     Returns a list with duplicates removed from the iterable `it`.
252 | 
253 |     Order is preserved.
254 |     """
255 |     lst = []
256 |     seen = set()
257 |     for i in it:
258 |         if i in seen or i in already_seen:
259 |             continue
260 |         lst.append(i)
261 |         seen.add(i)
262 |     return lst
263 | 
264 | 
265 | class Future:
266 |     """Generic class to defer some work.
267 | 
268 |     Handled specially in RegexLexerMeta, to support regex string construction at
269 |     first use.
270 |     """
271 |     def get(self):
272 |         raise NotImplementedError
273 | 
274 | 
275 | def guess_decode(text):
276 |     """Decode *text* with guessed encoding.
277 | 
278 |     First try UTF-8; this should fail for non-UTF-8 encodings.
279 |     Then try the preferred locale encoding.
280 |     Fall back to latin-1, which always works.
281 |     """
282 |     try:
283 |         text = text.decode('utf-8')
284 |         return text, 'utf-8'
285 |     except UnicodeDecodeError:
286 |         try:
287 |             import locale
288 |             prefencoding = locale.getpreferredencoding()
289 |             text = text.decode()
290 |             return text, prefencoding
291 |         except (UnicodeDecodeError, LookupError):
292 |             text = text.decode('latin1')
293 |             return text, 'latin1'
294 | 
295 | 
296 | def guess_decode_from_terminal(text, term):
297 |     """Decode *text* coming from terminal *term*.
298 | 
299 |     First try the terminal encoding, if given.
300 |     Then try UTF-8.  Then try the preferred locale encoding.
301 |     Fall back to latin-1, which always works.
302 |     """
303 |     if getattr(term, 'encoding', None):
304 |         try:
305 |             text = text.decode(term.encoding)
306 |         except UnicodeDecodeError:
307 |             pass
308 |         else:
309 |             return text, term.encoding
310 |     return guess_decode(text)
311 | 
312 | 
313 | def terminal_encoding(term):
314 |     """Return our best guess of encoding for the given *term*."""
315 |     if getattr(term, 'encoding', None):
316 |         return term.encoding
317 |     import locale
318 |     return locale.getpreferredencoding()
319 | 
320 | 
321 | class UnclosingTextIOWrapper(TextIOWrapper):
322 |     # Don't close underlying buffer on destruction.
323 |     def close(self):
324 |         self.flush()
```

.venv/lib/python3.13/site-packages/pip/_vendor/tomli/__init__.py
```
1 | # SPDX-License-Identifier: MIT
2 | # SPDX-FileCopyrightText: 2021 Taneli Hukkinen
3 | # Licensed to PSF under a Contributor Agreement.
4 | 
5 | __all__ = ("loads", "load", "TOMLDecodeError")
6 | __version__ = "2.2.1"  # DO NOT EDIT THIS LINE MANUALLY. LET bump2version UTILITY DO IT
7 | 
8 | from ._parser import TOMLDecodeError, load, loads
```

.venv/lib/python3.13/site-packages/pip/_vendor/tomli/_parser.py
```
1 | # SPDX-License-Identifier: MIT
2 | # SPDX-FileCopyrightText: 2021 Taneli Hukkinen
3 | # Licensed to PSF under a Contributor Agreement.
4 | 
5 | from __future__ import annotations
6 | 
7 | from collections.abc import Iterable
8 | import string
9 | import sys
10 | from types import MappingProxyType
11 | from typing import IO, Any, Final, NamedTuple
12 | import warnings
13 | 
14 | from ._re import (
15 |     RE_DATETIME,
16 |     RE_LOCALTIME,
17 |     RE_NUMBER,
18 |     match_to_datetime,
19 |     match_to_localtime,
20 |     match_to_number,
21 | )
22 | from ._types import Key, ParseFloat, Pos
23 | 
24 | # Inline tables/arrays are implemented using recursion. Pathologically
25 | # nested documents cause pure Python to raise RecursionError (which is OK),
26 | # but mypyc binary wheels will crash unrecoverably (not OK). According to
27 | # mypyc docs this will be fixed in the future:
28 | # https://mypyc.readthedocs.io/en/latest/differences_from_python.html#stack-overflows
29 | # Before mypyc's fix is in, recursion needs to be limited by this library.
30 | # Choosing `sys.getrecursionlimit()` as maximum inline table/array nesting
31 | # level, as it allows more nesting than pure Python, but still seems a far
32 | # lower number than where mypyc binaries crash.
33 | MAX_INLINE_NESTING: Final = sys.getrecursionlimit()
34 | 
35 | ASCII_CTRL: Final = frozenset(chr(i) for i in range(32)) | frozenset(chr(127))
36 | 
37 | # Neither of these sets include quotation mark or backslash. They are
38 | # currently handled as separate cases in the parser functions.
39 | ILLEGAL_BASIC_STR_CHARS: Final = ASCII_CTRL - frozenset("\t")
40 | ILLEGAL_MULTILINE_BASIC_STR_CHARS: Final = ASCII_CTRL - frozenset("\t\n")
41 | 
42 | ILLEGAL_LITERAL_STR_CHARS: Final = ILLEGAL_BASIC_STR_CHARS
43 | ILLEGAL_MULTILINE_LITERAL_STR_CHARS: Final = ILLEGAL_MULTILINE_BASIC_STR_CHARS
44 | 
45 | ILLEGAL_COMMENT_CHARS: Final = ILLEGAL_BASIC_STR_CHARS
46 | 
47 | TOML_WS: Final = frozenset(" \t")
48 | TOML_WS_AND_NEWLINE: Final = TOML_WS | frozenset("\n")
49 | BARE_KEY_CHARS: Final = frozenset(string.ascii_letters + string.digits + "-_")
50 | KEY_INITIAL_CHARS: Final = BARE_KEY_CHARS | frozenset("\"'")
51 | HEXDIGIT_CHARS: Final = frozenset(string.hexdigits)
52 | 
53 | BASIC_STR_ESCAPE_REPLACEMENTS: Final = MappingProxyType(
54 |     {
55 |         "\\b": "\u0008",  # backspace
56 |         "\\t": "\u0009",  # tab
57 |         "\\n": "\u000A",  # linefeed
58 |         "\\f": "\u000C",  # form feed
59 |         "\\r": "\u000D",  # carriage return
60 |         '\\"': "\u0022",  # quote
61 |         "\\\\": "\u005C",  # backslash
62 |     }
63 | )
64 | 
65 | 
66 | class DEPRECATED_DEFAULT:
67 |     """Sentinel to be used as default arg during deprecation
68 |     period of TOMLDecodeError's free-form arguments."""
69 | 
70 | 
71 | class TOMLDecodeError(ValueError):
72 |     """An error raised if a document is not valid TOML.
73 | 
74 |     Adds the following attributes to ValueError:
75 |     msg: The unformatted error message
76 |     doc: The TOML document being parsed
77 |     pos: The index of doc where parsing failed
78 |     lineno: The line corresponding to pos
79 |     colno: The column corresponding to pos
80 |     """
81 | 
82 |     def __init__(
83 |         self,
84 |         msg: str | type[DEPRECATED_DEFAULT] = DEPRECATED_DEFAULT,
85 |         doc: str | type[DEPRECATED_DEFAULT] = DEPRECATED_DEFAULT,
86 |         pos: Pos | type[DEPRECATED_DEFAULT] = DEPRECATED_DEFAULT,
87 |         *args: Any,
88 |     ):
89 |         if (
90 |             args
91 |             or not isinstance(msg, str)
92 |             or not isinstance(doc, str)
93 |             or not isinstance(pos, int)
94 |         ):
95 |             warnings.warn(
96 |                 "Free-form arguments for TOMLDecodeError are deprecated. "
97 |                 "Please set 'msg' (str), 'doc' (str) and 'pos' (int) arguments only.",
98 |                 DeprecationWarning,
99 |                 stacklevel=2,
100 |             )
101 |             if pos is not DEPRECATED_DEFAULT:
102 |                 args = pos, *args
103 |             if doc is not DEPRECATED_DEFAULT:
104 |                 args = doc, *args
105 |             if msg is not DEPRECATED_DEFAULT:
106 |                 args = msg, *args
107 |             ValueError.__init__(self, *args)
108 |             return
109 | 
110 |         lineno = doc.count("\n", 0, pos) + 1
111 |         if lineno == 1:
112 |             colno = pos + 1
113 |         else:
114 |             colno = pos - doc.rindex("\n", 0, pos)
115 | 
116 |         if pos >= len(doc):
117 |             coord_repr = "end of document"
118 |         else:
119 |             coord_repr = f"line {lineno}, column {colno}"
120 |         errmsg = f"{msg} (at {coord_repr})"
121 |         ValueError.__init__(self, errmsg)
122 | 
123 |         self.msg = msg
124 |         self.doc = doc
125 |         self.pos = pos
126 |         self.lineno = lineno
127 |         self.colno = colno
128 | 
129 | 
130 | def load(__fp: IO[bytes], *, parse_float: ParseFloat = float) -> dict[str, Any]:
131 |     """Parse TOML from a binary file object."""
132 |     b = __fp.read()
133 |     try:
134 |         s = b.decode()
135 |     except AttributeError:
136 |         raise TypeError(
137 |             "File must be opened in binary mode, e.g. use `open('foo.toml', 'rb')`"
138 |         ) from None
139 |     return loads(s, parse_float=parse_float)
140 | 
141 | 
142 | def loads(__s: str, *, parse_float: ParseFloat = float) -> dict[str, Any]:  # noqa: C901
143 |     """Parse TOML from a string."""
144 | 
145 |     # The spec allows converting "\r\n" to "\n", even in string
146 |     # literals. Let's do so to simplify parsing.
147 |     try:
148 |         src = __s.replace("\r\n", "\n")
149 |     except (AttributeError, TypeError):
150 |         raise TypeError(
151 |             f"Expected str object, not '{type(__s).__qualname__}'"
152 |         ) from None
153 |     pos = 0
154 |     out = Output(NestedDict(), Flags())
155 |     header: Key = ()
156 |     parse_float = make_safe_parse_float(parse_float)
157 | 
158 |     # Parse one statement at a time
159 |     # (typically means one line in TOML source)
160 |     while True:
161 |         # 1. Skip line leading whitespace
162 |         pos = skip_chars(src, pos, TOML_WS)
163 | 
164 |         # 2. Parse rules. Expect one of the following:
165 |         #    - end of file
166 |         #    - end of line
167 |         #    - comment
168 |         #    - key/value pair
169 |         #    - append dict to list (and move to its namespace)
170 |         #    - create dict (and move to its namespace)
171 |         # Skip trailing whitespace when applicable.
172 |         try:
173 |             char = src[pos]
174 |         except IndexError:
175 |             break
176 |         if char == "\n":
177 |             pos += 1
178 |             continue
179 |         if char in KEY_INITIAL_CHARS:
180 |             pos = key_value_rule(src, pos, out, header, parse_float)
181 |             pos = skip_chars(src, pos, TOML_WS)
182 |         elif char == "[":
183 |             try:
184 |                 second_char: str | None = src[pos + 1]
185 |             except IndexError:
186 |                 second_char = None
187 |             out.flags.finalize_pending()
188 |             if second_char == "[":
189 |                 pos, header = create_list_rule(src, pos, out)
190 |             else:
191 |                 pos, header = create_dict_rule(src, pos, out)
192 |             pos = skip_chars(src, pos, TOML_WS)
193 |         elif char != "#":
194 |             raise TOMLDecodeError("Invalid statement", src, pos)
195 | 
196 |         # 3. Skip comment
197 |         pos = skip_comment(src, pos)
198 | 
199 |         # 4. Expect end of line or end of file
200 |         try:
201 |             char = src[pos]
202 |         except IndexError:
203 |             break
204 |         if char != "\n":
205 |             raise TOMLDecodeError(
206 |                 "Expected newline or end of document after a statement", src, pos
207 |             )
208 |         pos += 1
209 | 
210 |     return out.data.dict
211 | 
212 | 
213 | class Flags:
214 |     """Flags that map to parsed keys/namespaces."""
215 | 
216 |     # Marks an immutable namespace (inline array or inline table).
217 |     FROZEN: Final = 0
218 |     # Marks a nest that has been explicitly created and can no longer
219 |     # be opened using the "[table]" syntax.
220 |     EXPLICIT_NEST: Final = 1
221 | 
222 |     def __init__(self) -> None:
223 |         self._flags: dict[str, dict] = {}
224 |         self._pending_flags: set[tuple[Key, int]] = set()
225 | 
226 |     def add_pending(self, key: Key, flag: int) -> None:
227 |         self._pending_flags.add((key, flag))
228 | 
229 |     def finalize_pending(self) -> None:
230 |         for key, flag in self._pending_flags:
231 |             self.set(key, flag, recursive=False)
232 |         self._pending_flags.clear()
233 | 
234 |     def unset_all(self, key: Key) -> None:
235 |         cont = self._flags
236 |         for k in key[:-1]:
237 |             if k not in cont:
238 |                 return
239 |             cont = cont[k]["nested"]
240 |         cont.pop(key[-1], None)
241 | 
242 |     def set(self, key: Key, flag: int, *, recursive: bool) -> None:  # noqa: A003
243 |         cont = self._flags
244 |         key_parent, key_stem = key[:-1], key[-1]
245 |         for k in key_parent:
246 |             if k not in cont:
247 |                 cont[k] = {"flags": set(), "recursive_flags": set(), "nested": {}}
248 |             cont = cont[k]["nested"]
249 |         if key_stem not in cont:
250 |             cont[key_stem] = {"flags": set(), "recursive_flags": set(), "nested": {}}
251 |         cont[key_stem]["recursive_flags" if recursive else "flags"].add(flag)
252 | 
253 |     def is_(self, key: Key, flag: int) -> bool:
254 |         if not key:
255 |             return False  # document root has no flags
256 |         cont = self._flags
257 |         for k in key[:-1]:
258 |             if k not in cont:
259 |                 return False
260 |             inner_cont = cont[k]
261 |             if flag in inner_cont["recursive_flags"]:
262 |                 return True
263 |             cont = inner_cont["nested"]
264 |         key_stem = key[-1]
265 |         if key_stem in cont:
266 |             inner_cont = cont[key_stem]
267 |             return flag in inner_cont["flags"] or flag in inner_cont["recursive_flags"]
268 |         return False
269 | 
270 | 
271 | class NestedDict:
272 |     def __init__(self) -> None:
273 |         # The parsed content of the TOML document
274 |         self.dict: dict[str, Any] = {}
275 | 
276 |     def get_or_create_nest(
277 |         self,
278 |         key: Key,
279 |         *,
280 |         access_lists: bool = True,
281 |     ) -> dict:
282 |         cont: Any = self.dict
283 |         for k in key:
284 |             if k not in cont:
285 |                 cont[k] = {}
286 |             cont = cont[k]
287 |             if access_lists and isinstance(cont, list):
288 |                 cont = cont[-1]
289 |             if not isinstance(cont, dict):
290 |                 raise KeyError("There is no nest behind this key")
291 |         return cont
292 | 
293 |     def append_nest_to_list(self, key: Key) -> None:
294 |         cont = self.get_or_create_nest(key[:-1])
295 |         last_key = key[-1]
296 |         if last_key in cont:
297 |             list_ = cont[last_key]
298 |             if not isinstance(list_, list):
299 |                 raise KeyError("An object other than list found behind this key")
300 |             list_.append({})
301 |         else:
302 |             cont[last_key] = [{}]
303 | 
304 | 
305 | class Output(NamedTuple):
306 |     data: NestedDict
307 |     flags: Flags
308 | 
309 | 
310 | def skip_chars(src: str, pos: Pos, chars: Iterable[str]) -> Pos:
311 |     try:
312 |         while src[pos] in chars:
313 |             pos += 1
314 |     except IndexError:
315 |         pass
316 |     return pos
317 | 
318 | 
319 | def skip_until(
320 |     src: str,
321 |     pos: Pos,
322 |     expect: str,
323 |     *,
324 |     error_on: frozenset[str],
325 |     error_on_eof: bool,
326 | ) -> Pos:
327 |     try:
328 |         new_pos = src.index(expect, pos)
329 |     except ValueError:
330 |         new_pos = len(src)
331 |         if error_on_eof:
332 |             raise TOMLDecodeError(f"Expected {expect!r}", src, new_pos) from None
333 | 
334 |     if not error_on.isdisjoint(src[pos:new_pos]):
335 |         while src[pos] not in error_on:
336 |             pos += 1
337 |         raise TOMLDecodeError(f"Found invalid character {src[pos]!r}", src, pos)
338 |     return new_pos
339 | 
340 | 
341 | def skip_comment(src: str, pos: Pos) -> Pos:
342 |     try:
343 |         char: str | None = src[pos]
344 |     except IndexError:
345 |         char = None
346 |     if char == "#":
347 |         return skip_until(
348 |             src, pos + 1, "\n", error_on=ILLEGAL_COMMENT_CHARS, error_on_eof=False
349 |         )
350 |     return pos
351 | 
352 | 
[TRUNCATED]
```

.venv/lib/python3.13/site-packages/pip/_vendor/tomli/_re.py
```
1 | # SPDX-License-Identifier: MIT
2 | # SPDX-FileCopyrightText: 2021 Taneli Hukkinen
3 | # Licensed to PSF under a Contributor Agreement.
4 | 
5 | from __future__ import annotations
6 | 
7 | from datetime import date, datetime, time, timedelta, timezone, tzinfo
8 | from functools import lru_cache
9 | import re
10 | from typing import Any, Final
11 | 
12 | from ._types import ParseFloat
13 | 
14 | # E.g.
15 | # - 00:32:00.999999
16 | # - 00:32:00
17 | _TIME_RE_STR: Final = (
18 |     r"([01][0-9]|2[0-3]):([0-5][0-9]):([0-5][0-9])(?:\.([0-9]{1,6})[0-9]*)?"
19 | )
20 | 
21 | RE_NUMBER: Final = re.compile(
22 |     r"""
23 | 0
24 | (?:
25 |     x[0-9A-Fa-f](?:_?[0-9A-Fa-f])*   # hex
26 |     |
27 |     b[01](?:_?[01])*                 # bin
28 |     |
29 |     o[0-7](?:_?[0-7])*               # oct
30 | )
31 | |
32 | [+-]?(?:0|[1-9](?:_?[0-9])*)         # dec, integer part
33 | (?P<floatpart>
34 |     (?:\.[0-9](?:_?[0-9])*)?         # optional fractional part
35 |     (?:[eE][+-]?[0-9](?:_?[0-9])*)?  # optional exponent part
36 | )
37 | """,
38 |     flags=re.VERBOSE,
39 | )
40 | RE_LOCALTIME: Final = re.compile(_TIME_RE_STR)
41 | RE_DATETIME: Final = re.compile(
42 |     rf"""
43 | ([0-9]{{4}})-(0[1-9]|1[0-2])-(0[1-9]|[12][0-9]|3[01])  # date, e.g. 1988-10-27
44 | (?:
45 |     [Tt ]
46 |     {_TIME_RE_STR}
47 |     (?:([Zz])|([+-])([01][0-9]|2[0-3]):([0-5][0-9]))?  # optional time offset
48 | )?
49 | """,
50 |     flags=re.VERBOSE,
51 | )
52 | 
53 | 
54 | def match_to_datetime(match: re.Match) -> datetime | date:
55 |     """Convert a `RE_DATETIME` match to `datetime.datetime` or `datetime.date`.
56 | 
57 |     Raises ValueError if the match does not correspond to a valid date
58 |     or datetime.
59 |     """
60 |     (
61 |         year_str,
62 |         month_str,
63 |         day_str,
64 |         hour_str,
65 |         minute_str,
66 |         sec_str,
67 |         micros_str,
68 |         zulu_time,
69 |         offset_sign_str,
70 |         offset_hour_str,
71 |         offset_minute_str,
72 |     ) = match.groups()
73 |     year, month, day = int(year_str), int(month_str), int(day_str)
74 |     if hour_str is None:
75 |         return date(year, month, day)
76 |     hour, minute, sec = int(hour_str), int(minute_str), int(sec_str)
77 |     micros = int(micros_str.ljust(6, "0")) if micros_str else 0
78 |     if offset_sign_str:
79 |         tz: tzinfo | None = cached_tz(
80 |             offset_hour_str, offset_minute_str, offset_sign_str
81 |         )
82 |     elif zulu_time:
83 |         tz = timezone.utc
84 |     else:  # local date-time
85 |         tz = None
86 |     return datetime(year, month, day, hour, minute, sec, micros, tzinfo=tz)
87 | 
88 | 
89 | # No need to limit cache size. This is only ever called on input
90 | # that matched RE_DATETIME, so there is an implicit bound of
91 | # 24 (hours) * 60 (minutes) * 2 (offset direction) = 2880.
92 | @lru_cache(maxsize=None)
93 | def cached_tz(hour_str: str, minute_str: str, sign_str: str) -> timezone:
94 |     sign = 1 if sign_str == "+" else -1
95 |     return timezone(
96 |         timedelta(
97 |             hours=sign * int(hour_str),
98 |             minutes=sign * int(minute_str),
99 |         )
100 |     )
101 | 
102 | 
103 | def match_to_localtime(match: re.Match) -> time:
104 |     hour_str, minute_str, sec_str, micros_str = match.groups()
105 |     micros = int(micros_str.ljust(6, "0")) if micros_str else 0
106 |     return time(int(hour_str), int(minute_str), int(sec_str), micros)
107 | 
108 | 
109 | def match_to_number(match: re.Match, parse_float: ParseFloat) -> Any:
110 |     if match.group("floatpart"):
111 |         return parse_float(match.group())
112 |     return int(match.group(), 0)
```

.venv/lib/python3.13/site-packages/pip/_vendor/tomli/_types.py
```
1 | # SPDX-License-Identifier: MIT
2 | # SPDX-FileCopyrightText: 2021 Taneli Hukkinen
3 | # Licensed to PSF under a Contributor Agreement.
4 | 
5 | from typing import Any, Callable, Tuple
6 | 
7 | # Type annotations
8 | ParseFloat = Callable[[str], Any]
9 | Key = Tuple[str, ...]
10 | Pos = int
```

.venv/lib/python3.13/site-packages/pip/_vendor/tomli/py.typed
```
1 | # Marker file for PEP 561
```

.venv/lib/python3.13/site-packages/pip/_vendor/tomli_w/__init__.py
```
1 | __all__ = ("dumps", "dump")
2 | __version__ = "1.2.0"  # DO NOT EDIT THIS LINE MANUALLY. LET bump2version UTILITY DO IT
3 | 
4 | from pip._vendor.tomli_w._writer import dump, dumps
```

.venv/lib/python3.13/site-packages/pip/_vendor/tomli_w/_writer.py
```
1 | from __future__ import annotations
2 | 
3 | from collections.abc import Mapping
4 | from datetime import date, datetime, time
5 | from types import MappingProxyType
6 | 
7 | TYPE_CHECKING = False
8 | if TYPE_CHECKING:
9 |     from collections.abc import Generator
10 |     from decimal import Decimal
11 |     from typing import IO, Any, Final
12 | 
13 | ASCII_CTRL = frozenset(chr(i) for i in range(32)) | frozenset(chr(127))
14 | ILLEGAL_BASIC_STR_CHARS = frozenset('"\\') | ASCII_CTRL - frozenset("\t")
15 | BARE_KEY_CHARS = frozenset(
16 |     "abcdefghijklmnopqrstuvwxyz" "ABCDEFGHIJKLMNOPQRSTUVWXYZ" "0123456789" "-_"
17 | )
18 | ARRAY_TYPES = (list, tuple)
19 | MAX_LINE_LENGTH = 100
20 | 
21 | COMPACT_ESCAPES = MappingProxyType(
22 |     {
23 |         "\u0008": "\\b",  # backspace
24 |         "\u000A": "\\n",  # linefeed
25 |         "\u000C": "\\f",  # form feed
26 |         "\u000D": "\\r",  # carriage return
27 |         "\u0022": '\\"',  # quote
28 |         "\u005C": "\\\\",  # backslash
29 |     }
30 | )
31 | 
32 | 
33 | class Context:
34 |     def __init__(self, allow_multiline: bool, indent: int):
35 |         if indent < 0:
36 |             raise ValueError("Indent width must be non-negative")
37 |         self.allow_multiline: Final = allow_multiline
38 |         # cache rendered inline tables (mapping from object id to rendered inline table)
39 |         self.inline_table_cache: Final[dict[int, str]] = {}
40 |         self.indent_str: Final = " " * indent
41 | 
42 | 
43 | def dump(
44 |     obj: Mapping[str, Any],
45 |     fp: IO[bytes],
46 |     /,
47 |     *,
48 |     multiline_strings: bool = False,
49 |     indent: int = 4,
50 | ) -> None:
51 |     ctx = Context(multiline_strings, indent)
52 |     for chunk in gen_table_chunks(obj, ctx, name=""):
53 |         fp.write(chunk.encode())
54 | 
55 | 
56 | def dumps(
57 |     obj: Mapping[str, Any], /, *, multiline_strings: bool = False, indent: int = 4
58 | ) -> str:
59 |     ctx = Context(multiline_strings, indent)
60 |     return "".join(gen_table_chunks(obj, ctx, name=""))
61 | 
62 | 
63 | def gen_table_chunks(
64 |     table: Mapping[str, Any],
65 |     ctx: Context,
66 |     *,
67 |     name: str,
68 |     inside_aot: bool = False,
69 | ) -> Generator[str, None, None]:
70 |     yielded = False
71 |     literals = []
72 |     tables: list[tuple[str, Any, bool]] = []  # => [(key, value, inside_aot)]
73 |     for k, v in table.items():
74 |         if isinstance(v, Mapping):
75 |             tables.append((k, v, False))
76 |         elif is_aot(v) and not all(is_suitable_inline_table(t, ctx) for t in v):
77 |             tables.extend((k, t, True) for t in v)
78 |         else:
79 |             literals.append((k, v))
80 | 
81 |     if inside_aot or name and (literals or not tables):
82 |         yielded = True
83 |         yield f"[[{name}]]\n" if inside_aot else f"[{name}]\n"
84 | 
85 |     if literals:
86 |         yielded = True
87 |         for k, v in literals:
88 |             yield f"{format_key_part(k)} = {format_literal(v, ctx)}\n"
89 | 
90 |     for k, v, in_aot in tables:
91 |         if yielded:
92 |             yield "\n"
93 |         else:
94 |             yielded = True
95 |         key_part = format_key_part(k)
96 |         display_name = f"{name}.{key_part}" if name else key_part
97 |         yield from gen_table_chunks(v, ctx, name=display_name, inside_aot=in_aot)
98 | 
99 | 
100 | def format_literal(obj: object, ctx: Context, *, nest_level: int = 0) -> str:
101 |     if isinstance(obj, bool):
102 |         return "true" if obj else "false"
103 |     if isinstance(obj, (int, float, date, datetime)):
104 |         return str(obj)
105 |     if isinstance(obj, time):
106 |         if obj.tzinfo:
107 |             raise ValueError("TOML does not support offset times")
108 |         return str(obj)
109 |     if isinstance(obj, str):
110 |         return format_string(obj, allow_multiline=ctx.allow_multiline)
111 |     if isinstance(obj, ARRAY_TYPES):
112 |         return format_inline_array(obj, ctx, nest_level)
113 |     if isinstance(obj, Mapping):
114 |         return format_inline_table(obj, ctx)
115 | 
116 |     # Lazy import to improve module import time
117 |     from decimal import Decimal
118 | 
119 |     if isinstance(obj, Decimal):
120 |         return format_decimal(obj)
121 |     raise TypeError(
122 |         f"Object of type '{type(obj).__qualname__}' is not TOML serializable"
123 |     )
124 | 
125 | 
126 | def format_decimal(obj: Decimal) -> str:
127 |     if obj.is_nan():
128 |         return "nan"
129 |     if obj.is_infinite():
130 |         return "-inf" if obj.is_signed() else "inf"
131 |     dec_str = str(obj).lower()
132 |     return dec_str if "." in dec_str or "e" in dec_str else dec_str + ".0"
133 | 
134 | 
135 | def format_inline_table(obj: Mapping, ctx: Context) -> str:
136 |     # check cache first
137 |     obj_id = id(obj)
138 |     if obj_id in ctx.inline_table_cache:
139 |         return ctx.inline_table_cache[obj_id]
140 | 
141 |     if not obj:
142 |         rendered = "{}"
143 |     else:
144 |         rendered = (
145 |             "{ "
146 |             + ", ".join(
147 |                 f"{format_key_part(k)} = {format_literal(v, ctx)}"
148 |                 for k, v in obj.items()
149 |             )
150 |             + " }"
151 |         )
152 |     ctx.inline_table_cache[obj_id] = rendered
153 |     return rendered
154 | 
155 | 
156 | def format_inline_array(obj: tuple | list, ctx: Context, nest_level: int) -> str:
157 |     if not obj:
158 |         return "[]"
159 |     item_indent = ctx.indent_str * (1 + nest_level)
160 |     closing_bracket_indent = ctx.indent_str * nest_level
161 |     return (
162 |         "[\n"
163 |         + ",\n".join(
164 |             item_indent + format_literal(item, ctx, nest_level=nest_level + 1)
165 |             for item in obj
166 |         )
167 |         + f",\n{closing_bracket_indent}]"
168 |     )
169 | 
170 | 
171 | def format_key_part(part: str) -> str:
172 |     try:
173 |         only_bare_key_chars = BARE_KEY_CHARS.issuperset(part)
174 |     except TypeError:
175 |         raise TypeError(
176 |             f"Invalid mapping key '{part}' of type '{type(part).__qualname__}'."
177 |             " A string is required."
178 |         ) from None
179 | 
180 |     if part and only_bare_key_chars:
181 |         return part
182 |     return format_string(part, allow_multiline=False)
183 | 
184 | 
185 | def format_string(s: str, *, allow_multiline: bool) -> str:
186 |     do_multiline = allow_multiline and "\n" in s
187 |     if do_multiline:
188 |         result = '"""\n'
189 |         s = s.replace("\r\n", "\n")
190 |     else:
191 |         result = '"'
192 | 
193 |     pos = seq_start = 0
194 |     while True:
195 |         try:
196 |             char = s[pos]
197 |         except IndexError:
198 |             result += s[seq_start:pos]
199 |             if do_multiline:
200 |                 return result + '"""'
201 |             return result + '"'
202 |         if char in ILLEGAL_BASIC_STR_CHARS:
203 |             result += s[seq_start:pos]
204 |             if char in COMPACT_ESCAPES:
205 |                 if do_multiline and char == "\n":
206 |                     result += "\n"
207 |                 else:
208 |                     result += COMPACT_ESCAPES[char]
209 |             else:
210 |                 result += "\\u" + hex(ord(char))[2:].rjust(4, "0")
211 |             seq_start = pos + 1
212 |         pos += 1
213 | 
214 | 
215 | def is_aot(obj: Any) -> bool:
216 |     """Decides if an object behaves as an array of tables (i.e. a nonempty list
217 |     of dicts)."""
218 |     return bool(
219 |         isinstance(obj, ARRAY_TYPES)
220 |         and obj
221 |         and all(isinstance(v, Mapping) for v in obj)
222 |     )
223 | 
224 | 
225 | def is_suitable_inline_table(obj: Mapping, ctx: Context) -> bool:
226 |     """Use heuristics to decide if the inline-style representation is a good
227 |     choice for a given table."""
228 |     rendered_inline = f"{ctx.indent_str}{format_inline_table(obj, ctx)},"
229 |     return len(rendered_inline) <= MAX_LINE_LENGTH and "\n" not in rendered_inline
```

.venv/lib/python3.13/site-packages/pip/_vendor/tomli_w/py.typed
```
1 | # Marker file for PEP 561
```

.venv/lib/python3.13/site-packages/pip/_vendor/truststore/__init__.py
```
1 | """Verify certificates using native system trust stores"""
2 | 
3 | import sys as _sys
4 | 
5 | if _sys.version_info < (3, 10):
6 |     raise ImportError("truststore requires Python 3.10 or later")
7 | 
8 | # Detect Python runtimes which don't implement SSLObject.get_unverified_chain() API
9 | # This API only became public in Python 3.13 but was available in CPython and PyPy since 3.10.
10 | if _sys.version_info < (3, 13) and _sys.implementation.name not in ("cpython", "pypy"):
11 |     try:
12 |         import ssl as _ssl
13 |     except ImportError:
14 |         raise ImportError("truststore requires the 'ssl' module")
15 |     else:
16 |         _sslmem = _ssl.MemoryBIO()
17 |         _sslobj = _ssl.create_default_context().wrap_bio(
18 |             _sslmem,
19 |             _sslmem,
20 |         )
21 |         try:
22 |             while not hasattr(_sslobj, "get_unverified_chain"):
23 |                 _sslobj = _sslobj._sslobj  # type: ignore[attr-defined]
24 |         except AttributeError:
25 |             raise ImportError(
26 |                 "truststore requires peer certificate chain APIs to be available"
27 |             ) from None
28 | 
29 |         del _ssl, _sslobj, _sslmem  # noqa: F821
30 | 
31 | from ._api import SSLContext, extract_from_ssl, inject_into_ssl  # noqa: E402
32 | 
33 | del _api, _sys  # type: ignore[name-defined] # noqa: F821
34 | 
35 | __all__ = ["SSLContext", "inject_into_ssl", "extract_from_ssl"]
36 | __version__ = "0.10.1"
```

.venv/lib/python3.13/site-packages/pip/_vendor/truststore/_api.py
```
1 | import os
2 | import platform
3 | import socket
4 | import ssl
5 | import sys
6 | import typing
7 | 
8 | import _ssl
9 | 
10 | from ._ssl_constants import (
11 |     _original_SSLContext,
12 |     _original_super_SSLContext,
13 |     _truststore_SSLContext_dunder_class,
14 |     _truststore_SSLContext_super_class,
15 | )
16 | 
17 | if platform.system() == "Windows":
18 |     from ._windows import _configure_context, _verify_peercerts_impl
19 | elif platform.system() == "Darwin":
20 |     from ._macos import _configure_context, _verify_peercerts_impl
21 | else:
22 |     from ._openssl import _configure_context, _verify_peercerts_impl
23 | 
24 | if typing.TYPE_CHECKING:
25 |     from pip._vendor.typing_extensions import Buffer
26 | 
27 | # From typeshed/stdlib/ssl.pyi
28 | _StrOrBytesPath: typing.TypeAlias = str | bytes | os.PathLike[str] | os.PathLike[bytes]
29 | _PasswordType: typing.TypeAlias = str | bytes | typing.Callable[[], str | bytes]
30 | 
31 | 
32 | def inject_into_ssl() -> None:
33 |     """Injects the :class:`truststore.SSLContext` into the ``ssl``
34 |     module by replacing :class:`ssl.SSLContext`.
35 |     """
36 |     setattr(ssl, "SSLContext", SSLContext)
37 |     # urllib3 holds on to its own reference of ssl.SSLContext
38 |     # so we need to replace that reference too.
39 |     try:
40 |         import pip._vendor.urllib3.util.ssl_ as urllib3_ssl
41 | 
42 |         setattr(urllib3_ssl, "SSLContext", SSLContext)
43 |     except ImportError:
44 |         pass
45 | 
46 |     # requests starting with 2.32.0 added a preloaded SSL context to improve concurrent performance;
47 |     # this unfortunately leads to a RecursionError, which can be avoided by patching the preloaded SSL context with
48 |     # the truststore patched instance
49 |     # also see https://github.com/psf/requests/pull/6667
50 |     try:
51 |         from pip._vendor.requests import adapters as requests_adapters
52 | 
53 |         preloaded_context = getattr(requests_adapters, "_preloaded_ssl_context", None)
54 |         if preloaded_context is not None:
55 |             setattr(
56 |                 requests_adapters,
57 |                 "_preloaded_ssl_context",
58 |                 SSLContext(ssl.PROTOCOL_TLS_CLIENT),
59 |             )
60 |     except ImportError:
61 |         pass
62 | 
63 | 
64 | def extract_from_ssl() -> None:
65 |     """Restores the :class:`ssl.SSLContext` class to its original state"""
66 |     setattr(ssl, "SSLContext", _original_SSLContext)
67 |     try:
68 |         import pip._vendor.urllib3.util.ssl_ as urllib3_ssl
69 | 
70 |         urllib3_ssl.SSLContext = _original_SSLContext  # type: ignore[assignment]
71 |     except ImportError:
72 |         pass
73 | 
74 | 
75 | class SSLContext(_truststore_SSLContext_super_class):  # type: ignore[misc]
76 |     """SSLContext API that uses system certificates on all platforms"""
77 | 
78 |     @property  # type: ignore[misc]
79 |     def __class__(self) -> type:
80 |         # Dirty hack to get around isinstance() checks
81 |         # for ssl.SSLContext instances in aiohttp/trustme
82 |         # when using non-CPython implementations.
83 |         return _truststore_SSLContext_dunder_class or SSLContext
84 | 
85 |     def __init__(self, protocol: int = None) -> None:  # type: ignore[assignment]
86 |         self._ctx = _original_SSLContext(protocol)
87 | 
88 |         class TruststoreSSLObject(ssl.SSLObject):
89 |             # This object exists because wrap_bio() doesn't
90 |             # immediately do the handshake so we need to do
91 |             # certificate verifications after SSLObject.do_handshake()
92 | 
93 |             def do_handshake(self) -> None:
94 |                 ret = super().do_handshake()
95 |                 _verify_peercerts(self, server_hostname=self.server_hostname)
96 |                 return ret
97 | 
98 |         self._ctx.sslobject_class = TruststoreSSLObject
99 | 
100 |     def wrap_socket(
101 |         self,
102 |         sock: socket.socket,
103 |         server_side: bool = False,
104 |         do_handshake_on_connect: bool = True,
105 |         suppress_ragged_eofs: bool = True,
106 |         server_hostname: str | None = None,
107 |         session: ssl.SSLSession | None = None,
108 |     ) -> ssl.SSLSocket:
109 |         # Use a context manager here because the
110 |         # inner SSLContext holds on to our state
111 |         # but also does the actual handshake.
112 |         with _configure_context(self._ctx):
113 |             ssl_sock = self._ctx.wrap_socket(
114 |                 sock,
115 |                 server_side=server_side,
116 |                 server_hostname=server_hostname,
117 |                 do_handshake_on_connect=do_handshake_on_connect,
118 |                 suppress_ragged_eofs=suppress_ragged_eofs,
119 |                 session=session,
120 |             )
121 |         try:
122 |             _verify_peercerts(ssl_sock, server_hostname=server_hostname)
123 |         except Exception:
124 |             ssl_sock.close()
125 |             raise
126 |         return ssl_sock
127 | 
128 |     def wrap_bio(
129 |         self,
130 |         incoming: ssl.MemoryBIO,
131 |         outgoing: ssl.MemoryBIO,
132 |         server_side: bool = False,
133 |         server_hostname: str | None = None,
134 |         session: ssl.SSLSession | None = None,
135 |     ) -> ssl.SSLObject:
136 |         with _configure_context(self._ctx):
137 |             ssl_obj = self._ctx.wrap_bio(
138 |                 incoming,
139 |                 outgoing,
140 |                 server_hostname=server_hostname,
141 |                 server_side=server_side,
142 |                 session=session,
143 |             )
144 |         return ssl_obj
145 | 
146 |     def load_verify_locations(
147 |         self,
148 |         cafile: str | bytes | os.PathLike[str] | os.PathLike[bytes] | None = None,
149 |         capath: str | bytes | os.PathLike[str] | os.PathLike[bytes] | None = None,
150 |         cadata: typing.Union[str, "Buffer", None] = None,
151 |     ) -> None:
152 |         return self._ctx.load_verify_locations(
153 |             cafile=cafile, capath=capath, cadata=cadata
154 |         )
155 | 
156 |     def load_cert_chain(
157 |         self,
158 |         certfile: _StrOrBytesPath,
159 |         keyfile: _StrOrBytesPath | None = None,
160 |         password: _PasswordType | None = None,
161 |     ) -> None:
162 |         return self._ctx.load_cert_chain(
163 |             certfile=certfile, keyfile=keyfile, password=password
164 |         )
165 | 
166 |     def load_default_certs(
167 |         self, purpose: ssl.Purpose = ssl.Purpose.SERVER_AUTH
168 |     ) -> None:
169 |         return self._ctx.load_default_certs(purpose)
170 | 
171 |     def set_alpn_protocols(self, alpn_protocols: typing.Iterable[str]) -> None:
172 |         return self._ctx.set_alpn_protocols(alpn_protocols)
173 | 
174 |     def set_npn_protocols(self, npn_protocols: typing.Iterable[str]) -> None:
175 |         return self._ctx.set_npn_protocols(npn_protocols)
176 | 
177 |     def set_ciphers(self, __cipherlist: str) -> None:
178 |         return self._ctx.set_ciphers(__cipherlist)
179 | 
180 |     def get_ciphers(self) -> typing.Any:
181 |         return self._ctx.get_ciphers()
182 | 
183 |     def session_stats(self) -> dict[str, int]:
184 |         return self._ctx.session_stats()
185 | 
186 |     def cert_store_stats(self) -> dict[str, int]:
187 |         raise NotImplementedError()
188 | 
189 |     def set_default_verify_paths(self) -> None:
190 |         self._ctx.set_default_verify_paths()
191 | 
192 |     @typing.overload
193 |     def get_ca_certs(
194 |         self, binary_form: typing.Literal[False] = ...
195 |     ) -> list[typing.Any]: ...
196 | 
197 |     @typing.overload
198 |     def get_ca_certs(self, binary_form: typing.Literal[True] = ...) -> list[bytes]: ...
199 | 
200 |     @typing.overload
201 |     def get_ca_certs(self, binary_form: bool = ...) -> typing.Any: ...
202 | 
203 |     def get_ca_certs(self, binary_form: bool = False) -> list[typing.Any] | list[bytes]:
204 |         raise NotImplementedError()
205 | 
206 |     @property
207 |     def check_hostname(self) -> bool:
208 |         return self._ctx.check_hostname
209 | 
210 |     @check_hostname.setter
211 |     def check_hostname(self, value: bool) -> None:
212 |         self._ctx.check_hostname = value
213 | 
214 |     @property
215 |     def hostname_checks_common_name(self) -> bool:
216 |         return self._ctx.hostname_checks_common_name
217 | 
218 |     @hostname_checks_common_name.setter
219 |     def hostname_checks_common_name(self, value: bool) -> None:
220 |         self._ctx.hostname_checks_common_name = value
221 | 
222 |     @property
223 |     def keylog_filename(self) -> str:
224 |         return self._ctx.keylog_filename
225 | 
226 |     @keylog_filename.setter
227 |     def keylog_filename(self, value: str) -> None:
228 |         self._ctx.keylog_filename = value
229 | 
230 |     @property
231 |     def maximum_version(self) -> ssl.TLSVersion:
232 |         return self._ctx.maximum_version
233 | 
234 |     @maximum_version.setter
235 |     def maximum_version(self, value: ssl.TLSVersion) -> None:
236 |         _original_super_SSLContext.maximum_version.__set__(  # type: ignore[attr-defined]
237 |             self._ctx, value
238 |         )
239 | 
240 |     @property
241 |     def minimum_version(self) -> ssl.TLSVersion:
242 |         return self._ctx.minimum_version
243 | 
244 |     @minimum_version.setter
245 |     def minimum_version(self, value: ssl.TLSVersion) -> None:
246 |         _original_super_SSLContext.minimum_version.__set__(  # type: ignore[attr-defined]
247 |             self._ctx, value
248 |         )
249 | 
250 |     @property
251 |     def options(self) -> ssl.Options:
252 |         return self._ctx.options
253 | 
254 |     @options.setter
255 |     def options(self, value: ssl.Options) -> None:
256 |         _original_super_SSLContext.options.__set__(  # type: ignore[attr-defined]
257 |             self._ctx, value
258 |         )
259 | 
260 |     @property
261 |     def post_handshake_auth(self) -> bool:
262 |         return self._ctx.post_handshake_auth
263 | 
264 |     @post_handshake_auth.setter
265 |     def post_handshake_auth(self, value: bool) -> None:
266 |         self._ctx.post_handshake_auth = value
267 | 
268 |     @property
269 |     def protocol(self) -> ssl._SSLMethod:
270 |         return self._ctx.protocol
271 | 
272 |     @property
273 |     def security_level(self) -> int:
274 |         return self._ctx.security_level
275 | 
276 |     @property
277 |     def verify_flags(self) -> ssl.VerifyFlags:
278 |         return self._ctx.verify_flags
279 | 
280 |     @verify_flags.setter
281 |     def verify_flags(self, value: ssl.VerifyFlags) -> None:
282 |         _original_super_SSLContext.verify_flags.__set__(  # type: ignore[attr-defined]
283 |             self._ctx, value
284 |         )
285 | 
286 |     @property
287 |     def verify_mode(self) -> ssl.VerifyMode:
288 |         return self._ctx.verify_mode
289 | 
290 |     @verify_mode.setter
291 |     def verify_mode(self, value: ssl.VerifyMode) -> None:
292 |         _original_super_SSLContext.verify_mode.__set__(  # type: ignore[attr-defined]
293 |             self._ctx, value
294 |         )
295 | 
296 | 
297 | # Python 3.13+ makes get_unverified_chain() a public API that only returns DER
298 | # encoded certificates. We detect whether we need to call public_bytes() for 3.10->3.12
299 | # Pre-3.13 returned None instead of an empty list from get_unverified_chain()
300 | if sys.version_info >= (3, 13):
301 | 
302 |     def _get_unverified_chain_bytes(sslobj: ssl.SSLObject) -> list[bytes]:
303 |         unverified_chain = sslobj.get_unverified_chain() or ()  # type: ignore[attr-defined]
304 |         return [
305 |             cert if isinstance(cert, bytes) else cert.public_bytes(_ssl.ENCODING_DER)
306 |             for cert in unverified_chain
307 |         ]
308 | 
309 | else:
310 | 
311 |     def _get_unverified_chain_bytes(sslobj: ssl.SSLObject) -> list[bytes]:
312 |         unverified_chain = sslobj.get_unverified_chain() or ()  # type: ignore[attr-defined]
313 |         return [cert.public_bytes(_ssl.ENCODING_DER) for cert in unverified_chain]
314 | 
315 | 
316 | def _verify_peercerts(
317 |     sock_or_sslobj: ssl.SSLSocket | ssl.SSLObject, server_hostname: str | None
318 | ) -> None:
319 |     """
320 |     Verifies the peer certificates from an SSLSocket or SSLObject
321 |     against the certificates in the OS trust store.
322 |     """
323 |     sslobj: ssl.SSLObject = sock_or_sslobj  # type: ignore[assignment]
324 |     try:
325 |         while not hasattr(sslobj, "get_unverified_chain"):
326 |             sslobj = sslobj._sslobj  # type: ignore[attr-defined]
327 |     except AttributeError:
328 |         pass
329 | 
330 |     cert_bytes = _get_unverified_chain_bytes(sslobj)
331 |     _verify_peercerts_impl(
332 |         sock_or_sslobj.context, cert_bytes, server_hostname=server_hostname
333 |     )
```

.venv/lib/python3.13/site-packages/pip/_vendor/truststore/_macos.py
```
1 | import contextlib
2 | import ctypes
3 | import platform
4 | import ssl
5 | import typing
6 | from ctypes import (
7 |     CDLL,
8 |     POINTER,
9 |     c_bool,
10 |     c_char_p,
11 |     c_int32,
12 |     c_long,
13 |     c_uint32,
14 |     c_ulong,
15 |     c_void_p,
16 | )
17 | from ctypes.util import find_library
18 | 
19 | from ._ssl_constants import _set_ssl_context_verify_mode
20 | 
21 | _mac_version = platform.mac_ver()[0]
22 | _mac_version_info = tuple(map(int, _mac_version.split(".")))
23 | if _mac_version_info < (10, 8):
24 |     raise ImportError(
25 |         f"Only OS X 10.8 and newer are supported, not {_mac_version_info[0]}.{_mac_version_info[1]}"
26 |     )
27 | 
28 | _is_macos_version_10_14_or_later = _mac_version_info >= (10, 14)
29 | 
30 | 
31 | def _load_cdll(name: str, macos10_16_path: str) -> CDLL:
32 |     """Loads a CDLL by name, falling back to known path on 10.16+"""
33 |     try:
34 |         # Big Sur is technically 11 but we use 10.16 due to the Big Sur
35 |         # beta being labeled as 10.16.
36 |         path: str | None
37 |         if _mac_version_info >= (10, 16):
38 |             path = macos10_16_path
39 |         else:
40 |             path = find_library(name)
41 |         if not path:
42 |             raise OSError  # Caught and reraised as 'ImportError'
43 |         return CDLL(path, use_errno=True)
44 |     except OSError:
45 |         raise ImportError(f"The library {name} failed to load") from None
46 | 
47 | 
48 | Security = _load_cdll(
49 |     "Security", "/System/Library/Frameworks/Security.framework/Security"
50 | )
51 | CoreFoundation = _load_cdll(
52 |     "CoreFoundation",
53 |     "/System/Library/Frameworks/CoreFoundation.framework/CoreFoundation",
54 | )
55 | 
56 | Boolean = c_bool
57 | CFIndex = c_long
58 | CFStringEncoding = c_uint32
59 | CFData = c_void_p
60 | CFString = c_void_p
61 | CFArray = c_void_p
62 | CFMutableArray = c_void_p
63 | CFError = c_void_p
64 | CFType = c_void_p
65 | CFTypeID = c_ulong
66 | CFTypeRef = POINTER(CFType)
67 | CFAllocatorRef = c_void_p
68 | 
69 | OSStatus = c_int32
70 | 
71 | CFErrorRef = POINTER(CFError)
72 | CFDataRef = POINTER(CFData)
73 | CFStringRef = POINTER(CFString)
74 | CFArrayRef = POINTER(CFArray)
75 | CFMutableArrayRef = POINTER(CFMutableArray)
76 | CFArrayCallBacks = c_void_p
77 | CFOptionFlags = c_uint32
78 | 
79 | SecCertificateRef = POINTER(c_void_p)
80 | SecPolicyRef = POINTER(c_void_p)
81 | SecTrustRef = POINTER(c_void_p)
82 | SecTrustResultType = c_uint32
83 | SecTrustOptionFlags = c_uint32
84 | 
85 | try:
86 |     Security.SecCertificateCreateWithData.argtypes = [CFAllocatorRef, CFDataRef]
87 |     Security.SecCertificateCreateWithData.restype = SecCertificateRef
88 | 
89 |     Security.SecCertificateCopyData.argtypes = [SecCertificateRef]
90 |     Security.SecCertificateCopyData.restype = CFDataRef
91 | 
92 |     Security.SecCopyErrorMessageString.argtypes = [OSStatus, c_void_p]
93 |     Security.SecCopyErrorMessageString.restype = CFStringRef
94 | 
95 |     Security.SecTrustSetAnchorCertificates.argtypes = [SecTrustRef, CFArrayRef]
96 |     Security.SecTrustSetAnchorCertificates.restype = OSStatus
97 | 
98 |     Security.SecTrustSetAnchorCertificatesOnly.argtypes = [SecTrustRef, Boolean]
99 |     Security.SecTrustSetAnchorCertificatesOnly.restype = OSStatus
100 | 
101 |     Security.SecPolicyCreateRevocation.argtypes = [CFOptionFlags]
102 |     Security.SecPolicyCreateRevocation.restype = SecPolicyRef
103 | 
104 |     Security.SecPolicyCreateSSL.argtypes = [Boolean, CFStringRef]
105 |     Security.SecPolicyCreateSSL.restype = SecPolicyRef
106 | 
107 |     Security.SecTrustCreateWithCertificates.argtypes = [
108 |         CFTypeRef,
109 |         CFTypeRef,
110 |         POINTER(SecTrustRef),
111 |     ]
112 |     Security.SecTrustCreateWithCertificates.restype = OSStatus
113 | 
114 |     Security.SecTrustGetTrustResult.argtypes = [
115 |         SecTrustRef,
116 |         POINTER(SecTrustResultType),
117 |     ]
118 |     Security.SecTrustGetTrustResult.restype = OSStatus
119 | 
120 |     Security.SecTrustEvaluate.argtypes = [
121 |         SecTrustRef,
122 |         POINTER(SecTrustResultType),
123 |     ]
124 |     Security.SecTrustEvaluate.restype = OSStatus
125 | 
126 |     Security.SecTrustRef = SecTrustRef  # type: ignore[attr-defined]
127 |     Security.SecTrustResultType = SecTrustResultType  # type: ignore[attr-defined]
128 |     Security.OSStatus = OSStatus  # type: ignore[attr-defined]
129 | 
130 |     kSecRevocationUseAnyAvailableMethod = 3
131 |     kSecRevocationRequirePositiveResponse = 8
132 | 
133 |     CoreFoundation.CFRelease.argtypes = [CFTypeRef]
134 |     CoreFoundation.CFRelease.restype = None
135 | 
136 |     CoreFoundation.CFGetTypeID.argtypes = [CFTypeRef]
137 |     CoreFoundation.CFGetTypeID.restype = CFTypeID
138 | 
139 |     CoreFoundation.CFStringCreateWithCString.argtypes = [
140 |         CFAllocatorRef,
141 |         c_char_p,
142 |         CFStringEncoding,
143 |     ]
144 |     CoreFoundation.CFStringCreateWithCString.restype = CFStringRef
145 | 
146 |     CoreFoundation.CFStringGetCStringPtr.argtypes = [CFStringRef, CFStringEncoding]
147 |     CoreFoundation.CFStringGetCStringPtr.restype = c_char_p
148 | 
149 |     CoreFoundation.CFStringGetCString.argtypes = [
150 |         CFStringRef,
151 |         c_char_p,
152 |         CFIndex,
153 |         CFStringEncoding,
154 |     ]
155 |     CoreFoundation.CFStringGetCString.restype = c_bool
156 | 
157 |     CoreFoundation.CFDataCreate.argtypes = [CFAllocatorRef, c_char_p, CFIndex]
158 |     CoreFoundation.CFDataCreate.restype = CFDataRef
159 | 
160 |     CoreFoundation.CFDataGetLength.argtypes = [CFDataRef]
161 |     CoreFoundation.CFDataGetLength.restype = CFIndex
162 | 
163 |     CoreFoundation.CFDataGetBytePtr.argtypes = [CFDataRef]
164 |     CoreFoundation.CFDataGetBytePtr.restype = c_void_p
165 | 
166 |     CoreFoundation.CFArrayCreate.argtypes = [
167 |         CFAllocatorRef,
168 |         POINTER(CFTypeRef),
169 |         CFIndex,
170 |         CFArrayCallBacks,
171 |     ]
172 |     CoreFoundation.CFArrayCreate.restype = CFArrayRef
173 | 
174 |     CoreFoundation.CFArrayCreateMutable.argtypes = [
175 |         CFAllocatorRef,
176 |         CFIndex,
177 |         CFArrayCallBacks,
178 |     ]
179 |     CoreFoundation.CFArrayCreateMutable.restype = CFMutableArrayRef
180 | 
181 |     CoreFoundation.CFArrayAppendValue.argtypes = [CFMutableArrayRef, c_void_p]
182 |     CoreFoundation.CFArrayAppendValue.restype = None
183 | 
184 |     CoreFoundation.CFArrayGetCount.argtypes = [CFArrayRef]
185 |     CoreFoundation.CFArrayGetCount.restype = CFIndex
186 | 
187 |     CoreFoundation.CFArrayGetValueAtIndex.argtypes = [CFArrayRef, CFIndex]
188 |     CoreFoundation.CFArrayGetValueAtIndex.restype = c_void_p
189 | 
190 |     CoreFoundation.CFErrorGetCode.argtypes = [CFErrorRef]
191 |     CoreFoundation.CFErrorGetCode.restype = CFIndex
192 | 
193 |     CoreFoundation.CFErrorCopyDescription.argtypes = [CFErrorRef]
194 |     CoreFoundation.CFErrorCopyDescription.restype = CFStringRef
195 | 
196 |     CoreFoundation.kCFAllocatorDefault = CFAllocatorRef.in_dll(  # type: ignore[attr-defined]
197 |         CoreFoundation, "kCFAllocatorDefault"
198 |     )
199 |     CoreFoundation.kCFTypeArrayCallBacks = c_void_p.in_dll(  # type: ignore[attr-defined]
200 |         CoreFoundation, "kCFTypeArrayCallBacks"
201 |     )
202 | 
203 |     CoreFoundation.CFTypeRef = CFTypeRef  # type: ignore[attr-defined]
204 |     CoreFoundation.CFArrayRef = CFArrayRef  # type: ignore[attr-defined]
205 |     CoreFoundation.CFStringRef = CFStringRef  # type: ignore[attr-defined]
206 |     CoreFoundation.CFErrorRef = CFErrorRef  # type: ignore[attr-defined]
207 | 
208 | except AttributeError as e:
209 |     raise ImportError(f"Error initializing ctypes: {e}") from None
210 | 
211 | # SecTrustEvaluateWithError is macOS 10.14+
212 | if _is_macos_version_10_14_or_later:
213 |     try:
214 |         Security.SecTrustEvaluateWithError.argtypes = [
215 |             SecTrustRef,
216 |             POINTER(CFErrorRef),
217 |         ]
218 |         Security.SecTrustEvaluateWithError.restype = c_bool
219 |     except AttributeError as e:
220 |         raise ImportError(f"Error initializing ctypes: {e}") from None
221 | 
222 | 
223 | def _handle_osstatus(result: OSStatus, _: typing.Any, args: typing.Any) -> typing.Any:
224 |     """
225 |     Raises an error if the OSStatus value is non-zero.
226 |     """
227 |     if int(result) == 0:
228 |         return args
229 | 
230 |     # Returns a CFString which we need to transform
231 |     # into a UTF-8 Python string.
232 |     error_message_cfstring = None
233 |     try:
234 |         error_message_cfstring = Security.SecCopyErrorMessageString(result, None)
235 | 
236 |         # First step is convert the CFString into a C string pointer.
237 |         # We try the fast no-copy way first.
238 |         error_message_cfstring_c_void_p = ctypes.cast(
239 |             error_message_cfstring, ctypes.POINTER(ctypes.c_void_p)
240 |         )
241 |         message = CoreFoundation.CFStringGetCStringPtr(
242 |             error_message_cfstring_c_void_p, CFConst.kCFStringEncodingUTF8
243 |         )
244 | 
245 |         # Quoting the Apple dev docs:
246 |         #
247 |         # "A pointer to a C string or NULL if the internal
248 |         # storage of theString does not allow this to be
249 |         # returned efficiently."
250 |         #
251 |         # So we need to get our hands dirty.
252 |         if message is None:
253 |             buffer = ctypes.create_string_buffer(1024)
254 |             result = CoreFoundation.CFStringGetCString(
255 |                 error_message_cfstring_c_void_p,
256 |                 buffer,
257 |                 1024,
258 |                 CFConst.kCFStringEncodingUTF8,
259 |             )
260 |             if not result:
261 |                 raise OSError("Error copying C string from CFStringRef")
262 |             message = buffer.value
263 | 
264 |     finally:
265 |         if error_message_cfstring is not None:
266 |             CoreFoundation.CFRelease(error_message_cfstring)
267 | 
268 |     # If no message can be found for this status we come
269 |     # up with a generic one that forwards the status code.
270 |     if message is None or message == "":
271 |         message = f"SecureTransport operation returned a non-zero OSStatus: {result}"
272 | 
273 |     raise ssl.SSLError(message)
274 | 
275 | 
276 | Security.SecTrustCreateWithCertificates.errcheck = _handle_osstatus  # type: ignore[assignment]
277 | Security.SecTrustSetAnchorCertificates.errcheck = _handle_osstatus  # type: ignore[assignment]
278 | Security.SecTrustSetAnchorCertificatesOnly.errcheck = _handle_osstatus  # type: ignore[assignment]
279 | Security.SecTrustGetTrustResult.errcheck = _handle_osstatus  # type: ignore[assignment]
280 | Security.SecTrustEvaluate.errcheck = _handle_osstatus  # type: ignore[assignment]
281 | 
282 | 
283 | class CFConst:
284 |     """CoreFoundation constants"""
285 | 
286 |     kCFStringEncodingUTF8 = CFStringEncoding(0x08000100)
287 | 
288 |     errSecIncompleteCertRevocationCheck = -67635
289 |     errSecHostNameMismatch = -67602
290 |     errSecCertificateExpired = -67818
291 |     errSecNotTrusted = -67843
292 | 
293 | 
294 | def _bytes_to_cf_data_ref(value: bytes) -> CFDataRef:  # type: ignore[valid-type]
295 |     return CoreFoundation.CFDataCreate(  # type: ignore[no-any-return]
296 |         CoreFoundation.kCFAllocatorDefault, value, len(value)
297 |     )
298 | 
299 | 
300 | def _bytes_to_cf_string(value: bytes) -> CFString:
301 |     """
302 |     Given a Python binary data, create a CFString.
303 |     The string must be CFReleased by the caller.
304 |     """
305 |     c_str = ctypes.c_char_p(value)
306 |     cf_str = CoreFoundation.CFStringCreateWithCString(
307 |         CoreFoundation.kCFAllocatorDefault,
308 |         c_str,
309 |         CFConst.kCFStringEncodingUTF8,
310 |     )
311 |     return cf_str  # type: ignore[no-any-return]
312 | 
313 | 
314 | def _cf_string_ref_to_str(cf_string_ref: CFStringRef) -> str | None:  # type: ignore[valid-type]
315 |     """
316 |     Creates a Unicode string from a CFString object. Used entirely for error
317 |     reporting.
318 |     Yes, it annoys me quite a lot that this function is this complex.
319 |     """
320 | 
321 |     string = CoreFoundation.CFStringGetCStringPtr(
322 |         cf_string_ref, CFConst.kCFStringEncodingUTF8
323 |     )
324 |     if string is None:
325 |         buffer = ctypes.create_string_buffer(1024)
326 |         result = CoreFoundation.CFStringGetCString(
327 |             cf_string_ref, buffer, 1024, CFConst.kCFStringEncodingUTF8
328 |         )
329 |         if not result:
330 |             raise OSError("Error copying C string from CFStringRef")
331 |         string = buffer.value
332 |     if string is not None:
333 |         string = string.decode("utf-8")
334 |     return string  # type: ignore[no-any-return]
335 | 
336 | 
337 | def _der_certs_to_cf_cert_array(certs: list[bytes]) -> CFMutableArrayRef:  # type: ignore[valid-type]
338 |     """Builds a CFArray of SecCertificateRefs from a list of DER-encoded certificates.
339 |     Responsibility of the caller to call CoreFoundation.CFRelease on the CFArray.
340 |     """
341 |     cf_array = CoreFoundation.CFArrayCreateMutable(
342 |         CoreFoundation.kCFAllocatorDefault,
343 |         0,
344 |         ctypes.byref(CoreFoundation.kCFTypeArrayCallBacks),
345 |     )
346 |     if not cf_array:
347 |         raise MemoryError("Unable to allocate memory!")
348 | 
349 |     for cert_data in certs:
350 |         cf_data = None
351 |         sec_cert_ref = None
352 |         try:
353 |             cf_data = _bytes_to_cf_data_ref(cert_data)
354 |             sec_cert_ref = Security.SecCertificateCreateWithData(
355 |                 CoreFoundation.kCFAllocatorDefault, cf_data
356 |             )
357 |             CoreFoundation.CFArrayAppendValue(cf_array, sec_cert_ref)
358 |         finally:
359 |             if cf_data:
360 |                 CoreFoundation.CFRelease(cf_data)
361 |             if sec_cert_ref:
362 |                 CoreFoundation.CFRelease(sec_cert_ref)
363 | 
364 |     return cf_array  # type: ignore[no-any-return]
365 | 
366 | 
367 | @contextlib.contextmanager
368 | def _configure_context(ctx: ssl.SSLContext) -> typing.Iterator[None]:
369 |     check_hostname = ctx.check_hostname
370 |     verify_mode = ctx.verify_mode
371 |     ctx.check_hostname = False
372 |     _set_ssl_context_verify_mode(ctx, ssl.CERT_NONE)
373 |     try:
374 |         yield
375 |     finally:
376 |         ctx.check_hostname = check_hostname
377 |         _set_ssl_context_verify_mode(ctx, verify_mode)
378 | 
379 | 
380 | def _verify_peercerts_impl(
381 |     ssl_context: ssl.SSLContext,
382 |     cert_chain: list[bytes],
383 |     server_hostname: str | None = None,
384 | ) -> None:
385 |     certs = None
386 |     policies = None
[TRUNCATED]
```

.venv/lib/python3.13/site-packages/pip/_vendor/truststore/_openssl.py
```
1 | import contextlib
2 | import os
3 | import re
4 | import ssl
5 | import typing
6 | 
7 | # candidates based on https://github.com/tiran/certifi-system-store by Christian Heimes
8 | _CA_FILE_CANDIDATES = [
9 |     # Alpine, Arch, Fedora 34+, OpenWRT, RHEL 9+, BSD
10 |     "/etc/ssl/cert.pem",
11 |     # Fedora <= 34, RHEL <= 9, CentOS <= 9
12 |     "/etc/pki/tls/cert.pem",
13 |     # Debian, Ubuntu (requires ca-certificates)
14 |     "/etc/ssl/certs/ca-certificates.crt",
15 |     # SUSE
16 |     "/etc/ssl/ca-bundle.pem",
17 | ]
18 | 
19 | _HASHED_CERT_FILENAME_RE = re.compile(r"^[0-9a-fA-F]{8}\.[0-9]$")
20 | 
21 | 
22 | @contextlib.contextmanager
23 | def _configure_context(ctx: ssl.SSLContext) -> typing.Iterator[None]:
24 |     # First, check whether the default locations from OpenSSL
25 |     # seem like they will give us a usable set of CA certs.
26 |     # ssl.get_default_verify_paths already takes care of:
27 |     # - getting cafile from either the SSL_CERT_FILE env var
28 |     #   or the path configured when OpenSSL was compiled,
29 |     #   and verifying that that path exists
30 |     # - getting capath from either the SSL_CERT_DIR env var
31 |     #   or the path configured when OpenSSL was compiled,
32 |     #   and verifying that that path exists
33 |     # In addition we'll check whether capath appears to contain certs.
34 |     defaults = ssl.get_default_verify_paths()
35 |     if defaults.cafile or (defaults.capath and _capath_contains_certs(defaults.capath)):
36 |         ctx.set_default_verify_paths()
37 |     else:
38 |         # cafile from OpenSSL doesn't exist
39 |         # and capath from OpenSSL doesn't contain certs.
40 |         # Let's search other common locations instead.
41 |         for cafile in _CA_FILE_CANDIDATES:
42 |             if os.path.isfile(cafile):
43 |                 ctx.load_verify_locations(cafile=cafile)
44 |                 break
45 | 
46 |     yield
47 | 
48 | 
49 | def _capath_contains_certs(capath: str) -> bool:
50 |     """Check whether capath exists and contains certs in the expected format."""
51 |     if not os.path.isdir(capath):
52 |         return False
53 |     for name in os.listdir(capath):
54 |         if _HASHED_CERT_FILENAME_RE.match(name):
55 |             return True
56 |     return False
57 | 
58 | 
59 | def _verify_peercerts_impl(
60 |     ssl_context: ssl.SSLContext,
61 |     cert_chain: list[bytes],
62 |     server_hostname: str | None = None,
63 | ) -> None:
64 |     # This is a no-op because we've enabled SSLContext's built-in
65 |     # verification via verify_mode=CERT_REQUIRED, and don't need to repeat it.
66 |     pass
```

.venv/lib/python3.13/site-packages/pip/_vendor/truststore/_ssl_constants.py
```
1 | import ssl
2 | import sys
3 | import typing
4 | 
5 | # Hold on to the original class so we can create it consistently
6 | # even if we inject our own SSLContext into the ssl module.
7 | _original_SSLContext = ssl.SSLContext
8 | _original_super_SSLContext = super(_original_SSLContext, _original_SSLContext)
9 | 
10 | # CPython is known to be good, but non-CPython implementations
11 | # may implement SSLContext differently so to be safe we don't
12 | # subclass the SSLContext.
13 | 
14 | # This is returned by truststore.SSLContext.__class__()
15 | _truststore_SSLContext_dunder_class: typing.Optional[type]
16 | 
17 | # This value is the superclass of truststore.SSLContext.
18 | _truststore_SSLContext_super_class: type
19 | 
20 | if sys.implementation.name == "cpython":
21 |     _truststore_SSLContext_super_class = _original_SSLContext
22 |     _truststore_SSLContext_dunder_class = None
23 | else:
24 |     _truststore_SSLContext_super_class = object
25 |     _truststore_SSLContext_dunder_class = _original_SSLContext
26 | 
27 | 
28 | def _set_ssl_context_verify_mode(
29 |     ssl_context: ssl.SSLContext, verify_mode: ssl.VerifyMode
30 | ) -> None:
31 |     _original_super_SSLContext.verify_mode.__set__(ssl_context, verify_mode)  # type: ignore[attr-defined]
```

.venv/lib/python3.13/site-packages/pip/_vendor/truststore/_windows.py
```
1 | import contextlib
2 | import ssl
3 | import typing
4 | from ctypes import WinDLL  # type: ignore
5 | from ctypes import WinError  # type: ignore
6 | from ctypes import (
7 |     POINTER,
8 |     Structure,
9 |     c_char_p,
10 |     c_ulong,
11 |     c_void_p,
12 |     c_wchar_p,
13 |     cast,
14 |     create_unicode_buffer,
15 |     pointer,
16 |     sizeof,
17 | )
18 | from ctypes.wintypes import (
19 |     BOOL,
20 |     DWORD,
21 |     HANDLE,
22 |     LONG,
23 |     LPCSTR,
24 |     LPCVOID,
25 |     LPCWSTR,
26 |     LPFILETIME,
27 |     LPSTR,
28 |     LPWSTR,
29 | )
30 | from typing import TYPE_CHECKING, Any
31 | 
32 | from ._ssl_constants import _set_ssl_context_verify_mode
33 | 
34 | HCERTCHAINENGINE = HANDLE
35 | HCERTSTORE = HANDLE
36 | HCRYPTPROV_LEGACY = HANDLE
37 | 
38 | 
39 | class CERT_CONTEXT(Structure):
40 |     _fields_ = (
41 |         ("dwCertEncodingType", DWORD),
42 |         ("pbCertEncoded", c_void_p),
43 |         ("cbCertEncoded", DWORD),
44 |         ("pCertInfo", c_void_p),
45 |         ("hCertStore", HCERTSTORE),
46 |     )
47 | 
48 | 
49 | PCERT_CONTEXT = POINTER(CERT_CONTEXT)
50 | PCCERT_CONTEXT = POINTER(PCERT_CONTEXT)
51 | 
52 | 
53 | class CERT_ENHKEY_USAGE(Structure):
54 |     _fields_ = (
55 |         ("cUsageIdentifier", DWORD),
56 |         ("rgpszUsageIdentifier", POINTER(LPSTR)),
57 |     )
58 | 
59 | 
60 | PCERT_ENHKEY_USAGE = POINTER(CERT_ENHKEY_USAGE)
61 | 
62 | 
63 | class CERT_USAGE_MATCH(Structure):
64 |     _fields_ = (
65 |         ("dwType", DWORD),
66 |         ("Usage", CERT_ENHKEY_USAGE),
67 |     )
68 | 
69 | 
70 | class CERT_CHAIN_PARA(Structure):
71 |     _fields_ = (
72 |         ("cbSize", DWORD),
73 |         ("RequestedUsage", CERT_USAGE_MATCH),
74 |         ("RequestedIssuancePolicy", CERT_USAGE_MATCH),
75 |         ("dwUrlRetrievalTimeout", DWORD),
76 |         ("fCheckRevocationFreshnessTime", BOOL),
77 |         ("dwRevocationFreshnessTime", DWORD),
78 |         ("pftCacheResync", LPFILETIME),
79 |         ("pStrongSignPara", c_void_p),
80 |         ("dwStrongSignFlags", DWORD),
81 |     )
82 | 
83 | 
84 | if TYPE_CHECKING:
85 |     PCERT_CHAIN_PARA = pointer[CERT_CHAIN_PARA]  # type: ignore[misc]
86 | else:
87 |     PCERT_CHAIN_PARA = POINTER(CERT_CHAIN_PARA)
88 | 
89 | 
90 | class CERT_TRUST_STATUS(Structure):
91 |     _fields_ = (
92 |         ("dwErrorStatus", DWORD),
93 |         ("dwInfoStatus", DWORD),
94 |     )
95 | 
96 | 
97 | class CERT_CHAIN_ELEMENT(Structure):
98 |     _fields_ = (
99 |         ("cbSize", DWORD),
100 |         ("pCertContext", PCERT_CONTEXT),
101 |         ("TrustStatus", CERT_TRUST_STATUS),
102 |         ("pRevocationInfo", c_void_p),
103 |         ("pIssuanceUsage", PCERT_ENHKEY_USAGE),
104 |         ("pApplicationUsage", PCERT_ENHKEY_USAGE),
105 |         ("pwszExtendedErrorInfo", LPCWSTR),
106 |     )
107 | 
108 | 
109 | PCERT_CHAIN_ELEMENT = POINTER(CERT_CHAIN_ELEMENT)
110 | 
111 | 
112 | class CERT_SIMPLE_CHAIN(Structure):
113 |     _fields_ = (
114 |         ("cbSize", DWORD),
115 |         ("TrustStatus", CERT_TRUST_STATUS),
116 |         ("cElement", DWORD),
117 |         ("rgpElement", POINTER(PCERT_CHAIN_ELEMENT)),
118 |         ("pTrustListInfo", c_void_p),
119 |         ("fHasRevocationFreshnessTime", BOOL),
120 |         ("dwRevocationFreshnessTime", DWORD),
121 |     )
122 | 
123 | 
124 | PCERT_SIMPLE_CHAIN = POINTER(CERT_SIMPLE_CHAIN)
125 | 
126 | 
127 | class CERT_CHAIN_CONTEXT(Structure):
128 |     _fields_ = (
129 |         ("cbSize", DWORD),
130 |         ("TrustStatus", CERT_TRUST_STATUS),
131 |         ("cChain", DWORD),
132 |         ("rgpChain", POINTER(PCERT_SIMPLE_CHAIN)),
133 |         ("cLowerQualityChainContext", DWORD),
134 |         ("rgpLowerQualityChainContext", c_void_p),
135 |         ("fHasRevocationFreshnessTime", BOOL),
136 |         ("dwRevocationFreshnessTime", DWORD),
137 |     )
138 | 
139 | 
140 | PCERT_CHAIN_CONTEXT = POINTER(CERT_CHAIN_CONTEXT)
141 | PCCERT_CHAIN_CONTEXT = POINTER(PCERT_CHAIN_CONTEXT)
142 | 
143 | 
144 | class SSL_EXTRA_CERT_CHAIN_POLICY_PARA(Structure):
145 |     _fields_ = (
146 |         ("cbSize", DWORD),
147 |         ("dwAuthType", DWORD),
148 |         ("fdwChecks", DWORD),
149 |         ("pwszServerName", LPCWSTR),
150 |     )
151 | 
152 | 
153 | class CERT_CHAIN_POLICY_PARA(Structure):
154 |     _fields_ = (
155 |         ("cbSize", DWORD),
156 |         ("dwFlags", DWORD),
157 |         ("pvExtraPolicyPara", c_void_p),
158 |     )
159 | 
160 | 
161 | PCERT_CHAIN_POLICY_PARA = POINTER(CERT_CHAIN_POLICY_PARA)
162 | 
163 | 
164 | class CERT_CHAIN_POLICY_STATUS(Structure):
165 |     _fields_ = (
166 |         ("cbSize", DWORD),
167 |         ("dwError", DWORD),
168 |         ("lChainIndex", LONG),
169 |         ("lElementIndex", LONG),
170 |         ("pvExtraPolicyStatus", c_void_p),
171 |     )
172 | 
173 | 
174 | PCERT_CHAIN_POLICY_STATUS = POINTER(CERT_CHAIN_POLICY_STATUS)
175 | 
176 | 
177 | class CERT_CHAIN_ENGINE_CONFIG(Structure):
178 |     _fields_ = (
179 |         ("cbSize", DWORD),
180 |         ("hRestrictedRoot", HCERTSTORE),
181 |         ("hRestrictedTrust", HCERTSTORE),
182 |         ("hRestrictedOther", HCERTSTORE),
183 |         ("cAdditionalStore", DWORD),
184 |         ("rghAdditionalStore", c_void_p),
185 |         ("dwFlags", DWORD),
186 |         ("dwUrlRetrievalTimeout", DWORD),
187 |         ("MaximumCachedCertificates", DWORD),
188 |         ("CycleDetectionModulus", DWORD),
189 |         ("hExclusiveRoot", HCERTSTORE),
190 |         ("hExclusiveTrustedPeople", HCERTSTORE),
191 |         ("dwExclusiveFlags", DWORD),
192 |     )
193 | 
194 | 
195 | PCERT_CHAIN_ENGINE_CONFIG = POINTER(CERT_CHAIN_ENGINE_CONFIG)
196 | PHCERTCHAINENGINE = POINTER(HCERTCHAINENGINE)
197 | 
198 | X509_ASN_ENCODING = 0x00000001
199 | PKCS_7_ASN_ENCODING = 0x00010000
200 | CERT_STORE_PROV_MEMORY = b"Memory"
201 | CERT_STORE_ADD_USE_EXISTING = 2
202 | USAGE_MATCH_TYPE_OR = 1
203 | OID_PKIX_KP_SERVER_AUTH = c_char_p(b"1.3.6.1.5.5.7.3.1")
204 | CERT_CHAIN_REVOCATION_CHECK_END_CERT = 0x10000000
205 | CERT_CHAIN_REVOCATION_CHECK_CHAIN = 0x20000000
206 | CERT_CHAIN_POLICY_IGNORE_ALL_NOT_TIME_VALID_FLAGS = 0x00000007
207 | CERT_CHAIN_POLICY_IGNORE_INVALID_BASIC_CONSTRAINTS_FLAG = 0x00000008
208 | CERT_CHAIN_POLICY_ALLOW_UNKNOWN_CA_FLAG = 0x00000010
209 | CERT_CHAIN_POLICY_IGNORE_INVALID_NAME_FLAG = 0x00000040
210 | CERT_CHAIN_POLICY_IGNORE_WRONG_USAGE_FLAG = 0x00000020
211 | CERT_CHAIN_POLICY_IGNORE_INVALID_POLICY_FLAG = 0x00000080
212 | CERT_CHAIN_POLICY_IGNORE_ALL_REV_UNKNOWN_FLAGS = 0x00000F00
213 | CERT_CHAIN_POLICY_ALLOW_TESTROOT_FLAG = 0x00008000
214 | CERT_CHAIN_POLICY_TRUST_TESTROOT_FLAG = 0x00004000
215 | SECURITY_FLAG_IGNORE_CERT_CN_INVALID = 0x00001000
216 | AUTHTYPE_SERVER = 2
217 | CERT_CHAIN_POLICY_SSL = 4
218 | FORMAT_MESSAGE_FROM_SYSTEM = 0x00001000
219 | FORMAT_MESSAGE_IGNORE_INSERTS = 0x00000200
220 | 
221 | # Flags to set for SSLContext.verify_mode=CERT_NONE
222 | CERT_CHAIN_POLICY_VERIFY_MODE_NONE_FLAGS = (
223 |     CERT_CHAIN_POLICY_IGNORE_ALL_NOT_TIME_VALID_FLAGS
224 |     | CERT_CHAIN_POLICY_IGNORE_INVALID_BASIC_CONSTRAINTS_FLAG
225 |     | CERT_CHAIN_POLICY_ALLOW_UNKNOWN_CA_FLAG
226 |     | CERT_CHAIN_POLICY_IGNORE_INVALID_NAME_FLAG
227 |     | CERT_CHAIN_POLICY_IGNORE_WRONG_USAGE_FLAG
228 |     | CERT_CHAIN_POLICY_IGNORE_INVALID_POLICY_FLAG
229 |     | CERT_CHAIN_POLICY_IGNORE_ALL_REV_UNKNOWN_FLAGS
230 |     | CERT_CHAIN_POLICY_ALLOW_TESTROOT_FLAG
231 |     | CERT_CHAIN_POLICY_TRUST_TESTROOT_FLAG
232 | )
233 | 
234 | wincrypt = WinDLL("crypt32.dll")
235 | kernel32 = WinDLL("kernel32.dll")
236 | 
237 | 
238 | def _handle_win_error(result: bool, _: Any, args: Any) -> Any:
239 |     if not result:
240 |         # Note, actually raises OSError after calling GetLastError and FormatMessage
241 |         raise WinError()
242 |     return args
243 | 
244 | 
245 | CertCreateCertificateChainEngine = wincrypt.CertCreateCertificateChainEngine
246 | CertCreateCertificateChainEngine.argtypes = (
247 |     PCERT_CHAIN_ENGINE_CONFIG,
248 |     PHCERTCHAINENGINE,
249 | )
250 | CertCreateCertificateChainEngine.errcheck = _handle_win_error
251 | 
252 | CertOpenStore = wincrypt.CertOpenStore
253 | CertOpenStore.argtypes = (LPCSTR, DWORD, HCRYPTPROV_LEGACY, DWORD, c_void_p)
254 | CertOpenStore.restype = HCERTSTORE
255 | CertOpenStore.errcheck = _handle_win_error
256 | 
257 | CertAddEncodedCertificateToStore = wincrypt.CertAddEncodedCertificateToStore
258 | CertAddEncodedCertificateToStore.argtypes = (
259 |     HCERTSTORE,
260 |     DWORD,
261 |     c_char_p,
262 |     DWORD,
263 |     DWORD,
264 |     PCCERT_CONTEXT,
265 | )
266 | CertAddEncodedCertificateToStore.restype = BOOL
267 | 
268 | CertCreateCertificateContext = wincrypt.CertCreateCertificateContext
269 | CertCreateCertificateContext.argtypes = (DWORD, c_char_p, DWORD)
270 | CertCreateCertificateContext.restype = PCERT_CONTEXT
271 | CertCreateCertificateContext.errcheck = _handle_win_error
272 | 
273 | CertGetCertificateChain = wincrypt.CertGetCertificateChain
274 | CertGetCertificateChain.argtypes = (
275 |     HCERTCHAINENGINE,
276 |     PCERT_CONTEXT,
277 |     LPFILETIME,
278 |     HCERTSTORE,
279 |     PCERT_CHAIN_PARA,
280 |     DWORD,
281 |     c_void_p,
282 |     PCCERT_CHAIN_CONTEXT,
283 | )
284 | CertGetCertificateChain.restype = BOOL
285 | CertGetCertificateChain.errcheck = _handle_win_error
286 | 
287 | CertVerifyCertificateChainPolicy = wincrypt.CertVerifyCertificateChainPolicy
288 | CertVerifyCertificateChainPolicy.argtypes = (
289 |     c_ulong,
290 |     PCERT_CHAIN_CONTEXT,
291 |     PCERT_CHAIN_POLICY_PARA,
292 |     PCERT_CHAIN_POLICY_STATUS,
293 | )
294 | CertVerifyCertificateChainPolicy.restype = BOOL
295 | 
296 | CertCloseStore = wincrypt.CertCloseStore
297 | CertCloseStore.argtypes = (HCERTSTORE, DWORD)
298 | CertCloseStore.restype = BOOL
299 | CertCloseStore.errcheck = _handle_win_error
300 | 
301 | CertFreeCertificateChain = wincrypt.CertFreeCertificateChain
302 | CertFreeCertificateChain.argtypes = (PCERT_CHAIN_CONTEXT,)
303 | 
304 | CertFreeCertificateContext = wincrypt.CertFreeCertificateContext
305 | CertFreeCertificateContext.argtypes = (PCERT_CONTEXT,)
306 | 
307 | CertFreeCertificateChainEngine = wincrypt.CertFreeCertificateChainEngine
308 | CertFreeCertificateChainEngine.argtypes = (HCERTCHAINENGINE,)
309 | 
310 | FormatMessageW = kernel32.FormatMessageW
311 | FormatMessageW.argtypes = (
312 |     DWORD,
313 |     LPCVOID,
314 |     DWORD,
315 |     DWORD,
316 |     LPWSTR,
317 |     DWORD,
318 |     c_void_p,
319 | )
320 | FormatMessageW.restype = DWORD
321 | 
322 | 
323 | def _verify_peercerts_impl(
324 |     ssl_context: ssl.SSLContext,
325 |     cert_chain: list[bytes],
326 |     server_hostname: str | None = None,
327 | ) -> None:
328 |     """Verify the cert_chain from the server using Windows APIs."""
329 | 
330 |     # If the peer didn't send any certificates then
331 |     # we can't do verification. Raise an error.
332 |     if not cert_chain:
333 |         raise ssl.SSLCertVerificationError("Peer sent no certificates to verify")
334 | 
335 |     pCertContext = None
336 |     hIntermediateCertStore = CertOpenStore(CERT_STORE_PROV_MEMORY, 0, None, 0, None)
337 |     try:
338 |         # Add intermediate certs to an in-memory cert store
339 |         for cert_bytes in cert_chain[1:]:
340 |             CertAddEncodedCertificateToStore(
341 |                 hIntermediateCertStore,
342 |                 X509_ASN_ENCODING | PKCS_7_ASN_ENCODING,
343 |                 cert_bytes,
344 |                 len(cert_bytes),
345 |                 CERT_STORE_ADD_USE_EXISTING,
346 |                 None,
347 |             )
348 | 
349 |         # Cert context for leaf cert
350 |         leaf_cert = cert_chain[0]
351 |         pCertContext = CertCreateCertificateContext(
352 |             X509_ASN_ENCODING | PKCS_7_ASN_ENCODING, leaf_cert, len(leaf_cert)
353 |         )
354 | 
355 |         # Chain params to match certs for serverAuth extended usage
356 |         cert_enhkey_usage = CERT_ENHKEY_USAGE()
357 |         cert_enhkey_usage.cUsageIdentifier = 1
358 |         cert_enhkey_usage.rgpszUsageIdentifier = (c_char_p * 1)(OID_PKIX_KP_SERVER_AUTH)
359 |         cert_usage_match = CERT_USAGE_MATCH()
360 |         cert_usage_match.Usage = cert_enhkey_usage
361 |         chain_params = CERT_CHAIN_PARA()
362 |         chain_params.RequestedUsage = cert_usage_match
363 |         chain_params.cbSize = sizeof(chain_params)
364 |         pChainPara = pointer(chain_params)
365 | 
366 |         if ssl_context.verify_flags & ssl.VERIFY_CRL_CHECK_CHAIN:
367 |             chain_flags = CERT_CHAIN_REVOCATION_CHECK_CHAIN
368 |         elif ssl_context.verify_flags & ssl.VERIFY_CRL_CHECK_LEAF:
369 |             chain_flags = CERT_CHAIN_REVOCATION_CHECK_END_CERT
370 |         else:
371 |             chain_flags = 0
372 | 
373 |         try:
374 |             # First attempt to verify using the default Windows system trust roots
375 |             # (default chain engine).
376 |             _get_and_verify_cert_chain(
377 |                 ssl_context,
378 |                 None,
379 |                 hIntermediateCertStore,
380 |                 pCertContext,
381 |                 pChainPara,
382 |                 server_hostname,
383 |                 chain_flags=chain_flags,
384 |             )
385 |         except ssl.SSLCertVerificationError as e:
386 |             # If that fails but custom CA certs have been added
387 |             # to the SSLContext using load_verify_locations,
388 |             # try verifying using a custom chain engine
389 |             # that trusts the custom CA certs.
390 |             custom_ca_certs: list[bytes] | None = ssl_context.get_ca_certs(
391 |                 binary_form=True
392 |             )
393 |             if custom_ca_certs:
394 |                 try:
395 |                     _verify_using_custom_ca_certs(
396 |                         ssl_context,
397 |                         custom_ca_certs,
398 |                         hIntermediateCertStore,
399 |                         pCertContext,
400 |                         pChainPara,
401 |                         server_hostname,
402 |                         chain_flags=chain_flags,
403 |                     )
404 |                 # Raise the original error, not the new error.
405 |                 except ssl.SSLCertVerificationError:
406 |                     raise e from None
407 |             else:
408 |                 raise
409 |     finally:
410 |         CertCloseStore(hIntermediateCertStore, 0)
411 |         if pCertContext:
412 |             CertFreeCertificateContext(pCertContext)
413 | 
414 | 
415 | def _get_and_verify_cert_chain(
416 |     ssl_context: ssl.SSLContext,
417 |     hChainEngine: HCERTCHAINENGINE | None,
418 |     hIntermediateCertStore: HCERTSTORE,
419 |     pPeerCertContext: c_void_p,
420 |     pChainPara: PCERT_CHAIN_PARA,  # type: ignore[valid-type]
421 |     server_hostname: str | None,
422 |     chain_flags: int,
423 | ) -> None:
424 |     ppChainContext = None
425 |     try:
[TRUNCATED]
```

.venv/lib/python3.13/site-packages/pip/_vendor/truststore/py.typed
```
```

.venv/lib/python3.13/site-packages/pip/_vendor/urllib3/__init__.py
```
1 | """
2 | Python HTTP library with thread-safe connection pooling, file post support, user friendly, and more
3 | """
4 | from __future__ import absolute_import
5 | 
6 | # Set default logging handler to avoid "No handler found" warnings.
7 | import logging
8 | import warnings
9 | from logging import NullHandler
10 | 
11 | from . import exceptions
12 | from ._version import __version__
13 | from .connectionpool import HTTPConnectionPool, HTTPSConnectionPool, connection_from_url
14 | from .filepost import encode_multipart_formdata
15 | from .poolmanager import PoolManager, ProxyManager, proxy_from_url
16 | from .response import HTTPResponse
17 | from .util.request import make_headers
18 | from .util.retry import Retry
19 | from .util.timeout import Timeout
20 | from .util.url import get_host
21 | 
22 | # === NOTE TO REPACKAGERS AND VENDORS ===
23 | # Please delete this block, this logic is only
24 | # for urllib3 being distributed via PyPI.
25 | # See: https://github.com/urllib3/urllib3/issues/2680
26 | try:
27 |     import urllib3_secure_extra  # type: ignore # noqa: F401
28 | except ImportError:
29 |     pass
30 | else:
31 |     warnings.warn(
32 |         "'urllib3[secure]' extra is deprecated and will be removed "
33 |         "in a future release of urllib3 2.x. Read more in this issue: "
34 |         "https://github.com/urllib3/urllib3/issues/2680",
35 |         category=DeprecationWarning,
36 |         stacklevel=2,
37 |     )
38 | 
39 | __author__ = "Andrey Petrov (andrey.petrov@shazow.net)"
40 | __license__ = "MIT"
41 | __version__ = __version__
42 | 
43 | __all__ = (
44 |     "HTTPConnectionPool",
45 |     "HTTPSConnectionPool",
46 |     "PoolManager",
47 |     "ProxyManager",
48 |     "HTTPResponse",
49 |     "Retry",
50 |     "Timeout",
51 |     "add_stderr_logger",
52 |     "connection_from_url",
53 |     "disable_warnings",
54 |     "encode_multipart_formdata",
55 |     "get_host",
56 |     "make_headers",
57 |     "proxy_from_url",
58 | )
59 | 
60 | logging.getLogger(__name__).addHandler(NullHandler())
61 | 
62 | 
63 | def add_stderr_logger(level=logging.DEBUG):
64 |     """
65 |     Helper for quickly adding a StreamHandler to the logger. Useful for
66 |     debugging.
67 | 
68 |     Returns the handler after adding it.
69 |     """
70 |     # This method needs to be in this __init__.py to get the __name__ correct
71 |     # even if urllib3 is vendored within another package.
72 |     logger = logging.getLogger(__name__)
73 |     handler = logging.StreamHandler()
74 |     handler.setFormatter(logging.Formatter("%(asctime)s %(levelname)s %(message)s"))
75 |     logger.addHandler(handler)
76 |     logger.setLevel(level)
77 |     logger.debug("Added a stderr logging handler to logger: %s", __name__)
78 |     return handler
79 | 
80 | 
81 | # ... Clean up.
82 | del NullHandler
83 | 
84 | 
85 | # All warning filters *must* be appended unless you're really certain that they
86 | # shouldn't be: otherwise, it's very hard for users to use most Python
87 | # mechanisms to silence them.
88 | # SecurityWarning's always go off by default.
89 | warnings.simplefilter("always", exceptions.SecurityWarning, append=True)
90 | # SubjectAltNameWarning's should go off once per host
91 | warnings.simplefilter("default", exceptions.SubjectAltNameWarning, append=True)
92 | # InsecurePlatformWarning's don't vary between requests, so we keep it default.
93 | warnings.simplefilter("default", exceptions.InsecurePlatformWarning, append=True)
94 | # SNIMissingWarnings should go off only once.
95 | warnings.simplefilter("default", exceptions.SNIMissingWarning, append=True)
96 | 
97 | 
98 | def disable_warnings(category=exceptions.HTTPWarning):
99 |     """
100 |     Helper for quickly disabling all urllib3 warnings.
101 |     """
102 |     warnings.simplefilter("ignore", category)
```

.venv/lib/python3.13/site-packages/pip/_vendor/urllib3/_collections.py
```
1 | from __future__ import absolute_import
2 | 
3 | try:
4 |     from collections.abc import Mapping, MutableMapping
5 | except ImportError:
6 |     from collections import Mapping, MutableMapping
7 | try:
8 |     from threading import RLock
9 | except ImportError:  # Platform-specific: No threads available
10 | 
11 |     class RLock:
12 |         def __enter__(self):
13 |             pass
14 | 
15 |         def __exit__(self, exc_type, exc_value, traceback):
16 |             pass
17 | 
18 | 
19 | from collections import OrderedDict
20 | 
21 | from .exceptions import InvalidHeader
22 | from .packages import six
23 | from .packages.six import iterkeys, itervalues
24 | 
25 | __all__ = ["RecentlyUsedContainer", "HTTPHeaderDict"]
26 | 
27 | 
28 | _Null = object()
29 | 
30 | 
31 | class RecentlyUsedContainer(MutableMapping):
32 |     """
33 |     Provides a thread-safe dict-like container which maintains up to
34 |     ``maxsize`` keys while throwing away the least-recently-used keys beyond
35 |     ``maxsize``.
36 | 
37 |     :param maxsize:
38 |         Maximum number of recent elements to retain.
39 | 
40 |     :param dispose_func:
41 |         Every time an item is evicted from the container,
42 |         ``dispose_func(value)`` is called.  Callback which will get called
43 |     """
44 | 
45 |     ContainerCls = OrderedDict
46 | 
47 |     def __init__(self, maxsize=10, dispose_func=None):
48 |         self._maxsize = maxsize
49 |         self.dispose_func = dispose_func
50 | 
51 |         self._container = self.ContainerCls()
52 |         self.lock = RLock()
53 | 
54 |     def __getitem__(self, key):
55 |         # Re-insert the item, moving it to the end of the eviction line.
56 |         with self.lock:
57 |             item = self._container.pop(key)
58 |             self._container[key] = item
59 |             return item
60 | 
61 |     def __setitem__(self, key, value):
62 |         evicted_value = _Null
63 |         with self.lock:
64 |             # Possibly evict the existing value of 'key'
65 |             evicted_value = self._container.get(key, _Null)
66 |             self._container[key] = value
67 | 
68 |             # If we didn't evict an existing value, we might have to evict the
69 |             # least recently used item from the beginning of the container.
70 |             if len(self._container) > self._maxsize:
71 |                 _key, evicted_value = self._container.popitem(last=False)
72 | 
73 |         if self.dispose_func and evicted_value is not _Null:
74 |             self.dispose_func(evicted_value)
75 | 
76 |     def __delitem__(self, key):
77 |         with self.lock:
78 |             value = self._container.pop(key)
79 | 
80 |         if self.dispose_func:
81 |             self.dispose_func(value)
82 | 
83 |     def __len__(self):
84 |         with self.lock:
85 |             return len(self._container)
86 | 
87 |     def __iter__(self):
88 |         raise NotImplementedError(
89 |             "Iteration over this class is unlikely to be threadsafe."
90 |         )
91 | 
92 |     def clear(self):
93 |         with self.lock:
94 |             # Copy pointers to all values, then wipe the mapping
95 |             values = list(itervalues(self._container))
96 |             self._container.clear()
97 | 
98 |         if self.dispose_func:
99 |             for value in values:
100 |                 self.dispose_func(value)
101 | 
102 |     def keys(self):
103 |         with self.lock:
104 |             return list(iterkeys(self._container))
105 | 
106 | 
107 | class HTTPHeaderDict(MutableMapping):
108 |     """
109 |     :param headers:
110 |         An iterable of field-value pairs. Must not contain multiple field names
111 |         when compared case-insensitively.
112 | 
113 |     :param kwargs:
114 |         Additional field-value pairs to pass in to ``dict.update``.
115 | 
116 |     A ``dict`` like container for storing HTTP Headers.
117 | 
118 |     Field names are stored and compared case-insensitively in compliance with
119 |     RFC 7230. Iteration provides the first case-sensitive key seen for each
120 |     case-insensitive pair.
121 | 
122 |     Using ``__setitem__`` syntax overwrites fields that compare equal
123 |     case-insensitively in order to maintain ``dict``'s api. For fields that
124 |     compare equal, instead create a new ``HTTPHeaderDict`` and use ``.add``
125 |     in a loop.
126 | 
127 |     If multiple fields that are equal case-insensitively are passed to the
128 |     constructor or ``.update``, the behavior is undefined and some will be
129 |     lost.
130 | 
131 |     >>> headers = HTTPHeaderDict()
132 |     >>> headers.add('Set-Cookie', 'foo=bar')
133 |     >>> headers.add('set-cookie', 'baz=quxx')
134 |     >>> headers['content-length'] = '7'
135 |     >>> headers['SET-cookie']
136 |     'foo=bar, baz=quxx'
137 |     >>> headers['Content-Length']
138 |     '7'
139 |     """
140 | 
141 |     def __init__(self, headers=None, **kwargs):
142 |         super(HTTPHeaderDict, self).__init__()
143 |         self._container = OrderedDict()
144 |         if headers is not None:
145 |             if isinstance(headers, HTTPHeaderDict):
146 |                 self._copy_from(headers)
147 |             else:
148 |                 self.extend(headers)
149 |         if kwargs:
150 |             self.extend(kwargs)
151 | 
152 |     def __setitem__(self, key, val):
153 |         self._container[key.lower()] = [key, val]
154 |         return self._container[key.lower()]
155 | 
156 |     def __getitem__(self, key):
157 |         val = self._container[key.lower()]
158 |         return ", ".join(val[1:])
159 | 
160 |     def __delitem__(self, key):
161 |         del self._container[key.lower()]
162 | 
163 |     def __contains__(self, key):
164 |         return key.lower() in self._container
165 | 
166 |     def __eq__(self, other):
167 |         if not isinstance(other, Mapping) and not hasattr(other, "keys"):
168 |             return False
169 |         if not isinstance(other, type(self)):
170 |             other = type(self)(other)
171 |         return dict((k.lower(), v) for k, v in self.itermerged()) == dict(
172 |             (k.lower(), v) for k, v in other.itermerged()
173 |         )
174 | 
175 |     def __ne__(self, other):
176 |         return not self.__eq__(other)
177 | 
178 |     if six.PY2:  # Python 2
179 |         iterkeys = MutableMapping.iterkeys
180 |         itervalues = MutableMapping.itervalues
181 | 
182 |     __marker = object()
183 | 
184 |     def __len__(self):
185 |         return len(self._container)
186 | 
187 |     def __iter__(self):
188 |         # Only provide the originally cased names
189 |         for vals in self._container.values():
190 |             yield vals[0]
191 | 
192 |     def pop(self, key, default=__marker):
193 |         """D.pop(k[,d]) -> v, remove specified key and return the corresponding value.
194 |         If key is not found, d is returned if given, otherwise KeyError is raised.
195 |         """
196 |         # Using the MutableMapping function directly fails due to the private marker.
197 |         # Using ordinary dict.pop would expose the internal structures.
198 |         # So let's reinvent the wheel.
199 |         try:
200 |             value = self[key]
201 |         except KeyError:
202 |             if default is self.__marker:
203 |                 raise
204 |             return default
205 |         else:
206 |             del self[key]
207 |             return value
208 | 
209 |     def discard(self, key):
210 |         try:
211 |             del self[key]
212 |         except KeyError:
213 |             pass
214 | 
215 |     def add(self, key, val):
216 |         """Adds a (name, value) pair, doesn't overwrite the value if it already
217 |         exists.
218 | 
219 |         >>> headers = HTTPHeaderDict(foo='bar')
220 |         >>> headers.add('Foo', 'baz')
221 |         >>> headers['foo']
222 |         'bar, baz'
223 |         """
224 |         key_lower = key.lower()
225 |         new_vals = [key, val]
226 |         # Keep the common case aka no item present as fast as possible
227 |         vals = self._container.setdefault(key_lower, new_vals)
228 |         if new_vals is not vals:
229 |             vals.append(val)
230 | 
231 |     def extend(self, *args, **kwargs):
232 |         """Generic import function for any type of header-like object.
233 |         Adapted version of MutableMapping.update in order to insert items
234 |         with self.add instead of self.__setitem__
235 |         """
236 |         if len(args) > 1:
237 |             raise TypeError(
238 |                 "extend() takes at most 1 positional "
239 |                 "arguments ({0} given)".format(len(args))
240 |             )
241 |         other = args[0] if len(args) >= 1 else ()
242 | 
243 |         if isinstance(other, HTTPHeaderDict):
244 |             for key, val in other.iteritems():
245 |                 self.add(key, val)
246 |         elif isinstance(other, Mapping):
247 |             for key in other:
248 |                 self.add(key, other[key])
249 |         elif hasattr(other, "keys"):
250 |             for key in other.keys():
251 |                 self.add(key, other[key])
252 |         else:
253 |             for key, value in other:
254 |                 self.add(key, value)
255 | 
256 |         for key, value in kwargs.items():
257 |             self.add(key, value)
258 | 
259 |     def getlist(self, key, default=__marker):
260 |         """Returns a list of all the values for the named field. Returns an
261 |         empty list if the key doesn't exist."""
262 |         try:
263 |             vals = self._container[key.lower()]
264 |         except KeyError:
265 |             if default is self.__marker:
266 |                 return []
267 |             return default
268 |         else:
269 |             return vals[1:]
270 | 
271 |     def _prepare_for_method_change(self):
272 |         """
273 |         Remove content-specific header fields before changing the request
274 |         method to GET or HEAD according to RFC 9110, Section 15.4.
275 |         """
276 |         content_specific_headers = [
277 |             "Content-Encoding",
278 |             "Content-Language",
279 |             "Content-Location",
280 |             "Content-Type",
281 |             "Content-Length",
282 |             "Digest",
283 |             "Last-Modified",
284 |         ]
285 |         for header in content_specific_headers:
286 |             self.discard(header)
287 |         return self
288 | 
289 |     # Backwards compatibility for httplib
290 |     getheaders = getlist
291 |     getallmatchingheaders = getlist
292 |     iget = getlist
293 | 
294 |     # Backwards compatibility for http.cookiejar
295 |     get_all = getlist
296 | 
297 |     def __repr__(self):
298 |         return "%s(%s)" % (type(self).__name__, dict(self.itermerged()))
299 | 
300 |     def _copy_from(self, other):
301 |         for key in other:
302 |             val = other.getlist(key)
303 |             if isinstance(val, list):
304 |                 # Don't need to convert tuples
305 |                 val = list(val)
306 |             self._container[key.lower()] = [key] + val
307 | 
308 |     def copy(self):
309 |         clone = type(self)()
310 |         clone._copy_from(self)
311 |         return clone
312 | 
313 |     def iteritems(self):
314 |         """Iterate over all header lines, including duplicate ones."""
315 |         for key in self:
316 |             vals = self._container[key.lower()]
317 |             for val in vals[1:]:
318 |                 yield vals[0], val
319 | 
320 |     def itermerged(self):
321 |         """Iterate over all headers, merging duplicate ones together."""
322 |         for key in self:
323 |             val = self._container[key.lower()]
324 |             yield val[0], ", ".join(val[1:])
325 | 
326 |     def items(self):
327 |         return list(self.iteritems())
328 | 
329 |     @classmethod
330 |     def from_httplib(cls, message):  # Python 2
331 |         """Read headers from a Python 2 httplib message object."""
332 |         # python2.7 does not expose a proper API for exporting multiheaders
333 |         # efficiently. This function re-reads raw lines from the message
334 |         # object and extracts the multiheaders properly.
335 |         obs_fold_continued_leaders = (" ", "\t")
336 |         headers = []
337 | 
338 |         for line in message.headers:
339 |             if line.startswith(obs_fold_continued_leaders):
340 |                 if not headers:
341 |                     # We received a header line that starts with OWS as described
342 |                     # in RFC-7230 S3.2.4. This indicates a multiline header, but
343 |                     # there exists no previous header to which we can attach it.
344 |                     raise InvalidHeader(
345 |                         "Header continuation with no previous header: %s" % line
346 |                     )
347 |                 else:
348 |                     key, value = headers[-1]
349 |                     headers[-1] = (key, value + " " + line.strip())
350 |                     continue
351 | 
352 |             key, value = line.split(":", 1)
353 |             headers.append((key, value.strip()))
354 | 
355 |         return cls(headers)
```

.venv/lib/python3.13/site-packages/pip/_vendor/urllib3/_version.py
```
1 | # This file is protected via CODEOWNERS
2 | __version__ = "1.26.20"
```

.venv/lib/python3.13/site-packages/pip/_vendor/urllib3/connection.py
```
1 | from __future__ import absolute_import
2 | 
3 | import datetime
4 | import logging
5 | import os
6 | import re
7 | import socket
8 | import warnings
9 | from socket import error as SocketError
10 | from socket import timeout as SocketTimeout
11 | 
12 | from .packages import six
13 | from .packages.six.moves.http_client import HTTPConnection as _HTTPConnection
14 | from .packages.six.moves.http_client import HTTPException  # noqa: F401
15 | from .util.proxy import create_proxy_ssl_context
16 | 
17 | try:  # Compiled with SSL?
18 |     import ssl
19 | 
20 |     BaseSSLError = ssl.SSLError
21 | except (ImportError, AttributeError):  # Platform-specific: No SSL.
22 |     ssl = None
23 | 
24 |     class BaseSSLError(BaseException):
25 |         pass
26 | 
27 | 
28 | try:
29 |     # Python 3: not a no-op, we're adding this to the namespace so it can be imported.
30 |     ConnectionError = ConnectionError
31 | except NameError:
32 |     # Python 2
33 |     class ConnectionError(Exception):
34 |         pass
35 | 
36 | 
37 | try:  # Python 3:
38 |     # Not a no-op, we're adding this to the namespace so it can be imported.
39 |     BrokenPipeError = BrokenPipeError
40 | except NameError:  # Python 2:
41 | 
42 |     class BrokenPipeError(Exception):
43 |         pass
44 | 
45 | 
46 | from ._collections import HTTPHeaderDict  # noqa (historical, removed in v2)
47 | from ._version import __version__
48 | from .exceptions import (
49 |     ConnectTimeoutError,
50 |     NewConnectionError,
51 |     SubjectAltNameWarning,
52 |     SystemTimeWarning,
53 | )
54 | from .util import SKIP_HEADER, SKIPPABLE_HEADERS, connection
55 | from .util.ssl_ import (
56 |     assert_fingerprint,
57 |     create_urllib3_context,
58 |     is_ipaddress,
59 |     resolve_cert_reqs,
60 |     resolve_ssl_version,
61 |     ssl_wrap_socket,
62 | )
63 | from .util.ssl_match_hostname import CertificateError, match_hostname
64 | 
65 | log = logging.getLogger(__name__)
66 | 
67 | port_by_scheme = {"http": 80, "https": 443}
68 | 
69 | # When it comes time to update this value as a part of regular maintenance
70 | # (ie test_recent_date is failing) update it to ~6 months before the current date.
71 | RECENT_DATE = datetime.date(2024, 1, 1)
72 | 
73 | _CONTAINS_CONTROL_CHAR_RE = re.compile(r"[^-!#$%&'*+.^_`|~0-9a-zA-Z]")
74 | 
75 | 
76 | class HTTPConnection(_HTTPConnection, object):
77 |     """
78 |     Based on :class:`http.client.HTTPConnection` but provides an extra constructor
79 |     backwards-compatibility layer between older and newer Pythons.
80 | 
81 |     Additional keyword parameters are used to configure attributes of the connection.
82 |     Accepted parameters include:
83 | 
84 |     - ``strict``: See the documentation on :class:`urllib3.connectionpool.HTTPConnectionPool`
85 |     - ``source_address``: Set the source address for the current connection.
86 |     - ``socket_options``: Set specific options on the underlying socket. If not specified, then
87 |       defaults are loaded from ``HTTPConnection.default_socket_options`` which includes disabling
88 |       Nagle's algorithm (sets TCP_NODELAY to 1) unless the connection is behind a proxy.
89 | 
90 |       For example, if you wish to enable TCP Keep Alive in addition to the defaults,
91 |       you might pass:
92 | 
93 |       .. code-block:: python
94 | 
95 |          HTTPConnection.default_socket_options + [
96 |              (socket.SOL_SOCKET, socket.SO_KEEPALIVE, 1),
97 |          ]
98 | 
99 |       Or you may want to disable the defaults by passing an empty list (e.g., ``[]``).
100 |     """
101 | 
102 |     default_port = port_by_scheme["http"]
103 | 
104 |     #: Disable Nagle's algorithm by default.
105 |     #: ``[(socket.IPPROTO_TCP, socket.TCP_NODELAY, 1)]``
106 |     default_socket_options = [(socket.IPPROTO_TCP, socket.TCP_NODELAY, 1)]
107 | 
108 |     #: Whether this connection verifies the host's certificate.
109 |     is_verified = False
110 | 
111 |     #: Whether this proxy connection (if used) verifies the proxy host's
112 |     #: certificate.
113 |     proxy_is_verified = None
114 | 
115 |     def __init__(self, *args, **kw):
116 |         if not six.PY2:
117 |             kw.pop("strict", None)
118 | 
119 |         # Pre-set source_address.
120 |         self.source_address = kw.get("source_address")
121 | 
122 |         #: The socket options provided by the user. If no options are
123 |         #: provided, we use the default options.
124 |         self.socket_options = kw.pop("socket_options", self.default_socket_options)
125 | 
126 |         # Proxy options provided by the user.
127 |         self.proxy = kw.pop("proxy", None)
128 |         self.proxy_config = kw.pop("proxy_config", None)
129 | 
130 |         _HTTPConnection.__init__(self, *args, **kw)
131 | 
132 |     @property
133 |     def host(self):
134 |         """
135 |         Getter method to remove any trailing dots that indicate the hostname is an FQDN.
136 | 
137 |         In general, SSL certificates don't include the trailing dot indicating a
138 |         fully-qualified domain name, and thus, they don't validate properly when
139 |         checked against a domain name that includes the dot. In addition, some
140 |         servers may not expect to receive the trailing dot when provided.
141 | 
142 |         However, the hostname with trailing dot is critical to DNS resolution; doing a
143 |         lookup with the trailing dot will properly only resolve the appropriate FQDN,
144 |         whereas a lookup without a trailing dot will search the system's search domain
145 |         list. Thus, it's important to keep the original host around for use only in
146 |         those cases where it's appropriate (i.e., when doing DNS lookup to establish the
147 |         actual TCP connection across which we're going to send HTTP requests).
148 |         """
149 |         return self._dns_host.rstrip(".")
150 | 
151 |     @host.setter
152 |     def host(self, value):
153 |         """
154 |         Setter for the `host` property.
155 | 
156 |         We assume that only urllib3 uses the _dns_host attribute; httplib itself
157 |         only uses `host`, and it seems reasonable that other libraries follow suit.
158 |         """
159 |         self._dns_host = value
160 | 
161 |     def _new_conn(self):
162 |         """Establish a socket connection and set nodelay settings on it.
163 | 
164 |         :return: New socket connection.
165 |         """
166 |         extra_kw = {}
167 |         if self.source_address:
168 |             extra_kw["source_address"] = self.source_address
169 | 
170 |         if self.socket_options:
171 |             extra_kw["socket_options"] = self.socket_options
172 | 
173 |         try:
174 |             conn = connection.create_connection(
175 |                 (self._dns_host, self.port), self.timeout, **extra_kw
176 |             )
177 | 
178 |         except SocketTimeout:
179 |             raise ConnectTimeoutError(
180 |                 self,
181 |                 "Connection to %s timed out. (connect timeout=%s)"
182 |                 % (self.host, self.timeout),
183 |             )
184 | 
185 |         except SocketError as e:
186 |             raise NewConnectionError(
187 |                 self, "Failed to establish a new connection: %s" % e
188 |             )
189 | 
190 |         return conn
191 | 
192 |     def _is_using_tunnel(self):
193 |         # Google App Engine's httplib does not define _tunnel_host
194 |         return getattr(self, "_tunnel_host", None)
195 | 
196 |     def _prepare_conn(self, conn):
197 |         self.sock = conn
198 |         if self._is_using_tunnel():
199 |             # TODO: Fix tunnel so it doesn't depend on self.sock state.
200 |             self._tunnel()
201 |             # Mark this connection as not reusable
202 |             self.auto_open = 0
203 | 
204 |     def connect(self):
205 |         conn = self._new_conn()
206 |         self._prepare_conn(conn)
207 | 
208 |     def putrequest(self, method, url, *args, **kwargs):
209 |         """ """
210 |         # Empty docstring because the indentation of CPython's implementation
211 |         # is broken but we don't want this method in our documentation.
212 |         match = _CONTAINS_CONTROL_CHAR_RE.search(method)
213 |         if match:
214 |             raise ValueError(
215 |                 "Method cannot contain non-token characters %r (found at least %r)"
216 |                 % (method, match.group())
217 |             )
218 | 
219 |         return _HTTPConnection.putrequest(self, method, url, *args, **kwargs)
220 | 
221 |     def putheader(self, header, *values):
222 |         """ """
223 |         if not any(isinstance(v, str) and v == SKIP_HEADER for v in values):
224 |             _HTTPConnection.putheader(self, header, *values)
225 |         elif six.ensure_str(header.lower()) not in SKIPPABLE_HEADERS:
226 |             raise ValueError(
227 |                 "urllib3.util.SKIP_HEADER only supports '%s'"
228 |                 % ("', '".join(map(str.title, sorted(SKIPPABLE_HEADERS))),)
229 |             )
230 | 
231 |     def request(self, method, url, body=None, headers=None):
232 |         # Update the inner socket's timeout value to send the request.
233 |         # This only triggers if the connection is re-used.
234 |         if getattr(self, "sock", None) is not None:
235 |             self.sock.settimeout(self.timeout)
236 | 
237 |         if headers is None:
238 |             headers = {}
239 |         else:
240 |             # Avoid modifying the headers passed into .request()
241 |             headers = headers.copy()
242 |         if "user-agent" not in (six.ensure_str(k.lower()) for k in headers):
243 |             headers["User-Agent"] = _get_default_user_agent()
244 |         super(HTTPConnection, self).request(method, url, body=body, headers=headers)
245 | 
246 |     def request_chunked(self, method, url, body=None, headers=None):
247 |         """
248 |         Alternative to the common request method, which sends the
249 |         body with chunked encoding and not as one block
250 |         """
251 |         headers = headers or {}
252 |         header_keys = set([six.ensure_str(k.lower()) for k in headers])
253 |         skip_accept_encoding = "accept-encoding" in header_keys
254 |         skip_host = "host" in header_keys
255 |         self.putrequest(
256 |             method, url, skip_accept_encoding=skip_accept_encoding, skip_host=skip_host
257 |         )
258 |         if "user-agent" not in header_keys:
259 |             self.putheader("User-Agent", _get_default_user_agent())
260 |         for header, value in headers.items():
261 |             self.putheader(header, value)
262 |         if "transfer-encoding" not in header_keys:
263 |             self.putheader("Transfer-Encoding", "chunked")
264 |         self.endheaders()
265 | 
266 |         if body is not None:
267 |             stringish_types = six.string_types + (bytes,)
268 |             if isinstance(body, stringish_types):
269 |                 body = (body,)
270 |             for chunk in body:
271 |                 if not chunk:
272 |                     continue
273 |                 if not isinstance(chunk, bytes):
274 |                     chunk = chunk.encode("utf8")
275 |                 len_str = hex(len(chunk))[2:]
276 |                 to_send = bytearray(len_str.encode())
277 |                 to_send += b"\r\n"
278 |                 to_send += chunk
279 |                 to_send += b"\r\n"
280 |                 self.send(to_send)
281 | 
282 |         # After the if clause, to always have a closed body
283 |         self.send(b"0\r\n\r\n")
284 | 
285 | 
286 | class HTTPSConnection(HTTPConnection):
287 |     """
288 |     Many of the parameters to this constructor are passed to the underlying SSL
289 |     socket by means of :py:func:`urllib3.util.ssl_wrap_socket`.
290 |     """
291 | 
292 |     default_port = port_by_scheme["https"]
293 | 
294 |     cert_reqs = None
295 |     ca_certs = None
296 |     ca_cert_dir = None
297 |     ca_cert_data = None
298 |     ssl_version = None
299 |     assert_fingerprint = None
300 |     tls_in_tls_required = False
301 | 
302 |     def __init__(
303 |         self,
304 |         host,
305 |         port=None,
306 |         key_file=None,
307 |         cert_file=None,
308 |         key_password=None,
309 |         strict=None,
310 |         timeout=socket._GLOBAL_DEFAULT_TIMEOUT,
311 |         ssl_context=None,
312 |         server_hostname=None,
313 |         **kw
314 |     ):
315 | 
316 |         HTTPConnection.__init__(self, host, port, strict=strict, timeout=timeout, **kw)
317 | 
318 |         self.key_file = key_file
319 |         self.cert_file = cert_file
320 |         self.key_password = key_password
321 |         self.ssl_context = ssl_context
322 |         self.server_hostname = server_hostname
323 | 
324 |         # Required property for Google AppEngine 1.9.0 which otherwise causes
325 |         # HTTPS requests to go out as HTTP. (See Issue #356)
326 |         self._protocol = "https"
327 | 
328 |     def set_cert(
329 |         self,
330 |         key_file=None,
331 |         cert_file=None,
332 |         cert_reqs=None,
333 |         key_password=None,
334 |         ca_certs=None,
335 |         assert_hostname=None,
336 |         assert_fingerprint=None,
337 |         ca_cert_dir=None,
338 |         ca_cert_data=None,
339 |     ):
340 |         """
341 |         This method should only be called once, before the connection is used.
342 |         """
343 |         # If cert_reqs is not provided we'll assume CERT_REQUIRED unless we also
344 |         # have an SSLContext object in which case we'll use its verify_mode.
345 |         if cert_reqs is None:
346 |             if self.ssl_context is not None:
347 |                 cert_reqs = self.ssl_context.verify_mode
348 |             else:
[TRUNCATED]
```

.venv/lib/python3.13/site-packages/pip/_vendor/urllib3/connectionpool.py
```
1 | from __future__ import absolute_import
2 | 
3 | import errno
4 | import logging
5 | import re
6 | import socket
7 | import sys
8 | import warnings
9 | from socket import error as SocketError
10 | from socket import timeout as SocketTimeout
11 | 
12 | from ._collections import HTTPHeaderDict
13 | from .connection import (
14 |     BaseSSLError,
15 |     BrokenPipeError,
16 |     DummyConnection,
17 |     HTTPConnection,
18 |     HTTPException,
19 |     HTTPSConnection,
20 |     VerifiedHTTPSConnection,
21 |     port_by_scheme,
22 | )
23 | from .exceptions import (
24 |     ClosedPoolError,
25 |     EmptyPoolError,
26 |     HeaderParsingError,
27 |     HostChangedError,
28 |     InsecureRequestWarning,
29 |     LocationValueError,
30 |     MaxRetryError,
31 |     NewConnectionError,
32 |     ProtocolError,
33 |     ProxyError,
34 |     ReadTimeoutError,
35 |     SSLError,
36 |     TimeoutError,
37 | )
38 | from .packages import six
39 | from .packages.six.moves import queue
40 | from .request import RequestMethods
41 | from .response import HTTPResponse
42 | from .util.connection import is_connection_dropped
43 | from .util.proxy import connection_requires_http_tunnel
44 | from .util.queue import LifoQueue
45 | from .util.request import set_file_position
46 | from .util.response import assert_header_parsing
47 | from .util.retry import Retry
48 | from .util.ssl_match_hostname import CertificateError
49 | from .util.timeout import Timeout
50 | from .util.url import Url, _encode_target
51 | from .util.url import _normalize_host as normalize_host
52 | from .util.url import get_host, parse_url
53 | 
54 | try:  # Platform-specific: Python 3
55 |     import weakref
56 | 
57 |     weakref_finalize = weakref.finalize
58 | except AttributeError:  # Platform-specific: Python 2
59 |     from .packages.backports.weakref_finalize import weakref_finalize
60 | 
61 | xrange = six.moves.xrange
62 | 
63 | log = logging.getLogger(__name__)
64 | 
65 | _Default = object()
66 | 
67 | 
68 | # Pool objects
69 | class ConnectionPool(object):
70 |     """
71 |     Base class for all connection pools, such as
72 |     :class:`.HTTPConnectionPool` and :class:`.HTTPSConnectionPool`.
73 | 
74 |     .. note::
75 |        ConnectionPool.urlopen() does not normalize or percent-encode target URIs
76 |        which is useful if your target server doesn't support percent-encoded
77 |        target URIs.
78 |     """
79 | 
80 |     scheme = None
81 |     QueueCls = LifoQueue
82 | 
83 |     def __init__(self, host, port=None):
84 |         if not host:
85 |             raise LocationValueError("No host specified.")
86 | 
87 |         self.host = _normalize_host(host, scheme=self.scheme)
88 |         self._proxy_host = host.lower()
89 |         self.port = port
90 | 
91 |     def __str__(self):
92 |         return "%s(host=%r, port=%r)" % (type(self).__name__, self.host, self.port)
93 | 
94 |     def __enter__(self):
95 |         return self
96 | 
97 |     def __exit__(self, exc_type, exc_val, exc_tb):
98 |         self.close()
99 |         # Return False to re-raise any potential exceptions
100 |         return False
101 | 
102 |     def close(self):
103 |         """
104 |         Close all pooled connections and disable the pool.
105 |         """
106 |         pass
107 | 
108 | 
109 | # This is taken from http://hg.python.org/cpython/file/7aaba721ebc0/Lib/socket.py#l252
110 | _blocking_errnos = {errno.EAGAIN, errno.EWOULDBLOCK}
111 | 
112 | 
113 | class HTTPConnectionPool(ConnectionPool, RequestMethods):
114 |     """
115 |     Thread-safe connection pool for one host.
116 | 
117 |     :param host:
118 |         Host used for this HTTP Connection (e.g. "localhost"), passed into
119 |         :class:`http.client.HTTPConnection`.
120 | 
121 |     :param port:
122 |         Port used for this HTTP Connection (None is equivalent to 80), passed
123 |         into :class:`http.client.HTTPConnection`.
124 | 
125 |     :param strict:
126 |         Causes BadStatusLine to be raised if the status line can't be parsed
127 |         as a valid HTTP/1.0 or 1.1 status line, passed into
128 |         :class:`http.client.HTTPConnection`.
129 | 
130 |         .. note::
131 |            Only works in Python 2. This parameter is ignored in Python 3.
132 | 
133 |     :param timeout:
134 |         Socket timeout in seconds for each individual connection. This can
135 |         be a float or integer, which sets the timeout for the HTTP request,
136 |         or an instance of :class:`urllib3.util.Timeout` which gives you more
137 |         fine-grained control over request timeouts. After the constructor has
138 |         been parsed, this is always a `urllib3.util.Timeout` object.
139 | 
140 |     :param maxsize:
141 |         Number of connections to save that can be reused. More than 1 is useful
142 |         in multithreaded situations. If ``block`` is set to False, more
143 |         connections will be created but they will not be saved once they've
144 |         been used.
145 | 
146 |     :param block:
147 |         If set to True, no more than ``maxsize`` connections will be used at
148 |         a time. When no free connections are available, the call will block
149 |         until a connection has been released. This is a useful side effect for
150 |         particular multithreaded situations where one does not want to use more
151 |         than maxsize connections per host to prevent flooding.
152 | 
153 |     :param headers:
154 |         Headers to include with all requests, unless other headers are given
155 |         explicitly.
156 | 
157 |     :param retries:
158 |         Retry configuration to use by default with requests in this pool.
159 | 
160 |     :param _proxy:
161 |         Parsed proxy URL, should not be used directly, instead, see
162 |         :class:`urllib3.ProxyManager`
163 | 
164 |     :param _proxy_headers:
165 |         A dictionary with proxy headers, should not be used directly,
166 |         instead, see :class:`urllib3.ProxyManager`
167 | 
168 |     :param \\**conn_kw:
169 |         Additional parameters are used to create fresh :class:`urllib3.connection.HTTPConnection`,
170 |         :class:`urllib3.connection.HTTPSConnection` instances.
171 |     """
172 | 
173 |     scheme = "http"
174 |     ConnectionCls = HTTPConnection
175 |     ResponseCls = HTTPResponse
176 | 
177 |     def __init__(
178 |         self,
179 |         host,
180 |         port=None,
181 |         strict=False,
182 |         timeout=Timeout.DEFAULT_TIMEOUT,
183 |         maxsize=1,
184 |         block=False,
185 |         headers=None,
186 |         retries=None,
187 |         _proxy=None,
188 |         _proxy_headers=None,
189 |         _proxy_config=None,
190 |         **conn_kw
191 |     ):
192 |         ConnectionPool.__init__(self, host, port)
193 |         RequestMethods.__init__(self, headers)
194 | 
195 |         self.strict = strict
196 | 
197 |         if not isinstance(timeout, Timeout):
198 |             timeout = Timeout.from_float(timeout)
199 | 
200 |         if retries is None:
201 |             retries = Retry.DEFAULT
202 | 
203 |         self.timeout = timeout
204 |         self.retries = retries
205 | 
206 |         self.pool = self.QueueCls(maxsize)
207 |         self.block = block
208 | 
209 |         self.proxy = _proxy
210 |         self.proxy_headers = _proxy_headers or {}
211 |         self.proxy_config = _proxy_config
212 | 
213 |         # Fill the queue up so that doing get() on it will block properly
214 |         for _ in xrange(maxsize):
215 |             self.pool.put(None)
216 | 
217 |         # These are mostly for testing and debugging purposes.
218 |         self.num_connections = 0
219 |         self.num_requests = 0
220 |         self.conn_kw = conn_kw
221 | 
222 |         if self.proxy:
223 |             # Enable Nagle's algorithm for proxies, to avoid packet fragmentation.
224 |             # We cannot know if the user has added default socket options, so we cannot replace the
225 |             # list.
226 |             self.conn_kw.setdefault("socket_options", [])
227 | 
228 |             self.conn_kw["proxy"] = self.proxy
229 |             self.conn_kw["proxy_config"] = self.proxy_config
230 | 
231 |         # Do not pass 'self' as callback to 'finalize'.
232 |         # Then the 'finalize' would keep an endless living (leak) to self.
233 |         # By just passing a reference to the pool allows the garbage collector
234 |         # to free self if nobody else has a reference to it.
235 |         pool = self.pool
236 | 
237 |         # Close all the HTTPConnections in the pool before the
238 |         # HTTPConnectionPool object is garbage collected.
239 |         weakref_finalize(self, _close_pool_connections, pool)
240 | 
241 |     def _new_conn(self):
242 |         """
243 |         Return a fresh :class:`HTTPConnection`.
244 |         """
245 |         self.num_connections += 1
246 |         log.debug(
247 |             "Starting new HTTP connection (%d): %s:%s",
248 |             self.num_connections,
249 |             self.host,
250 |             self.port or "80",
251 |         )
252 | 
253 |         conn = self.ConnectionCls(
254 |             host=self.host,
255 |             port=self.port,
256 |             timeout=self.timeout.connect_timeout,
257 |             strict=self.strict,
258 |             **self.conn_kw
259 |         )
260 |         return conn
261 | 
262 |     def _get_conn(self, timeout=None):
263 |         """
264 |         Get a connection. Will return a pooled connection if one is available.
265 | 
266 |         If no connections are available and :prop:`.block` is ``False``, then a
267 |         fresh connection is returned.
268 | 
269 |         :param timeout:
270 |             Seconds to wait before giving up and raising
271 |             :class:`urllib3.exceptions.EmptyPoolError` if the pool is empty and
272 |             :prop:`.block` is ``True``.
273 |         """
274 |         conn = None
275 |         try:
276 |             conn = self.pool.get(block=self.block, timeout=timeout)
277 | 
278 |         except AttributeError:  # self.pool is None
279 |             raise ClosedPoolError(self, "Pool is closed.")
280 | 
281 |         except queue.Empty:
282 |             if self.block:
283 |                 raise EmptyPoolError(
284 |                     self,
285 |                     "Pool reached maximum size and no more connections are allowed.",
286 |                 )
287 |             pass  # Oh well, we'll create a new connection then
288 | 
289 |         # If this is a persistent connection, check if it got disconnected
290 |         if conn and is_connection_dropped(conn):
291 |             log.debug("Resetting dropped connection: %s", self.host)
292 |             conn.close()
293 |             if getattr(conn, "auto_open", 1) == 0:
294 |                 # This is a proxied connection that has been mutated by
295 |                 # http.client._tunnel() and cannot be reused (since it would
296 |                 # attempt to bypass the proxy)
297 |                 conn = None
298 | 
299 |         return conn or self._new_conn()
300 | 
301 |     def _put_conn(self, conn):
302 |         """
303 |         Put a connection back into the pool.
304 | 
305 |         :param conn:
306 |             Connection object for the current host and port as returned by
307 |             :meth:`._new_conn` or :meth:`._get_conn`.
308 | 
309 |         If the pool is already full, the connection is closed and discarded
310 |         because we exceeded maxsize. If connections are discarded frequently,
311 |         then maxsize should be increased.
312 | 
313 |         If the pool is closed, then the connection will be closed and discarded.
314 |         """
315 |         try:
316 |             self.pool.put(conn, block=False)
317 |             return  # Everything is dandy, done.
318 |         except AttributeError:
319 |             # self.pool is None.
320 |             pass
321 |         except queue.Full:
322 |             # This should never happen if self.block == True
323 |             log.warning(
324 |                 "Connection pool is full, discarding connection: %s. Connection pool size: %s",
325 |                 self.host,
326 |                 self.pool.qsize(),
327 |             )
328 |         # Connection never got put back into the pool, close it.
329 |         if conn:
330 |             conn.close()
331 | 
332 |     def _validate_conn(self, conn):
333 |         """
334 |         Called right before a request is made, after the socket is created.
335 |         """
336 |         pass
337 | 
338 |     def _prepare_proxy(self, conn):
339 |         # Nothing to do for HTTP connections.
340 |         pass
341 | 
342 |     def _get_timeout(self, timeout):
343 |         """Helper that always returns a :class:`urllib3.util.Timeout`"""
344 |         if timeout is _Default:
345 |             return self.timeout.clone()
346 | 
347 |         if isinstance(timeout, Timeout):
348 |             return timeout.clone()
349 |         else:
350 |             # User passed us an int/float. This is for backwards compatibility,
351 |             # can be removed later
352 |             return Timeout.from_float(timeout)
353 | 
354 |     def _raise_timeout(self, err, url, timeout_value):
355 |         """Is the error actually a timeout? Will raise a ReadTimeout or pass"""
356 | 
357 |         if isinstance(err, SocketTimeout):
358 |             raise ReadTimeoutError(
359 |                 self, url, "Read timed out. (read timeout=%s)" % timeout_value
360 |             )
361 | 
362 |         # See the above comment about EAGAIN in Python 3. In Python 2 we have
363 |         # to specifically catch it and throw the timeout error
364 |         if hasattr(err, "errno") and err.errno in _blocking_errnos:
365 |             raise ReadTimeoutError(
366 |                 self, url, "Read timed out. (read timeout=%s)" % timeout_value
367 |             )
368 | 
369 |         # Catch possible read timeouts thrown as SSL errors. If not the
370 |         # case, rethrow the original. We need to do this because of:
371 |         # http://bugs.python.org/issue10272
[TRUNCATED]
```

.venv/lib/python3.13/site-packages/pip/_vendor/urllib3/exceptions.py
```
1 | from __future__ import absolute_import
2 | 
3 | from .packages.six.moves.http_client import IncompleteRead as httplib_IncompleteRead
4 | 
5 | # Base Exceptions
6 | 
7 | 
8 | class HTTPError(Exception):
9 |     """Base exception used by this module."""
10 | 
11 |     pass
12 | 
13 | 
14 | class HTTPWarning(Warning):
15 |     """Base warning used by this module."""
16 | 
17 |     pass
18 | 
19 | 
20 | class PoolError(HTTPError):
21 |     """Base exception for errors caused within a pool."""
22 | 
23 |     def __init__(self, pool, message):
24 |         self.pool = pool
25 |         HTTPError.__init__(self, "%s: %s" % (pool, message))
26 | 
27 |     def __reduce__(self):
28 |         # For pickling purposes.
29 |         return self.__class__, (None, None)
30 | 
31 | 
32 | class RequestError(PoolError):
33 |     """Base exception for PoolErrors that have associated URLs."""
34 | 
35 |     def __init__(self, pool, url, message):
36 |         self.url = url
37 |         PoolError.__init__(self, pool, message)
38 | 
39 |     def __reduce__(self):
40 |         # For pickling purposes.
41 |         return self.__class__, (None, self.url, None)
42 | 
43 | 
44 | class SSLError(HTTPError):
45 |     """Raised when SSL certificate fails in an HTTPS connection."""
46 | 
47 |     pass
48 | 
49 | 
50 | class ProxyError(HTTPError):
51 |     """Raised when the connection to a proxy fails."""
52 | 
53 |     def __init__(self, message, error, *args):
54 |         super(ProxyError, self).__init__(message, error, *args)
55 |         self.original_error = error
56 | 
57 | 
58 | class DecodeError(HTTPError):
59 |     """Raised when automatic decoding based on Content-Type fails."""
60 | 
61 |     pass
62 | 
63 | 
64 | class ProtocolError(HTTPError):
65 |     """Raised when something unexpected happens mid-request/response."""
66 | 
67 |     pass
68 | 
69 | 
70 | #: Renamed to ProtocolError but aliased for backwards compatibility.
71 | ConnectionError = ProtocolError
72 | 
73 | 
74 | # Leaf Exceptions
75 | 
76 | 
77 | class MaxRetryError(RequestError):
78 |     """Raised when the maximum number of retries is exceeded.
79 | 
80 |     :param pool: The connection pool
81 |     :type pool: :class:`~urllib3.connectionpool.HTTPConnectionPool`
82 |     :param string url: The requested Url
83 |     :param exceptions.Exception reason: The underlying error
84 | 
85 |     """
86 | 
87 |     def __init__(self, pool, url, reason=None):
88 |         self.reason = reason
89 | 
90 |         message = "Max retries exceeded with url: %s (Caused by %r)" % (url, reason)
91 | 
92 |         RequestError.__init__(self, pool, url, message)
93 | 
94 | 
95 | class HostChangedError(RequestError):
96 |     """Raised when an existing pool gets a request for a foreign host."""
97 | 
98 |     def __init__(self, pool, url, retries=3):
99 |         message = "Tried to open a foreign host with url: %s" % url
100 |         RequestError.__init__(self, pool, url, message)
101 |         self.retries = retries
102 | 
103 | 
104 | class TimeoutStateError(HTTPError):
105 |     """Raised when passing an invalid state to a timeout"""
106 | 
107 |     pass
108 | 
109 | 
110 | class TimeoutError(HTTPError):
111 |     """Raised when a socket timeout error occurs.
112 | 
113 |     Catching this error will catch both :exc:`ReadTimeoutErrors
114 |     <ReadTimeoutError>` and :exc:`ConnectTimeoutErrors <ConnectTimeoutError>`.
115 |     """
116 | 
117 |     pass
118 | 
119 | 
120 | class ReadTimeoutError(TimeoutError, RequestError):
121 |     """Raised when a socket timeout occurs while receiving data from a server"""
122 | 
123 |     pass
124 | 
125 | 
126 | # This timeout error does not have a URL attached and needs to inherit from the
127 | # base HTTPError
128 | class ConnectTimeoutError(TimeoutError):
129 |     """Raised when a socket timeout occurs while connecting to a server"""
130 | 
131 |     pass
132 | 
133 | 
134 | class NewConnectionError(ConnectTimeoutError, PoolError):
135 |     """Raised when we fail to establish a new connection. Usually ECONNREFUSED."""
136 | 
137 |     pass
138 | 
139 | 
140 | class EmptyPoolError(PoolError):
141 |     """Raised when a pool runs out of connections and no more are allowed."""
142 | 
143 |     pass
144 | 
145 | 
146 | class ClosedPoolError(PoolError):
147 |     """Raised when a request enters a pool after the pool has been closed."""
148 | 
149 |     pass
150 | 
151 | 
152 | class LocationValueError(ValueError, HTTPError):
153 |     """Raised when there is something wrong with a given URL input."""
154 | 
155 |     pass
156 | 
157 | 
158 | class LocationParseError(LocationValueError):
159 |     """Raised when get_host or similar fails to parse the URL input."""
160 | 
161 |     def __init__(self, location):
162 |         message = "Failed to parse: %s" % location
163 |         HTTPError.__init__(self, message)
164 | 
165 |         self.location = location
166 | 
167 | 
168 | class URLSchemeUnknown(LocationValueError):
169 |     """Raised when a URL input has an unsupported scheme."""
170 | 
171 |     def __init__(self, scheme):
172 |         message = "Not supported URL scheme %s" % scheme
173 |         super(URLSchemeUnknown, self).__init__(message)
174 | 
175 |         self.scheme = scheme
176 | 
177 | 
178 | class ResponseError(HTTPError):
179 |     """Used as a container for an error reason supplied in a MaxRetryError."""
180 | 
181 |     GENERIC_ERROR = "too many error responses"
182 |     SPECIFIC_ERROR = "too many {status_code} error responses"
183 | 
184 | 
185 | class SecurityWarning(HTTPWarning):
186 |     """Warned when performing security reducing actions"""
187 | 
188 |     pass
189 | 
190 | 
191 | class SubjectAltNameWarning(SecurityWarning):
192 |     """Warned when connecting to a host with a certificate missing a SAN."""
193 | 
194 |     pass
195 | 
196 | 
197 | class InsecureRequestWarning(SecurityWarning):
198 |     """Warned when making an unverified HTTPS request."""
199 | 
200 |     pass
201 | 
202 | 
203 | class SystemTimeWarning(SecurityWarning):
204 |     """Warned when system time is suspected to be wrong"""
205 | 
206 |     pass
207 | 
208 | 
209 | class InsecurePlatformWarning(SecurityWarning):
210 |     """Warned when certain TLS/SSL configuration is not available on a platform."""
211 | 
212 |     pass
213 | 
214 | 
215 | class SNIMissingWarning(HTTPWarning):
216 |     """Warned when making a HTTPS request without SNI available."""
217 | 
218 |     pass
219 | 
220 | 
221 | class DependencyWarning(HTTPWarning):
222 |     """
223 |     Warned when an attempt is made to import a module with missing optional
224 |     dependencies.
225 |     """
226 | 
227 |     pass
228 | 
229 | 
230 | class ResponseNotChunked(ProtocolError, ValueError):
231 |     """Response needs to be chunked in order to read it as chunks."""
232 | 
233 |     pass
234 | 
235 | 
236 | class BodyNotHttplibCompatible(HTTPError):
237 |     """
238 |     Body should be :class:`http.client.HTTPResponse` like
239 |     (have an fp attribute which returns raw chunks) for read_chunked().
240 |     """
241 | 
242 |     pass
243 | 
244 | 
245 | class IncompleteRead(HTTPError, httplib_IncompleteRead):
246 |     """
247 |     Response length doesn't match expected Content-Length
248 | 
249 |     Subclass of :class:`http.client.IncompleteRead` to allow int value
250 |     for ``partial`` to avoid creating large objects on streamed reads.
251 |     """
252 | 
253 |     def __init__(self, partial, expected):
254 |         super(IncompleteRead, self).__init__(partial, expected)
255 | 
256 |     def __repr__(self):
257 |         return "IncompleteRead(%i bytes read, %i more expected)" % (
258 |             self.partial,
259 |             self.expected,
260 |         )
261 | 
262 | 
263 | class InvalidChunkLength(HTTPError, httplib_IncompleteRead):
264 |     """Invalid chunk length in a chunked response."""
265 | 
266 |     def __init__(self, response, length):
267 |         super(InvalidChunkLength, self).__init__(
268 |             response.tell(), response.length_remaining
269 |         )
270 |         self.response = response
271 |         self.length = length
272 | 
273 |     def __repr__(self):
274 |         return "InvalidChunkLength(got length %r, %i bytes read)" % (
275 |             self.length,
276 |             self.partial,
277 |         )
278 | 
279 | 
280 | class InvalidHeader(HTTPError):
281 |     """The header provided was somehow invalid."""
282 | 
283 |     pass
284 | 
285 | 
286 | class ProxySchemeUnknown(AssertionError, URLSchemeUnknown):
287 |     """ProxyManager does not support the supplied scheme"""
288 | 
289 |     # TODO(t-8ch): Stop inheriting from AssertionError in v2.0.
290 | 
291 |     def __init__(self, scheme):
292 |         # 'localhost' is here because our URL parser parses
293 |         # localhost:8080 -> scheme=localhost, remove if we fix this.
294 |         if scheme == "localhost":
295 |             scheme = None
296 |         if scheme is None:
297 |             message = "Proxy URL had no scheme, should start with http:// or https://"
298 |         else:
299 |             message = (
300 |                 "Proxy URL had unsupported scheme %s, should use http:// or https://"
301 |                 % scheme
302 |             )
303 |         super(ProxySchemeUnknown, self).__init__(message)
304 | 
305 | 
306 | class ProxySchemeUnsupported(ValueError):
307 |     """Fetching HTTPS resources through HTTPS proxies is unsupported"""
308 | 
309 |     pass
310 | 
311 | 
312 | class HeaderParsingError(HTTPError):
313 |     """Raised by assert_header_parsing, but we convert it to a log.warning statement."""
314 | 
315 |     def __init__(self, defects, unparsed_data):
316 |         message = "%s, unparsed data: %r" % (defects or "Unknown", unparsed_data)
317 |         super(HeaderParsingError, self).__init__(message)
318 | 
319 | 
320 | class UnrewindableBodyError(HTTPError):
321 |     """urllib3 encountered an error when trying to rewind a body"""
322 | 
323 |     pass
```

.venv/lib/python3.13/site-packages/pip/_vendor/urllib3/fields.py
```
1 | from __future__ import absolute_import
2 | 
3 | import email.utils
4 | import mimetypes
5 | import re
6 | 
7 | from .packages import six
8 | 
9 | 
10 | def guess_content_type(filename, default="application/octet-stream"):
11 |     """
12 |     Guess the "Content-Type" of a file.
13 | 
14 |     :param filename:
15 |         The filename to guess the "Content-Type" of using :mod:`mimetypes`.
16 |     :param default:
17 |         If no "Content-Type" can be guessed, default to `default`.
18 |     """
19 |     if filename:
20 |         return mimetypes.guess_type(filename)[0] or default
21 |     return default
22 | 
23 | 
24 | def format_header_param_rfc2231(name, value):
25 |     """
26 |     Helper function to format and quote a single header parameter using the
27 |     strategy defined in RFC 2231.
28 | 
29 |     Particularly useful for header parameters which might contain
30 |     non-ASCII values, like file names. This follows
31 |     `RFC 2388 Section 4.4 <https://tools.ietf.org/html/rfc2388#section-4.4>`_.
32 | 
33 |     :param name:
34 |         The name of the parameter, a string expected to be ASCII only.
35 |     :param value:
36 |         The value of the parameter, provided as ``bytes`` or `str``.
37 |     :ret:
38 |         An RFC-2231-formatted unicode string.
39 |     """
40 |     if isinstance(value, six.binary_type):
41 |         value = value.decode("utf-8")
42 | 
43 |     if not any(ch in value for ch in '"\\\r\n'):
44 |         result = u'%s="%s"' % (name, value)
45 |         try:
46 |             result.encode("ascii")
47 |         except (UnicodeEncodeError, UnicodeDecodeError):
48 |             pass
49 |         else:
50 |             return result
51 | 
52 |     if six.PY2:  # Python 2:
53 |         value = value.encode("utf-8")
54 | 
55 |     # encode_rfc2231 accepts an encoded string and returns an ascii-encoded
56 |     # string in Python 2 but accepts and returns unicode strings in Python 3
57 |     value = email.utils.encode_rfc2231(value, "utf-8")
58 |     value = "%s*=%s" % (name, value)
59 | 
60 |     if six.PY2:  # Python 2:
61 |         value = value.decode("utf-8")
62 | 
63 |     return value
64 | 
65 | 
66 | _HTML5_REPLACEMENTS = {
67 |     u"\u0022": u"%22",
68 |     # Replace "\" with "\\".
69 |     u"\u005C": u"\u005C\u005C",
70 | }
71 | 
72 | # All control characters from 0x00 to 0x1F *except* 0x1B.
73 | _HTML5_REPLACEMENTS.update(
74 |     {
75 |         six.unichr(cc): u"%{:02X}".format(cc)
76 |         for cc in range(0x00, 0x1F + 1)
77 |         if cc not in (0x1B,)
78 |     }
79 | )
80 | 
81 | 
82 | def _replace_multiple(value, needles_and_replacements):
83 |     def replacer(match):
84 |         return needles_and_replacements[match.group(0)]
85 | 
86 |     pattern = re.compile(
87 |         r"|".join([re.escape(needle) for needle in needles_and_replacements.keys()])
88 |     )
89 | 
90 |     result = pattern.sub(replacer, value)
91 | 
92 |     return result
93 | 
94 | 
95 | def format_header_param_html5(name, value):
96 |     """
97 |     Helper function to format and quote a single header parameter using the
98 |     HTML5 strategy.
99 | 
100 |     Particularly useful for header parameters which might contain
101 |     non-ASCII values, like file names. This follows the `HTML5 Working Draft
102 |     Section 4.10.22.7`_ and matches the behavior of curl and modern browsers.
103 | 
104 |     .. _HTML5 Working Draft Section 4.10.22.7:
105 |         https://w3c.github.io/html/sec-forms.html#multipart-form-data
106 | 
107 |     :param name:
108 |         The name of the parameter, a string expected to be ASCII only.
109 |     :param value:
110 |         The value of the parameter, provided as ``bytes`` or `str``.
111 |     :ret:
112 |         A unicode string, stripped of troublesome characters.
113 |     """
114 |     if isinstance(value, six.binary_type):
115 |         value = value.decode("utf-8")
116 | 
117 |     value = _replace_multiple(value, _HTML5_REPLACEMENTS)
118 | 
119 |     return u'%s="%s"' % (name, value)
120 | 
121 | 
122 | # For backwards-compatibility.
123 | format_header_param = format_header_param_html5
124 | 
125 | 
126 | class RequestField(object):
127 |     """
128 |     A data container for request body parameters.
129 | 
130 |     :param name:
131 |         The name of this request field. Must be unicode.
132 |     :param data:
133 |         The data/value body.
134 |     :param filename:
135 |         An optional filename of the request field. Must be unicode.
136 |     :param headers:
137 |         An optional dict-like object of headers to initially use for the field.
138 |     :param header_formatter:
139 |         An optional callable that is used to encode and format the headers. By
140 |         default, this is :func:`format_header_param_html5`.
141 |     """
142 | 
143 |     def __init__(
144 |         self,
145 |         name,
146 |         data,
147 |         filename=None,
148 |         headers=None,
149 |         header_formatter=format_header_param_html5,
150 |     ):
151 |         self._name = name
152 |         self._filename = filename
153 |         self.data = data
154 |         self.headers = {}
155 |         if headers:
156 |             self.headers = dict(headers)
157 |         self.header_formatter = header_formatter
158 | 
159 |     @classmethod
160 |     def from_tuples(cls, fieldname, value, header_formatter=format_header_param_html5):
161 |         """
162 |         A :class:`~urllib3.fields.RequestField` factory from old-style tuple parameters.
163 | 
164 |         Supports constructing :class:`~urllib3.fields.RequestField` from
165 |         parameter of key/value strings AND key/filetuple. A filetuple is a
166 |         (filename, data, MIME type) tuple where the MIME type is optional.
167 |         For example::
168 | 
169 |             'foo': 'bar',
170 |             'fakefile': ('foofile.txt', 'contents of foofile'),
171 |             'realfile': ('barfile.txt', open('realfile').read()),
172 |             'typedfile': ('bazfile.bin', open('bazfile').read(), 'image/jpeg'),
173 |             'nonamefile': 'contents of nonamefile field',
174 | 
175 |         Field names and filenames must be unicode.
176 |         """
177 |         if isinstance(value, tuple):
178 |             if len(value) == 3:
179 |                 filename, data, content_type = value
180 |             else:
181 |                 filename, data = value
182 |                 content_type = guess_content_type(filename)
183 |         else:
184 |             filename = None
185 |             content_type = None
186 |             data = value
187 | 
188 |         request_param = cls(
189 |             fieldname, data, filename=filename, header_formatter=header_formatter
190 |         )
191 |         request_param.make_multipart(content_type=content_type)
192 | 
193 |         return request_param
194 | 
195 |     def _render_part(self, name, value):
196 |         """
197 |         Overridable helper function to format a single header parameter. By
198 |         default, this calls ``self.header_formatter``.
199 | 
200 |         :param name:
201 |             The name of the parameter, a string expected to be ASCII only.
202 |         :param value:
203 |             The value of the parameter, provided as a unicode string.
204 |         """
205 | 
206 |         return self.header_formatter(name, value)
207 | 
208 |     def _render_parts(self, header_parts):
209 |         """
210 |         Helper function to format and quote a single header.
211 | 
212 |         Useful for single headers that are composed of multiple items. E.g.,
213 |         'Content-Disposition' fields.
214 | 
215 |         :param header_parts:
216 |             A sequence of (k, v) tuples or a :class:`dict` of (k, v) to format
217 |             as `k1="v1"; k2="v2"; ...`.
218 |         """
219 |         parts = []
220 |         iterable = header_parts
221 |         if isinstance(header_parts, dict):
222 |             iterable = header_parts.items()
223 | 
224 |         for name, value in iterable:
225 |             if value is not None:
226 |                 parts.append(self._render_part(name, value))
227 | 
228 |         return u"; ".join(parts)
229 | 
230 |     def render_headers(self):
231 |         """
232 |         Renders the headers for this request field.
233 |         """
234 |         lines = []
235 | 
236 |         sort_keys = ["Content-Disposition", "Content-Type", "Content-Location"]
237 |         for sort_key in sort_keys:
238 |             if self.headers.get(sort_key, False):
239 |                 lines.append(u"%s: %s" % (sort_key, self.headers[sort_key]))
240 | 
241 |         for header_name, header_value in self.headers.items():
242 |             if header_name not in sort_keys:
243 |                 if header_value:
244 |                     lines.append(u"%s: %s" % (header_name, header_value))
245 | 
246 |         lines.append(u"\r\n")
247 |         return u"\r\n".join(lines)
248 | 
249 |     def make_multipart(
250 |         self, content_disposition=None, content_type=None, content_location=None
251 |     ):
252 |         """
253 |         Makes this request field into a multipart request field.
254 | 
255 |         This method overrides "Content-Disposition", "Content-Type" and
256 |         "Content-Location" headers to the request parameter.
257 | 
258 |         :param content_type:
259 |             The 'Content-Type' of the request body.
260 |         :param content_location:
261 |             The 'Content-Location' of the request body.
262 | 
263 |         """
264 |         self.headers["Content-Disposition"] = content_disposition or u"form-data"
265 |         self.headers["Content-Disposition"] += u"; ".join(
266 |             [
267 |                 u"",
268 |                 self._render_parts(
269 |                     ((u"name", self._name), (u"filename", self._filename))
270 |                 ),
271 |             ]
272 |         )
273 |         self.headers["Content-Type"] = content_type
274 |         self.headers["Content-Location"] = content_location
```

.venv/lib/python3.13/site-packages/pip/_vendor/urllib3/filepost.py
```
1 | from __future__ import absolute_import
2 | 
3 | import binascii
4 | import codecs
5 | import os
6 | from io import BytesIO
7 | 
8 | from .fields import RequestField
9 | from .packages import six
10 | from .packages.six import b
11 | 
12 | writer = codecs.lookup("utf-8")[3]
13 | 
14 | 
15 | def choose_boundary():
16 |     """
17 |     Our embarrassingly-simple replacement for mimetools.choose_boundary.
18 |     """
19 |     boundary = binascii.hexlify(os.urandom(16))
20 |     if not six.PY2:
21 |         boundary = boundary.decode("ascii")
22 |     return boundary
23 | 
24 | 
25 | def iter_field_objects(fields):
26 |     """
27 |     Iterate over fields.
28 | 
29 |     Supports list of (k, v) tuples and dicts, and lists of
30 |     :class:`~urllib3.fields.RequestField`.
31 | 
32 |     """
33 |     if isinstance(fields, dict):
34 |         i = six.iteritems(fields)
35 |     else:
36 |         i = iter(fields)
37 | 
38 |     for field in i:
39 |         if isinstance(field, RequestField):
40 |             yield field
41 |         else:
42 |             yield RequestField.from_tuples(*field)
43 | 
44 | 
45 | def iter_fields(fields):
46 |     """
47 |     .. deprecated:: 1.6
48 | 
49 |     Iterate over fields.
50 | 
51 |     The addition of :class:`~urllib3.fields.RequestField` makes this function
52 |     obsolete. Instead, use :func:`iter_field_objects`, which returns
53 |     :class:`~urllib3.fields.RequestField` objects.
54 | 
55 |     Supports list of (k, v) tuples and dicts.
56 |     """
57 |     if isinstance(fields, dict):
58 |         return ((k, v) for k, v in six.iteritems(fields))
59 | 
60 |     return ((k, v) for k, v in fields)
61 | 
62 | 
63 | def encode_multipart_formdata(fields, boundary=None):
64 |     """
65 |     Encode a dictionary of ``fields`` using the multipart/form-data MIME format.
66 | 
67 |     :param fields:
68 |         Dictionary of fields or list of (key, :class:`~urllib3.fields.RequestField`).
69 | 
70 |     :param boundary:
71 |         If not specified, then a random boundary will be generated using
72 |         :func:`urllib3.filepost.choose_boundary`.
73 |     """
74 |     body = BytesIO()
75 |     if boundary is None:
76 |         boundary = choose_boundary()
77 | 
78 |     for field in iter_field_objects(fields):
79 |         body.write(b("--%s\r\n" % (boundary)))
80 | 
81 |         writer(body).write(field.render_headers())
82 |         data = field.data
83 | 
84 |         if isinstance(data, int):
85 |             data = str(data)  # Backwards compatibility
86 | 
87 |         if isinstance(data, six.text_type):
88 |             writer(body).write(data)
89 |         else:
90 |             body.write(data)
91 | 
92 |         body.write(b"\r\n")
93 | 
94 |     body.write(b("--%s--\r\n" % (boundary)))
95 | 
96 |     content_type = str("multipart/form-data; boundary=%s" % boundary)
97 | 
98 |     return body.getvalue(), content_type
```

.venv/lib/python3.13/site-packages/pip/_vendor/urllib3/poolmanager.py
```
1 | from __future__ import absolute_import
2 | 
3 | import collections
4 | import functools
5 | import logging
6 | 
7 | from ._collections import HTTPHeaderDict, RecentlyUsedContainer
8 | from .connectionpool import HTTPConnectionPool, HTTPSConnectionPool, port_by_scheme
9 | from .exceptions import (
10 |     LocationValueError,
11 |     MaxRetryError,
12 |     ProxySchemeUnknown,
13 |     ProxySchemeUnsupported,
14 |     URLSchemeUnknown,
15 | )
16 | from .packages import six
17 | from .packages.six.moves.urllib.parse import urljoin
18 | from .request import RequestMethods
19 | from .util.proxy import connection_requires_http_tunnel
20 | from .util.retry import Retry
21 | from .util.url import parse_url
22 | 
23 | __all__ = ["PoolManager", "ProxyManager", "proxy_from_url"]
24 | 
25 | 
26 | log = logging.getLogger(__name__)
27 | 
28 | SSL_KEYWORDS = (
29 |     "key_file",
30 |     "cert_file",
31 |     "cert_reqs",
32 |     "ca_certs",
33 |     "ssl_version",
34 |     "ca_cert_dir",
35 |     "ssl_context",
36 |     "key_password",
37 |     "server_hostname",
38 | )
39 | 
40 | # All known keyword arguments that could be provided to the pool manager, its
41 | # pools, or the underlying connections. This is used to construct a pool key.
42 | _key_fields = (
43 |     "key_scheme",  # str
44 |     "key_host",  # str
45 |     "key_port",  # int
46 |     "key_timeout",  # int or float or Timeout
47 |     "key_retries",  # int or Retry
48 |     "key_strict",  # bool
49 |     "key_block",  # bool
50 |     "key_source_address",  # str
51 |     "key_key_file",  # str
52 |     "key_key_password",  # str
53 |     "key_cert_file",  # str
54 |     "key_cert_reqs",  # str
55 |     "key_ca_certs",  # str
56 |     "key_ssl_version",  # str
57 |     "key_ca_cert_dir",  # str
58 |     "key_ssl_context",  # instance of ssl.SSLContext or urllib3.util.ssl_.SSLContext
59 |     "key_maxsize",  # int
60 |     "key_headers",  # dict
61 |     "key__proxy",  # parsed proxy url
62 |     "key__proxy_headers",  # dict
63 |     "key__proxy_config",  # class
64 |     "key_socket_options",  # list of (level (int), optname (int), value (int or str)) tuples
65 |     "key__socks_options",  # dict
66 |     "key_assert_hostname",  # bool or string
67 |     "key_assert_fingerprint",  # str
68 |     "key_server_hostname",  # str
69 | )
70 | 
71 | #: The namedtuple class used to construct keys for the connection pool.
72 | #: All custom key schemes should include the fields in this key at a minimum.
73 | PoolKey = collections.namedtuple("PoolKey", _key_fields)
74 | 
75 | _proxy_config_fields = ("ssl_context", "use_forwarding_for_https")
76 | ProxyConfig = collections.namedtuple("ProxyConfig", _proxy_config_fields)
77 | 
78 | 
79 | def _default_key_normalizer(key_class, request_context):
80 |     """
81 |     Create a pool key out of a request context dictionary.
82 | 
83 |     According to RFC 3986, both the scheme and host are case-insensitive.
84 |     Therefore, this function normalizes both before constructing the pool
85 |     key for an HTTPS request. If you wish to change this behaviour, provide
86 |     alternate callables to ``key_fn_by_scheme``.
87 | 
88 |     :param key_class:
89 |         The class to use when constructing the key. This should be a namedtuple
90 |         with the ``scheme`` and ``host`` keys at a minimum.
91 |     :type  key_class: namedtuple
92 |     :param request_context:
93 |         A dictionary-like object that contain the context for a request.
94 |     :type  request_context: dict
95 | 
96 |     :return: A namedtuple that can be used as a connection pool key.
97 |     :rtype:  PoolKey
98 |     """
99 |     # Since we mutate the dictionary, make a copy first
100 |     context = request_context.copy()
101 |     context["scheme"] = context["scheme"].lower()
102 |     context["host"] = context["host"].lower()
103 | 
104 |     # These are both dictionaries and need to be transformed into frozensets
105 |     for key in ("headers", "_proxy_headers", "_socks_options"):
106 |         if key in context and context[key] is not None:
107 |             context[key] = frozenset(context[key].items())
108 | 
109 |     # The socket_options key may be a list and needs to be transformed into a
110 |     # tuple.
111 |     socket_opts = context.get("socket_options")
112 |     if socket_opts is not None:
113 |         context["socket_options"] = tuple(socket_opts)
114 | 
115 |     # Map the kwargs to the names in the namedtuple - this is necessary since
116 |     # namedtuples can't have fields starting with '_'.
117 |     for key in list(context.keys()):
118 |         context["key_" + key] = context.pop(key)
119 | 
120 |     # Default to ``None`` for keys missing from the context
121 |     for field in key_class._fields:
122 |         if field not in context:
123 |             context[field] = None
124 | 
125 |     return key_class(**context)
126 | 
127 | 
128 | #: A dictionary that maps a scheme to a callable that creates a pool key.
129 | #: This can be used to alter the way pool keys are constructed, if desired.
130 | #: Each PoolManager makes a copy of this dictionary so they can be configured
131 | #: globally here, or individually on the instance.
132 | key_fn_by_scheme = {
133 |     "http": functools.partial(_default_key_normalizer, PoolKey),
134 |     "https": functools.partial(_default_key_normalizer, PoolKey),
135 | }
136 | 
137 | pool_classes_by_scheme = {"http": HTTPConnectionPool, "https": HTTPSConnectionPool}
138 | 
139 | 
140 | class PoolManager(RequestMethods):
141 |     """
142 |     Allows for arbitrary requests while transparently keeping track of
143 |     necessary connection pools for you.
144 | 
145 |     :param num_pools:
146 |         Number of connection pools to cache before discarding the least
147 |         recently used pool.
148 | 
149 |     :param headers:
150 |         Headers to include with all requests, unless other headers are given
151 |         explicitly.
152 | 
153 |     :param \\**connection_pool_kw:
154 |         Additional parameters are used to create fresh
155 |         :class:`urllib3.connectionpool.ConnectionPool` instances.
156 | 
157 |     Example::
158 | 
159 |         >>> manager = PoolManager(num_pools=2)
160 |         >>> r = manager.request('GET', 'http://google.com/')
161 |         >>> r = manager.request('GET', 'http://google.com/mail')
162 |         >>> r = manager.request('GET', 'http://yahoo.com/')
163 |         >>> len(manager.pools)
164 |         2
165 | 
166 |     """
167 | 
168 |     proxy = None
169 |     proxy_config = None
170 | 
171 |     def __init__(self, num_pools=10, headers=None, **connection_pool_kw):
172 |         RequestMethods.__init__(self, headers)
173 |         self.connection_pool_kw = connection_pool_kw
174 |         self.pools = RecentlyUsedContainer(num_pools)
175 | 
176 |         # Locally set the pool classes and keys so other PoolManagers can
177 |         # override them.
178 |         self.pool_classes_by_scheme = pool_classes_by_scheme
179 |         self.key_fn_by_scheme = key_fn_by_scheme.copy()
180 | 
181 |     def __enter__(self):
182 |         return self
183 | 
184 |     def __exit__(self, exc_type, exc_val, exc_tb):
185 |         self.clear()
186 |         # Return False to re-raise any potential exceptions
187 |         return False
188 | 
189 |     def _new_pool(self, scheme, host, port, request_context=None):
190 |         """
191 |         Create a new :class:`urllib3.connectionpool.ConnectionPool` based on host, port, scheme, and
192 |         any additional pool keyword arguments.
193 | 
194 |         If ``request_context`` is provided, it is provided as keyword arguments
195 |         to the pool class used. This method is used to actually create the
196 |         connection pools handed out by :meth:`connection_from_url` and
197 |         companion methods. It is intended to be overridden for customization.
198 |         """
199 |         pool_cls = self.pool_classes_by_scheme[scheme]
200 |         if request_context is None:
201 |             request_context = self.connection_pool_kw.copy()
202 | 
203 |         # Although the context has everything necessary to create the pool,
204 |         # this function has historically only used the scheme, host, and port
205 |         # in the positional args. When an API change is acceptable these can
206 |         # be removed.
207 |         for key in ("scheme", "host", "port"):
208 |             request_context.pop(key, None)
209 | 
210 |         if scheme == "http":
211 |             for kw in SSL_KEYWORDS:
212 |                 request_context.pop(kw, None)
213 | 
214 |         return pool_cls(host, port, **request_context)
215 | 
216 |     def clear(self):
217 |         """
218 |         Empty our store of pools and direct them all to close.
219 | 
220 |         This will not affect in-flight connections, but they will not be
221 |         re-used after completion.
222 |         """
223 |         self.pools.clear()
224 | 
225 |     def connection_from_host(self, host, port=None, scheme="http", pool_kwargs=None):
226 |         """
227 |         Get a :class:`urllib3.connectionpool.ConnectionPool` based on the host, port, and scheme.
228 | 
229 |         If ``port`` isn't given, it will be derived from the ``scheme`` using
230 |         ``urllib3.connectionpool.port_by_scheme``. If ``pool_kwargs`` is
231 |         provided, it is merged with the instance's ``connection_pool_kw``
232 |         variable and used to create the new connection pool, if one is
233 |         needed.
234 |         """
235 | 
236 |         if not host:
237 |             raise LocationValueError("No host specified.")
238 | 
239 |         request_context = self._merge_pool_kwargs(pool_kwargs)
240 |         request_context["scheme"] = scheme or "http"
241 |         if not port:
242 |             port = port_by_scheme.get(request_context["scheme"].lower(), 80)
243 |         request_context["port"] = port
244 |         request_context["host"] = host
245 | 
246 |         return self.connection_from_context(request_context)
247 | 
248 |     def connection_from_context(self, request_context):
249 |         """
250 |         Get a :class:`urllib3.connectionpool.ConnectionPool` based on the request context.
251 | 
252 |         ``request_context`` must at least contain the ``scheme`` key and its
253 |         value must be a key in ``key_fn_by_scheme`` instance variable.
254 |         """
255 |         scheme = request_context["scheme"].lower()
256 |         pool_key_constructor = self.key_fn_by_scheme.get(scheme)
257 |         if not pool_key_constructor:
258 |             raise URLSchemeUnknown(scheme)
259 |         pool_key = pool_key_constructor(request_context)
260 | 
261 |         return self.connection_from_pool_key(pool_key, request_context=request_context)
262 | 
263 |     def connection_from_pool_key(self, pool_key, request_context=None):
264 |         """
265 |         Get a :class:`urllib3.connectionpool.ConnectionPool` based on the provided pool key.
266 | 
267 |         ``pool_key`` should be a namedtuple that only contains immutable
268 |         objects. At a minimum it must have the ``scheme``, ``host``, and
269 |         ``port`` fields.
270 |         """
271 |         with self.pools.lock:
272 |             # If the scheme, host, or port doesn't match existing open
273 |             # connections, open a new ConnectionPool.
274 |             pool = self.pools.get(pool_key)
275 |             if pool:
276 |                 return pool
277 | 
278 |             # Make a fresh ConnectionPool of the desired type
279 |             scheme = request_context["scheme"]
280 |             host = request_context["host"]
281 |             port = request_context["port"]
282 |             pool = self._new_pool(scheme, host, port, request_context=request_context)
283 |             self.pools[pool_key] = pool
284 | 
285 |         return pool
286 | 
287 |     def connection_from_url(self, url, pool_kwargs=None):
288 |         """
289 |         Similar to :func:`urllib3.connectionpool.connection_from_url`.
290 | 
291 |         If ``pool_kwargs`` is not provided and a new pool needs to be
292 |         constructed, ``self.connection_pool_kw`` is used to initialize
293 |         the :class:`urllib3.connectionpool.ConnectionPool`. If ``pool_kwargs``
294 |         is provided, it is used instead. Note that if a new pool does not
295 |         need to be created for the request, the provided ``pool_kwargs`` are
296 |         not used.
297 |         """
298 |         u = parse_url(url)
299 |         return self.connection_from_host(
300 |             u.host, port=u.port, scheme=u.scheme, pool_kwargs=pool_kwargs
301 |         )
302 | 
303 |     def _merge_pool_kwargs(self, override):
304 |         """
305 |         Merge a dictionary of override values for self.connection_pool_kw.
306 | 
307 |         This does not modify self.connection_pool_kw and returns a new dict.
308 |         Any keys in the override dictionary with a value of ``None`` are
309 |         removed from the merged dictionary.
310 |         """
311 |         base_pool_kwargs = self.connection_pool_kw.copy()
312 |         if override:
313 |             for key, value in override.items():
314 |                 if value is None:
315 |                     try:
316 |                         del base_pool_kwargs[key]
317 |                     except KeyError:
318 |                         pass
319 |                 else:
320 |                     base_pool_kwargs[key] = value
321 |         return base_pool_kwargs
322 | 
323 |     def _proxy_requires_url_absolute_form(self, parsed_url):
324 |         """
325 |         Indicates if the proxy requires the complete destination URL in the
326 |         request.  Normally this is only needed when not using an HTTP CONNECT
327 |         tunnel.
[TRUNCATED]
```

.venv/lib/python3.13/site-packages/pip/_vendor/urllib3/request.py
```
1 | from __future__ import absolute_import
2 | 
3 | import sys
4 | 
5 | from .filepost import encode_multipart_formdata
6 | from .packages import six
7 | from .packages.six.moves.urllib.parse import urlencode
8 | 
9 | __all__ = ["RequestMethods"]
10 | 
11 | 
12 | class RequestMethods(object):
13 |     """
14 |     Convenience mixin for classes who implement a :meth:`urlopen` method, such
15 |     as :class:`urllib3.HTTPConnectionPool` and
16 |     :class:`urllib3.PoolManager`.
17 | 
18 |     Provides behavior for making common types of HTTP request methods and
19 |     decides which type of request field encoding to use.
20 | 
21 |     Specifically,
22 | 
23 |     :meth:`.request_encode_url` is for sending requests whose fields are
24 |     encoded in the URL (such as GET, HEAD, DELETE).
25 | 
26 |     :meth:`.request_encode_body` is for sending requests whose fields are
27 |     encoded in the *body* of the request using multipart or www-form-urlencoded
28 |     (such as for POST, PUT, PATCH).
29 | 
30 |     :meth:`.request` is for making any kind of request, it will look up the
31 |     appropriate encoding format and use one of the above two methods to make
32 |     the request.
33 | 
34 |     Initializer parameters:
35 | 
36 |     :param headers:
37 |         Headers to include with all requests, unless other headers are given
38 |         explicitly.
39 |     """
40 | 
41 |     _encode_url_methods = {"DELETE", "GET", "HEAD", "OPTIONS"}
42 | 
43 |     def __init__(self, headers=None):
44 |         self.headers = headers or {}
45 | 
46 |     def urlopen(
47 |         self,
48 |         method,
49 |         url,
50 |         body=None,
51 |         headers=None,
52 |         encode_multipart=True,
53 |         multipart_boundary=None,
54 |         **kw
55 |     ):  # Abstract
56 |         raise NotImplementedError(
57 |             "Classes extending RequestMethods must implement "
58 |             "their own ``urlopen`` method."
59 |         )
60 | 
61 |     def request(self, method, url, fields=None, headers=None, **urlopen_kw):
62 |         """
63 |         Make a request using :meth:`urlopen` with the appropriate encoding of
64 |         ``fields`` based on the ``method`` used.
65 | 
66 |         This is a convenience method that requires the least amount of manual
67 |         effort. It can be used in most situations, while still having the
68 |         option to drop down to more specific methods when necessary, such as
69 |         :meth:`request_encode_url`, :meth:`request_encode_body`,
70 |         or even the lowest level :meth:`urlopen`.
71 |         """
72 |         method = method.upper()
73 | 
74 |         urlopen_kw["request_url"] = url
75 | 
76 |         if method in self._encode_url_methods:
77 |             return self.request_encode_url(
78 |                 method, url, fields=fields, headers=headers, **urlopen_kw
79 |             )
80 |         else:
81 |             return self.request_encode_body(
82 |                 method, url, fields=fields, headers=headers, **urlopen_kw
83 |             )
84 | 
85 |     def request_encode_url(self, method, url, fields=None, headers=None, **urlopen_kw):
86 |         """
87 |         Make a request using :meth:`urlopen` with the ``fields`` encoded in
88 |         the url. This is useful for request methods like GET, HEAD, DELETE, etc.
89 |         """
90 |         if headers is None:
91 |             headers = self.headers
92 | 
93 |         extra_kw = {"headers": headers}
94 |         extra_kw.update(urlopen_kw)
95 | 
96 |         if fields:
97 |             url += "?" + urlencode(fields)
98 | 
99 |         return self.urlopen(method, url, **extra_kw)
100 | 
101 |     def request_encode_body(
102 |         self,
103 |         method,
104 |         url,
105 |         fields=None,
106 |         headers=None,
107 |         encode_multipart=True,
108 |         multipart_boundary=None,
109 |         **urlopen_kw
110 |     ):
111 |         """
112 |         Make a request using :meth:`urlopen` with the ``fields`` encoded in
113 |         the body. This is useful for request methods like POST, PUT, PATCH, etc.
114 | 
115 |         When ``encode_multipart=True`` (default), then
116 |         :func:`urllib3.encode_multipart_formdata` is used to encode
117 |         the payload with the appropriate content type. Otherwise
118 |         :func:`urllib.parse.urlencode` is used with the
119 |         'application/x-www-form-urlencoded' content type.
120 | 
121 |         Multipart encoding must be used when posting files, and it's reasonably
122 |         safe to use it in other times too. However, it may break request
123 |         signing, such as with OAuth.
124 | 
125 |         Supports an optional ``fields`` parameter of key/value strings AND
126 |         key/filetuple. A filetuple is a (filename, data, MIME type) tuple where
127 |         the MIME type is optional. For example::
128 | 
129 |             fields = {
130 |                 'foo': 'bar',
131 |                 'fakefile': ('foofile.txt', 'contents of foofile'),
132 |                 'realfile': ('barfile.txt', open('realfile').read()),
133 |                 'typedfile': ('bazfile.bin', open('bazfile').read(),
134 |                               'image/jpeg'),
135 |                 'nonamefile': 'contents of nonamefile field',
136 |             }
137 | 
138 |         When uploading a file, providing a filename (the first parameter of the
139 |         tuple) is optional but recommended to best mimic behavior of browsers.
140 | 
141 |         Note that if ``headers`` are supplied, the 'Content-Type' header will
142 |         be overwritten because it depends on the dynamic random boundary string
143 |         which is used to compose the body of the request. The random boundary
144 |         string can be explicitly set with the ``multipart_boundary`` parameter.
145 |         """
146 |         if headers is None:
147 |             headers = self.headers
148 | 
149 |         extra_kw = {"headers": {}}
150 | 
151 |         if fields:
152 |             if "body" in urlopen_kw:
153 |                 raise TypeError(
154 |                     "request got values for both 'fields' and 'body', can only specify one."
155 |                 )
156 | 
157 |             if encode_multipart:
158 |                 body, content_type = encode_multipart_formdata(
159 |                     fields, boundary=multipart_boundary
160 |                 )
161 |             else:
162 |                 body, content_type = (
163 |                     urlencode(fields),
164 |                     "application/x-www-form-urlencoded",
165 |                 )
166 | 
167 |             extra_kw["body"] = body
168 |             extra_kw["headers"] = {"Content-Type": content_type}
169 | 
170 |         extra_kw["headers"].update(headers)
171 |         extra_kw.update(urlopen_kw)
172 | 
173 |         return self.urlopen(method, url, **extra_kw)
174 | 
175 | 
176 | if not six.PY2:
177 | 
178 |     class RequestModule(sys.modules[__name__].__class__):
179 |         def __call__(self, *args, **kwargs):
180 |             """
181 |             If user tries to call this module directly urllib3 v2.x style raise an error to the user
182 |             suggesting they may need urllib3 v2
183 |             """
184 |             raise TypeError(
185 |                 "'module' object is not callable\n"
186 |                 "urllib3.request() method is not supported in this release, "
187 |                 "upgrade to urllib3 v2 to use it\n"
188 |                 "see https://urllib3.readthedocs.io/en/stable/v2-migration-guide.html"
189 |             )
190 | 
191 |     sys.modules[__name__].__class__ = RequestModule
```

.venv/lib/python3.13/site-packages/pip/_vendor/urllib3/response.py
```
1 | from __future__ import absolute_import
2 | 
3 | import io
4 | import logging
5 | import sys
6 | import warnings
7 | import zlib
8 | from contextlib import contextmanager
9 | from socket import error as SocketError
10 | from socket import timeout as SocketTimeout
11 | 
12 | brotli = None
13 | 
14 | from . import util
15 | from ._collections import HTTPHeaderDict
16 | from .connection import BaseSSLError, HTTPException
17 | from .exceptions import (
18 |     BodyNotHttplibCompatible,
19 |     DecodeError,
20 |     HTTPError,
21 |     IncompleteRead,
22 |     InvalidChunkLength,
23 |     InvalidHeader,
24 |     ProtocolError,
25 |     ReadTimeoutError,
26 |     ResponseNotChunked,
27 |     SSLError,
28 | )
29 | from .packages import six
30 | from .util.response import is_fp_closed, is_response_to_head
31 | 
32 | log = logging.getLogger(__name__)
33 | 
34 | 
35 | class DeflateDecoder(object):
36 |     def __init__(self):
37 |         self._first_try = True
38 |         self._data = b""
39 |         self._obj = zlib.decompressobj()
40 | 
41 |     def __getattr__(self, name):
42 |         return getattr(self._obj, name)
43 | 
44 |     def decompress(self, data):
45 |         if not data:
46 |             return data
47 | 
48 |         if not self._first_try:
49 |             return self._obj.decompress(data)
50 | 
51 |         self._data += data
52 |         try:
53 |             decompressed = self._obj.decompress(data)
54 |             if decompressed:
55 |                 self._first_try = False
56 |                 self._data = None
57 |             return decompressed
58 |         except zlib.error:
59 |             self._first_try = False
60 |             self._obj = zlib.decompressobj(-zlib.MAX_WBITS)
61 |             try:
62 |                 return self.decompress(self._data)
63 |             finally:
64 |                 self._data = None
65 | 
66 | 
67 | class GzipDecoderState(object):
68 | 
69 |     FIRST_MEMBER = 0
70 |     OTHER_MEMBERS = 1
71 |     SWALLOW_DATA = 2
72 | 
73 | 
74 | class GzipDecoder(object):
75 |     def __init__(self):
76 |         self._obj = zlib.decompressobj(16 + zlib.MAX_WBITS)
77 |         self._state = GzipDecoderState.FIRST_MEMBER
78 | 
79 |     def __getattr__(self, name):
80 |         return getattr(self._obj, name)
81 | 
82 |     def decompress(self, data):
83 |         ret = bytearray()
84 |         if self._state == GzipDecoderState.SWALLOW_DATA or not data:
85 |             return bytes(ret)
86 |         while True:
87 |             try:
88 |                 ret += self._obj.decompress(data)
89 |             except zlib.error:
90 |                 previous_state = self._state
91 |                 # Ignore data after the first error
92 |                 self._state = GzipDecoderState.SWALLOW_DATA
93 |                 if previous_state == GzipDecoderState.OTHER_MEMBERS:
94 |                     # Allow trailing garbage acceptable in other gzip clients
95 |                     return bytes(ret)
96 |                 raise
97 |             data = self._obj.unused_data
98 |             if not data:
99 |                 return bytes(ret)
100 |             self._state = GzipDecoderState.OTHER_MEMBERS
101 |             self._obj = zlib.decompressobj(16 + zlib.MAX_WBITS)
102 | 
103 | 
104 | if brotli is not None:
105 | 
106 |     class BrotliDecoder(object):
107 |         # Supports both 'brotlipy' and 'Brotli' packages
108 |         # since they share an import name. The top branches
109 |         # are for 'brotlipy' and bottom branches for 'Brotli'
110 |         def __init__(self):
111 |             self._obj = brotli.Decompressor()
112 |             if hasattr(self._obj, "decompress"):
113 |                 self.decompress = self._obj.decompress
114 |             else:
115 |                 self.decompress = self._obj.process
116 | 
117 |         def flush(self):
118 |             if hasattr(self._obj, "flush"):
119 |                 return self._obj.flush()
120 |             return b""
121 | 
122 | 
123 | class MultiDecoder(object):
124 |     """
125 |     From RFC7231:
126 |         If one or more encodings have been applied to a representation, the
127 |         sender that applied the encodings MUST generate a Content-Encoding
128 |         header field that lists the content codings in the order in which
129 |         they were applied.
130 |     """
131 | 
132 |     def __init__(self, modes):
133 |         self._decoders = [_get_decoder(m.strip()) for m in modes.split(",")]
134 | 
135 |     def flush(self):
136 |         return self._decoders[0].flush()
137 | 
138 |     def decompress(self, data):
139 |         for d in reversed(self._decoders):
140 |             data = d.decompress(data)
141 |         return data
142 | 
143 | 
144 | def _get_decoder(mode):
145 |     if "," in mode:
146 |         return MultiDecoder(mode)
147 | 
148 |     if mode == "gzip":
149 |         return GzipDecoder()
150 | 
151 |     if brotli is not None and mode == "br":
152 |         return BrotliDecoder()
153 | 
154 |     return DeflateDecoder()
155 | 
156 | 
157 | class HTTPResponse(io.IOBase):
158 |     """
159 |     HTTP Response container.
160 | 
161 |     Backwards-compatible with :class:`http.client.HTTPResponse` but the response ``body`` is
162 |     loaded and decoded on-demand when the ``data`` property is accessed.  This
163 |     class is also compatible with the Python standard library's :mod:`io`
164 |     module, and can hence be treated as a readable object in the context of that
165 |     framework.
166 | 
167 |     Extra parameters for behaviour not present in :class:`http.client.HTTPResponse`:
168 | 
169 |     :param preload_content:
170 |         If True, the response's body will be preloaded during construction.
171 | 
172 |     :param decode_content:
173 |         If True, will attempt to decode the body based on the
174 |         'content-encoding' header.
175 | 
176 |     :param original_response:
177 |         When this HTTPResponse wrapper is generated from an :class:`http.client.HTTPResponse`
178 |         object, it's convenient to include the original for debug purposes. It's
179 |         otherwise unused.
180 | 
181 |     :param retries:
182 |         The retries contains the last :class:`~urllib3.util.retry.Retry` that
183 |         was used during the request.
184 | 
185 |     :param enforce_content_length:
186 |         Enforce content length checking. Body returned by server must match
187 |         value of Content-Length header, if present. Otherwise, raise error.
188 |     """
189 | 
190 |     CONTENT_DECODERS = ["gzip", "deflate"]
191 |     if brotli is not None:
192 |         CONTENT_DECODERS += ["br"]
193 |     REDIRECT_STATUSES = [301, 302, 303, 307, 308]
194 | 
195 |     def __init__(
196 |         self,
197 |         body="",
198 |         headers=None,
199 |         status=0,
200 |         version=0,
201 |         reason=None,
202 |         strict=0,
203 |         preload_content=True,
204 |         decode_content=True,
205 |         original_response=None,
206 |         pool=None,
207 |         connection=None,
208 |         msg=None,
209 |         retries=None,
210 |         enforce_content_length=False,
211 |         request_method=None,
212 |         request_url=None,
213 |         auto_close=True,
214 |     ):
215 | 
216 |         if isinstance(headers, HTTPHeaderDict):
217 |             self.headers = headers
218 |         else:
219 |             self.headers = HTTPHeaderDict(headers)
220 |         self.status = status
221 |         self.version = version
222 |         self.reason = reason
223 |         self.strict = strict
224 |         self.decode_content = decode_content
225 |         self.retries = retries
226 |         self.enforce_content_length = enforce_content_length
227 |         self.auto_close = auto_close
228 | 
229 |         self._decoder = None
230 |         self._body = None
231 |         self._fp = None
232 |         self._original_response = original_response
233 |         self._fp_bytes_read = 0
234 |         self.msg = msg
235 |         self._request_url = request_url
236 | 
237 |         if body and isinstance(body, (six.string_types, bytes)):
238 |             self._body = body
239 | 
240 |         self._pool = pool
241 |         self._connection = connection
242 | 
243 |         if hasattr(body, "read"):
244 |             self._fp = body
245 | 
246 |         # Are we using the chunked-style of transfer encoding?
247 |         self.chunked = False
248 |         self.chunk_left = None
249 |         tr_enc = self.headers.get("transfer-encoding", "").lower()
250 |         # Don't incur the penalty of creating a list and then discarding it
251 |         encodings = (enc.strip() for enc in tr_enc.split(","))
252 |         if "chunked" in encodings:
253 |             self.chunked = True
254 | 
255 |         # Determine length of response
256 |         self.length_remaining = self._init_length(request_method)
257 | 
258 |         # If requested, preload the body.
259 |         if preload_content and not self._body:
260 |             self._body = self.read(decode_content=decode_content)
261 | 
262 |     def get_redirect_location(self):
263 |         """
264 |         Should we redirect and where to?
265 | 
266 |         :returns: Truthy redirect location string if we got a redirect status
267 |             code and valid location. ``None`` if redirect status and no
268 |             location. ``False`` if not a redirect status code.
269 |         """
270 |         if self.status in self.REDIRECT_STATUSES:
271 |             return self.headers.get("location")
272 | 
273 |         return False
274 | 
275 |     def release_conn(self):
276 |         if not self._pool or not self._connection:
277 |             return
278 | 
279 |         self._pool._put_conn(self._connection)
280 |         self._connection = None
281 | 
282 |     def drain_conn(self):
283 |         """
284 |         Read and discard any remaining HTTP response data in the response connection.
285 | 
286 |         Unread data in the HTTPResponse connection blocks the connection from being released back to the pool.
287 |         """
288 |         try:
289 |             self.read()
290 |         except (HTTPError, SocketError, BaseSSLError, HTTPException):
291 |             pass
292 | 
293 |     @property
294 |     def data(self):
295 |         # For backwards-compat with earlier urllib3 0.4 and earlier.
296 |         if self._body:
297 |             return self._body
298 | 
299 |         if self._fp:
300 |             return self.read(cache_content=True)
301 | 
302 |     @property
303 |     def connection(self):
304 |         return self._connection
305 | 
306 |     def isclosed(self):
307 |         return is_fp_closed(self._fp)
308 | 
309 |     def tell(self):
310 |         """
311 |         Obtain the number of bytes pulled over the wire so far. May differ from
312 |         the amount of content returned by :meth:``urllib3.response.HTTPResponse.read``
313 |         if bytes are encoded on the wire (e.g, compressed).
314 |         """
315 |         return self._fp_bytes_read
316 | 
317 |     def _init_length(self, request_method):
318 |         """
319 |         Set initial length value for Response content if available.
320 |         """
321 |         length = self.headers.get("content-length")
322 | 
323 |         if length is not None:
324 |             if self.chunked:
325 |                 # This Response will fail with an IncompleteRead if it can't be
326 |                 # received as chunked. This method falls back to attempt reading
327 |                 # the response before raising an exception.
328 |                 log.warning(
329 |                     "Received response with both Content-Length and "
330 |                     "Transfer-Encoding set. This is expressly forbidden "
331 |                     "by RFC 7230 sec 3.3.2. Ignoring Content-Length and "
332 |                     "attempting to process response as Transfer-Encoding: "
333 |                     "chunked."
334 |                 )
335 |                 return None
336 | 
337 |             try:
338 |                 # RFC 7230 section 3.3.2 specifies multiple content lengths can
339 |                 # be sent in a single Content-Length header
340 |                 # (e.g. Content-Length: 42, 42). This line ensures the values
341 |                 # are all valid ints and that as long as the `set` length is 1,
342 |                 # all values are the same. Otherwise, the header is invalid.
343 |                 lengths = set([int(val) for val in length.split(",")])
344 |                 if len(lengths) > 1:
345 |                     raise InvalidHeader(
346 |                         "Content-Length contained multiple "
347 |                         "unmatching values (%s)" % length
348 |                     )
349 |                 length = lengths.pop()
350 |             except ValueError:
351 |                 length = None
352 |             else:
353 |                 if length < 0:
354 |                     length = None
355 | 
356 |         # Convert status to int for comparison
357 |         # In some cases, httplib returns a status of "_UNKNOWN"
358 |         try:
359 |             status = int(self.status)
360 |         except ValueError:
361 |             status = 0
362 | 
363 |         # Check for responses that shouldn't include a body
364 |         if status in (204, 304) or 100 <= status < 200 or request_method == "HEAD":
365 |             length = 0
366 | 
367 |         return length
368 | 
369 |     def _init_decoder(self):
370 |         """
371 |         Set-up the _decoder attribute if necessary.
372 |         """
373 |         # Note: content-encoding value should be case-insensitive, per RFC 7230
374 |         # Section 3.2
375 |         content_encoding = self.headers.get("content-encoding", "").lower()
376 |         if self._decoder is None:
377 |             if content_encoding in self.CONTENT_DECODERS:
378 |                 self._decoder = _get_decoder(content_encoding)
379 |             elif "," in content_encoding:
380 |                 encodings = [
381 |                     e.strip()
382 |                     for e in content_encoding.split(",")
383 |                     if e.strip() in self.CONTENT_DECODERS
384 |                 ]
385 |                 if len(encodings):
386 |                     self._decoder = _get_decoder(content_encoding)
387 | 
[TRUNCATED]
```

.venv/lib/python3.13/site-packages/pip/_vendor/rich/__init__.py
```
1 | """Rich text and beautiful formatting in the terminal."""
2 | 
3 | import os
4 | from typing import IO, TYPE_CHECKING, Any, Callable, Optional, Union
5 | 
6 | from ._extension import load_ipython_extension  # noqa: F401
7 | 
8 | __all__ = ["get_console", "reconfigure", "print", "inspect", "print_json"]
9 | 
10 | if TYPE_CHECKING:
11 |     from .console import Console
12 | 
13 | # Global console used by alternative print
14 | _console: Optional["Console"] = None
15 | 
16 | try:
17 |     _IMPORT_CWD = os.path.abspath(os.getcwd())
18 | except FileNotFoundError:
19 |     # Can happen if the cwd has been deleted
20 |     _IMPORT_CWD = ""
21 | 
22 | 
23 | def get_console() -> "Console":
24 |     """Get a global :class:`~rich.console.Console` instance. This function is used when Rich requires a Console,
25 |     and hasn't been explicitly given one.
26 | 
27 |     Returns:
28 |         Console: A console instance.
29 |     """
30 |     global _console
31 |     if _console is None:
32 |         from .console import Console
33 | 
34 |         _console = Console()
35 | 
36 |     return _console
37 | 
38 | 
39 | def reconfigure(*args: Any, **kwargs: Any) -> None:
40 |     """Reconfigures the global console by replacing it with another.
41 | 
42 |     Args:
43 |         *args (Any): Positional arguments for the replacement :class:`~rich.console.Console`.
44 |         **kwargs (Any): Keyword arguments for the replacement :class:`~rich.console.Console`.
45 |     """
46 |     from pip._vendor.rich.console import Console
47 | 
48 |     new_console = Console(*args, **kwargs)
49 |     _console = get_console()
50 |     _console.__dict__ = new_console.__dict__
51 | 
52 | 
53 | def print(
54 |     *objects: Any,
55 |     sep: str = " ",
56 |     end: str = "\n",
57 |     file: Optional[IO[str]] = None,
58 |     flush: bool = False,
59 | ) -> None:
60 |     r"""Print object(s) supplied via positional arguments.
61 |     This function has an identical signature to the built-in print.
62 |     For more advanced features, see the :class:`~rich.console.Console` class.
63 | 
64 |     Args:
65 |         sep (str, optional): Separator between printed objects. Defaults to " ".
66 |         end (str, optional): Character to write at end of output. Defaults to "\\n".
67 |         file (IO[str], optional): File to write to, or None for stdout. Defaults to None.
68 |         flush (bool, optional): Has no effect as Rich always flushes output. Defaults to False.
69 | 
70 |     """
71 |     from .console import Console
72 | 
73 |     write_console = get_console() if file is None else Console(file=file)
74 |     return write_console.print(*objects, sep=sep, end=end)
75 | 
76 | 
77 | def print_json(
78 |     json: Optional[str] = None,
79 |     *,
80 |     data: Any = None,
81 |     indent: Union[None, int, str] = 2,
82 |     highlight: bool = True,
83 |     skip_keys: bool = False,
84 |     ensure_ascii: bool = False,
85 |     check_circular: bool = True,
86 |     allow_nan: bool = True,
87 |     default: Optional[Callable[[Any], Any]] = None,
88 |     sort_keys: bool = False,
89 | ) -> None:
90 |     """Pretty prints JSON. Output will be valid JSON.
91 | 
92 |     Args:
93 |         json (str): A string containing JSON.
94 |         data (Any): If json is not supplied, then encode this data.
95 |         indent (int, optional): Number of spaces to indent. Defaults to 2.
96 |         highlight (bool, optional): Enable highlighting of output: Defaults to True.
97 |         skip_keys (bool, optional): Skip keys not of a basic type. Defaults to False.
98 |         ensure_ascii (bool, optional): Escape all non-ascii characters. Defaults to False.
99 |         check_circular (bool, optional): Check for circular references. Defaults to True.
100 |         allow_nan (bool, optional): Allow NaN and Infinity values. Defaults to True.
101 |         default (Callable, optional): A callable that converts values that can not be encoded
102 |             in to something that can be JSON encoded. Defaults to None.
103 |         sort_keys (bool, optional): Sort dictionary keys. Defaults to False.
104 |     """
105 | 
106 |     get_console().print_json(
107 |         json,
108 |         data=data,
109 |         indent=indent,
110 |         highlight=highlight,
111 |         skip_keys=skip_keys,
112 |         ensure_ascii=ensure_ascii,
113 |         check_circular=check_circular,
114 |         allow_nan=allow_nan,
115 |         default=default,
116 |         sort_keys=sort_keys,
117 |     )
118 | 
119 | 
120 | def inspect(
121 |     obj: Any,
122 |     *,
123 |     console: Optional["Console"] = None,
124 |     title: Optional[str] = None,
125 |     help: bool = False,
126 |     methods: bool = False,
127 |     docs: bool = True,
128 |     private: bool = False,
129 |     dunder: bool = False,
130 |     sort: bool = True,
131 |     all: bool = False,
132 |     value: bool = True,
133 | ) -> None:
134 |     """Inspect any Python object.
135 | 
136 |     * inspect(<OBJECT>) to see summarized info.
137 |     * inspect(<OBJECT>, methods=True) to see methods.
138 |     * inspect(<OBJECT>, help=True) to see full (non-abbreviated) help.
139 |     * inspect(<OBJECT>, private=True) to see private attributes (single underscore).
140 |     * inspect(<OBJECT>, dunder=True) to see attributes beginning with double underscore.
141 |     * inspect(<OBJECT>, all=True) to see all attributes.
142 | 
143 |     Args:
144 |         obj (Any): An object to inspect.
145 |         title (str, optional): Title to display over inspect result, or None use type. Defaults to None.
146 |         help (bool, optional): Show full help text rather than just first paragraph. Defaults to False.
147 |         methods (bool, optional): Enable inspection of callables. Defaults to False.
148 |         docs (bool, optional): Also render doc strings. Defaults to True.
149 |         private (bool, optional): Show private attributes (beginning with underscore). Defaults to False.
150 |         dunder (bool, optional): Show attributes starting with double underscore. Defaults to False.
151 |         sort (bool, optional): Sort attributes alphabetically. Defaults to True.
152 |         all (bool, optional): Show all attributes. Defaults to False.
153 |         value (bool, optional): Pretty print value. Defaults to True.
154 |     """
155 |     _console = console or get_console()
156 |     from pip._vendor.rich._inspect import Inspect
157 | 
158 |     # Special case for inspect(inspect)
159 |     is_inspect = obj is inspect
160 | 
161 |     _inspect = Inspect(
162 |         obj,
163 |         title=title,
164 |         help=is_inspect or help,
165 |         methods=is_inspect or methods,
166 |         docs=is_inspect or docs,
167 |         private=private,
168 |         dunder=dunder,
169 |         sort=sort,
170 |         all=all,
171 |         value=value,
172 |     )
173 |     _console.print(_inspect)
174 | 
175 | 
176 | if __name__ == "__main__":  # pragma: no cover
177 |     print("Hello, **World**")
```

.venv/lib/python3.13/site-packages/pip/_vendor/rich/__main__.py
```
1 | import colorsys
2 | import io
3 | from time import process_time
4 | 
5 | from pip._vendor.rich import box
6 | from pip._vendor.rich.color import Color
7 | from pip._vendor.rich.console import Console, ConsoleOptions, Group, RenderableType, RenderResult
8 | from pip._vendor.rich.markdown import Markdown
9 | from pip._vendor.rich.measure import Measurement
10 | from pip._vendor.rich.pretty import Pretty
11 | from pip._vendor.rich.segment import Segment
12 | from pip._vendor.rich.style import Style
13 | from pip._vendor.rich.syntax import Syntax
14 | from pip._vendor.rich.table import Table
15 | from pip._vendor.rich.text import Text
16 | 
17 | 
18 | class ColorBox:
19 |     def __rich_console__(
20 |         self, console: Console, options: ConsoleOptions
21 |     ) -> RenderResult:
22 |         for y in range(0, 5):
23 |             for x in range(options.max_width):
24 |                 h = x / options.max_width
25 |                 l = 0.1 + ((y / 5) * 0.7)
26 |                 r1, g1, b1 = colorsys.hls_to_rgb(h, l, 1.0)
27 |                 r2, g2, b2 = colorsys.hls_to_rgb(h, l + 0.7 / 10, 1.0)
28 |                 bgcolor = Color.from_rgb(r1 * 255, g1 * 255, b1 * 255)
29 |                 color = Color.from_rgb(r2 * 255, g2 * 255, b2 * 255)
30 |                 yield Segment("", Style(color=color, bgcolor=bgcolor))
31 |             yield Segment.line()
32 | 
33 |     def __rich_measure__(
34 |         self, console: "Console", options: ConsoleOptions
35 |     ) -> Measurement:
36 |         return Measurement(1, options.max_width)
37 | 
38 | 
39 | def make_test_card() -> Table:
40 |     """Get a renderable that demonstrates a number of features."""
41 |     table = Table.grid(padding=1, pad_edge=True)
42 |     table.title = "Rich features"
43 |     table.add_column("Feature", no_wrap=True, justify="center", style="bold red")
44 |     table.add_column("Demonstration")
45 | 
46 |     color_table = Table(
47 |         box=None,
48 |         expand=False,
49 |         show_header=False,
50 |         show_edge=False,
51 |         pad_edge=False,
52 |     )
53 |     color_table.add_row(
54 |         (
55 |             " [bold green]4-bit color[/]\n"
56 |             " [bold blue]8-bit color[/]\n"
57 |             " [bold magenta]Truecolor (16.7 million)[/]\n"
58 |             " [bold yellow]Dumb terminals[/]\n"
59 |             " [bold cyan]Automatic color conversion"
60 |         ),
61 |         ColorBox(),
62 |     )
63 | 
64 |     table.add_row("Colors", color_table)
65 | 
66 |     table.add_row(
67 |         "Styles",
68 |         "All ansi styles: [bold]bold[/], [dim]dim[/], [italic]italic[/italic], [underline]underline[/], [strike]strikethrough[/], [reverse]reverse[/], and even [blink]blink[/].",
69 |     )
70 | 
71 |     lorem = "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Quisque in metus sed sapien ultricies pretium a at justo. Maecenas luctus velit et auctor maximus."
72 |     lorem_table = Table.grid(padding=1, collapse_padding=True)
73 |     lorem_table.pad_edge = False
74 |     lorem_table.add_row(
75 |         Text(lorem, justify="left", style="green"),
76 |         Text(lorem, justify="center", style="yellow"),
77 |         Text(lorem, justify="right", style="blue"),
78 |         Text(lorem, justify="full", style="red"),
79 |     )
80 |     table.add_row(
81 |         "Text",
82 |         Group(
83 |             Text.from_markup(
84 |                 """Word wrap text. Justify [green]left[/], [yellow]center[/], [blue]right[/] or [red]full[/].\n"""
85 |             ),
86 |             lorem_table,
87 |         ),
88 |     )
89 | 
90 |     def comparison(renderable1: RenderableType, renderable2: RenderableType) -> Table:
91 |         table = Table(show_header=False, pad_edge=False, box=None, expand=True)
92 |         table.add_column("1", ratio=1)
93 |         table.add_column("2", ratio=1)
94 |         table.add_row(renderable1, renderable2)
95 |         return table
96 | 
97 |     table.add_row(
98 |         "Asian\nlanguage\nsupport",
99 |         ":flag_for_china:  \n:flag_for_japan:  \n:flag_for_south_korea:    ,     ",
100 |     )
101 | 
102 |     markup_example = (
103 |         "[bold magenta]Rich[/] supports a simple [i]bbcode[/i]-like [b]markup[/b] for [yellow]color[/], [underline]style[/], and emoji! "
104 |         ":+1: :apple: :ant: :bear: :baguette_bread: :bus: "
105 |     )
106 |     table.add_row("Markup", markup_example)
107 | 
108 |     example_table = Table(
109 |         show_edge=False,
110 |         show_header=True,
111 |         expand=False,
112 |         row_styles=["none", "dim"],
113 |         box=box.SIMPLE,
114 |     )
115 |     example_table.add_column("[green]Date", style="green", no_wrap=True)
116 |     example_table.add_column("[blue]Title", style="blue")
117 |     example_table.add_column(
118 |         "[cyan]Production Budget",
119 |         style="cyan",
120 |         justify="right",
121 |         no_wrap=True,
122 |     )
123 |     example_table.add_column(
124 |         "[magenta]Box Office",
125 |         style="magenta",
126 |         justify="right",
127 |         no_wrap=True,
128 |     )
129 |     example_table.add_row(
130 |         "Dec 20, 2019",
131 |         "Star Wars: The Rise of Skywalker",
132 |         "$275,000,000",
133 |         "$375,126,118",
134 |     )
135 |     example_table.add_row(
136 |         "May 25, 2018",
137 |         "[b]Solo[/]: A Star Wars Story",
138 |         "$275,000,000",
139 |         "$393,151,347",
140 |     )
141 |     example_table.add_row(
142 |         "Dec 15, 2017",
143 |         "Star Wars Ep. VIII: The Last Jedi",
144 |         "$262,000,000",
145 |         "[bold]$1,332,539,889[/bold]",
146 |     )
147 |     example_table.add_row(
148 |         "May 19, 1999",
149 |         "Star Wars Ep. [b]I[/b]: [i]The phantom Menace",
150 |         "$115,000,000",
151 |         "$1,027,044,677",
152 |     )
153 | 
154 |     table.add_row("Tables", example_table)
155 | 
156 |     code = '''\
157 | def iter_last(values: Iterable[T]) -> Iterable[Tuple[bool, T]]:
158 |     """Iterate and generate a tuple with a flag for last value."""
159 |     iter_values = iter(values)
160 |     try:
161 |         previous_value = next(iter_values)
162 |     except StopIteration:
163 |         return
164 |     for value in iter_values:
165 |         yield False, previous_value
166 |         previous_value = value
167 |     yield True, previous_value'''
168 | 
169 |     pretty_data = {
170 |         "foo": [
171 |             3.1427,
172 |             (
173 |                 "Paul Atreides",
174 |                 "Vladimir Harkonnen",
175 |                 "Thufir Hawat",
176 |             ),
177 |         ],
178 |         "atomic": (False, True, None),
179 |     }
180 |     table.add_row(
181 |         "Syntax\nhighlighting\n&\npretty\nprinting",
182 |         comparison(
183 |             Syntax(code, "python3", line_numbers=True, indent_guides=True),
184 |             Pretty(pretty_data, indent_guides=True),
185 |         ),
186 |     )
187 | 
188 |     markdown_example = """\
189 | # Markdown
190 | 
191 | Supports much of the *markdown* __syntax__!
192 | 
193 | - Headers
194 | - Basic formatting: **bold**, *italic*, `code`
195 | - Block quotes
196 | - Lists, and more...
197 |     """
198 |     table.add_row(
199 |         "Markdown", comparison("[cyan]" + markdown_example, Markdown(markdown_example))
200 |     )
201 | 
202 |     table.add_row(
203 |         "+more!",
204 |         """Progress bars, columns, styled logging handler, tracebacks, etc...""",
205 |     )
206 |     return table
207 | 
208 | 
209 | if __name__ == "__main__":  # pragma: no cover
210 |     console = Console(
211 |         file=io.StringIO(),
212 |         force_terminal=True,
213 |     )
214 |     test_card = make_test_card()
215 | 
216 |     # Print once to warm cache
217 |     start = process_time()
218 |     console.print(test_card)
219 |     pre_cache_taken = round((process_time() - start) * 1000.0, 1)
220 | 
221 |     console.file = io.StringIO()
222 | 
223 |     start = process_time()
224 |     console.print(test_card)
225 |     taken = round((process_time() - start) * 1000.0, 1)
226 | 
227 |     c = Console(record=True)
228 |     c.print(test_card)
229 | 
230 |     print(f"rendered in {pre_cache_taken}ms (cold cache)")
231 |     print(f"rendered in {taken}ms (warm cache)")
232 | 
233 |     from pip._vendor.rich.panel import Panel
234 | 
235 |     console = Console()
236 | 
237 |     sponsor_message = Table.grid(padding=1)
238 |     sponsor_message.add_column(style="green", justify="right")
239 |     sponsor_message.add_column(no_wrap=True)
240 | 
241 |     sponsor_message.add_row(
242 |         "Textualize",
243 |         "[u blue link=https://github.com/textualize]https://github.com/textualize",
244 |     )
245 |     sponsor_message.add_row(
246 |         "Twitter",
247 |         "[u blue link=https://twitter.com/willmcgugan]https://twitter.com/willmcgugan",
248 |     )
249 | 
250 |     intro_message = Text.from_markup(
251 |         """\
252 | We hope you enjoy using Rich!
253 | 
254 | Rich is maintained with [red]:heart:[/] by [link=https://www.textualize.io]Textualize.io[/]
255 | 
256 | - Will McGugan"""
257 |     )
258 | 
259 |     message = Table.grid(padding=2)
260 |     message.add_column()
261 |     message.add_column(no_wrap=True)
262 |     message.add_row(intro_message, sponsor_message)
263 | 
264 |     console.print(
265 |         Panel.fit(
266 |             message,
267 |             box=box.ROUNDED,
268 |             padding=(1, 2),
269 |             title="[b red]Thanks for trying out Rich!",
270 |             border_style="bright_blue",
271 |         ),
272 |         justify="center",
273 |     )
```

.venv/lib/python3.13/site-packages/pip/_vendor/rich/_cell_widths.py
```
1 | # Auto generated by make_terminal_widths.py
2 | 
3 | CELL_WIDTHS = [
4 |     (0, 0, 0),
5 |     (1, 31, -1),
6 |     (127, 159, -1),
7 |     (173, 173, 0),
8 |     (768, 879, 0),
9 |     (1155, 1161, 0),
10 |     (1425, 1469, 0),
11 |     (1471, 1471, 0),
12 |     (1473, 1474, 0),
13 |     (1476, 1477, 0),
14 |     (1479, 1479, 0),
15 |     (1536, 1541, 0),
16 |     (1552, 1562, 0),
17 |     (1564, 1564, 0),
18 |     (1611, 1631, 0),
19 |     (1648, 1648, 0),
20 |     (1750, 1757, 0),
21 |     (1759, 1764, 0),
22 |     (1767, 1768, 0),
23 |     (1770, 1773, 0),
24 |     (1807, 1807, 0),
25 |     (1809, 1809, 0),
26 |     (1840, 1866, 0),
27 |     (1958, 1968, 0),
28 |     (2027, 2035, 0),
29 |     (2045, 2045, 0),
30 |     (2070, 2073, 0),
31 |     (2075, 2083, 0),
32 |     (2085, 2087, 0),
33 |     (2089, 2093, 0),
34 |     (2137, 2139, 0),
35 |     (2192, 2193, 0),
36 |     (2200, 2207, 0),
37 |     (2250, 2307, 0),
38 |     (2362, 2364, 0),
39 |     (2366, 2383, 0),
40 |     (2385, 2391, 0),
41 |     (2402, 2403, 0),
42 |     (2433, 2435, 0),
43 |     (2492, 2492, 0),
44 |     (2494, 2500, 0),
45 |     (2503, 2504, 0),
46 |     (2507, 2509, 0),
47 |     (2519, 2519, 0),
48 |     (2530, 2531, 0),
49 |     (2558, 2558, 0),
50 |     (2561, 2563, 0),
51 |     (2620, 2620, 0),
52 |     (2622, 2626, 0),
53 |     (2631, 2632, 0),
54 |     (2635, 2637, 0),
55 |     (2641, 2641, 0),
56 |     (2672, 2673, 0),
57 |     (2677, 2677, 0),
58 |     (2689, 2691, 0),
59 |     (2748, 2748, 0),
60 |     (2750, 2757, 0),
61 |     (2759, 2761, 0),
62 |     (2763, 2765, 0),
63 |     (2786, 2787, 0),
64 |     (2810, 2815, 0),
65 |     (2817, 2819, 0),
66 |     (2876, 2876, 0),
67 |     (2878, 2884, 0),
68 |     (2887, 2888, 0),
69 |     (2891, 2893, 0),
70 |     (2901, 2903, 0),
71 |     (2914, 2915, 0),
72 |     (2946, 2946, 0),
73 |     (3006, 3010, 0),
74 |     (3014, 3016, 0),
75 |     (3018, 3021, 0),
76 |     (3031, 3031, 0),
77 |     (3072, 3076, 0),
78 |     (3132, 3132, 0),
79 |     (3134, 3140, 0),
80 |     (3142, 3144, 0),
81 |     (3146, 3149, 0),
82 |     (3157, 3158, 0),
83 |     (3170, 3171, 0),
84 |     (3201, 3203, 0),
85 |     (3260, 3260, 0),
86 |     (3262, 3268, 0),
87 |     (3270, 3272, 0),
88 |     (3274, 3277, 0),
89 |     (3285, 3286, 0),
90 |     (3298, 3299, 0),
91 |     (3315, 3315, 0),
92 |     (3328, 3331, 0),
93 |     (3387, 3388, 0),
94 |     (3390, 3396, 0),
95 |     (3398, 3400, 0),
96 |     (3402, 3405, 0),
97 |     (3415, 3415, 0),
98 |     (3426, 3427, 0),
99 |     (3457, 3459, 0),
100 |     (3530, 3530, 0),
101 |     (3535, 3540, 0),
102 |     (3542, 3542, 0),
103 |     (3544, 3551, 0),
104 |     (3570, 3571, 0),
105 |     (3633, 3633, 0),
106 |     (3636, 3642, 0),
107 |     (3655, 3662, 0),
108 |     (3761, 3761, 0),
109 |     (3764, 3772, 0),
110 |     (3784, 3790, 0),
111 |     (3864, 3865, 0),
112 |     (3893, 3893, 0),
113 |     (3895, 3895, 0),
114 |     (3897, 3897, 0),
115 |     (3902, 3903, 0),
116 |     (3953, 3972, 0),
117 |     (3974, 3975, 0),
118 |     (3981, 3991, 0),
119 |     (3993, 4028, 0),
120 |     (4038, 4038, 0),
121 |     (4139, 4158, 0),
122 |     (4182, 4185, 0),
123 |     (4190, 4192, 0),
124 |     (4194, 4196, 0),
125 |     (4199, 4205, 0),
126 |     (4209, 4212, 0),
127 |     (4226, 4237, 0),
128 |     (4239, 4239, 0),
129 |     (4250, 4253, 0),
130 |     (4352, 4447, 2),
131 |     (4448, 4607, 0),
132 |     (4957, 4959, 0),
133 |     (5906, 5909, 0),
134 |     (5938, 5940, 0),
135 |     (5970, 5971, 0),
136 |     (6002, 6003, 0),
137 |     (6068, 6099, 0),
138 |     (6109, 6109, 0),
139 |     (6155, 6159, 0),
140 |     (6277, 6278, 0),
141 |     (6313, 6313, 0),
142 |     (6432, 6443, 0),
143 |     (6448, 6459, 0),
144 |     (6679, 6683, 0),
145 |     (6741, 6750, 0),
146 |     (6752, 6780, 0),
147 |     (6783, 6783, 0),
148 |     (6832, 6862, 0),
149 |     (6912, 6916, 0),
150 |     (6964, 6980, 0),
151 |     (7019, 7027, 0),
152 |     (7040, 7042, 0),
153 |     (7073, 7085, 0),
154 |     (7142, 7155, 0),
155 |     (7204, 7223, 0),
156 |     (7376, 7378, 0),
157 |     (7380, 7400, 0),
158 |     (7405, 7405, 0),
159 |     (7412, 7412, 0),
160 |     (7415, 7417, 0),
161 |     (7616, 7679, 0),
162 |     (8203, 8207, 0),
163 |     (8232, 8238, 0),
164 |     (8288, 8292, 0),
165 |     (8294, 8303, 0),
166 |     (8400, 8432, 0),
167 |     (8986, 8987, 2),
168 |     (9001, 9002, 2),
169 |     (9193, 9196, 2),
170 |     (9200, 9200, 2),
171 |     (9203, 9203, 2),
172 |     (9725, 9726, 2),
173 |     (9748, 9749, 2),
174 |     (9800, 9811, 2),
175 |     (9855, 9855, 2),
176 |     (9875, 9875, 2),
177 |     (9889, 9889, 2),
178 |     (9898, 9899, 2),
179 |     (9917, 9918, 2),
180 |     (9924, 9925, 2),
181 |     (9934, 9934, 2),
182 |     (9940, 9940, 2),
183 |     (9962, 9962, 2),
184 |     (9970, 9971, 2),
185 |     (9973, 9973, 2),
186 |     (9978, 9978, 2),
187 |     (9981, 9981, 2),
188 |     (9989, 9989, 2),
189 |     (9994, 9995, 2),
190 |     (10024, 10024, 2),
191 |     (10060, 10060, 2),
192 |     (10062, 10062, 2),
193 |     (10067, 10069, 2),
194 |     (10071, 10071, 2),
195 |     (10133, 10135, 2),
196 |     (10160, 10160, 2),
197 |     (10175, 10175, 2),
198 |     (11035, 11036, 2),
199 |     (11088, 11088, 2),
200 |     (11093, 11093, 2),
201 |     (11503, 11505, 0),
202 |     (11647, 11647, 0),
203 |     (11744, 11775, 0),
204 |     (11904, 11929, 2),
205 |     (11931, 12019, 2),
206 |     (12032, 12245, 2),
207 |     (12272, 12329, 2),
208 |     (12330, 12335, 0),
209 |     (12336, 12350, 2),
210 |     (12353, 12438, 2),
211 |     (12441, 12442, 0),
212 |     (12443, 12543, 2),
213 |     (12549, 12591, 2),
214 |     (12593, 12686, 2),
215 |     (12688, 12771, 2),
216 |     (12783, 12830, 2),
217 |     (12832, 12871, 2),
218 |     (12880, 19903, 2),
219 |     (19968, 42124, 2),
220 |     (42128, 42182, 2),
221 |     (42607, 42610, 0),
222 |     (42612, 42621, 0),
223 |     (42654, 42655, 0),
224 |     (42736, 42737, 0),
225 |     (43010, 43010, 0),
226 |     (43014, 43014, 0),
227 |     (43019, 43019, 0),
228 |     (43043, 43047, 0),
229 |     (43052, 43052, 0),
230 |     (43136, 43137, 0),
231 |     (43188, 43205, 0),
232 |     (43232, 43249, 0),
233 |     (43263, 43263, 0),
234 |     (43302, 43309, 0),
235 |     (43335, 43347, 0),
236 |     (43360, 43388, 2),
237 |     (43392, 43395, 0),
238 |     (43443, 43456, 0),
239 |     (43493, 43493, 0),
240 |     (43561, 43574, 0),
241 |     (43587, 43587, 0),
242 |     (43596, 43597, 0),
243 |     (43643, 43645, 0),
244 |     (43696, 43696, 0),
245 |     (43698, 43700, 0),
246 |     (43703, 43704, 0),
247 |     (43710, 43711, 0),
248 |     (43713, 43713, 0),
249 |     (43755, 43759, 0),
250 |     (43765, 43766, 0),
251 |     (44003, 44010, 0),
252 |     (44012, 44013, 0),
253 |     (44032, 55203, 2),
254 |     (55216, 55295, 0),
255 |     (63744, 64255, 2),
256 |     (64286, 64286, 0),
257 |     (65024, 65039, 0),
258 |     (65040, 65049, 2),
259 |     (65056, 65071, 0),
260 |     (65072, 65106, 2),
261 |     (65108, 65126, 2),
262 |     (65128, 65131, 2),
263 |     (65279, 65279, 0),
264 |     (65281, 65376, 2),
265 |     (65504, 65510, 2),
266 |     (65529, 65531, 0),
267 |     (66045, 66045, 0),
268 |     (66272, 66272, 0),
269 |     (66422, 66426, 0),
270 |     (68097, 68099, 0),
271 |     (68101, 68102, 0),
272 |     (68108, 68111, 0),
273 |     (68152, 68154, 0),
274 |     (68159, 68159, 0),
275 |     (68325, 68326, 0),
276 |     (68900, 68903, 0),
277 |     (69291, 69292, 0),
278 |     (69373, 69375, 0),
279 |     (69446, 69456, 0),
280 |     (69506, 69509, 0),
281 |     (69632, 69634, 0),
282 |     (69688, 69702, 0),
283 |     (69744, 69744, 0),
284 |     (69747, 69748, 0),
285 |     (69759, 69762, 0),
286 |     (69808, 69818, 0),
287 |     (69821, 69821, 0),
288 |     (69826, 69826, 0),
289 |     (69837, 69837, 0),
290 |     (69888, 69890, 0),
291 |     (69927, 69940, 0),
292 |     (69957, 69958, 0),
293 |     (70003, 70003, 0),
294 |     (70016, 70018, 0),
295 |     (70067, 70080, 0),
296 |     (70089, 70092, 0),
297 |     (70094, 70095, 0),
298 |     (70188, 70199, 0),
299 |     (70206, 70206, 0),
300 |     (70209, 70209, 0),
301 |     (70367, 70378, 0),
302 |     (70400, 70403, 0),
303 |     (70459, 70460, 0),
304 |     (70462, 70468, 0),
305 |     (70471, 70472, 0),
306 |     (70475, 70477, 0),
307 |     (70487, 70487, 0),
308 |     (70498, 70499, 0),
309 |     (70502, 70508, 0),
310 |     (70512, 70516, 0),
311 |     (70709, 70726, 0),
312 |     (70750, 70750, 0),
313 |     (70832, 70851, 0),
314 |     (71087, 71093, 0),
315 |     (71096, 71104, 0),
316 |     (71132, 71133, 0),
317 |     (71216, 71232, 0),
318 |     (71339, 71351, 0),
319 |     (71453, 71467, 0),
320 |     (71724, 71738, 0),
321 |     (71984, 71989, 0),
322 |     (71991, 71992, 0),
323 |     (71995, 71998, 0),
324 |     (72000, 72000, 0),
325 |     (72002, 72003, 0),
326 |     (72145, 72151, 0),
327 |     (72154, 72160, 0),
328 |     (72164, 72164, 0),
329 |     (72193, 72202, 0),
330 |     (72243, 72249, 0),
331 |     (72251, 72254, 0),
332 |     (72263, 72263, 0),
333 |     (72273, 72283, 0),
334 |     (72330, 72345, 0),
335 |     (72751, 72758, 0),
336 |     (72760, 72767, 0),
337 |     (72850, 72871, 0),
338 |     (72873, 72886, 0),
339 |     (73009, 73014, 0),
340 |     (73018, 73018, 0),
341 |     (73020, 73021, 0),
342 |     (73023, 73029, 0),
343 |     (73031, 73031, 0),
344 |     (73098, 73102, 0),
345 |     (73104, 73105, 0),
346 |     (73107, 73111, 0),
347 |     (73459, 73462, 0),
348 |     (73472, 73473, 0),
349 |     (73475, 73475, 0),
350 |     (73524, 73530, 0),
351 |     (73534, 73538, 0),
352 |     (78896, 78912, 0),
353 |     (78919, 78933, 0),
354 |     (92912, 92916, 0),
355 |     (92976, 92982, 0),
356 |     (94031, 94031, 0),
357 |     (94033, 94087, 0),
358 |     (94095, 94098, 0),
359 |     (94176, 94179, 2),
360 |     (94180, 94180, 0),
361 |     (94192, 94193, 0),
362 |     (94208, 100343, 2),
363 |     (100352, 101589, 2),
364 |     (101632, 101640, 2),
365 |     (110576, 110579, 2),
366 |     (110581, 110587, 2),
367 |     (110589, 110590, 2),
368 |     (110592, 110882, 2),
369 |     (110898, 110898, 2),
370 |     (110928, 110930, 2),
371 |     (110933, 110933, 2),
372 |     (110948, 110951, 2),
373 |     (110960, 111355, 2),
374 |     (113821, 113822, 0),
375 |     (113824, 113827, 0),
376 |     (118528, 118573, 0),
377 |     (118576, 118598, 0),
378 |     (119141, 119145, 0),
379 |     (119149, 119170, 0),
380 |     (119173, 119179, 0),
381 |     (119210, 119213, 0),
382 |     (119362, 119364, 0),
383 |     (121344, 121398, 0),
384 |     (121403, 121452, 0),
385 |     (121461, 121461, 0),
386 |     (121476, 121476, 0),
387 |     (121499, 121503, 0),
388 |     (121505, 121519, 0),
389 |     (122880, 122886, 0),
390 |     (122888, 122904, 0),
391 |     (122907, 122913, 0),
392 |     (122915, 122916, 0),
393 |     (122918, 122922, 0),
394 |     (123023, 123023, 0),
395 |     (123184, 123190, 0),
396 |     (123566, 123566, 0),
397 |     (123628, 123631, 0),
398 |     (124140, 124143, 0),
399 |     (125136, 125142, 0),
400 |     (125252, 125258, 0),
401 |     (126980, 126980, 2),
402 |     (127183, 127183, 2),
403 |     (127374, 127374, 2),
404 |     (127377, 127386, 2),
405 |     (127488, 127490, 2),
406 |     (127504, 127547, 2),
407 |     (127552, 127560, 2),
408 |     (127568, 127569, 2),
409 |     (127584, 127589, 2),
410 |     (127744, 127776, 2),
411 |     (127789, 127797, 2),
412 |     (127799, 127868, 2),
413 |     (127870, 127891, 2),
414 |     (127904, 127946, 2),
415 |     (127951, 127955, 2),
416 |     (127968, 127984, 2),
417 |     (127988, 127988, 2),
418 |     (127992, 127994, 2),
419 |     (127995, 127999, 0),
420 |     (128000, 128062, 2),
421 |     (128064, 128064, 2),
422 |     (128066, 128252, 2),
423 |     (128255, 128317, 2),
424 |     (128331, 128334, 2),
425 |     (128336, 128359, 2),
426 |     (128378, 128378, 2),
427 |     (128405, 128406, 2),
428 |     (128420, 128420, 2),
429 |     (128507, 128591, 2),
430 |     (128640, 128709, 2),
431 |     (128716, 128716, 2),
432 |     (128720, 128722, 2),
433 |     (128725, 128727, 2),
434 |     (128732, 128735, 2),
435 |     (128747, 128748, 2),
436 |     (128756, 128764, 2),
437 |     (128992, 129003, 2),
438 |     (129008, 129008, 2),
439 |     (129292, 129338, 2),
440 |     (129340, 129349, 2),
441 |     (129351, 129535, 2),
442 |     (129648, 129660, 2),
443 |     (129664, 129672, 2),
444 |     (129680, 129725, 2),
445 |     (129727, 129733, 2),
446 |     (129742, 129755, 2),
447 |     (129760, 129768, 2),
448 |     (129776, 129784, 2),
[TRUNCATED]
```

.venv/lib/python3.13/site-packages/pip/_vendor/rich/_emoji_codes.py
```
1 | EMOJI = {
2 |     "1st_place_medal": "",
3 |     "2nd_place_medal": "",
4 |     "3rd_place_medal": "",
5 |     "ab_button_(blood_type)": "",
6 |     "atm_sign": "",
7 |     "a_button_(blood_type)": "",
8 |     "afghanistan": "",
9 |     "albania": "",
10 |     "algeria": "",
11 |     "american_samoa": "",
12 |     "andorra": "",
13 |     "angola": "",
14 |     "anguilla": "",
15 |     "antarctica": "",
16 |     "antigua_&_barbuda": "",
17 |     "aquarius": "",
18 |     "argentina": "",
19 |     "aries": "",
20 |     "armenia": "",
21 |     "aruba": "",
22 |     "ascension_island": "",
23 |     "australia": "",
24 |     "austria": "",
25 |     "azerbaijan": "",
26 |     "back_arrow": "",
27 |     "b_button_(blood_type)": "",
28 |     "bahamas": "",
29 |     "bahrain": "",
30 |     "bangladesh": "",
31 |     "barbados": "",
32 |     "belarus": "",
33 |     "belgium": "",
34 |     "belize": "",
35 |     "benin": "",
36 |     "bermuda": "",
37 |     "bhutan": "",
38 |     "bolivia": "",
39 |     "bosnia_&_herzegovina": "",
40 |     "botswana": "",
41 |     "bouvet_island": "",
42 |     "brazil": "",
43 |     "british_indian_ocean_territory": "",
44 |     "british_virgin_islands": "",
45 |     "brunei": "",
46 |     "bulgaria": "",
47 |     "burkina_faso": "",
48 |     "burundi": "",
49 |     "cl_button": "",
50 |     "cool_button": "",
51 |     "cambodia": "",
52 |     "cameroon": "",
53 |     "canada": "",
54 |     "canary_islands": "",
55 |     "cancer": "",
56 |     "cape_verde": "",
57 |     "capricorn": "",
58 |     "caribbean_netherlands": "",
59 |     "cayman_islands": "",
60 |     "central_african_republic": "",
61 |     "ceuta_&_melilla": "",
62 |     "chad": "",
63 |     "chile": "",
64 |     "china": "",
65 |     "christmas_island": "",
66 |     "christmas_tree": "",
67 |     "clipperton_island": "",
68 |     "cocos_(keeling)_islands": "",
69 |     "colombia": "",
70 |     "comoros": "",
71 |     "congo_-_brazzaville": "",
72 |     "congo_-_kinshasa": "",
73 |     "cook_islands": "",
74 |     "costa_rica": "",
75 |     "croatia": "",
76 |     "cuba": "",
77 |     "curaao": "",
78 |     "cyprus": "",
79 |     "czechia": "",
80 |     "cte_divoire": "",
81 |     "denmark": "",
82 |     "diego_garcia": "",
83 |     "djibouti": "",
84 |     "dominica": "",
85 |     "dominican_republic": "",
86 |     "end_arrow": "",
87 |     "ecuador": "",
88 |     "egypt": "",
89 |     "el_salvador": "",
90 |     "england": "\U000e0067\U000e0062\U000e0065\U000e006e\U000e0067\U000e007f",
91 |     "equatorial_guinea": "",
92 |     "eritrea": "",
93 |     "estonia": "",
94 |     "ethiopia": "",
95 |     "european_union": "",
96 |     "free_button": "",
97 |     "falkland_islands": "",
98 |     "faroe_islands": "",
99 |     "fiji": "",
100 |     "finland": "",
101 |     "france": "",
102 |     "french_guiana": "",
103 |     "french_polynesia": "",
104 |     "french_southern_territories": "",
105 |     "gabon": "",
106 |     "gambia": "",
107 |     "gemini": "",
108 |     "georgia": "",
109 |     "germany": "",
110 |     "ghana": "",
111 |     "gibraltar": "",
112 |     "greece": "",
113 |     "greenland": "",
114 |     "grenada": "",
115 |     "guadeloupe": "",
116 |     "guam": "",
117 |     "guatemala": "",
118 |     "guernsey": "",
119 |     "guinea": "",
120 |     "guinea-bissau": "",
121 |     "guyana": "",
122 |     "haiti": "",
123 |     "heard_&_mcdonald_islands": "",
124 |     "honduras": "",
125 |     "hong_kong_sar_china": "",
126 |     "hungary": "",
127 |     "id_button": "",
128 |     "iceland": "",
129 |     "india": "",
130 |     "indonesia": "",
131 |     "iran": "",
132 |     "iraq": "",
133 |     "ireland": "",
134 |     "isle_of_man": "",
135 |     "israel": "",
136 |     "italy": "",
137 |     "jamaica": "",
138 |     "japan": "",
139 |     "japanese_acceptable_button": "",
140 |     "japanese_application_button": "",
141 |     "japanese_bargain_button": "",
142 |     "japanese_castle": "",
143 |     "japanese_congratulations_button": "",
144 |     "japanese_discount_button": "",
145 |     "japanese_dolls": "",
146 |     "japanese_free_of_charge_button": "",
147 |     "japanese_here_button": "",
148 |     "japanese_monthly_amount_button": "",
149 |     "japanese_no_vacancy_button": "",
150 |     "japanese_not_free_of_charge_button": "",
151 |     "japanese_open_for_business_button": "",
152 |     "japanese_passing_grade_button": "",
153 |     "japanese_post_office": "",
154 |     "japanese_prohibited_button": "",
155 |     "japanese_reserved_button": "",
156 |     "japanese_secret_button": "",
157 |     "japanese_service_charge_button": "",
158 |     "japanese_symbol_for_beginner": "",
159 |     "japanese_vacancy_button": "",
160 |     "jersey": "",
161 |     "jordan": "",
162 |     "kazakhstan": "",
163 |     "kenya": "",
164 |     "kiribati": "",
165 |     "kosovo": "",
166 |     "kuwait": "",
167 |     "kyrgyzstan": "",
168 |     "laos": "",
169 |     "latvia": "",
170 |     "lebanon": "",
171 |     "leo": "",
172 |     "lesotho": "",
173 |     "liberia": "",
174 |     "libra": "",
175 |     "libya": "",
176 |     "liechtenstein": "",
177 |     "lithuania": "",
178 |     "luxembourg": "",
179 |     "macau_sar_china": "",
180 |     "macedonia": "",
181 |     "madagascar": "",
182 |     "malawi": "",
183 |     "malaysia": "",
184 |     "maldives": "",
185 |     "mali": "",
186 |     "malta": "",
187 |     "marshall_islands": "",
188 |     "martinique": "",
189 |     "mauritania": "",
190 |     "mauritius": "",
191 |     "mayotte": "",
192 |     "mexico": "",
193 |     "micronesia": "",
194 |     "moldova": "",
195 |     "monaco": "",
196 |     "mongolia": "",
197 |     "montenegro": "",
198 |     "montserrat": "",
199 |     "morocco": "",
200 |     "mozambique": "",
201 |     "mrs._claus": "",
202 |     "mrs._claus_dark_skin_tone": "",
203 |     "mrs._claus_light_skin_tone": "",
204 |     "mrs._claus_medium-dark_skin_tone": "",
205 |     "mrs._claus_medium-light_skin_tone": "",
206 |     "mrs._claus_medium_skin_tone": "",
207 |     "myanmar_(burma)": "",
208 |     "new_button": "",
209 |     "ng_button": "",
210 |     "namibia": "",
211 |     "nauru": "",
212 |     "nepal": "",
213 |     "netherlands": "",
214 |     "new_caledonia": "",
215 |     "new_zealand": "",
216 |     "nicaragua": "",
217 |     "niger": "",
218 |     "nigeria": "",
219 |     "niue": "",
220 |     "norfolk_island": "",
221 |     "north_korea": "",
222 |     "northern_mariana_islands": "",
223 |     "norway": "",
224 |     "ok_button": "",
225 |     "ok_hand": "",
226 |     "ok_hand_dark_skin_tone": "",
227 |     "ok_hand_light_skin_tone": "",
228 |     "ok_hand_medium-dark_skin_tone": "",
229 |     "ok_hand_medium-light_skin_tone": "",
230 |     "ok_hand_medium_skin_tone": "",
231 |     "on!_arrow": "",
232 |     "o_button_(blood_type)": "",
233 |     "oman": "",
234 |     "ophiuchus": "",
235 |     "p_button": "",
236 |     "pakistan": "",
237 |     "palau": "",
238 |     "palestinian_territories": "",
239 |     "panama": "",
240 |     "papua_new_guinea": "",
241 |     "paraguay": "",
242 |     "peru": "",
243 |     "philippines": "",
244 |     "pisces": "",
245 |     "pitcairn_islands": "",
246 |     "poland": "",
247 |     "portugal": "",
248 |     "puerto_rico": "",
249 |     "qatar": "",
250 |     "romania": "",
251 |     "russia": "",
252 |     "rwanda": "",
253 |     "runion": "",
254 |     "soon_arrow": "",
255 |     "sos_button": "",
256 |     "sagittarius": "",
257 |     "samoa": "",
258 |     "san_marino": "",
259 |     "santa_claus": "",
260 |     "santa_claus_dark_skin_tone": "",
261 |     "santa_claus_light_skin_tone": "",
262 |     "santa_claus_medium-dark_skin_tone": "",
263 |     "santa_claus_medium-light_skin_tone": "",
264 |     "santa_claus_medium_skin_tone": "",
265 |     "saudi_arabia": "",
266 |     "scorpio": "",
267 |     "scotland": "\U000e0067\U000e0062\U000e0073\U000e0063\U000e0074\U000e007f",
268 |     "senegal": "",
269 |     "serbia": "",
270 |     "seychelles": "",
271 |     "sierra_leone": "",
272 |     "singapore": "",
273 |     "sint_maarten": "",
274 |     "slovakia": "",
275 |     "slovenia": "",
276 |     "solomon_islands": "",
277 |     "somalia": "",
278 |     "south_africa": "",
279 |     "south_georgia_&_south_sandwich_islands": "",
280 |     "south_korea": "",
281 |     "south_sudan": "",
282 |     "spain": "",
283 |     "sri_lanka": "",
284 |     "st._barthlemy": "",
285 |     "st._helena": "",
286 |     "st._kitts_&_nevis": "",
287 |     "st._lucia": "",
288 |     "st._martin": "",
289 |     "st._pierre_&_miquelon": "",
290 |     "st._vincent_&_grenadines": "",
291 |     "statue_of_liberty": "",
292 |     "sudan": "",
293 |     "suriname": "",
294 |     "svalbard_&_jan_mayen": "",
295 |     "swaziland": "",
296 |     "sweden": "",
297 |     "switzerland": "",
298 |     "syria": "",
299 |     "so_tom_&_prncipe": "",
300 |     "t-rex": "",
301 |     "top_arrow": "",
302 |     "taiwan": "",
303 |     "tajikistan": "",
304 |     "tanzania": "",
305 |     "taurus": "",
306 |     "thailand": "",
307 |     "timor-leste": "",
308 |     "togo": "",
309 |     "tokelau": "",
310 |     "tokyo_tower": "",
311 |     "tonga": "",
312 |     "trinidad_&_tobago": "",
313 |     "tristan_da_cunha": "",
314 |     "tunisia": "",
315 |     "turkey": "",
316 |     "turkmenistan": "",
317 |     "turks_&_caicos_islands": "",
318 |     "tuvalu": "",
319 |     "u.s._outlying_islands": "",
320 |     "u.s._virgin_islands": "",
321 |     "up!_button": "",
322 |     "uganda": "",
323 |     "ukraine": "",
324 |     "united_arab_emirates": "",
325 |     "united_kingdom": "",
326 |     "united_nations": "",
327 |     "united_states": "",
328 |     "uruguay": "",
329 |     "uzbekistan": "",
330 |     "vs_button": "",
331 |     "vanuatu": "",
332 |     "vatican_city": "",
333 |     "venezuela": "",
334 |     "vietnam": "",
335 |     "virgo": "",
336 |     "wales": "\U000e0067\U000e0062\U000e0077\U000e006c\U000e0073\U000e007f",
337 |     "wallis_&_futuna": "",
338 |     "western_sahara": "",
339 |     "yemen": "",
340 |     "zambia": "",
341 |     "zimbabwe": "",
342 |     "abacus": "",
343 |     "adhesive_bandage": "",
344 |     "admission_tickets": "",
345 |     "adult": "",
346 |     "adult_dark_skin_tone": "",
347 |     "adult_light_skin_tone": "",
348 |     "adult_medium-dark_skin_tone": "",
349 |     "adult_medium-light_skin_tone": "",
350 |     "adult_medium_skin_tone": "",
351 |     "aerial_tramway": "",
352 |     "airplane": "",
353 |     "airplane_arrival": "",
354 |     "airplane_departure": "",
355 |     "alarm_clock": "",
356 |     "alembic": "",
357 |     "alien": "",
358 |     "alien_monster": "",
359 |     "ambulance": "",
360 |     "american_football": "",
361 |     "amphora": "",
362 |     "anchor": "",
363 |     "anger_symbol": "",
364 |     "angry_face": "",
365 |     "angry_face_with_horns": "",
366 |     "anguished_face": "",
367 |     "ant": "",
368 |     "antenna_bars": "",
369 |     "anxious_face_with_sweat": "",
370 |     "articulated_lorry": "",
371 |     "artist_palette": "",
372 |     "astonished_face": "",
373 |     "atom_symbol": "",
374 |     "auto_rickshaw": "",
375 |     "automobile": "",
376 |     "avocado": "",
377 |     "axe": "",
378 |     "baby": "",
379 |     "baby_angel": "",
380 |     "baby_angel_dark_skin_tone": "",
381 |     "baby_angel_light_skin_tone": "",
382 |     "baby_angel_medium-dark_skin_tone": "",
383 |     "baby_angel_medium-light_skin_tone": "",
384 |     "baby_angel_medium_skin_tone": "",
385 |     "baby_bottle": "",
386 |     "baby_chick": "",
387 |     "baby_dark_skin_tone": "",
388 |     "baby_light_skin_tone": "",
389 |     "baby_medium-dark_skin_tone": "",
390 |     "baby_medium-light_skin_tone": "",
391 |     "baby_medium_skin_tone": "",
392 |     "baby_symbol": "",
393 |     "backhand_index_pointing_down": "",
394 |     "backhand_index_pointing_down_dark_skin_tone": "",
395 |     "backhand_index_pointing_down_light_skin_tone": "",
396 |     "backhand_index_pointing_down_medium-dark_skin_tone": "",
397 |     "backhand_index_pointing_down_medium-light_skin_tone": "",
398 |     "backhand_index_pointing_down_medium_skin_tone": "",
399 |     "backhand_index_pointing_left": "",
400 |     "backhand_index_pointing_left_dark_skin_tone": "",
401 |     "backhand_index_pointing_left_light_skin_tone": "",
402 |     "backhand_index_pointing_left_medium-dark_skin_tone": "",
403 |     "backhand_index_pointing_left_medium-light_skin_tone": "",
404 |     "backhand_index_pointing_left_medium_skin_tone": "",
405 |     "backhand_index_pointing_right": "",
406 |     "backhand_index_pointing_right_dark_skin_tone": "",
407 |     "backhand_index_pointing_right_light_skin_tone": "",
408 |     "backhand_index_pointing_right_medium-dark_skin_tone": "",
409 |     "backhand_index_pointing_right_medium-light_skin_tone": "",
410 |     "backhand_index_pointing_right_medium_skin_tone": "",
411 |     "backhand_index_pointing_up": "",
412 |     "backhand_index_pointing_up_dark_skin_tone": "",
413 |     "backhand_index_pointing_up_light_skin_tone": "",
414 |     "backhand_index_pointing_up_medium-dark_skin_tone": "",
415 |     "backhand_index_pointing_up_medium-light_skin_tone": "",
416 |     "backhand_index_pointing_up_medium_skin_tone": "",
417 |     "bacon": "",
418 |     "badger": "",
419 |     "badminton": "",
420 |     "bagel": "",
421 |     "baggage_claim": "",
422 |     "baguette_bread": "",
423 |     "balance_scale": "",
424 |     "bald": "",
425 |     "bald_man": "\u200d",
426 |     "bald_woman": "\u200d",
427 |     "ballet_shoes": "",
428 |     "balloon": "",
429 |     "ballot_box_with_ballot": "",
430 |     "ballot_box_with_check": "",
[TRUNCATED]
```

.venv/lib/python3.13/site-packages/pip/_vendor/rich/_emoji_replace.py
```
1 | from typing import Callable, Match, Optional
2 | import re
3 | 
4 | from ._emoji_codes import EMOJI
5 | 
6 | 
7 | _ReStringMatch = Match[str]  # regex match object
8 | _ReSubCallable = Callable[[_ReStringMatch], str]  # Callable invoked by re.sub
9 | _EmojiSubMethod = Callable[[_ReSubCallable, str], str]  # Sub method of a compiled re
10 | 
11 | 
12 | def _emoji_replace(
13 |     text: str,
14 |     default_variant: Optional[str] = None,
15 |     _emoji_sub: _EmojiSubMethod = re.compile(r"(:(\S*?)(?:(?:\-)(emoji|text))?:)").sub,
16 | ) -> str:
17 |     """Replace emoji code in text."""
18 |     get_emoji = EMOJI.__getitem__
19 |     variants = {"text": "\uFE0E", "emoji": "\uFE0F"}
20 |     get_variant = variants.get
21 |     default_variant_code = variants.get(default_variant, "") if default_variant else ""
22 | 
23 |     def do_replace(match: Match[str]) -> str:
24 |         emoji_code, emoji_name, variant = match.groups()
25 |         try:
26 |             return get_emoji(emoji_name.lower()) + get_variant(
27 |                 variant, default_variant_code
28 |             )
29 |         except KeyError:
30 |             return emoji_code
31 | 
32 |     return _emoji_sub(do_replace, text)
```

.venv/lib/python3.13/site-packages/pip/_vendor/rich/_export_format.py
```
1 | CONSOLE_HTML_FORMAT = """\
2 | <!DOCTYPE html>
3 | <html>
4 | <head>
5 | <meta charset="UTF-8">
6 | <style>
7 | {stylesheet}
8 | body {{
9 |     color: {foreground};
10 |     background-color: {background};
11 | }}
12 | </style>
13 | </head>
14 | <body>
15 |     <pre style="font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><code style="font-family:inherit">{code}</code></pre>
16 | </body>
17 | </html>
18 | """
19 | 
20 | CONSOLE_SVG_FORMAT = """\
21 | <svg class="rich-terminal" viewBox="0 0 {width} {height}" xmlns="http://www.w3.org/2000/svg">
22 |     <!-- Generated with Rich https://www.textualize.io -->
23 |     <style>
24 | 
25 |     @font-face {{
26 |         font-family: "Fira Code";
27 |         src: local("FiraCode-Regular"),
28 |                 url("https://cdnjs.cloudflare.com/ajax/libs/firacode/6.2.0/woff2/FiraCode-Regular.woff2") format("woff2"),
29 |                 url("https://cdnjs.cloudflare.com/ajax/libs/firacode/6.2.0/woff/FiraCode-Regular.woff") format("woff");
30 |         font-style: normal;
31 |         font-weight: 400;
32 |     }}
33 |     @font-face {{
34 |         font-family: "Fira Code";
35 |         src: local("FiraCode-Bold"),
36 |                 url("https://cdnjs.cloudflare.com/ajax/libs/firacode/6.2.0/woff2/FiraCode-Bold.woff2") format("woff2"),
37 |                 url("https://cdnjs.cloudflare.com/ajax/libs/firacode/6.2.0/woff/FiraCode-Bold.woff") format("woff");
38 |         font-style: bold;
39 |         font-weight: 700;
40 |     }}
41 | 
42 |     .{unique_id}-matrix {{
43 |         font-family: Fira Code, monospace;
44 |         font-size: {char_height}px;
45 |         line-height: {line_height}px;
46 |         font-variant-east-asian: full-width;
47 |     }}
48 | 
49 |     .{unique_id}-title {{
50 |         font-size: 18px;
51 |         font-weight: bold;
52 |         font-family: arial;
53 |     }}
54 | 
55 |     {styles}
56 |     </style>
57 | 
58 |     <defs>
59 |     <clipPath id="{unique_id}-clip-terminal">
60 |       <rect x="0" y="0" width="{terminal_width}" height="{terminal_height}" />
61 |     </clipPath>
62 |     {lines}
63 |     </defs>
64 | 
65 |     {chrome}
66 |     <g transform="translate({terminal_x}, {terminal_y})" clip-path="url(#{unique_id}-clip-terminal)">
67 |     {backgrounds}
68 |     <g class="{unique_id}-matrix">
69 |     {matrix}
70 |     </g>
71 |     </g>
72 | </svg>
73 | """
74 | 
75 | _SVG_FONT_FAMILY = "Rich Fira Code"
76 | _SVG_CLASSES_PREFIX = "rich-svg"
```

.venv/lib/python3.13/site-packages/pip/_vendor/rich/_extension.py
```
1 | from typing import Any
2 | 
3 | 
4 | def load_ipython_extension(ip: Any) -> None:  # pragma: no cover
5 |     # prevent circular import
6 |     from pip._vendor.rich.pretty import install
7 |     from pip._vendor.rich.traceback import install as tr_install
8 | 
9 |     install()
10 |     tr_install()
```

.venv/lib/python3.13/site-packages/pip/_vendor/rich/_fileno.py
```
1 | from __future__ import annotations
2 | 
3 | from typing import IO, Callable
4 | 
5 | 
6 | def get_fileno(file_like: IO[str]) -> int | None:
7 |     """Get fileno() from a file, accounting for poorly implemented file-like objects.
8 | 
9 |     Args:
10 |         file_like (IO): A file-like object.
11 | 
12 |     Returns:
13 |         int | None: The result of fileno if available, or None if operation failed.
14 |     """
15 |     fileno: Callable[[], int] | None = getattr(file_like, "fileno", None)
16 |     if fileno is not None:
17 |         try:
18 |             return fileno()
19 |         except Exception:
20 |             # `fileno` is documented as potentially raising a OSError
21 |             # Alas, from the issues, there are so many poorly implemented file-like objects,
22 |             # that `fileno()` can raise just about anything.
23 |             return None
24 |     return None
```

.venv/lib/python3.13/site-packages/pip/_vendor/rich/_inspect.py
```
1 | import inspect
2 | from inspect import cleandoc, getdoc, getfile, isclass, ismodule, signature
3 | from typing import Any, Collection, Iterable, Optional, Tuple, Type, Union
4 | 
5 | from .console import Group, RenderableType
6 | from .control import escape_control_codes
7 | from .highlighter import ReprHighlighter
8 | from .jupyter import JupyterMixin
9 | from .panel import Panel
10 | from .pretty import Pretty
11 | from .table import Table
12 | from .text import Text, TextType
13 | 
14 | 
15 | def _first_paragraph(doc: str) -> str:
16 |     """Get the first paragraph from a docstring."""
17 |     paragraph, _, _ = doc.partition("\n\n")
18 |     return paragraph
19 | 
20 | 
21 | class Inspect(JupyterMixin):
22 |     """A renderable to inspect any Python Object.
23 | 
24 |     Args:
25 |         obj (Any): An object to inspect.
26 |         title (str, optional): Title to display over inspect result, or None use type. Defaults to None.
27 |         help (bool, optional): Show full help text rather than just first paragraph. Defaults to False.
28 |         methods (bool, optional): Enable inspection of callables. Defaults to False.
29 |         docs (bool, optional): Also render doc strings. Defaults to True.
30 |         private (bool, optional): Show private attributes (beginning with underscore). Defaults to False.
31 |         dunder (bool, optional): Show attributes starting with double underscore. Defaults to False.
32 |         sort (bool, optional): Sort attributes alphabetically. Defaults to True.
33 |         all (bool, optional): Show all attributes. Defaults to False.
34 |         value (bool, optional): Pretty print value of object. Defaults to True.
35 |     """
36 | 
37 |     def __init__(
38 |         self,
39 |         obj: Any,
40 |         *,
41 |         title: Optional[TextType] = None,
42 |         help: bool = False,
43 |         methods: bool = False,
44 |         docs: bool = True,
45 |         private: bool = False,
46 |         dunder: bool = False,
47 |         sort: bool = True,
48 |         all: bool = True,
49 |         value: bool = True,
50 |     ) -> None:
51 |         self.highlighter = ReprHighlighter()
52 |         self.obj = obj
53 |         self.title = title or self._make_title(obj)
54 |         if all:
55 |             methods = private = dunder = True
56 |         self.help = help
57 |         self.methods = methods
58 |         self.docs = docs or help
59 |         self.private = private or dunder
60 |         self.dunder = dunder
61 |         self.sort = sort
62 |         self.value = value
63 | 
64 |     def _make_title(self, obj: Any) -> Text:
65 |         """Make a default title."""
66 |         title_str = (
67 |             str(obj)
68 |             if (isclass(obj) or callable(obj) or ismodule(obj))
69 |             else str(type(obj))
70 |         )
71 |         title_text = self.highlighter(title_str)
72 |         return title_text
73 | 
74 |     def __rich__(self) -> Panel:
75 |         return Panel.fit(
76 |             Group(*self._render()),
77 |             title=self.title,
78 |             border_style="scope.border",
79 |             padding=(0, 1),
80 |         )
81 | 
82 |     def _get_signature(self, name: str, obj: Any) -> Optional[Text]:
83 |         """Get a signature for a callable."""
84 |         try:
85 |             _signature = str(signature(obj)) + ":"
86 |         except ValueError:
87 |             _signature = "(...)"
88 |         except TypeError:
89 |             return None
90 | 
91 |         source_filename: Optional[str] = None
92 |         try:
93 |             source_filename = getfile(obj)
94 |         except (OSError, TypeError):
95 |             # OSError is raised if obj has no source file, e.g. when defined in REPL.
96 |             pass
97 | 
98 |         callable_name = Text(name, style="inspect.callable")
99 |         if source_filename:
100 |             callable_name.stylize(f"link file://{source_filename}")
101 |         signature_text = self.highlighter(_signature)
102 | 
103 |         qualname = name or getattr(obj, "__qualname__", name)
104 | 
105 |         # If obj is a module, there may be classes (which are callable) to display
106 |         if inspect.isclass(obj):
107 |             prefix = "class"
108 |         elif inspect.iscoroutinefunction(obj):
109 |             prefix = "async def"
110 |         else:
111 |             prefix = "def"
112 | 
113 |         qual_signature = Text.assemble(
114 |             (f"{prefix} ", f"inspect.{prefix.replace(' ', '_')}"),
115 |             (qualname, "inspect.callable"),
116 |             signature_text,
117 |         )
118 | 
119 |         return qual_signature
120 | 
121 |     def _render(self) -> Iterable[RenderableType]:
122 |         """Render object."""
123 | 
124 |         def sort_items(item: Tuple[str, Any]) -> Tuple[bool, str]:
125 |             key, (_error, value) = item
126 |             return (callable(value), key.strip("_").lower())
127 | 
128 |         def safe_getattr(attr_name: str) -> Tuple[Any, Any]:
129 |             """Get attribute or any exception."""
130 |             try:
131 |                 return (None, getattr(obj, attr_name))
132 |             except Exception as error:
133 |                 return (error, None)
134 | 
135 |         obj = self.obj
136 |         keys = dir(obj)
137 |         total_items = len(keys)
138 |         if not self.dunder:
139 |             keys = [key for key in keys if not key.startswith("__")]
140 |         if not self.private:
141 |             keys = [key for key in keys if not key.startswith("_")]
142 |         not_shown_count = total_items - len(keys)
143 |         items = [(key, safe_getattr(key)) for key in keys]
144 |         if self.sort:
145 |             items.sort(key=sort_items)
146 | 
147 |         items_table = Table.grid(padding=(0, 1), expand=False)
148 |         items_table.add_column(justify="right")
149 |         add_row = items_table.add_row
150 |         highlighter = self.highlighter
151 | 
152 |         if callable(obj):
153 |             signature = self._get_signature("", obj)
154 |             if signature is not None:
155 |                 yield signature
156 |                 yield ""
157 | 
158 |         if self.docs:
159 |             _doc = self._get_formatted_doc(obj)
160 |             if _doc is not None:
161 |                 doc_text = Text(_doc, style="inspect.help")
162 |                 doc_text = highlighter(doc_text)
163 |                 yield doc_text
164 |                 yield ""
165 | 
166 |         if self.value and not (isclass(obj) or callable(obj) or ismodule(obj)):
167 |             yield Panel(
168 |                 Pretty(obj, indent_guides=True, max_length=10, max_string=60),
169 |                 border_style="inspect.value.border",
170 |             )
171 |             yield ""
172 | 
173 |         for key, (error, value) in items:
174 |             key_text = Text.assemble(
175 |                 (
176 |                     key,
177 |                     "inspect.attr.dunder" if key.startswith("__") else "inspect.attr",
178 |                 ),
179 |                 (" =", "inspect.equals"),
180 |             )
181 |             if error is not None:
182 |                 warning = key_text.copy()
183 |                 warning.stylize("inspect.error")
184 |                 add_row(warning, highlighter(repr(error)))
185 |                 continue
186 | 
187 |             if callable(value):
188 |                 if not self.methods:
189 |                     continue
190 | 
191 |                 _signature_text = self._get_signature(key, value)
192 |                 if _signature_text is None:
193 |                     add_row(key_text, Pretty(value, highlighter=highlighter))
194 |                 else:
195 |                     if self.docs:
196 |                         docs = self._get_formatted_doc(value)
197 |                         if docs is not None:
198 |                             _signature_text.append("\n" if "\n" in docs else " ")
199 |                             doc = highlighter(docs)
200 |                             doc.stylize("inspect.doc")
201 |                             _signature_text.append(doc)
202 | 
203 |                     add_row(key_text, _signature_text)
204 |             else:
205 |                 add_row(key_text, Pretty(value, highlighter=highlighter))
206 |         if items_table.row_count:
207 |             yield items_table
208 |         elif not_shown_count:
209 |             yield Text.from_markup(
210 |                 f"[b cyan]{not_shown_count}[/][i] attribute(s) not shown.[/i] "
211 |                 f"Run [b][magenta]inspect[/]([not b]inspect[/])[/b] for options."
212 |             )
213 | 
214 |     def _get_formatted_doc(self, object_: Any) -> Optional[str]:
215 |         """
216 |         Extract the docstring of an object, process it and returns it.
217 |         The processing consists in cleaning up the doctring's indentation,
218 |         taking only its 1st paragraph if `self.help` is not True,
219 |         and escape its control codes.
220 | 
221 |         Args:
222 |             object_ (Any): the object to get the docstring from.
223 | 
224 |         Returns:
225 |             Optional[str]: the processed docstring, or None if no docstring was found.
226 |         """
227 |         docs = getdoc(object_)
228 |         if docs is None:
229 |             return None
230 |         docs = cleandoc(docs).strip()
231 |         if not self.help:
232 |             docs = _first_paragraph(docs)
233 |         return escape_control_codes(docs)
234 | 
235 | 
236 | def get_object_types_mro(obj: Union[object, Type[Any]]) -> Tuple[type, ...]:
237 |     """Returns the MRO of an object's class, or of the object itself if it's a class."""
238 |     if not hasattr(obj, "__mro__"):
239 |         # N.B. we cannot use `if type(obj) is type` here because it doesn't work with
240 |         # some types of classes, such as the ones that use abc.ABCMeta.
241 |         obj = type(obj)
242 |     return getattr(obj, "__mro__", ())
243 | 
244 | 
245 | def get_object_types_mro_as_strings(obj: object) -> Collection[str]:
246 |     """
247 |     Returns the MRO of an object's class as full qualified names, or of the object itself if it's a class.
248 | 
249 |     Examples:
250 |         `object_types_mro_as_strings(JSONDecoder)` will return `['json.decoder.JSONDecoder', 'builtins.object']`
251 |     """
252 |     return [
253 |         f'{getattr(type_, "__module__", "")}.{getattr(type_, "__qualname__", "")}'
254 |         for type_ in get_object_types_mro(obj)
255 |     ]
256 | 
257 | 
258 | def is_object_one_of_types(
259 |     obj: object, fully_qualified_types_names: Collection[str]
260 | ) -> bool:
261 |     """
262 |     Returns `True` if the given object's class (or the object itself, if it's a class) has one of the
263 |     fully qualified names in its MRO.
264 |     """
265 |     for type_name in get_object_types_mro_as_strings(obj):
266 |         if type_name in fully_qualified_types_names:
267 |             return True
268 |     return False
```

.venv/lib/python3.13/site-packages/pip/_vendor/rich/_log_render.py
```
1 | from datetime import datetime
2 | from typing import Iterable, List, Optional, TYPE_CHECKING, Union, Callable
3 | 
4 | 
5 | from .text import Text, TextType
6 | 
7 | if TYPE_CHECKING:
8 |     from .console import Console, ConsoleRenderable, RenderableType
9 |     from .table import Table
10 | 
11 | FormatTimeCallable = Callable[[datetime], Text]
12 | 
13 | 
14 | class LogRender:
15 |     def __init__(
16 |         self,
17 |         show_time: bool = True,
18 |         show_level: bool = False,
19 |         show_path: bool = True,
20 |         time_format: Union[str, FormatTimeCallable] = "[%x %X]",
21 |         omit_repeated_times: bool = True,
22 |         level_width: Optional[int] = 8,
23 |     ) -> None:
24 |         self.show_time = show_time
25 |         self.show_level = show_level
26 |         self.show_path = show_path
27 |         self.time_format = time_format
28 |         self.omit_repeated_times = omit_repeated_times
29 |         self.level_width = level_width
30 |         self._last_time: Optional[Text] = None
31 | 
32 |     def __call__(
33 |         self,
34 |         console: "Console",
35 |         renderables: Iterable["ConsoleRenderable"],
36 |         log_time: Optional[datetime] = None,
37 |         time_format: Optional[Union[str, FormatTimeCallable]] = None,
38 |         level: TextType = "",
39 |         path: Optional[str] = None,
40 |         line_no: Optional[int] = None,
41 |         link_path: Optional[str] = None,
42 |     ) -> "Table":
43 |         from .containers import Renderables
44 |         from .table import Table
45 | 
46 |         output = Table.grid(padding=(0, 1))
47 |         output.expand = True
48 |         if self.show_time:
49 |             output.add_column(style="log.time")
50 |         if self.show_level:
51 |             output.add_column(style="log.level", width=self.level_width)
52 |         output.add_column(ratio=1, style="log.message", overflow="fold")
53 |         if self.show_path and path:
54 |             output.add_column(style="log.path")
55 |         row: List["RenderableType"] = []
56 |         if self.show_time:
57 |             log_time = log_time or console.get_datetime()
58 |             time_format = time_format or self.time_format
59 |             if callable(time_format):
60 |                 log_time_display = time_format(log_time)
61 |             else:
62 |                 log_time_display = Text(log_time.strftime(time_format))
63 |             if log_time_display == self._last_time and self.omit_repeated_times:
64 |                 row.append(Text(" " * len(log_time_display)))
65 |             else:
66 |                 row.append(log_time_display)
67 |                 self._last_time = log_time_display
68 |         if self.show_level:
69 |             row.append(level)
70 | 
71 |         row.append(Renderables(renderables))
72 |         if self.show_path and path:
73 |             path_text = Text()
74 |             path_text.append(
75 |                 path, style=f"link file://{link_path}" if link_path else ""
76 |             )
77 |             if line_no:
78 |                 path_text.append(":")
79 |                 path_text.append(
80 |                     f"{line_no}",
81 |                     style=f"link file://{link_path}#{line_no}" if link_path else "",
82 |                 )
83 |             row.append(path_text)
84 | 
85 |         output.add_row(*row)
86 |         return output
87 | 
88 | 
89 | if __name__ == "__main__":  # pragma: no cover
90 |     from pip._vendor.rich.console import Console
91 | 
92 |     c = Console()
93 |     c.print("[on blue]Hello", justify="right")
94 |     c.log("[on blue]hello", justify="right")
```

.venv/lib/python3.13/site-packages/pip/_vendor/rich/_loop.py
```
1 | from typing import Iterable, Tuple, TypeVar
2 | 
3 | T = TypeVar("T")
4 | 
5 | 
6 | def loop_first(values: Iterable[T]) -> Iterable[Tuple[bool, T]]:
7 |     """Iterate and generate a tuple with a flag for first value."""
8 |     iter_values = iter(values)
9 |     try:
10 |         value = next(iter_values)
11 |     except StopIteration:
12 |         return
13 |     yield True, value
14 |     for value in iter_values:
15 |         yield False, value
16 | 
17 | 
18 | def loop_last(values: Iterable[T]) -> Iterable[Tuple[bool, T]]:
19 |     """Iterate and generate a tuple with a flag for last value."""
20 |     iter_values = iter(values)
21 |     try:
22 |         previous_value = next(iter_values)
23 |     except StopIteration:
24 |         return
25 |     for value in iter_values:
26 |         yield False, previous_value
27 |         previous_value = value
28 |     yield True, previous_value
29 | 
30 | 
31 | def loop_first_last(values: Iterable[T]) -> Iterable[Tuple[bool, bool, T]]:
32 |     """Iterate and generate a tuple with a flag for first and last value."""
33 |     iter_values = iter(values)
34 |     try:
35 |         previous_value = next(iter_values)
36 |     except StopIteration:
37 |         return
38 |     first = True
39 |     for value in iter_values:
40 |         yield first, False, previous_value
41 |         first = False
42 |         previous_value = value
43 |     yield first, True, previous_value
```

.venv/lib/python3.13/site-packages/pip/_vendor/rich/_null_file.py
```
1 | from types import TracebackType
2 | from typing import IO, Iterable, Iterator, List, Optional, Type
3 | 
4 | 
5 | class NullFile(IO[str]):
6 |     def close(self) -> None:
7 |         pass
8 | 
9 |     def isatty(self) -> bool:
10 |         return False
11 | 
12 |     def read(self, __n: int = 1) -> str:
13 |         return ""
14 | 
15 |     def readable(self) -> bool:
16 |         return False
17 | 
18 |     def readline(self, __limit: int = 1) -> str:
19 |         return ""
20 | 
21 |     def readlines(self, __hint: int = 1) -> List[str]:
22 |         return []
23 | 
24 |     def seek(self, __offset: int, __whence: int = 1) -> int:
25 |         return 0
26 | 
27 |     def seekable(self) -> bool:
28 |         return False
29 | 
30 |     def tell(self) -> int:
31 |         return 0
32 | 
33 |     def truncate(self, __size: Optional[int] = 1) -> int:
34 |         return 0
35 | 
36 |     def writable(self) -> bool:
37 |         return False
38 | 
39 |     def writelines(self, __lines: Iterable[str]) -> None:
40 |         pass
41 | 
42 |     def __next__(self) -> str:
43 |         return ""
44 | 
45 |     def __iter__(self) -> Iterator[str]:
46 |         return iter([""])
47 | 
48 |     def __enter__(self) -> IO[str]:
49 |         return self
50 | 
51 |     def __exit__(
52 |         self,
53 |         __t: Optional[Type[BaseException]],
54 |         __value: Optional[BaseException],
55 |         __traceback: Optional[TracebackType],
56 |     ) -> None:
57 |         pass
58 | 
59 |     def write(self, text: str) -> int:
60 |         return 0
61 | 
62 |     def flush(self) -> None:
63 |         pass
64 | 
65 |     def fileno(self) -> int:
66 |         return -1
67 | 
68 | 
69 | NULL_FILE = NullFile()
```

.venv/lib/python3.13/site-packages/pip/_vendor/rich/_palettes.py
```
1 | from .palette import Palette
2 | 
3 | 
4 | # Taken from https://en.wikipedia.org/wiki/ANSI_escape_code (Windows 10 column)
5 | WINDOWS_PALETTE = Palette(
6 |     [
7 |         (12, 12, 12),
8 |         (197, 15, 31),
9 |         (19, 161, 14),
10 |         (193, 156, 0),
11 |         (0, 55, 218),
12 |         (136, 23, 152),
13 |         (58, 150, 221),
14 |         (204, 204, 204),
15 |         (118, 118, 118),
16 |         (231, 72, 86),
17 |         (22, 198, 12),
18 |         (249, 241, 165),
19 |         (59, 120, 255),
20 |         (180, 0, 158),
21 |         (97, 214, 214),
22 |         (242, 242, 242),
23 |     ]
24 | )
25 | 
26 | # # The standard ansi colors (including bright variants)
27 | STANDARD_PALETTE = Palette(
28 |     [
29 |         (0, 0, 0),
30 |         (170, 0, 0),
31 |         (0, 170, 0),
32 |         (170, 85, 0),
33 |         (0, 0, 170),
34 |         (170, 0, 170),
35 |         (0, 170, 170),
36 |         (170, 170, 170),
37 |         (85, 85, 85),
38 |         (255, 85, 85),
39 |         (85, 255, 85),
40 |         (255, 255, 85),
41 |         (85, 85, 255),
42 |         (255, 85, 255),
43 |         (85, 255, 255),
44 |         (255, 255, 255),
45 |     ]
46 | )
47 | 
48 | 
49 | # The 256 color palette
50 | EIGHT_BIT_PALETTE = Palette(
51 |     [
52 |         (0, 0, 0),
53 |         (128, 0, 0),
54 |         (0, 128, 0),
55 |         (128, 128, 0),
56 |         (0, 0, 128),
57 |         (128, 0, 128),
58 |         (0, 128, 128),
59 |         (192, 192, 192),
60 |         (128, 128, 128),
61 |         (255, 0, 0),
62 |         (0, 255, 0),
63 |         (255, 255, 0),
64 |         (0, 0, 255),
65 |         (255, 0, 255),
66 |         (0, 255, 255),
67 |         (255, 255, 255),
68 |         (0, 0, 0),
69 |         (0, 0, 95),
70 |         (0, 0, 135),
71 |         (0, 0, 175),
72 |         (0, 0, 215),
73 |         (0, 0, 255),
74 |         (0, 95, 0),
75 |         (0, 95, 95),
76 |         (0, 95, 135),
77 |         (0, 95, 175),
78 |         (0, 95, 215),
79 |         (0, 95, 255),
80 |         (0, 135, 0),
81 |         (0, 135, 95),
82 |         (0, 135, 135),
83 |         (0, 135, 175),
84 |         (0, 135, 215),
85 |         (0, 135, 255),
86 |         (0, 175, 0),
87 |         (0, 175, 95),
88 |         (0, 175, 135),
89 |         (0, 175, 175),
90 |         (0, 175, 215),
91 |         (0, 175, 255),
92 |         (0, 215, 0),
93 |         (0, 215, 95),
94 |         (0, 215, 135),
95 |         (0, 215, 175),
96 |         (0, 215, 215),
97 |         (0, 215, 255),
98 |         (0, 255, 0),
99 |         (0, 255, 95),
100 |         (0, 255, 135),
101 |         (0, 255, 175),
102 |         (0, 255, 215),
103 |         (0, 255, 255),
104 |         (95, 0, 0),
105 |         (95, 0, 95),
106 |         (95, 0, 135),
107 |         (95, 0, 175),
108 |         (95, 0, 215),
109 |         (95, 0, 255),
110 |         (95, 95, 0),
111 |         (95, 95, 95),
112 |         (95, 95, 135),
113 |         (95, 95, 175),
114 |         (95, 95, 215),
115 |         (95, 95, 255),
116 |         (95, 135, 0),
117 |         (95, 135, 95),
118 |         (95, 135, 135),
119 |         (95, 135, 175),
120 |         (95, 135, 215),
121 |         (95, 135, 255),
122 |         (95, 175, 0),
123 |         (95, 175, 95),
124 |         (95, 175, 135),
125 |         (95, 175, 175),
126 |         (95, 175, 215),
127 |         (95, 175, 255),
128 |         (95, 215, 0),
129 |         (95, 215, 95),
130 |         (95, 215, 135),
131 |         (95, 215, 175),
132 |         (95, 215, 215),
133 |         (95, 215, 255),
134 |         (95, 255, 0),
135 |         (95, 255, 95),
136 |         (95, 255, 135),
137 |         (95, 255, 175),
138 |         (95, 255, 215),
139 |         (95, 255, 255),
140 |         (135, 0, 0),
141 |         (135, 0, 95),
142 |         (135, 0, 135),
143 |         (135, 0, 175),
144 |         (135, 0, 215),
145 |         (135, 0, 255),
146 |         (135, 95, 0),
147 |         (135, 95, 95),
148 |         (135, 95, 135),
149 |         (135, 95, 175),
150 |         (135, 95, 215),
151 |         (135, 95, 255),
152 |         (135, 135, 0),
153 |         (135, 135, 95),
154 |         (135, 135, 135),
155 |         (135, 135, 175),
156 |         (135, 135, 215),
157 |         (135, 135, 255),
158 |         (135, 175, 0),
159 |         (135, 175, 95),
160 |         (135, 175, 135),
161 |         (135, 175, 175),
162 |         (135, 175, 215),
163 |         (135, 175, 255),
164 |         (135, 215, 0),
165 |         (135, 215, 95),
166 |         (135, 215, 135),
167 |         (135, 215, 175),
168 |         (135, 215, 215),
169 |         (135, 215, 255),
170 |         (135, 255, 0),
171 |         (135, 255, 95),
172 |         (135, 255, 135),
173 |         (135, 255, 175),
174 |         (135, 255, 215),
175 |         (135, 255, 255),
176 |         (175, 0, 0),
177 |         (175, 0, 95),
178 |         (175, 0, 135),
179 |         (175, 0, 175),
180 |         (175, 0, 215),
181 |         (175, 0, 255),
182 |         (175, 95, 0),
183 |         (175, 95, 95),
184 |         (175, 95, 135),
185 |         (175, 95, 175),
186 |         (175, 95, 215),
187 |         (175, 95, 255),
188 |         (175, 135, 0),
189 |         (175, 135, 95),
190 |         (175, 135, 135),
191 |         (175, 135, 175),
192 |         (175, 135, 215),
193 |         (175, 135, 255),
194 |         (175, 175, 0),
195 |         (175, 175, 95),
196 |         (175, 175, 135),
197 |         (175, 175, 175),
198 |         (175, 175, 215),
199 |         (175, 175, 255),
200 |         (175, 215, 0),
201 |         (175, 215, 95),
202 |         (175, 215, 135),
203 |         (175, 215, 175),
204 |         (175, 215, 215),
205 |         (175, 215, 255),
206 |         (175, 255, 0),
207 |         (175, 255, 95),
208 |         (175, 255, 135),
209 |         (175, 255, 175),
210 |         (175, 255, 215),
211 |         (175, 255, 255),
212 |         (215, 0, 0),
213 |         (215, 0, 95),
214 |         (215, 0, 135),
215 |         (215, 0, 175),
216 |         (215, 0, 215),
217 |         (215, 0, 255),
218 |         (215, 95, 0),
219 |         (215, 95, 95),
220 |         (215, 95, 135),
221 |         (215, 95, 175),
222 |         (215, 95, 215),
223 |         (215, 95, 255),
224 |         (215, 135, 0),
225 |         (215, 135, 95),
226 |         (215, 135, 135),
227 |         (215, 135, 175),
228 |         (215, 135, 215),
229 |         (215, 135, 255),
230 |         (215, 175, 0),
231 |         (215, 175, 95),
232 |         (215, 175, 135),
233 |         (215, 175, 175),
234 |         (215, 175, 215),
235 |         (215, 175, 255),
236 |         (215, 215, 0),
237 |         (215, 215, 95),
238 |         (215, 215, 135),
239 |         (215, 215, 175),
240 |         (215, 215, 215),
241 |         (215, 215, 255),
242 |         (215, 255, 0),
243 |         (215, 255, 95),
244 |         (215, 255, 135),
245 |         (215, 255, 175),
246 |         (215, 255, 215),
247 |         (215, 255, 255),
248 |         (255, 0, 0),
249 |         (255, 0, 95),
250 |         (255, 0, 135),
251 |         (255, 0, 175),
252 |         (255, 0, 215),
253 |         (255, 0, 255),
254 |         (255, 95, 0),
255 |         (255, 95, 95),
256 |         (255, 95, 135),
257 |         (255, 95, 175),
258 |         (255, 95, 215),
259 |         (255, 95, 255),
260 |         (255, 135, 0),
261 |         (255, 135, 95),
262 |         (255, 135, 135),
263 |         (255, 135, 175),
264 |         (255, 135, 215),
265 |         (255, 135, 255),
266 |         (255, 175, 0),
267 |         (255, 175, 95),
268 |         (255, 175, 135),
269 |         (255, 175, 175),
270 |         (255, 175, 215),
271 |         (255, 175, 255),
272 |         (255, 215, 0),
273 |         (255, 215, 95),
274 |         (255, 215, 135),
275 |         (255, 215, 175),
276 |         (255, 215, 215),
277 |         (255, 215, 255),
278 |         (255, 255, 0),
279 |         (255, 255, 95),
280 |         (255, 255, 135),
281 |         (255, 255, 175),
282 |         (255, 255, 215),
283 |         (255, 255, 255),
284 |         (8, 8, 8),
285 |         (18, 18, 18),
286 |         (28, 28, 28),
287 |         (38, 38, 38),
288 |         (48, 48, 48),
289 |         (58, 58, 58),
290 |         (68, 68, 68),
291 |         (78, 78, 78),
292 |         (88, 88, 88),
293 |         (98, 98, 98),
294 |         (108, 108, 108),
295 |         (118, 118, 118),
296 |         (128, 128, 128),
297 |         (138, 138, 138),
298 |         (148, 148, 148),
299 |         (158, 158, 158),
300 |         (168, 168, 168),
301 |         (178, 178, 178),
302 |         (188, 188, 188),
303 |         (198, 198, 198),
304 |         (208, 208, 208),
305 |         (218, 218, 218),
306 |         (228, 228, 228),
307 |         (238, 238, 238),
308 |     ]
309 | )
```

.venv/lib/python3.13/site-packages/pip/_vendor/rich/_pick.py
```
1 | from typing import Optional
2 | 
3 | 
4 | def pick_bool(*values: Optional[bool]) -> bool:
5 |     """Pick the first non-none bool or return the last value.
6 | 
7 |     Args:
8 |         *values (bool): Any number of boolean or None values.
9 | 
10 |     Returns:
11 |         bool: First non-none boolean.
12 |     """
13 |     assert values, "1 or more values required"
14 |     for value in values:
15 |         if value is not None:
16 |             return value
17 |     return bool(value)
```

.venv/lib/python3.13/site-packages/pip/_vendor/rich/_ratio.py
```
1 | import sys
2 | from fractions import Fraction
3 | from math import ceil
4 | from typing import cast, List, Optional, Sequence
5 | 
6 | if sys.version_info >= (3, 8):
7 |     from typing import Protocol
8 | else:
9 |     from pip._vendor.typing_extensions import Protocol  # pragma: no cover
10 | 
11 | 
12 | class Edge(Protocol):
13 |     """Any object that defines an edge (such as Layout)."""
14 | 
15 |     size: Optional[int] = None
16 |     ratio: int = 1
17 |     minimum_size: int = 1
18 | 
19 | 
20 | def ratio_resolve(total: int, edges: Sequence[Edge]) -> List[int]:
21 |     """Divide total space to satisfy size, ratio, and minimum_size, constraints.
22 | 
23 |     The returned list of integers should add up to total in most cases, unless it is
24 |     impossible to satisfy all the constraints. For instance, if there are two edges
25 |     with a minimum size of 20 each and `total` is 30 then the returned list will be
26 |     greater than total. In practice, this would mean that a Layout object would
27 |     clip the rows that would overflow the screen height.
28 | 
29 |     Args:
30 |         total (int): Total number of characters.
31 |         edges (List[Edge]): Edges within total space.
32 | 
33 |     Returns:
34 |         List[int]: Number of characters for each edge.
35 |     """
36 |     # Size of edge or None for yet to be determined
37 |     sizes = [(edge.size or None) for edge in edges]
38 | 
39 |     _Fraction = Fraction
40 | 
41 |     # While any edges haven't been calculated
42 |     while None in sizes:
43 |         # Get flexible edges and index to map these back on to sizes list
44 |         flexible_edges = [
45 |             (index, edge)
46 |             for index, (size, edge) in enumerate(zip(sizes, edges))
47 |             if size is None
48 |         ]
49 |         # Remaining space in total
50 |         remaining = total - sum(size or 0 for size in sizes)
51 |         if remaining <= 0:
52 |             # No room for flexible edges
53 |             return [
54 |                 ((edge.minimum_size or 1) if size is None else size)
55 |                 for size, edge in zip(sizes, edges)
56 |             ]
57 |         # Calculate number of characters in a ratio portion
58 |         portion = _Fraction(
59 |             remaining, sum((edge.ratio or 1) for _, edge in flexible_edges)
60 |         )
61 | 
62 |         # If any edges will be less than their minimum, replace size with the minimum
63 |         for index, edge in flexible_edges:
64 |             if portion * edge.ratio <= edge.minimum_size:
65 |                 sizes[index] = edge.minimum_size
66 |                 # New fixed size will invalidate calculations, so we need to repeat the process
67 |                 break
68 |         else:
69 |             # Distribute flexible space and compensate for rounding error
70 |             # Since edge sizes can only be integers we need to add the remainder
71 |             # to the following line
72 |             remainder = _Fraction(0)
73 |             for index, edge in flexible_edges:
74 |                 size, remainder = divmod(portion * edge.ratio + remainder, 1)
75 |                 sizes[index] = size
76 |             break
77 |     # Sizes now contains integers only
78 |     return cast(List[int], sizes)
79 | 
80 | 
81 | def ratio_reduce(
82 |     total: int, ratios: List[int], maximums: List[int], values: List[int]
83 | ) -> List[int]:
84 |     """Divide an integer total in to parts based on ratios.
85 | 
86 |     Args:
87 |         total (int): The total to divide.
88 |         ratios (List[int]): A list of integer ratios.
89 |         maximums (List[int]): List of maximums values for each slot.
90 |         values (List[int]): List of values
91 | 
92 |     Returns:
93 |         List[int]: A list of integers guaranteed to sum to total.
94 |     """
95 |     ratios = [ratio if _max else 0 for ratio, _max in zip(ratios, maximums)]
96 |     total_ratio = sum(ratios)
97 |     if not total_ratio:
98 |         return values[:]
99 |     total_remaining = total
100 |     result: List[int] = []
101 |     append = result.append
102 |     for ratio, maximum, value in zip(ratios, maximums, values):
103 |         if ratio and total_ratio > 0:
104 |             distributed = min(maximum, round(ratio * total_remaining / total_ratio))
105 |             append(value - distributed)
106 |             total_remaining -= distributed
107 |             total_ratio -= ratio
108 |         else:
109 |             append(value)
110 |     return result
111 | 
112 | 
113 | def ratio_distribute(
114 |     total: int, ratios: List[int], minimums: Optional[List[int]] = None
115 | ) -> List[int]:
116 |     """Distribute an integer total in to parts based on ratios.
117 | 
118 |     Args:
119 |         total (int): The total to divide.
120 |         ratios (List[int]): A list of integer ratios.
121 |         minimums (List[int]): List of minimum values for each slot.
122 | 
123 |     Returns:
124 |         List[int]: A list of integers guaranteed to sum to total.
125 |     """
126 |     if minimums:
127 |         ratios = [ratio if _min else 0 for ratio, _min in zip(ratios, minimums)]
128 |     total_ratio = sum(ratios)
129 |     assert total_ratio > 0, "Sum of ratios must be > 0"
130 | 
131 |     total_remaining = total
132 |     distributed_total: List[int] = []
133 |     append = distributed_total.append
134 |     if minimums is None:
135 |         _minimums = [0] * len(ratios)
136 |     else:
137 |         _minimums = minimums
138 |     for ratio, minimum in zip(ratios, _minimums):
139 |         if total_ratio > 0:
140 |             distributed = max(minimum, ceil(ratio * total_remaining / total_ratio))
141 |         else:
142 |             distributed = total_remaining
143 |         append(distributed)
144 |         total_ratio -= ratio
145 |         total_remaining -= distributed
146 |     return distributed_total
147 | 
148 | 
149 | if __name__ == "__main__":
150 |     from dataclasses import dataclass
151 | 
152 |     @dataclass
153 |     class E:
154 |         size: Optional[int] = None
155 |         ratio: int = 1
156 |         minimum_size: int = 1
157 | 
158 |     resolved = ratio_resolve(110, [E(None, 1, 1), E(None, 1, 1), E(None, 1, 1)])
159 |     print(sum(resolved))
```

.venv/lib/python3.13/site-packages/pip/_vendor/rich/_spinners.py
```
1 | """
2 | Spinners are from:
3 | * cli-spinners:
4 |     MIT License
5 |     Copyright (c) Sindre Sorhus <sindresorhus@gmail.com> (sindresorhus.com)
6 |     Permission is hereby granted, free of charge, to any person obtaining a copy
7 |     of this software and associated documentation files (the "Software"), to deal
8 |     in the Software without restriction, including without limitation the rights to
9 |     use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of
10 |     the Software, and to permit persons to whom the Software is furnished to do so,
11 |     subject to the following conditions:
12 |     The above copyright notice and this permission notice shall be included
13 |     in all copies or substantial portions of the Software.
14 |     THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED,
15 |     INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR
16 |     PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE
17 |     FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
18 |     ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS
19 |     IN THE SOFTWARE.
20 | """
21 | 
22 | SPINNERS = {
23 |     "dots": {
24 |         "interval": 80,
25 |         "frames": "",
26 |     },
27 |     "dots2": {"interval": 80, "frames": ""},
28 |     "dots3": {
29 |         "interval": 80,
30 |         "frames": "",
31 |     },
32 |     "dots4": {
33 |         "interval": 80,
34 |         "frames": "",
35 |     },
36 |     "dots5": {
37 |         "interval": 80,
38 |         "frames": "",
39 |     },
40 |     "dots6": {
41 |         "interval": 80,
42 |         "frames": "",
43 |     },
44 |     "dots7": {
45 |         "interval": 80,
46 |         "frames": "",
47 |     },
48 |     "dots8": {
49 |         "interval": 80,
50 |         "frames": "",
51 |     },
52 |     "dots9": {"interval": 80, "frames": ""},
53 |     "dots10": {"interval": 80, "frames": ""},
54 |     "dots11": {"interval": 100, "frames": ""},
55 |     "dots12": {
56 |         "interval": 80,
57 |         "frames": [
58 |             "",
59 |             "",
60 |             "",
61 |             "",
62 |             "",
63 |             "",
64 |             "",
65 |             "",
66 |             "",
67 |             "",
68 |             "",
69 |             "",
70 |             "",
71 |             "",
72 |             "",
73 |             "",
74 |             "",
75 |             "",
76 |             "",
77 |             "",
78 |             "",
79 |             "",
80 |             "",
81 |             "",
82 |             "",
83 |             "",
84 |             "",
85 |             "",
86 |             "",
87 |             "",
88 |             "",
89 |             "",
90 |             "",
91 |             "",
92 |             "",
93 |             "",
94 |             "",
95 |             "",
96 |             "",
97 |             "",
98 |             "",
99 |             "",
100 |             "",
101 |             "",
102 |             "",
103 |             "",
104 |             "",
105 |             "",
106 |             "",
107 |             "",
108 |             "",
109 |             "",
110 |             "",
111 |             "",
112 |             "",
113 |             "",
114 |         ],
115 |     },
116 |     "dots8Bit": {
117 |         "interval": 80,
118 |         "frames": ""
119 |         ""
120 |         ""
121 |         ""
122 |         "",
123 |     },
124 |     "line": {"interval": 130, "frames": ["-", "\\", "|", "/"]},
125 |     "line2": {"interval": 100, "frames": "--"},
126 |     "pipe": {"interval": 100, "frames": ""},
127 |     "simpleDots": {"interval": 400, "frames": [".  ", ".. ", "...", "   "]},
128 |     "simpleDotsScrolling": {
129 |         "interval": 200,
130 |         "frames": [".  ", ".. ", "...", " ..", "  .", "   "],
131 |     },
132 |     "star": {"interval": 70, "frames": ""},
133 |     "star2": {"interval": 80, "frames": "+x*"},
134 |     "flip": {
135 |         "interval": 70,
136 |         "frames": "___-``'-___",
137 |     },
138 |     "hamburger": {"interval": 100, "frames": ""},
139 |     "growVertical": {
140 |         "interval": 120,
141 |         "frames": "",
142 |     },
143 |     "growHorizontal": {
144 |         "interval": 120,
145 |         "frames": "",
146 |     },
147 |     "balloon": {"interval": 140, "frames": " .oO@* "},
148 |     "balloon2": {"interval": 120, "frames": ".oOOo."},
149 |     "noise": {"interval": 100, "frames": ""},
150 |     "bounce": {"interval": 120, "frames": ""},
151 |     "boxBounce": {"interval": 120, "frames": ""},
152 |     "boxBounce2": {"interval": 100, "frames": ""},
153 |     "triangle": {"interval": 50, "frames": ""},
154 |     "arc": {"interval": 100, "frames": ""},
155 |     "circle": {"interval": 120, "frames": ""},
156 |     "squareCorners": {"interval": 180, "frames": ""},
157 |     "circleQuarters": {"interval": 120, "frames": ""},
158 |     "circleHalves": {"interval": 50, "frames": ""},
159 |     "squish": {"interval": 100, "frames": ""},
160 |     "toggle": {"interval": 250, "frames": ""},
161 |     "toggle2": {"interval": 80, "frames": ""},
162 |     "toggle3": {"interval": 120, "frames": ""},
163 |     "toggle4": {"interval": 100, "frames": ""},
164 |     "toggle5": {"interval": 100, "frames": ""},
165 |     "toggle6": {"interval": 300, "frames": ""},
166 |     "toggle7": {"interval": 80, "frames": ""},
167 |     "toggle8": {"interval": 100, "frames": ""},
168 |     "toggle9": {"interval": 100, "frames": ""},
169 |     "toggle10": {"interval": 100, "frames": ""},
170 |     "toggle11": {"interval": 50, "frames": ""},
171 |     "toggle12": {"interval": 120, "frames": ""},
172 |     "toggle13": {"interval": 80, "frames": "=*-"},
173 |     "arrow": {"interval": 100, "frames": ""},
174 |     "arrow2": {
175 |         "interval": 80,
176 |         "frames": [" ", " ", " ", " ", " ", " ", " ", " "],
177 |     },
178 |     "arrow3": {
179 |         "interval": 120,
180 |         "frames": ["", "", "", "", "", ""],
181 |     },
182 |     "bouncingBar": {
183 |         "interval": 80,
184 |         "frames": [
185 |             "[    ]",
186 |             "[=   ]",
187 |             "[==  ]",
188 |             "[=== ]",
189 |             "[ ===]",
190 |             "[  ==]",
191 |             "[   =]",
192 |             "[    ]",
193 |             "[   =]",
194 |             "[  ==]",
195 |             "[ ===]",
196 |             "[====]",
197 |             "[=== ]",
198 |             "[==  ]",
199 |             "[=   ]",
200 |         ],
201 |     },
202 |     "bouncingBall": {
203 |         "interval": 80,
204 |         "frames": [
205 |             "(     )",
206 |             "(     )",
207 |             "(     )",
208 |             "(     )",
209 |             "(     )",
210 |             "(     )",
211 |             "(     )",
212 |             "(     )",
213 |             "(     )",
214 |             "(     )",
215 |         ],
216 |     },
217 |     "smiley": {"interval": 200, "frames": [" ", " "]},
218 |     "monkey": {"interval": 300, "frames": [" ", " ", " ", " "]},
219 |     "hearts": {"interval": 100, "frames": [" ", " ", " ", " ", " "]},
220 |     "clock": {
221 |         "interval": 100,
222 |         "frames": [
223 |             " ",
224 |             " ",
225 |             " ",
226 |             " ",
227 |             " ",
228 |             " ",
229 |             " ",
230 |             " ",
231 |             " ",
232 |             " ",
233 |             " ",
234 |             " ",
235 |         ],
236 |     },
237 |     "earth": {"interval": 180, "frames": [" ", " ", " "]},
238 |     "material": {
239 |         "interval": 17,
240 |         "frames": [
241 |             "",
242 |             "",
243 |             "",
244 |             "",
245 |             "",
246 |             "",
247 |             "",
248 |             "",
249 |             "",
250 |             "",
251 |             "",
252 |             "",
253 |             "",
254 |             "",
255 |             "",
256 |             "",
257 |             "",
258 |             "",
259 |             "",
260 |             "",
261 |             "",
262 |             "",
263 |             "",
264 |             "",
265 |             "",
266 |             "",
267 |             "",
268 |             "",
269 |             "",
270 |             "",
271 |             "",
272 |             "",
273 |             "",
274 |             "",
275 |             "",
276 |             "",
277 |             "",
278 |             "",
279 |             "",
280 |             "",
281 |             "",
282 |             "",
283 |             "",
284 |             "",
285 |             "",
286 |             "",
287 |             "",
288 |             "",
289 |             "",
290 |             "",
291 |             "",
292 |             "",
293 |             "",
294 |             "",
295 |             "",
296 |             "",
297 |             "",
298 |             "",
299 |             "",
300 |             "",
301 |             "",
302 |             "",
303 |             "",
304 |             "",
305 |             "",
306 |             "",
307 |             "",
308 |             "",
309 |             "",
310 |             "",
311 |             "",
312 |             "",
313 |             "",
314 |             "",
315 |             "",
316 |             "",
317 |             "",
318 |             "",
319 |             "",
320 |             "",
321 |             "",
322 |             "",
323 |             "",
324 |             "",
325 |             "",
326 |             "",
327 |             "",
328 |             "",
329 |             "",
330 |             "",
331 |             "",
332 |             "",
333 |         ],
334 |     },
335 |     "moon": {
336 |         "interval": 80,
337 |         "frames": [" ", " ", " ", " ", " ", " ", " ", " "],
338 |     },
339 |     "runner": {"interval": 140, "frames": [" ", " "]},
340 |     "pong": {
341 |         "interval": 80,
342 |         "frames": [
343 |             "       ",
344 |             "       ",
345 |             "       ",
346 |             "       ",
347 |             "       ",
348 |             "       ",
349 |             "       ",
350 |             "       ",
351 |             "       ",
352 |             "       ",
353 |             "       ",
354 |             "       ",
355 |             "       ",
356 |             "       ",
357 |             "       ",
358 |             "       ",
359 |             "       ",
360 |             "       ",
361 |             "       ",
362 |             "       ",
363 |             "       ",
364 |             "       ",
365 |             "       ",
366 |             "       ",
367 |             "       ",
368 |             "       ",
369 |             "       ",
370 |             "       ",
371 |             "       ",
372 |             "       ",
373 |         ],
374 |     },
375 |     "shark": {
376 |         "interval": 120,
377 |         "frames": [
378 |             "|\\____________",
379 |             "_|\\___________",
380 |             "__|\\__________",
381 |             "___|\\_________",
382 |             "____|\\________",
383 |             "_____|\\_______",
384 |             "______|\\______",
385 |             "_______|\\_____",
386 |             "________|\\____",
387 |             "_________|\\___",
388 |             "__________|\\__",
389 |             "___________|\\_",
390 |             "____________|\\",
391 |             "____________/|",
392 |             "___________/|_",
393 |             "__________/|__",
394 |             "_________/|___",
395 |             "________/|____",
396 |             "_______/|_____",
397 |             "______/|______",
398 |             "_____/|_______",
399 |             "____/|________",
400 |             "___/|_________",
401 |             "__/|__________",
402 |             "_/|___________",
403 |             "/|____________",
404 |         ],
405 |     },
406 |     "dqpb": {"interval": 100, "frames": "dqpb"},
407 |     "weather": {
408 |         "interval": 100,
409 |         "frames": [
410 |             " ",
411 |             " ",
412 |             " ",
413 |             " ",
414 |             " ",
415 |             " ",
416 |             " ",
417 |             " ",
418 |             " ",
419 |             " ",
420 |             " ",
421 |             " ",
422 |             " ",
423 |             " ",
424 |             " ",
425 |             " ",
426 |             " ",
427 |             " ",
428 |             " ",
429 |             " ",
430 |             " ",
431 |             " ",
432 |             " ",
433 |         ],
434 |     },
435 |     "christmas": {"interval": 400, "frames": ""},
436 |     "grenade": {
437 |         "interval": 80,
438 |         "frames": [
439 |             "   ",
440 |             "   ",
441 |             "  ",
442 |             "  ",
443 |             "  ",
444 |             "  ",
445 |             "  |",
446 |             "  ",
447 |             "  ",
448 |             "  ",
449 |             "  ",
450 |             "   ",
451 |             "   ",
452 |             "   ",
453 |         ],
454 |     },
455 |     "point": {"interval": 125, "frames": ["", "", "", "", ""]},
456 |     "layer": {"interval": 150, "frames": "-="},
457 |     "betaWave": {
458 |         "interval": 80,
459 |         "frames": [
460 |             "",
461 |             "",
462 |             "",
463 |             "",
464 |             "",
465 |             "",
466 |             "",
467 |         ],
468 |     },
469 |     "aesthetic": {
470 |         "interval": 80,
471 |         "frames": [
472 |             "",
473 |             "",
474 |             "",
475 |             "",
476 |             "",
477 |             "",
478 |             "",
479 |             "",
480 |         ],
481 |     },
482 | }
```

.venv/lib/python3.13/site-packages/pip/_vendor/rich/_stack.py
```
1 | from typing import List, TypeVar
2 | 
3 | T = TypeVar("T")
4 | 
5 | 
6 | class Stack(List[T]):
7 |     """A small shim over builtin list."""
8 | 
9 |     @property
10 |     def top(self) -> T:
11 |         """Get top of stack."""
12 |         return self[-1]
13 | 
14 |     def push(self, item: T) -> None:
15 |         """Push an item on to the stack (append in stack nomenclature)."""
16 |         self.append(item)
```

.venv/lib/python3.13/site-packages/pip/_vendor/rich/_timer.py
```
1 | """
2 | Timer context manager, only used in debug.
3 | 
4 | """
5 | 
6 | from time import time
7 | 
8 | import contextlib
9 | from typing import Generator
10 | 
11 | 
12 | @contextlib.contextmanager
13 | def timer(subject: str = "time") -> Generator[None, None, None]:
14 |     """print the elapsed time. (only used in debugging)"""
15 |     start = time()
16 |     yield
17 |     elapsed = time() - start
18 |     elapsed_ms = elapsed * 1000
19 |     print(f"{subject} elapsed {elapsed_ms:.1f}ms")
```

.venv/lib/python3.13/site-packages/pip/_vendor/rich/_win32_console.py
```
1 | """Light wrapper around the Win32 Console API - this module should only be imported on Windows
2 | 
3 | The API that this module wraps is documented at https://docs.microsoft.com/en-us/windows/console/console-functions
4 | """
5 | 
6 | import ctypes
7 | import sys
8 | from typing import Any
9 | 
10 | windll: Any = None
11 | if sys.platform == "win32":
12 |     windll = ctypes.LibraryLoader(ctypes.WinDLL)
13 | else:
14 |     raise ImportError(f"{__name__} can only be imported on Windows")
15 | 
16 | import time
17 | from ctypes import Structure, byref, wintypes
18 | from typing import IO, NamedTuple, Type, cast
19 | 
20 | from pip._vendor.rich.color import ColorSystem
21 | from pip._vendor.rich.style import Style
22 | 
23 | STDOUT = -11
24 | ENABLE_VIRTUAL_TERMINAL_PROCESSING = 4
25 | 
26 | COORD = wintypes._COORD
27 | 
28 | 
29 | class LegacyWindowsError(Exception):
30 |     pass
31 | 
32 | 
33 | class WindowsCoordinates(NamedTuple):
34 |     """Coordinates in the Windows Console API are (y, x), not (x, y).
35 |     This class is intended to prevent that confusion.
36 |     Rows and columns are indexed from 0.
37 |     This class can be used in place of wintypes._COORD in arguments and argtypes.
38 |     """
39 | 
40 |     row: int
41 |     col: int
42 | 
43 |     @classmethod
44 |     def from_param(cls, value: "WindowsCoordinates") -> COORD:
45 |         """Converts a WindowsCoordinates into a wintypes _COORD structure.
46 |         This classmethod is internally called by ctypes to perform the conversion.
47 | 
48 |         Args:
49 |             value (WindowsCoordinates): The input coordinates to convert.
50 | 
51 |         Returns:
52 |             wintypes._COORD: The converted coordinates struct.
53 |         """
54 |         return COORD(value.col, value.row)
55 | 
56 | 
57 | class CONSOLE_SCREEN_BUFFER_INFO(Structure):
58 |     _fields_ = [
59 |         ("dwSize", COORD),
60 |         ("dwCursorPosition", COORD),
61 |         ("wAttributes", wintypes.WORD),
62 |         ("srWindow", wintypes.SMALL_RECT),
63 |         ("dwMaximumWindowSize", COORD),
64 |     ]
65 | 
66 | 
67 | class CONSOLE_CURSOR_INFO(ctypes.Structure):
68 |     _fields_ = [("dwSize", wintypes.DWORD), ("bVisible", wintypes.BOOL)]
69 | 
70 | 
71 | _GetStdHandle = windll.kernel32.GetStdHandle
72 | _GetStdHandle.argtypes = [
73 |     wintypes.DWORD,
74 | ]
75 | _GetStdHandle.restype = wintypes.HANDLE
76 | 
77 | 
78 | def GetStdHandle(handle: int = STDOUT) -> wintypes.HANDLE:
79 |     """Retrieves a handle to the specified standard device (standard input, standard output, or standard error).
80 | 
81 |     Args:
82 |         handle (int): Integer identifier for the handle. Defaults to -11 (stdout).
83 | 
84 |     Returns:
85 |         wintypes.HANDLE: The handle
86 |     """
87 |     return cast(wintypes.HANDLE, _GetStdHandle(handle))
88 | 
89 | 
90 | _GetConsoleMode = windll.kernel32.GetConsoleMode
91 | _GetConsoleMode.argtypes = [wintypes.HANDLE, wintypes.LPDWORD]
92 | _GetConsoleMode.restype = wintypes.BOOL
93 | 
94 | 
95 | def GetConsoleMode(std_handle: wintypes.HANDLE) -> int:
96 |     """Retrieves the current input mode of a console's input buffer
97 |     or the current output mode of a console screen buffer.
98 | 
99 |     Args:
100 |         std_handle (wintypes.HANDLE): A handle to the console input buffer or the console screen buffer.
101 | 
102 |     Raises:
103 |         LegacyWindowsError: If any error occurs while calling the Windows console API.
104 | 
105 |     Returns:
106 |         int: Value representing the current console mode as documented at
107 |             https://docs.microsoft.com/en-us/windows/console/getconsolemode#parameters
108 |     """
109 | 
110 |     console_mode = wintypes.DWORD()
111 |     success = bool(_GetConsoleMode(std_handle, console_mode))
112 |     if not success:
113 |         raise LegacyWindowsError("Unable to get legacy Windows Console Mode")
114 |     return console_mode.value
115 | 
116 | 
117 | _FillConsoleOutputCharacterW = windll.kernel32.FillConsoleOutputCharacterW
118 | _FillConsoleOutputCharacterW.argtypes = [
119 |     wintypes.HANDLE,
120 |     ctypes.c_char,
121 |     wintypes.DWORD,
122 |     cast(Type[COORD], WindowsCoordinates),
123 |     ctypes.POINTER(wintypes.DWORD),
124 | ]
125 | _FillConsoleOutputCharacterW.restype = wintypes.BOOL
126 | 
127 | 
128 | def FillConsoleOutputCharacter(
129 |     std_handle: wintypes.HANDLE,
130 |     char: str,
131 |     length: int,
132 |     start: WindowsCoordinates,
133 | ) -> int:
134 |     """Writes a character to the console screen buffer a specified number of times, beginning at the specified coordinates.
135 | 
136 |     Args:
137 |         std_handle (wintypes.HANDLE): A handle to the console input buffer or the console screen buffer.
138 |         char (str): The character to write. Must be a string of length 1.
139 |         length (int): The number of times to write the character.
140 |         start (WindowsCoordinates): The coordinates to start writing at.
141 | 
142 |     Returns:
143 |         int: The number of characters written.
144 |     """
145 |     character = ctypes.c_char(char.encode())
146 |     num_characters = wintypes.DWORD(length)
147 |     num_written = wintypes.DWORD(0)
148 |     _FillConsoleOutputCharacterW(
149 |         std_handle,
150 |         character,
151 |         num_characters,
152 |         start,
153 |         byref(num_written),
154 |     )
155 |     return num_written.value
156 | 
157 | 
158 | _FillConsoleOutputAttribute = windll.kernel32.FillConsoleOutputAttribute
159 | _FillConsoleOutputAttribute.argtypes = [
160 |     wintypes.HANDLE,
161 |     wintypes.WORD,
162 |     wintypes.DWORD,
163 |     cast(Type[COORD], WindowsCoordinates),
164 |     ctypes.POINTER(wintypes.DWORD),
165 | ]
166 | _FillConsoleOutputAttribute.restype = wintypes.BOOL
167 | 
168 | 
169 | def FillConsoleOutputAttribute(
170 |     std_handle: wintypes.HANDLE,
171 |     attributes: int,
172 |     length: int,
173 |     start: WindowsCoordinates,
174 | ) -> int:
175 |     """Sets the character attributes for a specified number of character cells,
176 |     beginning at the specified coordinates in a screen buffer.
177 | 
178 |     Args:
179 |         std_handle (wintypes.HANDLE): A handle to the console input buffer or the console screen buffer.
180 |         attributes (int): Integer value representing the foreground and background colours of the cells.
181 |         length (int): The number of cells to set the output attribute of.
182 |         start (WindowsCoordinates): The coordinates of the first cell whose attributes are to be set.
183 | 
184 |     Returns:
185 |         int: The number of cells whose attributes were actually set.
186 |     """
187 |     num_cells = wintypes.DWORD(length)
188 |     style_attrs = wintypes.WORD(attributes)
189 |     num_written = wintypes.DWORD(0)
190 |     _FillConsoleOutputAttribute(
191 |         std_handle, style_attrs, num_cells, start, byref(num_written)
192 |     )
193 |     return num_written.value
194 | 
195 | 
196 | _SetConsoleTextAttribute = windll.kernel32.SetConsoleTextAttribute
197 | _SetConsoleTextAttribute.argtypes = [
198 |     wintypes.HANDLE,
199 |     wintypes.WORD,
200 | ]
201 | _SetConsoleTextAttribute.restype = wintypes.BOOL
202 | 
203 | 
204 | def SetConsoleTextAttribute(
205 |     std_handle: wintypes.HANDLE, attributes: wintypes.WORD
206 | ) -> bool:
207 |     """Set the colour attributes for all text written after this function is called.
208 | 
209 |     Args:
210 |         std_handle (wintypes.HANDLE): A handle to the console input buffer or the console screen buffer.
211 |         attributes (int): Integer value representing the foreground and background colours.
212 | 
213 | 
214 |     Returns:
215 |         bool: True if the attribute was set successfully, otherwise False.
216 |     """
217 |     return bool(_SetConsoleTextAttribute(std_handle, attributes))
218 | 
219 | 
220 | _GetConsoleScreenBufferInfo = windll.kernel32.GetConsoleScreenBufferInfo
221 | _GetConsoleScreenBufferInfo.argtypes = [
222 |     wintypes.HANDLE,
223 |     ctypes.POINTER(CONSOLE_SCREEN_BUFFER_INFO),
224 | ]
225 | _GetConsoleScreenBufferInfo.restype = wintypes.BOOL
226 | 
227 | 
228 | def GetConsoleScreenBufferInfo(
229 |     std_handle: wintypes.HANDLE,
230 | ) -> CONSOLE_SCREEN_BUFFER_INFO:
231 |     """Retrieves information about the specified console screen buffer.
232 | 
233 |     Args:
234 |         std_handle (wintypes.HANDLE): A handle to the console input buffer or the console screen buffer.
235 | 
236 |     Returns:
237 |         CONSOLE_SCREEN_BUFFER_INFO: A CONSOLE_SCREEN_BUFFER_INFO ctype struct contain information about
238 |             screen size, cursor position, colour attributes, and more."""
239 |     console_screen_buffer_info = CONSOLE_SCREEN_BUFFER_INFO()
240 |     _GetConsoleScreenBufferInfo(std_handle, byref(console_screen_buffer_info))
241 |     return console_screen_buffer_info
242 | 
243 | 
244 | _SetConsoleCursorPosition = windll.kernel32.SetConsoleCursorPosition
245 | _SetConsoleCursorPosition.argtypes = [
246 |     wintypes.HANDLE,
247 |     cast(Type[COORD], WindowsCoordinates),
248 | ]
249 | _SetConsoleCursorPosition.restype = wintypes.BOOL
250 | 
251 | 
252 | def SetConsoleCursorPosition(
253 |     std_handle: wintypes.HANDLE, coords: WindowsCoordinates
254 | ) -> bool:
255 |     """Set the position of the cursor in the console screen
256 | 
257 |     Args:
258 |         std_handle (wintypes.HANDLE): A handle to the console input buffer or the console screen buffer.
259 |         coords (WindowsCoordinates): The coordinates to move the cursor to.
260 | 
261 |     Returns:
262 |         bool: True if the function succeeds, otherwise False.
263 |     """
264 |     return bool(_SetConsoleCursorPosition(std_handle, coords))
265 | 
266 | 
267 | _GetConsoleCursorInfo = windll.kernel32.GetConsoleCursorInfo
268 | _GetConsoleCursorInfo.argtypes = [
269 |     wintypes.HANDLE,
270 |     ctypes.POINTER(CONSOLE_CURSOR_INFO),
271 | ]
272 | _GetConsoleCursorInfo.restype = wintypes.BOOL
273 | 
274 | 
275 | def GetConsoleCursorInfo(
276 |     std_handle: wintypes.HANDLE, cursor_info: CONSOLE_CURSOR_INFO
277 | ) -> bool:
278 |     """Get the cursor info - used to get cursor visibility and width
279 | 
280 |     Args:
281 |         std_handle (wintypes.HANDLE): A handle to the console input buffer or the console screen buffer.
282 |         cursor_info (CONSOLE_CURSOR_INFO): CONSOLE_CURSOR_INFO ctype struct that receives information
283 |             about the console's cursor.
284 | 
285 |     Returns:
286 |           bool: True if the function succeeds, otherwise False.
287 |     """
288 |     return bool(_GetConsoleCursorInfo(std_handle, byref(cursor_info)))
289 | 
290 | 
291 | _SetConsoleCursorInfo = windll.kernel32.SetConsoleCursorInfo
292 | _SetConsoleCursorInfo.argtypes = [
293 |     wintypes.HANDLE,
294 |     ctypes.POINTER(CONSOLE_CURSOR_INFO),
295 | ]
296 | _SetConsoleCursorInfo.restype = wintypes.BOOL
297 | 
298 | 
299 | def SetConsoleCursorInfo(
300 |     std_handle: wintypes.HANDLE, cursor_info: CONSOLE_CURSOR_INFO
301 | ) -> bool:
302 |     """Set the cursor info - used for adjusting cursor visibility and width
303 | 
304 |     Args:
305 |         std_handle (wintypes.HANDLE): A handle to the console input buffer or the console screen buffer.
306 |         cursor_info (CONSOLE_CURSOR_INFO): CONSOLE_CURSOR_INFO ctype struct containing the new cursor info.
307 | 
308 |     Returns:
309 |           bool: True if the function succeeds, otherwise False.
310 |     """
311 |     return bool(_SetConsoleCursorInfo(std_handle, byref(cursor_info)))
312 | 
313 | 
314 | _SetConsoleTitle = windll.kernel32.SetConsoleTitleW
315 | _SetConsoleTitle.argtypes = [wintypes.LPCWSTR]
316 | _SetConsoleTitle.restype = wintypes.BOOL
317 | 
318 | 
319 | def SetConsoleTitle(title: str) -> bool:
320 |     """Sets the title of the current console window
321 | 
322 |     Args:
323 |         title (str): The new title of the console window.
324 | 
325 |     Returns:
326 |         bool: True if the function succeeds, otherwise False.
327 |     """
328 |     return bool(_SetConsoleTitle(title))
329 | 
330 | 
331 | class LegacyWindowsTerm:
332 |     """This class allows interaction with the legacy Windows Console API. It should only be used in the context
333 |     of environments where virtual terminal processing is not available. However, if it is used in a Windows environment,
334 |     the entire API should work.
335 | 
336 |     Args:
337 |         file (IO[str]): The file which the Windows Console API HANDLE is retrieved from, defaults to sys.stdout.
338 |     """
339 | 
340 |     BRIGHT_BIT = 8
341 | 
342 |     # Indices are ANSI color numbers, values are the corresponding Windows Console API color numbers
343 |     ANSI_TO_WINDOWS = [
344 |         0,  # black                      The Windows colours are defined in wincon.h as follows:
345 |         4,  # red                         define FOREGROUND_BLUE            0x0001 -- 0000 0001
346 |         2,  # green                       define FOREGROUND_GREEN           0x0002 -- 0000 0010
347 |         6,  # yellow                      define FOREGROUND_RED             0x0004 -- 0000 0100
348 |         1,  # blue                        define FOREGROUND_INTENSITY       0x0008 -- 0000 1000
349 |         5,  # magenta                     define BACKGROUND_BLUE            0x0010 -- 0001 0000
350 |         3,  # cyan                        define BACKGROUND_GREEN           0x0020 -- 0010 0000
351 |         7,  # white                       define BACKGROUND_RED             0x0040 -- 0100 0000
352 |         8,  # bright black (grey)         define BACKGROUND_INTENSITY       0x0080 -- 1000 0000
353 |         12,  # bright red
354 |         10,  # bright green
355 |         14,  # bright yellow
356 |         9,  # bright blue
357 |         13,  # bright magenta
358 |         11,  # bright cyan
359 |         15,  # bright white
360 |     ]
361 | 
362 |     def __init__(self, file: "IO[str]") -> None:
363 |         handle = GetStdHandle(STDOUT)
364 |         self._handle = handle
365 |         default_text = GetConsoleScreenBufferInfo(handle).wAttributes
366 |         self._default_text = default_text
367 | 
368 |         self._default_fore = default_text & 7
369 |         self._default_back = (default_text >> 4) & 7
370 |         self._default_attrs = self._default_fore | (self._default_back << 4)
371 | 
372 |         self._file = file
373 |         self.write = file.write
[TRUNCATED]
```

.venv/lib/python3.13/site-packages/pip/_vendor/rich/_windows.py
```
1 | import sys
2 | from dataclasses import dataclass
3 | 
4 | 
5 | @dataclass
6 | class WindowsConsoleFeatures:
7 |     """Windows features available."""
8 | 
9 |     vt: bool = False
10 |     """The console supports VT codes."""
11 |     truecolor: bool = False
12 |     """The console supports truecolor."""
13 | 
14 | 
15 | try:
16 |     import ctypes
17 |     from ctypes import LibraryLoader
18 | 
19 |     if sys.platform == "win32":
20 |         windll = LibraryLoader(ctypes.WinDLL)
21 |     else:
22 |         windll = None
23 |         raise ImportError("Not windows")
24 | 
25 |     from pip._vendor.rich._win32_console import (
26 |         ENABLE_VIRTUAL_TERMINAL_PROCESSING,
27 |         GetConsoleMode,
28 |         GetStdHandle,
29 |         LegacyWindowsError,
30 |     )
31 | 
32 | except (AttributeError, ImportError, ValueError):
33 |     # Fallback if we can't load the Windows DLL
34 |     def get_windows_console_features() -> WindowsConsoleFeatures:
35 |         features = WindowsConsoleFeatures()
36 |         return features
37 | 
38 | else:
39 | 
40 |     def get_windows_console_features() -> WindowsConsoleFeatures:
41 |         """Get windows console features.
42 | 
43 |         Returns:
44 |             WindowsConsoleFeatures: An instance of WindowsConsoleFeatures.
45 |         """
46 |         handle = GetStdHandle()
47 |         try:
48 |             console_mode = GetConsoleMode(handle)
49 |             success = True
50 |         except LegacyWindowsError:
51 |             console_mode = 0
52 |             success = False
53 |         vt = bool(success and console_mode & ENABLE_VIRTUAL_TERMINAL_PROCESSING)
54 |         truecolor = False
55 |         if vt:
56 |             win_version = sys.getwindowsversion()
57 |             truecolor = win_version.major > 10 or (
58 |                 win_version.major == 10 and win_version.build >= 15063
59 |             )
60 |         features = WindowsConsoleFeatures(vt=vt, truecolor=truecolor)
61 |         return features
62 | 
63 | 
64 | if __name__ == "__main__":
65 |     import platform
66 | 
67 |     features = get_windows_console_features()
68 |     from pip._vendor.rich import print
69 | 
70 |     print(f'platform="{platform.system()}"')
71 |     print(repr(features))
```

.venv/lib/python3.13/site-packages/pip/_vendor/rich/_windows_renderer.py
```
1 | from typing import Iterable, Sequence, Tuple, cast
2 | 
3 | from pip._vendor.rich._win32_console import LegacyWindowsTerm, WindowsCoordinates
4 | from pip._vendor.rich.segment import ControlCode, ControlType, Segment
5 | 
6 | 
7 | def legacy_windows_render(buffer: Iterable[Segment], term: LegacyWindowsTerm) -> None:
8 |     """Makes appropriate Windows Console API calls based on the segments in the buffer.
9 | 
10 |     Args:
11 |         buffer (Iterable[Segment]): Iterable of Segments to convert to Win32 API calls.
12 |         term (LegacyWindowsTerm): Used to call the Windows Console API.
13 |     """
14 |     for text, style, control in buffer:
15 |         if not control:
16 |             if style:
17 |                 term.write_styled(text, style)
18 |             else:
19 |                 term.write_text(text)
20 |         else:
21 |             control_codes: Sequence[ControlCode] = control
22 |             for control_code in control_codes:
23 |                 control_type = control_code[0]
24 |                 if control_type == ControlType.CURSOR_MOVE_TO:
25 |                     _, x, y = cast(Tuple[ControlType, int, int], control_code)
26 |                     term.move_cursor_to(WindowsCoordinates(row=y - 1, col=x - 1))
27 |                 elif control_type == ControlType.CARRIAGE_RETURN:
28 |                     term.write_text("\r")
29 |                 elif control_type == ControlType.HOME:
30 |                     term.move_cursor_to(WindowsCoordinates(0, 0))
31 |                 elif control_type == ControlType.CURSOR_UP:
32 |                     term.move_cursor_up()
33 |                 elif control_type == ControlType.CURSOR_DOWN:
34 |                     term.move_cursor_down()
35 |                 elif control_type == ControlType.CURSOR_FORWARD:
36 |                     term.move_cursor_forward()
37 |                 elif control_type == ControlType.CURSOR_BACKWARD:
38 |                     term.move_cursor_backward()
39 |                 elif control_type == ControlType.CURSOR_MOVE_TO_COLUMN:
40 |                     _, column = cast(Tuple[ControlType, int], control_code)
41 |                     term.move_cursor_to_column(column - 1)
42 |                 elif control_type == ControlType.HIDE_CURSOR:
43 |                     term.hide_cursor()
44 |                 elif control_type == ControlType.SHOW_CURSOR:
45 |                     term.show_cursor()
46 |                 elif control_type == ControlType.ERASE_IN_LINE:
47 |                     _, mode = cast(Tuple[ControlType, int], control_code)
48 |                     if mode == 0:
49 |                         term.erase_end_of_line()
50 |                     elif mode == 1:
51 |                         term.erase_start_of_line()
52 |                     elif mode == 2:
53 |                         term.erase_line()
54 |                 elif control_type == ControlType.SET_WINDOW_TITLE:
55 |                     _, title = cast(Tuple[ControlType, str], control_code)
56 |                     term.set_title(title)
```

.venv/lib/python3.13/site-packages/pip/_vendor/rich/_wrap.py
```
1 | from __future__ import annotations
2 | 
3 | import re
4 | from typing import Iterable
5 | 
6 | from ._loop import loop_last
7 | from .cells import cell_len, chop_cells
8 | 
9 | re_word = re.compile(r"\s*\S+\s*")
10 | 
11 | 
12 | def words(text: str) -> Iterable[tuple[int, int, str]]:
13 |     """Yields each word from the text as a tuple
14 |     containing (start_index, end_index, word). A "word" in this context may
15 |     include the actual word and any whitespace to the right.
16 |     """
17 |     position = 0
18 |     word_match = re_word.match(text, position)
19 |     while word_match is not None:
20 |         start, end = word_match.span()
21 |         word = word_match.group(0)
22 |         yield start, end, word
23 |         word_match = re_word.match(text, end)
24 | 
25 | 
26 | def divide_line(text: str, width: int, fold: bool = True) -> list[int]:
27 |     """Given a string of text, and a width (measured in cells), return a list
28 |     of cell offsets which the string should be split at in order for it to fit
29 |     within the given width.
30 | 
31 |     Args:
32 |         text: The text to examine.
33 |         width: The available cell width.
34 |         fold: If True, words longer than `width` will be folded onto a new line.
35 | 
36 |     Returns:
37 |         A list of indices to break the line at.
38 |     """
39 |     break_positions: list[int] = []  # offsets to insert the breaks at
40 |     append = break_positions.append
41 |     cell_offset = 0
42 |     _cell_len = cell_len
43 | 
44 |     for start, _end, word in words(text):
45 |         word_length = _cell_len(word.rstrip())
46 |         remaining_space = width - cell_offset
47 |         word_fits_remaining_space = remaining_space >= word_length
48 | 
49 |         if word_fits_remaining_space:
50 |             # Simplest case - the word fits within the remaining width for this line.
51 |             cell_offset += _cell_len(word)
52 |         else:
53 |             # Not enough space remaining for this word on the current line.
54 |             if word_length > width:
55 |                 # The word doesn't fit on any line, so we can't simply
56 |                 # place it on the next line...
57 |                 if fold:
58 |                     # Fold the word across multiple lines.
59 |                     folded_word = chop_cells(word, width=width)
60 |                     for last, line in loop_last(folded_word):
61 |                         if start:
62 |                             append(start)
63 |                         if last:
64 |                             cell_offset = _cell_len(line)
65 |                         else:
66 |                             start += len(line)
67 |                 else:
68 |                     # Folding isn't allowed, so crop the word.
69 |                     if start:
70 |                         append(start)
71 |                     cell_offset = _cell_len(word)
72 |             elif cell_offset and start:
73 |                 # The word doesn't fit within the remaining space on the current
74 |                 # line, but it *can* fit on to the next (empty) line.
75 |                 append(start)
76 |                 cell_offset = _cell_len(word)
77 | 
78 |     return break_positions
79 | 
80 | 
81 | if __name__ == "__main__":  # pragma: no cover
82 |     from .console import Console
83 | 
84 |     console = Console(width=10)
85 |     console.print("12345 abcdefghijklmnopqrstuvwyxzABCDEFGHIJKLMNOPQRSTUVWXYZ 12345")
86 |     print(chop_cells("abcdefghijklmnopqrstuvwxyz", 10))
87 | 
88 |     console = Console(width=20)
89 |     console.rule()
90 |     console.print("TextualPython")
91 | 
92 |     console.rule()
93 |     console.print("1670")
```

.venv/lib/python3.13/site-packages/pip/_vendor/rich/abc.py
```
1 | from abc import ABC
2 | 
3 | 
4 | class RichRenderable(ABC):
5 |     """An abstract base class for Rich renderables.
6 | 
7 |     Note that there is no need to extend this class, the intended use is to check if an
8 |     object supports the Rich renderable protocol. For example::
9 | 
10 |         if isinstance(my_object, RichRenderable):
11 |             console.print(my_object)
12 | 
13 |     """
14 | 
15 |     @classmethod
16 |     def __subclasshook__(cls, other: type) -> bool:
17 |         """Check if this class supports the rich render protocol."""
18 |         return hasattr(other, "__rich_console__") or hasattr(other, "__rich__")
19 | 
20 | 
21 | if __name__ == "__main__":  # pragma: no cover
22 |     from pip._vendor.rich.text import Text
23 | 
24 |     t = Text()
25 |     print(isinstance(Text, RichRenderable))
26 |     print(isinstance(t, RichRenderable))
27 | 
28 |     class Foo:
29 |         pass
30 | 
31 |     f = Foo()
32 |     print(isinstance(f, RichRenderable))
33 |     print(isinstance("", RichRenderable))
```

.venv/lib/python3.13/site-packages/pip/_vendor/rich/align.py
```
1 | import sys
2 | from itertools import chain
3 | from typing import TYPE_CHECKING, Iterable, Optional
4 | 
5 | if sys.version_info >= (3, 8):
6 |     from typing import Literal
7 | else:
8 |     from pip._vendor.typing_extensions import Literal  # pragma: no cover
9 | 
10 | from .constrain import Constrain
11 | from .jupyter import JupyterMixin
12 | from .measure import Measurement
13 | from .segment import Segment
14 | from .style import StyleType
15 | 
16 | if TYPE_CHECKING:
17 |     from .console import Console, ConsoleOptions, RenderableType, RenderResult
18 | 
19 | AlignMethod = Literal["left", "center", "right"]
20 | VerticalAlignMethod = Literal["top", "middle", "bottom"]
21 | 
22 | 
23 | class Align(JupyterMixin):
24 |     """Align a renderable by adding spaces if necessary.
25 | 
26 |     Args:
27 |         renderable (RenderableType): A console renderable.
28 |         align (AlignMethod): One of "left", "center", or "right""
29 |         style (StyleType, optional): An optional style to apply to the background.
30 |         vertical (Optional[VerticalAlignMethod], optional): Optional vertical align, one of "top", "middle", or "bottom". Defaults to None.
31 |         pad (bool, optional): Pad the right with spaces. Defaults to True.
32 |         width (int, optional): Restrict contents to given width, or None to use default width. Defaults to None.
33 |         height (int, optional): Set height of align renderable, or None to fit to contents. Defaults to None.
34 | 
35 |     Raises:
36 |         ValueError: if ``align`` is not one of the expected values.
37 |     """
38 | 
39 |     def __init__(
40 |         self,
41 |         renderable: "RenderableType",
42 |         align: AlignMethod = "left",
43 |         style: Optional[StyleType] = None,
44 |         *,
45 |         vertical: Optional[VerticalAlignMethod] = None,
46 |         pad: bool = True,
47 |         width: Optional[int] = None,
48 |         height: Optional[int] = None,
49 |     ) -> None:
50 |         if align not in ("left", "center", "right"):
51 |             raise ValueError(
52 |                 f'invalid value for align, expected "left", "center", or "right" (not {align!r})'
53 |             )
54 |         if vertical is not None and vertical not in ("top", "middle", "bottom"):
55 |             raise ValueError(
56 |                 f'invalid value for vertical, expected "top", "middle", or "bottom" (not {vertical!r})'
57 |             )
58 |         self.renderable = renderable
59 |         self.align = align
60 |         self.style = style
61 |         self.vertical = vertical
62 |         self.pad = pad
63 |         self.width = width
64 |         self.height = height
65 | 
66 |     def __repr__(self) -> str:
67 |         return f"Align({self.renderable!r}, {self.align!r})"
68 | 
69 |     @classmethod
70 |     def left(
71 |         cls,
72 |         renderable: "RenderableType",
73 |         style: Optional[StyleType] = None,
74 |         *,
75 |         vertical: Optional[VerticalAlignMethod] = None,
76 |         pad: bool = True,
77 |         width: Optional[int] = None,
78 |         height: Optional[int] = None,
79 |     ) -> "Align":
80 |         """Align a renderable to the left."""
81 |         return cls(
82 |             renderable,
83 |             "left",
84 |             style=style,
85 |             vertical=vertical,
86 |             pad=pad,
87 |             width=width,
88 |             height=height,
89 |         )
90 | 
91 |     @classmethod
92 |     def center(
93 |         cls,
94 |         renderable: "RenderableType",
95 |         style: Optional[StyleType] = None,
96 |         *,
97 |         vertical: Optional[VerticalAlignMethod] = None,
98 |         pad: bool = True,
99 |         width: Optional[int] = None,
100 |         height: Optional[int] = None,
101 |     ) -> "Align":
102 |         """Align a renderable to the center."""
103 |         return cls(
104 |             renderable,
105 |             "center",
106 |             style=style,
107 |             vertical=vertical,
108 |             pad=pad,
109 |             width=width,
110 |             height=height,
111 |         )
112 | 
113 |     @classmethod
114 |     def right(
115 |         cls,
116 |         renderable: "RenderableType",
117 |         style: Optional[StyleType] = None,
118 |         *,
119 |         vertical: Optional[VerticalAlignMethod] = None,
120 |         pad: bool = True,
121 |         width: Optional[int] = None,
122 |         height: Optional[int] = None,
123 |     ) -> "Align":
124 |         """Align a renderable to the right."""
125 |         return cls(
126 |             renderable,
127 |             "right",
128 |             style=style,
129 |             vertical=vertical,
130 |             pad=pad,
131 |             width=width,
132 |             height=height,
133 |         )
134 | 
135 |     def __rich_console__(
136 |         self, console: "Console", options: "ConsoleOptions"
137 |     ) -> "RenderResult":
138 |         align = self.align
139 |         width = console.measure(self.renderable, options=options).maximum
140 |         rendered = console.render(
141 |             Constrain(
142 |                 self.renderable, width if self.width is None else min(width, self.width)
143 |             ),
144 |             options.update(height=None),
145 |         )
146 |         lines = list(Segment.split_lines(rendered))
147 |         width, height = Segment.get_shape(lines)
148 |         lines = Segment.set_shape(lines, width, height)
149 |         new_line = Segment.line()
150 |         excess_space = options.max_width - width
151 |         style = console.get_style(self.style) if self.style is not None else None
152 | 
153 |         def generate_segments() -> Iterable[Segment]:
154 |             if excess_space <= 0:
155 |                 # Exact fit
156 |                 for line in lines:
157 |                     yield from line
158 |                     yield new_line
159 | 
160 |             elif align == "left":
161 |                 # Pad on the right
162 |                 pad = Segment(" " * excess_space, style) if self.pad else None
163 |                 for line in lines:
164 |                     yield from line
165 |                     if pad:
166 |                         yield pad
167 |                     yield new_line
168 | 
169 |             elif align == "center":
170 |                 # Pad left and right
171 |                 left = excess_space // 2
172 |                 pad = Segment(" " * left, style)
173 |                 pad_right = (
174 |                     Segment(" " * (excess_space - left), style) if self.pad else None
175 |                 )
176 |                 for line in lines:
177 |                     if left:
178 |                         yield pad
179 |                     yield from line
180 |                     if pad_right:
181 |                         yield pad_right
182 |                     yield new_line
183 | 
184 |             elif align == "right":
185 |                 # Padding on left
186 |                 pad = Segment(" " * excess_space, style)
187 |                 for line in lines:
188 |                     yield pad
189 |                     yield from line
190 |                     yield new_line
191 | 
192 |         blank_line = (
193 |             Segment(f"{' ' * (self.width or options.max_width)}\n", style)
194 |             if self.pad
195 |             else Segment("\n")
196 |         )
197 | 
198 |         def blank_lines(count: int) -> Iterable[Segment]:
199 |             if count > 0:
200 |                 for _ in range(count):
201 |                     yield blank_line
202 | 
203 |         vertical_height = self.height or options.height
204 |         iter_segments: Iterable[Segment]
205 |         if self.vertical and vertical_height is not None:
206 |             if self.vertical == "top":
207 |                 bottom_space = vertical_height - height
208 |                 iter_segments = chain(generate_segments(), blank_lines(bottom_space))
209 |             elif self.vertical == "middle":
210 |                 top_space = (vertical_height - height) // 2
211 |                 bottom_space = vertical_height - top_space - height
212 |                 iter_segments = chain(
213 |                     blank_lines(top_space),
214 |                     generate_segments(),
215 |                     blank_lines(bottom_space),
216 |                 )
217 |             else:  #  self.vertical == "bottom":
218 |                 top_space = vertical_height - height
219 |                 iter_segments = chain(blank_lines(top_space), generate_segments())
220 |         else:
221 |             iter_segments = generate_segments()
222 |         if self.style:
223 |             style = console.get_style(self.style)
224 |             iter_segments = Segment.apply_style(iter_segments, style)
225 |         yield from iter_segments
226 | 
227 |     def __rich_measure__(
228 |         self, console: "Console", options: "ConsoleOptions"
229 |     ) -> Measurement:
230 |         measurement = Measurement.get(console, options, self.renderable)
231 |         return measurement
232 | 
233 | 
234 | class VerticalCenter(JupyterMixin):
235 |     """Vertically aligns a renderable.
236 | 
237 |     Warn:
238 |         This class is deprecated and may be removed in a future version. Use Align class with
239 |         `vertical="middle"`.
240 | 
241 |     Args:
242 |         renderable (RenderableType): A renderable object.
243 |         style (StyleType, optional): An optional style to apply to the background. Defaults to None.
244 |     """
245 | 
246 |     def __init__(
247 |         self,
248 |         renderable: "RenderableType",
249 |         style: Optional[StyleType] = None,
250 |     ) -> None:
251 |         self.renderable = renderable
252 |         self.style = style
253 | 
254 |     def __repr__(self) -> str:
255 |         return f"VerticalCenter({self.renderable!r})"
256 | 
257 |     def __rich_console__(
258 |         self, console: "Console", options: "ConsoleOptions"
259 |     ) -> "RenderResult":
260 |         style = console.get_style(self.style) if self.style is not None else None
261 |         lines = console.render_lines(
262 |             self.renderable, options.update(height=None), pad=False
263 |         )
264 |         width, _height = Segment.get_shape(lines)
265 |         new_line = Segment.line()
266 |         height = options.height or options.size.height
267 |         top_space = (height - len(lines)) // 2
268 |         bottom_space = height - top_space - len(lines)
269 |         blank_line = Segment(f"{' ' * width}", style)
270 | 
271 |         def blank_lines(count: int) -> Iterable[Segment]:
272 |             for _ in range(count):
273 |                 yield blank_line
274 |                 yield new_line
275 | 
276 |         if top_space > 0:
277 |             yield from blank_lines(top_space)
278 |         for line in lines:
279 |             yield from line
280 |             yield new_line
281 |         if bottom_space > 0:
282 |             yield from blank_lines(bottom_space)
283 | 
284 |     def __rich_measure__(
285 |         self, console: "Console", options: "ConsoleOptions"
286 |     ) -> Measurement:
287 |         measurement = Measurement.get(console, options, self.renderable)
288 |         return measurement
289 | 
290 | 
291 | if __name__ == "__main__":  # pragma: no cover
292 |     from pip._vendor.rich.console import Console, Group
293 |     from pip._vendor.rich.highlighter import ReprHighlighter
294 |     from pip._vendor.rich.panel import Panel
295 | 
296 |     highlighter = ReprHighlighter()
297 |     console = Console()
298 | 
299 |     panel = Panel(
300 |         Group(
301 |             Align.left(highlighter("align='left'")),
302 |             Align.center(highlighter("align='center'")),
303 |             Align.right(highlighter("align='right'")),
304 |         ),
305 |         width=60,
306 |         style="on dark_blue",
307 |         title="Align",
308 |     )
309 | 
310 |     console.print(
311 |         Align.center(panel, vertical="middle", style="on red", height=console.height)
312 |     )
```

.venv/lib/python3.13/site-packages/pip/_vendor/rich/ansi.py
```
1 | import re
2 | import sys
3 | from contextlib import suppress
4 | from typing import Iterable, NamedTuple, Optional
5 | 
6 | from .color import Color
7 | from .style import Style
8 | from .text import Text
9 | 
10 | re_ansi = re.compile(
11 |     r"""
12 | (?:\x1b[0-?])|
13 | (?:\x1b\](.*?)\x1b\\)|
14 | (?:\x1b([(@-Z\\-_]|\[[0-?]*[ -/]*[@-~]))
15 | """,
16 |     re.VERBOSE,
17 | )
18 | 
19 | 
20 | class _AnsiToken(NamedTuple):
21 |     """Result of ansi tokenized string."""
22 | 
23 |     plain: str = ""
24 |     sgr: Optional[str] = ""
25 |     osc: Optional[str] = ""
26 | 
27 | 
28 | def _ansi_tokenize(ansi_text: str) -> Iterable[_AnsiToken]:
29 |     """Tokenize a string in to plain text and ANSI codes.
30 | 
31 |     Args:
32 |         ansi_text (str): A String containing ANSI codes.
33 | 
34 |     Yields:
35 |         AnsiToken: A named tuple of (plain, sgr, osc)
36 |     """
37 | 
38 |     position = 0
39 |     sgr: Optional[str]
40 |     osc: Optional[str]
41 |     for match in re_ansi.finditer(ansi_text):
42 |         start, end = match.span(0)
43 |         osc, sgr = match.groups()
44 |         if start > position:
45 |             yield _AnsiToken(ansi_text[position:start])
46 |         if sgr:
47 |             if sgr == "(":
48 |                 position = end + 1
49 |                 continue
50 |             if sgr.endswith("m"):
51 |                 yield _AnsiToken("", sgr[1:-1], osc)
52 |         else:
53 |             yield _AnsiToken("", sgr, osc)
54 |         position = end
55 |     if position < len(ansi_text):
56 |         yield _AnsiToken(ansi_text[position:])
57 | 
58 | 
59 | SGR_STYLE_MAP = {
60 |     1: "bold",
61 |     2: "dim",
62 |     3: "italic",
63 |     4: "underline",
64 |     5: "blink",
65 |     6: "blink2",
66 |     7: "reverse",
67 |     8: "conceal",
68 |     9: "strike",
69 |     21: "underline2",
70 |     22: "not dim not bold",
71 |     23: "not italic",
72 |     24: "not underline",
73 |     25: "not blink",
74 |     26: "not blink2",
75 |     27: "not reverse",
76 |     28: "not conceal",
77 |     29: "not strike",
78 |     30: "color(0)",
79 |     31: "color(1)",
80 |     32: "color(2)",
81 |     33: "color(3)",
82 |     34: "color(4)",
83 |     35: "color(5)",
84 |     36: "color(6)",
85 |     37: "color(7)",
86 |     39: "default",
87 |     40: "on color(0)",
88 |     41: "on color(1)",
89 |     42: "on color(2)",
90 |     43: "on color(3)",
91 |     44: "on color(4)",
92 |     45: "on color(5)",
93 |     46: "on color(6)",
94 |     47: "on color(7)",
95 |     49: "on default",
96 |     51: "frame",
97 |     52: "encircle",
98 |     53: "overline",
99 |     54: "not frame not encircle",
100 |     55: "not overline",
101 |     90: "color(8)",
102 |     91: "color(9)",
103 |     92: "color(10)",
104 |     93: "color(11)",
105 |     94: "color(12)",
106 |     95: "color(13)",
107 |     96: "color(14)",
108 |     97: "color(15)",
109 |     100: "on color(8)",
110 |     101: "on color(9)",
111 |     102: "on color(10)",
112 |     103: "on color(11)",
113 |     104: "on color(12)",
114 |     105: "on color(13)",
115 |     106: "on color(14)",
116 |     107: "on color(15)",
117 | }
118 | 
119 | 
120 | class AnsiDecoder:
121 |     """Translate ANSI code in to styled Text."""
122 | 
123 |     def __init__(self) -> None:
124 |         self.style = Style.null()
125 | 
126 |     def decode(self, terminal_text: str) -> Iterable[Text]:
127 |         """Decode ANSI codes in an iterable of lines.
128 | 
129 |         Args:
130 |             lines (Iterable[str]): An iterable of lines of terminal output.
131 | 
132 |         Yields:
133 |             Text: Marked up Text.
134 |         """
135 |         for line in terminal_text.splitlines():
136 |             yield self.decode_line(line)
137 | 
138 |     def decode_line(self, line: str) -> Text:
139 |         """Decode a line containing ansi codes.
140 | 
141 |         Args:
142 |             line (str): A line of terminal output.
143 | 
144 |         Returns:
145 |             Text: A Text instance marked up according to ansi codes.
146 |         """
147 |         from_ansi = Color.from_ansi
148 |         from_rgb = Color.from_rgb
149 |         _Style = Style
150 |         text = Text()
151 |         append = text.append
152 |         line = line.rsplit("\r", 1)[-1]
153 |         for plain_text, sgr, osc in _ansi_tokenize(line):
154 |             if plain_text:
155 |                 append(plain_text, self.style or None)
156 |             elif osc is not None:
157 |                 if osc.startswith("8;"):
158 |                     _params, semicolon, link = osc[2:].partition(";")
159 |                     if semicolon:
160 |                         self.style = self.style.update_link(link or None)
161 |             elif sgr is not None:
162 |                 # Translate in to semi-colon separated codes
163 |                 # Ignore invalid codes, because we want to be lenient
164 |                 codes = [
165 |                     min(255, int(_code) if _code else 0)
166 |                     for _code in sgr.split(";")
167 |                     if _code.isdigit() or _code == ""
168 |                 ]
169 |                 iter_codes = iter(codes)
170 |                 for code in iter_codes:
171 |                     if code == 0:
172 |                         # reset
173 |                         self.style = _Style.null()
174 |                     elif code in SGR_STYLE_MAP:
175 |                         # styles
176 |                         self.style += _Style.parse(SGR_STYLE_MAP[code])
177 |                     elif code == 38:
178 |                         # Foreground
179 |                         with suppress(StopIteration):
180 |                             color_type = next(iter_codes)
181 |                             if color_type == 5:
182 |                                 self.style += _Style.from_color(
183 |                                     from_ansi(next(iter_codes))
184 |                                 )
185 |                             elif color_type == 2:
186 |                                 self.style += _Style.from_color(
187 |                                     from_rgb(
188 |                                         next(iter_codes),
189 |                                         next(iter_codes),
190 |                                         next(iter_codes),
191 |                                     )
192 |                                 )
193 |                     elif code == 48:
194 |                         # Background
195 |                         with suppress(StopIteration):
196 |                             color_type = next(iter_codes)
197 |                             if color_type == 5:
198 |                                 self.style += _Style.from_color(
199 |                                     None, from_ansi(next(iter_codes))
200 |                                 )
201 |                             elif color_type == 2:
202 |                                 self.style += _Style.from_color(
203 |                                     None,
204 |                                     from_rgb(
205 |                                         next(iter_codes),
206 |                                         next(iter_codes),
207 |                                         next(iter_codes),
208 |                                     ),
209 |                                 )
210 | 
211 |         return text
212 | 
213 | 
214 | if sys.platform != "win32" and __name__ == "__main__":  # pragma: no cover
215 |     import io
216 |     import os
217 |     import pty
218 |     import sys
219 | 
220 |     decoder = AnsiDecoder()
221 | 
222 |     stdout = io.BytesIO()
223 | 
224 |     def read(fd: int) -> bytes:
225 |         data = os.read(fd, 1024)
226 |         stdout.write(data)
227 |         return data
228 | 
229 |     pty.spawn(sys.argv[1:], read)
230 | 
231 |     from .console import Console
232 | 
233 |     console = Console(record=True)
234 | 
235 |     stdout_result = stdout.getvalue().decode("utf-8")
236 |     print(stdout_result)
237 | 
238 |     for line in decoder.decode(stdout_result):
239 |         console.print(line)
240 | 
241 |     console.save_html("stdout.html")
```

.venv/lib/python3.13/site-packages/pip/_vendor/rich/bar.py
```
1 | from typing import Optional, Union
2 | 
3 | from .color import Color
4 | from .console import Console, ConsoleOptions, RenderResult
5 | from .jupyter import JupyterMixin
6 | from .measure import Measurement
7 | from .segment import Segment
8 | from .style import Style
9 | 
10 | # There are left-aligned characters for 1/8 to 7/8, but
11 | # the right-aligned characters exist only for 1/8 and 4/8.
12 | BEGIN_BLOCK_ELEMENTS = ["", "", "", "", "", "", "", ""]
13 | END_BLOCK_ELEMENTS = [" ", "", "", "", "", "", "", ""]
14 | FULL_BLOCK = ""
15 | 
16 | 
17 | class Bar(JupyterMixin):
18 |     """Renders a solid block bar.
19 | 
20 |     Args:
21 |         size (float): Value for the end of the bar.
22 |         begin (float): Begin point (between 0 and size, inclusive).
23 |         end (float): End point (between 0 and size, inclusive).
24 |         width (int, optional): Width of the bar, or ``None`` for maximum width. Defaults to None.
25 |         color (Union[Color, str], optional): Color of the bar. Defaults to "default".
26 |         bgcolor (Union[Color, str], optional): Color of bar background. Defaults to "default".
27 |     """
28 | 
29 |     def __init__(
30 |         self,
31 |         size: float,
32 |         begin: float,
33 |         end: float,
34 |         *,
35 |         width: Optional[int] = None,
36 |         color: Union[Color, str] = "default",
37 |         bgcolor: Union[Color, str] = "default",
38 |     ):
39 |         self.size = size
40 |         self.begin = max(begin, 0)
41 |         self.end = min(end, size)
42 |         self.width = width
43 |         self.style = Style(color=color, bgcolor=bgcolor)
44 | 
45 |     def __repr__(self) -> str:
46 |         return f"Bar({self.size}, {self.begin}, {self.end})"
47 | 
48 |     def __rich_console__(
49 |         self, console: Console, options: ConsoleOptions
50 |     ) -> RenderResult:
51 |         width = min(
52 |             self.width if self.width is not None else options.max_width,
53 |             options.max_width,
54 |         )
55 | 
56 |         if self.begin >= self.end:
57 |             yield Segment(" " * width, self.style)
58 |             yield Segment.line()
59 |             return
60 | 
61 |         prefix_complete_eights = int(width * 8 * self.begin / self.size)
62 |         prefix_bar_count = prefix_complete_eights // 8
63 |         prefix_eights_count = prefix_complete_eights % 8
64 | 
65 |         body_complete_eights = int(width * 8 * self.end / self.size)
66 |         body_bar_count = body_complete_eights // 8
67 |         body_eights_count = body_complete_eights % 8
68 | 
69 |         # When start and end fall into the same cell, we ideally should render
70 |         # a symbol that's "center-aligned", but there is no good symbol in Unicode.
71 |         # In this case, we fall back to right-aligned block symbol for simplicity.
72 | 
73 |         prefix = " " * prefix_bar_count
74 |         if prefix_eights_count:
75 |             prefix += BEGIN_BLOCK_ELEMENTS[prefix_eights_count]
76 | 
77 |         body = FULL_BLOCK * body_bar_count
78 |         if body_eights_count:
79 |             body += END_BLOCK_ELEMENTS[body_eights_count]
80 | 
81 |         suffix = " " * (width - len(body))
82 | 
83 |         yield Segment(prefix + body[len(prefix) :] + suffix, self.style)
84 |         yield Segment.line()
85 | 
86 |     def __rich_measure__(
87 |         self, console: Console, options: ConsoleOptions
88 |     ) -> Measurement:
89 |         return (
90 |             Measurement(self.width, self.width)
91 |             if self.width is not None
92 |             else Measurement(4, options.max_width)
93 |         )
```

.venv/lib/python3.13/site-packages/pip/_vendor/rich/box.py
```
1 | import sys
2 | from typing import TYPE_CHECKING, Iterable, List
3 | 
4 | if sys.version_info >= (3, 8):
5 |     from typing import Literal
6 | else:
7 |     from pip._vendor.typing_extensions import Literal  # pragma: no cover
8 | 
9 | 
10 | from ._loop import loop_last
11 | 
12 | if TYPE_CHECKING:
13 |     from pip._vendor.rich.console import ConsoleOptions
14 | 
15 | 
16 | class Box:
17 |     """Defines characters to render boxes.
18 | 
19 |      top
20 |       head
21 |      head_row
22 |       mid
23 |      row
24 |      foot_row
25 |       foot
26 |      bottom
27 | 
28 |     Args:
29 |         box (str): Characters making up box.
30 |         ascii (bool, optional): True if this box uses ascii characters only. Default is False.
31 |     """
32 | 
33 |     def __init__(self, box: str, *, ascii: bool = False) -> None:
34 |         self._box = box
35 |         self.ascii = ascii
36 |         line1, line2, line3, line4, line5, line6, line7, line8 = box.splitlines()
37 |         # top
38 |         self.top_left, self.top, self.top_divider, self.top_right = iter(line1)
39 |         # head
40 |         self.head_left, _, self.head_vertical, self.head_right = iter(line2)
41 |         # head_row
42 |         (
43 |             self.head_row_left,
44 |             self.head_row_horizontal,
45 |             self.head_row_cross,
46 |             self.head_row_right,
47 |         ) = iter(line3)
48 | 
49 |         # mid
50 |         self.mid_left, _, self.mid_vertical, self.mid_right = iter(line4)
51 |         # row
52 |         self.row_left, self.row_horizontal, self.row_cross, self.row_right = iter(line5)
53 |         # foot_row
54 |         (
55 |             self.foot_row_left,
56 |             self.foot_row_horizontal,
57 |             self.foot_row_cross,
58 |             self.foot_row_right,
59 |         ) = iter(line6)
60 |         # foot
61 |         self.foot_left, _, self.foot_vertical, self.foot_right = iter(line7)
62 |         # bottom
63 |         self.bottom_left, self.bottom, self.bottom_divider, self.bottom_right = iter(
64 |             line8
65 |         )
66 | 
67 |     def __repr__(self) -> str:
68 |         return "Box(...)"
69 | 
70 |     def __str__(self) -> str:
71 |         return self._box
72 | 
73 |     def substitute(self, options: "ConsoleOptions", safe: bool = True) -> "Box":
74 |         """Substitute this box for another if it won't render due to platform issues.
75 | 
76 |         Args:
77 |             options (ConsoleOptions): Console options used in rendering.
78 |             safe (bool, optional): Substitute this for another Box if there are known problems
79 |                 displaying on the platform (currently only relevant on Windows). Default is True.
80 | 
81 |         Returns:
82 |             Box: A different Box or the same Box.
83 |         """
84 |         box = self
85 |         if options.legacy_windows and safe:
86 |             box = LEGACY_WINDOWS_SUBSTITUTIONS.get(box, box)
87 |         if options.ascii_only and not box.ascii:
88 |             box = ASCII
89 |         return box
90 | 
91 |     def get_plain_headed_box(self) -> "Box":
92 |         """If this box uses special characters for the borders of the header, then
93 |         return the equivalent box that does not.
94 | 
95 |         Returns:
96 |             Box: The most similar Box that doesn't use header-specific box characters.
97 |                 If the current Box already satisfies this criterion, then it's returned.
98 |         """
99 |         return PLAIN_HEADED_SUBSTITUTIONS.get(self, self)
100 | 
101 |     def get_top(self, widths: Iterable[int]) -> str:
102 |         """Get the top of a simple box.
103 | 
104 |         Args:
105 |             widths (List[int]): Widths of columns.
106 | 
107 |         Returns:
108 |             str: A string of box characters.
109 |         """
110 | 
111 |         parts: List[str] = []
112 |         append = parts.append
113 |         append(self.top_left)
114 |         for last, width in loop_last(widths):
115 |             append(self.top * width)
116 |             if not last:
117 |                 append(self.top_divider)
118 |         append(self.top_right)
119 |         return "".join(parts)
120 | 
121 |     def get_row(
122 |         self,
123 |         widths: Iterable[int],
124 |         level: Literal["head", "row", "foot", "mid"] = "row",
125 |         edge: bool = True,
126 |     ) -> str:
127 |         """Get the top of a simple box.
128 | 
129 |         Args:
130 |             width (List[int]): Widths of columns.
131 | 
132 |         Returns:
133 |             str: A string of box characters.
134 |         """
135 |         if level == "head":
136 |             left = self.head_row_left
137 |             horizontal = self.head_row_horizontal
138 |             cross = self.head_row_cross
139 |             right = self.head_row_right
140 |         elif level == "row":
141 |             left = self.row_left
142 |             horizontal = self.row_horizontal
143 |             cross = self.row_cross
144 |             right = self.row_right
145 |         elif level == "mid":
146 |             left = self.mid_left
147 |             horizontal = " "
148 |             cross = self.mid_vertical
149 |             right = self.mid_right
150 |         elif level == "foot":
151 |             left = self.foot_row_left
152 |             horizontal = self.foot_row_horizontal
153 |             cross = self.foot_row_cross
154 |             right = self.foot_row_right
155 |         else:
156 |             raise ValueError("level must be 'head', 'row' or 'foot'")
157 | 
158 |         parts: List[str] = []
159 |         append = parts.append
160 |         if edge:
161 |             append(left)
162 |         for last, width in loop_last(widths):
163 |             append(horizontal * width)
164 |             if not last:
165 |                 append(cross)
166 |         if edge:
167 |             append(right)
168 |         return "".join(parts)
169 | 
170 |     def get_bottom(self, widths: Iterable[int]) -> str:
171 |         """Get the bottom of a simple box.
172 | 
173 |         Args:
174 |             widths (List[int]): Widths of columns.
175 | 
176 |         Returns:
177 |             str: A string of box characters.
178 |         """
179 | 
180 |         parts: List[str] = []
181 |         append = parts.append
182 |         append(self.bottom_left)
183 |         for last, width in loop_last(widths):
184 |             append(self.bottom * width)
185 |             if not last:
186 |                 append(self.bottom_divider)
187 |         append(self.bottom_right)
188 |         return "".join(parts)
189 | 
190 | 
191 | # fmt: off
192 | ASCII: Box = Box(
193 |     "+--+\n"
194 |     "| ||\n"
195 |     "|-+|\n"
196 |     "| ||\n"
197 |     "|-+|\n"
198 |     "|-+|\n"
199 |     "| ||\n"
200 |     "+--+\n",
201 |     ascii=True,
202 | )
203 | 
204 | ASCII2: Box = Box(
205 |     "+-++\n"
206 |     "| ||\n"
207 |     "+-++\n"
208 |     "| ||\n"
209 |     "+-++\n"
210 |     "+-++\n"
211 |     "| ||\n"
212 |     "+-++\n",
213 |     ascii=True,
214 | )
215 | 
216 | ASCII_DOUBLE_HEAD: Box = Box(
217 |     "+-++\n"
218 |     "| ||\n"
219 |     "+=++\n"
220 |     "| ||\n"
221 |     "+-++\n"
222 |     "+-++\n"
223 |     "| ||\n"
224 |     "+-++\n",
225 |     ascii=True,
226 | )
227 | 
228 | SQUARE: Box = Box(
229 |     "\n"
230 |     " \n"
231 |     "\n"
232 |     " \n"
233 |     "\n"
234 |     "\n"
235 |     " \n"
236 |     "\n"
237 | )
238 | 
239 | SQUARE_DOUBLE_HEAD: Box = Box(
240 |     "\n"
241 |     " \n"
242 |     "\n"
243 |     " \n"
244 |     "\n"
245 |     "\n"
246 |     " \n"
247 |     "\n"
248 | )
249 | 
250 | MINIMAL: Box = Box(
251 |     "   \n"
252 |     "   \n"
253 |     "\n"
254 |     "   \n"
255 |     "\n"
256 |     "\n"
257 |     "   \n"
258 |     "   \n"
259 | )
260 | 
261 | 
262 | MINIMAL_HEAVY_HEAD: Box = Box(
263 |     "   \n"
264 |     "   \n"
265 |     "\n"
266 |     "   \n"
267 |     "\n"
268 |     "\n"
269 |     "   \n"
270 |     "   \n"
271 | )
272 | 
273 | MINIMAL_DOUBLE_HEAD: Box = Box(
274 |     "   \n"
275 |     "   \n"
276 |     "  \n"
277 |     "   \n"
278 |     "  \n"
279 |     "  \n"
280 |     "   \n"
281 |     "   \n"
282 | )
283 | 
284 | 
285 | SIMPLE: Box = Box(
286 |     "    \n"
287 |     "    \n"
288 |     "  \n"
289 |     "    \n"
290 |     "    \n"
291 |     "  \n"
292 |     "    \n"
293 |     "    \n"
294 | )
295 | 
296 | SIMPLE_HEAD: Box = Box(
297 |     "    \n"
298 |     "    \n"
299 |     "  \n"
300 |     "    \n"
301 |     "    \n"
302 |     "    \n"
303 |     "    \n"
304 |     "    \n"
305 | )
306 | 
307 | 
308 | SIMPLE_HEAVY: Box = Box(
309 |     "    \n"
310 |     "    \n"
311 |     "  \n"
312 |     "    \n"
313 |     "    \n"
314 |     "  \n"
315 |     "    \n"
316 |     "    \n"
317 | )
318 | 
319 | 
320 | HORIZONTALS: Box = Box(
321 |     "  \n"
322 |     "    \n"
323 |     "  \n"
324 |     "    \n"
325 |     "  \n"
326 |     "  \n"
327 |     "    \n"
328 |     "  \n"
329 | )
330 | 
331 | ROUNDED: Box = Box(
332 |     "\n"
333 |     " \n"
334 |     "\n"
335 |     " \n"
336 |     "\n"
337 |     "\n"
338 |     " \n"
339 |     "\n"
340 | )
341 | 
342 | HEAVY: Box = Box(
343 |     "\n"
344 |     " \n"
345 |     "\n"
346 |     " \n"
347 |     "\n"
348 |     "\n"
349 |     " \n"
350 |     "\n"
351 | )
352 | 
353 | HEAVY_EDGE: Box = Box(
354 |     "\n"
355 |     " \n"
356 |     "\n"
357 |     " \n"
358 |     "\n"
359 |     "\n"
360 |     " \n"
361 |     "\n"
362 | )
363 | 
364 | HEAVY_HEAD: Box = Box(
365 |     "\n"
366 |     " \n"
367 |     "\n"
368 |     " \n"
369 |     "\n"
370 |     "\n"
371 |     " \n"
372 |     "\n"
373 | )
374 | 
375 | DOUBLE: Box = Box(
376 |     "\n"
377 |     " \n"
378 |     "\n"
379 |     " \n"
380 |     "\n"
381 |     "\n"
382 |     " \n"
383 |     "\n"
384 | )
385 | 
386 | DOUBLE_EDGE: Box = Box(
387 |     "\n"
388 |     " \n"
389 |     "\n"
390 |     " \n"
391 |     "\n"
392 |     "\n"
393 |     " \n"
394 |     "\n"
395 | )
396 | 
397 | MARKDOWN: Box = Box(
398 |     "    \n"
399 |     "| ||\n"
400 |     "|-||\n"
401 |     "| ||\n"
402 |     "|-||\n"
403 |     "|-||\n"
404 |     "| ||\n"
405 |     "    \n",
406 |     ascii=True,
407 | )
408 | # fmt: on
409 | 
410 | # Map Boxes that don't render with raster fonts on to equivalent that do
411 | LEGACY_WINDOWS_SUBSTITUTIONS = {
412 |     ROUNDED: SQUARE,
413 |     MINIMAL_HEAVY_HEAD: MINIMAL,
414 |     SIMPLE_HEAVY: SIMPLE,
415 |     HEAVY: SQUARE,
416 |     HEAVY_EDGE: SQUARE,
417 |     HEAVY_HEAD: SQUARE,
418 | }
419 | 
420 | # Map headed boxes to their headerless equivalents
421 | PLAIN_HEADED_SUBSTITUTIONS = {
422 |     HEAVY_HEAD: SQUARE,
423 |     SQUARE_DOUBLE_HEAD: SQUARE,
424 |     MINIMAL_DOUBLE_HEAD: MINIMAL,
425 |     MINIMAL_HEAVY_HEAD: MINIMAL,
426 |     ASCII_DOUBLE_HEAD: ASCII2,
427 | }
428 | 
429 | 
430 | if __name__ == "__main__":  # pragma: no cover
431 |     from pip._vendor.rich.columns import Columns
432 |     from pip._vendor.rich.panel import Panel
433 | 
434 |     from . import box as box
435 |     from .console import Console
436 |     from .table import Table
437 |     from .text import Text
438 | 
439 |     console = Console(record=True)
440 | 
441 |     BOXES = [
442 |         "ASCII",
443 |         "ASCII2",
444 |         "ASCII_DOUBLE_HEAD",
445 |         "SQUARE",
446 |         "SQUARE_DOUBLE_HEAD",
447 |         "MINIMAL",
448 |         "MINIMAL_HEAVY_HEAD",
449 |         "MINIMAL_DOUBLE_HEAD",
450 |         "SIMPLE",
451 |         "SIMPLE_HEAD",
452 |         "SIMPLE_HEAVY",
453 |         "HORIZONTALS",
454 |         "ROUNDED",
455 |         "HEAVY",
456 |         "HEAVY_EDGE",
457 |         "HEAVY_HEAD",
458 |         "DOUBLE",
459 |         "DOUBLE_EDGE",
460 |         "MARKDOWN",
461 |     ]
462 | 
[TRUNCATED]
```

.venv/lib/python3.13/site-packages/pip/_vendor/rich/cells.py
```
1 | from __future__ import annotations
2 | 
3 | from functools import lru_cache
4 | from typing import Callable
5 | 
6 | from ._cell_widths import CELL_WIDTHS
7 | 
8 | # Ranges of unicode ordinals that produce a 1-cell wide character
9 | # This is non-exhaustive, but covers most common Western characters
10 | _SINGLE_CELL_UNICODE_RANGES: list[tuple[int, int]] = [
11 |     (0x20, 0x7E),  # Latin (excluding non-printable)
12 |     (0xA0, 0xAC),
13 |     (0xAE, 0x002FF),
14 |     (0x00370, 0x00482),  # Greek / Cyrillic
15 |     (0x02500, 0x025FC),  # Box drawing, box elements, geometric shapes
16 |     (0x02800, 0x028FF),  # Braille
17 | ]
18 | 
19 | # A set of characters that are a single cell wide
20 | _SINGLE_CELLS = frozenset(
21 |     [
22 |         character
23 |         for _start, _end in _SINGLE_CELL_UNICODE_RANGES
24 |         for character in map(chr, range(_start, _end + 1))
25 |     ]
26 | )
27 | 
28 | # When called with a string this will return True if all
29 | # characters are single-cell, otherwise False
30 | _is_single_cell_widths: Callable[[str], bool] = _SINGLE_CELLS.issuperset
31 | 
32 | 
33 | @lru_cache(4096)
34 | def cached_cell_len(text: str) -> int:
35 |     """Get the number of cells required to display text.
36 | 
37 |     This method always caches, which may use up a lot of memory. It is recommended to use
38 |     `cell_len` over this method.
39 | 
40 |     Args:
41 |         text (str): Text to display.
42 | 
43 |     Returns:
44 |         int: Get the number of cells required to display text.
45 |     """
46 |     if _is_single_cell_widths(text):
47 |         return len(text)
48 |     return sum(map(get_character_cell_size, text))
49 | 
50 | 
51 | def cell_len(text: str, _cell_len: Callable[[str], int] = cached_cell_len) -> int:
52 |     """Get the number of cells required to display text.
53 | 
54 |     Args:
55 |         text (str): Text to display.
56 | 
57 |     Returns:
58 |         int: Get the number of cells required to display text.
59 |     """
60 |     if len(text) < 512:
61 |         return _cell_len(text)
62 |     if _is_single_cell_widths(text):
63 |         return len(text)
64 |     return sum(map(get_character_cell_size, text))
65 | 
66 | 
67 | @lru_cache(maxsize=4096)
68 | def get_character_cell_size(character: str) -> int:
69 |     """Get the cell size of a character.
70 | 
71 |     Args:
72 |         character (str): A single character.
73 | 
74 |     Returns:
75 |         int: Number of cells (0, 1 or 2) occupied by that character.
76 |     """
77 |     codepoint = ord(character)
78 |     _table = CELL_WIDTHS
79 |     lower_bound = 0
80 |     upper_bound = len(_table) - 1
81 |     index = (lower_bound + upper_bound) // 2
82 |     while True:
83 |         start, end, width = _table[index]
84 |         if codepoint < start:
85 |             upper_bound = index - 1
86 |         elif codepoint > end:
87 |             lower_bound = index + 1
88 |         else:
89 |             return 0 if width == -1 else width
90 |         if upper_bound < lower_bound:
91 |             break
92 |         index = (lower_bound + upper_bound) // 2
93 |     return 1
94 | 
95 | 
96 | def set_cell_size(text: str, total: int) -> str:
97 |     """Set the length of a string to fit within given number of cells."""
98 | 
99 |     if _is_single_cell_widths(text):
100 |         size = len(text)
101 |         if size < total:
102 |             return text + " " * (total - size)
103 |         return text[:total]
104 | 
105 |     if total <= 0:
106 |         return ""
107 |     cell_size = cell_len(text)
108 |     if cell_size == total:
109 |         return text
110 |     if cell_size < total:
111 |         return text + " " * (total - cell_size)
112 | 
113 |     start = 0
114 |     end = len(text)
115 | 
116 |     # Binary search until we find the right size
117 |     while True:
118 |         pos = (start + end) // 2
119 |         before = text[: pos + 1]
120 |         before_len = cell_len(before)
121 |         if before_len == total + 1 and cell_len(before[-1]) == 2:
122 |             return before[:-1] + " "
123 |         if before_len == total:
124 |             return before
125 |         if before_len > total:
126 |             end = pos
127 |         else:
128 |             start = pos
129 | 
130 | 
131 | def chop_cells(
132 |     text: str,
133 |     width: int,
134 | ) -> list[str]:
135 |     """Split text into lines such that each line fits within the available (cell) width.
136 | 
137 |     Args:
138 |         text: The text to fold such that it fits in the given width.
139 |         width: The width available (number of cells).
140 | 
141 |     Returns:
142 |         A list of strings such that each string in the list has cell width
143 |         less than or equal to the available width.
144 |     """
145 |     _get_character_cell_size = get_character_cell_size
146 |     lines: list[list[str]] = [[]]
147 | 
148 |     append_new_line = lines.append
149 |     append_to_last_line = lines[-1].append
150 | 
151 |     total_width = 0
152 | 
153 |     for character in text:
154 |         cell_width = _get_character_cell_size(character)
155 |         char_doesnt_fit = total_width + cell_width > width
156 | 
157 |         if char_doesnt_fit:
158 |             append_new_line([character])
159 |             append_to_last_line = lines[-1].append
160 |             total_width = cell_width
161 |         else:
162 |             append_to_last_line(character)
163 |             total_width += cell_width
164 | 
165 |     return ["".join(line) for line in lines]
166 | 
167 | 
168 | if __name__ == "__main__":  # pragma: no cover
169 |     print(get_character_cell_size(""))
170 |     for line in chop_cells("""""", 8):
171 |         print(line)
172 |     for n in range(80, 1, -1):
173 |         print(set_cell_size("""""", n) + "|")
174 |         print("x" * n)
```

.venv/lib/python3.13/site-packages/pip/_vendor/rich/color.py
```
1 | import re
2 | import sys
3 | from colorsys import rgb_to_hls
4 | from enum import IntEnum
5 | from functools import lru_cache
6 | from typing import TYPE_CHECKING, NamedTuple, Optional, Tuple
7 | 
8 | from ._palettes import EIGHT_BIT_PALETTE, STANDARD_PALETTE, WINDOWS_PALETTE
9 | from .color_triplet import ColorTriplet
10 | from .repr import Result, rich_repr
11 | from .terminal_theme import DEFAULT_TERMINAL_THEME
12 | 
13 | if TYPE_CHECKING:  # pragma: no cover
14 |     from .terminal_theme import TerminalTheme
15 |     from .text import Text
16 | 
17 | 
18 | WINDOWS = sys.platform == "win32"
19 | 
20 | 
21 | class ColorSystem(IntEnum):
22 |     """One of the 3 color system supported by terminals."""
23 | 
24 |     STANDARD = 1
25 |     EIGHT_BIT = 2
26 |     TRUECOLOR = 3
27 |     WINDOWS = 4
28 | 
29 |     def __repr__(self) -> str:
30 |         return f"ColorSystem.{self.name}"
31 | 
32 |     def __str__(self) -> str:
33 |         return repr(self)
34 | 
35 | 
36 | class ColorType(IntEnum):
37 |     """Type of color stored in Color class."""
38 | 
39 |     DEFAULT = 0
40 |     STANDARD = 1
41 |     EIGHT_BIT = 2
42 |     TRUECOLOR = 3
43 |     WINDOWS = 4
44 | 
45 |     def __repr__(self) -> str:
46 |         return f"ColorType.{self.name}"
47 | 
48 | 
49 | ANSI_COLOR_NAMES = {
50 |     "black": 0,
51 |     "red": 1,
52 |     "green": 2,
53 |     "yellow": 3,
54 |     "blue": 4,
55 |     "magenta": 5,
56 |     "cyan": 6,
57 |     "white": 7,
58 |     "bright_black": 8,
59 |     "bright_red": 9,
60 |     "bright_green": 10,
61 |     "bright_yellow": 11,
62 |     "bright_blue": 12,
63 |     "bright_magenta": 13,
64 |     "bright_cyan": 14,
65 |     "bright_white": 15,
66 |     "grey0": 16,
67 |     "gray0": 16,
68 |     "navy_blue": 17,
69 |     "dark_blue": 18,
70 |     "blue3": 20,
71 |     "blue1": 21,
72 |     "dark_green": 22,
73 |     "deep_sky_blue4": 25,
74 |     "dodger_blue3": 26,
75 |     "dodger_blue2": 27,
76 |     "green4": 28,
77 |     "spring_green4": 29,
78 |     "turquoise4": 30,
79 |     "deep_sky_blue3": 32,
80 |     "dodger_blue1": 33,
81 |     "green3": 40,
82 |     "spring_green3": 41,
83 |     "dark_cyan": 36,
84 |     "light_sea_green": 37,
85 |     "deep_sky_blue2": 38,
86 |     "deep_sky_blue1": 39,
87 |     "spring_green2": 47,
88 |     "cyan3": 43,
89 |     "dark_turquoise": 44,
90 |     "turquoise2": 45,
91 |     "green1": 46,
92 |     "spring_green1": 48,
93 |     "medium_spring_green": 49,
94 |     "cyan2": 50,
95 |     "cyan1": 51,
96 |     "dark_red": 88,
97 |     "deep_pink4": 125,
98 |     "purple4": 55,
99 |     "purple3": 56,
100 |     "blue_violet": 57,
101 |     "orange4": 94,
102 |     "grey37": 59,
103 |     "gray37": 59,
104 |     "medium_purple4": 60,
105 |     "slate_blue3": 62,
106 |     "royal_blue1": 63,
107 |     "chartreuse4": 64,
108 |     "dark_sea_green4": 71,
109 |     "pale_turquoise4": 66,
110 |     "steel_blue": 67,
111 |     "steel_blue3": 68,
112 |     "cornflower_blue": 69,
113 |     "chartreuse3": 76,
114 |     "cadet_blue": 73,
115 |     "sky_blue3": 74,
116 |     "steel_blue1": 81,
117 |     "pale_green3": 114,
118 |     "sea_green3": 78,
119 |     "aquamarine3": 79,
120 |     "medium_turquoise": 80,
121 |     "chartreuse2": 112,
122 |     "sea_green2": 83,
123 |     "sea_green1": 85,
124 |     "aquamarine1": 122,
125 |     "dark_slate_gray2": 87,
126 |     "dark_magenta": 91,
127 |     "dark_violet": 128,
128 |     "purple": 129,
129 |     "light_pink4": 95,
130 |     "plum4": 96,
131 |     "medium_purple3": 98,
132 |     "slate_blue1": 99,
133 |     "yellow4": 106,
134 |     "wheat4": 101,
135 |     "grey53": 102,
136 |     "gray53": 102,
137 |     "light_slate_grey": 103,
138 |     "light_slate_gray": 103,
139 |     "medium_purple": 104,
140 |     "light_slate_blue": 105,
141 |     "dark_olive_green3": 149,
142 |     "dark_sea_green": 108,
143 |     "light_sky_blue3": 110,
144 |     "sky_blue2": 111,
145 |     "dark_sea_green3": 150,
146 |     "dark_slate_gray3": 116,
147 |     "sky_blue1": 117,
148 |     "chartreuse1": 118,
149 |     "light_green": 120,
150 |     "pale_green1": 156,
151 |     "dark_slate_gray1": 123,
152 |     "red3": 160,
153 |     "medium_violet_red": 126,
154 |     "magenta3": 164,
155 |     "dark_orange3": 166,
156 |     "indian_red": 167,
157 |     "hot_pink3": 168,
158 |     "medium_orchid3": 133,
159 |     "medium_orchid": 134,
160 |     "medium_purple2": 140,
161 |     "dark_goldenrod": 136,
162 |     "light_salmon3": 173,
163 |     "rosy_brown": 138,
164 |     "grey63": 139,
165 |     "gray63": 139,
166 |     "medium_purple1": 141,
167 |     "gold3": 178,
168 |     "dark_khaki": 143,
169 |     "navajo_white3": 144,
170 |     "grey69": 145,
171 |     "gray69": 145,
172 |     "light_steel_blue3": 146,
173 |     "light_steel_blue": 147,
174 |     "yellow3": 184,
175 |     "dark_sea_green2": 157,
176 |     "light_cyan3": 152,
177 |     "light_sky_blue1": 153,
178 |     "green_yellow": 154,
179 |     "dark_olive_green2": 155,
180 |     "dark_sea_green1": 193,
181 |     "pale_turquoise1": 159,
182 |     "deep_pink3": 162,
183 |     "magenta2": 200,
184 |     "hot_pink2": 169,
185 |     "orchid": 170,
186 |     "medium_orchid1": 207,
187 |     "orange3": 172,
188 |     "light_pink3": 174,
189 |     "pink3": 175,
190 |     "plum3": 176,
191 |     "violet": 177,
192 |     "light_goldenrod3": 179,
193 |     "tan": 180,
194 |     "misty_rose3": 181,
195 |     "thistle3": 182,
196 |     "plum2": 183,
197 |     "khaki3": 185,
198 |     "light_goldenrod2": 222,
199 |     "light_yellow3": 187,
200 |     "grey84": 188,
201 |     "gray84": 188,
202 |     "light_steel_blue1": 189,
203 |     "yellow2": 190,
204 |     "dark_olive_green1": 192,
205 |     "honeydew2": 194,
206 |     "light_cyan1": 195,
207 |     "red1": 196,
208 |     "deep_pink2": 197,
209 |     "deep_pink1": 199,
210 |     "magenta1": 201,
211 |     "orange_red1": 202,
212 |     "indian_red1": 204,
213 |     "hot_pink": 206,
214 |     "dark_orange": 208,
215 |     "salmon1": 209,
216 |     "light_coral": 210,
217 |     "pale_violet_red1": 211,
218 |     "orchid2": 212,
219 |     "orchid1": 213,
220 |     "orange1": 214,
221 |     "sandy_brown": 215,
222 |     "light_salmon1": 216,
223 |     "light_pink1": 217,
224 |     "pink1": 218,
225 |     "plum1": 219,
226 |     "gold1": 220,
227 |     "navajo_white1": 223,
228 |     "misty_rose1": 224,
229 |     "thistle1": 225,
230 |     "yellow1": 226,
231 |     "light_goldenrod1": 227,
232 |     "khaki1": 228,
233 |     "wheat1": 229,
234 |     "cornsilk1": 230,
235 |     "grey100": 231,
236 |     "gray100": 231,
237 |     "grey3": 232,
238 |     "gray3": 232,
239 |     "grey7": 233,
240 |     "gray7": 233,
241 |     "grey11": 234,
242 |     "gray11": 234,
243 |     "grey15": 235,
244 |     "gray15": 235,
245 |     "grey19": 236,
246 |     "gray19": 236,
247 |     "grey23": 237,
248 |     "gray23": 237,
249 |     "grey27": 238,
250 |     "gray27": 238,
251 |     "grey30": 239,
252 |     "gray30": 239,
253 |     "grey35": 240,
254 |     "gray35": 240,
255 |     "grey39": 241,
256 |     "gray39": 241,
257 |     "grey42": 242,
258 |     "gray42": 242,
259 |     "grey46": 243,
260 |     "gray46": 243,
261 |     "grey50": 244,
262 |     "gray50": 244,
263 |     "grey54": 245,
264 |     "gray54": 245,
265 |     "grey58": 246,
266 |     "gray58": 246,
267 |     "grey62": 247,
268 |     "gray62": 247,
269 |     "grey66": 248,
270 |     "gray66": 248,
271 |     "grey70": 249,
272 |     "gray70": 249,
273 |     "grey74": 250,
274 |     "gray74": 250,
275 |     "grey78": 251,
276 |     "gray78": 251,
277 |     "grey82": 252,
278 |     "gray82": 252,
279 |     "grey85": 253,
280 |     "gray85": 253,
281 |     "grey89": 254,
282 |     "gray89": 254,
283 |     "grey93": 255,
284 |     "gray93": 255,
285 | }
286 | 
287 | 
288 | class ColorParseError(Exception):
289 |     """The color could not be parsed."""
290 | 
291 | 
292 | RE_COLOR = re.compile(
293 |     r"""^
294 | \#([0-9a-f]{6})$|
295 | color\(([0-9]{1,3})\)$|
296 | rgb\(([\d\s,]+)\)$
297 | """,
298 |     re.VERBOSE,
299 | )
300 | 
301 | 
302 | @rich_repr
303 | class Color(NamedTuple):
304 |     """Terminal color definition."""
305 | 
306 |     name: str
307 |     """The name of the color (typically the input to Color.parse)."""
308 |     type: ColorType
309 |     """The type of the color."""
310 |     number: Optional[int] = None
311 |     """The color number, if a standard color, or None."""
312 |     triplet: Optional[ColorTriplet] = None
313 |     """A triplet of color components, if an RGB color."""
314 | 
315 |     def __rich__(self) -> "Text":
316 |         """Displays the actual color if Rich printed."""
317 |         from .style import Style
318 |         from .text import Text
319 | 
320 |         return Text.assemble(
321 |             f"<color {self.name!r} ({self.type.name.lower()})",
322 |             ("", Style(color=self)),
323 |             " >",
324 |         )
325 | 
326 |     def __rich_repr__(self) -> Result:
327 |         yield self.name
328 |         yield self.type
329 |         yield "number", self.number, None
330 |         yield "triplet", self.triplet, None
331 | 
332 |     @property
333 |     def system(self) -> ColorSystem:
334 |         """Get the native color system for this color."""
335 |         if self.type == ColorType.DEFAULT:
336 |             return ColorSystem.STANDARD
337 |         return ColorSystem(int(self.type))
338 | 
339 |     @property
340 |     def is_system_defined(self) -> bool:
341 |         """Check if the color is ultimately defined by the system."""
342 |         return self.system not in (ColorSystem.EIGHT_BIT, ColorSystem.TRUECOLOR)
343 | 
344 |     @property
345 |     def is_default(self) -> bool:
346 |         """Check if the color is a default color."""
347 |         return self.type == ColorType.DEFAULT
348 | 
349 |     def get_truecolor(
350 |         self, theme: Optional["TerminalTheme"] = None, foreground: bool = True
351 |     ) -> ColorTriplet:
352 |         """Get an equivalent color triplet for this color.
353 | 
354 |         Args:
355 |             theme (TerminalTheme, optional): Optional terminal theme, or None to use default. Defaults to None.
356 |             foreground (bool, optional): True for a foreground color, or False for background. Defaults to True.
357 | 
358 |         Returns:
359 |             ColorTriplet: A color triplet containing RGB components.
360 |         """
361 | 
362 |         if theme is None:
363 |             theme = DEFAULT_TERMINAL_THEME
364 |         if self.type == ColorType.TRUECOLOR:
365 |             assert self.triplet is not None
366 |             return self.triplet
367 |         elif self.type == ColorType.EIGHT_BIT:
368 |             assert self.number is not None
369 |             return EIGHT_BIT_PALETTE[self.number]
370 |         elif self.type == ColorType.STANDARD:
371 |             assert self.number is not None
372 |             return theme.ansi_colors[self.number]
373 |         elif self.type == ColorType.WINDOWS:
374 |             assert self.number is not None
375 |             return WINDOWS_PALETTE[self.number]
376 |         else:  # self.type == ColorType.DEFAULT:
377 |             assert self.number is None
378 |             return theme.foreground_color if foreground else theme.background_color
379 | 
380 |     @classmethod
381 |     def from_ansi(cls, number: int) -> "Color":
382 |         """Create a Color number from it's 8-bit ansi number.
383 | 
384 |         Args:
385 |             number (int): A number between 0-255 inclusive.
386 | 
387 |         Returns:
388 |             Color: A new Color instance.
389 |         """
390 |         return cls(
391 |             name=f"color({number})",
392 |             type=(ColorType.STANDARD if number < 16 else ColorType.EIGHT_BIT),
393 |             number=number,
394 |         )
395 | 
396 |     @classmethod
397 |     def from_triplet(cls, triplet: "ColorTriplet") -> "Color":
398 |         """Create a truecolor RGB color from a triplet of values.
399 | 
400 |         Args:
401 |             triplet (ColorTriplet): A color triplet containing red, green and blue components.
402 | 
403 |         Returns:
404 |             Color: A new color object.
405 |         """
406 |         return cls(name=triplet.hex, type=ColorType.TRUECOLOR, triplet=triplet)
407 | 
408 |     @classmethod
409 |     def from_rgb(cls, red: float, green: float, blue: float) -> "Color":
410 |         """Create a truecolor from three color components in the range(0->255).
411 | 
412 |         Args:
413 |             red (float): Red component in range 0-255.
414 |             green (float): Green component in range 0-255.
415 |             blue (float): Blue component in range 0-255.
416 | 
417 |         Returns:
418 |             Color: A new color object.
419 |         """
420 |         return cls.from_triplet(ColorTriplet(int(red), int(green), int(blue)))
421 | 
422 |     @classmethod
423 |     def default(cls) -> "Color":
424 |         """Get a Color instance representing the default color.
425 | 
426 |         Returns:
427 |             Color: Default color.
428 |         """
429 |         return cls(name="default", type=ColorType.DEFAULT)
430 | 
431 |     @classmethod
432 |     @lru_cache(maxsize=1024)
433 |     def parse(cls, color: str) -> "Color":
434 |         """Parse a color definition."""
435 |         original_color = color
436 |         color = color.lower().strip()
437 | 
438 |         if color == "default":
[TRUNCATED]
```

.venv/lib/python3.13/site-packages/pip/_vendor/rich/color_triplet.py
```
1 | from typing import NamedTuple, Tuple
2 | 
3 | 
4 | class ColorTriplet(NamedTuple):
5 |     """The red, green, and blue components of a color."""
6 | 
7 |     red: int
8 |     """Red component in 0 to 255 range."""
9 |     green: int
10 |     """Green component in 0 to 255 range."""
11 |     blue: int
12 |     """Blue component in 0 to 255 range."""
13 | 
14 |     @property
15 |     def hex(self) -> str:
16 |         """get the color triplet in CSS style."""
17 |         red, green, blue = self
18 |         return f"#{red:02x}{green:02x}{blue:02x}"
19 | 
20 |     @property
21 |     def rgb(self) -> str:
22 |         """The color in RGB format.
23 | 
24 |         Returns:
25 |             str: An rgb color, e.g. ``"rgb(100,23,255)"``.
26 |         """
27 |         red, green, blue = self
28 |         return f"rgb({red},{green},{blue})"
29 | 
30 |     @property
31 |     def normalized(self) -> Tuple[float, float, float]:
32 |         """Convert components into floats between 0 and 1.
33 | 
34 |         Returns:
35 |             Tuple[float, float, float]: A tuple of three normalized colour components.
36 |         """
37 |         red, green, blue = self
38 |         return red / 255.0, green / 255.0, blue / 255.0
```

.venv/lib/python3.13/site-packages/pip/_vendor/rich/columns.py
```
1 | from collections import defaultdict
2 | from itertools import chain
3 | from operator import itemgetter
4 | from typing import Dict, Iterable, List, Optional, Tuple
5 | 
6 | from .align import Align, AlignMethod
7 | from .console import Console, ConsoleOptions, RenderableType, RenderResult
8 | from .constrain import Constrain
9 | from .measure import Measurement
10 | from .padding import Padding, PaddingDimensions
11 | from .table import Table
12 | from .text import TextType
13 | from .jupyter import JupyterMixin
14 | 
15 | 
16 | class Columns(JupyterMixin):
17 |     """Display renderables in neat columns.
18 | 
19 |     Args:
20 |         renderables (Iterable[RenderableType]): Any number of Rich renderables (including str).
21 |         width (int, optional): The desired width of the columns, or None to auto detect. Defaults to None.
22 |         padding (PaddingDimensions, optional): Optional padding around cells. Defaults to (0, 1).
23 |         expand (bool, optional): Expand columns to full width. Defaults to False.
24 |         equal (bool, optional): Arrange in to equal sized columns. Defaults to False.
25 |         column_first (bool, optional): Align items from top to bottom (rather than left to right). Defaults to False.
26 |         right_to_left (bool, optional): Start column from right hand side. Defaults to False.
27 |         align (str, optional): Align value ("left", "right", or "center") or None for default. Defaults to None.
28 |         title (TextType, optional): Optional title for Columns.
29 |     """
30 | 
31 |     def __init__(
32 |         self,
33 |         renderables: Optional[Iterable[RenderableType]] = None,
34 |         padding: PaddingDimensions = (0, 1),
35 |         *,
36 |         width: Optional[int] = None,
37 |         expand: bool = False,
38 |         equal: bool = False,
39 |         column_first: bool = False,
40 |         right_to_left: bool = False,
41 |         align: Optional[AlignMethod] = None,
42 |         title: Optional[TextType] = None,
43 |     ) -> None:
44 |         self.renderables = list(renderables or [])
45 |         self.width = width
46 |         self.padding = padding
47 |         self.expand = expand
48 |         self.equal = equal
49 |         self.column_first = column_first
50 |         self.right_to_left = right_to_left
51 |         self.align: Optional[AlignMethod] = align
52 |         self.title = title
53 | 
54 |     def add_renderable(self, renderable: RenderableType) -> None:
55 |         """Add a renderable to the columns.
56 | 
57 |         Args:
58 |             renderable (RenderableType): Any renderable object.
59 |         """
60 |         self.renderables.append(renderable)
61 | 
62 |     def __rich_console__(
63 |         self, console: Console, options: ConsoleOptions
64 |     ) -> RenderResult:
65 |         render_str = console.render_str
66 |         renderables = [
67 |             render_str(renderable) if isinstance(renderable, str) else renderable
68 |             for renderable in self.renderables
69 |         ]
70 |         if not renderables:
71 |             return
72 |         _top, right, _bottom, left = Padding.unpack(self.padding)
73 |         width_padding = max(left, right)
74 |         max_width = options.max_width
75 |         widths: Dict[int, int] = defaultdict(int)
76 |         column_count = len(renderables)
77 | 
78 |         get_measurement = Measurement.get
79 |         renderable_widths = [
80 |             get_measurement(console, options, renderable).maximum
81 |             for renderable in renderables
82 |         ]
83 |         if self.equal:
84 |             renderable_widths = [max(renderable_widths)] * len(renderable_widths)
85 | 
86 |         def iter_renderables(
87 |             column_count: int,
88 |         ) -> Iterable[Tuple[int, Optional[RenderableType]]]:
89 |             item_count = len(renderables)
90 |             if self.column_first:
91 |                 width_renderables = list(zip(renderable_widths, renderables))
92 | 
93 |                 column_lengths: List[int] = [item_count // column_count] * column_count
94 |                 for col_no in range(item_count % column_count):
95 |                     column_lengths[col_no] += 1
96 | 
97 |                 row_count = (item_count + column_count - 1) // column_count
98 |                 cells = [[-1] * column_count for _ in range(row_count)]
99 |                 row = col = 0
100 |                 for index in range(item_count):
101 |                     cells[row][col] = index
102 |                     column_lengths[col] -= 1
103 |                     if column_lengths[col]:
104 |                         row += 1
105 |                     else:
106 |                         col += 1
107 |                         row = 0
108 |                 for index in chain.from_iterable(cells):
109 |                     if index == -1:
110 |                         break
111 |                     yield width_renderables[index]
112 |             else:
113 |                 yield from zip(renderable_widths, renderables)
114 |             # Pad odd elements with spaces
115 |             if item_count % column_count:
116 |                 for _ in range(column_count - (item_count % column_count)):
117 |                     yield 0, None
118 | 
119 |         table = Table.grid(padding=self.padding, collapse_padding=True, pad_edge=False)
120 |         table.expand = self.expand
121 |         table.title = self.title
122 | 
123 |         if self.width is not None:
124 |             column_count = (max_width) // (self.width + width_padding)
125 |             for _ in range(column_count):
126 |                 table.add_column(width=self.width)
127 |         else:
128 |             while column_count > 1:
129 |                 widths.clear()
130 |                 column_no = 0
131 |                 for renderable_width, _ in iter_renderables(column_count):
132 |                     widths[column_no] = max(widths[column_no], renderable_width)
133 |                     total_width = sum(widths.values()) + width_padding * (
134 |                         len(widths) - 1
135 |                     )
136 |                     if total_width > max_width:
137 |                         column_count = len(widths) - 1
138 |                         break
139 |                     else:
140 |                         column_no = (column_no + 1) % column_count
141 |                 else:
142 |                     break
143 | 
144 |         get_renderable = itemgetter(1)
145 |         _renderables = [
146 |             get_renderable(_renderable)
147 |             for _renderable in iter_renderables(column_count)
148 |         ]
149 |         if self.equal:
150 |             _renderables = [
151 |                 None
152 |                 if renderable is None
153 |                 else Constrain(renderable, renderable_widths[0])
154 |                 for renderable in _renderables
155 |             ]
156 |         if self.align:
157 |             align = self.align
158 |             _Align = Align
159 |             _renderables = [
160 |                 None if renderable is None else _Align(renderable, align)
161 |                 for renderable in _renderables
162 |             ]
163 | 
164 |         right_to_left = self.right_to_left
165 |         add_row = table.add_row
166 |         for start in range(0, len(_renderables), column_count):
167 |             row = _renderables[start : start + column_count]
168 |             if right_to_left:
169 |                 row = row[::-1]
170 |             add_row(*row)
171 |         yield table
172 | 
173 | 
174 | if __name__ == "__main__":  # pragma: no cover
175 |     import os
176 | 
177 |     console = Console()
178 | 
179 |     files = [f"{i} {s}" for i, s in enumerate(sorted(os.listdir()))]
180 |     columns = Columns(files, padding=(0, 1), expand=False, equal=False)
181 |     console.print(columns)
182 |     console.rule()
183 |     columns.column_first = True
184 |     console.print(columns)
185 |     columns.right_to_left = True
186 |     console.rule()
187 |     console.print(columns)
```

.venv/lib/python3.13/site-packages/pip/_vendor/rich/console.py
```
1 | import inspect
2 | import os
3 | import sys
4 | import threading
5 | import zlib
6 | from abc import ABC, abstractmethod
7 | from dataclasses import dataclass, field
8 | from datetime import datetime
9 | from functools import wraps
10 | from getpass import getpass
11 | from html import escape
12 | from inspect import isclass
13 | from itertools import islice
14 | from math import ceil
15 | from time import monotonic
16 | from types import FrameType, ModuleType, TracebackType
17 | from typing import (
18 |     IO,
19 |     TYPE_CHECKING,
20 |     Any,
21 |     Callable,
22 |     Dict,
23 |     Iterable,
24 |     List,
25 |     Mapping,
26 |     NamedTuple,
27 |     Optional,
28 |     TextIO,
29 |     Tuple,
30 |     Type,
31 |     Union,
32 |     cast,
33 | )
34 | 
35 | from pip._vendor.rich._null_file import NULL_FILE
36 | 
37 | if sys.version_info >= (3, 8):
38 |     from typing import Literal, Protocol, runtime_checkable
39 | else:
40 |     from pip._vendor.typing_extensions import (
41 |         Literal,
42 |         Protocol,
43 |         runtime_checkable,
44 |     )  # pragma: no cover
45 | 
46 | from . import errors, themes
47 | from ._emoji_replace import _emoji_replace
48 | from ._export_format import CONSOLE_HTML_FORMAT, CONSOLE_SVG_FORMAT
49 | from ._fileno import get_fileno
50 | from ._log_render import FormatTimeCallable, LogRender
51 | from .align import Align, AlignMethod
52 | from .color import ColorSystem, blend_rgb
53 | from .control import Control
54 | from .emoji import EmojiVariant
55 | from .highlighter import NullHighlighter, ReprHighlighter
56 | from .markup import render as render_markup
57 | from .measure import Measurement, measure_renderables
58 | from .pager import Pager, SystemPager
59 | from .pretty import Pretty, is_expandable
60 | from .protocol import rich_cast
61 | from .region import Region
62 | from .scope import render_scope
63 | from .screen import Screen
64 | from .segment import Segment
65 | from .style import Style, StyleType
66 | from .styled import Styled
67 | from .terminal_theme import DEFAULT_TERMINAL_THEME, SVG_EXPORT_THEME, TerminalTheme
68 | from .text import Text, TextType
69 | from .theme import Theme, ThemeStack
70 | 
71 | if TYPE_CHECKING:
72 |     from ._windows import WindowsConsoleFeatures
73 |     from .live import Live
74 |     from .status import Status
75 | 
76 | JUPYTER_DEFAULT_COLUMNS = 115
77 | JUPYTER_DEFAULT_LINES = 100
78 | WINDOWS = sys.platform == "win32"
79 | 
80 | HighlighterType = Callable[[Union[str, "Text"]], "Text"]
81 | JustifyMethod = Literal["default", "left", "center", "right", "full"]
82 | OverflowMethod = Literal["fold", "crop", "ellipsis", "ignore"]
83 | 
84 | 
85 | class NoChange:
86 |     pass
87 | 
88 | 
89 | NO_CHANGE = NoChange()
90 | 
91 | try:
92 |     _STDIN_FILENO = sys.__stdin__.fileno()  # type: ignore[union-attr]
93 | except Exception:
94 |     _STDIN_FILENO = 0
95 | try:
96 |     _STDOUT_FILENO = sys.__stdout__.fileno()  # type: ignore[union-attr]
97 | except Exception:
98 |     _STDOUT_FILENO = 1
99 | try:
100 |     _STDERR_FILENO = sys.__stderr__.fileno()  # type: ignore[union-attr]
101 | except Exception:
102 |     _STDERR_FILENO = 2
103 | 
104 | _STD_STREAMS = (_STDIN_FILENO, _STDOUT_FILENO, _STDERR_FILENO)
105 | _STD_STREAMS_OUTPUT = (_STDOUT_FILENO, _STDERR_FILENO)
106 | 
107 | 
108 | _TERM_COLORS = {
109 |     "kitty": ColorSystem.EIGHT_BIT,
110 |     "256color": ColorSystem.EIGHT_BIT,
111 |     "16color": ColorSystem.STANDARD,
112 | }
113 | 
114 | 
115 | class ConsoleDimensions(NamedTuple):
116 |     """Size of the terminal."""
117 | 
118 |     width: int
119 |     """The width of the console in 'cells'."""
120 |     height: int
121 |     """The height of the console in lines."""
122 | 
123 | 
124 | @dataclass
125 | class ConsoleOptions:
126 |     """Options for __rich_console__ method."""
127 | 
128 |     size: ConsoleDimensions
129 |     """Size of console."""
130 |     legacy_windows: bool
131 |     """legacy_windows: flag for legacy windows."""
132 |     min_width: int
133 |     """Minimum width of renderable."""
134 |     max_width: int
135 |     """Maximum width of renderable."""
136 |     is_terminal: bool
137 |     """True if the target is a terminal, otherwise False."""
138 |     encoding: str
139 |     """Encoding of terminal."""
140 |     max_height: int
141 |     """Height of container (starts as terminal)"""
142 |     justify: Optional[JustifyMethod] = None
143 |     """Justify value override for renderable."""
144 |     overflow: Optional[OverflowMethod] = None
145 |     """Overflow value override for renderable."""
146 |     no_wrap: Optional[bool] = False
147 |     """Disable wrapping for text."""
148 |     highlight: Optional[bool] = None
149 |     """Highlight override for render_str."""
150 |     markup: Optional[bool] = None
151 |     """Enable markup when rendering strings."""
152 |     height: Optional[int] = None
153 | 
154 |     @property
155 |     def ascii_only(self) -> bool:
156 |         """Check if renderables should use ascii only."""
157 |         return not self.encoding.startswith("utf")
158 | 
159 |     def copy(self) -> "ConsoleOptions":
160 |         """Return a copy of the options.
161 | 
162 |         Returns:
163 |             ConsoleOptions: a copy of self.
164 |         """
165 |         options: ConsoleOptions = ConsoleOptions.__new__(ConsoleOptions)
166 |         options.__dict__ = self.__dict__.copy()
167 |         return options
168 | 
169 |     def update(
170 |         self,
171 |         *,
172 |         width: Union[int, NoChange] = NO_CHANGE,
173 |         min_width: Union[int, NoChange] = NO_CHANGE,
174 |         max_width: Union[int, NoChange] = NO_CHANGE,
175 |         justify: Union[Optional[JustifyMethod], NoChange] = NO_CHANGE,
176 |         overflow: Union[Optional[OverflowMethod], NoChange] = NO_CHANGE,
177 |         no_wrap: Union[Optional[bool], NoChange] = NO_CHANGE,
178 |         highlight: Union[Optional[bool], NoChange] = NO_CHANGE,
179 |         markup: Union[Optional[bool], NoChange] = NO_CHANGE,
180 |         height: Union[Optional[int], NoChange] = NO_CHANGE,
181 |     ) -> "ConsoleOptions":
182 |         """Update values, return a copy."""
183 |         options = self.copy()
184 |         if not isinstance(width, NoChange):
185 |             options.min_width = options.max_width = max(0, width)
186 |         if not isinstance(min_width, NoChange):
187 |             options.min_width = min_width
188 |         if not isinstance(max_width, NoChange):
189 |             options.max_width = max_width
190 |         if not isinstance(justify, NoChange):
191 |             options.justify = justify
192 |         if not isinstance(overflow, NoChange):
193 |             options.overflow = overflow
194 |         if not isinstance(no_wrap, NoChange):
195 |             options.no_wrap = no_wrap
196 |         if not isinstance(highlight, NoChange):
197 |             options.highlight = highlight
198 |         if not isinstance(markup, NoChange):
199 |             options.markup = markup
200 |         if not isinstance(height, NoChange):
201 |             if height is not None:
202 |                 options.max_height = height
203 |             options.height = None if height is None else max(0, height)
204 |         return options
205 | 
206 |     def update_width(self, width: int) -> "ConsoleOptions":
207 |         """Update just the width, return a copy.
208 | 
209 |         Args:
210 |             width (int): New width (sets both min_width and max_width)
211 | 
212 |         Returns:
213 |             ~ConsoleOptions: New console options instance.
214 |         """
215 |         options = self.copy()
216 |         options.min_width = options.max_width = max(0, width)
217 |         return options
218 | 
219 |     def update_height(self, height: int) -> "ConsoleOptions":
220 |         """Update the height, and return a copy.
221 | 
222 |         Args:
223 |             height (int): New height
224 | 
225 |         Returns:
226 |             ~ConsoleOptions: New Console options instance.
227 |         """
228 |         options = self.copy()
229 |         options.max_height = options.height = height
230 |         return options
231 | 
232 |     def reset_height(self) -> "ConsoleOptions":
233 |         """Return a copy of the options with height set to ``None``.
234 | 
235 |         Returns:
236 |             ~ConsoleOptions: New console options instance.
237 |         """
238 |         options = self.copy()
239 |         options.height = None
240 |         return options
241 | 
242 |     def update_dimensions(self, width: int, height: int) -> "ConsoleOptions":
243 |         """Update the width and height, and return a copy.
244 | 
245 |         Args:
246 |             width (int): New width (sets both min_width and max_width).
247 |             height (int): New height.
248 | 
249 |         Returns:
250 |             ~ConsoleOptions: New console options instance.
251 |         """
252 |         options = self.copy()
253 |         options.min_width = options.max_width = max(0, width)
254 |         options.height = options.max_height = height
255 |         return options
256 | 
257 | 
258 | @runtime_checkable
259 | class RichCast(Protocol):
260 |     """An object that may be 'cast' to a console renderable."""
261 | 
262 |     def __rich__(
263 |         self,
264 |     ) -> Union["ConsoleRenderable", "RichCast", str]:  # pragma: no cover
265 |         ...
266 | 
267 | 
268 | @runtime_checkable
269 | class ConsoleRenderable(Protocol):
270 |     """An object that supports the console protocol."""
271 | 
272 |     def __rich_console__(
273 |         self, console: "Console", options: "ConsoleOptions"
274 |     ) -> "RenderResult":  # pragma: no cover
275 |         ...
276 | 
277 | 
278 | # A type that may be rendered by Console.
279 | RenderableType = Union[ConsoleRenderable, RichCast, str]
280 | """A string or any object that may be rendered by Rich."""
281 | 
282 | # The result of calling a __rich_console__ method.
283 | RenderResult = Iterable[Union[RenderableType, Segment]]
284 | 
285 | _null_highlighter = NullHighlighter()
286 | 
287 | 
288 | class CaptureError(Exception):
289 |     """An error in the Capture context manager."""
290 | 
291 | 
292 | class NewLine:
293 |     """A renderable to generate new line(s)"""
294 | 
295 |     def __init__(self, count: int = 1) -> None:
296 |         self.count = count
297 | 
298 |     def __rich_console__(
299 |         self, console: "Console", options: "ConsoleOptions"
300 |     ) -> Iterable[Segment]:
301 |         yield Segment("\n" * self.count)
302 | 
303 | 
304 | class ScreenUpdate:
305 |     """Render a list of lines at a given offset."""
306 | 
307 |     def __init__(self, lines: List[List[Segment]], x: int, y: int) -> None:
308 |         self._lines = lines
309 |         self.x = x
310 |         self.y = y
311 | 
312 |     def __rich_console__(
313 |         self, console: "Console", options: ConsoleOptions
314 |     ) -> RenderResult:
315 |         x = self.x
316 |         move_to = Control.move_to
317 |         for offset, line in enumerate(self._lines, self.y):
318 |             yield move_to(x, offset)
319 |             yield from line
320 | 
321 | 
322 | class Capture:
323 |     """Context manager to capture the result of printing to the console.
324 |     See :meth:`~rich.console.Console.capture` for how to use.
325 | 
326 |     Args:
327 |         console (Console): A console instance to capture output.
328 |     """
329 | 
330 |     def __init__(self, console: "Console") -> None:
331 |         self._console = console
332 |         self._result: Optional[str] = None
333 | 
334 |     def __enter__(self) -> "Capture":
335 |         self._console.begin_capture()
336 |         return self
337 | 
338 |     def __exit__(
339 |         self,
340 |         exc_type: Optional[Type[BaseException]],
341 |         exc_val: Optional[BaseException],
342 |         exc_tb: Optional[TracebackType],
343 |     ) -> None:
344 |         self._result = self._console.end_capture()
345 | 
346 |     def get(self) -> str:
347 |         """Get the result of the capture."""
348 |         if self._result is None:
349 |             raise CaptureError(
350 |                 "Capture result is not available until context manager exits."
351 |             )
352 |         return self._result
353 | 
354 | 
355 | class ThemeContext:
356 |     """A context manager to use a temporary theme. See :meth:`~rich.console.Console.use_theme` for usage."""
357 | 
358 |     def __init__(self, console: "Console", theme: Theme, inherit: bool = True) -> None:
359 |         self.console = console
360 |         self.theme = theme
361 |         self.inherit = inherit
362 | 
363 |     def __enter__(self) -> "ThemeContext":
364 |         self.console.push_theme(self.theme)
365 |         return self
366 | 
367 |     def __exit__(
368 |         self,
369 |         exc_type: Optional[Type[BaseException]],
370 |         exc_val: Optional[BaseException],
371 |         exc_tb: Optional[TracebackType],
372 |     ) -> None:
373 |         self.console.pop_theme()
374 | 
375 | 
376 | class PagerContext:
377 |     """A context manager that 'pages' content. See :meth:`~rich.console.Console.pager` for usage."""
378 | 
379 |     def __init__(
380 |         self,
381 |         console: "Console",
382 |         pager: Optional[Pager] = None,
383 |         styles: bool = False,
384 |         links: bool = False,
385 |     ) -> None:
386 |         self._console = console
387 |         self.pager = SystemPager() if pager is None else pager
388 |         self.styles = styles
389 |         self.links = links
390 | 
391 |     def __enter__(self) -> "PagerContext":
392 |         self._console._enter_buffer()
393 |         return self
394 | 
395 |     def __exit__(
396 |         self,
[TRUNCATED]
```

.venv/lib/python3.13/site-packages/pip/_vendor/rich/constrain.py
```
1 | from typing import Optional, TYPE_CHECKING
2 | 
3 | from .jupyter import JupyterMixin
4 | from .measure import Measurement
5 | 
6 | if TYPE_CHECKING:
7 |     from .console import Console, ConsoleOptions, RenderableType, RenderResult
8 | 
9 | 
10 | class Constrain(JupyterMixin):
11 |     """Constrain the width of a renderable to a given number of characters.
12 | 
13 |     Args:
14 |         renderable (RenderableType): A renderable object.
15 |         width (int, optional): The maximum width (in characters) to render. Defaults to 80.
16 |     """
17 | 
18 |     def __init__(self, renderable: "RenderableType", width: Optional[int] = 80) -> None:
19 |         self.renderable = renderable
20 |         self.width = width
21 | 
22 |     def __rich_console__(
23 |         self, console: "Console", options: "ConsoleOptions"
24 |     ) -> "RenderResult":
25 |         if self.width is None:
26 |             yield self.renderable
27 |         else:
28 |             child_options = options.update_width(min(self.width, options.max_width))
29 |             yield from console.render(self.renderable, child_options)
30 | 
31 |     def __rich_measure__(
32 |         self, console: "Console", options: "ConsoleOptions"
33 |     ) -> "Measurement":
34 |         if self.width is not None:
35 |             options = options.update_width(self.width)
36 |         measurement = Measurement.get(console, options, self.renderable)
37 |         return measurement
```

.venv/lib/python3.13/site-packages/pip/_vendor/rich/containers.py
```
1 | from itertools import zip_longest
2 | from typing import (
3 |     TYPE_CHECKING,
4 |     Iterable,
5 |     Iterator,
6 |     List,
7 |     Optional,
8 |     TypeVar,
9 |     Union,
10 |     overload,
11 | )
12 | 
13 | if TYPE_CHECKING:
14 |     from .console import (
15 |         Console,
16 |         ConsoleOptions,
17 |         JustifyMethod,
18 |         OverflowMethod,
19 |         RenderResult,
20 |         RenderableType,
21 |     )
22 |     from .text import Text
23 | 
24 | from .cells import cell_len
25 | from .measure import Measurement
26 | 
27 | T = TypeVar("T")
28 | 
29 | 
30 | class Renderables:
31 |     """A list subclass which renders its contents to the console."""
32 | 
33 |     def __init__(
34 |         self, renderables: Optional[Iterable["RenderableType"]] = None
35 |     ) -> None:
36 |         self._renderables: List["RenderableType"] = (
37 |             list(renderables) if renderables is not None else []
38 |         )
39 | 
40 |     def __rich_console__(
41 |         self, console: "Console", options: "ConsoleOptions"
42 |     ) -> "RenderResult":
43 |         """Console render method to insert line-breaks."""
44 |         yield from self._renderables
45 | 
46 |     def __rich_measure__(
47 |         self, console: "Console", options: "ConsoleOptions"
48 |     ) -> "Measurement":
49 |         dimensions = [
50 |             Measurement.get(console, options, renderable)
51 |             for renderable in self._renderables
52 |         ]
53 |         if not dimensions:
54 |             return Measurement(1, 1)
55 |         _min = max(dimension.minimum for dimension in dimensions)
56 |         _max = max(dimension.maximum for dimension in dimensions)
57 |         return Measurement(_min, _max)
58 | 
59 |     def append(self, renderable: "RenderableType") -> None:
60 |         self._renderables.append(renderable)
61 | 
62 |     def __iter__(self) -> Iterable["RenderableType"]:
63 |         return iter(self._renderables)
64 | 
65 | 
66 | class Lines:
67 |     """A list subclass which can render to the console."""
68 | 
69 |     def __init__(self, lines: Iterable["Text"] = ()) -> None:
70 |         self._lines: List["Text"] = list(lines)
71 | 
72 |     def __repr__(self) -> str:
73 |         return f"Lines({self._lines!r})"
74 | 
75 |     def __iter__(self) -> Iterator["Text"]:
76 |         return iter(self._lines)
77 | 
78 |     @overload
79 |     def __getitem__(self, index: int) -> "Text":
80 |         ...
81 | 
82 |     @overload
83 |     def __getitem__(self, index: slice) -> List["Text"]:
84 |         ...
85 | 
86 |     def __getitem__(self, index: Union[slice, int]) -> Union["Text", List["Text"]]:
87 |         return self._lines[index]
88 | 
89 |     def __setitem__(self, index: int, value: "Text") -> "Lines":
90 |         self._lines[index] = value
91 |         return self
92 | 
93 |     def __len__(self) -> int:
94 |         return self._lines.__len__()
95 | 
96 |     def __rich_console__(
97 |         self, console: "Console", options: "ConsoleOptions"
98 |     ) -> "RenderResult":
99 |         """Console render method to insert line-breaks."""
100 |         yield from self._lines
101 | 
102 |     def append(self, line: "Text") -> None:
103 |         self._lines.append(line)
104 | 
105 |     def extend(self, lines: Iterable["Text"]) -> None:
106 |         self._lines.extend(lines)
107 | 
108 |     def pop(self, index: int = -1) -> "Text":
109 |         return self._lines.pop(index)
110 | 
111 |     def justify(
112 |         self,
113 |         console: "Console",
114 |         width: int,
115 |         justify: "JustifyMethod" = "left",
116 |         overflow: "OverflowMethod" = "fold",
117 |     ) -> None:
118 |         """Justify and overflow text to a given width.
119 | 
120 |         Args:
121 |             console (Console): Console instance.
122 |             width (int): Number of cells available per line.
123 |             justify (str, optional): Default justify method for text: "left", "center", "full" or "right". Defaults to "left".
124 |             overflow (str, optional): Default overflow for text: "crop", "fold", or "ellipsis". Defaults to "fold".
125 | 
126 |         """
127 |         from .text import Text
128 | 
129 |         if justify == "left":
130 |             for line in self._lines:
131 |                 line.truncate(width, overflow=overflow, pad=True)
132 |         elif justify == "center":
133 |             for line in self._lines:
134 |                 line.rstrip()
135 |                 line.truncate(width, overflow=overflow)
136 |                 line.pad_left((width - cell_len(line.plain)) // 2)
137 |                 line.pad_right(width - cell_len(line.plain))
138 |         elif justify == "right":
139 |             for line in self._lines:
140 |                 line.rstrip()
141 |                 line.truncate(width, overflow=overflow)
142 |                 line.pad_left(width - cell_len(line.plain))
143 |         elif justify == "full":
144 |             for line_index, line in enumerate(self._lines):
145 |                 if line_index == len(self._lines) - 1:
146 |                     break
147 |                 words = line.split(" ")
148 |                 words_size = sum(cell_len(word.plain) for word in words)
149 |                 num_spaces = len(words) - 1
150 |                 spaces = [1 for _ in range(num_spaces)]
151 |                 index = 0
152 |                 if spaces:
153 |                     while words_size + num_spaces < width:
154 |                         spaces[len(spaces) - index - 1] += 1
155 |                         num_spaces += 1
156 |                         index = (index + 1) % len(spaces)
157 |                 tokens: List[Text] = []
158 |                 for index, (word, next_word) in enumerate(
159 |                     zip_longest(words, words[1:])
160 |                 ):
161 |                     tokens.append(word)
162 |                     if index < len(spaces):
163 |                         style = word.get_style_at_offset(console, -1)
164 |                         next_style = next_word.get_style_at_offset(console, 0)
165 |                         space_style = style if style == next_style else line.style
166 |                         tokens.append(Text(" " * spaces[index], style=space_style))
167 |                 self[line_index] = Text("").join(tokens)
```

.venv/lib/python3.13/site-packages/pip/_vendor/rich/control.py
```
1 | import sys
2 | import time
3 | from typing import TYPE_CHECKING, Callable, Dict, Iterable, List, Union
4 | 
5 | if sys.version_info >= (3, 8):
6 |     from typing import Final
7 | else:
8 |     from pip._vendor.typing_extensions import Final  # pragma: no cover
9 | 
10 | from .segment import ControlCode, ControlType, Segment
11 | 
12 | if TYPE_CHECKING:
13 |     from .console import Console, ConsoleOptions, RenderResult
14 | 
15 | STRIP_CONTROL_CODES: Final = [
16 |     7,  # Bell
17 |     8,  # Backspace
18 |     11,  # Vertical tab
19 |     12,  # Form feed
20 |     13,  # Carriage return
21 | ]
22 | _CONTROL_STRIP_TRANSLATE: Final = {
23 |     _codepoint: None for _codepoint in STRIP_CONTROL_CODES
24 | }
25 | 
26 | CONTROL_ESCAPE: Final = {
27 |     7: "\\a",
28 |     8: "\\b",
29 |     11: "\\v",
30 |     12: "\\f",
31 |     13: "\\r",
32 | }
33 | 
34 | CONTROL_CODES_FORMAT: Dict[int, Callable[..., str]] = {
35 |     ControlType.BELL: lambda: "\x07",
36 |     ControlType.CARRIAGE_RETURN: lambda: "\r",
37 |     ControlType.HOME: lambda: "\x1b[H",
38 |     ControlType.CLEAR: lambda: "\x1b[2J",
39 |     ControlType.ENABLE_ALT_SCREEN: lambda: "\x1b[?1049h",
40 |     ControlType.DISABLE_ALT_SCREEN: lambda: "\x1b[?1049l",
41 |     ControlType.SHOW_CURSOR: lambda: "\x1b[?25h",
42 |     ControlType.HIDE_CURSOR: lambda: "\x1b[?25l",
43 |     ControlType.CURSOR_UP: lambda param: f"\x1b[{param}A",
44 |     ControlType.CURSOR_DOWN: lambda param: f"\x1b[{param}B",
45 |     ControlType.CURSOR_FORWARD: lambda param: f"\x1b[{param}C",
46 |     ControlType.CURSOR_BACKWARD: lambda param: f"\x1b[{param}D",
47 |     ControlType.CURSOR_MOVE_TO_COLUMN: lambda param: f"\x1b[{param+1}G",
48 |     ControlType.ERASE_IN_LINE: lambda param: f"\x1b[{param}K",
49 |     ControlType.CURSOR_MOVE_TO: lambda x, y: f"\x1b[{y+1};{x+1}H",
50 |     ControlType.SET_WINDOW_TITLE: lambda title: f"\x1b]0;{title}\x07",
51 | }
52 | 
53 | 
54 | class Control:
55 |     """A renderable that inserts a control code (non printable but may move cursor).
56 | 
57 |     Args:
58 |         *codes (str): Positional arguments are either a :class:`~rich.segment.ControlType` enum or a
59 |             tuple of ControlType and an integer parameter
60 |     """
61 | 
62 |     __slots__ = ["segment"]
63 | 
64 |     def __init__(self, *codes: Union[ControlType, ControlCode]) -> None:
65 |         control_codes: List[ControlCode] = [
66 |             (code,) if isinstance(code, ControlType) else code for code in codes
67 |         ]
68 |         _format_map = CONTROL_CODES_FORMAT
69 |         rendered_codes = "".join(
70 |             _format_map[code](*parameters) for code, *parameters in control_codes
71 |         )
72 |         self.segment = Segment(rendered_codes, None, control_codes)
73 | 
74 |     @classmethod
75 |     def bell(cls) -> "Control":
76 |         """Ring the 'bell'."""
77 |         return cls(ControlType.BELL)
78 | 
79 |     @classmethod
80 |     def home(cls) -> "Control":
81 |         """Move cursor to 'home' position."""
82 |         return cls(ControlType.HOME)
83 | 
84 |     @classmethod
85 |     def move(cls, x: int = 0, y: int = 0) -> "Control":
86 |         """Move cursor relative to current position.
87 | 
88 |         Args:
89 |             x (int): X offset.
90 |             y (int): Y offset.
91 | 
92 |         Returns:
93 |             ~Control: Control object.
94 | 
95 |         """
96 | 
97 |         def get_codes() -> Iterable[ControlCode]:
98 |             control = ControlType
99 |             if x:
100 |                 yield (
101 |                     control.CURSOR_FORWARD if x > 0 else control.CURSOR_BACKWARD,
102 |                     abs(x),
103 |                 )
104 |             if y:
105 |                 yield (
106 |                     control.CURSOR_DOWN if y > 0 else control.CURSOR_UP,
107 |                     abs(y),
108 |                 )
109 | 
110 |         control = cls(*get_codes())
111 |         return control
112 | 
113 |     @classmethod
114 |     def move_to_column(cls, x: int, y: int = 0) -> "Control":
115 |         """Move to the given column, optionally add offset to row.
116 | 
117 |         Returns:
118 |             x (int): absolute x (column)
119 |             y (int): optional y offset (row)
120 | 
121 |         Returns:
122 |             ~Control: Control object.
123 |         """
124 | 
125 |         return (
126 |             cls(
127 |                 (ControlType.CURSOR_MOVE_TO_COLUMN, x),
128 |                 (
129 |                     ControlType.CURSOR_DOWN if y > 0 else ControlType.CURSOR_UP,
130 |                     abs(y),
131 |                 ),
132 |             )
133 |             if y
134 |             else cls((ControlType.CURSOR_MOVE_TO_COLUMN, x))
135 |         )
136 | 
137 |     @classmethod
138 |     def move_to(cls, x: int, y: int) -> "Control":
139 |         """Move cursor to absolute position.
140 | 
141 |         Args:
142 |             x (int): x offset (column)
143 |             y (int): y offset (row)
144 | 
145 |         Returns:
146 |             ~Control: Control object.
147 |         """
148 |         return cls((ControlType.CURSOR_MOVE_TO, x, y))
149 | 
150 |     @classmethod
151 |     def clear(cls) -> "Control":
152 |         """Clear the screen."""
153 |         return cls(ControlType.CLEAR)
154 | 
155 |     @classmethod
156 |     def show_cursor(cls, show: bool) -> "Control":
157 |         """Show or hide the cursor."""
158 |         return cls(ControlType.SHOW_CURSOR if show else ControlType.HIDE_CURSOR)
159 | 
160 |     @classmethod
161 |     def alt_screen(cls, enable: bool) -> "Control":
162 |         """Enable or disable alt screen."""
163 |         if enable:
164 |             return cls(ControlType.ENABLE_ALT_SCREEN, ControlType.HOME)
165 |         else:
166 |             return cls(ControlType.DISABLE_ALT_SCREEN)
167 | 
168 |     @classmethod
169 |     def title(cls, title: str) -> "Control":
170 |         """Set the terminal window title
171 | 
172 |         Args:
173 |             title (str): The new terminal window title
174 |         """
175 |         return cls((ControlType.SET_WINDOW_TITLE, title))
176 | 
177 |     def __str__(self) -> str:
178 |         return self.segment.text
179 | 
180 |     def __rich_console__(
181 |         self, console: "Console", options: "ConsoleOptions"
182 |     ) -> "RenderResult":
183 |         if self.segment.text:
184 |             yield self.segment
185 | 
186 | 
187 | def strip_control_codes(
188 |     text: str, _translate_table: Dict[int, None] = _CONTROL_STRIP_TRANSLATE
189 | ) -> str:
190 |     """Remove control codes from text.
191 | 
192 |     Args:
193 |         text (str): A string possibly contain control codes.
194 | 
195 |     Returns:
196 |         str: String with control codes removed.
197 |     """
198 |     return text.translate(_translate_table)
199 | 
200 | 
201 | def escape_control_codes(
202 |     text: str,
203 |     _translate_table: Dict[int, str] = CONTROL_ESCAPE,
204 | ) -> str:
205 |     """Replace control codes with their "escaped" equivalent in the given text.
206 |     (e.g. "\b" becomes "\\b")
207 | 
208 |     Args:
209 |         text (str): A string possibly containing control codes.
210 | 
211 |     Returns:
212 |         str: String with control codes replaced with their escaped version.
213 |     """
214 |     return text.translate(_translate_table)
215 | 
216 | 
217 | if __name__ == "__main__":  # pragma: no cover
218 |     from pip._vendor.rich.console import Console
219 | 
220 |     console = Console()
221 |     console.print("Look at the title of your terminal window ^")
222 |     # console.print(Control((ControlType.SET_WINDOW_TITLE, "Hello, world!")))
223 |     for i in range(10):
224 |         console.set_window_title(" Loading" + "." * i)
225 |         time.sleep(0.5)
```

.venv/lib/python3.13/site-packages/pip/_vendor/rich/default_styles.py
```
1 | from typing import Dict
2 | 
3 | from .style import Style
4 | 
5 | DEFAULT_STYLES: Dict[str, Style] = {
6 |     "none": Style.null(),
7 |     "reset": Style(
8 |         color="default",
9 |         bgcolor="default",
10 |         dim=False,
11 |         bold=False,
12 |         italic=False,
13 |         underline=False,
14 |         blink=False,
15 |         blink2=False,
16 |         reverse=False,
17 |         conceal=False,
18 |         strike=False,
19 |     ),
20 |     "dim": Style(dim=True),
21 |     "bright": Style(dim=False),
22 |     "bold": Style(bold=True),
23 |     "strong": Style(bold=True),
24 |     "code": Style(reverse=True, bold=True),
25 |     "italic": Style(italic=True),
26 |     "emphasize": Style(italic=True),
27 |     "underline": Style(underline=True),
28 |     "blink": Style(blink=True),
29 |     "blink2": Style(blink2=True),
30 |     "reverse": Style(reverse=True),
31 |     "strike": Style(strike=True),
32 |     "black": Style(color="black"),
33 |     "red": Style(color="red"),
34 |     "green": Style(color="green"),
35 |     "yellow": Style(color="yellow"),
36 |     "magenta": Style(color="magenta"),
37 |     "cyan": Style(color="cyan"),
38 |     "white": Style(color="white"),
39 |     "inspect.attr": Style(color="yellow", italic=True),
40 |     "inspect.attr.dunder": Style(color="yellow", italic=True, dim=True),
41 |     "inspect.callable": Style(bold=True, color="red"),
42 |     "inspect.async_def": Style(italic=True, color="bright_cyan"),
43 |     "inspect.def": Style(italic=True, color="bright_cyan"),
44 |     "inspect.class": Style(italic=True, color="bright_cyan"),
45 |     "inspect.error": Style(bold=True, color="red"),
46 |     "inspect.equals": Style(),
47 |     "inspect.help": Style(color="cyan"),
48 |     "inspect.doc": Style(dim=True),
49 |     "inspect.value.border": Style(color="green"),
50 |     "live.ellipsis": Style(bold=True, color="red"),
51 |     "layout.tree.row": Style(dim=False, color="red"),
52 |     "layout.tree.column": Style(dim=False, color="blue"),
53 |     "logging.keyword": Style(bold=True, color="yellow"),
54 |     "logging.level.notset": Style(dim=True),
55 |     "logging.level.debug": Style(color="green"),
56 |     "logging.level.info": Style(color="blue"),
57 |     "logging.level.warning": Style(color="yellow"),
58 |     "logging.level.error": Style(color="red", bold=True),
59 |     "logging.level.critical": Style(color="red", bold=True, reverse=True),
60 |     "log.level": Style.null(),
61 |     "log.time": Style(color="cyan", dim=True),
62 |     "log.message": Style.null(),
63 |     "log.path": Style(dim=True),
64 |     "repr.ellipsis": Style(color="yellow"),
65 |     "repr.indent": Style(color="green", dim=True),
66 |     "repr.error": Style(color="red", bold=True),
67 |     "repr.str": Style(color="green", italic=False, bold=False),
68 |     "repr.brace": Style(bold=True),
69 |     "repr.comma": Style(bold=True),
70 |     "repr.ipv4": Style(bold=True, color="bright_green"),
71 |     "repr.ipv6": Style(bold=True, color="bright_green"),
72 |     "repr.eui48": Style(bold=True, color="bright_green"),
73 |     "repr.eui64": Style(bold=True, color="bright_green"),
74 |     "repr.tag_start": Style(bold=True),
75 |     "repr.tag_name": Style(color="bright_magenta", bold=True),
76 |     "repr.tag_contents": Style(color="default"),
77 |     "repr.tag_end": Style(bold=True),
78 |     "repr.attrib_name": Style(color="yellow", italic=False),
79 |     "repr.attrib_equal": Style(bold=True),
80 |     "repr.attrib_value": Style(color="magenta", italic=False),
81 |     "repr.number": Style(color="cyan", bold=True, italic=False),
82 |     "repr.number_complex": Style(color="cyan", bold=True, italic=False),  # same
83 |     "repr.bool_true": Style(color="bright_green", italic=True),
84 |     "repr.bool_false": Style(color="bright_red", italic=True),
85 |     "repr.none": Style(color="magenta", italic=True),
86 |     "repr.url": Style(underline=True, color="bright_blue", italic=False, bold=False),
87 |     "repr.uuid": Style(color="bright_yellow", bold=False),
88 |     "repr.call": Style(color="magenta", bold=True),
89 |     "repr.path": Style(color="magenta"),
90 |     "repr.filename": Style(color="bright_magenta"),
91 |     "rule.line": Style(color="bright_green"),
92 |     "rule.text": Style.null(),
93 |     "json.brace": Style(bold=True),
94 |     "json.bool_true": Style(color="bright_green", italic=True),
95 |     "json.bool_false": Style(color="bright_red", italic=True),
96 |     "json.null": Style(color="magenta", italic=True),
97 |     "json.number": Style(color="cyan", bold=True, italic=False),
98 |     "json.str": Style(color="green", italic=False, bold=False),
99 |     "json.key": Style(color="blue", bold=True),
100 |     "prompt": Style.null(),
101 |     "prompt.choices": Style(color="magenta", bold=True),
102 |     "prompt.default": Style(color="cyan", bold=True),
103 |     "prompt.invalid": Style(color="red"),
104 |     "prompt.invalid.choice": Style(color="red"),
105 |     "pretty": Style.null(),
106 |     "scope.border": Style(color="blue"),
107 |     "scope.key": Style(color="yellow", italic=True),
108 |     "scope.key.special": Style(color="yellow", italic=True, dim=True),
109 |     "scope.equals": Style(color="red"),
110 |     "table.header": Style(bold=True),
111 |     "table.footer": Style(bold=True),
112 |     "table.cell": Style.null(),
113 |     "table.title": Style(italic=True),
114 |     "table.caption": Style(italic=True, dim=True),
115 |     "traceback.error": Style(color="red", italic=True),
116 |     "traceback.border.syntax_error": Style(color="bright_red"),
117 |     "traceback.border": Style(color="red"),
118 |     "traceback.text": Style.null(),
119 |     "traceback.title": Style(color="red", bold=True),
120 |     "traceback.exc_type": Style(color="bright_red", bold=True),
121 |     "traceback.exc_value": Style.null(),
122 |     "traceback.offset": Style(color="bright_red", bold=True),
123 |     "traceback.error_range": Style(underline=True, bold=True),
124 |     "traceback.note": Style(color="green", bold=True),
125 |     "traceback.group.border": Style(color="magenta"),
126 |     "bar.back": Style(color="grey23"),
127 |     "bar.complete": Style(color="rgb(249,38,114)"),
128 |     "bar.finished": Style(color="rgb(114,156,31)"),
129 |     "bar.pulse": Style(color="rgb(249,38,114)"),
130 |     "progress.description": Style.null(),
131 |     "progress.filesize": Style(color="green"),
132 |     "progress.filesize.total": Style(color="green"),
133 |     "progress.download": Style(color="green"),
134 |     "progress.elapsed": Style(color="yellow"),
135 |     "progress.percentage": Style(color="magenta"),
136 |     "progress.remaining": Style(color="cyan"),
137 |     "progress.data.speed": Style(color="red"),
138 |     "progress.spinner": Style(color="green"),
139 |     "status.spinner": Style(color="green"),
140 |     "tree": Style(),
141 |     "tree.line": Style(),
142 |     "markdown.paragraph": Style(),
143 |     "markdown.text": Style(),
144 |     "markdown.em": Style(italic=True),
145 |     "markdown.emph": Style(italic=True),  # For commonmark backwards compatibility
146 |     "markdown.strong": Style(bold=True),
147 |     "markdown.code": Style(bold=True, color="cyan", bgcolor="black"),
148 |     "markdown.code_block": Style(color="cyan", bgcolor="black"),
149 |     "markdown.block_quote": Style(color="magenta"),
150 |     "markdown.list": Style(color="cyan"),
151 |     "markdown.item": Style(),
152 |     "markdown.item.bullet": Style(color="yellow", bold=True),
153 |     "markdown.item.number": Style(color="yellow", bold=True),
154 |     "markdown.hr": Style(color="yellow"),
155 |     "markdown.h1.border": Style(),
156 |     "markdown.h1": Style(bold=True),
157 |     "markdown.h2": Style(bold=True, underline=True),
158 |     "markdown.h3": Style(bold=True),
159 |     "markdown.h4": Style(bold=True, dim=True),
160 |     "markdown.h5": Style(underline=True),
161 |     "markdown.h6": Style(italic=True),
162 |     "markdown.h7": Style(italic=True, dim=True),
163 |     "markdown.link": Style(color="bright_blue"),
164 |     "markdown.link_url": Style(color="blue", underline=True),
165 |     "markdown.s": Style(strike=True),
166 |     "iso8601.date": Style(color="blue"),
167 |     "iso8601.time": Style(color="magenta"),
168 |     "iso8601.timezone": Style(color="yellow"),
169 | }
170 | 
171 | 
172 | if __name__ == "__main__":  # pragma: no cover
173 |     import argparse
174 |     import io
175 | 
176 |     from pip._vendor.rich.console import Console
177 |     from pip._vendor.rich.table import Table
178 |     from pip._vendor.rich.text import Text
179 | 
180 |     parser = argparse.ArgumentParser()
181 |     parser.add_argument("--html", action="store_true", help="Export as HTML table")
182 |     args = parser.parse_args()
183 |     html: bool = args.html
184 |     console = Console(record=True, width=70, file=io.StringIO()) if html else Console()
185 | 
186 |     table = Table("Name", "Styling")
187 | 
188 |     for style_name, style in DEFAULT_STYLES.items():
189 |         table.add_row(Text(style_name, style=style), str(style))
190 | 
191 |     console.print(table)
192 |     if html:
193 |         print(console.export_html(inline_styles=True))
```

.venv/lib/python3.13/site-packages/pip/_vendor/rich/diagnose.py
```
1 | import os
2 | import platform
3 | 
4 | from pip._vendor.rich import inspect
5 | from pip._vendor.rich.console import Console, get_windows_console_features
6 | from pip._vendor.rich.panel import Panel
7 | from pip._vendor.rich.pretty import Pretty
8 | 
9 | 
10 | def report() -> None:  # pragma: no cover
11 |     """Print a report to the terminal with debugging information"""
12 |     console = Console()
13 |     inspect(console)
14 |     features = get_windows_console_features()
15 |     inspect(features)
16 | 
17 |     env_names = (
18 |         "CLICOLOR",
19 |         "COLORTERM",
20 |         "COLUMNS",
21 |         "JPY_PARENT_PID",
22 |         "JUPYTER_COLUMNS",
23 |         "JUPYTER_LINES",
24 |         "LINES",
25 |         "NO_COLOR",
26 |         "TERM_PROGRAM",
27 |         "TERM",
28 |         "TTY_COMPATIBLE",
29 |         "VSCODE_VERBOSE_LOGGING",
30 |     )
31 |     env = {name: os.getenv(name) for name in env_names}
32 |     console.print(Panel.fit((Pretty(env)), title="[b]Environment Variables"))
33 | 
34 |     console.print(f'platform="{platform.system()}"')
35 | 
36 | 
37 | if __name__ == "__main__":  # pragma: no cover
38 |     report()
```

.venv/lib/python3.13/site-packages/pip/_vendor/rich/emoji.py
```
1 | import sys
2 | from typing import TYPE_CHECKING, Optional, Union
3 | 
4 | from .jupyter import JupyterMixin
5 | from .segment import Segment
6 | from .style import Style
7 | from ._emoji_codes import EMOJI
8 | from ._emoji_replace import _emoji_replace
9 | 
10 | if sys.version_info >= (3, 8):
11 |     from typing import Literal
12 | else:
13 |     from pip._vendor.typing_extensions import Literal  # pragma: no cover
14 | 
15 | 
16 | if TYPE_CHECKING:
17 |     from .console import Console, ConsoleOptions, RenderResult
18 | 
19 | 
20 | EmojiVariant = Literal["emoji", "text"]
21 | 
22 | 
23 | class NoEmoji(Exception):
24 |     """No emoji by that name."""
25 | 
26 | 
27 | class Emoji(JupyterMixin):
28 |     __slots__ = ["name", "style", "_char", "variant"]
29 | 
30 |     VARIANTS = {"text": "\uFE0E", "emoji": "\uFE0F"}
31 | 
32 |     def __init__(
33 |         self,
34 |         name: str,
35 |         style: Union[str, Style] = "none",
36 |         variant: Optional[EmojiVariant] = None,
37 |     ) -> None:
38 |         """A single emoji character.
39 | 
40 |         Args:
41 |             name (str): Name of emoji.
42 |             style (Union[str, Style], optional): Optional style. Defaults to None.
43 | 
44 |         Raises:
45 |             NoEmoji: If the emoji doesn't exist.
46 |         """
47 |         self.name = name
48 |         self.style = style
49 |         self.variant = variant
50 |         try:
51 |             self._char = EMOJI[name]
52 |         except KeyError:
53 |             raise NoEmoji(f"No emoji called {name!r}")
54 |         if variant is not None:
55 |             self._char += self.VARIANTS.get(variant, "")
56 | 
57 |     @classmethod
58 |     def replace(cls, text: str) -> str:
59 |         """Replace emoji markup with corresponding unicode characters.
60 | 
61 |         Args:
62 |             text (str): A string with emojis codes, e.g. "Hello :smiley:!"
63 | 
64 |         Returns:
65 |             str: A string with emoji codes replaces with actual emoji.
66 |         """
67 |         return _emoji_replace(text)
68 | 
69 |     def __repr__(self) -> str:
70 |         return f"<emoji {self.name!r}>"
71 | 
72 |     def __str__(self) -> str:
73 |         return self._char
74 | 
75 |     def __rich_console__(
76 |         self, console: "Console", options: "ConsoleOptions"
77 |     ) -> "RenderResult":
78 |         yield Segment(self._char, console.get_style(self.style))
79 | 
80 | 
81 | if __name__ == "__main__":  # pragma: no cover
82 |     import sys
83 | 
84 |     from pip._vendor.rich.columns import Columns
85 |     from pip._vendor.rich.console import Console
86 | 
87 |     console = Console(record=True)
88 | 
89 |     columns = Columns(
90 |         (f":{name}: {name}" for name in sorted(EMOJI.keys()) if "\u200D" not in name),
91 |         column_first=True,
92 |     )
93 | 
94 |     console.print(columns)
95 |     if len(sys.argv) > 1:
96 |         console.save_html(sys.argv[1])
```

.venv/lib/python3.13/site-packages/pip/_vendor/rich/errors.py
```
1 | class ConsoleError(Exception):
2 |     """An error in console operation."""
3 | 
4 | 
5 | class StyleError(Exception):
6 |     """An error in styles."""
7 | 
8 | 
9 | class StyleSyntaxError(ConsoleError):
10 |     """Style was badly formatted."""
11 | 
12 | 
13 | class MissingStyle(StyleError):
14 |     """No such style."""
15 | 
16 | 
17 | class StyleStackError(ConsoleError):
18 |     """Style stack is invalid."""
19 | 
20 | 
21 | class NotRenderableError(ConsoleError):
22 |     """Object is not renderable."""
23 | 
24 | 
25 | class MarkupError(ConsoleError):
26 |     """Markup was badly formatted."""
27 | 
28 | 
29 | class LiveError(ConsoleError):
30 |     """Error related to Live display."""
31 | 
32 | 
33 | class NoAltScreen(ConsoleError):
34 |     """Alt screen mode was required."""
```

.venv/lib/python3.13/site-packages/pip/_vendor/rich/file_proxy.py
```
1 | import io
2 | from typing import IO, TYPE_CHECKING, Any, List
3 | 
4 | from .ansi import AnsiDecoder
5 | from .text import Text
6 | 
7 | if TYPE_CHECKING:
8 |     from .console import Console
9 | 
10 | 
11 | class FileProxy(io.TextIOBase):
12 |     """Wraps a file (e.g. sys.stdout) and redirects writes to a console."""
13 | 
14 |     def __init__(self, console: "Console", file: IO[str]) -> None:
15 |         self.__console = console
16 |         self.__file = file
17 |         self.__buffer: List[str] = []
18 |         self.__ansi_decoder = AnsiDecoder()
19 | 
20 |     @property
21 |     def rich_proxied_file(self) -> IO[str]:
22 |         """Get proxied file."""
23 |         return self.__file
24 | 
25 |     def __getattr__(self, name: str) -> Any:
26 |         return getattr(self.__file, name)
27 | 
28 |     def write(self, text: str) -> int:
29 |         if not isinstance(text, str):
30 |             raise TypeError(f"write() argument must be str, not {type(text).__name__}")
31 |         buffer = self.__buffer
32 |         lines: List[str] = []
33 |         while text:
34 |             line, new_line, text = text.partition("\n")
35 |             if new_line:
36 |                 lines.append("".join(buffer) + line)
37 |                 buffer.clear()
38 |             else:
39 |                 buffer.append(line)
40 |                 break
41 |         if lines:
42 |             console = self.__console
43 |             with console:
44 |                 output = Text("\n").join(
45 |                     self.__ansi_decoder.decode_line(line) for line in lines
46 |                 )
47 |                 console.print(output)
48 |         return len(text)
49 | 
50 |     def flush(self) -> None:
51 |         output = "".join(self.__buffer)
52 |         if output:
53 |             self.__console.print(output)
54 |         del self.__buffer[:]
55 | 
56 |     def fileno(self) -> int:
57 |         return self.__file.fileno()
```

.venv/lib/python3.13/site-packages/pip/_vendor/rich/filesize.py
```
1 | """Functions for reporting filesizes. Borrowed from https://github.com/PyFilesystem/pyfilesystem2
2 | 
3 | The functions declared in this module should cover the different
4 | use cases needed to generate a string representation of a file size
5 | using several different units. Since there are many standards regarding
6 | file size units, three different functions have been implemented.
7 | 
8 | See Also:
9 |     * `Wikipedia: Binary prefix <https://en.wikipedia.org/wiki/Binary_prefix>`_
10 | 
11 | """
12 | 
13 | __all__ = ["decimal"]
14 | 
15 | from typing import Iterable, List, Optional, Tuple
16 | 
17 | 
18 | def _to_str(
19 |     size: int,
20 |     suffixes: Iterable[str],
21 |     base: int,
22 |     *,
23 |     precision: Optional[int] = 1,
24 |     separator: Optional[str] = " ",
25 | ) -> str:
26 |     if size == 1:
27 |         return "1 byte"
28 |     elif size < base:
29 |         return f"{size:,} bytes"
30 | 
31 |     for i, suffix in enumerate(suffixes, 2):  # noqa: B007
32 |         unit = base**i
33 |         if size < unit:
34 |             break
35 |     return "{:,.{precision}f}{separator}{}".format(
36 |         (base * size / unit),
37 |         suffix,
38 |         precision=precision,
39 |         separator=separator,
40 |     )
41 | 
42 | 
43 | def pick_unit_and_suffix(size: int, suffixes: List[str], base: int) -> Tuple[int, str]:
44 |     """Pick a suffix and base for the given size."""
45 |     for i, suffix in enumerate(suffixes):
46 |         unit = base**i
47 |         if size < unit * base:
48 |             break
49 |     return unit, suffix
50 | 
51 | 
52 | def decimal(
53 |     size: int,
54 |     *,
55 |     precision: Optional[int] = 1,
56 |     separator: Optional[str] = " ",
57 | ) -> str:
58 |     """Convert a filesize in to a string (powers of 1000, SI prefixes).
59 | 
60 |     In this convention, ``1000 B = 1 kB``.
61 | 
62 |     This is typically the format used to advertise the storage
63 |     capacity of USB flash drives and the like (*256 MB* meaning
64 |     actually a storage capacity of more than *256 000 000 B*),
65 |     or used by **Mac OS X** since v10.6 to report file sizes.
66 | 
67 |     Arguments:
68 |         int (size): A file size.
69 |         int (precision): The number of decimal places to include (default = 1).
70 |         str (separator): The string to separate the value from the units (default = " ").
71 | 
72 |     Returns:
73 |         `str`: A string containing a abbreviated file size and units.
74 | 
75 |     Example:
76 |         >>> filesize.decimal(30000)
77 |         '30.0 kB'
78 |         >>> filesize.decimal(30000, precision=2, separator="")
79 |         '30.00kB'
80 | 
81 |     """
82 |     return _to_str(
83 |         size,
84 |         ("kB", "MB", "GB", "TB", "PB", "EB", "ZB", "YB"),
85 |         1000,
86 |         precision=precision,
87 |         separator=separator,
88 |     )
```

.venv/lib/python3.13/site-packages/pip/_vendor/rich/highlighter.py
```
1 | import re
2 | from abc import ABC, abstractmethod
3 | from typing import List, Union
4 | 
5 | from .text import Span, Text
6 | 
7 | 
8 | def _combine_regex(*regexes: str) -> str:
9 |     """Combine a number of regexes in to a single regex.
10 | 
11 |     Returns:
12 |         str: New regex with all regexes ORed together.
13 |     """
14 |     return "|".join(regexes)
15 | 
16 | 
17 | class Highlighter(ABC):
18 |     """Abstract base class for highlighters."""
19 | 
20 |     def __call__(self, text: Union[str, Text]) -> Text:
21 |         """Highlight a str or Text instance.
22 | 
23 |         Args:
24 |             text (Union[str, ~Text]): Text to highlight.
25 | 
26 |         Raises:
27 |             TypeError: If not called with text or str.
28 | 
29 |         Returns:
30 |             Text: A test instance with highlighting applied.
31 |         """
32 |         if isinstance(text, str):
33 |             highlight_text = Text(text)
34 |         elif isinstance(text, Text):
35 |             highlight_text = text.copy()
36 |         else:
37 |             raise TypeError(f"str or Text instance required, not {text!r}")
38 |         self.highlight(highlight_text)
39 |         return highlight_text
40 | 
41 |     @abstractmethod
42 |     def highlight(self, text: Text) -> None:
43 |         """Apply highlighting in place to text.
44 | 
45 |         Args:
46 |             text (~Text): A text object highlight.
47 |         """
48 | 
49 | 
50 | class NullHighlighter(Highlighter):
51 |     """A highlighter object that doesn't highlight.
52 | 
53 |     May be used to disable highlighting entirely.
54 | 
55 |     """
56 | 
57 |     def highlight(self, text: Text) -> None:
58 |         """Nothing to do"""
59 | 
60 | 
61 | class RegexHighlighter(Highlighter):
62 |     """Applies highlighting from a list of regular expressions."""
63 | 
64 |     highlights: List[str] = []
65 |     base_style: str = ""
66 | 
67 |     def highlight(self, text: Text) -> None:
68 |         """Highlight :class:`rich.text.Text` using regular expressions.
69 | 
70 |         Args:
71 |             text (~Text): Text to highlighted.
72 | 
73 |         """
74 | 
75 |         highlight_regex = text.highlight_regex
76 |         for re_highlight in self.highlights:
77 |             highlight_regex(re_highlight, style_prefix=self.base_style)
78 | 
79 | 
80 | class ReprHighlighter(RegexHighlighter):
81 |     """Highlights the text typically produced from ``__repr__`` methods."""
82 | 
83 |     base_style = "repr."
84 |     highlights = [
85 |         r"(?P<tag_start><)(?P<tag_name>[-\w.:|]*)(?P<tag_contents>[\w\W]*)(?P<tag_end>>)",
86 |         r'(?P<attrib_name>[\w_]{1,50})=(?P<attrib_value>"?[\w_]+"?)?',
87 |         r"(?P<brace>[][{}()])",
88 |         _combine_regex(
89 |             r"(?P<ipv4>[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3})",
90 |             r"(?P<ipv6>([A-Fa-f0-9]{1,4}::?){1,7}[A-Fa-f0-9]{1,4})",
91 |             r"(?P<eui64>(?:[0-9A-Fa-f]{1,2}-){7}[0-9A-Fa-f]{1,2}|(?:[0-9A-Fa-f]{1,2}:){7}[0-9A-Fa-f]{1,2}|(?:[0-9A-Fa-f]{4}\.){3}[0-9A-Fa-f]{4})",
92 |             r"(?P<eui48>(?:[0-9A-Fa-f]{1,2}-){5}[0-9A-Fa-f]{1,2}|(?:[0-9A-Fa-f]{1,2}:){5}[0-9A-Fa-f]{1,2}|(?:[0-9A-Fa-f]{4}\.){2}[0-9A-Fa-f]{4})",
93 |             r"(?P<uuid>[a-fA-F0-9]{8}-[a-fA-F0-9]{4}-[a-fA-F0-9]{4}-[a-fA-F0-9]{4}-[a-fA-F0-9]{12})",
94 |             r"(?P<call>[\w.]*?)\(",
95 |             r"\b(?P<bool_true>True)\b|\b(?P<bool_false>False)\b|\b(?P<none>None)\b",
96 |             r"(?P<ellipsis>\.\.\.)",
97 |             r"(?P<number_complex>(?<!\w)(?:\-?[0-9]+\.?[0-9]*(?:e[-+]?\d+?)?)(?:[-+](?:[0-9]+\.?[0-9]*(?:e[-+]?\d+)?))?j)",
98 |             r"(?P<number>(?<!\w)\-?[0-9]+\.?[0-9]*(e[-+]?\d+?)?\b|0x[0-9a-fA-F]*)",
99 |             r"(?P<path>\B(/[-\w._+]+)*\/)(?P<filename>[-\w._+]*)?",
100 |             r"(?<![\\\w])(?P<str>b?'''.*?(?<!\\)'''|b?'.*?(?<!\\)'|b?\"\"\".*?(?<!\\)\"\"\"|b?\".*?(?<!\\)\")",
101 |             r"(?P<url>(file|https|http|ws|wss)://[-0-9a-zA-Z$_+!`(),.?/;:&=%#~@]*)",
102 |         ),
103 |     ]
104 | 
105 | 
106 | class JSONHighlighter(RegexHighlighter):
107 |     """Highlights JSON"""
108 | 
109 |     # Captures the start and end of JSON strings, handling escaped quotes
110 |     JSON_STR = r"(?<![\\\w])(?P<str>b?\".*?(?<!\\)\")"
111 |     JSON_WHITESPACE = {" ", "\n", "\r", "\t"}
112 | 
113 |     base_style = "json."
114 |     highlights = [
115 |         _combine_regex(
116 |             r"(?P<brace>[\{\[\(\)\]\}])",
117 |             r"\b(?P<bool_true>true)\b|\b(?P<bool_false>false)\b|\b(?P<null>null)\b",
118 |             r"(?P<number>(?<!\w)\-?[0-9]+\.?[0-9]*(e[\-\+]?\d+?)?\b|0x[0-9a-fA-F]*)",
119 |             JSON_STR,
120 |         ),
121 |     ]
122 | 
123 |     def highlight(self, text: Text) -> None:
124 |         super().highlight(text)
125 | 
126 |         # Additional work to handle highlighting JSON keys
127 |         plain = text.plain
128 |         append = text.spans.append
129 |         whitespace = self.JSON_WHITESPACE
130 |         for match in re.finditer(self.JSON_STR, plain):
131 |             start, end = match.span()
132 |             cursor = end
133 |             while cursor < len(plain):
134 |                 char = plain[cursor]
135 |                 cursor += 1
136 |                 if char == ":":
137 |                     append(Span(start, end, "json.key"))
138 |                 elif char in whitespace:
139 |                     continue
140 |                 break
141 | 
142 | 
143 | class ISO8601Highlighter(RegexHighlighter):
144 |     """Highlights the ISO8601 date time strings.
145 |     Regex reference: https://www.oreilly.com/library/view/regular-expressions-cookbook/9781449327453/ch04s07.html
146 |     """
147 | 
148 |     base_style = "iso8601."
149 |     highlights = [
150 |         #
151 |         # Dates
152 |         #
153 |         # Calendar month (e.g. 2008-08). The hyphen is required
154 |         r"^(?P<year>[0-9]{4})-(?P<month>1[0-2]|0[1-9])$",
155 |         # Calendar date w/o hyphens (e.g. 20080830)
156 |         r"^(?P<date>(?P<year>[0-9]{4})(?P<month>1[0-2]|0[1-9])(?P<day>3[01]|0[1-9]|[12][0-9]))$",
157 |         # Ordinal date (e.g. 2008-243). The hyphen is optional
158 |         r"^(?P<date>(?P<year>[0-9]{4})-?(?P<day>36[0-6]|3[0-5][0-9]|[12][0-9]{2}|0[1-9][0-9]|00[1-9]))$",
159 |         #
160 |         # Weeks
161 |         #
162 |         # Week of the year (e.g., 2008-W35). The hyphen is optional
163 |         r"^(?P<date>(?P<year>[0-9]{4})-?W(?P<week>5[0-3]|[1-4][0-9]|0[1-9]))$",
164 |         # Week date (e.g., 2008-W35-6). The hyphens are optional
165 |         r"^(?P<date>(?P<year>[0-9]{4})-?W(?P<week>5[0-3]|[1-4][0-9]|0[1-9])-?(?P<day>[1-7]))$",
166 |         #
167 |         # Times
168 |         #
169 |         # Hours and minutes (e.g., 17:21). The colon is optional
170 |         r"^(?P<time>(?P<hour>2[0-3]|[01][0-9]):?(?P<minute>[0-5][0-9]))$",
171 |         # Hours, minutes, and seconds w/o colons (e.g., 172159)
172 |         r"^(?P<time>(?P<hour>2[0-3]|[01][0-9])(?P<minute>[0-5][0-9])(?P<second>[0-5][0-9]))$",
173 |         # Time zone designator (e.g., Z, +07 or +07:00). The colons and the minutes are optional
174 |         r"^(?P<timezone>(Z|[+-](?:2[0-3]|[01][0-9])(?::?(?:[0-5][0-9]))?))$",
175 |         # Hours, minutes, and seconds with time zone designator (e.g., 17:21:59+07:00).
176 |         # All the colons are optional. The minutes in the time zone designator are also optional
177 |         r"^(?P<time>(?P<hour>2[0-3]|[01][0-9])(?P<minute>[0-5][0-9])(?P<second>[0-5][0-9]))(?P<timezone>Z|[+-](?:2[0-3]|[01][0-9])(?::?(?:[0-5][0-9]))?)$",
178 |         #
179 |         # Date and Time
180 |         #
181 |         # Calendar date with hours, minutes, and seconds (e.g., 2008-08-30 17:21:59 or 20080830 172159).
182 |         # A space is required between the date and the time. The hyphens and colons are optional.
183 |         # This regex matches dates and times that specify some hyphens or colons but omit others.
184 |         # This does not follow ISO 8601
185 |         r"^(?P<date>(?P<year>[0-9]{4})(?P<hyphen>-)?(?P<month>1[0-2]|0[1-9])(?(hyphen)-)(?P<day>3[01]|0[1-9]|[12][0-9])) (?P<time>(?P<hour>2[0-3]|[01][0-9])(?(hyphen):)(?P<minute>[0-5][0-9])(?(hyphen):)(?P<second>[0-5][0-9]))$",
186 |         #
187 |         # XML Schema dates and times
188 |         #
189 |         # Date, with optional time zone (e.g., 2008-08-30 or 2008-08-30+07:00).
190 |         # Hyphens are required. This is the XML Schema 'date' type
191 |         r"^(?P<date>(?P<year>-?(?:[1-9][0-9]*)?[0-9]{4})-(?P<month>1[0-2]|0[1-9])-(?P<day>3[01]|0[1-9]|[12][0-9]))(?P<timezone>Z|[+-](?:2[0-3]|[01][0-9]):[0-5][0-9])?$",
192 |         # Time, with optional fractional seconds and time zone (e.g., 01:45:36 or 01:45:36.123+07:00).
193 |         # There is no limit on the number of digits for the fractional seconds. This is the XML Schema 'time' type
194 |         r"^(?P<time>(?P<hour>2[0-3]|[01][0-9]):(?P<minute>[0-5][0-9]):(?P<second>[0-5][0-9])(?P<frac>\.[0-9]+)?)(?P<timezone>Z|[+-](?:2[0-3]|[01][0-9]):[0-5][0-9])?$",
195 |         # Date and time, with optional fractional seconds and time zone (e.g., 2008-08-30T01:45:36 or 2008-08-30T01:45:36.123Z).
196 |         # This is the XML Schema 'dateTime' type
197 |         r"^(?P<date>(?P<year>-?(?:[1-9][0-9]*)?[0-9]{4})-(?P<month>1[0-2]|0[1-9])-(?P<day>3[01]|0[1-9]|[12][0-9]))T(?P<time>(?P<hour>2[0-3]|[01][0-9]):(?P<minute>[0-5][0-9]):(?P<second>[0-5][0-9])(?P<ms>\.[0-9]+)?)(?P<timezone>Z|[+-](?:2[0-3]|[01][0-9]):[0-5][0-9])?$",
198 |     ]
199 | 
200 | 
201 | if __name__ == "__main__":  # pragma: no cover
202 |     from .console import Console
203 | 
204 |     console = Console()
205 |     console.print("[bold green]hello world![/bold green]")
206 |     console.print("'[bold green]hello world![/bold green]'")
207 | 
208 |     console.print(" /foo")
209 |     console.print("/foo/")
210 |     console.print("/foo/bar")
211 |     console.print("foo/bar/baz")
212 | 
213 |     console.print("/foo/bar/baz?foo=bar+egg&egg=baz")
214 |     console.print("/foo/bar/baz/")
215 |     console.print("/foo/bar/baz/egg")
216 |     console.print("/foo/bar/baz/egg.py")
217 |     console.print("/foo/bar/baz/egg.py word")
218 |     console.print(" /foo/bar/baz/egg.py word")
219 |     console.print("foo /foo/bar/baz/egg.py word")
220 |     console.print("foo /foo/bar/ba._++z/egg+.py word")
221 |     console.print("https://example.org?foo=bar#header")
222 | 
223 |     console.print(1234567.34)
224 |     console.print(1 / 2)
225 |     console.print(-1 / 123123123123)
226 | 
227 |     console.print(
228 |         "127.0.1.1 bar 192.168.1.4 2001:0db8:85a3:0000:0000:8a2e:0370:7334 foo"
229 |     )
230 |     import json
231 | 
232 |     console.print_json(json.dumps(obj={"name": "apple", "count": 1}), indent=None)
```

.venv/lib/python3.13/site-packages/pip/_vendor/rich/json.py
```
1 | from pathlib import Path
2 | from json import loads, dumps
3 | from typing import Any, Callable, Optional, Union
4 | 
5 | from .text import Text
6 | from .highlighter import JSONHighlighter, NullHighlighter
7 | 
8 | 
9 | class JSON:
10 |     """A renderable which pretty prints JSON.
11 | 
12 |     Args:
13 |         json (str): JSON encoded data.
14 |         indent (Union[None, int, str], optional): Number of characters to indent by. Defaults to 2.
15 |         highlight (bool, optional): Enable highlighting. Defaults to True.
16 |         skip_keys (bool, optional): Skip keys not of a basic type. Defaults to False.
17 |         ensure_ascii (bool, optional): Escape all non-ascii characters. Defaults to False.
18 |         check_circular (bool, optional): Check for circular references. Defaults to True.
19 |         allow_nan (bool, optional): Allow NaN and Infinity values. Defaults to True.
20 |         default (Callable, optional): A callable that converts values that can not be encoded
21 |             in to something that can be JSON encoded. Defaults to None.
22 |         sort_keys (bool, optional): Sort dictionary keys. Defaults to False.
23 |     """
24 | 
25 |     def __init__(
26 |         self,
27 |         json: str,
28 |         indent: Union[None, int, str] = 2,
29 |         highlight: bool = True,
30 |         skip_keys: bool = False,
31 |         ensure_ascii: bool = False,
32 |         check_circular: bool = True,
33 |         allow_nan: bool = True,
34 |         default: Optional[Callable[[Any], Any]] = None,
35 |         sort_keys: bool = False,
36 |     ) -> None:
37 |         data = loads(json)
38 |         json = dumps(
39 |             data,
40 |             indent=indent,
41 |             skipkeys=skip_keys,
42 |             ensure_ascii=ensure_ascii,
43 |             check_circular=check_circular,
44 |             allow_nan=allow_nan,
45 |             default=default,
46 |             sort_keys=sort_keys,
47 |         )
48 |         highlighter = JSONHighlighter() if highlight else NullHighlighter()
49 |         self.text = highlighter(json)
50 |         self.text.no_wrap = True
51 |         self.text.overflow = None
52 | 
53 |     @classmethod
54 |     def from_data(
55 |         cls,
56 |         data: Any,
57 |         indent: Union[None, int, str] = 2,
58 |         highlight: bool = True,
59 |         skip_keys: bool = False,
60 |         ensure_ascii: bool = False,
61 |         check_circular: bool = True,
62 |         allow_nan: bool = True,
63 |         default: Optional[Callable[[Any], Any]] = None,
64 |         sort_keys: bool = False,
65 |     ) -> "JSON":
66 |         """Encodes a JSON object from arbitrary data.
67 | 
68 |         Args:
69 |             data (Any): An object that may be encoded in to JSON
70 |             indent (Union[None, int, str], optional): Number of characters to indent by. Defaults to 2.
71 |             highlight (bool, optional): Enable highlighting. Defaults to True.
72 |             default (Callable, optional): Optional callable which will be called for objects that cannot be serialized. Defaults to None.
73 |             skip_keys (bool, optional): Skip keys not of a basic type. Defaults to False.
74 |             ensure_ascii (bool, optional): Escape all non-ascii characters. Defaults to False.
75 |             check_circular (bool, optional): Check for circular references. Defaults to True.
76 |             allow_nan (bool, optional): Allow NaN and Infinity values. Defaults to True.
77 |             default (Callable, optional): A callable that converts values that can not be encoded
78 |                 in to something that can be JSON encoded. Defaults to None.
79 |             sort_keys (bool, optional): Sort dictionary keys. Defaults to False.
80 | 
81 |         Returns:
82 |             JSON: New JSON object from the given data.
83 |         """
84 |         json_instance: "JSON" = cls.__new__(cls)
85 |         json = dumps(
86 |             data,
87 |             indent=indent,
88 |             skipkeys=skip_keys,
89 |             ensure_ascii=ensure_ascii,
90 |             check_circular=check_circular,
91 |             allow_nan=allow_nan,
92 |             default=default,
93 |             sort_keys=sort_keys,
94 |         )
95 |         highlighter = JSONHighlighter() if highlight else NullHighlighter()
96 |         json_instance.text = highlighter(json)
97 |         json_instance.text.no_wrap = True
98 |         json_instance.text.overflow = None
99 |         return json_instance
100 | 
101 |     def __rich__(self) -> Text:
102 |         return self.text
103 | 
104 | 
105 | if __name__ == "__main__":
106 |     import argparse
107 |     import sys
108 | 
109 |     parser = argparse.ArgumentParser(description="Pretty print json")
110 |     parser.add_argument(
111 |         "path",
112 |         metavar="PATH",
113 |         help="path to file, or - for stdin",
114 |     )
115 |     parser.add_argument(
116 |         "-i",
117 |         "--indent",
118 |         metavar="SPACES",
119 |         type=int,
120 |         help="Number of spaces in an indent",
121 |         default=2,
122 |     )
123 |     args = parser.parse_args()
124 | 
125 |     from pip._vendor.rich.console import Console
126 | 
127 |     console = Console()
128 |     error_console = Console(stderr=True)
129 | 
130 |     try:
131 |         if args.path == "-":
132 |             json_data = sys.stdin.read()
133 |         else:
134 |             json_data = Path(args.path).read_text()
135 |     except Exception as error:
136 |         error_console.print(f"Unable to read {args.path!r}; {error}")
137 |         sys.exit(-1)
138 | 
139 |     console.print(JSON(json_data, indent=args.indent), soft_wrap=True)
```

.venv/lib/python3.13/site-packages/pip/_vendor/rich/jupyter.py
```
1 | from typing import TYPE_CHECKING, Any, Dict, Iterable, List, Sequence
2 | 
3 | if TYPE_CHECKING:
4 |     from pip._vendor.rich.console import ConsoleRenderable
5 | 
6 | from . import get_console
7 | from .segment import Segment
8 | from .terminal_theme import DEFAULT_TERMINAL_THEME
9 | 
10 | if TYPE_CHECKING:
11 |     from pip._vendor.rich.console import ConsoleRenderable
12 | 
13 | JUPYTER_HTML_FORMAT = """\
14 | <pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">{code}</pre>
15 | """
16 | 
17 | 
18 | class JupyterRenderable:
19 |     """A shim to write html to Jupyter notebook."""
20 | 
21 |     def __init__(self, html: str, text: str) -> None:
22 |         self.html = html
23 |         self.text = text
24 | 
25 |     def _repr_mimebundle_(
26 |         self, include: Sequence[str], exclude: Sequence[str], **kwargs: Any
27 |     ) -> Dict[str, str]:
28 |         data = {"text/plain": self.text, "text/html": self.html}
29 |         if include:
30 |             data = {k: v for (k, v) in data.items() if k in include}
31 |         if exclude:
32 |             data = {k: v for (k, v) in data.items() if k not in exclude}
33 |         return data
34 | 
35 | 
36 | class JupyterMixin:
37 |     """Add to an Rich renderable to make it render in Jupyter notebook."""
38 | 
39 |     __slots__ = ()
40 | 
41 |     def _repr_mimebundle_(
42 |         self: "ConsoleRenderable",
43 |         include: Sequence[str],
44 |         exclude: Sequence[str],
45 |         **kwargs: Any,
46 |     ) -> Dict[str, str]:
47 |         console = get_console()
48 |         segments = list(console.render(self, console.options))
49 |         html = _render_segments(segments)
50 |         text = console._render_buffer(segments)
51 |         data = {"text/plain": text, "text/html": html}
52 |         if include:
53 |             data = {k: v for (k, v) in data.items() if k in include}
54 |         if exclude:
55 |             data = {k: v for (k, v) in data.items() if k not in exclude}
56 |         return data
57 | 
58 | 
59 | def _render_segments(segments: Iterable[Segment]) -> str:
60 |     def escape(text: str) -> str:
61 |         """Escape html."""
62 |         return text.replace("&", "&amp;").replace("<", "&lt;").replace(">", "&gt;")
63 | 
64 |     fragments: List[str] = []
65 |     append_fragment = fragments.append
66 |     theme = DEFAULT_TERMINAL_THEME
67 |     for text, style, control in Segment.simplify(segments):
68 |         if control:
69 |             continue
70 |         text = escape(text)
71 |         if style:
72 |             rule = style.get_html_style(theme)
73 |             text = f'<span style="{rule}">{text}</span>' if rule else text
74 |             if style.link:
75 |                 text = f'<a href="{style.link}" target="_blank">{text}</a>'
76 |         append_fragment(text)
77 | 
78 |     code = "".join(fragments)
79 |     html = JUPYTER_HTML_FORMAT.format(code=code)
80 | 
81 |     return html
82 | 
83 | 
84 | def display(segments: Iterable[Segment], text: str) -> None:
85 |     """Render segments to Jupyter."""
86 |     html = _render_segments(segments)
87 |     jupyter_renderable = JupyterRenderable(html, text)
88 |     try:
89 |         from IPython.display import display as ipython_display
90 | 
91 |         ipython_display(jupyter_renderable)
92 |     except ModuleNotFoundError:
93 |         # Handle the case where the Console has force_jupyter=True,
94 |         # but IPython is not installed.
95 |         pass
96 | 
97 | 
98 | def print(*args: Any, **kwargs: Any) -> None:
99 |     """Proxy for Console print."""
100 |     console = get_console()
101 |     return console.print(*args, **kwargs)
```

.venv/lib/python3.13/site-packages/pip/_vendor/rich/layout.py
```
1 | from abc import ABC, abstractmethod
2 | from itertools import islice
3 | from operator import itemgetter
4 | from threading import RLock
5 | from typing import (
6 |     TYPE_CHECKING,
7 |     Dict,
8 |     Iterable,
9 |     List,
10 |     NamedTuple,
11 |     Optional,
12 |     Sequence,
13 |     Tuple,
14 |     Union,
15 | )
16 | 
17 | from ._ratio import ratio_resolve
18 | from .align import Align
19 | from .console import Console, ConsoleOptions, RenderableType, RenderResult
20 | from .highlighter import ReprHighlighter
21 | from .panel import Panel
22 | from .pretty import Pretty
23 | from .region import Region
24 | from .repr import Result, rich_repr
25 | from .segment import Segment
26 | from .style import StyleType
27 | 
28 | if TYPE_CHECKING:
29 |     from pip._vendor.rich.tree import Tree
30 | 
31 | 
32 | class LayoutRender(NamedTuple):
33 |     """An individual layout render."""
34 | 
35 |     region: Region
36 |     render: List[List[Segment]]
37 | 
38 | 
39 | RegionMap = Dict["Layout", Region]
40 | RenderMap = Dict["Layout", LayoutRender]
41 | 
42 | 
43 | class LayoutError(Exception):
44 |     """Layout related error."""
45 | 
46 | 
47 | class NoSplitter(LayoutError):
48 |     """Requested splitter does not exist."""
49 | 
50 | 
51 | class _Placeholder:
52 |     """An internal renderable used as a Layout placeholder."""
53 | 
54 |     highlighter = ReprHighlighter()
55 | 
56 |     def __init__(self, layout: "Layout", style: StyleType = "") -> None:
57 |         self.layout = layout
58 |         self.style = style
59 | 
60 |     def __rich_console__(
61 |         self, console: Console, options: ConsoleOptions
62 |     ) -> RenderResult:
63 |         width = options.max_width
64 |         height = options.height or options.size.height
65 |         layout = self.layout
66 |         title = (
67 |             f"{layout.name!r} ({width} x {height})"
68 |             if layout.name
69 |             else f"({width} x {height})"
70 |         )
71 |         yield Panel(
72 |             Align.center(Pretty(layout), vertical="middle"),
73 |             style=self.style,
74 |             title=self.highlighter(title),
75 |             border_style="blue",
76 |             height=height,
77 |         )
78 | 
79 | 
80 | class Splitter(ABC):
81 |     """Base class for a splitter."""
82 | 
83 |     name: str = ""
84 | 
85 |     @abstractmethod
86 |     def get_tree_icon(self) -> str:
87 |         """Get the icon (emoji) used in layout.tree"""
88 | 
89 |     @abstractmethod
90 |     def divide(
91 |         self, children: Sequence["Layout"], region: Region
92 |     ) -> Iterable[Tuple["Layout", Region]]:
93 |         """Divide a region amongst several child layouts.
94 | 
95 |         Args:
96 |             children (Sequence(Layout)): A number of child layouts.
97 |             region (Region): A rectangular region to divide.
98 |         """
99 | 
100 | 
101 | class RowSplitter(Splitter):
102 |     """Split a layout region in to rows."""
103 | 
104 |     name = "row"
105 | 
106 |     def get_tree_icon(self) -> str:
107 |         return "[layout.tree.row]"
108 | 
109 |     def divide(
110 |         self, children: Sequence["Layout"], region: Region
111 |     ) -> Iterable[Tuple["Layout", Region]]:
112 |         x, y, width, height = region
113 |         render_widths = ratio_resolve(width, children)
114 |         offset = 0
115 |         _Region = Region
116 |         for child, child_width in zip(children, render_widths):
117 |             yield child, _Region(x + offset, y, child_width, height)
118 |             offset += child_width
119 | 
120 | 
121 | class ColumnSplitter(Splitter):
122 |     """Split a layout region in to columns."""
123 | 
124 |     name = "column"
125 | 
126 |     def get_tree_icon(self) -> str:
127 |         return "[layout.tree.column]"
128 | 
129 |     def divide(
130 |         self, children: Sequence["Layout"], region: Region
131 |     ) -> Iterable[Tuple["Layout", Region]]:
132 |         x, y, width, height = region
133 |         render_heights = ratio_resolve(height, children)
134 |         offset = 0
135 |         _Region = Region
136 |         for child, child_height in zip(children, render_heights):
137 |             yield child, _Region(x, y + offset, width, child_height)
138 |             offset += child_height
139 | 
140 | 
141 | @rich_repr
142 | class Layout:
143 |     """A renderable to divide a fixed height in to rows or columns.
144 | 
145 |     Args:
146 |         renderable (RenderableType, optional): Renderable content, or None for placeholder. Defaults to None.
147 |         name (str, optional): Optional identifier for Layout. Defaults to None.
148 |         size (int, optional): Optional fixed size of layout. Defaults to None.
149 |         minimum_size (int, optional): Minimum size of layout. Defaults to 1.
150 |         ratio (int, optional): Optional ratio for flexible layout. Defaults to 1.
151 |         visible (bool, optional): Visibility of layout. Defaults to True.
152 |     """
153 | 
154 |     splitters = {"row": RowSplitter, "column": ColumnSplitter}
155 | 
156 |     def __init__(
157 |         self,
158 |         renderable: Optional[RenderableType] = None,
159 |         *,
160 |         name: Optional[str] = None,
161 |         size: Optional[int] = None,
162 |         minimum_size: int = 1,
163 |         ratio: int = 1,
164 |         visible: bool = True,
165 |     ) -> None:
166 |         self._renderable = renderable or _Placeholder(self)
167 |         self.size = size
168 |         self.minimum_size = minimum_size
169 |         self.ratio = ratio
170 |         self.name = name
171 |         self.visible = visible
172 |         self.splitter: Splitter = self.splitters["column"]()
173 |         self._children: List[Layout] = []
174 |         self._render_map: RenderMap = {}
175 |         self._lock = RLock()
176 | 
177 |     def __rich_repr__(self) -> Result:
178 |         yield "name", self.name, None
179 |         yield "size", self.size, None
180 |         yield "minimum_size", self.minimum_size, 1
181 |         yield "ratio", self.ratio, 1
182 | 
183 |     @property
184 |     def renderable(self) -> RenderableType:
185 |         """Layout renderable."""
186 |         return self if self._children else self._renderable
187 | 
188 |     @property
189 |     def children(self) -> List["Layout"]:
190 |         """Gets (visible) layout children."""
191 |         return [child for child in self._children if child.visible]
192 | 
193 |     @property
194 |     def map(self) -> RenderMap:
195 |         """Get a map of the last render."""
196 |         return self._render_map
197 | 
198 |     def get(self, name: str) -> Optional["Layout"]:
199 |         """Get a named layout, or None if it doesn't exist.
200 | 
201 |         Args:
202 |             name (str): Name of layout.
203 | 
204 |         Returns:
205 |             Optional[Layout]: Layout instance or None if no layout was found.
206 |         """
207 |         if self.name == name:
208 |             return self
209 |         else:
210 |             for child in self._children:
211 |                 named_layout = child.get(name)
212 |                 if named_layout is not None:
213 |                     return named_layout
214 |         return None
215 | 
216 |     def __getitem__(self, name: str) -> "Layout":
217 |         layout = self.get(name)
218 |         if layout is None:
219 |             raise KeyError(f"No layout with name {name!r}")
220 |         return layout
221 | 
222 |     @property
223 |     def tree(self) -> "Tree":
224 |         """Get a tree renderable to show layout structure."""
225 |         from pip._vendor.rich.styled import Styled
226 |         from pip._vendor.rich.table import Table
227 |         from pip._vendor.rich.tree import Tree
228 | 
229 |         def summary(layout: "Layout") -> Table:
230 |             icon = layout.splitter.get_tree_icon()
231 | 
232 |             table = Table.grid(padding=(0, 1, 0, 0))
233 | 
234 |             text: RenderableType = (
235 |                 Pretty(layout) if layout.visible else Styled(Pretty(layout), "dim")
236 |             )
237 |             table.add_row(icon, text)
238 |             _summary = table
239 |             return _summary
240 | 
241 |         layout = self
242 |         tree = Tree(
243 |             summary(layout),
244 |             guide_style=f"layout.tree.{layout.splitter.name}",
245 |             highlight=True,
246 |         )
247 | 
248 |         def recurse(tree: "Tree", layout: "Layout") -> None:
249 |             for child in layout._children:
250 |                 recurse(
251 |                     tree.add(
252 |                         summary(child),
253 |                         guide_style=f"layout.tree.{child.splitter.name}",
254 |                     ),
255 |                     child,
256 |                 )
257 | 
258 |         recurse(tree, self)
259 |         return tree
260 | 
261 |     def split(
262 |         self,
263 |         *layouts: Union["Layout", RenderableType],
264 |         splitter: Union[Splitter, str] = "column",
265 |     ) -> None:
266 |         """Split the layout in to multiple sub-layouts.
267 | 
268 |         Args:
269 |             *layouts (Layout): Positional arguments should be (sub) Layout instances.
270 |             splitter (Union[Splitter, str]): Splitter instance or name of splitter.
271 |         """
272 |         _layouts = [
273 |             layout if isinstance(layout, Layout) else Layout(layout)
274 |             for layout in layouts
275 |         ]
276 |         try:
277 |             self.splitter = (
278 |                 splitter
279 |                 if isinstance(splitter, Splitter)
280 |                 else self.splitters[splitter]()
281 |             )
282 |         except KeyError:
283 |             raise NoSplitter(f"No splitter called {splitter!r}")
284 |         self._children[:] = _layouts
285 | 
286 |     def add_split(self, *layouts: Union["Layout", RenderableType]) -> None:
287 |         """Add a new layout(s) to existing split.
288 | 
289 |         Args:
290 |             *layouts (Union[Layout, RenderableType]): Positional arguments should be renderables or (sub) Layout instances.
291 | 
292 |         """
293 |         _layouts = (
294 |             layout if isinstance(layout, Layout) else Layout(layout)
295 |             for layout in layouts
296 |         )
297 |         self._children.extend(_layouts)
298 | 
299 |     def split_row(self, *layouts: Union["Layout", RenderableType]) -> None:
300 |         """Split the layout in to a row (layouts side by side).
301 | 
302 |         Args:
303 |             *layouts (Layout): Positional arguments should be (sub) Layout instances.
304 |         """
305 |         self.split(*layouts, splitter="row")
306 | 
307 |     def split_column(self, *layouts: Union["Layout", RenderableType]) -> None:
308 |         """Split the layout in to a column (layouts stacked on top of each other).
309 | 
310 |         Args:
311 |             *layouts (Layout): Positional arguments should be (sub) Layout instances.
312 |         """
313 |         self.split(*layouts, splitter="column")
314 | 
315 |     def unsplit(self) -> None:
316 |         """Reset splits to initial state."""
317 |         del self._children[:]
318 | 
319 |     def update(self, renderable: RenderableType) -> None:
320 |         """Update renderable.
321 | 
322 |         Args:
323 |             renderable (RenderableType): New renderable object.
324 |         """
325 |         with self._lock:
326 |             self._renderable = renderable
327 | 
328 |     def refresh_screen(self, console: "Console", layout_name: str) -> None:
329 |         """Refresh a sub-layout.
330 | 
331 |         Args:
332 |             console (Console): Console instance where Layout is to be rendered.
333 |             layout_name (str): Name of layout.
334 |         """
335 |         with self._lock:
336 |             layout = self[layout_name]
337 |             region, _lines = self._render_map[layout]
338 |             (x, y, width, height) = region
339 |             lines = console.render_lines(
340 |                 layout, console.options.update_dimensions(width, height)
341 |             )
342 |             self._render_map[layout] = LayoutRender(region, lines)
343 |             console.update_screen_lines(lines, x, y)
344 | 
345 |     def _make_region_map(self, width: int, height: int) -> RegionMap:
346 |         """Create a dict that maps layout on to Region."""
347 |         stack: List[Tuple[Layout, Region]] = [(self, Region(0, 0, width, height))]
348 |         push = stack.append
349 |         pop = stack.pop
350 |         layout_regions: List[Tuple[Layout, Region]] = []
351 |         append_layout_region = layout_regions.append
352 |         while stack:
353 |             append_layout_region(pop())
354 |             layout, region = layout_regions[-1]
355 |             children = layout.children
356 |             if children:
357 |                 for child_and_region in layout.splitter.divide(children, region):
358 |                     push(child_and_region)
359 | 
360 |         region_map = {
361 |             layout: region
362 |             for layout, region in sorted(layout_regions, key=itemgetter(1))
363 |         }
364 |         return region_map
365 | 
366 |     def render(self, console: Console, options: ConsoleOptions) -> RenderMap:
367 |         """Render the sub_layouts.
368 | 
369 |         Args:
370 |             console (Console): Console instance.
371 |             options (ConsoleOptions): Console options.
372 | 
373 |         Returns:
374 |             RenderMap: A dict that maps Layout on to a tuple of Region, lines
375 |         """
376 |         render_width = options.max_width
377 |         render_height = options.height or console.height
378 |         region_map = self._make_region_map(render_width, render_height)
379 |         layout_regions = [
380 |             (layout, region)
381 |             for layout, region in region_map.items()
382 |             if not layout.children
383 |         ]
384 |         render_map: Dict["Layout", "LayoutRender"] = {}
385 |         render_lines = console.render_lines
386 |         update_dimensions = options.update_dimensions
387 | 
388 |         for layout, region in layout_regions:
389 |             lines = render_lines(
390 |                 layout.renderable, update_dimensions(region.width, region.height)
391 |             )
392 |             render_map[layout] = LayoutRender(region, lines)
[TRUNCATED]
```

.venv/lib/python3.13/site-packages/pip/_vendor/rich/live.py
```
1 | import sys
2 | from threading import Event, RLock, Thread
3 | from types import TracebackType
4 | from typing import IO, Any, Callable, List, Optional, TextIO, Type, cast
5 | 
6 | from . import get_console
7 | from .console import Console, ConsoleRenderable, RenderableType, RenderHook
8 | from .control import Control
9 | from .file_proxy import FileProxy
10 | from .jupyter import JupyterMixin
11 | from .live_render import LiveRender, VerticalOverflowMethod
12 | from .screen import Screen
13 | from .text import Text
14 | 
15 | 
16 | class _RefreshThread(Thread):
17 |     """A thread that calls refresh() at regular intervals."""
18 | 
19 |     def __init__(self, live: "Live", refresh_per_second: float) -> None:
20 |         self.live = live
21 |         self.refresh_per_second = refresh_per_second
22 |         self.done = Event()
23 |         super().__init__(daemon=True)
24 | 
25 |     def stop(self) -> None:
26 |         self.done.set()
27 | 
28 |     def run(self) -> None:
29 |         while not self.done.wait(1 / self.refresh_per_second):
30 |             with self.live._lock:
31 |                 if not self.done.is_set():
32 |                     self.live.refresh()
33 | 
34 | 
35 | class Live(JupyterMixin, RenderHook):
36 |     """Renders an auto-updating live display of any given renderable.
37 | 
38 |     Args:
39 |         renderable (RenderableType, optional): The renderable to live display. Defaults to displaying nothing.
40 |         console (Console, optional): Optional Console instance. Defaults to an internal Console instance writing to stdout.
41 |         screen (bool, optional): Enable alternate screen mode. Defaults to False.
42 |         auto_refresh (bool, optional): Enable auto refresh. If disabled, you will need to call `refresh()` or `update()` with refresh flag. Defaults to True
43 |         refresh_per_second (float, optional): Number of times per second to refresh the live display. Defaults to 4.
44 |         transient (bool, optional): Clear the renderable on exit (has no effect when screen=True). Defaults to False.
45 |         redirect_stdout (bool, optional): Enable redirection of stdout, so ``print`` may be used. Defaults to True.
46 |         redirect_stderr (bool, optional): Enable redirection of stderr. Defaults to True.
47 |         vertical_overflow (VerticalOverflowMethod, optional): How to handle renderable when it is too tall for the console. Defaults to "ellipsis".
48 |         get_renderable (Callable[[], RenderableType], optional): Optional callable to get renderable. Defaults to None.
49 |     """
50 | 
51 |     def __init__(
52 |         self,
53 |         renderable: Optional[RenderableType] = None,
54 |         *,
55 |         console: Optional[Console] = None,
56 |         screen: bool = False,
57 |         auto_refresh: bool = True,
58 |         refresh_per_second: float = 4,
59 |         transient: bool = False,
60 |         redirect_stdout: bool = True,
61 |         redirect_stderr: bool = True,
62 |         vertical_overflow: VerticalOverflowMethod = "ellipsis",
63 |         get_renderable: Optional[Callable[[], RenderableType]] = None,
64 |     ) -> None:
65 |         assert refresh_per_second > 0, "refresh_per_second must be > 0"
66 |         self._renderable = renderable
67 |         self.console = console if console is not None else get_console()
68 |         self._screen = screen
69 |         self._alt_screen = False
70 | 
71 |         self._redirect_stdout = redirect_stdout
72 |         self._redirect_stderr = redirect_stderr
73 |         self._restore_stdout: Optional[IO[str]] = None
74 |         self._restore_stderr: Optional[IO[str]] = None
75 | 
76 |         self._lock = RLock()
77 |         self.ipy_widget: Optional[Any] = None
78 |         self.auto_refresh = auto_refresh
79 |         self._started: bool = False
80 |         self.transient = True if screen else transient
81 | 
82 |         self._refresh_thread: Optional[_RefreshThread] = None
83 |         self.refresh_per_second = refresh_per_second
84 | 
85 |         self.vertical_overflow = vertical_overflow
86 |         self._get_renderable = get_renderable
87 |         self._live_render = LiveRender(
88 |             self.get_renderable(), vertical_overflow=vertical_overflow
89 |         )
90 | 
91 |     @property
92 |     def is_started(self) -> bool:
93 |         """Check if live display has been started."""
94 |         return self._started
95 | 
96 |     def get_renderable(self) -> RenderableType:
97 |         renderable = (
98 |             self._get_renderable()
99 |             if self._get_renderable is not None
100 |             else self._renderable
101 |         )
102 |         return renderable or ""
103 | 
104 |     def start(self, refresh: bool = False) -> None:
105 |         """Start live rendering display.
106 | 
107 |         Args:
108 |             refresh (bool, optional): Also refresh. Defaults to False.
109 |         """
110 |         with self._lock:
111 |             if self._started:
112 |                 return
113 |             self.console.set_live(self)
114 |             self._started = True
115 |             if self._screen:
116 |                 self._alt_screen = self.console.set_alt_screen(True)
117 |             self.console.show_cursor(False)
118 |             self._enable_redirect_io()
119 |             self.console.push_render_hook(self)
120 |             if refresh:
121 |                 try:
122 |                     self.refresh()
123 |                 except Exception:
124 |                     # If refresh fails, we want to stop the redirection of sys.stderr,
125 |                     # so the error stacktrace is properly displayed in the terminal.
126 |                     # (or, if the code that calls Rich captures the exception and wants to display something,
127 |                     # let this be displayed in the terminal).
128 |                     self.stop()
129 |                     raise
130 |             if self.auto_refresh:
131 |                 self._refresh_thread = _RefreshThread(self, self.refresh_per_second)
132 |                 self._refresh_thread.start()
133 | 
134 |     def stop(self) -> None:
135 |         """Stop live rendering display."""
136 |         with self._lock:
137 |             if not self._started:
138 |                 return
139 |             self.console.clear_live()
140 |             self._started = False
141 | 
142 |             if self.auto_refresh and self._refresh_thread is not None:
143 |                 self._refresh_thread.stop()
144 |                 self._refresh_thread = None
145 |             # allow it to fully render on the last even if overflow
146 |             self.vertical_overflow = "visible"
147 |             with self.console:
148 |                 try:
149 |                     if not self._alt_screen and not self.console.is_jupyter:
150 |                         self.refresh()
151 |                 finally:
152 |                     self._disable_redirect_io()
153 |                     self.console.pop_render_hook()
154 |                     if not self._alt_screen and self.console.is_terminal:
155 |                         self.console.line()
156 |                     self.console.show_cursor(True)
157 |                     if self._alt_screen:
158 |                         self.console.set_alt_screen(False)
159 | 
160 |                     if self.transient and not self._alt_screen:
161 |                         self.console.control(self._live_render.restore_cursor())
162 |                     if self.ipy_widget is not None and self.transient:
163 |                         self.ipy_widget.close()  # pragma: no cover
164 | 
165 |     def __enter__(self) -> "Live":
166 |         self.start(refresh=self._renderable is not None)
167 |         return self
168 | 
169 |     def __exit__(
170 |         self,
171 |         exc_type: Optional[Type[BaseException]],
172 |         exc_val: Optional[BaseException],
173 |         exc_tb: Optional[TracebackType],
174 |     ) -> None:
175 |         self.stop()
176 | 
177 |     def _enable_redirect_io(self) -> None:
178 |         """Enable redirecting of stdout / stderr."""
179 |         if self.console.is_terminal or self.console.is_jupyter:
180 |             if self._redirect_stdout and not isinstance(sys.stdout, FileProxy):
181 |                 self._restore_stdout = sys.stdout
182 |                 sys.stdout = cast("TextIO", FileProxy(self.console, sys.stdout))
183 |             if self._redirect_stderr and not isinstance(sys.stderr, FileProxy):
184 |                 self._restore_stderr = sys.stderr
185 |                 sys.stderr = cast("TextIO", FileProxy(self.console, sys.stderr))
186 | 
187 |     def _disable_redirect_io(self) -> None:
188 |         """Disable redirecting of stdout / stderr."""
189 |         if self._restore_stdout:
190 |             sys.stdout = cast("TextIO", self._restore_stdout)
191 |             self._restore_stdout = None
192 |         if self._restore_stderr:
193 |             sys.stderr = cast("TextIO", self._restore_stderr)
194 |             self._restore_stderr = None
195 | 
196 |     @property
197 |     def renderable(self) -> RenderableType:
198 |         """Get the renderable that is being displayed
199 | 
200 |         Returns:
201 |             RenderableType: Displayed renderable.
202 |         """
203 |         renderable = self.get_renderable()
204 |         return Screen(renderable) if self._alt_screen else renderable
205 | 
206 |     def update(self, renderable: RenderableType, *, refresh: bool = False) -> None:
207 |         """Update the renderable that is being displayed
208 | 
209 |         Args:
210 |             renderable (RenderableType): New renderable to use.
211 |             refresh (bool, optional): Refresh the display. Defaults to False.
212 |         """
213 |         if isinstance(renderable, str):
214 |             renderable = self.console.render_str(renderable)
215 |         with self._lock:
216 |             self._renderable = renderable
217 |             if refresh:
218 |                 self.refresh()
219 | 
220 |     def refresh(self) -> None:
221 |         """Update the display of the Live Render."""
222 |         with self._lock:
223 |             self._live_render.set_renderable(self.renderable)
224 |             if self.console.is_jupyter:  # pragma: no cover
225 |                 try:
226 |                     from IPython.display import display
227 |                     from ipywidgets import Output
228 |                 except ImportError:
229 |                     import warnings
230 | 
231 |                     warnings.warn('install "ipywidgets" for Jupyter support')
232 |                 else:
233 |                     if self.ipy_widget is None:
234 |                         self.ipy_widget = Output()
235 |                         display(self.ipy_widget)
236 | 
237 |                     with self.ipy_widget:
238 |                         self.ipy_widget.clear_output(wait=True)
239 |                         self.console.print(self._live_render.renderable)
240 |             elif self.console.is_terminal and not self.console.is_dumb_terminal:
241 |                 with self.console:
242 |                     self.console.print(Control())
243 |             elif (
244 |                 not self._started and not self.transient
245 |             ):  # if it is finished allow files or dumb-terminals to see final result
246 |                 with self.console:
247 |                     self.console.print(Control())
248 | 
249 |     def process_renderables(
250 |         self, renderables: List[ConsoleRenderable]
251 |     ) -> List[ConsoleRenderable]:
252 |         """Process renderables to restore cursor and display progress."""
253 |         self._live_render.vertical_overflow = self.vertical_overflow
254 |         if self.console.is_interactive:
255 |             # lock needs acquiring as user can modify live_render renderable at any time unlike in Progress.
256 |             with self._lock:
257 |                 reset = (
258 |                     Control.home()
259 |                     if self._alt_screen
260 |                     else self._live_render.position_cursor()
261 |                 )
262 |                 renderables = [reset, *renderables, self._live_render]
263 |         elif (
264 |             not self._started and not self.transient
265 |         ):  # if it is finished render the final output for files or dumb_terminals
266 |             renderables = [*renderables, self._live_render]
267 | 
268 |         return renderables
269 | 
270 | 
271 | if __name__ == "__main__":  # pragma: no cover
272 |     import random
273 |     import time
274 |     from itertools import cycle
275 |     from typing import Dict, List, Tuple
276 | 
277 |     from .align import Align
278 |     from .console import Console
279 |     from .live import Live as Live
280 |     from .panel import Panel
281 |     from .rule import Rule
282 |     from .syntax import Syntax
283 |     from .table import Table
284 | 
285 |     console = Console()
286 | 
287 |     syntax = Syntax(
288 |         '''def loop_last(values: Iterable[T]) -> Iterable[Tuple[bool, T]]:
289 |     """Iterate and generate a tuple with a flag for last value."""
290 |     iter_values = iter(values)
291 |     try:
292 |         previous_value = next(iter_values)
293 |     except StopIteration:
294 |         return
295 |     for value in iter_values:
296 |         yield False, previous_value
297 |         previous_value = value
298 |     yield True, previous_value''',
299 |         "python",
300 |         line_numbers=True,
301 |     )
302 | 
303 |     table = Table("foo", "bar", "baz")
304 |     table.add_row("1", "2", "3")
305 | 
306 |     progress_renderables = [
307 |         "You can make the terminal shorter and taller to see the live table hide"
308 |         "Text may be printed while the progress bars are rendering.",
309 |         Panel("In fact, [i]any[/i] renderable will work"),
310 |         "Such as [magenta]tables[/]...",
311 |         table,
312 |         "Pretty printed structures...",
313 |         {"type": "example", "text": "Pretty printed"},
314 |         "Syntax...",
315 |         syntax,
316 |         Rule("Give it a try!"),
317 |     ]
318 | 
319 |     examples = cycle(progress_renderables)
320 | 
321 |     exchanges = [
322 |         "SGD",
323 |         "MYR",
324 |         "EUR",
325 |         "USD",
326 |         "AUD",
327 |         "JPY",
328 |         "CNH",
329 |         "HKD",
330 |         "CAD",
331 |         "INR",
332 |         "DKK",
333 |         "GBP",
334 |         "RUB",
335 |         "NZD",
336 |         "MXN",
337 |         "IDR",
338 |         "TWD",
339 |         "THB",
340 |         "VND",
341 |     ]
342 |     with Live(console=console) as live_table:
343 |         exchange_rate_dict: Dict[Tuple[str, str], float] = {}
344 | 
345 |         for index in range(100):
346 |             select_exchange = exchanges[index % len(exchanges)]
347 | 
348 |             for exchange in exchanges:
349 |                 if exchange == select_exchange:
350 |                     continue
[TRUNCATED]
```

.venv/lib/python3.13/site-packages/pip/_vendor/rich/live_render.py
```
1 | import sys
2 | from typing import Optional, Tuple
3 | 
4 | if sys.version_info >= (3, 8):
5 |     from typing import Literal
6 | else:
7 |     from pip._vendor.typing_extensions import Literal  # pragma: no cover
8 | 
9 | 
10 | from ._loop import loop_last
11 | from .console import Console, ConsoleOptions, RenderableType, RenderResult
12 | from .control import Control
13 | from .segment import ControlType, Segment
14 | from .style import StyleType
15 | from .text import Text
16 | 
17 | VerticalOverflowMethod = Literal["crop", "ellipsis", "visible"]
18 | 
19 | 
20 | class LiveRender:
21 |     """Creates a renderable that may be updated.
22 | 
23 |     Args:
24 |         renderable (RenderableType): Any renderable object.
25 |         style (StyleType, optional): An optional style to apply to the renderable. Defaults to "".
26 |     """
27 | 
28 |     def __init__(
29 |         self,
30 |         renderable: RenderableType,
31 |         style: StyleType = "",
32 |         vertical_overflow: VerticalOverflowMethod = "ellipsis",
33 |     ) -> None:
34 |         self.renderable = renderable
35 |         self.style = style
36 |         self.vertical_overflow = vertical_overflow
37 |         self._shape: Optional[Tuple[int, int]] = None
38 | 
39 |     def set_renderable(self, renderable: RenderableType) -> None:
40 |         """Set a new renderable.
41 | 
42 |         Args:
43 |             renderable (RenderableType): Any renderable object, including str.
44 |         """
45 |         self.renderable = renderable
46 | 
47 |     def position_cursor(self) -> Control:
48 |         """Get control codes to move cursor to beginning of live render.
49 | 
50 |         Returns:
51 |             Control: A control instance that may be printed.
52 |         """
53 |         if self._shape is not None:
54 |             _, height = self._shape
55 |             return Control(
56 |                 ControlType.CARRIAGE_RETURN,
57 |                 (ControlType.ERASE_IN_LINE, 2),
58 |                 *(
59 |                     (
60 |                         (ControlType.CURSOR_UP, 1),
61 |                         (ControlType.ERASE_IN_LINE, 2),
62 |                     )
63 |                     * (height - 1)
64 |                 )
65 |             )
66 |         return Control()
67 | 
68 |     def restore_cursor(self) -> Control:
69 |         """Get control codes to clear the render and restore the cursor to its previous position.
70 | 
71 |         Returns:
72 |             Control: A Control instance that may be printed.
73 |         """
74 |         if self._shape is not None:
75 |             _, height = self._shape
76 |             return Control(
77 |                 ControlType.CARRIAGE_RETURN,
78 |                 *((ControlType.CURSOR_UP, 1), (ControlType.ERASE_IN_LINE, 2)) * height
79 |             )
80 |         return Control()
81 | 
82 |     def __rich_console__(
83 |         self, console: Console, options: ConsoleOptions
84 |     ) -> RenderResult:
85 |         renderable = self.renderable
86 |         style = console.get_style(self.style)
87 |         lines = console.render_lines(renderable, options, style=style, pad=False)
88 |         shape = Segment.get_shape(lines)
89 | 
90 |         _, height = shape
91 |         if height > options.size.height:
92 |             if self.vertical_overflow == "crop":
93 |                 lines = lines[: options.size.height]
94 |                 shape = Segment.get_shape(lines)
95 |             elif self.vertical_overflow == "ellipsis":
96 |                 lines = lines[: (options.size.height - 1)]
97 |                 overflow_text = Text(
98 |                     "...",
99 |                     overflow="crop",
100 |                     justify="center",
101 |                     end="",
102 |                     style="live.ellipsis",
103 |                 )
104 |                 lines.append(list(console.render(overflow_text)))
105 |                 shape = Segment.get_shape(lines)
106 |         self._shape = shape
107 | 
108 |         new_line = Segment.line()
109 |         for last, line in loop_last(lines):
110 |             yield from line
111 |             if not last:
112 |                 yield new_line
```

.venv/lib/python3.13/site-packages/pip/_vendor/rich/logging.py
```
1 | import logging
2 | from datetime import datetime
3 | from logging import Handler, LogRecord
4 | from pathlib import Path
5 | from types import ModuleType
6 | from typing import ClassVar, Iterable, List, Optional, Type, Union
7 | 
8 | from pip._vendor.rich._null_file import NullFile
9 | 
10 | from . import get_console
11 | from ._log_render import FormatTimeCallable, LogRender
12 | from .console import Console, ConsoleRenderable
13 | from .highlighter import Highlighter, ReprHighlighter
14 | from .text import Text
15 | from .traceback import Traceback
16 | 
17 | 
18 | class RichHandler(Handler):
19 |     """A logging handler that renders output with Rich. The time / level / message and file are displayed in columns.
20 |     The level is color coded, and the message is syntax highlighted.
21 | 
22 |     Note:
23 |         Be careful when enabling console markup in log messages if you have configured logging for libraries not
24 |         under your control. If a dependency writes messages containing square brackets, it may not produce the intended output.
25 | 
26 |     Args:
27 |         level (Union[int, str], optional): Log level. Defaults to logging.NOTSET.
28 |         console (:class:`~rich.console.Console`, optional): Optional console instance to write logs.
29 |             Default will use a global console instance writing to stdout.
30 |         show_time (bool, optional): Show a column for the time. Defaults to True.
31 |         omit_repeated_times (bool, optional): Omit repetition of the same time. Defaults to True.
32 |         show_level (bool, optional): Show a column for the level. Defaults to True.
33 |         show_path (bool, optional): Show the path to the original log call. Defaults to True.
34 |         enable_link_path (bool, optional): Enable terminal link of path column to file. Defaults to True.
35 |         highlighter (Highlighter, optional): Highlighter to style log messages, or None to use ReprHighlighter. Defaults to None.
36 |         markup (bool, optional): Enable console markup in log messages. Defaults to False.
37 |         rich_tracebacks (bool, optional): Enable rich tracebacks with syntax highlighting and formatting. Defaults to False.
38 |         tracebacks_width (Optional[int], optional): Number of characters used to render tracebacks, or None for full width. Defaults to None.
39 |         tracebacks_code_width (int, optional): Number of code characters used to render tracebacks, or None for full width. Defaults to 88.
40 |         tracebacks_extra_lines (int, optional): Additional lines of code to render tracebacks, or None for full width. Defaults to None.
41 |         tracebacks_theme (str, optional): Override pygments theme used in traceback.
42 |         tracebacks_word_wrap (bool, optional): Enable word wrapping of long tracebacks lines. Defaults to True.
43 |         tracebacks_show_locals (bool, optional): Enable display of locals in tracebacks. Defaults to False.
44 |         tracebacks_suppress (Sequence[Union[str, ModuleType]]): Optional sequence of modules or paths to exclude from traceback.
45 |         tracebacks_max_frames (int, optional): Optional maximum number of frames returned by traceback.
46 |         locals_max_length (int, optional): Maximum length of containers before abbreviating, or None for no abbreviation.
47 |             Defaults to 10.
48 |         locals_max_string (int, optional): Maximum length of string before truncating, or None to disable. Defaults to 80.
49 |         log_time_format (Union[str, TimeFormatterCallable], optional): If ``log_time`` is enabled, either string for strftime or callable that formats the time. Defaults to "[%x %X] ".
50 |         keywords (List[str], optional): List of words to highlight instead of ``RichHandler.KEYWORDS``.
51 |     """
52 | 
53 |     KEYWORDS: ClassVar[Optional[List[str]]] = [
54 |         "GET",
55 |         "POST",
56 |         "HEAD",
57 |         "PUT",
58 |         "DELETE",
59 |         "OPTIONS",
60 |         "TRACE",
61 |         "PATCH",
62 |     ]
63 |     HIGHLIGHTER_CLASS: ClassVar[Type[Highlighter]] = ReprHighlighter
64 | 
65 |     def __init__(
66 |         self,
67 |         level: Union[int, str] = logging.NOTSET,
68 |         console: Optional[Console] = None,
69 |         *,
70 |         show_time: bool = True,
71 |         omit_repeated_times: bool = True,
72 |         show_level: bool = True,
73 |         show_path: bool = True,
74 |         enable_link_path: bool = True,
75 |         highlighter: Optional[Highlighter] = None,
76 |         markup: bool = False,
77 |         rich_tracebacks: bool = False,
78 |         tracebacks_width: Optional[int] = None,
79 |         tracebacks_code_width: int = 88,
80 |         tracebacks_extra_lines: int = 3,
81 |         tracebacks_theme: Optional[str] = None,
82 |         tracebacks_word_wrap: bool = True,
83 |         tracebacks_show_locals: bool = False,
84 |         tracebacks_suppress: Iterable[Union[str, ModuleType]] = (),
85 |         tracebacks_max_frames: int = 100,
86 |         locals_max_length: int = 10,
87 |         locals_max_string: int = 80,
88 |         log_time_format: Union[str, FormatTimeCallable] = "[%x %X]",
89 |         keywords: Optional[List[str]] = None,
90 |     ) -> None:
91 |         super().__init__(level=level)
92 |         self.console = console or get_console()
93 |         self.highlighter = highlighter or self.HIGHLIGHTER_CLASS()
94 |         self._log_render = LogRender(
95 |             show_time=show_time,
96 |             show_level=show_level,
97 |             show_path=show_path,
98 |             time_format=log_time_format,
99 |             omit_repeated_times=omit_repeated_times,
100 |             level_width=None,
101 |         )
102 |         self.enable_link_path = enable_link_path
103 |         self.markup = markup
104 |         self.rich_tracebacks = rich_tracebacks
105 |         self.tracebacks_width = tracebacks_width
106 |         self.tracebacks_extra_lines = tracebacks_extra_lines
107 |         self.tracebacks_theme = tracebacks_theme
108 |         self.tracebacks_word_wrap = tracebacks_word_wrap
109 |         self.tracebacks_show_locals = tracebacks_show_locals
110 |         self.tracebacks_suppress = tracebacks_suppress
111 |         self.tracebacks_max_frames = tracebacks_max_frames
112 |         self.tracebacks_code_width = tracebacks_code_width
113 |         self.locals_max_length = locals_max_length
114 |         self.locals_max_string = locals_max_string
115 |         self.keywords = keywords
116 | 
117 |     def get_level_text(self, record: LogRecord) -> Text:
118 |         """Get the level name from the record.
119 | 
120 |         Args:
121 |             record (LogRecord): LogRecord instance.
122 | 
123 |         Returns:
124 |             Text: A tuple of the style and level name.
125 |         """
126 |         level_name = record.levelname
127 |         level_text = Text.styled(
128 |             level_name.ljust(8), f"logging.level.{level_name.lower()}"
129 |         )
130 |         return level_text
131 | 
132 |     def emit(self, record: LogRecord) -> None:
133 |         """Invoked by logging."""
134 |         message = self.format(record)
135 |         traceback = None
136 |         if (
137 |             self.rich_tracebacks
138 |             and record.exc_info
139 |             and record.exc_info != (None, None, None)
140 |         ):
141 |             exc_type, exc_value, exc_traceback = record.exc_info
142 |             assert exc_type is not None
143 |             assert exc_value is not None
144 |             traceback = Traceback.from_exception(
145 |                 exc_type,
146 |                 exc_value,
147 |                 exc_traceback,
148 |                 width=self.tracebacks_width,
149 |                 code_width=self.tracebacks_code_width,
150 |                 extra_lines=self.tracebacks_extra_lines,
151 |                 theme=self.tracebacks_theme,
152 |                 word_wrap=self.tracebacks_word_wrap,
153 |                 show_locals=self.tracebacks_show_locals,
154 |                 locals_max_length=self.locals_max_length,
155 |                 locals_max_string=self.locals_max_string,
156 |                 suppress=self.tracebacks_suppress,
157 |                 max_frames=self.tracebacks_max_frames,
158 |             )
159 |             message = record.getMessage()
160 |             if self.formatter:
161 |                 record.message = record.getMessage()
162 |                 formatter = self.formatter
163 |                 if hasattr(formatter, "usesTime") and formatter.usesTime():
164 |                     record.asctime = formatter.formatTime(record, formatter.datefmt)
165 |                 message = formatter.formatMessage(record)
166 | 
167 |         message_renderable = self.render_message(record, message)
168 |         log_renderable = self.render(
169 |             record=record, traceback=traceback, message_renderable=message_renderable
170 |         )
171 |         if isinstance(self.console.file, NullFile):
172 |             # Handles pythonw, where stdout/stderr are null, and we return NullFile
173 |             # instance from Console.file. In this case, we still want to make a log record
174 |             # even though we won't be writing anything to a file.
175 |             self.handleError(record)
176 |         else:
177 |             try:
178 |                 self.console.print(log_renderable)
179 |             except Exception:
180 |                 self.handleError(record)
181 | 
182 |     def render_message(self, record: LogRecord, message: str) -> "ConsoleRenderable":
183 |         """Render message text in to Text.
184 | 
185 |         Args:
186 |             record (LogRecord): logging Record.
187 |             message (str): String containing log message.
188 | 
189 |         Returns:
190 |             ConsoleRenderable: Renderable to display log message.
191 |         """
192 |         use_markup = getattr(record, "markup", self.markup)
193 |         message_text = Text.from_markup(message) if use_markup else Text(message)
194 | 
195 |         highlighter = getattr(record, "highlighter", self.highlighter)
196 |         if highlighter:
197 |             message_text = highlighter(message_text)
198 | 
199 |         if self.keywords is None:
200 |             self.keywords = self.KEYWORDS
201 | 
202 |         if self.keywords:
203 |             message_text.highlight_words(self.keywords, "logging.keyword")
204 | 
205 |         return message_text
206 | 
207 |     def render(
208 |         self,
209 |         *,
210 |         record: LogRecord,
211 |         traceback: Optional[Traceback],
212 |         message_renderable: "ConsoleRenderable",
213 |     ) -> "ConsoleRenderable":
214 |         """Render log for display.
215 | 
216 |         Args:
217 |             record (LogRecord): logging Record.
218 |             traceback (Optional[Traceback]): Traceback instance or None for no Traceback.
219 |             message_renderable (ConsoleRenderable): Renderable (typically Text) containing log message contents.
220 | 
221 |         Returns:
222 |             ConsoleRenderable: Renderable to display log.
223 |         """
224 |         path = Path(record.pathname).name
225 |         level = self.get_level_text(record)
226 |         time_format = None if self.formatter is None else self.formatter.datefmt
227 |         log_time = datetime.fromtimestamp(record.created)
228 | 
229 |         log_renderable = self._log_render(
230 |             self.console,
231 |             [message_renderable] if not traceback else [message_renderable, traceback],
232 |             log_time=log_time,
233 |             time_format=time_format,
234 |             level=level,
235 |             path=path,
236 |             line_no=record.lineno,
237 |             link_path=record.pathname if self.enable_link_path else None,
238 |         )
239 |         return log_renderable
240 | 
241 | 
242 | if __name__ == "__main__":  # pragma: no cover
243 |     from time import sleep
244 | 
245 |     FORMAT = "%(message)s"
246 |     # FORMAT = "%(asctime)-15s - %(levelname)s - %(message)s"
247 |     logging.basicConfig(
248 |         level="NOTSET",
249 |         format=FORMAT,
250 |         datefmt="[%X]",
251 |         handlers=[RichHandler(rich_tracebacks=True, tracebacks_show_locals=True)],
252 |     )
253 |     log = logging.getLogger("rich")
254 | 
255 |     log.info("Server starting...")
256 |     log.info("Listening on http://127.0.0.1:8080")
257 |     sleep(1)
258 | 
259 |     log.info("GET /index.html 200 1298")
260 |     log.info("GET /imgs/backgrounds/back1.jpg 200 54386")
261 |     log.info("GET /css/styles.css 200 54386")
262 |     log.warning("GET /favicon.ico 404 242")
263 |     sleep(1)
264 | 
265 |     log.debug(
266 |         "JSONRPC request\n--> %r\n<-- %r",
267 |         {
268 |             "version": "1.1",
269 |             "method": "confirmFruitPurchase",
270 |             "params": [["apple", "orange", "mangoes", "pomelo"], 1.123],
271 |             "id": "194521489",
272 |         },
273 |         {"version": "1.1", "result": True, "error": None, "id": "194521489"},
274 |     )
275 |     log.debug(
276 |         "Loading configuration file /adasd/asdasd/qeqwe/qwrqwrqwr/sdgsdgsdg/werwerwer/dfgerert/ertertert/ertetert/werwerwer"
277 |     )
278 |     log.error("Unable to find 'pomelo' in database!")
279 |     log.info("POST /jsonrpc/ 200 65532")
280 |     log.info("POST /admin/ 401 42234")
281 |     log.warning("password was rejected for admin site.")
282 | 
283 |     def divide() -> None:
284 |         number = 1
285 |         divisor = 0
286 |         foos = ["foo"] * 100
287 |         log.debug("in divide")
288 |         try:
289 |             number / divisor
290 |         except:
291 |             log.exception("An error of some kind occurred!")
292 | 
293 |     divide()
294 |     sleep(1)
295 |     log.critical("Out of memory!")
296 |     log.info("Server exited with code=-1")
297 |     log.info("[bold]EXITING...[/bold]", extra=dict(markup=True))
```

.venv/lib/python3.13/site-packages/pip/_vendor/rich/markup.py
```
1 | import re
2 | from ast import literal_eval
3 | from operator import attrgetter
4 | from typing import Callable, Iterable, List, Match, NamedTuple, Optional, Tuple, Union
5 | 
6 | from ._emoji_replace import _emoji_replace
7 | from .emoji import EmojiVariant
8 | from .errors import MarkupError
9 | from .style import Style
10 | from .text import Span, Text
11 | 
12 | RE_TAGS = re.compile(
13 |     r"""((\\*)\[([a-z#/@][^[]*?)])""",
14 |     re.VERBOSE,
15 | )
16 | 
17 | RE_HANDLER = re.compile(r"^([\w.]*?)(\(.*?\))?$")
18 | 
19 | 
20 | class Tag(NamedTuple):
21 |     """A tag in console markup."""
22 | 
23 |     name: str
24 |     """The tag name. e.g. 'bold'."""
25 |     parameters: Optional[str]
26 |     """Any additional parameters after the name."""
27 | 
28 |     def __str__(self) -> str:
29 |         return (
30 |             self.name if self.parameters is None else f"{self.name} {self.parameters}"
31 |         )
32 | 
33 |     @property
34 |     def markup(self) -> str:
35 |         """Get the string representation of this tag."""
36 |         return (
37 |             f"[{self.name}]"
38 |             if self.parameters is None
39 |             else f"[{self.name}={self.parameters}]"
40 |         )
41 | 
42 | 
43 | _ReStringMatch = Match[str]  # regex match object
44 | _ReSubCallable = Callable[[_ReStringMatch], str]  # Callable invoked by re.sub
45 | _EscapeSubMethod = Callable[[_ReSubCallable, str], str]  # Sub method of a compiled re
46 | 
47 | 
48 | def escape(
49 |     markup: str,
50 |     _escape: _EscapeSubMethod = re.compile(r"(\\*)(\[[a-z#/@][^[]*?])").sub,
51 | ) -> str:
52 |     """Escapes text so that it won't be interpreted as markup.
53 | 
54 |     Args:
55 |         markup (str): Content to be inserted in to markup.
56 | 
57 |     Returns:
58 |         str: Markup with square brackets escaped.
59 |     """
60 | 
61 |     def escape_backslashes(match: Match[str]) -> str:
62 |         """Called by re.sub replace matches."""
63 |         backslashes, text = match.groups()
64 |         return f"{backslashes}{backslashes}\\{text}"
65 | 
66 |     markup = _escape(escape_backslashes, markup)
67 |     if markup.endswith("\\") and not markup.endswith("\\\\"):
68 |         return markup + "\\"
69 | 
70 |     return markup
71 | 
72 | 
73 | def _parse(markup: str) -> Iterable[Tuple[int, Optional[str], Optional[Tag]]]:
74 |     """Parse markup in to an iterable of tuples of (position, text, tag).
75 | 
76 |     Args:
77 |         markup (str): A string containing console markup
78 | 
79 |     """
80 |     position = 0
81 |     _divmod = divmod
82 |     _Tag = Tag
83 |     for match in RE_TAGS.finditer(markup):
84 |         full_text, escapes, tag_text = match.groups()
85 |         start, end = match.span()
86 |         if start > position:
87 |             yield start, markup[position:start], None
88 |         if escapes:
89 |             backslashes, escaped = _divmod(len(escapes), 2)
90 |             if backslashes:
91 |                 # Literal backslashes
92 |                 yield start, "\\" * backslashes, None
93 |                 start += backslashes * 2
94 |             if escaped:
95 |                 # Escape of tag
96 |                 yield start, full_text[len(escapes) :], None
97 |                 position = end
98 |                 continue
99 |         text, equals, parameters = tag_text.partition("=")
100 |         yield start, None, _Tag(text, parameters if equals else None)
101 |         position = end
102 |     if position < len(markup):
103 |         yield position, markup[position:], None
104 | 
105 | 
106 | def render(
107 |     markup: str,
108 |     style: Union[str, Style] = "",
109 |     emoji: bool = True,
110 |     emoji_variant: Optional[EmojiVariant] = None,
111 | ) -> Text:
112 |     """Render console markup in to a Text instance.
113 | 
114 |     Args:
115 |         markup (str): A string containing console markup.
116 |         style: (Union[str, Style]): The style to use.
117 |         emoji (bool, optional): Also render emoji code. Defaults to True.
118 |         emoji_variant (str, optional): Optional emoji variant, either "text" or "emoji". Defaults to None.
119 | 
120 | 
121 |     Raises:
122 |         MarkupError: If there is a syntax error in the markup.
123 | 
124 |     Returns:
125 |         Text: A test instance.
126 |     """
127 |     emoji_replace = _emoji_replace
128 |     if "[" not in markup:
129 |         return Text(
130 |             emoji_replace(markup, default_variant=emoji_variant) if emoji else markup,
131 |             style=style,
132 |         )
133 |     text = Text(style=style)
134 |     append = text.append
135 |     normalize = Style.normalize
136 | 
137 |     style_stack: List[Tuple[int, Tag]] = []
138 |     pop = style_stack.pop
139 | 
140 |     spans: List[Span] = []
141 |     append_span = spans.append
142 | 
143 |     _Span = Span
144 |     _Tag = Tag
145 | 
146 |     def pop_style(style_name: str) -> Tuple[int, Tag]:
147 |         """Pop tag matching given style name."""
148 |         for index, (_, tag) in enumerate(reversed(style_stack), 1):
149 |             if tag.name == style_name:
150 |                 return pop(-index)
151 |         raise KeyError(style_name)
152 | 
153 |     for position, plain_text, tag in _parse(markup):
154 |         if plain_text is not None:
155 |             # Handle open brace escapes, where the brace is not part of a tag.
156 |             plain_text = plain_text.replace("\\[", "[")
157 |             append(emoji_replace(plain_text) if emoji else plain_text)
158 |         elif tag is not None:
159 |             if tag.name.startswith("/"):  # Closing tag
160 |                 style_name = tag.name[1:].strip()
161 | 
162 |                 if style_name:  # explicit close
163 |                     style_name = normalize(style_name)
164 |                     try:
165 |                         start, open_tag = pop_style(style_name)
166 |                     except KeyError:
167 |                         raise MarkupError(
168 |                             f"closing tag '{tag.markup}' at position {position} doesn't match any open tag"
169 |                         ) from None
170 |                 else:  # implicit close
171 |                     try:
172 |                         start, open_tag = pop()
173 |                     except IndexError:
174 |                         raise MarkupError(
175 |                             f"closing tag '[/]' at position {position} has nothing to close"
176 |                         ) from None
177 | 
178 |                 if open_tag.name.startswith("@"):
179 |                     if open_tag.parameters:
180 |                         handler_name = ""
181 |                         parameters = open_tag.parameters.strip()
182 |                         handler_match = RE_HANDLER.match(parameters)
183 |                         if handler_match is not None:
184 |                             handler_name, match_parameters = handler_match.groups()
185 |                             parameters = (
186 |                                 "()" if match_parameters is None else match_parameters
187 |                             )
188 | 
189 |                         try:
190 |                             meta_params = literal_eval(parameters)
191 |                         except SyntaxError as error:
192 |                             raise MarkupError(
193 |                                 f"error parsing {parameters!r} in {open_tag.parameters!r}; {error.msg}"
194 |                             )
195 |                         except Exception as error:
196 |                             raise MarkupError(
197 |                                 f"error parsing {open_tag.parameters!r}; {error}"
198 |                             ) from None
199 | 
200 |                         if handler_name:
201 |                             meta_params = (
202 |                                 handler_name,
203 |                                 meta_params
204 |                                 if isinstance(meta_params, tuple)
205 |                                 else (meta_params,),
206 |                             )
207 | 
208 |                     else:
209 |                         meta_params = ()
210 | 
211 |                     append_span(
212 |                         _Span(
213 |                             start, len(text), Style(meta={open_tag.name: meta_params})
214 |                         )
215 |                     )
216 |                 else:
217 |                     append_span(_Span(start, len(text), str(open_tag)))
218 | 
219 |             else:  # Opening tag
220 |                 normalized_tag = _Tag(normalize(tag.name), tag.parameters)
221 |                 style_stack.append((len(text), normalized_tag))
222 | 
223 |     text_length = len(text)
224 |     while style_stack:
225 |         start, tag = style_stack.pop()
226 |         style = str(tag)
227 |         if style:
228 |             append_span(_Span(start, text_length, style))
229 | 
230 |     text.spans = sorted(spans[::-1], key=attrgetter("start"))
231 |     return text
232 | 
233 | 
234 | if __name__ == "__main__":  # pragma: no cover
235 |     MARKUP = [
236 |         "[red]Hello World[/red]",
237 |         "[magenta]Hello [b]World[/b]",
238 |         "[bold]Bold[italic] bold and italic [/bold]italic[/italic]",
239 |         "Click [link=https://www.willmcgugan.com]here[/link] to visit my Blog",
240 |         ":warning-emoji: [bold red blink] DANGER![/]",
241 |     ]
242 | 
243 |     from pip._vendor.rich import print
244 |     from pip._vendor.rich.table import Table
245 | 
246 |     grid = Table("Markup", "Result", padding=(0, 1))
247 | 
248 |     for markup in MARKUP:
249 |         grid.add_row(Text(markup), markup)
250 | 
251 |     print(grid)
```

.venv/lib/python3.13/site-packages/pip/_vendor/rich/measure.py
```
1 | from operator import itemgetter
2 | from typing import TYPE_CHECKING, Callable, NamedTuple, Optional, Sequence
3 | 
4 | from . import errors
5 | from .protocol import is_renderable, rich_cast
6 | 
7 | if TYPE_CHECKING:
8 |     from .console import Console, ConsoleOptions, RenderableType
9 | 
10 | 
11 | class Measurement(NamedTuple):
12 |     """Stores the minimum and maximum widths (in characters) required to render an object."""
13 | 
14 |     minimum: int
15 |     """Minimum number of cells required to render."""
16 |     maximum: int
17 |     """Maximum number of cells required to render."""
18 | 
19 |     @property
20 |     def span(self) -> int:
21 |         """Get difference between maximum and minimum."""
22 |         return self.maximum - self.minimum
23 | 
24 |     def normalize(self) -> "Measurement":
25 |         """Get measurement that ensures that minimum <= maximum and minimum >= 0
26 | 
27 |         Returns:
28 |             Measurement: A normalized measurement.
29 |         """
30 |         minimum, maximum = self
31 |         minimum = min(max(0, minimum), maximum)
32 |         return Measurement(max(0, minimum), max(0, max(minimum, maximum)))
33 | 
34 |     def with_maximum(self, width: int) -> "Measurement":
35 |         """Get a RenderableWith where the widths are <= width.
36 | 
37 |         Args:
38 |             width (int): Maximum desired width.
39 | 
40 |         Returns:
41 |             Measurement: New Measurement object.
42 |         """
43 |         minimum, maximum = self
44 |         return Measurement(min(minimum, width), min(maximum, width))
45 | 
46 |     def with_minimum(self, width: int) -> "Measurement":
47 |         """Get a RenderableWith where the widths are >= width.
48 | 
49 |         Args:
50 |             width (int): Minimum desired width.
51 | 
52 |         Returns:
53 |             Measurement: New Measurement object.
54 |         """
55 |         minimum, maximum = self
56 |         width = max(0, width)
57 |         return Measurement(max(minimum, width), max(maximum, width))
58 | 
59 |     def clamp(
60 |         self, min_width: Optional[int] = None, max_width: Optional[int] = None
61 |     ) -> "Measurement":
62 |         """Clamp a measurement within the specified range.
63 | 
64 |         Args:
65 |             min_width (int): Minimum desired width, or ``None`` for no minimum. Defaults to None.
66 |             max_width (int): Maximum desired width, or ``None`` for no maximum. Defaults to None.
67 | 
68 |         Returns:
69 |             Measurement: New Measurement object.
70 |         """
71 |         measurement = self
72 |         if min_width is not None:
73 |             measurement = measurement.with_minimum(min_width)
74 |         if max_width is not None:
75 |             measurement = measurement.with_maximum(max_width)
76 |         return measurement
77 | 
78 |     @classmethod
79 |     def get(
80 |         cls, console: "Console", options: "ConsoleOptions", renderable: "RenderableType"
81 |     ) -> "Measurement":
82 |         """Get a measurement for a renderable.
83 | 
84 |         Args:
85 |             console (~rich.console.Console): Console instance.
86 |             options (~rich.console.ConsoleOptions): Console options.
87 |             renderable (RenderableType): An object that may be rendered with Rich.
88 | 
89 |         Raises:
90 |             errors.NotRenderableError: If the object is not renderable.
91 | 
92 |         Returns:
93 |             Measurement: Measurement object containing range of character widths required to render the object.
94 |         """
95 |         _max_width = options.max_width
96 |         if _max_width < 1:
97 |             return Measurement(0, 0)
98 |         if isinstance(renderable, str):
99 |             renderable = console.render_str(
100 |                 renderable, markup=options.markup, highlight=False
101 |             )
102 |         renderable = rich_cast(renderable)
103 |         if is_renderable(renderable):
104 |             get_console_width: Optional[
105 |                 Callable[["Console", "ConsoleOptions"], "Measurement"]
106 |             ] = getattr(renderable, "__rich_measure__", None)
107 |             if get_console_width is not None:
108 |                 render_width = (
109 |                     get_console_width(console, options)
110 |                     .normalize()
111 |                     .with_maximum(_max_width)
112 |                 )
113 |                 if render_width.maximum < 1:
114 |                     return Measurement(0, 0)
115 |                 return render_width.normalize()
116 |             else:
117 |                 return Measurement(0, _max_width)
118 |         else:
119 |             raise errors.NotRenderableError(
120 |                 f"Unable to get render width for {renderable!r}; "
121 |                 "a str, Segment, or object with __rich_console__ method is required"
122 |             )
123 | 
124 | 
125 | def measure_renderables(
126 |     console: "Console",
127 |     options: "ConsoleOptions",
128 |     renderables: Sequence["RenderableType"],
129 | ) -> "Measurement":
130 |     """Get a measurement that would fit a number of renderables.
131 | 
132 |     Args:
133 |         console (~rich.console.Console): Console instance.
134 |         options (~rich.console.ConsoleOptions): Console options.
135 |         renderables (Iterable[RenderableType]): One or more renderable objects.
136 | 
137 |     Returns:
138 |         Measurement: Measurement object containing range of character widths required to
139 |             contain all given renderables.
140 |     """
141 |     if not renderables:
142 |         return Measurement(0, 0)
143 |     get_measurement = Measurement.get
144 |     measurements = [
145 |         get_measurement(console, options, renderable) for renderable in renderables
146 |     ]
147 |     measured_width = Measurement(
148 |         max(measurements, key=itemgetter(0)).minimum,
149 |         max(measurements, key=itemgetter(1)).maximum,
150 |     )
151 |     return measured_width
```

.venv/lib/python3.13/site-packages/pip/_vendor/rich/padding.py
```
1 | from typing import TYPE_CHECKING, List, Optional, Tuple, Union
2 | 
3 | if TYPE_CHECKING:
4 |     from .console import (
5 |         Console,
6 |         ConsoleOptions,
7 |         RenderableType,
8 |         RenderResult,
9 |     )
10 | 
11 | from .jupyter import JupyterMixin
12 | from .measure import Measurement
13 | from .segment import Segment
14 | from .style import Style
15 | 
16 | PaddingDimensions = Union[int, Tuple[int], Tuple[int, int], Tuple[int, int, int, int]]
17 | 
18 | 
19 | class Padding(JupyterMixin):
20 |     """Draw space around content.
21 | 
22 |     Example:
23 |         >>> print(Padding("Hello", (2, 4), style="on blue"))
24 | 
25 |     Args:
26 |         renderable (RenderableType): String or other renderable.
27 |         pad (Union[int, Tuple[int]]): Padding for top, right, bottom, and left borders.
28 |             May be specified with 1, 2, or 4 integers (CSS style).
29 |         style (Union[str, Style], optional): Style for padding characters. Defaults to "none".
30 |         expand (bool, optional): Expand padding to fit available width. Defaults to True.
31 |     """
32 | 
33 |     def __init__(
34 |         self,
35 |         renderable: "RenderableType",
36 |         pad: "PaddingDimensions" = (0, 0, 0, 0),
37 |         *,
38 |         style: Union[str, Style] = "none",
39 |         expand: bool = True,
40 |     ):
41 |         self.renderable = renderable
42 |         self.top, self.right, self.bottom, self.left = self.unpack(pad)
43 |         self.style = style
44 |         self.expand = expand
45 | 
46 |     @classmethod
47 |     def indent(cls, renderable: "RenderableType", level: int) -> "Padding":
48 |         """Make padding instance to render an indent.
49 | 
50 |         Args:
51 |             renderable (RenderableType): String or other renderable.
52 |             level (int): Number of characters to indent.
53 | 
54 |         Returns:
55 |             Padding: A Padding instance.
56 |         """
57 | 
58 |         return Padding(renderable, pad=(0, 0, 0, level), expand=False)
59 | 
60 |     @staticmethod
61 |     def unpack(pad: "PaddingDimensions") -> Tuple[int, int, int, int]:
62 |         """Unpack padding specified in CSS style."""
63 |         if isinstance(pad, int):
64 |             return (pad, pad, pad, pad)
65 |         if len(pad) == 1:
66 |             _pad = pad[0]
67 |             return (_pad, _pad, _pad, _pad)
68 |         if len(pad) == 2:
69 |             pad_top, pad_right = pad
70 |             return (pad_top, pad_right, pad_top, pad_right)
71 |         if len(pad) == 4:
72 |             top, right, bottom, left = pad
73 |             return (top, right, bottom, left)
74 |         raise ValueError(f"1, 2 or 4 integers required for padding; {len(pad)} given")
75 | 
76 |     def __repr__(self) -> str:
77 |         return f"Padding({self.renderable!r}, ({self.top},{self.right},{self.bottom},{self.left}))"
78 | 
79 |     def __rich_console__(
80 |         self, console: "Console", options: "ConsoleOptions"
81 |     ) -> "RenderResult":
82 |         style = console.get_style(self.style)
83 |         if self.expand:
84 |             width = options.max_width
85 |         else:
86 |             width = min(
87 |                 Measurement.get(console, options, self.renderable).maximum
88 |                 + self.left
89 |                 + self.right,
90 |                 options.max_width,
91 |             )
92 |         render_options = options.update_width(width - self.left - self.right)
93 |         if render_options.height is not None:
94 |             render_options = render_options.update_height(
95 |                 height=render_options.height - self.top - self.bottom
96 |             )
97 |         lines = console.render_lines(
98 |             self.renderable, render_options, style=style, pad=True
99 |         )
100 |         _Segment = Segment
101 | 
102 |         left = _Segment(" " * self.left, style) if self.left else None
103 |         right = (
104 |             [_Segment(f'{" " * self.right}', style), _Segment.line()]
105 |             if self.right
106 |             else [_Segment.line()]
107 |         )
108 |         blank_line: Optional[List[Segment]] = None
109 |         if self.top:
110 |             blank_line = [_Segment(f'{" " * width}\n', style)]
111 |             yield from blank_line * self.top
112 |         if left:
113 |             for line in lines:
114 |                 yield left
115 |                 yield from line
116 |                 yield from right
117 |         else:
118 |             for line in lines:
119 |                 yield from line
120 |                 yield from right
121 |         if self.bottom:
122 |             blank_line = blank_line or [_Segment(f'{" " * width}\n', style)]
123 |             yield from blank_line * self.bottom
124 | 
125 |     def __rich_measure__(
126 |         self, console: "Console", options: "ConsoleOptions"
127 |     ) -> "Measurement":
128 |         max_width = options.max_width
129 |         extra_width = self.left + self.right
130 |         if max_width - extra_width < 1:
131 |             return Measurement(max_width, max_width)
132 |         measure_min, measure_max = Measurement.get(console, options, self.renderable)
133 |         measurement = Measurement(measure_min + extra_width, measure_max + extra_width)
134 |         measurement = measurement.with_maximum(max_width)
135 |         return measurement
136 | 
137 | 
138 | if __name__ == "__main__":  #  pragma: no cover
139 |     from pip._vendor.rich import print
140 | 
141 |     print(Padding("Hello, World", (2, 4), style="on blue"))
```

.venv/lib/python3.13/site-packages/pip/_vendor/rich/pager.py
```
1 | from abc import ABC, abstractmethod
2 | from typing import Any
3 | 
4 | 
5 | class Pager(ABC):
6 |     """Base class for a pager."""
7 | 
8 |     @abstractmethod
9 |     def show(self, content: str) -> None:
10 |         """Show content in pager.
11 | 
12 |         Args:
13 |             content (str): Content to be displayed.
14 |         """
15 | 
16 | 
17 | class SystemPager(Pager):
18 |     """Uses the pager installed on the system."""
19 | 
20 |     def _pager(self, content: str) -> Any:  # pragma: no cover
21 |         return __import__("pydoc").pager(content)
22 | 
23 |     def show(self, content: str) -> None:
24 |         """Use the same pager used by pydoc."""
25 |         self._pager(content)
26 | 
27 | 
28 | if __name__ == "__main__":  # pragma: no cover
29 |     from .__main__ import make_test_card
30 |     from .console import Console
31 | 
32 |     console = Console()
33 |     with console.pager(styles=True):
34 |         console.print(make_test_card())
```

.venv/lib/python3.13/site-packages/pip/_vendor/rich/palette.py
```
1 | from math import sqrt
2 | from functools import lru_cache
3 | from typing import Sequence, Tuple, TYPE_CHECKING
4 | 
5 | from .color_triplet import ColorTriplet
6 | 
7 | if TYPE_CHECKING:
8 |     from pip._vendor.rich.table import Table
9 | 
10 | 
11 | class Palette:
12 |     """A palette of available colors."""
13 | 
14 |     def __init__(self, colors: Sequence[Tuple[int, int, int]]):
15 |         self._colors = colors
16 | 
17 |     def __getitem__(self, number: int) -> ColorTriplet:
18 |         return ColorTriplet(*self._colors[number])
19 | 
20 |     def __rich__(self) -> "Table":
21 |         from pip._vendor.rich.color import Color
22 |         from pip._vendor.rich.style import Style
23 |         from pip._vendor.rich.text import Text
24 |         from pip._vendor.rich.table import Table
25 | 
26 |         table = Table(
27 |             "index",
28 |             "RGB",
29 |             "Color",
30 |             title="Palette",
31 |             caption=f"{len(self._colors)} colors",
32 |             highlight=True,
33 |             caption_justify="right",
34 |         )
35 |         for index, color in enumerate(self._colors):
36 |             table.add_row(
37 |                 str(index),
38 |                 repr(color),
39 |                 Text(" " * 16, style=Style(bgcolor=Color.from_rgb(*color))),
40 |             )
41 |         return table
42 | 
43 |     # This is somewhat inefficient and needs caching
44 |     @lru_cache(maxsize=1024)
45 |     def match(self, color: Tuple[int, int, int]) -> int:
46 |         """Find a color from a palette that most closely matches a given color.
47 | 
48 |         Args:
49 |             color (Tuple[int, int, int]): RGB components in range 0 > 255.
50 | 
51 |         Returns:
52 |             int: Index of closes matching color.
53 |         """
54 |         red1, green1, blue1 = color
55 |         _sqrt = sqrt
56 |         get_color = self._colors.__getitem__
57 | 
58 |         def get_color_distance(index: int) -> float:
59 |             """Get the distance to a color."""
60 |             red2, green2, blue2 = get_color(index)
61 |             red_mean = (red1 + red2) // 2
62 |             red = red1 - red2
63 |             green = green1 - green2
64 |             blue = blue1 - blue2
65 |             return _sqrt(
66 |                 (((512 + red_mean) * red * red) >> 8)
67 |                 + 4 * green * green
68 |                 + (((767 - red_mean) * blue * blue) >> 8)
69 |             )
70 | 
71 |         min_index = min(range(len(self._colors)), key=get_color_distance)
72 |         return min_index
73 | 
74 | 
75 | if __name__ == "__main__":  # pragma: no cover
76 |     import colorsys
77 |     from typing import Iterable
78 |     from pip._vendor.rich.color import Color
79 |     from pip._vendor.rich.console import Console, ConsoleOptions
80 |     from pip._vendor.rich.segment import Segment
81 |     from pip._vendor.rich.style import Style
82 | 
83 |     class ColorBox:
84 |         def __rich_console__(
85 |             self, console: Console, options: ConsoleOptions
86 |         ) -> Iterable[Segment]:
87 |             height = console.size.height - 3
88 |             for y in range(0, height):
89 |                 for x in range(options.max_width):
90 |                     h = x / options.max_width
91 |                     l = y / (height + 1)
92 |                     r1, g1, b1 = colorsys.hls_to_rgb(h, l, 1.0)
93 |                     r2, g2, b2 = colorsys.hls_to_rgb(h, l + (1 / height / 2), 1.0)
94 |                     bgcolor = Color.from_rgb(r1 * 255, g1 * 255, b1 * 255)
95 |                     color = Color.from_rgb(r2 * 255, g2 * 255, b2 * 255)
96 |                     yield Segment("", Style(color=color, bgcolor=bgcolor))
97 |                 yield Segment.line()
98 | 
99 |     console = Console()
100 |     console.print(ColorBox())
```

.venv/lib/python3.13/site-packages/pip/_vendor/rich/panel.py
```
1 | from typing import TYPE_CHECKING, Optional
2 | 
3 | from .align import AlignMethod
4 | from .box import ROUNDED, Box
5 | from .cells import cell_len
6 | from .jupyter import JupyterMixin
7 | from .measure import Measurement, measure_renderables
8 | from .padding import Padding, PaddingDimensions
9 | from .segment import Segment
10 | from .style import Style, StyleType
11 | from .text import Text, TextType
12 | 
13 | if TYPE_CHECKING:
14 |     from .console import Console, ConsoleOptions, RenderableType, RenderResult
15 | 
16 | 
17 | class Panel(JupyterMixin):
18 |     """A console renderable that draws a border around its contents.
19 | 
20 |     Example:
21 |         >>> console.print(Panel("Hello, World!"))
22 | 
23 |     Args:
24 |         renderable (RenderableType): A console renderable object.
25 |         box (Box): A Box instance that defines the look of the border (see :ref:`appendix_box`. Defaults to box.ROUNDED.
26 |         title (Optional[TextType], optional): Optional title displayed in panel header. Defaults to None.
27 |         title_align (AlignMethod, optional): Alignment of title. Defaults to "center".
28 |         subtitle (Optional[TextType], optional): Optional subtitle displayed in panel footer. Defaults to None.
29 |         subtitle_align (AlignMethod, optional): Alignment of subtitle. Defaults to "center".
30 |         safe_box (bool, optional): Disable box characters that don't display on windows legacy terminal with *raster* fonts. Defaults to True.
31 |         expand (bool, optional): If True the panel will stretch to fill the console width, otherwise it will be sized to fit the contents. Defaults to True.
32 |         style (str, optional): The style of the panel (border and contents). Defaults to "none".
33 |         border_style (str, optional): The style of the border. Defaults to "none".
34 |         width (Optional[int], optional): Optional width of panel. Defaults to None to auto-detect.
35 |         height (Optional[int], optional): Optional height of panel. Defaults to None to auto-detect.
36 |         padding (Optional[PaddingDimensions]): Optional padding around renderable. Defaults to 0.
37 |         highlight (bool, optional): Enable automatic highlighting of panel title (if str). Defaults to False.
38 |     """
39 | 
40 |     def __init__(
41 |         self,
42 |         renderable: "RenderableType",
43 |         box: Box = ROUNDED,
44 |         *,
45 |         title: Optional[TextType] = None,
46 |         title_align: AlignMethod = "center",
47 |         subtitle: Optional[TextType] = None,
48 |         subtitle_align: AlignMethod = "center",
49 |         safe_box: Optional[bool] = None,
50 |         expand: bool = True,
51 |         style: StyleType = "none",
52 |         border_style: StyleType = "none",
53 |         width: Optional[int] = None,
54 |         height: Optional[int] = None,
55 |         padding: PaddingDimensions = (0, 1),
56 |         highlight: bool = False,
57 |     ) -> None:
58 |         self.renderable = renderable
59 |         self.box = box
60 |         self.title = title
61 |         self.title_align: AlignMethod = title_align
62 |         self.subtitle = subtitle
63 |         self.subtitle_align = subtitle_align
64 |         self.safe_box = safe_box
65 |         self.expand = expand
66 |         self.style = style
67 |         self.border_style = border_style
68 |         self.width = width
69 |         self.height = height
70 |         self.padding = padding
71 |         self.highlight = highlight
72 | 
73 |     @classmethod
74 |     def fit(
75 |         cls,
76 |         renderable: "RenderableType",
77 |         box: Box = ROUNDED,
78 |         *,
79 |         title: Optional[TextType] = None,
80 |         title_align: AlignMethod = "center",
81 |         subtitle: Optional[TextType] = None,
82 |         subtitle_align: AlignMethod = "center",
83 |         safe_box: Optional[bool] = None,
84 |         style: StyleType = "none",
85 |         border_style: StyleType = "none",
86 |         width: Optional[int] = None,
87 |         height: Optional[int] = None,
88 |         padding: PaddingDimensions = (0, 1),
89 |         highlight: bool = False,
90 |     ) -> "Panel":
91 |         """An alternative constructor that sets expand=False."""
92 |         return cls(
93 |             renderable,
94 |             box,
95 |             title=title,
96 |             title_align=title_align,
97 |             subtitle=subtitle,
98 |             subtitle_align=subtitle_align,
99 |             safe_box=safe_box,
100 |             style=style,
101 |             border_style=border_style,
102 |             width=width,
103 |             height=height,
104 |             padding=padding,
105 |             highlight=highlight,
106 |             expand=False,
107 |         )
108 | 
109 |     @property
110 |     def _title(self) -> Optional[Text]:
111 |         if self.title:
112 |             title_text = (
113 |                 Text.from_markup(self.title)
114 |                 if isinstance(self.title, str)
115 |                 else self.title.copy()
116 |             )
117 |             title_text.end = ""
118 |             title_text.plain = title_text.plain.replace("\n", " ")
119 |             title_text.no_wrap = True
120 |             title_text.expand_tabs()
121 |             title_text.pad(1)
122 |             return title_text
123 |         return None
124 | 
125 |     @property
126 |     def _subtitle(self) -> Optional[Text]:
127 |         if self.subtitle:
128 |             subtitle_text = (
129 |                 Text.from_markup(self.subtitle)
130 |                 if isinstance(self.subtitle, str)
131 |                 else self.subtitle.copy()
132 |             )
133 |             subtitle_text.end = ""
134 |             subtitle_text.plain = subtitle_text.plain.replace("\n", " ")
135 |             subtitle_text.no_wrap = True
136 |             subtitle_text.expand_tabs()
137 |             subtitle_text.pad(1)
138 |             return subtitle_text
139 |         return None
140 | 
141 |     def __rich_console__(
142 |         self, console: "Console", options: "ConsoleOptions"
143 |     ) -> "RenderResult":
144 |         _padding = Padding.unpack(self.padding)
145 |         renderable = (
146 |             Padding(self.renderable, _padding) if any(_padding) else self.renderable
147 |         )
148 |         style = console.get_style(self.style)
149 |         partial_border_style = console.get_style(self.border_style)
150 |         border_style = style + partial_border_style
151 |         width = (
152 |             options.max_width
153 |             if self.width is None
154 |             else min(options.max_width, self.width)
155 |         )
156 | 
157 |         safe_box: bool = console.safe_box if self.safe_box is None else self.safe_box
158 |         box = self.box.substitute(options, safe=safe_box)
159 | 
160 |         def align_text(
161 |             text: Text, width: int, align: str, character: str, style: Style
162 |         ) -> Text:
163 |             """Gets new aligned text.
164 | 
165 |             Args:
166 |                 text (Text): Title or subtitle text.
167 |                 width (int): Desired width.
168 |                 align (str): Alignment.
169 |                 character (str): Character for alignment.
170 |                 style (Style): Border style
171 | 
172 |             Returns:
173 |                 Text: New text instance
174 |             """
175 |             text = text.copy()
176 |             text.truncate(width)
177 |             excess_space = width - cell_len(text.plain)
178 |             if text.style:
179 |                 text.stylize(console.get_style(text.style))
180 | 
181 |             if excess_space:
182 |                 if align == "left":
183 |                     return Text.assemble(
184 |                         text,
185 |                         (character * excess_space, style),
186 |                         no_wrap=True,
187 |                         end="",
188 |                     )
189 |                 elif align == "center":
190 |                     left = excess_space // 2
191 |                     return Text.assemble(
192 |                         (character * left, style),
193 |                         text,
194 |                         (character * (excess_space - left), style),
195 |                         no_wrap=True,
196 |                         end="",
197 |                     )
198 |                 else:
199 |                     return Text.assemble(
200 |                         (character * excess_space, style),
201 |                         text,
202 |                         no_wrap=True,
203 |                         end="",
204 |                     )
205 |             return text
206 | 
207 |         title_text = self._title
208 |         if title_text is not None:
209 |             title_text.stylize_before(partial_border_style)
210 | 
211 |         child_width = (
212 |             width - 2
213 |             if self.expand
214 |             else console.measure(
215 |                 renderable, options=options.update_width(width - 2)
216 |             ).maximum
217 |         )
218 |         child_height = self.height or options.height or None
219 |         if child_height:
220 |             child_height -= 2
221 |         if title_text is not None:
222 |             child_width = min(
223 |                 options.max_width - 2, max(child_width, title_text.cell_len + 2)
224 |             )
225 | 
226 |         width = child_width + 2
227 |         child_options = options.update(
228 |             width=child_width, height=child_height, highlight=self.highlight
229 |         )
230 |         lines = console.render_lines(renderable, child_options, style=style)
231 | 
232 |         line_start = Segment(box.mid_left, border_style)
233 |         line_end = Segment(f"{box.mid_right}", border_style)
234 |         new_line = Segment.line()
235 |         if title_text is None or width <= 4:
236 |             yield Segment(box.get_top([width - 2]), border_style)
237 |         else:
238 |             title_text = align_text(
239 |                 title_text,
240 |                 width - 4,
241 |                 self.title_align,
242 |                 box.top,
243 |                 border_style,
244 |             )
245 |             yield Segment(box.top_left + box.top, border_style)
246 |             yield from console.render(title_text, child_options.update_width(width - 4))
247 |             yield Segment(box.top + box.top_right, border_style)
248 | 
249 |         yield new_line
250 |         for line in lines:
251 |             yield line_start
252 |             yield from line
253 |             yield line_end
254 |             yield new_line
255 | 
256 |         subtitle_text = self._subtitle
257 |         if subtitle_text is not None:
258 |             subtitle_text.stylize_before(partial_border_style)
259 | 
260 |         if subtitle_text is None or width <= 4:
261 |             yield Segment(box.get_bottom([width - 2]), border_style)
262 |         else:
263 |             subtitle_text = align_text(
264 |                 subtitle_text,
265 |                 width - 4,
266 |                 self.subtitle_align,
267 |                 box.bottom,
268 |                 border_style,
269 |             )
270 |             yield Segment(box.bottom_left + box.bottom, border_style)
271 |             yield from console.render(
272 |                 subtitle_text, child_options.update_width(width - 4)
273 |             )
274 |             yield Segment(box.bottom + box.bottom_right, border_style)
275 | 
276 |         yield new_line
277 | 
278 |     def __rich_measure__(
279 |         self, console: "Console", options: "ConsoleOptions"
280 |     ) -> "Measurement":
281 |         _title = self._title
282 |         _, right, _, left = Padding.unpack(self.padding)
283 |         padding = left + right
284 |         renderables = [self.renderable, _title] if _title else [self.renderable]
285 | 
286 |         if self.width is None:
287 |             width = (
288 |                 measure_renderables(
289 |                     console,
290 |                     options.update_width(options.max_width - padding - 2),
291 |                     renderables,
292 |                 ).maximum
293 |                 + padding
294 |                 + 2
295 |             )
296 |         else:
297 |             width = self.width
298 |         return Measurement(width, width)
299 | 
300 | 
301 | if __name__ == "__main__":  # pragma: no cover
302 |     from .console import Console
303 | 
304 |     c = Console()
305 | 
306 |     from .box import DOUBLE, ROUNDED
307 |     from .padding import Padding
308 | 
309 |     p = Panel(
310 |         "Hello, World!",
311 |         title="rich.Panel",
312 |         style="white on blue",
313 |         box=DOUBLE,
314 |         padding=1,
315 |     )
316 | 
317 |     c.print()
318 |     c.print(p)
```

.venv/lib/python3.13/site-packages/pip/_vendor/rich/pretty.py
```
1 | import builtins
2 | import collections
3 | import dataclasses
4 | import inspect
5 | import os
6 | import reprlib
7 | import sys
8 | from array import array
9 | from collections import Counter, UserDict, UserList, defaultdict, deque
10 | from dataclasses import dataclass, fields, is_dataclass
11 | from inspect import isclass
12 | from itertools import islice
13 | from types import MappingProxyType
14 | from typing import (
15 |     TYPE_CHECKING,
16 |     Any,
17 |     Callable,
18 |     DefaultDict,
19 |     Deque,
20 |     Dict,
21 |     Iterable,
22 |     List,
23 |     Optional,
24 |     Sequence,
25 |     Set,
26 |     Tuple,
27 |     Union,
28 | )
29 | 
30 | from pip._vendor.rich.repr import RichReprResult
31 | 
32 | try:
33 |     import attr as _attr_module
34 | 
35 |     _has_attrs = hasattr(_attr_module, "ib")
36 | except ImportError:  # pragma: no cover
37 |     _has_attrs = False
38 | 
39 | from . import get_console
40 | from ._loop import loop_last
41 | from ._pick import pick_bool
42 | from .abc import RichRenderable
43 | from .cells import cell_len
44 | from .highlighter import ReprHighlighter
45 | from .jupyter import JupyterMixin, JupyterRenderable
46 | from .measure import Measurement
47 | from .text import Text
48 | 
49 | if TYPE_CHECKING:
50 |     from .console import (
51 |         Console,
52 |         ConsoleOptions,
53 |         HighlighterType,
54 |         JustifyMethod,
55 |         OverflowMethod,
56 |         RenderResult,
57 |     )
58 | 
59 | 
60 | def _is_attr_object(obj: Any) -> bool:
61 |     """Check if an object was created with attrs module."""
62 |     return _has_attrs and _attr_module.has(type(obj))
63 | 
64 | 
65 | def _get_attr_fields(obj: Any) -> Sequence["_attr_module.Attribute[Any]"]:
66 |     """Get fields for an attrs object."""
67 |     return _attr_module.fields(type(obj)) if _has_attrs else []
68 | 
69 | 
70 | def _is_dataclass_repr(obj: object) -> bool:
71 |     """Check if an instance of a dataclass contains the default repr.
72 | 
73 |     Args:
74 |         obj (object): A dataclass instance.
75 | 
76 |     Returns:
77 |         bool: True if the default repr is used, False if there is a custom repr.
78 |     """
79 |     # Digging in to a lot of internals here
80 |     # Catching all exceptions in case something is missing on a non CPython implementation
81 |     try:
82 |         return obj.__repr__.__code__.co_filename in (
83 |             dataclasses.__file__,
84 |             reprlib.__file__,
85 |         )
86 |     except Exception:  # pragma: no coverage
87 |         return False
88 | 
89 | 
90 | _dummy_namedtuple = collections.namedtuple("_dummy_namedtuple", [])
91 | 
92 | 
93 | def _has_default_namedtuple_repr(obj: object) -> bool:
94 |     """Check if an instance of namedtuple contains the default repr
95 | 
96 |     Args:
97 |         obj (object): A namedtuple
98 | 
99 |     Returns:
100 |         bool: True if the default repr is used, False if there's a custom repr.
101 |     """
102 |     obj_file = None
103 |     try:
104 |         obj_file = inspect.getfile(obj.__repr__)
105 |     except (OSError, TypeError):
106 |         # OSError handles case where object is defined in __main__ scope, e.g. REPL - no filename available.
107 |         # TypeError trapped defensively, in case of object without filename slips through.
108 |         pass
109 |     default_repr_file = inspect.getfile(_dummy_namedtuple.__repr__)
110 |     return obj_file == default_repr_file
111 | 
112 | 
113 | def _ipy_display_hook(
114 |     value: Any,
115 |     console: Optional["Console"] = None,
116 |     overflow: "OverflowMethod" = "ignore",
117 |     crop: bool = False,
118 |     indent_guides: bool = False,
119 |     max_length: Optional[int] = None,
120 |     max_string: Optional[int] = None,
121 |     max_depth: Optional[int] = None,
122 |     expand_all: bool = False,
123 | ) -> Union[str, None]:
124 |     # needed here to prevent circular import:
125 |     from .console import ConsoleRenderable
126 | 
127 |     # always skip rich generated jupyter renderables or None values
128 |     if _safe_isinstance(value, JupyterRenderable) or value is None:
129 |         return None
130 | 
131 |     console = console or get_console()
132 | 
133 |     with console.capture() as capture:
134 |         # certain renderables should start on a new line
135 |         if _safe_isinstance(value, ConsoleRenderable):
136 |             console.line()
137 |         console.print(
138 |             (
139 |                 value
140 |                 if _safe_isinstance(value, RichRenderable)
141 |                 else Pretty(
142 |                     value,
143 |                     overflow=overflow,
144 |                     indent_guides=indent_guides,
145 |                     max_length=max_length,
146 |                     max_string=max_string,
147 |                     max_depth=max_depth,
148 |                     expand_all=expand_all,
149 |                     margin=12,
150 |                 )
151 |             ),
152 |             crop=crop,
153 |             new_line_start=True,
154 |             end="",
155 |         )
156 |     # strip trailing newline, not usually part of a text repr
157 |     # I'm not sure if this should be prevented at a lower level
158 |     return capture.get().rstrip("\n")
159 | 
160 | 
161 | def _safe_isinstance(
162 |     obj: object, class_or_tuple: Union[type, Tuple[type, ...]]
163 | ) -> bool:
164 |     """isinstance can fail in rare cases, for example types with no __class__"""
165 |     try:
166 |         return isinstance(obj, class_or_tuple)
167 |     except Exception:
168 |         return False
169 | 
170 | 
171 | def install(
172 |     console: Optional["Console"] = None,
173 |     overflow: "OverflowMethod" = "ignore",
174 |     crop: bool = False,
175 |     indent_guides: bool = False,
176 |     max_length: Optional[int] = None,
177 |     max_string: Optional[int] = None,
178 |     max_depth: Optional[int] = None,
179 |     expand_all: bool = False,
180 | ) -> None:
181 |     """Install automatic pretty printing in the Python REPL.
182 | 
183 |     Args:
184 |         console (Console, optional): Console instance or ``None`` to use global console. Defaults to None.
185 |         overflow (Optional[OverflowMethod], optional): Overflow method. Defaults to "ignore".
186 |         crop (Optional[bool], optional): Enable cropping of long lines. Defaults to False.
187 |         indent_guides (bool, optional): Enable indentation guides. Defaults to False.
188 |         max_length (int, optional): Maximum length of containers before abbreviating, or None for no abbreviation.
189 |             Defaults to None.
190 |         max_string (int, optional): Maximum length of string before truncating, or None to disable. Defaults to None.
191 |         max_depth (int, optional): Maximum depth of nested data structures, or None for no maximum. Defaults to None.
192 |         expand_all (bool, optional): Expand all containers. Defaults to False.
193 |         max_frames (int): Maximum number of frames to show in a traceback, 0 for no maximum. Defaults to 100.
194 |     """
195 |     from pip._vendor.rich import get_console
196 | 
197 |     console = console or get_console()
198 |     assert console is not None
199 | 
200 |     def display_hook(value: Any) -> None:
201 |         """Replacement sys.displayhook which prettifies objects with Rich."""
202 |         if value is not None:
203 |             assert console is not None
204 |             builtins._ = None  # type: ignore[attr-defined]
205 |             console.print(
206 |                 (
207 |                     value
208 |                     if _safe_isinstance(value, RichRenderable)
209 |                     else Pretty(
210 |                         value,
211 |                         overflow=overflow,
212 |                         indent_guides=indent_guides,
213 |                         max_length=max_length,
214 |                         max_string=max_string,
215 |                         max_depth=max_depth,
216 |                         expand_all=expand_all,
217 |                     )
218 |                 ),
219 |                 crop=crop,
220 |             )
221 |             builtins._ = value  # type: ignore[attr-defined]
222 | 
223 |     try:
224 |         ip = get_ipython()  # type: ignore[name-defined]
225 |     except NameError:
226 |         sys.displayhook = display_hook
227 |     else:
228 |         from IPython.core.formatters import BaseFormatter
229 | 
230 |         class RichFormatter(BaseFormatter):  # type: ignore[misc]
231 |             pprint: bool = True
232 | 
233 |             def __call__(self, value: Any) -> Any:
234 |                 if self.pprint:
235 |                     return _ipy_display_hook(
236 |                         value,
237 |                         console=get_console(),
238 |                         overflow=overflow,
239 |                         indent_guides=indent_guides,
240 |                         max_length=max_length,
241 |                         max_string=max_string,
242 |                         max_depth=max_depth,
243 |                         expand_all=expand_all,
244 |                     )
245 |                 else:
246 |                     return repr(value)
247 | 
248 |         # replace plain text formatter with rich formatter
249 |         rich_formatter = RichFormatter()
250 |         ip.display_formatter.formatters["text/plain"] = rich_formatter
251 | 
252 | 
253 | class Pretty(JupyterMixin):
254 |     """A rich renderable that pretty prints an object.
255 | 
256 |     Args:
257 |         _object (Any): An object to pretty print.
258 |         highlighter (HighlighterType, optional): Highlighter object to apply to result, or None for ReprHighlighter. Defaults to None.
259 |         indent_size (int, optional): Number of spaces in indent. Defaults to 4.
260 |         justify (JustifyMethod, optional): Justify method, or None for default. Defaults to None.
261 |         overflow (OverflowMethod, optional): Overflow method, or None for default. Defaults to None.
262 |         no_wrap (Optional[bool], optional): Disable word wrapping. Defaults to False.
263 |         indent_guides (bool, optional): Enable indentation guides. Defaults to False.
264 |         max_length (int, optional): Maximum length of containers before abbreviating, or None for no abbreviation.
265 |             Defaults to None.
266 |         max_string (int, optional): Maximum length of string before truncating, or None to disable. Defaults to None.
267 |         max_depth (int, optional): Maximum depth of nested data structures, or None for no maximum. Defaults to None.
268 |         expand_all (bool, optional): Expand all containers. Defaults to False.
269 |         margin (int, optional): Subtrace a margin from width to force containers to expand earlier. Defaults to 0.
270 |         insert_line (bool, optional): Insert a new line if the output has multiple new lines. Defaults to False.
271 |     """
272 | 
273 |     def __init__(
274 |         self,
275 |         _object: Any,
276 |         highlighter: Optional["HighlighterType"] = None,
277 |         *,
278 |         indent_size: int = 4,
279 |         justify: Optional["JustifyMethod"] = None,
280 |         overflow: Optional["OverflowMethod"] = None,
281 |         no_wrap: Optional[bool] = False,
282 |         indent_guides: bool = False,
283 |         max_length: Optional[int] = None,
284 |         max_string: Optional[int] = None,
285 |         max_depth: Optional[int] = None,
286 |         expand_all: bool = False,
287 |         margin: int = 0,
288 |         insert_line: bool = False,
289 |     ) -> None:
290 |         self._object = _object
291 |         self.highlighter = highlighter or ReprHighlighter()
292 |         self.indent_size = indent_size
293 |         self.justify: Optional["JustifyMethod"] = justify
294 |         self.overflow: Optional["OverflowMethod"] = overflow
295 |         self.no_wrap = no_wrap
296 |         self.indent_guides = indent_guides
297 |         self.max_length = max_length
298 |         self.max_string = max_string
299 |         self.max_depth = max_depth
300 |         self.expand_all = expand_all
301 |         self.margin = margin
302 |         self.insert_line = insert_line
303 | 
304 |     def __rich_console__(
305 |         self, console: "Console", options: "ConsoleOptions"
306 |     ) -> "RenderResult":
307 |         pretty_str = pretty_repr(
308 |             self._object,
309 |             max_width=options.max_width - self.margin,
310 |             indent_size=self.indent_size,
311 |             max_length=self.max_length,
312 |             max_string=self.max_string,
313 |             max_depth=self.max_depth,
314 |             expand_all=self.expand_all,
315 |         )
316 |         pretty_text = Text.from_ansi(
317 |             pretty_str,
318 |             justify=self.justify or options.justify,
319 |             overflow=self.overflow or options.overflow,
320 |             no_wrap=pick_bool(self.no_wrap, options.no_wrap),
321 |             style="pretty",
322 |         )
323 |         pretty_text = (
324 |             self.highlighter(pretty_text)
325 |             if pretty_text
326 |             else Text(
327 |                 f"{type(self._object)}.__repr__ returned empty string",
328 |                 style="dim italic",
329 |             )
330 |         )
331 |         if self.indent_guides and not options.ascii_only:
332 |             pretty_text = pretty_text.with_indent_guides(
333 |                 self.indent_size, style="repr.indent"
334 |             )
335 |         if self.insert_line and "\n" in pretty_text:
336 |             yield ""
337 |         yield pretty_text
338 | 
339 |     def __rich_measure__(
340 |         self, console: "Console", options: "ConsoleOptions"
341 |     ) -> "Measurement":
342 |         pretty_str = pretty_repr(
343 |             self._object,
344 |             max_width=options.max_width,
345 |             indent_size=self.indent_size,
346 |             max_length=self.max_length,
347 |             max_string=self.max_string,
348 |             max_depth=self.max_depth,
349 |             expand_all=self.expand_all,
350 |         )
351 |         text_width = (
352 |             max(cell_len(line) for line in pretty_str.splitlines()) if pretty_str else 0
353 |         )
354 |         return Measurement(text_width, text_width)
355 | 
356 | 
357 | def _get_braces_for_defaultdict(_object: DefaultDict[Any, Any]) -> Tuple[str, str, str]:
358 |     return (
359 |         f"defaultdict({_object.default_factory!r}, {{",
360 |         "})",
361 |         f"defaultdict({_object.default_factory!r}, {{}})",
362 |     )
363 | 
364 | 
365 | def _get_braces_for_deque(_object: Deque[Any]) -> Tuple[str, str, str]:
[TRUNCATED]
```

.venv/lib/python3.13/site-packages/pip/_vendor/rich/progress.py
```
1 | import io
2 | import sys
3 | import typing
4 | import warnings
5 | from abc import ABC, abstractmethod
6 | from collections import deque
7 | from dataclasses import dataclass, field
8 | from datetime import timedelta
9 | from io import RawIOBase, UnsupportedOperation
10 | from math import ceil
11 | from mmap import mmap
12 | from operator import length_hint
13 | from os import PathLike, stat
14 | from threading import Event, RLock, Thread
15 | from types import TracebackType
16 | from typing import (
17 |     Any,
18 |     BinaryIO,
19 |     Callable,
20 |     ContextManager,
21 |     Deque,
22 |     Dict,
23 |     Generic,
24 |     Iterable,
25 |     List,
26 |     NamedTuple,
27 |     NewType,
28 |     Optional,
29 |     Sequence,
30 |     TextIO,
31 |     Tuple,
32 |     Type,
33 |     TypeVar,
34 |     Union,
35 | )
36 | 
37 | if sys.version_info >= (3, 8):
38 |     from typing import Literal
39 | else:
40 |     from pip._vendor.typing_extensions import Literal  # pragma: no cover
41 | 
42 | if sys.version_info >= (3, 11):
43 |     from typing import Self
44 | else:
45 |     from pip._vendor.typing_extensions import Self  # pragma: no cover
46 | 
47 | from . import filesize, get_console
48 | from .console import Console, Group, JustifyMethod, RenderableType
49 | from .highlighter import Highlighter
50 | from .jupyter import JupyterMixin
51 | from .live import Live
52 | from .progress_bar import ProgressBar
53 | from .spinner import Spinner
54 | from .style import StyleType
55 | from .table import Column, Table
56 | from .text import Text, TextType
57 | 
58 | TaskID = NewType("TaskID", int)
59 | 
60 | ProgressType = TypeVar("ProgressType")
61 | 
62 | GetTimeCallable = Callable[[], float]
63 | 
64 | 
65 | _I = typing.TypeVar("_I", TextIO, BinaryIO)
66 | 
67 | 
68 | class _TrackThread(Thread):
69 |     """A thread to periodically update progress."""
70 | 
71 |     def __init__(self, progress: "Progress", task_id: "TaskID", update_period: float):
72 |         self.progress = progress
73 |         self.task_id = task_id
74 |         self.update_period = update_period
75 |         self.done = Event()
76 | 
77 |         self.completed = 0
78 |         super().__init__(daemon=True)
79 | 
80 |     def run(self) -> None:
81 |         task_id = self.task_id
82 |         advance = self.progress.advance
83 |         update_period = self.update_period
84 |         last_completed = 0
85 |         wait = self.done.wait
86 |         while not wait(update_period) and self.progress.live.is_started:
87 |             completed = self.completed
88 |             if last_completed != completed:
89 |                 advance(task_id, completed - last_completed)
90 |                 last_completed = completed
91 | 
92 |         self.progress.update(self.task_id, completed=self.completed, refresh=True)
93 | 
94 |     def __enter__(self) -> "_TrackThread":
95 |         self.start()
96 |         return self
97 | 
98 |     def __exit__(
99 |         self,
100 |         exc_type: Optional[Type[BaseException]],
101 |         exc_val: Optional[BaseException],
102 |         exc_tb: Optional[TracebackType],
103 |     ) -> None:
104 |         self.done.set()
105 |         self.join()
106 | 
107 | 
108 | def track(
109 |     sequence: Union[Sequence[ProgressType], Iterable[ProgressType]],
110 |     description: str = "Working...",
111 |     total: Optional[float] = None,
112 |     completed: int = 0,
113 |     auto_refresh: bool = True,
114 |     console: Optional[Console] = None,
115 |     transient: bool = False,
116 |     get_time: Optional[Callable[[], float]] = None,
117 |     refresh_per_second: float = 10,
118 |     style: StyleType = "bar.back",
119 |     complete_style: StyleType = "bar.complete",
120 |     finished_style: StyleType = "bar.finished",
121 |     pulse_style: StyleType = "bar.pulse",
122 |     update_period: float = 0.1,
123 |     disable: bool = False,
124 |     show_speed: bool = True,
125 | ) -> Iterable[ProgressType]:
126 |     """Track progress by iterating over a sequence.
127 | 
128 |     Args:
129 |         sequence (Iterable[ProgressType]): A sequence (must support "len") you wish to iterate over.
130 |         description (str, optional): Description of task show next to progress bar. Defaults to "Working".
131 |         total: (float, optional): Total number of steps. Default is len(sequence).
132 |         completed (int, optional): Number of steps completed so far. Defaults to 0.
133 |         auto_refresh (bool, optional): Automatic refresh, disable to force a refresh after each iteration. Default is True.
134 |         transient: (bool, optional): Clear the progress on exit. Defaults to False.
135 |         console (Console, optional): Console to write to. Default creates internal Console instance.
136 |         refresh_per_second (float): Number of times per second to refresh the progress information. Defaults to 10.
137 |         style (StyleType, optional): Style for the bar background. Defaults to "bar.back".
138 |         complete_style (StyleType, optional): Style for the completed bar. Defaults to "bar.complete".
139 |         finished_style (StyleType, optional): Style for a finished bar. Defaults to "bar.finished".
140 |         pulse_style (StyleType, optional): Style for pulsing bars. Defaults to "bar.pulse".
141 |         update_period (float, optional): Minimum time (in seconds) between calls to update(). Defaults to 0.1.
142 |         disable (bool, optional): Disable display of progress.
143 |         show_speed (bool, optional): Show speed if total isn't known. Defaults to True.
144 |     Returns:
145 |         Iterable[ProgressType]: An iterable of the values in the sequence.
146 | 
147 |     """
148 | 
149 |     columns: List["ProgressColumn"] = (
150 |         [TextColumn("[progress.description]{task.description}")] if description else []
151 |     )
152 |     columns.extend(
153 |         (
154 |             BarColumn(
155 |                 style=style,
156 |                 complete_style=complete_style,
157 |                 finished_style=finished_style,
158 |                 pulse_style=pulse_style,
159 |             ),
160 |             TaskProgressColumn(show_speed=show_speed),
161 |             TimeRemainingColumn(elapsed_when_finished=True),
162 |         )
163 |     )
164 |     progress = Progress(
165 |         *columns,
166 |         auto_refresh=auto_refresh,
167 |         console=console,
168 |         transient=transient,
169 |         get_time=get_time,
170 |         refresh_per_second=refresh_per_second or 10,
171 |         disable=disable,
172 |     )
173 | 
174 |     with progress:
175 |         yield from progress.track(
176 |             sequence,
177 |             total=total,
178 |             completed=completed,
179 |             description=description,
180 |             update_period=update_period,
181 |         )
182 | 
183 | 
184 | class _Reader(RawIOBase, BinaryIO):
185 |     """A reader that tracks progress while it's being read from."""
186 | 
187 |     def __init__(
188 |         self,
189 |         handle: BinaryIO,
190 |         progress: "Progress",
191 |         task: TaskID,
192 |         close_handle: bool = True,
193 |     ) -> None:
194 |         self.handle = handle
195 |         self.progress = progress
196 |         self.task = task
197 |         self.close_handle = close_handle
198 |         self._closed = False
199 | 
200 |     def __enter__(self) -> "_Reader":
201 |         self.handle.__enter__()
202 |         return self
203 | 
204 |     def __exit__(
205 |         self,
206 |         exc_type: Optional[Type[BaseException]],
207 |         exc_val: Optional[BaseException],
208 |         exc_tb: Optional[TracebackType],
209 |     ) -> None:
210 |         self.close()
211 | 
212 |     def __iter__(self) -> BinaryIO:
213 |         return self
214 | 
215 |     def __next__(self) -> bytes:
216 |         line = next(self.handle)
217 |         self.progress.advance(self.task, advance=len(line))
218 |         return line
219 | 
220 |     @property
221 |     def closed(self) -> bool:
222 |         return self._closed
223 | 
224 |     def fileno(self) -> int:
225 |         return self.handle.fileno()
226 | 
227 |     def isatty(self) -> bool:
228 |         return self.handle.isatty()
229 | 
230 |     @property
231 |     def mode(self) -> str:
232 |         return self.handle.mode
233 | 
234 |     @property
235 |     def name(self) -> str:
236 |         return self.handle.name
237 | 
238 |     def readable(self) -> bool:
239 |         return self.handle.readable()
240 | 
241 |     def seekable(self) -> bool:
242 |         return self.handle.seekable()
243 | 
244 |     def writable(self) -> bool:
245 |         return False
246 | 
247 |     def read(self, size: int = -1) -> bytes:
248 |         block = self.handle.read(size)
249 |         self.progress.advance(self.task, advance=len(block))
250 |         return block
251 | 
252 |     def readinto(self, b: Union[bytearray, memoryview, mmap]):  # type: ignore[no-untyped-def, override]
253 |         n = self.handle.readinto(b)  # type: ignore[attr-defined]
254 |         self.progress.advance(self.task, advance=n)
255 |         return n
256 | 
257 |     def readline(self, size: int = -1) -> bytes:  # type: ignore[override]
258 |         line = self.handle.readline(size)
259 |         self.progress.advance(self.task, advance=len(line))
260 |         return line
261 | 
262 |     def readlines(self, hint: int = -1) -> List[bytes]:
263 |         lines = self.handle.readlines(hint)
264 |         self.progress.advance(self.task, advance=sum(map(len, lines)))
265 |         return lines
266 | 
267 |     def close(self) -> None:
268 |         if self.close_handle:
269 |             self.handle.close()
270 |         self._closed = True
271 | 
272 |     def seek(self, offset: int, whence: int = 0) -> int:
273 |         pos = self.handle.seek(offset, whence)
274 |         self.progress.update(self.task, completed=pos)
275 |         return pos
276 | 
277 |     def tell(self) -> int:
278 |         return self.handle.tell()
279 | 
280 |     def write(self, s: Any) -> int:
281 |         raise UnsupportedOperation("write")
282 | 
283 |     def writelines(self, lines: Iterable[Any]) -> None:
284 |         raise UnsupportedOperation("writelines")
285 | 
286 | 
287 | class _ReadContext(ContextManager[_I], Generic[_I]):
288 |     """A utility class to handle a context for both a reader and a progress."""
289 | 
290 |     def __init__(self, progress: "Progress", reader: _I) -> None:
291 |         self.progress = progress
292 |         self.reader: _I = reader
293 | 
294 |     def __enter__(self) -> _I:
295 |         self.progress.start()
296 |         return self.reader.__enter__()
297 | 
298 |     def __exit__(
299 |         self,
300 |         exc_type: Optional[Type[BaseException]],
301 |         exc_val: Optional[BaseException],
302 |         exc_tb: Optional[TracebackType],
303 |     ) -> None:
304 |         self.progress.stop()
305 |         self.reader.__exit__(exc_type, exc_val, exc_tb)
306 | 
307 | 
308 | def wrap_file(
309 |     file: BinaryIO,
310 |     total: int,
311 |     *,
312 |     description: str = "Reading...",
313 |     auto_refresh: bool = True,
314 |     console: Optional[Console] = None,
315 |     transient: bool = False,
316 |     get_time: Optional[Callable[[], float]] = None,
317 |     refresh_per_second: float = 10,
318 |     style: StyleType = "bar.back",
319 |     complete_style: StyleType = "bar.complete",
320 |     finished_style: StyleType = "bar.finished",
321 |     pulse_style: StyleType = "bar.pulse",
322 |     disable: bool = False,
323 | ) -> ContextManager[BinaryIO]:
324 |     """Read bytes from a file while tracking progress.
325 | 
326 |     Args:
327 |         file (Union[str, PathLike[str], BinaryIO]): The path to the file to read, or a file-like object in binary mode.
328 |         total (int): Total number of bytes to read.
329 |         description (str, optional): Description of task show next to progress bar. Defaults to "Reading".
330 |         auto_refresh (bool, optional): Automatic refresh, disable to force a refresh after each iteration. Default is True.
331 |         transient: (bool, optional): Clear the progress on exit. Defaults to False.
332 |         console (Console, optional): Console to write to. Default creates internal Console instance.
333 |         refresh_per_second (float): Number of times per second to refresh the progress information. Defaults to 10.
334 |         style (StyleType, optional): Style for the bar background. Defaults to "bar.back".
335 |         complete_style (StyleType, optional): Style for the completed bar. Defaults to "bar.complete".
336 |         finished_style (StyleType, optional): Style for a finished bar. Defaults to "bar.finished".
337 |         pulse_style (StyleType, optional): Style for pulsing bars. Defaults to "bar.pulse".
338 |         disable (bool, optional): Disable display of progress.
339 |     Returns:
340 |         ContextManager[BinaryIO]: A context manager yielding a progress reader.
341 | 
342 |     """
343 | 
344 |     columns: List["ProgressColumn"] = (
345 |         [TextColumn("[progress.description]{task.description}")] if description else []
346 |     )
347 |     columns.extend(
348 |         (
349 |             BarColumn(
350 |                 style=style,
351 |                 complete_style=complete_style,
352 |                 finished_style=finished_style,
353 |                 pulse_style=pulse_style,
354 |             ),
355 |             DownloadColumn(),
356 |             TimeRemainingColumn(),
357 |         )
358 |     )
359 |     progress = Progress(
360 |         *columns,
361 |         auto_refresh=auto_refresh,
362 |         console=console,
363 |         transient=transient,
364 |         get_time=get_time,
365 |         refresh_per_second=refresh_per_second or 10,
366 |         disable=disable,
367 |     )
368 | 
369 |     reader = progress.wrap_file(file, total=total, description=description)
370 |     return _ReadContext(progress, reader)
371 | 
372 | 
373 | @typing.overload
374 | def open(
375 |     file: Union[str, "PathLike[str]", bytes],
376 |     mode: Union[Literal["rt"], Literal["r"]],
377 |     buffering: int = -1,
378 |     encoding: Optional[str] = None,
379 |     errors: Optional[str] = None,
[TRUNCATED]
```

.venv/lib/python3.13/site-packages/pip/_vendor/rich/progress_bar.py
```
1 | import math
2 | from functools import lru_cache
3 | from time import monotonic
4 | from typing import Iterable, List, Optional
5 | 
6 | from .color import Color, blend_rgb
7 | from .color_triplet import ColorTriplet
8 | from .console import Console, ConsoleOptions, RenderResult
9 | from .jupyter import JupyterMixin
10 | from .measure import Measurement
11 | from .segment import Segment
12 | from .style import Style, StyleType
13 | 
14 | # Number of characters before 'pulse' animation repeats
15 | PULSE_SIZE = 20
16 | 
17 | 
18 | class ProgressBar(JupyterMixin):
19 |     """Renders a (progress) bar. Used by rich.progress.
20 | 
21 |     Args:
22 |         total (float, optional): Number of steps in the bar. Defaults to 100. Set to None to render a pulsing animation.
23 |         completed (float, optional): Number of steps completed. Defaults to 0.
24 |         width (int, optional): Width of the bar, or ``None`` for maximum width. Defaults to None.
25 |         pulse (bool, optional): Enable pulse effect. Defaults to False. Will pulse if a None total was passed.
26 |         style (StyleType, optional): Style for the bar background. Defaults to "bar.back".
27 |         complete_style (StyleType, optional): Style for the completed bar. Defaults to "bar.complete".
28 |         finished_style (StyleType, optional): Style for a finished bar. Defaults to "bar.finished".
29 |         pulse_style (StyleType, optional): Style for pulsing bars. Defaults to "bar.pulse".
30 |         animation_time (Optional[float], optional): Time in seconds to use for animation, or None to use system time.
31 |     """
32 | 
33 |     def __init__(
34 |         self,
35 |         total: Optional[float] = 100.0,
36 |         completed: float = 0,
37 |         width: Optional[int] = None,
38 |         pulse: bool = False,
39 |         style: StyleType = "bar.back",
40 |         complete_style: StyleType = "bar.complete",
41 |         finished_style: StyleType = "bar.finished",
42 |         pulse_style: StyleType = "bar.pulse",
43 |         animation_time: Optional[float] = None,
44 |     ):
45 |         self.total = total
46 |         self.completed = completed
47 |         self.width = width
48 |         self.pulse = pulse
49 |         self.style = style
50 |         self.complete_style = complete_style
51 |         self.finished_style = finished_style
52 |         self.pulse_style = pulse_style
53 |         self.animation_time = animation_time
54 | 
55 |         self._pulse_segments: Optional[List[Segment]] = None
56 | 
57 |     def __repr__(self) -> str:
58 |         return f"<Bar {self.completed!r} of {self.total!r}>"
59 | 
60 |     @property
61 |     def percentage_completed(self) -> Optional[float]:
62 |         """Calculate percentage complete."""
63 |         if self.total is None:
64 |             return None
65 |         completed = (self.completed / self.total) * 100.0
66 |         completed = min(100, max(0.0, completed))
67 |         return completed
68 | 
69 |     @lru_cache(maxsize=16)
70 |     def _get_pulse_segments(
71 |         self,
72 |         fore_style: Style,
73 |         back_style: Style,
74 |         color_system: str,
75 |         no_color: bool,
76 |         ascii: bool = False,
77 |     ) -> List[Segment]:
78 |         """Get a list of segments to render a pulse animation.
79 | 
80 |         Returns:
81 |             List[Segment]: A list of segments, one segment per character.
82 |         """
83 |         bar = "-" if ascii else ""
84 |         segments: List[Segment] = []
85 |         if color_system not in ("standard", "eight_bit", "truecolor") or no_color:
86 |             segments += [Segment(bar, fore_style)] * (PULSE_SIZE // 2)
87 |             segments += [Segment(" " if no_color else bar, back_style)] * (
88 |                 PULSE_SIZE - (PULSE_SIZE // 2)
89 |             )
90 |             return segments
91 | 
92 |         append = segments.append
93 |         fore_color = (
94 |             fore_style.color.get_truecolor()
95 |             if fore_style.color
96 |             else ColorTriplet(255, 0, 255)
97 |         )
98 |         back_color = (
99 |             back_style.color.get_truecolor()
100 |             if back_style.color
101 |             else ColorTriplet(0, 0, 0)
102 |         )
103 |         cos = math.cos
104 |         pi = math.pi
105 |         _Segment = Segment
106 |         _Style = Style
107 |         from_triplet = Color.from_triplet
108 | 
109 |         for index in range(PULSE_SIZE):
110 |             position = index / PULSE_SIZE
111 |             fade = 0.5 + cos(position * pi * 2) / 2.0
112 |             color = blend_rgb(fore_color, back_color, cross_fade=fade)
113 |             append(_Segment(bar, _Style(color=from_triplet(color))))
114 |         return segments
115 | 
116 |     def update(self, completed: float, total: Optional[float] = None) -> None:
117 |         """Update progress with new values.
118 | 
119 |         Args:
120 |             completed (float): Number of steps completed.
121 |             total (float, optional): Total number of steps, or ``None`` to not change. Defaults to None.
122 |         """
123 |         self.completed = completed
124 |         self.total = total if total is not None else self.total
125 | 
126 |     def _render_pulse(
127 |         self, console: Console, width: int, ascii: bool = False
128 |     ) -> Iterable[Segment]:
129 |         """Renders the pulse animation.
130 | 
131 |         Args:
132 |             console (Console): Console instance.
133 |             width (int): Width in characters of pulse animation.
134 | 
135 |         Returns:
136 |             RenderResult: [description]
137 | 
138 |         Yields:
139 |             Iterator[Segment]: Segments to render pulse
140 |         """
141 |         fore_style = console.get_style(self.pulse_style, default="white")
142 |         back_style = console.get_style(self.style, default="black")
143 | 
144 |         pulse_segments = self._get_pulse_segments(
145 |             fore_style, back_style, console.color_system, console.no_color, ascii=ascii
146 |         )
147 |         segment_count = len(pulse_segments)
148 |         current_time = (
149 |             monotonic() if self.animation_time is None else self.animation_time
150 |         )
151 |         segments = pulse_segments * (int(width / segment_count) + 2)
152 |         offset = int(-current_time * 15) % segment_count
153 |         segments = segments[offset : offset + width]
154 |         yield from segments
155 | 
156 |     def __rich_console__(
157 |         self, console: Console, options: ConsoleOptions
158 |     ) -> RenderResult:
159 |         width = min(self.width or options.max_width, options.max_width)
160 |         ascii = options.legacy_windows or options.ascii_only
161 |         should_pulse = self.pulse or self.total is None
162 |         if should_pulse:
163 |             yield from self._render_pulse(console, width, ascii=ascii)
164 |             return
165 | 
166 |         completed: Optional[float] = (
167 |             min(self.total, max(0, self.completed)) if self.total is not None else None
168 |         )
169 | 
170 |         bar = "-" if ascii else ""
171 |         half_bar_right = " " if ascii else ""
172 |         half_bar_left = " " if ascii else ""
173 |         complete_halves = (
174 |             int(width * 2 * completed / self.total)
175 |             if self.total and completed is not None
176 |             else width * 2
177 |         )
178 |         bar_count = complete_halves // 2
179 |         half_bar_count = complete_halves % 2
180 |         style = console.get_style(self.style)
181 |         is_finished = self.total is None or self.completed >= self.total
182 |         complete_style = console.get_style(
183 |             self.finished_style if is_finished else self.complete_style
184 |         )
185 |         _Segment = Segment
186 |         if bar_count:
187 |             yield _Segment(bar * bar_count, complete_style)
188 |         if half_bar_count:
189 |             yield _Segment(half_bar_right * half_bar_count, complete_style)
190 | 
191 |         if not console.no_color:
192 |             remaining_bars = width - bar_count - half_bar_count
193 |             if remaining_bars and console.color_system is not None:
194 |                 if not half_bar_count and bar_count:
195 |                     yield _Segment(half_bar_left, style)
196 |                     remaining_bars -= 1
197 |                 if remaining_bars:
198 |                     yield _Segment(bar * remaining_bars, style)
199 | 
200 |     def __rich_measure__(
201 |         self, console: Console, options: ConsoleOptions
202 |     ) -> Measurement:
203 |         return (
204 |             Measurement(self.width, self.width)
205 |             if self.width is not None
206 |             else Measurement(4, options.max_width)
207 |         )
208 | 
209 | 
210 | if __name__ == "__main__":  # pragma: no cover
211 |     console = Console()
212 |     bar = ProgressBar(width=50, total=100)
213 | 
214 |     import time
215 | 
216 |     console.show_cursor(False)
217 |     for n in range(0, 101, 1):
218 |         bar.update(n)
219 |         console.print(bar)
220 |         console.file.write("\r")
221 |         time.sleep(0.05)
222 |     console.show_cursor(True)
223 |     console.print()
```

.venv/lib/python3.13/site-packages/pip/_vendor/rich/prompt.py
```
1 | from typing import Any, Generic, List, Optional, TextIO, TypeVar, Union, overload
2 | 
3 | from . import get_console
4 | from .console import Console
5 | from .text import Text, TextType
6 | 
7 | PromptType = TypeVar("PromptType")
8 | DefaultType = TypeVar("DefaultType")
9 | 
10 | 
11 | class PromptError(Exception):
12 |     """Exception base class for prompt related errors."""
13 | 
14 | 
15 | class InvalidResponse(PromptError):
16 |     """Exception to indicate a response was invalid. Raise this within process_response() to indicate an error
17 |     and provide an error message.
18 | 
19 |     Args:
20 |         message (Union[str, Text]): Error message.
21 |     """
22 | 
23 |     def __init__(self, message: TextType) -> None:
24 |         self.message = message
25 | 
26 |     def __rich__(self) -> TextType:
27 |         return self.message
28 | 
29 | 
30 | class PromptBase(Generic[PromptType]):
31 |     """Ask the user for input until a valid response is received. This is the base class, see one of
32 |     the concrete classes for examples.
33 | 
34 |     Args:
35 |         prompt (TextType, optional): Prompt text. Defaults to "".
36 |         console (Console, optional): A Console instance or None to use global console. Defaults to None.
37 |         password (bool, optional): Enable password input. Defaults to False.
38 |         choices (List[str], optional): A list of valid choices. Defaults to None.
39 |         case_sensitive (bool, optional): Matching of choices should be case-sensitive. Defaults to True.
40 |         show_default (bool, optional): Show default in prompt. Defaults to True.
41 |         show_choices (bool, optional): Show choices in prompt. Defaults to True.
42 |     """
43 | 
44 |     response_type: type = str
45 | 
46 |     validate_error_message = "[prompt.invalid]Please enter a valid value"
47 |     illegal_choice_message = (
48 |         "[prompt.invalid.choice]Please select one of the available options"
49 |     )
50 |     prompt_suffix = ": "
51 | 
52 |     choices: Optional[List[str]] = None
53 | 
54 |     def __init__(
55 |         self,
56 |         prompt: TextType = "",
57 |         *,
58 |         console: Optional[Console] = None,
59 |         password: bool = False,
60 |         choices: Optional[List[str]] = None,
61 |         case_sensitive: bool = True,
62 |         show_default: bool = True,
63 |         show_choices: bool = True,
64 |     ) -> None:
65 |         self.console = console or get_console()
66 |         self.prompt = (
67 |             Text.from_markup(prompt, style="prompt")
68 |             if isinstance(prompt, str)
69 |             else prompt
70 |         )
71 |         self.password = password
72 |         if choices is not None:
73 |             self.choices = choices
74 |         self.case_sensitive = case_sensitive
75 |         self.show_default = show_default
76 |         self.show_choices = show_choices
77 | 
78 |     @classmethod
79 |     @overload
80 |     def ask(
81 |         cls,
82 |         prompt: TextType = "",
83 |         *,
84 |         console: Optional[Console] = None,
85 |         password: bool = False,
86 |         choices: Optional[List[str]] = None,
87 |         case_sensitive: bool = True,
88 |         show_default: bool = True,
89 |         show_choices: bool = True,
90 |         default: DefaultType,
91 |         stream: Optional[TextIO] = None,
92 |     ) -> Union[DefaultType, PromptType]:
93 |         ...
94 | 
95 |     @classmethod
96 |     @overload
97 |     def ask(
98 |         cls,
99 |         prompt: TextType = "",
100 |         *,
101 |         console: Optional[Console] = None,
102 |         password: bool = False,
103 |         choices: Optional[List[str]] = None,
104 |         case_sensitive: bool = True,
105 |         show_default: bool = True,
106 |         show_choices: bool = True,
107 |         stream: Optional[TextIO] = None,
108 |     ) -> PromptType:
109 |         ...
110 | 
111 |     @classmethod
112 |     def ask(
113 |         cls,
114 |         prompt: TextType = "",
115 |         *,
116 |         console: Optional[Console] = None,
117 |         password: bool = False,
118 |         choices: Optional[List[str]] = None,
119 |         case_sensitive: bool = True,
120 |         show_default: bool = True,
121 |         show_choices: bool = True,
122 |         default: Any = ...,
123 |         stream: Optional[TextIO] = None,
124 |     ) -> Any:
125 |         """Shortcut to construct and run a prompt loop and return the result.
126 | 
127 |         Example:
128 |             >>> filename = Prompt.ask("Enter a filename")
129 | 
130 |         Args:
131 |             prompt (TextType, optional): Prompt text. Defaults to "".
132 |             console (Console, optional): A Console instance or None to use global console. Defaults to None.
133 |             password (bool, optional): Enable password input. Defaults to False.
134 |             choices (List[str], optional): A list of valid choices. Defaults to None.
135 |             case_sensitive (bool, optional): Matching of choices should be case-sensitive. Defaults to True.
136 |             show_default (bool, optional): Show default in prompt. Defaults to True.
137 |             show_choices (bool, optional): Show choices in prompt. Defaults to True.
138 |             stream (TextIO, optional): Optional text file open for reading to get input. Defaults to None.
139 |         """
140 |         _prompt = cls(
141 |             prompt,
142 |             console=console,
143 |             password=password,
144 |             choices=choices,
145 |             case_sensitive=case_sensitive,
146 |             show_default=show_default,
147 |             show_choices=show_choices,
148 |         )
149 |         return _prompt(default=default, stream=stream)
150 | 
151 |     def render_default(self, default: DefaultType) -> Text:
152 |         """Turn the supplied default in to a Text instance.
153 | 
154 |         Args:
155 |             default (DefaultType): Default value.
156 | 
157 |         Returns:
158 |             Text: Text containing rendering of default value.
159 |         """
160 |         return Text(f"({default})", "prompt.default")
161 | 
162 |     def make_prompt(self, default: DefaultType) -> Text:
163 |         """Make prompt text.
164 | 
165 |         Args:
166 |             default (DefaultType): Default value.
167 | 
168 |         Returns:
169 |             Text: Text to display in prompt.
170 |         """
171 |         prompt = self.prompt.copy()
172 |         prompt.end = ""
173 | 
174 |         if self.show_choices and self.choices:
175 |             _choices = "/".join(self.choices)
176 |             choices = f"[{_choices}]"
177 |             prompt.append(" ")
178 |             prompt.append(choices, "prompt.choices")
179 | 
180 |         if (
181 |             default != ...
182 |             and self.show_default
183 |             and isinstance(default, (str, self.response_type))
184 |         ):
185 |             prompt.append(" ")
186 |             _default = self.render_default(default)
187 |             prompt.append(_default)
188 | 
189 |         prompt.append(self.prompt_suffix)
190 | 
191 |         return prompt
192 | 
193 |     @classmethod
194 |     def get_input(
195 |         cls,
196 |         console: Console,
197 |         prompt: TextType,
198 |         password: bool,
199 |         stream: Optional[TextIO] = None,
200 |     ) -> str:
201 |         """Get input from user.
202 | 
203 |         Args:
204 |             console (Console): Console instance.
205 |             prompt (TextType): Prompt text.
206 |             password (bool): Enable password entry.
207 | 
208 |         Returns:
209 |             str: String from user.
210 |         """
211 |         return console.input(prompt, password=password, stream=stream)
212 | 
213 |     def check_choice(self, value: str) -> bool:
214 |         """Check value is in the list of valid choices.
215 | 
216 |         Args:
217 |             value (str): Value entered by user.
218 | 
219 |         Returns:
220 |             bool: True if choice was valid, otherwise False.
221 |         """
222 |         assert self.choices is not None
223 |         if self.case_sensitive:
224 |             return value.strip() in self.choices
225 |         return value.strip().lower() in [choice.lower() for choice in self.choices]
226 | 
227 |     def process_response(self, value: str) -> PromptType:
228 |         """Process response from user, convert to prompt type.
229 | 
230 |         Args:
231 |             value (str): String typed by user.
232 | 
233 |         Raises:
234 |             InvalidResponse: If ``value`` is invalid.
235 | 
236 |         Returns:
237 |             PromptType: The value to be returned from ask method.
238 |         """
239 |         value = value.strip()
240 |         try:
241 |             return_value: PromptType = self.response_type(value)
242 |         except ValueError:
243 |             raise InvalidResponse(self.validate_error_message)
244 | 
245 |         if self.choices is not None:
246 |             if not self.check_choice(value):
247 |                 raise InvalidResponse(self.illegal_choice_message)
248 | 
249 |             if not self.case_sensitive:
250 |                 # return the original choice, not the lower case version
251 |                 return_value = self.response_type(
252 |                     self.choices[
253 |                         [choice.lower() for choice in self.choices].index(value.lower())
254 |                     ]
255 |                 )
256 |         return return_value
257 | 
258 |     def on_validate_error(self, value: str, error: InvalidResponse) -> None:
259 |         """Called to handle validation error.
260 | 
261 |         Args:
262 |             value (str): String entered by user.
263 |             error (InvalidResponse): Exception instance the initiated the error.
264 |         """
265 |         self.console.print(error)
266 | 
267 |     def pre_prompt(self) -> None:
268 |         """Hook to display something before the prompt."""
269 | 
270 |     @overload
271 |     def __call__(self, *, stream: Optional[TextIO] = None) -> PromptType:
272 |         ...
273 | 
274 |     @overload
275 |     def __call__(
276 |         self, *, default: DefaultType, stream: Optional[TextIO] = None
277 |     ) -> Union[PromptType, DefaultType]:
278 |         ...
279 | 
280 |     def __call__(self, *, default: Any = ..., stream: Optional[TextIO] = None) -> Any:
281 |         """Run the prompt loop.
282 | 
283 |         Args:
284 |             default (Any, optional): Optional default value.
285 | 
286 |         Returns:
287 |             PromptType: Processed value.
288 |         """
289 |         while True:
290 |             self.pre_prompt()
291 |             prompt = self.make_prompt(default)
292 |             value = self.get_input(self.console, prompt, self.password, stream=stream)
293 |             if value == "" and default != ...:
294 |                 return default
295 |             try:
296 |                 return_value = self.process_response(value)
297 |             except InvalidResponse as error:
298 |                 self.on_validate_error(value, error)
299 |                 continue
300 |             else:
301 |                 return return_value
302 | 
303 | 
304 | class Prompt(PromptBase[str]):
305 |     """A prompt that returns a str.
306 | 
307 |     Example:
308 |         >>> name = Prompt.ask("Enter your name")
309 | 
310 | 
311 |     """
312 | 
313 |     response_type = str
314 | 
315 | 
316 | class IntPrompt(PromptBase[int]):
317 |     """A prompt that returns an integer.
318 | 
319 |     Example:
320 |         >>> burrito_count = IntPrompt.ask("How many burritos do you want to order")
321 | 
322 |     """
323 | 
324 |     response_type = int
325 |     validate_error_message = "[prompt.invalid]Please enter a valid integer number"
326 | 
327 | 
328 | class FloatPrompt(PromptBase[float]):
329 |     """A prompt that returns a float.
330 | 
331 |     Example:
332 |         >>> temperature = FloatPrompt.ask("Enter desired temperature")
333 | 
334 |     """
335 | 
336 |     response_type = float
337 |     validate_error_message = "[prompt.invalid]Please enter a number"
338 | 
339 | 
340 | class Confirm(PromptBase[bool]):
341 |     """A yes / no confirmation prompt.
342 | 
343 |     Example:
344 |         >>> if Confirm.ask("Continue"):
345 |                 run_job()
346 | 
347 |     """
348 | 
349 |     response_type = bool
350 |     validate_error_message = "[prompt.invalid]Please enter Y or N"
351 |     choices: List[str] = ["y", "n"]
352 | 
353 |     def render_default(self, default: DefaultType) -> Text:
354 |         """Render the default as (y) or (n) rather than True/False."""
355 |         yes, no = self.choices
356 |         return Text(f"({yes})" if default else f"({no})", style="prompt.default")
357 | 
358 |     def process_response(self, value: str) -> bool:
359 |         """Convert choices to a bool."""
360 |         value = value.strip().lower()
361 |         if value not in self.choices:
362 |             raise InvalidResponse(self.validate_error_message)
363 |         return value == self.choices[0]
364 | 
365 | 
366 | if __name__ == "__main__":  # pragma: no cover
367 |     from pip._vendor.rich import print
368 | 
369 |     if Confirm.ask("Run [i]prompt[/i] tests?", default=True):
370 |         while True:
371 |             result = IntPrompt.ask(
372 |                 ":rocket: Enter a number between [b]1[/b] and [b]10[/b]", default=5
373 |             )
374 |             if result >= 1 and result <= 10:
375 |                 break
376 |             print(":pile_of_poo: [prompt.invalid]Number must be between 1 and 10")
377 |         print(f"number={result}")
378 | 
379 |         while True:
380 |             password = Prompt.ask(
381 |                 "Please enter a password [cyan](must be at least 5 characters)",
382 |                 password=True,
383 |             )
384 |             if len(password) >= 5:
385 |                 break
386 |             print("[prompt.invalid]password too short")
387 |         print(f"password={password!r}")
388 | 
389 |         fruit = Prompt.ask("Enter a fruit", choices=["apple", "orange", "pear"])
390 |         print(f"fruit={fruit!r}")
391 | 
392 |         doggie = Prompt.ask(
393 |             "What's the best Dog? (Case INSENSITIVE)",
394 |             choices=["Border Terrier", "Collie", "Labradoodle"],
395 |             case_sensitive=False,
396 |         )
[TRUNCATED]
```

.venv/lib/python3.13/site-packages/pip/_vendor/rich/protocol.py
```
1 | from typing import Any, cast, Set, TYPE_CHECKING
2 | from inspect import isclass
3 | 
4 | if TYPE_CHECKING:
5 |     from pip._vendor.rich.console import RenderableType
6 | 
7 | _GIBBERISH = """aihwerij235234ljsdnp34ksodfipwoe234234jlskjdf"""
8 | 
9 | 
10 | def is_renderable(check_object: Any) -> bool:
11 |     """Check if an object may be rendered by Rich."""
12 |     return (
13 |         isinstance(check_object, str)
14 |         or hasattr(check_object, "__rich__")
15 |         or hasattr(check_object, "__rich_console__")
16 |     )
17 | 
18 | 
19 | def rich_cast(renderable: object) -> "RenderableType":
20 |     """Cast an object to a renderable by calling __rich__ if present.
21 | 
22 |     Args:
23 |         renderable (object): A potentially renderable object
24 | 
25 |     Returns:
26 |         object: The result of recursively calling __rich__.
27 |     """
28 |     from pip._vendor.rich.console import RenderableType
29 | 
30 |     rich_visited_set: Set[type] = set()  # Prevent potential infinite loop
31 |     while hasattr(renderable, "__rich__") and not isclass(renderable):
32 |         # Detect object which claim to have all the attributes
33 |         if hasattr(renderable, _GIBBERISH):
34 |             return repr(renderable)
35 |         cast_method = getattr(renderable, "__rich__")
36 |         renderable = cast_method()
37 |         renderable_type = type(renderable)
38 |         if renderable_type in rich_visited_set:
39 |             break
40 |         rich_visited_set.add(renderable_type)
41 | 
42 |     return cast(RenderableType, renderable)
```

.venv/lib/python3.13/site-packages/pip/_vendor/rich/py.typed
```
```

.venv/lib/python3.13/site-packages/pip/_vendor/rich/region.py
```
1 | from typing import NamedTuple
2 | 
3 | 
4 | class Region(NamedTuple):
5 |     """Defines a rectangular region of the screen."""
6 | 
7 |     x: int
8 |     y: int
9 |     width: int
10 |     height: int
```

.venv/lib/python3.13/site-packages/pip/_vendor/rich/repr.py
```
1 | import inspect
2 | from functools import partial
3 | from typing import (
4 |     Any,
5 |     Callable,
6 |     Iterable,
7 |     List,
8 |     Optional,
9 |     Tuple,
10 |     Type,
11 |     TypeVar,
12 |     Union,
13 |     overload,
14 | )
15 | 
16 | T = TypeVar("T")
17 | 
18 | 
19 | Result = Iterable[Union[Any, Tuple[Any], Tuple[str, Any], Tuple[str, Any, Any]]]
20 | RichReprResult = Result
21 | 
22 | 
23 | class ReprError(Exception):
24 |     """An error occurred when attempting to build a repr."""
25 | 
26 | 
27 | @overload
28 | def auto(cls: Optional[Type[T]]) -> Type[T]:
29 |     ...
30 | 
31 | 
32 | @overload
33 | def auto(*, angular: bool = False) -> Callable[[Type[T]], Type[T]]:
34 |     ...
35 | 
36 | 
37 | def auto(
38 |     cls: Optional[Type[T]] = None, *, angular: Optional[bool] = None
39 | ) -> Union[Type[T], Callable[[Type[T]], Type[T]]]:
40 |     """Class decorator to create __repr__ from __rich_repr__"""
41 | 
42 |     def do_replace(cls: Type[T], angular: Optional[bool] = None) -> Type[T]:
43 |         def auto_repr(self: T) -> str:
44 |             """Create repr string from __rich_repr__"""
45 |             repr_str: List[str] = []
46 |             append = repr_str.append
47 | 
48 |             angular: bool = getattr(self.__rich_repr__, "angular", False)  # type: ignore[attr-defined]
49 |             for arg in self.__rich_repr__():  # type: ignore[attr-defined]
50 |                 if isinstance(arg, tuple):
51 |                     if len(arg) == 1:
52 |                         append(repr(arg[0]))
53 |                     else:
54 |                         key, value, *default = arg
55 |                         if key is None:
56 |                             append(repr(value))
57 |                         else:
58 |                             if default and default[0] == value:
59 |                                 continue
60 |                             append(f"{key}={value!r}")
61 |                 else:
62 |                     append(repr(arg))
63 |             if angular:
64 |                 return f"<{self.__class__.__name__} {' '.join(repr_str)}>"
65 |             else:
66 |                 return f"{self.__class__.__name__}({', '.join(repr_str)})"
67 | 
68 |         def auto_rich_repr(self: Type[T]) -> Result:
69 |             """Auto generate __rich_rep__ from signature of __init__"""
70 |             try:
71 |                 signature = inspect.signature(self.__init__)
72 |                 for name, param in signature.parameters.items():
73 |                     if param.kind == param.POSITIONAL_ONLY:
74 |                         yield getattr(self, name)
75 |                     elif param.kind in (
76 |                         param.POSITIONAL_OR_KEYWORD,
77 |                         param.KEYWORD_ONLY,
78 |                     ):
79 |                         if param.default is param.empty:
80 |                             yield getattr(self, param.name)
81 |                         else:
82 |                             yield param.name, getattr(self, param.name), param.default
83 |             except Exception as error:
84 |                 raise ReprError(
85 |                     f"Failed to auto generate __rich_repr__; {error}"
86 |                 ) from None
87 | 
88 |         if not hasattr(cls, "__rich_repr__"):
89 |             auto_rich_repr.__doc__ = "Build a rich repr"
90 |             cls.__rich_repr__ = auto_rich_repr  # type: ignore[attr-defined]
91 | 
92 |         auto_repr.__doc__ = "Return repr(self)"
93 |         cls.__repr__ = auto_repr  # type: ignore[assignment]
94 |         if angular is not None:
95 |             cls.__rich_repr__.angular = angular  # type: ignore[attr-defined]
96 |         return cls
97 | 
98 |     if cls is None:
99 |         return partial(do_replace, angular=angular)
100 |     else:
101 |         return do_replace(cls, angular=angular)
102 | 
103 | 
104 | @overload
105 | def rich_repr(cls: Optional[Type[T]]) -> Type[T]:
106 |     ...
107 | 
108 | 
109 | @overload
110 | def rich_repr(*, angular: bool = False) -> Callable[[Type[T]], Type[T]]:
111 |     ...
112 | 
113 | 
114 | def rich_repr(
115 |     cls: Optional[Type[T]] = None, *, angular: bool = False
116 | ) -> Union[Type[T], Callable[[Type[T]], Type[T]]]:
117 |     if cls is None:
118 |         return auto(angular=angular)
119 |     else:
120 |         return auto(cls)
121 | 
122 | 
123 | if __name__ == "__main__":
124 | 
125 |     @auto
126 |     class Foo:
127 |         def __rich_repr__(self) -> Result:
128 |             yield "foo"
129 |             yield "bar", {"shopping": ["eggs", "ham", "pineapple"]}
130 |             yield "buy", "hand sanitizer"
131 | 
132 |     foo = Foo()
133 |     from pip._vendor.rich.console import Console
134 | 
135 |     console = Console()
136 | 
137 |     console.rule("Standard repr")
138 |     console.print(foo)
139 | 
140 |     console.print(foo, width=60)
141 |     console.print(foo, width=30)
142 | 
143 |     console.rule("Angular repr")
144 |     Foo.__rich_repr__.angular = True  # type: ignore[attr-defined]
145 | 
146 |     console.print(foo)
147 | 
148 |     console.print(foo, width=60)
149 |     console.print(foo, width=30)
```

.venv/lib/python3.13/site-packages/pip/_vendor/rich/rule.py
```
1 | from typing import Union
2 | 
3 | from .align import AlignMethod
4 | from .cells import cell_len, set_cell_size
5 | from .console import Console, ConsoleOptions, RenderResult
6 | from .jupyter import JupyterMixin
7 | from .measure import Measurement
8 | from .style import Style
9 | from .text import Text
10 | 
11 | 
12 | class Rule(JupyterMixin):
13 |     """A console renderable to draw a horizontal rule (line).
14 | 
15 |     Args:
16 |         title (Union[str, Text], optional): Text to render in the rule. Defaults to "".
17 |         characters (str, optional): Character(s) used to draw the line. Defaults to "".
18 |         style (StyleType, optional): Style of Rule. Defaults to "rule.line".
19 |         end (str, optional): Character at end of Rule. defaults to "\\\\n"
20 |         align (str, optional): How to align the title, one of "left", "center", or "right". Defaults to "center".
21 |     """
22 | 
23 |     def __init__(
24 |         self,
25 |         title: Union[str, Text] = "",
26 |         *,
27 |         characters: str = "",
28 |         style: Union[str, Style] = "rule.line",
29 |         end: str = "\n",
30 |         align: AlignMethod = "center",
31 |     ) -> None:
32 |         if cell_len(characters) < 1:
33 |             raise ValueError(
34 |                 "'characters' argument must have a cell width of at least 1"
35 |             )
36 |         if align not in ("left", "center", "right"):
37 |             raise ValueError(
38 |                 f'invalid value for align, expected "left", "center", "right" (not {align!r})'
39 |             )
40 |         self.title = title
41 |         self.characters = characters
42 |         self.style = style
43 |         self.end = end
44 |         self.align = align
45 | 
46 |     def __repr__(self) -> str:
47 |         return f"Rule({self.title!r}, {self.characters!r})"
48 | 
49 |     def __rich_console__(
50 |         self, console: Console, options: ConsoleOptions
51 |     ) -> RenderResult:
52 |         width = options.max_width
53 | 
54 |         characters = (
55 |             "-"
56 |             if (options.ascii_only and not self.characters.isascii())
57 |             else self.characters
58 |         )
59 | 
60 |         chars_len = cell_len(characters)
61 |         if not self.title:
62 |             yield self._rule_line(chars_len, width)
63 |             return
64 | 
65 |         if isinstance(self.title, Text):
66 |             title_text = self.title
67 |         else:
68 |             title_text = console.render_str(self.title, style="rule.text")
69 | 
70 |         title_text.plain = title_text.plain.replace("\n", " ")
71 |         title_text.expand_tabs()
72 | 
73 |         required_space = 4 if self.align == "center" else 2
74 |         truncate_width = max(0, width - required_space)
75 |         if not truncate_width:
76 |             yield self._rule_line(chars_len, width)
77 |             return
78 | 
79 |         rule_text = Text(end=self.end)
80 |         if self.align == "center":
81 |             title_text.truncate(truncate_width, overflow="ellipsis")
82 |             side_width = (width - cell_len(title_text.plain)) // 2
83 |             left = Text(characters * (side_width // chars_len + 1))
84 |             left.truncate(side_width - 1)
85 |             right_length = width - cell_len(left.plain) - cell_len(title_text.plain)
86 |             right = Text(characters * (side_width // chars_len + 1))
87 |             right.truncate(right_length)
88 |             rule_text.append(left.plain + " ", self.style)
89 |             rule_text.append(title_text)
90 |             rule_text.append(" " + right.plain, self.style)
91 |         elif self.align == "left":
92 |             title_text.truncate(truncate_width, overflow="ellipsis")
93 |             rule_text.append(title_text)
94 |             rule_text.append(" ")
95 |             rule_text.append(characters * (width - rule_text.cell_len), self.style)
96 |         elif self.align == "right":
97 |             title_text.truncate(truncate_width, overflow="ellipsis")
98 |             rule_text.append(characters * (width - title_text.cell_len - 1), self.style)
99 |             rule_text.append(" ")
100 |             rule_text.append(title_text)
101 | 
102 |         rule_text.plain = set_cell_size(rule_text.plain, width)
103 |         yield rule_text
104 | 
105 |     def _rule_line(self, chars_len: int, width: int) -> Text:
106 |         rule_text = Text(self.characters * ((width // chars_len) + 1), self.style)
107 |         rule_text.truncate(width)
108 |         rule_text.plain = set_cell_size(rule_text.plain, width)
109 |         return rule_text
110 | 
111 |     def __rich_measure__(
112 |         self, console: Console, options: ConsoleOptions
113 |     ) -> Measurement:
114 |         return Measurement(1, 1)
115 | 
116 | 
117 | if __name__ == "__main__":  # pragma: no cover
118 |     import sys
119 | 
120 |     from pip._vendor.rich.console import Console
121 | 
122 |     try:
123 |         text = sys.argv[1]
124 |     except IndexError:
125 |         text = "Hello, World"
126 |     console = Console()
127 |     console.print(Rule(title=text))
128 | 
129 |     console = Console()
130 |     console.print(Rule("foo"), width=4)
```

.venv/lib/python3.13/site-packages/pip/_vendor/rich/scope.py
```
1 | from collections.abc import Mapping
2 | from typing import TYPE_CHECKING, Any, Optional, Tuple
3 | 
4 | from .highlighter import ReprHighlighter
5 | from .panel import Panel
6 | from .pretty import Pretty
7 | from .table import Table
8 | from .text import Text, TextType
9 | 
10 | if TYPE_CHECKING:
11 |     from .console import ConsoleRenderable
12 | 
13 | 
14 | def render_scope(
15 |     scope: "Mapping[str, Any]",
16 |     *,
17 |     title: Optional[TextType] = None,
18 |     sort_keys: bool = True,
19 |     indent_guides: bool = False,
20 |     max_length: Optional[int] = None,
21 |     max_string: Optional[int] = None,
22 | ) -> "ConsoleRenderable":
23 |     """Render python variables in a given scope.
24 | 
25 |     Args:
26 |         scope (Mapping): A mapping containing variable names and values.
27 |         title (str, optional): Optional title. Defaults to None.
28 |         sort_keys (bool, optional): Enable sorting of items. Defaults to True.
29 |         indent_guides (bool, optional): Enable indentation guides. Defaults to False.
30 |         max_length (int, optional): Maximum length of containers before abbreviating, or None for no abbreviation.
31 |             Defaults to None.
32 |         max_string (int, optional): Maximum length of string before truncating, or None to disable. Defaults to None.
33 | 
34 |     Returns:
35 |         ConsoleRenderable: A renderable object.
36 |     """
37 |     highlighter = ReprHighlighter()
38 |     items_table = Table.grid(padding=(0, 1), expand=False)
39 |     items_table.add_column(justify="right")
40 | 
41 |     def sort_items(item: Tuple[str, Any]) -> Tuple[bool, str]:
42 |         """Sort special variables first, then alphabetically."""
43 |         key, _ = item
44 |         return (not key.startswith("__"), key.lower())
45 | 
46 |     items = sorted(scope.items(), key=sort_items) if sort_keys else scope.items()
47 |     for key, value in items:
48 |         key_text = Text.assemble(
49 |             (key, "scope.key.special" if key.startswith("__") else "scope.key"),
50 |             (" =", "scope.equals"),
51 |         )
52 |         items_table.add_row(
53 |             key_text,
54 |             Pretty(
55 |                 value,
56 |                 highlighter=highlighter,
57 |                 indent_guides=indent_guides,
58 |                 max_length=max_length,
59 |                 max_string=max_string,
60 |             ),
61 |         )
62 |     return Panel.fit(
63 |         items_table,
64 |         title=title,
65 |         border_style="scope.border",
66 |         padding=(0, 1),
67 |     )
68 | 
69 | 
70 | if __name__ == "__main__":  # pragma: no cover
71 |     from pip._vendor.rich import print
72 | 
73 |     print()
74 | 
75 |     def test(foo: float, bar: float) -> None:
76 |         list_of_things = [1, 2, 3, None, 4, True, False, "Hello World"]
77 |         dict_of_things = {
78 |             "version": "1.1",
79 |             "method": "confirmFruitPurchase",
80 |             "params": [["apple", "orange", "mangoes", "pomelo"], 1.123],
81 |             "id": "194521489",
82 |         }
83 |         print(render_scope(locals(), title="[i]locals", sort_keys=False))
84 | 
85 |     test(20.3423, 3.1427)
86 |     print()
```

.venv/lib/python3.13/site-packages/pip/_vendor/rich/screen.py
```
1 | from typing import Optional, TYPE_CHECKING
2 | 
3 | from .segment import Segment
4 | from .style import StyleType
5 | from ._loop import loop_last
6 | 
7 | 
8 | if TYPE_CHECKING:
9 |     from .console import (
10 |         Console,
11 |         ConsoleOptions,
12 |         RenderResult,
13 |         RenderableType,
14 |         Group,
15 |     )
16 | 
17 | 
18 | class Screen:
19 |     """A renderable that fills the terminal screen and crops excess.
20 | 
21 |     Args:
22 |         renderable (RenderableType): Child renderable.
23 |         style (StyleType, optional): Optional background style. Defaults to None.
24 |     """
25 | 
26 |     renderable: "RenderableType"
27 | 
28 |     def __init__(
29 |         self,
30 |         *renderables: "RenderableType",
31 |         style: Optional[StyleType] = None,
32 |         application_mode: bool = False,
33 |     ) -> None:
34 |         from pip._vendor.rich.console import Group
35 | 
36 |         self.renderable = Group(*renderables)
37 |         self.style = style
38 |         self.application_mode = application_mode
39 | 
40 |     def __rich_console__(
41 |         self, console: "Console", options: "ConsoleOptions"
42 |     ) -> "RenderResult":
43 |         width, height = options.size
44 |         style = console.get_style(self.style) if self.style else None
45 |         render_options = options.update(width=width, height=height)
46 |         lines = console.render_lines(
47 |             self.renderable or "", render_options, style=style, pad=True
48 |         )
49 |         lines = Segment.set_shape(lines, width, height, style=style)
50 |         new_line = Segment("\n\r") if self.application_mode else Segment.line()
51 |         for last, line in loop_last(lines):
52 |             yield from line
53 |             if not last:
54 |                 yield new_line
```

.venv/lib/python3.13/site-packages/pip/_vendor/rich/segment.py
```
1 | from enum import IntEnum
2 | from functools import lru_cache
3 | from itertools import filterfalse
4 | from logging import getLogger
5 | from operator import attrgetter
6 | from typing import (
7 |     TYPE_CHECKING,
8 |     Dict,
9 |     Iterable,
10 |     List,
11 |     NamedTuple,
12 |     Optional,
13 |     Sequence,
14 |     Tuple,
15 |     Type,
16 |     Union,
17 | )
18 | 
19 | from .cells import (
20 |     _is_single_cell_widths,
21 |     cached_cell_len,
22 |     cell_len,
23 |     get_character_cell_size,
24 |     set_cell_size,
25 | )
26 | from .repr import Result, rich_repr
27 | from .style import Style
28 | 
29 | if TYPE_CHECKING:
30 |     from .console import Console, ConsoleOptions, RenderResult
31 | 
32 | log = getLogger("rich")
33 | 
34 | 
35 | class ControlType(IntEnum):
36 |     """Non-printable control codes which typically translate to ANSI codes."""
37 | 
38 |     BELL = 1
39 |     CARRIAGE_RETURN = 2
40 |     HOME = 3
41 |     CLEAR = 4
42 |     SHOW_CURSOR = 5
43 |     HIDE_CURSOR = 6
44 |     ENABLE_ALT_SCREEN = 7
45 |     DISABLE_ALT_SCREEN = 8
46 |     CURSOR_UP = 9
47 |     CURSOR_DOWN = 10
48 |     CURSOR_FORWARD = 11
49 |     CURSOR_BACKWARD = 12
50 |     CURSOR_MOVE_TO_COLUMN = 13
51 |     CURSOR_MOVE_TO = 14
52 |     ERASE_IN_LINE = 15
53 |     SET_WINDOW_TITLE = 16
54 | 
55 | 
56 | ControlCode = Union[
57 |     Tuple[ControlType],
58 |     Tuple[ControlType, Union[int, str]],
59 |     Tuple[ControlType, int, int],
60 | ]
61 | 
62 | 
63 | @rich_repr()
64 | class Segment(NamedTuple):
65 |     """A piece of text with associated style. Segments are produced by the Console render process and
66 |     are ultimately converted in to strings to be written to the terminal.
67 | 
68 |     Args:
69 |         text (str): A piece of text.
70 |         style (:class:`~rich.style.Style`, optional): An optional style to apply to the text.
71 |         control (Tuple[ControlCode], optional): Optional sequence of control codes.
72 | 
73 |     Attributes:
74 |         cell_length (int): The cell length of this Segment.
75 |     """
76 | 
77 |     text: str
78 |     style: Optional[Style] = None
79 |     control: Optional[Sequence[ControlCode]] = None
80 | 
81 |     @property
82 |     def cell_length(self) -> int:
83 |         """The number of terminal cells required to display self.text.
84 | 
85 |         Returns:
86 |             int: A number of cells.
87 |         """
88 |         text, _style, control = self
89 |         return 0 if control else cell_len(text)
90 | 
91 |     def __rich_repr__(self) -> Result:
92 |         yield self.text
93 |         if self.control is None:
94 |             if self.style is not None:
95 |                 yield self.style
96 |         else:
97 |             yield self.style
98 |             yield self.control
99 | 
100 |     def __bool__(self) -> bool:
101 |         """Check if the segment contains text."""
102 |         return bool(self.text)
103 | 
104 |     @property
105 |     def is_control(self) -> bool:
106 |         """Check if the segment contains control codes."""
107 |         return self.control is not None
108 | 
109 |     @classmethod
110 |     @lru_cache(1024 * 16)
111 |     def _split_cells(cls, segment: "Segment", cut: int) -> Tuple["Segment", "Segment"]:
112 |         """Split a segment in to two at a given cell position.
113 | 
114 |         Note that splitting a double-width character, may result in that character turning
115 |         into two spaces.
116 | 
117 |         Args:
118 |             segment (Segment): A segment to split.
119 |             cut (int): A cell position to cut on.
120 | 
121 |         Returns:
122 |             A tuple of two segments.
123 |         """
124 |         text, style, control = segment
125 |         _Segment = Segment
126 |         cell_length = segment.cell_length
127 |         if cut >= cell_length:
128 |             return segment, _Segment("", style, control)
129 | 
130 |         cell_size = get_character_cell_size
131 | 
132 |         pos = int((cut / cell_length) * len(text))
133 | 
134 |         while True:
135 |             before = text[:pos]
136 |             cell_pos = cell_len(before)
137 |             out_by = cell_pos - cut
138 |             if not out_by:
139 |                 return (
140 |                     _Segment(before, style, control),
141 |                     _Segment(text[pos:], style, control),
142 |                 )
143 |             if out_by == -1 and cell_size(text[pos]) == 2:
144 |                 return (
145 |                     _Segment(text[:pos] + " ", style, control),
146 |                     _Segment(" " + text[pos + 1 :], style, control),
147 |                 )
148 |             if out_by == +1 and cell_size(text[pos - 1]) == 2:
149 |                 return (
150 |                     _Segment(text[: pos - 1] + " ", style, control),
151 |                     _Segment(" " + text[pos:], style, control),
152 |                 )
153 |             if cell_pos < cut:
154 |                 pos += 1
155 |             else:
156 |                 pos -= 1
157 | 
158 |     def split_cells(self, cut: int) -> Tuple["Segment", "Segment"]:
159 |         """Split segment in to two segments at the specified column.
160 | 
161 |         If the cut point falls in the middle of a 2-cell wide character then it is replaced
162 |         by two spaces, to preserve the display width of the parent segment.
163 | 
164 |         Args:
165 |             cut (int): Offset within the segment to cut.
166 | 
167 |         Returns:
168 |             Tuple[Segment, Segment]: Two segments.
169 |         """
170 |         text, style, control = self
171 |         assert cut >= 0
172 | 
173 |         if _is_single_cell_widths(text):
174 |             # Fast path with all 1 cell characters
175 |             if cut >= len(text):
176 |                 return self, Segment("", style, control)
177 |             return (
178 |                 Segment(text[:cut], style, control),
179 |                 Segment(text[cut:], style, control),
180 |             )
181 | 
182 |         return self._split_cells(self, cut)
183 | 
184 |     @classmethod
185 |     def line(cls) -> "Segment":
186 |         """Make a new line segment."""
187 |         return cls("\n")
188 | 
189 |     @classmethod
190 |     def apply_style(
191 |         cls,
192 |         segments: Iterable["Segment"],
193 |         style: Optional[Style] = None,
194 |         post_style: Optional[Style] = None,
195 |     ) -> Iterable["Segment"]:
196 |         """Apply style(s) to an iterable of segments.
197 | 
198 |         Returns an iterable of segments where the style is replaced by ``style + segment.style + post_style``.
199 | 
200 |         Args:
201 |             segments (Iterable[Segment]): Segments to process.
202 |             style (Style, optional): Base style. Defaults to None.
203 |             post_style (Style, optional): Style to apply on top of segment style. Defaults to None.
204 | 
205 |         Returns:
206 |             Iterable[Segments]: A new iterable of segments (possibly the same iterable).
207 |         """
208 |         result_segments = segments
209 |         if style:
210 |             apply = style.__add__
211 |             result_segments = (
212 |                 cls(text, None if control else apply(_style), control)
213 |                 for text, _style, control in result_segments
214 |             )
215 |         if post_style:
216 |             result_segments = (
217 |                 cls(
218 |                     text,
219 |                     (
220 |                         None
221 |                         if control
222 |                         else (_style + post_style if _style else post_style)
223 |                     ),
224 |                     control,
225 |                 )
226 |                 for text, _style, control in result_segments
227 |             )
228 |         return result_segments
229 | 
230 |     @classmethod
231 |     def filter_control(
232 |         cls, segments: Iterable["Segment"], is_control: bool = False
233 |     ) -> Iterable["Segment"]:
234 |         """Filter segments by ``is_control`` attribute.
235 | 
236 |         Args:
237 |             segments (Iterable[Segment]): An iterable of Segment instances.
238 |             is_control (bool, optional): is_control flag to match in search.
239 | 
240 |         Returns:
241 |             Iterable[Segment]: And iterable of Segment instances.
242 | 
243 |         """
244 |         if is_control:
245 |             return filter(attrgetter("control"), segments)
246 |         else:
247 |             return filterfalse(attrgetter("control"), segments)
248 | 
249 |     @classmethod
250 |     def split_lines(cls, segments: Iterable["Segment"]) -> Iterable[List["Segment"]]:
251 |         """Split a sequence of segments in to a list of lines.
252 | 
253 |         Args:
254 |             segments (Iterable[Segment]): Segments potentially containing line feeds.
255 | 
256 |         Yields:
257 |             Iterable[List[Segment]]: Iterable of segment lists, one per line.
258 |         """
259 |         line: List[Segment] = []
260 |         append = line.append
261 | 
262 |         for segment in segments:
263 |             if "\n" in segment.text and not segment.control:
264 |                 text, style, _ = segment
265 |                 while text:
266 |                     _text, new_line, text = text.partition("\n")
267 |                     if _text:
268 |                         append(cls(_text, style))
269 |                     if new_line:
270 |                         yield line
271 |                         line = []
272 |                         append = line.append
273 |             else:
274 |                 append(segment)
275 |         if line:
276 |             yield line
277 | 
278 |     @classmethod
279 |     def split_and_crop_lines(
280 |         cls,
281 |         segments: Iterable["Segment"],
282 |         length: int,
283 |         style: Optional[Style] = None,
284 |         pad: bool = True,
285 |         include_new_lines: bool = True,
286 |     ) -> Iterable[List["Segment"]]:
287 |         """Split segments in to lines, and crop lines greater than a given length.
288 | 
289 |         Args:
290 |             segments (Iterable[Segment]): An iterable of segments, probably
291 |                 generated from console.render.
292 |             length (int): Desired line length.
293 |             style (Style, optional): Style to use for any padding.
294 |             pad (bool): Enable padding of lines that are less than `length`.
295 | 
296 |         Returns:
297 |             Iterable[List[Segment]]: An iterable of lines of segments.
298 |         """
299 |         line: List[Segment] = []
300 |         append = line.append
301 | 
302 |         adjust_line_length = cls.adjust_line_length
303 |         new_line_segment = cls("\n")
304 | 
305 |         for segment in segments:
306 |             if "\n" in segment.text and not segment.control:
307 |                 text, segment_style, _ = segment
308 |                 while text:
309 |                     _text, new_line, text = text.partition("\n")
310 |                     if _text:
311 |                         append(cls(_text, segment_style))
312 |                     if new_line:
313 |                         cropped_line = adjust_line_length(
314 |                             line, length, style=style, pad=pad
315 |                         )
316 |                         if include_new_lines:
317 |                             cropped_line.append(new_line_segment)
318 |                         yield cropped_line
319 |                         line.clear()
320 |             else:
321 |                 append(segment)
322 |         if line:
323 |             yield adjust_line_length(line, length, style=style, pad=pad)
324 | 
325 |     @classmethod
326 |     def adjust_line_length(
327 |         cls,
328 |         line: List["Segment"],
329 |         length: int,
330 |         style: Optional[Style] = None,
331 |         pad: bool = True,
332 |     ) -> List["Segment"]:
333 |         """Adjust a line to a given width (cropping or padding as required).
334 | 
335 |         Args:
336 |             segments (Iterable[Segment]): A list of segments in a single line.
337 |             length (int): The desired width of the line.
338 |             style (Style, optional): The style of padding if used (space on the end). Defaults to None.
339 |             pad (bool, optional): Pad lines with spaces if they are shorter than `length`. Defaults to True.
340 | 
341 |         Returns:
342 |             List[Segment]: A line of segments with the desired length.
343 |         """
344 |         line_length = sum(segment.cell_length for segment in line)
345 |         new_line: List[Segment]
346 | 
347 |         if line_length < length:
348 |             if pad:
349 |                 new_line = line + [cls(" " * (length - line_length), style)]
350 |             else:
351 |                 new_line = line[:]
352 |         elif line_length > length:
353 |             new_line = []
354 |             append = new_line.append
355 |             line_length = 0
356 |             for segment in line:
357 |                 segment_length = segment.cell_length
358 |                 if line_length + segment_length < length or segment.control:
359 |                     append(segment)
360 |                     line_length += segment_length
361 |                 else:
362 |                     text, segment_style, _ = segment
363 |                     text = set_cell_size(text, length - line_length)
364 |                     append(cls(text, segment_style))
365 |                     break
366 |         else:
367 |             new_line = line[:]
368 |         return new_line
369 | 
370 |     @classmethod
371 |     def get_line_length(cls, line: List["Segment"]) -> int:
372 |         """Get the length of list of segments.
373 | 
374 |         Args:
375 |             line (List[Segment]): A line encoded as a list of Segments (assumes no '\\\\n' characters),
376 | 
377 |         Returns:
378 |             int: The length of the line.
379 |         """
380 |         _cell_len = cell_len
381 |         return sum(_cell_len(text) for text, style, control in line if not control)
382 | 
383 |     @classmethod
384 |     def get_shape(cls, lines: List[List["Segment"]]) -> Tuple[int, int]:
[TRUNCATED]
```

.venv/lib/python3.13/site-packages/pip/_vendor/rich/spinner.py
```
1 | from typing import cast, List, Optional, TYPE_CHECKING, Union
2 | 
3 | from ._spinners import SPINNERS
4 | from .measure import Measurement
5 | from .table import Table
6 | from .text import Text
7 | 
8 | if TYPE_CHECKING:
9 |     from .console import Console, ConsoleOptions, RenderResult, RenderableType
10 |     from .style import StyleType
11 | 
12 | 
13 | class Spinner:
14 |     """A spinner animation.
15 | 
16 |     Args:
17 |         name (str): Name of spinner (run python -m rich.spinner).
18 |         text (RenderableType, optional): A renderable to display at the right of the spinner (str or Text typically). Defaults to "".
19 |         style (StyleType, optional): Style for spinner animation. Defaults to None.
20 |         speed (float, optional): Speed factor for animation. Defaults to 1.0.
21 | 
22 |     Raises:
23 |         KeyError: If name isn't one of the supported spinner animations.
24 |     """
25 | 
26 |     def __init__(
27 |         self,
28 |         name: str,
29 |         text: "RenderableType" = "",
30 |         *,
31 |         style: Optional["StyleType"] = None,
32 |         speed: float = 1.0,
33 |     ) -> None:
34 |         try:
35 |             spinner = SPINNERS[name]
36 |         except KeyError:
37 |             raise KeyError(f"no spinner called {name!r}")
38 |         self.text: "Union[RenderableType, Text]" = (
39 |             Text.from_markup(text) if isinstance(text, str) else text
40 |         )
41 |         self.name = name
42 |         self.frames = cast(List[str], spinner["frames"])[:]
43 |         self.interval = cast(float, spinner["interval"])
44 |         self.start_time: Optional[float] = None
45 |         self.style = style
46 |         self.speed = speed
47 |         self.frame_no_offset: float = 0.0
48 |         self._update_speed = 0.0
49 | 
50 |     def __rich_console__(
51 |         self, console: "Console", options: "ConsoleOptions"
52 |     ) -> "RenderResult":
53 |         yield self.render(console.get_time())
54 | 
55 |     def __rich_measure__(
56 |         self, console: "Console", options: "ConsoleOptions"
57 |     ) -> Measurement:
58 |         text = self.render(0)
59 |         return Measurement.get(console, options, text)
60 | 
61 |     def render(self, time: float) -> "RenderableType":
62 |         """Render the spinner for a given time.
63 | 
64 |         Args:
65 |             time (float): Time in seconds.
66 | 
67 |         Returns:
68 |             RenderableType: A renderable containing animation frame.
69 |         """
70 |         if self.start_time is None:
71 |             self.start_time = time
72 | 
73 |         frame_no = ((time - self.start_time) * self.speed) / (
74 |             self.interval / 1000.0
75 |         ) + self.frame_no_offset
76 |         frame = Text(
77 |             self.frames[int(frame_no) % len(self.frames)], style=self.style or ""
78 |         )
79 | 
80 |         if self._update_speed:
81 |             self.frame_no_offset = frame_no
82 |             self.start_time = time
83 |             self.speed = self._update_speed
84 |             self._update_speed = 0.0
85 | 
86 |         if not self.text:
87 |             return frame
88 |         elif isinstance(self.text, (str, Text)):
89 |             return Text.assemble(frame, " ", self.text)
90 |         else:
91 |             table = Table.grid(padding=1)
92 |             table.add_row(frame, self.text)
93 |             return table
94 | 
95 |     def update(
96 |         self,
97 |         *,
98 |         text: "RenderableType" = "",
99 |         style: Optional["StyleType"] = None,
100 |         speed: Optional[float] = None,
101 |     ) -> None:
102 |         """Updates attributes of a spinner after it has been started.
103 | 
104 |         Args:
105 |             text (RenderableType, optional): A renderable to display at the right of the spinner (str or Text typically). Defaults to "".
106 |             style (StyleType, optional): Style for spinner animation. Defaults to None.
107 |             speed (float, optional): Speed factor for animation. Defaults to None.
108 |         """
109 |         if text:
110 |             self.text = Text.from_markup(text) if isinstance(text, str) else text
111 |         if style:
112 |             self.style = style
113 |         if speed:
114 |             self._update_speed = speed
115 | 
116 | 
117 | if __name__ == "__main__":  # pragma: no cover
118 |     from time import sleep
119 | 
120 |     from .columns import Columns
121 |     from .panel import Panel
122 |     from .live import Live
123 | 
124 |     all_spinners = Columns(
125 |         [
126 |             Spinner(spinner_name, text=Text(repr(spinner_name), style="green"))
127 |             for spinner_name in sorted(SPINNERS.keys())
128 |         ],
129 |         column_first=True,
130 |         expand=True,
131 |     )
132 | 
133 |     with Live(
134 |         Panel(all_spinners, title="Spinners", border_style="blue"),
135 |         refresh_per_second=20,
136 |     ) as live:
137 |         while True:
138 |             sleep(0.1)
```

.venv/lib/python3.13/site-packages/pip/_vendor/rich/status.py
```
1 | from types import TracebackType
2 | from typing import Optional, Type
3 | 
4 | from .console import Console, RenderableType
5 | from .jupyter import JupyterMixin
6 | from .live import Live
7 | from .spinner import Spinner
8 | from .style import StyleType
9 | 
10 | 
11 | class Status(JupyterMixin):
12 |     """Displays a status indicator with a 'spinner' animation.
13 | 
14 |     Args:
15 |         status (RenderableType): A status renderable (str or Text typically).
16 |         console (Console, optional): Console instance to use, or None for global console. Defaults to None.
17 |         spinner (str, optional): Name of spinner animation (see python -m rich.spinner). Defaults to "dots".
18 |         spinner_style (StyleType, optional): Style of spinner. Defaults to "status.spinner".
19 |         speed (float, optional): Speed factor for spinner animation. Defaults to 1.0.
20 |         refresh_per_second (float, optional): Number of refreshes per second. Defaults to 12.5.
21 |     """
22 | 
23 |     def __init__(
24 |         self,
25 |         status: RenderableType,
26 |         *,
27 |         console: Optional[Console] = None,
28 |         spinner: str = "dots",
29 |         spinner_style: StyleType = "status.spinner",
30 |         speed: float = 1.0,
31 |         refresh_per_second: float = 12.5,
32 |     ):
33 |         self.status = status
34 |         self.spinner_style = spinner_style
35 |         self.speed = speed
36 |         self._spinner = Spinner(spinner, text=status, style=spinner_style, speed=speed)
37 |         self._live = Live(
38 |             self.renderable,
39 |             console=console,
40 |             refresh_per_second=refresh_per_second,
41 |             transient=True,
42 |         )
43 | 
44 |     @property
45 |     def renderable(self) -> Spinner:
46 |         return self._spinner
47 | 
48 |     @property
49 |     def console(self) -> "Console":
50 |         """Get the Console used by the Status objects."""
51 |         return self._live.console
52 | 
53 |     def update(
54 |         self,
55 |         status: Optional[RenderableType] = None,
56 |         *,
57 |         spinner: Optional[str] = None,
58 |         spinner_style: Optional[StyleType] = None,
59 |         speed: Optional[float] = None,
60 |     ) -> None:
61 |         """Update status.
62 | 
63 |         Args:
64 |             status (Optional[RenderableType], optional): New status renderable or None for no change. Defaults to None.
65 |             spinner (Optional[str], optional): New spinner or None for no change. Defaults to None.
66 |             spinner_style (Optional[StyleType], optional): New spinner style or None for no change. Defaults to None.
67 |             speed (Optional[float], optional): Speed factor for spinner animation or None for no change. Defaults to None.
68 |         """
69 |         if status is not None:
70 |             self.status = status
71 |         if spinner_style is not None:
72 |             self.spinner_style = spinner_style
73 |         if speed is not None:
74 |             self.speed = speed
75 |         if spinner is not None:
76 |             self._spinner = Spinner(
77 |                 spinner, text=self.status, style=self.spinner_style, speed=self.speed
78 |             )
79 |             self._live.update(self.renderable, refresh=True)
80 |         else:
81 |             self._spinner.update(
82 |                 text=self.status, style=self.spinner_style, speed=self.speed
83 |             )
84 | 
85 |     def start(self) -> None:
86 |         """Start the status animation."""
87 |         self._live.start()
88 | 
89 |     def stop(self) -> None:
90 |         """Stop the spinner animation."""
91 |         self._live.stop()
92 | 
93 |     def __rich__(self) -> RenderableType:
94 |         return self.renderable
95 | 
96 |     def __enter__(self) -> "Status":
97 |         self.start()
98 |         return self
99 | 
100 |     def __exit__(
101 |         self,
102 |         exc_type: Optional[Type[BaseException]],
103 |         exc_val: Optional[BaseException],
104 |         exc_tb: Optional[TracebackType],
105 |     ) -> None:
106 |         self.stop()
107 | 
108 | 
109 | if __name__ == "__main__":  # pragma: no cover
110 |     from time import sleep
111 | 
112 |     from .console import Console
113 | 
114 |     console = Console()
115 |     with console.status("[magenta]Covid detector booting up") as status:
116 |         sleep(3)
117 |         console.log("Importing advanced AI")
118 |         sleep(3)
119 |         console.log("Advanced Covid AI Ready")
120 |         sleep(3)
121 |         status.update(status="[bold blue] Scanning for Covid", spinner="earth")
122 |         sleep(3)
123 |         console.log("Found 10,000,000,000 copies of Covid32.exe")
124 |         sleep(3)
125 |         status.update(
126 |             status="[bold red]Moving Covid32.exe to Trash",
127 |             spinner="bouncingBall",
128 |             spinner_style="yellow",
129 |         )
130 |         sleep(5)
131 |     console.print("[bold green]Covid deleted successfully")
```

.venv/lib/python3.13/site-packages/pip/_vendor/rich/style.py
```
1 | import sys
2 | from functools import lru_cache
3 | from marshal import dumps, loads
4 | from random import randint
5 | from typing import Any, Dict, Iterable, List, Optional, Type, Union, cast
6 | 
7 | from . import errors
8 | from .color import Color, ColorParseError, ColorSystem, blend_rgb
9 | from .repr import Result, rich_repr
10 | from .terminal_theme import DEFAULT_TERMINAL_THEME, TerminalTheme
11 | 
12 | # Style instances and style definitions are often interchangeable
13 | StyleType = Union[str, "Style"]
14 | 
15 | 
16 | class _Bit:
17 |     """A descriptor to get/set a style attribute bit."""
18 | 
19 |     __slots__ = ["bit"]
20 | 
21 |     def __init__(self, bit_no: int) -> None:
22 |         self.bit = 1 << bit_no
23 | 
24 |     def __get__(self, obj: "Style", objtype: Type["Style"]) -> Optional[bool]:
25 |         if obj._set_attributes & self.bit:
26 |             return obj._attributes & self.bit != 0
27 |         return None
28 | 
29 | 
30 | @rich_repr
31 | class Style:
32 |     """A terminal style.
33 | 
34 |     A terminal style consists of a color (`color`), a background color (`bgcolor`), and a number of attributes, such
35 |     as bold, italic etc. The attributes have 3 states: they can either be on
36 |     (``True``), off (``False``), or not set (``None``).
37 | 
38 |     Args:
39 |         color (Union[Color, str], optional): Color of terminal text. Defaults to None.
40 |         bgcolor (Union[Color, str], optional): Color of terminal background. Defaults to None.
41 |         bold (bool, optional): Enable bold text. Defaults to None.
42 |         dim (bool, optional): Enable dim text. Defaults to None.
43 |         italic (bool, optional): Enable italic text. Defaults to None.
44 |         underline (bool, optional): Enable underlined text. Defaults to None.
45 |         blink (bool, optional): Enabled blinking text. Defaults to None.
46 |         blink2 (bool, optional): Enable fast blinking text. Defaults to None.
47 |         reverse (bool, optional): Enabled reverse text. Defaults to None.
48 |         conceal (bool, optional): Enable concealed text. Defaults to None.
49 |         strike (bool, optional): Enable strikethrough text. Defaults to None.
50 |         underline2 (bool, optional): Enable doubly underlined text. Defaults to None.
51 |         frame (bool, optional): Enable framed text. Defaults to None.
52 |         encircle (bool, optional): Enable encircled text. Defaults to None.
53 |         overline (bool, optional): Enable overlined text. Defaults to None.
54 |         link (str, link): Link URL. Defaults to None.
55 | 
56 |     """
57 | 
58 |     _color: Optional[Color]
59 |     _bgcolor: Optional[Color]
60 |     _attributes: int
61 |     _set_attributes: int
62 |     _hash: Optional[int]
63 |     _null: bool
64 |     _meta: Optional[bytes]
65 | 
66 |     __slots__ = [
67 |         "_color",
68 |         "_bgcolor",
69 |         "_attributes",
70 |         "_set_attributes",
71 |         "_link",
72 |         "_link_id",
73 |         "_ansi",
74 |         "_style_definition",
75 |         "_hash",
76 |         "_null",
77 |         "_meta",
78 |     ]
79 | 
80 |     # maps bits on to SGR parameter
81 |     _style_map = {
82 |         0: "1",
83 |         1: "2",
84 |         2: "3",
85 |         3: "4",
86 |         4: "5",
87 |         5: "6",
88 |         6: "7",
89 |         7: "8",
90 |         8: "9",
91 |         9: "21",
92 |         10: "51",
93 |         11: "52",
94 |         12: "53",
95 |     }
96 | 
97 |     STYLE_ATTRIBUTES = {
98 |         "dim": "dim",
99 |         "d": "dim",
100 |         "bold": "bold",
101 |         "b": "bold",
102 |         "italic": "italic",
103 |         "i": "italic",
104 |         "underline": "underline",
105 |         "u": "underline",
106 |         "blink": "blink",
107 |         "blink2": "blink2",
108 |         "reverse": "reverse",
109 |         "r": "reverse",
110 |         "conceal": "conceal",
111 |         "c": "conceal",
112 |         "strike": "strike",
113 |         "s": "strike",
114 |         "underline2": "underline2",
115 |         "uu": "underline2",
116 |         "frame": "frame",
117 |         "encircle": "encircle",
118 |         "overline": "overline",
119 |         "o": "overline",
120 |     }
121 | 
122 |     def __init__(
123 |         self,
124 |         *,
125 |         color: Optional[Union[Color, str]] = None,
126 |         bgcolor: Optional[Union[Color, str]] = None,
127 |         bold: Optional[bool] = None,
128 |         dim: Optional[bool] = None,
129 |         italic: Optional[bool] = None,
130 |         underline: Optional[bool] = None,
131 |         blink: Optional[bool] = None,
132 |         blink2: Optional[bool] = None,
133 |         reverse: Optional[bool] = None,
134 |         conceal: Optional[bool] = None,
135 |         strike: Optional[bool] = None,
136 |         underline2: Optional[bool] = None,
137 |         frame: Optional[bool] = None,
138 |         encircle: Optional[bool] = None,
139 |         overline: Optional[bool] = None,
140 |         link: Optional[str] = None,
141 |         meta: Optional[Dict[str, Any]] = None,
142 |     ):
143 |         self._ansi: Optional[str] = None
144 |         self._style_definition: Optional[str] = None
145 | 
146 |         def _make_color(color: Union[Color, str]) -> Color:
147 |             return color if isinstance(color, Color) else Color.parse(color)
148 | 
149 |         self._color = None if color is None else _make_color(color)
150 |         self._bgcolor = None if bgcolor is None else _make_color(bgcolor)
151 |         self._set_attributes = sum(
152 |             (
153 |                 bold is not None,
154 |                 dim is not None and 2,
155 |                 italic is not None and 4,
156 |                 underline is not None and 8,
157 |                 blink is not None and 16,
158 |                 blink2 is not None and 32,
159 |                 reverse is not None and 64,
160 |                 conceal is not None and 128,
161 |                 strike is not None and 256,
162 |                 underline2 is not None and 512,
163 |                 frame is not None and 1024,
164 |                 encircle is not None and 2048,
165 |                 overline is not None and 4096,
166 |             )
167 |         )
168 |         self._attributes = (
169 |             sum(
170 |                 (
171 |                     bold and 1 or 0,
172 |                     dim and 2 or 0,
173 |                     italic and 4 or 0,
174 |                     underline and 8 or 0,
175 |                     blink and 16 or 0,
176 |                     blink2 and 32 or 0,
177 |                     reverse and 64 or 0,
178 |                     conceal and 128 or 0,
179 |                     strike and 256 or 0,
180 |                     underline2 and 512 or 0,
181 |                     frame and 1024 or 0,
182 |                     encircle and 2048 or 0,
183 |                     overline and 4096 or 0,
184 |                 )
185 |             )
186 |             if self._set_attributes
187 |             else 0
188 |         )
189 | 
190 |         self._link = link
191 |         self._meta = None if meta is None else dumps(meta)
192 |         self._link_id = (
193 |             f"{randint(0, 999999)}{hash(self._meta)}" if (link or meta) else ""
194 |         )
195 |         self._hash: Optional[int] = None
196 |         self._null = not (self._set_attributes or color or bgcolor or link or meta)
197 | 
198 |     @classmethod
199 |     def null(cls) -> "Style":
200 |         """Create an 'null' style, equivalent to Style(), but more performant."""
201 |         return NULL_STYLE
202 | 
203 |     @classmethod
204 |     def from_color(
205 |         cls, color: Optional[Color] = None, bgcolor: Optional[Color] = None
206 |     ) -> "Style":
207 |         """Create a new style with colors and no attributes.
208 | 
209 |         Returns:
210 |             color (Optional[Color]): A (foreground) color, or None for no color. Defaults to None.
211 |             bgcolor (Optional[Color]): A (background) color, or None for no color. Defaults to None.
212 |         """
213 |         style: Style = cls.__new__(Style)
214 |         style._ansi = None
215 |         style._style_definition = None
216 |         style._color = color
217 |         style._bgcolor = bgcolor
218 |         style._set_attributes = 0
219 |         style._attributes = 0
220 |         style._link = None
221 |         style._link_id = ""
222 |         style._meta = None
223 |         style._null = not (color or bgcolor)
224 |         style._hash = None
225 |         return style
226 | 
227 |     @classmethod
228 |     def from_meta(cls, meta: Optional[Dict[str, Any]]) -> "Style":
229 |         """Create a new style with meta data.
230 | 
231 |         Returns:
232 |             meta (Optional[Dict[str, Any]]): A dictionary of meta data. Defaults to None.
233 |         """
234 |         style: Style = cls.__new__(Style)
235 |         style._ansi = None
236 |         style._style_definition = None
237 |         style._color = None
238 |         style._bgcolor = None
239 |         style._set_attributes = 0
240 |         style._attributes = 0
241 |         style._link = None
242 |         style._meta = dumps(meta)
243 |         style._link_id = f"{randint(0, 999999)}{hash(style._meta)}"
244 |         style._hash = None
245 |         style._null = not (meta)
246 |         return style
247 | 
248 |     @classmethod
249 |     def on(cls, meta: Optional[Dict[str, Any]] = None, **handlers: Any) -> "Style":
250 |         """Create a blank style with meta information.
251 | 
252 |         Example:
253 |             style = Style.on(click=self.on_click)
254 | 
255 |         Args:
256 |             meta (Optional[Dict[str, Any]], optional): An optional dict of meta information.
257 |             **handlers (Any): Keyword arguments are translated in to handlers.
258 | 
259 |         Returns:
260 |             Style: A Style with meta information attached.
261 |         """
262 |         meta = {} if meta is None else meta
263 |         meta.update({f"@{key}": value for key, value in handlers.items()})
264 |         return cls.from_meta(meta)
265 | 
266 |     bold = _Bit(0)
267 |     dim = _Bit(1)
268 |     italic = _Bit(2)
269 |     underline = _Bit(3)
270 |     blink = _Bit(4)
271 |     blink2 = _Bit(5)
272 |     reverse = _Bit(6)
273 |     conceal = _Bit(7)
274 |     strike = _Bit(8)
275 |     underline2 = _Bit(9)
276 |     frame = _Bit(10)
277 |     encircle = _Bit(11)
278 |     overline = _Bit(12)
279 | 
280 |     @property
281 |     def link_id(self) -> str:
282 |         """Get a link id, used in ansi code for links."""
283 |         return self._link_id
284 | 
285 |     def __str__(self) -> str:
286 |         """Re-generate style definition from attributes."""
287 |         if self._style_definition is None:
288 |             attributes: List[str] = []
289 |             append = attributes.append
290 |             bits = self._set_attributes
291 |             if bits & 0b0000000001111:
292 |                 if bits & 1:
293 |                     append("bold" if self.bold else "not bold")
294 |                 if bits & (1 << 1):
295 |                     append("dim" if self.dim else "not dim")
296 |                 if bits & (1 << 2):
297 |                     append("italic" if self.italic else "not italic")
298 |                 if bits & (1 << 3):
299 |                     append("underline" if self.underline else "not underline")
300 |             if bits & 0b0000111110000:
301 |                 if bits & (1 << 4):
302 |                     append("blink" if self.blink else "not blink")
303 |                 if bits & (1 << 5):
304 |                     append("blink2" if self.blink2 else "not blink2")
305 |                 if bits & (1 << 6):
306 |                     append("reverse" if self.reverse else "not reverse")
307 |                 if bits & (1 << 7):
308 |                     append("conceal" if self.conceal else "not conceal")
309 |                 if bits & (1 << 8):
310 |                     append("strike" if self.strike else "not strike")
311 |             if bits & 0b1111000000000:
312 |                 if bits & (1 << 9):
313 |                     append("underline2" if self.underline2 else "not underline2")
314 |                 if bits & (1 << 10):
315 |                     append("frame" if self.frame else "not frame")
316 |                 if bits & (1 << 11):
317 |                     append("encircle" if self.encircle else "not encircle")
318 |                 if bits & (1 << 12):
319 |                     append("overline" if self.overline else "not overline")
320 |             if self._color is not None:
321 |                 append(self._color.name)
322 |             if self._bgcolor is not None:
323 |                 append("on")
324 |                 append(self._bgcolor.name)
325 |             if self._link:
326 |                 append("link")
327 |                 append(self._link)
328 |             self._style_definition = " ".join(attributes) or "none"
329 |         return self._style_definition
330 | 
331 |     def __bool__(self) -> bool:
332 |         """A Style is false if it has no attributes, colors, or links."""
333 |         return not self._null
334 | 
335 |     def _make_ansi_codes(self, color_system: ColorSystem) -> str:
336 |         """Generate ANSI codes for this style.
337 | 
338 |         Args:
339 |             color_system (ColorSystem): Color system.
340 | 
341 |         Returns:
342 |             str: String containing codes.
343 |         """
344 | 
345 |         if self._ansi is None:
346 |             sgr: List[str] = []
347 |             append = sgr.append
348 |             _style_map = self._style_map
349 |             attributes = self._attributes & self._set_attributes
350 |             if attributes:
351 |                 if attributes & 1:
352 |                     append(_style_map[0])
353 |                 if attributes & 2:
354 |                     append(_style_map[1])
355 |                 if attributes & 4:
356 |                     append(_style_map[2])
357 |                 if attributes & 8:
358 |                     append(_style_map[3])
[TRUNCATED]
```

.venv/lib/python3.13/site-packages/pip/_vendor/rich/styled.py
```
1 | from typing import TYPE_CHECKING
2 | 
3 | from .measure import Measurement
4 | from .segment import Segment
5 | from .style import StyleType
6 | 
7 | if TYPE_CHECKING:
8 |     from .console import Console, ConsoleOptions, RenderResult, RenderableType
9 | 
10 | 
11 | class Styled:
12 |     """Apply a style to a renderable.
13 | 
14 |     Args:
15 |         renderable (RenderableType): Any renderable.
16 |         style (StyleType): A style to apply across the entire renderable.
17 |     """
18 | 
19 |     def __init__(self, renderable: "RenderableType", style: "StyleType") -> None:
20 |         self.renderable = renderable
21 |         self.style = style
22 | 
23 |     def __rich_console__(
24 |         self, console: "Console", options: "ConsoleOptions"
25 |     ) -> "RenderResult":
26 |         style = console.get_style(self.style)
27 |         rendered_segments = console.render(self.renderable, options)
28 |         segments = Segment.apply_style(rendered_segments, style)
29 |         return segments
30 | 
31 |     def __rich_measure__(
32 |         self, console: "Console", options: "ConsoleOptions"
33 |     ) -> Measurement:
34 |         return Measurement.get(console, options, self.renderable)
35 | 
36 | 
37 | if __name__ == "__main__":  # pragma: no cover
38 |     from pip._vendor.rich import print
39 |     from pip._vendor.rich.panel import Panel
40 | 
41 |     panel = Styled(Panel("hello"), "on blue")
42 |     print(panel)
```

.venv/lib/python3.13/site-packages/pip/_vendor/rich/syntax.py
```
1 | import os.path
2 | import re
3 | import sys
4 | import textwrap
5 | from abc import ABC, abstractmethod
6 | from pathlib import Path
7 | from typing import (
8 |     Any,
9 |     Dict,
10 |     Iterable,
11 |     List,
12 |     NamedTuple,
13 |     Optional,
14 |     Sequence,
15 |     Set,
16 |     Tuple,
17 |     Type,
18 |     Union,
19 | )
20 | 
21 | from pip._vendor.pygments.lexer import Lexer
22 | from pip._vendor.pygments.lexers import get_lexer_by_name, guess_lexer_for_filename
23 | from pip._vendor.pygments.style import Style as PygmentsStyle
24 | from pip._vendor.pygments.styles import get_style_by_name
25 | from pip._vendor.pygments.token import (
26 |     Comment,
27 |     Error,
28 |     Generic,
29 |     Keyword,
30 |     Name,
31 |     Number,
32 |     Operator,
33 |     String,
34 |     Token,
35 |     Whitespace,
36 | )
37 | from pip._vendor.pygments.util import ClassNotFound
38 | 
39 | from pip._vendor.rich.containers import Lines
40 | from pip._vendor.rich.padding import Padding, PaddingDimensions
41 | 
42 | from ._loop import loop_first
43 | from .cells import cell_len
44 | from .color import Color, blend_rgb
45 | from .console import Console, ConsoleOptions, JustifyMethod, RenderResult
46 | from .jupyter import JupyterMixin
47 | from .measure import Measurement
48 | from .segment import Segment, Segments
49 | from .style import Style, StyleType
50 | from .text import Text
51 | 
52 | TokenType = Tuple[str, ...]
53 | 
54 | WINDOWS = sys.platform == "win32"
55 | DEFAULT_THEME = "monokai"
56 | 
57 | # The following styles are based on https://github.com/pygments/pygments/blob/master/pygments/formatters/terminal.py
58 | # A few modifications were made
59 | 
60 | ANSI_LIGHT: Dict[TokenType, Style] = {
61 |     Token: Style(),
62 |     Whitespace: Style(color="white"),
63 |     Comment: Style(dim=True),
64 |     Comment.Preproc: Style(color="cyan"),
65 |     Keyword: Style(color="blue"),
66 |     Keyword.Type: Style(color="cyan"),
67 |     Operator.Word: Style(color="magenta"),
68 |     Name.Builtin: Style(color="cyan"),
69 |     Name.Function: Style(color="green"),
70 |     Name.Namespace: Style(color="cyan", underline=True),
71 |     Name.Class: Style(color="green", underline=True),
72 |     Name.Exception: Style(color="cyan"),
73 |     Name.Decorator: Style(color="magenta", bold=True),
74 |     Name.Variable: Style(color="red"),
75 |     Name.Constant: Style(color="red"),
76 |     Name.Attribute: Style(color="cyan"),
77 |     Name.Tag: Style(color="bright_blue"),
78 |     String: Style(color="yellow"),
79 |     Number: Style(color="blue"),
80 |     Generic.Deleted: Style(color="bright_red"),
81 |     Generic.Inserted: Style(color="green"),
82 |     Generic.Heading: Style(bold=True),
83 |     Generic.Subheading: Style(color="magenta", bold=True),
84 |     Generic.Prompt: Style(bold=True),
85 |     Generic.Error: Style(color="bright_red"),
86 |     Error: Style(color="red", underline=True),
87 | }
88 | 
89 | ANSI_DARK: Dict[TokenType, Style] = {
90 |     Token: Style(),
91 |     Whitespace: Style(color="bright_black"),
92 |     Comment: Style(dim=True),
93 |     Comment.Preproc: Style(color="bright_cyan"),
94 |     Keyword: Style(color="bright_blue"),
95 |     Keyword.Type: Style(color="bright_cyan"),
96 |     Operator.Word: Style(color="bright_magenta"),
97 |     Name.Builtin: Style(color="bright_cyan"),
98 |     Name.Function: Style(color="bright_green"),
99 |     Name.Namespace: Style(color="bright_cyan", underline=True),
100 |     Name.Class: Style(color="bright_green", underline=True),
101 |     Name.Exception: Style(color="bright_cyan"),
102 |     Name.Decorator: Style(color="bright_magenta", bold=True),
103 |     Name.Variable: Style(color="bright_red"),
104 |     Name.Constant: Style(color="bright_red"),
105 |     Name.Attribute: Style(color="bright_cyan"),
106 |     Name.Tag: Style(color="bright_blue"),
107 |     String: Style(color="yellow"),
108 |     Number: Style(color="bright_blue"),
109 |     Generic.Deleted: Style(color="bright_red"),
110 |     Generic.Inserted: Style(color="bright_green"),
111 |     Generic.Heading: Style(bold=True),
112 |     Generic.Subheading: Style(color="bright_magenta", bold=True),
113 |     Generic.Prompt: Style(bold=True),
114 |     Generic.Error: Style(color="bright_red"),
115 |     Error: Style(color="red", underline=True),
116 | }
117 | 
118 | RICH_SYNTAX_THEMES = {"ansi_light": ANSI_LIGHT, "ansi_dark": ANSI_DARK}
119 | NUMBERS_COLUMN_DEFAULT_PADDING = 2
120 | 
121 | 
122 | class SyntaxTheme(ABC):
123 |     """Base class for a syntax theme."""
124 | 
125 |     @abstractmethod
126 |     def get_style_for_token(self, token_type: TokenType) -> Style:
127 |         """Get a style for a given Pygments token."""
128 |         raise NotImplementedError  # pragma: no cover
129 | 
130 |     @abstractmethod
131 |     def get_background_style(self) -> Style:
132 |         """Get the background color."""
133 |         raise NotImplementedError  # pragma: no cover
134 | 
135 | 
136 | class PygmentsSyntaxTheme(SyntaxTheme):
137 |     """Syntax theme that delegates to Pygments theme."""
138 | 
139 |     def __init__(self, theme: Union[str, Type[PygmentsStyle]]) -> None:
140 |         self._style_cache: Dict[TokenType, Style] = {}
141 |         if isinstance(theme, str):
142 |             try:
143 |                 self._pygments_style_class = get_style_by_name(theme)
144 |             except ClassNotFound:
145 |                 self._pygments_style_class = get_style_by_name("default")
146 |         else:
147 |             self._pygments_style_class = theme
148 | 
149 |         self._background_color = self._pygments_style_class.background_color
150 |         self._background_style = Style(bgcolor=self._background_color)
151 | 
152 |     def get_style_for_token(self, token_type: TokenType) -> Style:
153 |         """Get a style from a Pygments class."""
154 |         try:
155 |             return self._style_cache[token_type]
156 |         except KeyError:
157 |             try:
158 |                 pygments_style = self._pygments_style_class.style_for_token(token_type)
159 |             except KeyError:
160 |                 style = Style.null()
161 |             else:
162 |                 color = pygments_style["color"]
163 |                 bgcolor = pygments_style["bgcolor"]
164 |                 style = Style(
165 |                     color="#" + color if color else "#000000",
166 |                     bgcolor="#" + bgcolor if bgcolor else self._background_color,
167 |                     bold=pygments_style["bold"],
168 |                     italic=pygments_style["italic"],
169 |                     underline=pygments_style["underline"],
170 |                 )
171 |             self._style_cache[token_type] = style
172 |         return style
173 | 
174 |     def get_background_style(self) -> Style:
175 |         return self._background_style
176 | 
177 | 
178 | class ANSISyntaxTheme(SyntaxTheme):
179 |     """Syntax theme to use standard colors."""
180 | 
181 |     def __init__(self, style_map: Dict[TokenType, Style]) -> None:
182 |         self.style_map = style_map
183 |         self._missing_style = Style.null()
184 |         self._background_style = Style.null()
185 |         self._style_cache: Dict[TokenType, Style] = {}
186 | 
187 |     def get_style_for_token(self, token_type: TokenType) -> Style:
188 |         """Look up style in the style map."""
189 |         try:
190 |             return self._style_cache[token_type]
191 |         except KeyError:
192 |             # Styles form a hierarchy
193 |             # We need to go from most to least specific
194 |             # e.g. ("foo", "bar", "baz") to ("foo", "bar")  to ("foo",)
195 |             get_style = self.style_map.get
196 |             token = tuple(token_type)
197 |             style = self._missing_style
198 |             while token:
199 |                 _style = get_style(token)
200 |                 if _style is not None:
201 |                     style = _style
202 |                     break
203 |                 token = token[:-1]
204 |             self._style_cache[token_type] = style
205 |             return style
206 | 
207 |     def get_background_style(self) -> Style:
208 |         return self._background_style
209 | 
210 | 
211 | SyntaxPosition = Tuple[int, int]
212 | 
213 | 
214 | class _SyntaxHighlightRange(NamedTuple):
215 |     """
216 |     A range to highlight in a Syntax object.
217 |     `start` and `end` are 2-integers tuples, where the first integer is the line number
218 |     (starting from 1) and the second integer is the column index (starting from 0).
219 |     """
220 | 
221 |     style: StyleType
222 |     start: SyntaxPosition
223 |     end: SyntaxPosition
224 |     style_before: bool = False
225 | 
226 | 
227 | class Syntax(JupyterMixin):
228 |     """Construct a Syntax object to render syntax highlighted code.
229 | 
230 |     Args:
231 |         code (str): Code to highlight.
232 |         lexer (Lexer | str): Lexer to use (see https://pygments.org/docs/lexers/)
233 |         theme (str, optional): Color theme, aka Pygments style (see https://pygments.org/docs/styles/#getting-a-list-of-available-styles). Defaults to "monokai".
234 |         dedent (bool, optional): Enable stripping of initial whitespace. Defaults to False.
235 |         line_numbers (bool, optional): Enable rendering of line numbers. Defaults to False.
236 |         start_line (int, optional): Starting number for line numbers. Defaults to 1.
237 |         line_range (Tuple[int | None, int | None], optional): If given should be a tuple of the start and end line to render.
238 |             A value of None in the tuple indicates the range is open in that direction.
239 |         highlight_lines (Set[int]): A set of line numbers to highlight.
240 |         code_width: Width of code to render (not including line numbers), or ``None`` to use all available width.
241 |         tab_size (int, optional): Size of tabs. Defaults to 4.
242 |         word_wrap (bool, optional): Enable word wrapping.
243 |         background_color (str, optional): Optional background color, or None to use theme color. Defaults to None.
244 |         indent_guides (bool, optional): Show indent guides. Defaults to False.
245 |         padding (PaddingDimensions): Padding to apply around the syntax. Defaults to 0 (no padding).
246 |     """
247 | 
248 |     _pygments_style_class: Type[PygmentsStyle]
249 |     _theme: SyntaxTheme
250 | 
251 |     @classmethod
252 |     def get_theme(cls, name: Union[str, SyntaxTheme]) -> SyntaxTheme:
253 |         """Get a syntax theme instance."""
254 |         if isinstance(name, SyntaxTheme):
255 |             return name
256 |         theme: SyntaxTheme
257 |         if name in RICH_SYNTAX_THEMES:
258 |             theme = ANSISyntaxTheme(RICH_SYNTAX_THEMES[name])
259 |         else:
260 |             theme = PygmentsSyntaxTheme(name)
261 |         return theme
262 | 
263 |     def __init__(
264 |         self,
265 |         code: str,
266 |         lexer: Union[Lexer, str],
267 |         *,
268 |         theme: Union[str, SyntaxTheme] = DEFAULT_THEME,
269 |         dedent: bool = False,
270 |         line_numbers: bool = False,
271 |         start_line: int = 1,
272 |         line_range: Optional[Tuple[Optional[int], Optional[int]]] = None,
273 |         highlight_lines: Optional[Set[int]] = None,
274 |         code_width: Optional[int] = None,
275 |         tab_size: int = 4,
276 |         word_wrap: bool = False,
277 |         background_color: Optional[str] = None,
278 |         indent_guides: bool = False,
279 |         padding: PaddingDimensions = 0,
280 |     ) -> None:
281 |         self.code = code
282 |         self._lexer = lexer
283 |         self.dedent = dedent
284 |         self.line_numbers = line_numbers
285 |         self.start_line = start_line
286 |         self.line_range = line_range
287 |         self.highlight_lines = highlight_lines or set()
288 |         self.code_width = code_width
289 |         self.tab_size = tab_size
290 |         self.word_wrap = word_wrap
291 |         self.background_color = background_color
292 |         self.background_style = (
293 |             Style(bgcolor=background_color) if background_color else Style()
294 |         )
295 |         self.indent_guides = indent_guides
296 |         self.padding = padding
297 | 
298 |         self._theme = self.get_theme(theme)
299 |         self._stylized_ranges: List[_SyntaxHighlightRange] = []
300 | 
301 |     @classmethod
302 |     def from_path(
303 |         cls,
304 |         path: str,
305 |         encoding: str = "utf-8",
306 |         lexer: Optional[Union[Lexer, str]] = None,
307 |         theme: Union[str, SyntaxTheme] = DEFAULT_THEME,
308 |         dedent: bool = False,
309 |         line_numbers: bool = False,
310 |         line_range: Optional[Tuple[int, int]] = None,
311 |         start_line: int = 1,
312 |         highlight_lines: Optional[Set[int]] = None,
313 |         code_width: Optional[int] = None,
314 |         tab_size: int = 4,
315 |         word_wrap: bool = False,
316 |         background_color: Optional[str] = None,
317 |         indent_guides: bool = False,
318 |         padding: PaddingDimensions = 0,
319 |     ) -> "Syntax":
320 |         """Construct a Syntax object from a file.
321 | 
322 |         Args:
323 |             path (str): Path to file to highlight.
324 |             encoding (str): Encoding of file.
325 |             lexer (str | Lexer, optional): Lexer to use. If None, lexer will be auto-detected from path/file content.
326 |             theme (str, optional): Color theme, aka Pygments style (see https://pygments.org/docs/styles/#getting-a-list-of-available-styles). Defaults to "emacs".
327 |             dedent (bool, optional): Enable stripping of initial whitespace. Defaults to True.
328 |             line_numbers (bool, optional): Enable rendering of line numbers. Defaults to False.
329 |             start_line (int, optional): Starting number for line numbers. Defaults to 1.
330 |             line_range (Tuple[int, int], optional): If given should be a tuple of the start and end line to render.
[TRUNCATED]
```

.venv/lib/python3.13/site-packages/pip/_vendor/rich/table.py
```
1 | from dataclasses import dataclass, field, replace
2 | from typing import (
3 |     TYPE_CHECKING,
4 |     Dict,
5 |     Iterable,
6 |     List,
7 |     NamedTuple,
8 |     Optional,
9 |     Sequence,
10 |     Tuple,
11 |     Union,
12 | )
13 | 
14 | from . import box, errors
15 | from ._loop import loop_first_last, loop_last
16 | from ._pick import pick_bool
17 | from ._ratio import ratio_distribute, ratio_reduce
18 | from .align import VerticalAlignMethod
19 | from .jupyter import JupyterMixin
20 | from .measure import Measurement
21 | from .padding import Padding, PaddingDimensions
22 | from .protocol import is_renderable
23 | from .segment import Segment
24 | from .style import Style, StyleType
25 | from .text import Text, TextType
26 | 
27 | if TYPE_CHECKING:
28 |     from .console import (
29 |         Console,
30 |         ConsoleOptions,
31 |         JustifyMethod,
32 |         OverflowMethod,
33 |         RenderableType,
34 |         RenderResult,
35 |     )
36 | 
37 | 
38 | @dataclass
39 | class Column:
40 |     """Defines a column within a ~Table.
41 | 
42 |     Args:
43 |         title (Union[str, Text], optional): The title of the table rendered at the top. Defaults to None.
44 |         caption (Union[str, Text], optional): The table caption rendered below. Defaults to None.
45 |         width (int, optional): The width in characters of the table, or ``None`` to automatically fit. Defaults to None.
46 |         min_width (Optional[int], optional): The minimum width of the table, or ``None`` for no minimum. Defaults to None.
47 |         box (box.Box, optional): One of the constants in box.py used to draw the edges (see :ref:`appendix_box`), or ``None`` for no box lines. Defaults to box.HEAVY_HEAD.
48 |         safe_box (Optional[bool], optional): Disable box characters that don't display on windows legacy terminal with *raster* fonts. Defaults to True.
49 |         padding (PaddingDimensions, optional): Padding for cells (top, right, bottom, left). Defaults to (0, 1).
50 |         collapse_padding (bool, optional): Enable collapsing of padding around cells. Defaults to False.
51 |         pad_edge (bool, optional): Enable padding of edge cells. Defaults to True.
52 |         expand (bool, optional): Expand the table to fit the available space if ``True``, otherwise the table width will be auto-calculated. Defaults to False.
53 |         show_header (bool, optional): Show a header row. Defaults to True.
54 |         show_footer (bool, optional): Show a footer row. Defaults to False.
55 |         show_edge (bool, optional): Draw a box around the outside of the table. Defaults to True.
56 |         show_lines (bool, optional): Draw lines between every row. Defaults to False.
57 |         leading (int, optional): Number of blank lines between rows (precludes ``show_lines``). Defaults to 0.
58 |         style (Union[str, Style], optional): Default style for the table. Defaults to "none".
59 |         row_styles (List[Union, str], optional): Optional list of row styles, if more than one style is given then the styles will alternate. Defaults to None.
60 |         header_style (Union[str, Style], optional): Style of the header. Defaults to "table.header".
61 |         footer_style (Union[str, Style], optional): Style of the footer. Defaults to "table.footer".
62 |         border_style (Union[str, Style], optional): Style of the border. Defaults to None.
63 |         title_style (Union[str, Style], optional): Style of the title. Defaults to None.
64 |         caption_style (Union[str, Style], optional): Style of the caption. Defaults to None.
65 |         title_justify (str, optional): Justify method for title. Defaults to "center".
66 |         caption_justify (str, optional): Justify method for caption. Defaults to "center".
67 |         highlight (bool, optional): Highlight cell contents (if str). Defaults to False.
68 |     """
69 | 
70 |     header: "RenderableType" = ""
71 |     """RenderableType: Renderable for the header (typically a string)"""
72 | 
73 |     footer: "RenderableType" = ""
74 |     """RenderableType: Renderable for the footer (typically a string)"""
75 | 
76 |     header_style: StyleType = ""
77 |     """StyleType: The style of the header."""
78 | 
79 |     footer_style: StyleType = ""
80 |     """StyleType: The style of the footer."""
81 | 
82 |     style: StyleType = ""
83 |     """StyleType: The style of the column."""
84 | 
85 |     justify: "JustifyMethod" = "left"
86 |     """str: How to justify text within the column ("left", "center", "right", or "full")"""
87 | 
88 |     vertical: "VerticalAlignMethod" = "top"
89 |     """str: How to vertically align content ("top", "middle", or "bottom")"""
90 | 
91 |     overflow: "OverflowMethod" = "ellipsis"
92 |     """str: Overflow method."""
93 | 
94 |     width: Optional[int] = None
95 |     """Optional[int]: Width of the column, or ``None`` (default) to auto calculate width."""
96 | 
97 |     min_width: Optional[int] = None
98 |     """Optional[int]: Minimum width of column, or ``None`` for no minimum. Defaults to None."""
99 | 
100 |     max_width: Optional[int] = None
101 |     """Optional[int]: Maximum width of column, or ``None`` for no maximum. Defaults to None."""
102 | 
103 |     ratio: Optional[int] = None
104 |     """Optional[int]: Ratio to use when calculating column width, or ``None`` (default) to adapt to column contents."""
105 | 
106 |     no_wrap: bool = False
107 |     """bool: Prevent wrapping of text within the column. Defaults to ``False``."""
108 | 
109 |     highlight: bool = False
110 |     """bool: Apply highlighter to column. Defaults to ``False``."""
111 | 
112 |     _index: int = 0
113 |     """Index of column."""
114 | 
115 |     _cells: List["RenderableType"] = field(default_factory=list)
116 | 
117 |     def copy(self) -> "Column":
118 |         """Return a copy of this Column."""
119 |         return replace(self, _cells=[])
120 | 
121 |     @property
122 |     def cells(self) -> Iterable["RenderableType"]:
123 |         """Get all cells in the column, not including header."""
124 |         yield from self._cells
125 | 
126 |     @property
127 |     def flexible(self) -> bool:
128 |         """Check if this column is flexible."""
129 |         return self.ratio is not None
130 | 
131 | 
132 | @dataclass
133 | class Row:
134 |     """Information regarding a row."""
135 | 
136 |     style: Optional[StyleType] = None
137 |     """Style to apply to row."""
138 | 
139 |     end_section: bool = False
140 |     """Indicated end of section, which will force a line beneath the row."""
141 | 
142 | 
143 | class _Cell(NamedTuple):
144 |     """A single cell in a table."""
145 | 
146 |     style: StyleType
147 |     """Style to apply to cell."""
148 |     renderable: "RenderableType"
149 |     """Cell renderable."""
150 |     vertical: VerticalAlignMethod
151 |     """Cell vertical alignment."""
152 | 
153 | 
154 | class Table(JupyterMixin):
155 |     """A console renderable to draw a table.
156 | 
157 |     Args:
158 |         *headers (Union[Column, str]): Column headers, either as a string, or :class:`~rich.table.Column` instance.
159 |         title (Union[str, Text], optional): The title of the table rendered at the top. Defaults to None.
160 |         caption (Union[str, Text], optional): The table caption rendered below. Defaults to None.
161 |         width (int, optional): The width in characters of the table, or ``None`` to automatically fit. Defaults to None.
162 |         min_width (Optional[int], optional): The minimum width of the table, or ``None`` for no minimum. Defaults to None.
163 |         box (box.Box, optional): One of the constants in box.py used to draw the edges (see :ref:`appendix_box`), or ``None`` for no box lines. Defaults to box.HEAVY_HEAD.
164 |         safe_box (Optional[bool], optional): Disable box characters that don't display on windows legacy terminal with *raster* fonts. Defaults to True.
165 |         padding (PaddingDimensions, optional): Padding for cells (top, right, bottom, left). Defaults to (0, 1).
166 |         collapse_padding (bool, optional): Enable collapsing of padding around cells. Defaults to False.
167 |         pad_edge (bool, optional): Enable padding of edge cells. Defaults to True.
168 |         expand (bool, optional): Expand the table to fit the available space if ``True``, otherwise the table width will be auto-calculated. Defaults to False.
169 |         show_header (bool, optional): Show a header row. Defaults to True.
170 |         show_footer (bool, optional): Show a footer row. Defaults to False.
171 |         show_edge (bool, optional): Draw a box around the outside of the table. Defaults to True.
172 |         show_lines (bool, optional): Draw lines between every row. Defaults to False.
173 |         leading (int, optional): Number of blank lines between rows (precludes ``show_lines``). Defaults to 0.
174 |         style (Union[str, Style], optional): Default style for the table. Defaults to "none".
175 |         row_styles (List[Union, str], optional): Optional list of row styles, if more than one style is given then the styles will alternate. Defaults to None.
176 |         header_style (Union[str, Style], optional): Style of the header. Defaults to "table.header".
177 |         footer_style (Union[str, Style], optional): Style of the footer. Defaults to "table.footer".
178 |         border_style (Union[str, Style], optional): Style of the border. Defaults to None.
179 |         title_style (Union[str, Style], optional): Style of the title. Defaults to None.
180 |         caption_style (Union[str, Style], optional): Style of the caption. Defaults to None.
181 |         title_justify (str, optional): Justify method for title. Defaults to "center".
182 |         caption_justify (str, optional): Justify method for caption. Defaults to "center".
183 |         highlight (bool, optional): Highlight cell contents (if str). Defaults to False.
184 |     """
185 | 
186 |     columns: List[Column]
187 |     rows: List[Row]
188 | 
189 |     def __init__(
190 |         self,
191 |         *headers: Union[Column, str],
192 |         title: Optional[TextType] = None,
193 |         caption: Optional[TextType] = None,
194 |         width: Optional[int] = None,
195 |         min_width: Optional[int] = None,
196 |         box: Optional[box.Box] = box.HEAVY_HEAD,
197 |         safe_box: Optional[bool] = None,
198 |         padding: PaddingDimensions = (0, 1),
199 |         collapse_padding: bool = False,
200 |         pad_edge: bool = True,
201 |         expand: bool = False,
202 |         show_header: bool = True,
203 |         show_footer: bool = False,
204 |         show_edge: bool = True,
205 |         show_lines: bool = False,
206 |         leading: int = 0,
207 |         style: StyleType = "none",
208 |         row_styles: Optional[Iterable[StyleType]] = None,
209 |         header_style: Optional[StyleType] = "table.header",
210 |         footer_style: Optional[StyleType] = "table.footer",
211 |         border_style: Optional[StyleType] = None,
212 |         title_style: Optional[StyleType] = None,
213 |         caption_style: Optional[StyleType] = None,
214 |         title_justify: "JustifyMethod" = "center",
215 |         caption_justify: "JustifyMethod" = "center",
216 |         highlight: bool = False,
217 |     ) -> None:
218 |         self.columns: List[Column] = []
219 |         self.rows: List[Row] = []
220 |         self.title = title
221 |         self.caption = caption
222 |         self.width = width
223 |         self.min_width = min_width
224 |         self.box = box
225 |         self.safe_box = safe_box
226 |         self._padding = Padding.unpack(padding)
227 |         self.pad_edge = pad_edge
228 |         self._expand = expand
229 |         self.show_header = show_header
230 |         self.show_footer = show_footer
231 |         self.show_edge = show_edge
232 |         self.show_lines = show_lines
233 |         self.leading = leading
234 |         self.collapse_padding = collapse_padding
235 |         self.style = style
236 |         self.header_style = header_style or ""
237 |         self.footer_style = footer_style or ""
238 |         self.border_style = border_style
239 |         self.title_style = title_style
240 |         self.caption_style = caption_style
241 |         self.title_justify: "JustifyMethod" = title_justify
242 |         self.caption_justify: "JustifyMethod" = caption_justify
243 |         self.highlight = highlight
244 |         self.row_styles: Sequence[StyleType] = list(row_styles or [])
245 |         append_column = self.columns.append
246 |         for header in headers:
247 |             if isinstance(header, str):
248 |                 self.add_column(header=header)
249 |             else:
250 |                 header._index = len(self.columns)
251 |                 append_column(header)
252 | 
253 |     @classmethod
254 |     def grid(
255 |         cls,
256 |         *headers: Union[Column, str],
257 |         padding: PaddingDimensions = 0,
258 |         collapse_padding: bool = True,
259 |         pad_edge: bool = False,
260 |         expand: bool = False,
261 |     ) -> "Table":
262 |         """Get a table with no lines, headers, or footer.
263 | 
264 |         Args:
265 |             *headers (Union[Column, str]): Column headers, either as a string, or :class:`~rich.table.Column` instance.
266 |             padding (PaddingDimensions, optional): Get padding around cells. Defaults to 0.
267 |             collapse_padding (bool, optional): Enable collapsing of padding around cells. Defaults to True.
268 |             pad_edge (bool, optional): Enable padding around edges of table. Defaults to False.
269 |             expand (bool, optional): Expand the table to fit the available space if ``True``, otherwise the table width will be auto-calculated. Defaults to False.
270 | 
271 |         Returns:
272 |             Table: A table instance.
273 |         """
274 |         return cls(
275 |             *headers,
276 |             box=None,
277 |             padding=padding,
278 |             collapse_padding=collapse_padding,
279 |             show_header=False,
280 |             show_footer=False,
[TRUNCATED]
```

.venv/lib/python3.13/site-packages/pip/_vendor/rich/terminal_theme.py
```
1 | from typing import List, Optional, Tuple
2 | 
3 | from .color_triplet import ColorTriplet
4 | from .palette import Palette
5 | 
6 | _ColorTuple = Tuple[int, int, int]
7 | 
8 | 
9 | class TerminalTheme:
10 |     """A color theme used when exporting console content.
11 | 
12 |     Args:
13 |         background (Tuple[int, int, int]): The background color.
14 |         foreground (Tuple[int, int, int]): The foreground (text) color.
15 |         normal (List[Tuple[int, int, int]]): A list of 8 normal intensity colors.
16 |         bright (List[Tuple[int, int, int]], optional): A list of 8 bright colors, or None
17 |             to repeat normal intensity. Defaults to None.
18 |     """
19 | 
20 |     def __init__(
21 |         self,
22 |         background: _ColorTuple,
23 |         foreground: _ColorTuple,
24 |         normal: List[_ColorTuple],
25 |         bright: Optional[List[_ColorTuple]] = None,
26 |     ) -> None:
27 |         self.background_color = ColorTriplet(*background)
28 |         self.foreground_color = ColorTriplet(*foreground)
29 |         self.ansi_colors = Palette(normal + (bright or normal))
30 | 
31 | 
32 | DEFAULT_TERMINAL_THEME = TerminalTheme(
33 |     (255, 255, 255),
34 |     (0, 0, 0),
35 |     [
36 |         (0, 0, 0),
37 |         (128, 0, 0),
38 |         (0, 128, 0),
39 |         (128, 128, 0),
40 |         (0, 0, 128),
41 |         (128, 0, 128),
42 |         (0, 128, 128),
43 |         (192, 192, 192),
44 |     ],
45 |     [
46 |         (128, 128, 128),
47 |         (255, 0, 0),
48 |         (0, 255, 0),
49 |         (255, 255, 0),
50 |         (0, 0, 255),
51 |         (255, 0, 255),
52 |         (0, 255, 255),
53 |         (255, 255, 255),
54 |     ],
55 | )
56 | 
57 | MONOKAI = TerminalTheme(
58 |     (12, 12, 12),
59 |     (217, 217, 217),
60 |     [
61 |         (26, 26, 26),
62 |         (244, 0, 95),
63 |         (152, 224, 36),
64 |         (253, 151, 31),
65 |         (157, 101, 255),
66 |         (244, 0, 95),
67 |         (88, 209, 235),
68 |         (196, 197, 181),
69 |         (98, 94, 76),
70 |     ],
71 |     [
72 |         (244, 0, 95),
73 |         (152, 224, 36),
74 |         (224, 213, 97),
75 |         (157, 101, 255),
76 |         (244, 0, 95),
77 |         (88, 209, 235),
78 |         (246, 246, 239),
79 |     ],
80 | )
81 | DIMMED_MONOKAI = TerminalTheme(
82 |     (25, 25, 25),
83 |     (185, 188, 186),
84 |     [
85 |         (58, 61, 67),
86 |         (190, 63, 72),
87 |         (135, 154, 59),
88 |         (197, 166, 53),
89 |         (79, 118, 161),
90 |         (133, 92, 141),
91 |         (87, 143, 164),
92 |         (185, 188, 186),
93 |         (136, 137, 135),
94 |     ],
95 |     [
96 |         (251, 0, 31),
97 |         (15, 114, 47),
98 |         (196, 112, 51),
99 |         (24, 109, 227),
100 |         (251, 0, 103),
101 |         (46, 112, 109),
102 |         (253, 255, 185),
103 |     ],
104 | )
105 | NIGHT_OWLISH = TerminalTheme(
106 |     (255, 255, 255),
107 |     (64, 63, 83),
108 |     [
109 |         (1, 22, 39),
110 |         (211, 66, 62),
111 |         (42, 162, 152),
112 |         (218, 170, 1),
113 |         (72, 118, 214),
114 |         (64, 63, 83),
115 |         (8, 145, 106),
116 |         (122, 129, 129),
117 |         (122, 129, 129),
118 |     ],
119 |     [
120 |         (247, 110, 110),
121 |         (73, 208, 197),
122 |         (218, 194, 107),
123 |         (92, 167, 228),
124 |         (105, 112, 152),
125 |         (0, 201, 144),
126 |         (152, 159, 177),
127 |     ],
128 | )
129 | 
130 | SVG_EXPORT_THEME = TerminalTheme(
131 |     (41, 41, 41),
132 |     (197, 200, 198),
133 |     [
134 |         (75, 78, 85),
135 |         (204, 85, 90),
136 |         (152, 168, 75),
137 |         (208, 179, 68),
138 |         (96, 138, 177),
139 |         (152, 114, 159),
140 |         (104, 160, 179),
141 |         (197, 200, 198),
142 |         (154, 155, 153),
143 |     ],
144 |     [
145 |         (255, 38, 39),
146 |         (0, 130, 61),
147 |         (208, 132, 66),
148 |         (25, 132, 233),
149 |         (255, 44, 122),
150 |         (57, 130, 128),
151 |         (253, 253, 197),
152 |     ],
153 | )
```

.venv/lib/python3.13/site-packages/pip/_vendor/rich/text.py
```
1 | import re
2 | from functools import partial, reduce
3 | from math import gcd
4 | from operator import itemgetter
5 | from typing import (
6 |     TYPE_CHECKING,
7 |     Any,
8 |     Callable,
9 |     Dict,
10 |     Iterable,
11 |     List,
12 |     NamedTuple,
13 |     Optional,
14 |     Pattern,
15 |     Tuple,
16 |     Union,
17 | )
18 | 
19 | from ._loop import loop_last
20 | from ._pick import pick_bool
21 | from ._wrap import divide_line
22 | from .align import AlignMethod
23 | from .cells import cell_len, set_cell_size
24 | from .containers import Lines
25 | from .control import strip_control_codes
26 | from .emoji import EmojiVariant
27 | from .jupyter import JupyterMixin
28 | from .measure import Measurement
29 | from .segment import Segment
30 | from .style import Style, StyleType
31 | 
32 | if TYPE_CHECKING:  # pragma: no cover
33 |     from .console import Console, ConsoleOptions, JustifyMethod, OverflowMethod
34 | 
35 | DEFAULT_JUSTIFY: "JustifyMethod" = "default"
36 | DEFAULT_OVERFLOW: "OverflowMethod" = "fold"
37 | 
38 | 
39 | _re_whitespace = re.compile(r"\s+$")
40 | 
41 | TextType = Union[str, "Text"]
42 | """A plain string or a :class:`Text` instance."""
43 | 
44 | GetStyleCallable = Callable[[str], Optional[StyleType]]
45 | 
46 | 
47 | class Span(NamedTuple):
48 |     """A marked up region in some text."""
49 | 
50 |     start: int
51 |     """Span start index."""
52 |     end: int
53 |     """Span end index."""
54 |     style: Union[str, Style]
55 |     """Style associated with the span."""
56 | 
57 |     def __repr__(self) -> str:
58 |         return f"Span({self.start}, {self.end}, {self.style!r})"
59 | 
60 |     def __bool__(self) -> bool:
61 |         return self.end > self.start
62 | 
63 |     def split(self, offset: int) -> Tuple["Span", Optional["Span"]]:
64 |         """Split a span in to 2 from a given offset."""
65 | 
66 |         if offset < self.start:
67 |             return self, None
68 |         if offset >= self.end:
69 |             return self, None
70 | 
71 |         start, end, style = self
72 |         span1 = Span(start, min(end, offset), style)
73 |         span2 = Span(span1.end, end, style)
74 |         return span1, span2
75 | 
76 |     def move(self, offset: int) -> "Span":
77 |         """Move start and end by a given offset.
78 | 
79 |         Args:
80 |             offset (int): Number of characters to add to start and end.
81 | 
82 |         Returns:
83 |             TextSpan: A new TextSpan with adjusted position.
84 |         """
85 |         start, end, style = self
86 |         return Span(start + offset, end + offset, style)
87 | 
88 |     def right_crop(self, offset: int) -> "Span":
89 |         """Crop the span at the given offset.
90 | 
91 |         Args:
92 |             offset (int): A value between start and end.
93 | 
94 |         Returns:
95 |             Span: A new (possibly smaller) span.
96 |         """
97 |         start, end, style = self
98 |         if offset >= end:
99 |             return self
100 |         return Span(start, min(offset, end), style)
101 | 
102 |     def extend(self, cells: int) -> "Span":
103 |         """Extend the span by the given number of cells.
104 | 
105 |         Args:
106 |             cells (int): Additional space to add to end of span.
107 | 
108 |         Returns:
109 |             Span: A span.
110 |         """
111 |         if cells:
112 |             start, end, style = self
113 |             return Span(start, end + cells, style)
114 |         else:
115 |             return self
116 | 
117 | 
118 | class Text(JupyterMixin):
119 |     """Text with color / style.
120 | 
121 |     Args:
122 |         text (str, optional): Default unstyled text. Defaults to "".
123 |         style (Union[str, Style], optional): Base style for text. Defaults to "".
124 |         justify (str, optional): Justify method: "left", "center", "full", "right". Defaults to None.
125 |         overflow (str, optional): Overflow method: "crop", "fold", "ellipsis". Defaults to None.
126 |         no_wrap (bool, optional): Disable text wrapping, or None for default. Defaults to None.
127 |         end (str, optional): Character to end text with. Defaults to "\\\\n".
128 |         tab_size (int): Number of spaces per tab, or ``None`` to use ``console.tab_size``. Defaults to None.
129 |         spans (List[Span], optional). A list of predefined style spans. Defaults to None.
130 |     """
131 | 
132 |     __slots__ = [
133 |         "_text",
134 |         "style",
135 |         "justify",
136 |         "overflow",
137 |         "no_wrap",
138 |         "end",
139 |         "tab_size",
140 |         "_spans",
141 |         "_length",
142 |     ]
143 | 
144 |     def __init__(
145 |         self,
146 |         text: str = "",
147 |         style: Union[str, Style] = "",
148 |         *,
149 |         justify: Optional["JustifyMethod"] = None,
150 |         overflow: Optional["OverflowMethod"] = None,
151 |         no_wrap: Optional[bool] = None,
152 |         end: str = "\n",
153 |         tab_size: Optional[int] = None,
154 |         spans: Optional[List[Span]] = None,
155 |     ) -> None:
156 |         sanitized_text = strip_control_codes(text)
157 |         self._text = [sanitized_text]
158 |         self.style = style
159 |         self.justify: Optional["JustifyMethod"] = justify
160 |         self.overflow: Optional["OverflowMethod"] = overflow
161 |         self.no_wrap = no_wrap
162 |         self.end = end
163 |         self.tab_size = tab_size
164 |         self._spans: List[Span] = spans or []
165 |         self._length: int = len(sanitized_text)
166 | 
167 |     def __len__(self) -> int:
168 |         return self._length
169 | 
170 |     def __bool__(self) -> bool:
171 |         return bool(self._length)
172 | 
173 |     def __str__(self) -> str:
174 |         return self.plain
175 | 
176 |     def __repr__(self) -> str:
177 |         return f"<text {self.plain!r} {self._spans!r} {self.style!r}>"
178 | 
179 |     def __add__(self, other: Any) -> "Text":
180 |         if isinstance(other, (str, Text)):
181 |             result = self.copy()
182 |             result.append(other)
183 |             return result
184 |         return NotImplemented
185 | 
186 |     def __eq__(self, other: object) -> bool:
187 |         if not isinstance(other, Text):
188 |             return NotImplemented
189 |         return self.plain == other.plain and self._spans == other._spans
190 | 
191 |     def __contains__(self, other: object) -> bool:
192 |         if isinstance(other, str):
193 |             return other in self.plain
194 |         elif isinstance(other, Text):
195 |             return other.plain in self.plain
196 |         return False
197 | 
198 |     def __getitem__(self, slice: Union[int, slice]) -> "Text":
199 |         def get_text_at(offset: int) -> "Text":
200 |             _Span = Span
201 |             text = Text(
202 |                 self.plain[offset],
203 |                 spans=[
204 |                     _Span(0, 1, style)
205 |                     for start, end, style in self._spans
206 |                     if end > offset >= start
207 |                 ],
208 |                 end="",
209 |             )
210 |             return text
211 | 
212 |         if isinstance(slice, int):
213 |             return get_text_at(slice)
214 |         else:
215 |             start, stop, step = slice.indices(len(self.plain))
216 |             if step == 1:
217 |                 lines = self.divide([start, stop])
218 |                 return lines[1]
219 |             else:
220 |                 # This would be a bit of work to implement efficiently
221 |                 # For now, its not required
222 |                 raise TypeError("slices with step!=1 are not supported")
223 | 
224 |     @property
225 |     def cell_len(self) -> int:
226 |         """Get the number of cells required to render this text."""
227 |         return cell_len(self.plain)
228 | 
229 |     @property
230 |     def markup(self) -> str:
231 |         """Get console markup to render this Text.
232 | 
233 |         Returns:
234 |             str: A string potentially creating markup tags.
235 |         """
236 |         from .markup import escape
237 | 
238 |         output: List[str] = []
239 | 
240 |         plain = self.plain
241 |         markup_spans = [
242 |             (0, False, self.style),
243 |             *((span.start, False, span.style) for span in self._spans),
244 |             *((span.end, True, span.style) for span in self._spans),
245 |             (len(plain), True, self.style),
246 |         ]
247 |         markup_spans.sort(key=itemgetter(0, 1))
248 |         position = 0
249 |         append = output.append
250 |         for offset, closing, style in markup_spans:
251 |             if offset > position:
252 |                 append(escape(plain[position:offset]))
253 |                 position = offset
254 |             if style:
255 |                 append(f"[/{style}]" if closing else f"[{style}]")
256 |         markup = "".join(output)
257 |         return markup
258 | 
259 |     @classmethod
260 |     def from_markup(
261 |         cls,
262 |         text: str,
263 |         *,
264 |         style: Union[str, Style] = "",
265 |         emoji: bool = True,
266 |         emoji_variant: Optional[EmojiVariant] = None,
267 |         justify: Optional["JustifyMethod"] = None,
268 |         overflow: Optional["OverflowMethod"] = None,
269 |         end: str = "\n",
270 |     ) -> "Text":
271 |         """Create Text instance from markup.
272 | 
273 |         Args:
274 |             text (str): A string containing console markup.
275 |             style (Union[str, Style], optional): Base style for text. Defaults to "".
276 |             emoji (bool, optional): Also render emoji code. Defaults to True.
277 |             emoji_variant (str, optional): Optional emoji variant, either "text" or "emoji". Defaults to None.
278 |             justify (str, optional): Justify method: "left", "center", "full", "right". Defaults to None.
279 |             overflow (str, optional): Overflow method: "crop", "fold", "ellipsis". Defaults to None.
280 |             end (str, optional): Character to end text with. Defaults to "\\\\n".
281 | 
282 |         Returns:
283 |             Text: A Text instance with markup rendered.
284 |         """
285 |         from .markup import render
286 | 
287 |         rendered_text = render(text, style, emoji=emoji, emoji_variant=emoji_variant)
288 |         rendered_text.justify = justify
289 |         rendered_text.overflow = overflow
290 |         rendered_text.end = end
291 |         return rendered_text
292 | 
293 |     @classmethod
294 |     def from_ansi(
295 |         cls,
296 |         text: str,
297 |         *,
298 |         style: Union[str, Style] = "",
299 |         justify: Optional["JustifyMethod"] = None,
300 |         overflow: Optional["OverflowMethod"] = None,
301 |         no_wrap: Optional[bool] = None,
302 |         end: str = "\n",
303 |         tab_size: Optional[int] = 8,
304 |     ) -> "Text":
305 |         """Create a Text object from a string containing ANSI escape codes.
306 | 
307 |         Args:
308 |             text (str): A string containing escape codes.
309 |             style (Union[str, Style], optional): Base style for text. Defaults to "".
310 |             justify (str, optional): Justify method: "left", "center", "full", "right". Defaults to None.
311 |             overflow (str, optional): Overflow method: "crop", "fold", "ellipsis". Defaults to None.
312 |             no_wrap (bool, optional): Disable text wrapping, or None for default. Defaults to None.
313 |             end (str, optional): Character to end text with. Defaults to "\\\\n".
314 |             tab_size (int): Number of spaces per tab, or ``None`` to use ``console.tab_size``. Defaults to None.
315 |         """
316 |         from .ansi import AnsiDecoder
317 | 
318 |         joiner = Text(
319 |             "\n",
320 |             justify=justify,
321 |             overflow=overflow,
322 |             no_wrap=no_wrap,
323 |             end=end,
324 |             tab_size=tab_size,
325 |             style=style,
326 |         )
327 |         decoder = AnsiDecoder()
328 |         result = joiner.join(line for line in decoder.decode(text))
329 |         return result
330 | 
331 |     @classmethod
332 |     def styled(
333 |         cls,
334 |         text: str,
335 |         style: StyleType = "",
336 |         *,
337 |         justify: Optional["JustifyMethod"] = None,
338 |         overflow: Optional["OverflowMethod"] = None,
339 |     ) -> "Text":
340 |         """Construct a Text instance with a pre-applied styled. A style applied in this way won't be used
341 |         to pad the text when it is justified.
342 | 
343 |         Args:
344 |             text (str): A string containing console markup.
345 |             style (Union[str, Style]): Style to apply to the text. Defaults to "".
346 |             justify (str, optional): Justify method: "left", "center", "full", "right". Defaults to None.
347 |             overflow (str, optional): Overflow method: "crop", "fold", "ellipsis". Defaults to None.
348 | 
349 |         Returns:
350 |             Text: A text instance with a style applied to the entire string.
351 |         """
352 |         styled_text = cls(text, justify=justify, overflow=overflow)
353 |         styled_text.stylize(style)
354 |         return styled_text
355 | 
356 |     @classmethod
357 |     def assemble(
358 |         cls,
359 |         *parts: Union[str, "Text", Tuple[str, StyleType]],
360 |         style: Union[str, Style] = "",
361 |         justify: Optional["JustifyMethod"] = None,
362 |         overflow: Optional["OverflowMethod"] = None,
363 |         no_wrap: Optional[bool] = None,
364 |         end: str = "\n",
365 |         tab_size: int = 8,
366 |         meta: Optional[Dict[str, Any]] = None,
367 |     ) -> "Text":
368 |         """Construct a text instance by combining a sequence of strings with optional styles.
369 |         The positional arguments should be either strings, or a tuple of string + style.
370 | 
371 |         Args:
[TRUNCATED]
```

.venv/lib/python3.13/site-packages/pip/_vendor/rich/theme.py
```
1 | import configparser
2 | from typing import IO, Dict, List, Mapping, Optional
3 | 
4 | from .default_styles import DEFAULT_STYLES
5 | from .style import Style, StyleType
6 | 
7 | 
8 | class Theme:
9 |     """A container for style information, used by :class:`~rich.console.Console`.
10 | 
11 |     Args:
12 |         styles (Dict[str, Style], optional): A mapping of style names on to styles. Defaults to None for a theme with no styles.
13 |         inherit (bool, optional): Inherit default styles. Defaults to True.
14 |     """
15 | 
16 |     styles: Dict[str, Style]
17 | 
18 |     def __init__(
19 |         self, styles: Optional[Mapping[str, StyleType]] = None, inherit: bool = True
20 |     ):
21 |         self.styles = DEFAULT_STYLES.copy() if inherit else {}
22 |         if styles is not None:
23 |             self.styles.update(
24 |                 {
25 |                     name: style if isinstance(style, Style) else Style.parse(style)
26 |                     for name, style in styles.items()
27 |                 }
28 |             )
29 | 
30 |     @property
31 |     def config(self) -> str:
32 |         """Get contents of a config file for this theme."""
33 |         config = "[styles]\n" + "\n".join(
34 |             f"{name} = {style}" for name, style in sorted(self.styles.items())
35 |         )
36 |         return config
37 | 
38 |     @classmethod
39 |     def from_file(
40 |         cls, config_file: IO[str], source: Optional[str] = None, inherit: bool = True
41 |     ) -> "Theme":
42 |         """Load a theme from a text mode file.
43 | 
44 |         Args:
45 |             config_file (IO[str]): An open conf file.
46 |             source (str, optional): The filename of the open file. Defaults to None.
47 |             inherit (bool, optional): Inherit default styles. Defaults to True.
48 | 
49 |         Returns:
50 |             Theme: A New theme instance.
51 |         """
52 |         config = configparser.ConfigParser()
53 |         config.read_file(config_file, source=source)
54 |         styles = {name: Style.parse(value) for name, value in config.items("styles")}
55 |         theme = Theme(styles, inherit=inherit)
56 |         return theme
57 | 
58 |     @classmethod
59 |     def read(
60 |         cls, path: str, inherit: bool = True, encoding: Optional[str] = None
61 |     ) -> "Theme":
62 |         """Read a theme from a path.
63 | 
64 |         Args:
65 |             path (str): Path to a config file readable by Python configparser module.
66 |             inherit (bool, optional): Inherit default styles. Defaults to True.
67 |             encoding (str, optional): Encoding of the config file. Defaults to None.
68 | 
69 |         Returns:
70 |             Theme: A new theme instance.
71 |         """
72 |         with open(path, encoding=encoding) as config_file:
73 |             return cls.from_file(config_file, source=path, inherit=inherit)
74 | 
75 | 
76 | class ThemeStackError(Exception):
77 |     """Base exception for errors related to the theme stack."""
78 | 
79 | 
80 | class ThemeStack:
81 |     """A stack of themes.
82 | 
83 |     Args:
84 |         theme (Theme): A theme instance
85 |     """
86 | 
87 |     def __init__(self, theme: Theme) -> None:
88 |         self._entries: List[Dict[str, Style]] = [theme.styles]
89 |         self.get = self._entries[-1].get
90 | 
91 |     def push_theme(self, theme: Theme, inherit: bool = True) -> None:
92 |         """Push a theme on the top of the stack.
93 | 
94 |         Args:
95 |             theme (Theme): A Theme instance.
96 |             inherit (boolean, optional): Inherit styles from current top of stack.
97 |         """
98 |         styles: Dict[str, Style]
99 |         styles = (
100 |             {**self._entries[-1], **theme.styles} if inherit else theme.styles.copy()
101 |         )
102 |         self._entries.append(styles)
103 |         self.get = self._entries[-1].get
104 | 
105 |     def pop_theme(self) -> None:
106 |         """Pop (and discard) the top-most theme."""
107 |         if len(self._entries) == 1:
108 |             raise ThemeStackError("Unable to pop base theme")
109 |         self._entries.pop()
110 |         self.get = self._entries[-1].get
111 | 
112 | 
113 | if __name__ == "__main__":  # pragma: no cover
114 |     theme = Theme()
115 |     print(theme.config)
```

.venv/lib/python3.13/site-packages/pip/_vendor/rich/themes.py
```
1 | from .default_styles import DEFAULT_STYLES
2 | from .theme import Theme
3 | 
4 | 
5 | DEFAULT = Theme(DEFAULT_STYLES)
```

.venv/lib/python3.13/site-packages/pip/_vendor/rich/traceback.py
```
1 | import inspect
2 | import linecache
3 | import os
4 | import sys
5 | from dataclasses import dataclass, field
6 | from itertools import islice
7 | from traceback import walk_tb
8 | from types import ModuleType, TracebackType
9 | from typing import (
10 |     Any,
11 |     Callable,
12 |     Dict,
13 |     Iterable,
14 |     List,
15 |     Optional,
16 |     Sequence,
17 |     Tuple,
18 |     Type,
19 |     Union,
20 | )
21 | 
22 | from pip._vendor.pygments.lexers import guess_lexer_for_filename
23 | from pip._vendor.pygments.token import Comment, Keyword, Name, Number, Operator, String
24 | from pip._vendor.pygments.token import Text as TextToken
25 | from pip._vendor.pygments.token import Token
26 | from pip._vendor.pygments.util import ClassNotFound
27 | 
28 | from . import pretty
29 | from ._loop import loop_first_last, loop_last
30 | from .columns import Columns
31 | from .console import (
32 |     Console,
33 |     ConsoleOptions,
34 |     ConsoleRenderable,
35 |     Group,
36 |     RenderResult,
37 |     group,
38 | )
39 | from .constrain import Constrain
40 | from .highlighter import RegexHighlighter, ReprHighlighter
41 | from .panel import Panel
42 | from .scope import render_scope
43 | from .style import Style
44 | from .syntax import Syntax, SyntaxPosition
45 | from .text import Text
46 | from .theme import Theme
47 | 
48 | WINDOWS = sys.platform == "win32"
49 | 
50 | LOCALS_MAX_LENGTH = 10
51 | LOCALS_MAX_STRING = 80
52 | 
53 | 
54 | def _iter_syntax_lines(
55 |     start: SyntaxPosition, end: SyntaxPosition
56 | ) -> Iterable[Tuple[int, int, int]]:
57 |     """Yield start and end positions per line.
58 | 
59 |     Args:
60 |         start: Start position.
61 |         end: End position.
62 | 
63 |     Returns:
64 |         Iterable of (LINE, COLUMN1, COLUMN2).
65 |     """
66 | 
67 |     line1, column1 = start
68 |     line2, column2 = end
69 | 
70 |     if line1 == line2:
71 |         yield line1, column1, column2
72 |     else:
73 |         for first, last, line_no in loop_first_last(range(line1, line2 + 1)):
74 |             if first:
75 |                 yield line_no, column1, -1
76 |             elif last:
77 |                 yield line_no, 0, column2
78 |             else:
79 |                 yield line_no, 0, -1
80 | 
81 | 
82 | def install(
83 |     *,
84 |     console: Optional[Console] = None,
85 |     width: Optional[int] = 100,
86 |     code_width: Optional[int] = 88,
87 |     extra_lines: int = 3,
88 |     theme: Optional[str] = None,
89 |     word_wrap: bool = False,
90 |     show_locals: bool = False,
91 |     locals_max_length: int = LOCALS_MAX_LENGTH,
92 |     locals_max_string: int = LOCALS_MAX_STRING,
93 |     locals_hide_dunder: bool = True,
94 |     locals_hide_sunder: Optional[bool] = None,
95 |     indent_guides: bool = True,
96 |     suppress: Iterable[Union[str, ModuleType]] = (),
97 |     max_frames: int = 100,
98 | ) -> Callable[[Type[BaseException], BaseException, Optional[TracebackType]], Any]:
99 |     """Install a rich traceback handler.
100 | 
101 |     Once installed, any tracebacks will be printed with syntax highlighting and rich formatting.
102 | 
103 | 
104 |     Args:
105 |         console (Optional[Console], optional): Console to write exception to. Default uses internal Console instance.
106 |         width (Optional[int], optional): Width (in characters) of traceback. Defaults to 100.
107 |         code_width (Optional[int], optional): Code width (in characters) of traceback. Defaults to 88.
108 |         extra_lines (int, optional): Extra lines of code. Defaults to 3.
109 |         theme (Optional[str], optional): Pygments theme to use in traceback. Defaults to ``None`` which will pick
110 |             a theme appropriate for the platform.
111 |         word_wrap (bool, optional): Enable word wrapping of long lines. Defaults to False.
112 |         show_locals (bool, optional): Enable display of local variables. Defaults to False.
113 |         locals_max_length (int, optional): Maximum length of containers before abbreviating, or None for no abbreviation.
114 |             Defaults to 10.
115 |         locals_max_string (int, optional): Maximum length of string before truncating, or None to disable. Defaults to 80.
116 |         locals_hide_dunder (bool, optional): Hide locals prefixed with double underscore. Defaults to True.
117 |         locals_hide_sunder (bool, optional): Hide locals prefixed with single underscore. Defaults to False.
118 |         indent_guides (bool, optional): Enable indent guides in code and locals. Defaults to True.
119 |         suppress (Sequence[Union[str, ModuleType]]): Optional sequence of modules or paths to exclude from traceback.
120 | 
121 |     Returns:
122 |         Callable: The previous exception handler that was replaced.
123 | 
124 |     """
125 |     traceback_console = Console(stderr=True) if console is None else console
126 | 
127 |     locals_hide_sunder = (
128 |         True
129 |         if (traceback_console.is_jupyter and locals_hide_sunder is None)
130 |         else locals_hide_sunder
131 |     )
132 | 
133 |     def excepthook(
134 |         type_: Type[BaseException],
135 |         value: BaseException,
136 |         traceback: Optional[TracebackType],
137 |     ) -> None:
138 |         exception_traceback = Traceback.from_exception(
139 |             type_,
140 |             value,
141 |             traceback,
142 |             width=width,
143 |             code_width=code_width,
144 |             extra_lines=extra_lines,
145 |             theme=theme,
146 |             word_wrap=word_wrap,
147 |             show_locals=show_locals,
148 |             locals_max_length=locals_max_length,
149 |             locals_max_string=locals_max_string,
150 |             locals_hide_dunder=locals_hide_dunder,
151 |             locals_hide_sunder=bool(locals_hide_sunder),
152 |             indent_guides=indent_guides,
153 |             suppress=suppress,
154 |             max_frames=max_frames,
155 |         )
156 |         traceback_console.print(exception_traceback)
157 | 
158 |     def ipy_excepthook_closure(ip: Any) -> None:  # pragma: no cover
159 |         tb_data = {}  # store information about showtraceback call
160 |         default_showtraceback = ip.showtraceback  # keep reference of default traceback
161 | 
162 |         def ipy_show_traceback(*args: Any, **kwargs: Any) -> None:
163 |             """wrap the default ip.showtraceback to store info for ip._showtraceback"""
164 |             nonlocal tb_data
165 |             tb_data = kwargs
166 |             default_showtraceback(*args, **kwargs)
167 | 
168 |         def ipy_display_traceback(
169 |             *args: Any, is_syntax: bool = False, **kwargs: Any
170 |         ) -> None:
171 |             """Internally called traceback from ip._showtraceback"""
172 |             nonlocal tb_data
173 |             exc_tuple = ip._get_exc_info()
174 | 
175 |             # do not display trace on syntax error
176 |             tb: Optional[TracebackType] = None if is_syntax else exc_tuple[2]
177 | 
178 |             # determine correct tb_offset
179 |             compiled = tb_data.get("running_compiled_code", False)
180 |             tb_offset = tb_data.get("tb_offset", 1 if compiled else 0)
181 |             # remove ipython internal frames from trace with tb_offset
182 |             for _ in range(tb_offset):
183 |                 if tb is None:
184 |                     break
185 |                 tb = tb.tb_next
186 | 
187 |             excepthook(exc_tuple[0], exc_tuple[1], tb)
188 |             tb_data = {}  # clear data upon usage
189 | 
190 |         # replace _showtraceback instead of showtraceback to allow ipython features such as debugging to work
191 |         # this is also what the ipython docs recommends to modify when subclassing InteractiveShell
192 |         ip._showtraceback = ipy_display_traceback
193 |         # add wrapper to capture tb_data
194 |         ip.showtraceback = ipy_show_traceback
195 |         ip.showsyntaxerror = lambda *args, **kwargs: ipy_display_traceback(
196 |             *args, is_syntax=True, **kwargs
197 |         )
198 | 
199 |     try:  # pragma: no cover
200 |         # if within ipython, use customized traceback
201 |         ip = get_ipython()  # type: ignore[name-defined]
202 |         ipy_excepthook_closure(ip)
203 |         return sys.excepthook
204 |     except Exception:
205 |         # otherwise use default system hook
206 |         old_excepthook = sys.excepthook
207 |         sys.excepthook = excepthook
208 |         return old_excepthook
209 | 
210 | 
211 | @dataclass
212 | class Frame:
213 |     filename: str
214 |     lineno: int
215 |     name: str
216 |     line: str = ""
217 |     locals: Optional[Dict[str, pretty.Node]] = None
218 |     last_instruction: Optional[Tuple[Tuple[int, int], Tuple[int, int]]] = None
219 | 
220 | 
221 | @dataclass
222 | class _SyntaxError:
223 |     offset: int
224 |     filename: str
225 |     line: str
226 |     lineno: int
227 |     msg: str
228 |     notes: List[str] = field(default_factory=list)
229 | 
230 | 
231 | @dataclass
232 | class Stack:
233 |     exc_type: str
234 |     exc_value: str
235 |     syntax_error: Optional[_SyntaxError] = None
236 |     is_cause: bool = False
237 |     frames: List[Frame] = field(default_factory=list)
238 |     notes: List[str] = field(default_factory=list)
239 |     is_group: bool = False
240 |     exceptions: List["Trace"] = field(default_factory=list)
241 | 
242 | 
243 | @dataclass
244 | class Trace:
245 |     stacks: List[Stack]
246 | 
247 | 
248 | class PathHighlighter(RegexHighlighter):
249 |     highlights = [r"(?P<dim>.*/)(?P<bold>.+)"]
250 | 
251 | 
252 | class Traceback:
253 |     """A Console renderable that renders a traceback.
254 | 
255 |     Args:
256 |         trace (Trace, optional): A `Trace` object produced from `extract`. Defaults to None, which uses
257 |             the last exception.
258 |         width (Optional[int], optional): Number of characters used to traceback. Defaults to 100.
259 |         code_width (Optional[int], optional): Number of code characters used to traceback. Defaults to 88.
260 |         extra_lines (int, optional): Additional lines of code to render. Defaults to 3.
261 |         theme (str, optional): Override pygments theme used in traceback.
262 |         word_wrap (bool, optional): Enable word wrapping of long lines. Defaults to False.
263 |         show_locals (bool, optional): Enable display of local variables. Defaults to False.
264 |         indent_guides (bool, optional): Enable indent guides in code and locals. Defaults to True.
265 |         locals_max_length (int, optional): Maximum length of containers before abbreviating, or None for no abbreviation.
266 |             Defaults to 10.
267 |         locals_max_string (int, optional): Maximum length of string before truncating, or None to disable. Defaults to 80.
268 |         locals_hide_dunder (bool, optional): Hide locals prefixed with double underscore. Defaults to True.
269 |         locals_hide_sunder (bool, optional): Hide locals prefixed with single underscore. Defaults to False.
270 |         suppress (Sequence[Union[str, ModuleType]]): Optional sequence of modules or paths to exclude from traceback.
271 |         max_frames (int): Maximum number of frames to show in a traceback, 0 for no maximum. Defaults to 100.
272 | 
273 |     """
274 | 
275 |     LEXERS = {
276 |         "": "text",
277 |         ".py": "python",
278 |         ".pxd": "cython",
279 |         ".pyx": "cython",
280 |         ".pxi": "pyrex",
281 |     }
282 | 
283 |     def __init__(
284 |         self,
285 |         trace: Optional[Trace] = None,
286 |         *,
287 |         width: Optional[int] = 100,
288 |         code_width: Optional[int] = 88,
289 |         extra_lines: int = 3,
290 |         theme: Optional[str] = None,
291 |         word_wrap: bool = False,
292 |         show_locals: bool = False,
293 |         locals_max_length: int = LOCALS_MAX_LENGTH,
294 |         locals_max_string: int = LOCALS_MAX_STRING,
295 |         locals_hide_dunder: bool = True,
296 |         locals_hide_sunder: bool = False,
297 |         indent_guides: bool = True,
298 |         suppress: Iterable[Union[str, ModuleType]] = (),
299 |         max_frames: int = 100,
300 |     ):
301 |         if trace is None:
302 |             exc_type, exc_value, traceback = sys.exc_info()
303 |             if exc_type is None or exc_value is None or traceback is None:
304 |                 raise ValueError(
305 |                     "Value for 'trace' required if not called in except: block"
306 |                 )
307 |             trace = self.extract(
308 |                 exc_type, exc_value, traceback, show_locals=show_locals
309 |             )
310 |         self.trace = trace
311 |         self.width = width
312 |         self.code_width = code_width
313 |         self.extra_lines = extra_lines
314 |         self.theme = Syntax.get_theme(theme or "ansi_dark")
315 |         self.word_wrap = word_wrap
316 |         self.show_locals = show_locals
317 |         self.indent_guides = indent_guides
318 |         self.locals_max_length = locals_max_length
319 |         self.locals_max_string = locals_max_string
320 |         self.locals_hide_dunder = locals_hide_dunder
321 |         self.locals_hide_sunder = locals_hide_sunder
322 | 
323 |         self.suppress: Sequence[str] = []
324 |         for suppress_entity in suppress:
325 |             if not isinstance(suppress_entity, str):
326 |                 assert (
327 |                     suppress_entity.__file__ is not None
328 |                 ), f"{suppress_entity!r} must be a module with '__file__' attribute"
329 |                 path = os.path.dirname(suppress_entity.__file__)
330 |             else:
331 |                 path = suppress_entity
332 |             path = os.path.normpath(os.path.abspath(path))
333 |             self.suppress.append(path)
334 |         self.max_frames = max(4, max_frames) if max_frames > 0 else 0
335 | 
336 |     @classmethod
337 |     def from_exception(
338 |         cls,
[TRUNCATED]
```

.venv/lib/python3.13/site-packages/pip/_vendor/rich/tree.py
```
1 | from typing import Iterator, List, Optional, Tuple
2 | 
3 | from ._loop import loop_first, loop_last
4 | from .console import Console, ConsoleOptions, RenderableType, RenderResult
5 | from .jupyter import JupyterMixin
6 | from .measure import Measurement
7 | from .segment import Segment
8 | from .style import Style, StyleStack, StyleType
9 | from .styled import Styled
10 | 
11 | GuideType = Tuple[str, str, str, str]
12 | 
13 | 
14 | class Tree(JupyterMixin):
15 |     """A renderable for a tree structure.
16 | 
17 |     Attributes:
18 |         ASCII_GUIDES (GuideType): Guide lines used when Console.ascii_only is True.
19 |         TREE_GUIDES (List[GuideType, GuideType, GuideType]): Default guide lines.
20 | 
21 |     Args:
22 |         label (RenderableType): The renderable or str for the tree label.
23 |         style (StyleType, optional): Style of this tree. Defaults to "tree".
24 |         guide_style (StyleType, optional): Style of the guide lines. Defaults to "tree.line".
25 |         expanded (bool, optional): Also display children. Defaults to True.
26 |         highlight (bool, optional): Highlight renderable (if str). Defaults to False.
27 |         hide_root (bool, optional): Hide the root node. Defaults to False.
28 |     """
29 | 
30 |     ASCII_GUIDES = ("    ", "|   ", "+-- ", "`-- ")
31 |     TREE_GUIDES = [
32 |         ("    ", "   ", " ", " "),
33 |         ("    ", "   ", " ", " "),
34 |         ("    ", "   ", " ", " "),
35 |     ]
36 | 
37 |     def __init__(
38 |         self,
39 |         label: RenderableType,
40 |         *,
41 |         style: StyleType = "tree",
42 |         guide_style: StyleType = "tree.line",
43 |         expanded: bool = True,
44 |         highlight: bool = False,
45 |         hide_root: bool = False,
46 |     ) -> None:
47 |         self.label = label
48 |         self.style = style
49 |         self.guide_style = guide_style
50 |         self.children: List[Tree] = []
51 |         self.expanded = expanded
52 |         self.highlight = highlight
53 |         self.hide_root = hide_root
54 | 
55 |     def add(
56 |         self,
57 |         label: RenderableType,
58 |         *,
59 |         style: Optional[StyleType] = None,
60 |         guide_style: Optional[StyleType] = None,
61 |         expanded: bool = True,
62 |         highlight: Optional[bool] = False,
63 |     ) -> "Tree":
64 |         """Add a child tree.
65 | 
66 |         Args:
67 |             label (RenderableType): The renderable or str for the tree label.
68 |             style (StyleType, optional): Style of this tree. Defaults to "tree".
69 |             guide_style (StyleType, optional): Style of the guide lines. Defaults to "tree.line".
70 |             expanded (bool, optional): Also display children. Defaults to True.
71 |             highlight (Optional[bool], optional): Highlight renderable (if str). Defaults to False.
72 | 
73 |         Returns:
74 |             Tree: A new child Tree, which may be further modified.
75 |         """
76 |         node = Tree(
77 |             label,
78 |             style=self.style if style is None else style,
79 |             guide_style=self.guide_style if guide_style is None else guide_style,
80 |             expanded=expanded,
81 |             highlight=self.highlight if highlight is None else highlight,
82 |         )
83 |         self.children.append(node)
84 |         return node
85 | 
86 |     def __rich_console__(
87 |         self, console: "Console", options: "ConsoleOptions"
88 |     ) -> "RenderResult":
89 |         stack: List[Iterator[Tuple[bool, Tree]]] = []
90 |         pop = stack.pop
91 |         push = stack.append
92 |         new_line = Segment.line()
93 | 
94 |         get_style = console.get_style
95 |         null_style = Style.null()
96 |         guide_style = get_style(self.guide_style, default="") or null_style
97 |         SPACE, CONTINUE, FORK, END = range(4)
98 | 
99 |         _Segment = Segment
100 | 
101 |         def make_guide(index: int, style: Style) -> Segment:
102 |             """Make a Segment for a level of the guide lines."""
103 |             if options.ascii_only:
104 |                 line = self.ASCII_GUIDES[index]
105 |             else:
106 |                 guide = 1 if style.bold else (2 if style.underline2 else 0)
107 |                 line = self.TREE_GUIDES[0 if options.legacy_windows else guide][index]
108 |             return _Segment(line, style)
109 | 
110 |         levels: List[Segment] = [make_guide(CONTINUE, guide_style)]
111 |         push(iter(loop_last([self])))
112 | 
113 |         guide_style_stack = StyleStack(get_style(self.guide_style))
114 |         style_stack = StyleStack(get_style(self.style))
115 |         remove_guide_styles = Style(bold=False, underline2=False)
116 | 
117 |         depth = 0
118 | 
119 |         while stack:
120 |             stack_node = pop()
121 |             try:
122 |                 last, node = next(stack_node)
123 |             except StopIteration:
124 |                 levels.pop()
125 |                 if levels:
126 |                     guide_style = levels[-1].style or null_style
127 |                     levels[-1] = make_guide(FORK, guide_style)
128 |                     guide_style_stack.pop()
129 |                     style_stack.pop()
130 |                 continue
131 |             push(stack_node)
132 |             if last:
133 |                 levels[-1] = make_guide(END, levels[-1].style or null_style)
134 | 
135 |             guide_style = guide_style_stack.current + get_style(node.guide_style)
136 |             style = style_stack.current + get_style(node.style)
137 |             prefix = levels[(2 if self.hide_root else 1) :]
138 |             renderable_lines = console.render_lines(
139 |                 Styled(node.label, style),
140 |                 options.update(
141 |                     width=options.max_width
142 |                     - sum(level.cell_length for level in prefix),
143 |                     highlight=self.highlight,
144 |                     height=None,
145 |                 ),
146 |                 pad=options.justify is not None,
147 |             )
148 | 
149 |             if not (depth == 0 and self.hide_root):
150 |                 for first, line in loop_first(renderable_lines):
151 |                     if prefix:
152 |                         yield from _Segment.apply_style(
153 |                             prefix,
154 |                             style.background_style,
155 |                             post_style=remove_guide_styles,
156 |                         )
157 |                     yield from line
158 |                     yield new_line
159 |                     if first and prefix:
160 |                         prefix[-1] = make_guide(
161 |                             SPACE if last else CONTINUE, prefix[-1].style or null_style
162 |                         )
163 | 
164 |             if node.expanded and node.children:
165 |                 levels[-1] = make_guide(
166 |                     SPACE if last else CONTINUE, levels[-1].style or null_style
167 |                 )
168 |                 levels.append(
169 |                     make_guide(END if len(node.children) == 1 else FORK, guide_style)
170 |                 )
171 |                 style_stack.push(get_style(node.style))
172 |                 guide_style_stack.push(get_style(node.guide_style))
173 |                 push(iter(loop_last(node.children)))
174 |                 depth += 1
175 | 
176 |     def __rich_measure__(
177 |         self, console: "Console", options: "ConsoleOptions"
178 |     ) -> "Measurement":
179 |         stack: List[Iterator[Tree]] = [iter([self])]
180 |         pop = stack.pop
181 |         push = stack.append
182 |         minimum = 0
183 |         maximum = 0
184 |         measure = Measurement.get
185 |         level = 0
186 |         while stack:
187 |             iter_tree = pop()
188 |             try:
189 |                 tree = next(iter_tree)
190 |             except StopIteration:
191 |                 level -= 1
192 |                 continue
193 |             push(iter_tree)
194 |             min_measure, max_measure = measure(console, options, tree.label)
195 |             indent = level * 4
196 |             minimum = max(min_measure + indent, minimum)
197 |             maximum = max(max_measure + indent, maximum)
198 |             if tree.expanded and tree.children:
199 |                 push(iter(tree.children))
200 |                 level += 1
201 |         return Measurement(minimum, maximum)
202 | 
203 | 
204 | if __name__ == "__main__":  # pragma: no cover
205 |     from pip._vendor.rich.console import Group
206 |     from pip._vendor.rich.markdown import Markdown
207 |     from pip._vendor.rich.panel import Panel
208 |     from pip._vendor.rich.syntax import Syntax
209 |     from pip._vendor.rich.table import Table
210 | 
211 |     table = Table(row_styles=["", "dim"])
212 | 
213 |     table.add_column("Released", style="cyan", no_wrap=True)
214 |     table.add_column("Title", style="magenta")
215 |     table.add_column("Box Office", justify="right", style="green")
216 | 
217 |     table.add_row("Dec 20, 2019", "Star Wars: The Rise of Skywalker", "$952,110,690")
218 |     table.add_row("May 25, 2018", "Solo: A Star Wars Story", "$393,151,347")
219 |     table.add_row("Dec 15, 2017", "Star Wars Ep. V111: The Last Jedi", "$1,332,539,889")
220 |     table.add_row("Dec 16, 2016", "Rogue One: A Star Wars Story", "$1,332,439,889")
221 | 
222 |     code = """\
223 | class Segment(NamedTuple):
224 |     text: str = ""
225 |     style: Optional[Style] = None
226 |     is_control: bool = False
227 | """
228 |     syntax = Syntax(code, "python", theme="monokai", line_numbers=True)
229 | 
230 |     markdown = Markdown(
231 |         """\
232 | ### example.md
233 | > Hello, World!
234 | >
235 | > Markdown _all_ the things
236 | """
237 |     )
238 | 
239 |     root = Tree(" [b green]Rich Tree", highlight=True, hide_root=True)
240 | 
241 |     node = root.add(":file_folder: Renderables", guide_style="red")
242 |     simple_node = node.add(":file_folder: [bold yellow]Atomic", guide_style="uu green")
243 |     simple_node.add(Group(" Syntax", syntax))
244 |     simple_node.add(Group(" Markdown", Panel(markdown, border_style="green")))
245 | 
246 |     containers_node = node.add(
247 |         ":file_folder: [bold magenta]Containers", guide_style="bold magenta"
248 |     )
249 |     containers_node.expanded = True
250 |     panel = Panel.fit("Just a panel", border_style="red")
251 |     containers_node.add(Group(" Panels", panel))
252 | 
253 |     containers_node.add(Group(" [b magenta]Table", table))
254 | 
255 |     console = Console()
256 | 
257 |     console.print(root)
```

.venv/lib/python3.13/site-packages/pip/_internal/metadata/importlib/__init__.py
```
1 | from ._dists import Distribution
2 | from ._envs import Environment
3 | 
4 | __all__ = ["NAME", "Distribution", "Environment"]
5 | 
6 | NAME = "importlib"
```

.venv/lib/python3.13/site-packages/pip/_internal/metadata/importlib/_compat.py
```
1 | import importlib.metadata
2 | import os
3 | from typing import Any, Optional, Protocol, Tuple, cast
4 | 
5 | from pip._vendor.packaging.utils import NormalizedName, canonicalize_name
6 | 
7 | 
8 | class BadMetadata(ValueError):
9 |     def __init__(self, dist: importlib.metadata.Distribution, *, reason: str) -> None:
10 |         self.dist = dist
11 |         self.reason = reason
12 | 
13 |     def __str__(self) -> str:
14 |         return f"Bad metadata in {self.dist} ({self.reason})"
15 | 
16 | 
17 | class BasePath(Protocol):
18 |     """A protocol that various path objects conform.
19 | 
20 |     This exists because importlib.metadata uses both ``pathlib.Path`` and
21 |     ``zipfile.Path``, and we need a common base for type hints (Union does not
22 |     work well since ``zipfile.Path`` is too new for our linter setup).
23 | 
24 |     This does not mean to be exhaustive, but only contains things that present
25 |     in both classes *that we need*.
26 |     """
27 | 
28 |     @property
29 |     def name(self) -> str:
30 |         raise NotImplementedError()
31 | 
32 |     @property
33 |     def parent(self) -> "BasePath":
34 |         raise NotImplementedError()
35 | 
36 | 
37 | def get_info_location(d: importlib.metadata.Distribution) -> Optional[BasePath]:
38 |     """Find the path to the distribution's metadata directory.
39 | 
40 |     HACK: This relies on importlib.metadata's private ``_path`` attribute. Not
41 |     all distributions exist on disk, so importlib.metadata is correct to not
42 |     expose the attribute as public. But pip's code base is old and not as clean,
43 |     so we do this to avoid having to rewrite too many things. Hopefully we can
44 |     eliminate this some day.
45 |     """
46 |     return getattr(d, "_path", None)
47 | 
48 | 
49 | def parse_name_and_version_from_info_directory(
50 |     dist: importlib.metadata.Distribution,
51 | ) -> Tuple[Optional[str], Optional[str]]:
52 |     """Get a name and version from the metadata directory name.
53 | 
54 |     This is much faster than reading distribution metadata.
55 |     """
56 |     info_location = get_info_location(dist)
57 |     if info_location is None:
58 |         return None, None
59 | 
60 |     stem, suffix = os.path.splitext(info_location.name)
61 |     if suffix == ".dist-info":
62 |         name, sep, version = stem.partition("-")
63 |         if sep:
64 |             return name, version
65 | 
66 |     if suffix == ".egg-info":
67 |         name = stem.split("-", 1)[0]
68 |         return name, None
69 | 
70 |     return None, None
71 | 
72 | 
73 | def get_dist_canonical_name(dist: importlib.metadata.Distribution) -> NormalizedName:
74 |     """Get the distribution's normalized name.
75 | 
76 |     The ``name`` attribute is only available in Python 3.10 or later. We are
77 |     targeting exactly that, but Mypy does not know this.
78 |     """
79 |     if name := parse_name_and_version_from_info_directory(dist)[0]:
80 |         return canonicalize_name(name)
81 | 
82 |     name = cast(Any, dist).name
83 |     if not isinstance(name, str):
84 |         raise BadMetadata(dist, reason="invalid metadata entry 'name'")
85 |     return canonicalize_name(name)
```

.venv/lib/python3.13/site-packages/pip/_internal/metadata/importlib/_dists.py
```
1 | import email.message
2 | import importlib.metadata
3 | import pathlib
4 | import zipfile
5 | from os import PathLike
6 | from typing import (
7 |     Collection,
8 |     Dict,
9 |     Iterable,
10 |     Iterator,
11 |     Mapping,
12 |     Optional,
13 |     Sequence,
14 |     Union,
15 |     cast,
16 | )
17 | 
18 | from pip._vendor.packaging.requirements import Requirement
19 | from pip._vendor.packaging.utils import NormalizedName, canonicalize_name
20 | from pip._vendor.packaging.version import Version
21 | from pip._vendor.packaging.version import parse as parse_version
22 | 
23 | from pip._internal.exceptions import InvalidWheel, UnsupportedWheel
24 | from pip._internal.metadata.base import (
25 |     BaseDistribution,
26 |     BaseEntryPoint,
27 |     InfoPath,
28 |     Wheel,
29 | )
30 | from pip._internal.utils.misc import normalize_path
31 | from pip._internal.utils.packaging import get_requirement
32 | from pip._internal.utils.temp_dir import TempDirectory
33 | from pip._internal.utils.wheel import parse_wheel, read_wheel_metadata_file
34 | 
35 | from ._compat import (
36 |     BasePath,
37 |     get_dist_canonical_name,
38 |     parse_name_and_version_from_info_directory,
39 | )
40 | 
41 | 
42 | class WheelDistribution(importlib.metadata.Distribution):
43 |     """An ``importlib.metadata.Distribution`` read from a wheel.
44 | 
45 |     Although ``importlib.metadata.PathDistribution`` accepts ``zipfile.Path``,
46 |     its implementation is too "lazy" for pip's needs (we can't keep the ZipFile
47 |     handle open for the entire lifetime of the distribution object).
48 | 
49 |     This implementation eagerly reads the entire metadata directory into the
50 |     memory instead, and operates from that.
51 |     """
52 | 
53 |     def __init__(
54 |         self,
55 |         files: Mapping[pathlib.PurePosixPath, bytes],
56 |         info_location: pathlib.PurePosixPath,
57 |     ) -> None:
58 |         self._files = files
59 |         self.info_location = info_location
60 | 
61 |     @classmethod
62 |     def from_zipfile(
63 |         cls,
64 |         zf: zipfile.ZipFile,
65 |         name: str,
66 |         location: str,
67 |     ) -> "WheelDistribution":
68 |         info_dir, _ = parse_wheel(zf, name)
69 |         paths = (
70 |             (name, pathlib.PurePosixPath(name.split("/", 1)[-1]))
71 |             for name in zf.namelist()
72 |             if name.startswith(f"{info_dir}/")
73 |         )
74 |         files = {
75 |             relpath: read_wheel_metadata_file(zf, fullpath)
76 |             for fullpath, relpath in paths
77 |         }
78 |         info_location = pathlib.PurePosixPath(location, info_dir)
79 |         return cls(files, info_location)
80 | 
81 |     def iterdir(self, path: InfoPath) -> Iterator[pathlib.PurePosixPath]:
82 |         # Only allow iterating through the metadata directory.
83 |         if pathlib.PurePosixPath(str(path)) in self._files:
84 |             return iter(self._files)
85 |         raise FileNotFoundError(path)
86 | 
87 |     def read_text(self, filename: str) -> Optional[str]:
88 |         try:
89 |             data = self._files[pathlib.PurePosixPath(filename)]
90 |         except KeyError:
91 |             return None
92 |         try:
93 |             text = data.decode("utf-8")
94 |         except UnicodeDecodeError as e:
95 |             wheel = self.info_location.parent
96 |             error = f"Error decoding metadata for {wheel}: {e} in {filename} file"
97 |             raise UnsupportedWheel(error)
98 |         return text
99 | 
100 |     def locate_file(self, path: Union[str, "PathLike[str]"]) -> pathlib.Path:
101 |         # This method doesn't make sense for our in-memory wheel, but the API
102 |         # requires us to define it.
103 |         raise NotImplementedError
104 | 
105 | 
106 | class Distribution(BaseDistribution):
107 |     def __init__(
108 |         self,
109 |         dist: importlib.metadata.Distribution,
110 |         info_location: Optional[BasePath],
111 |         installed_location: Optional[BasePath],
112 |     ) -> None:
113 |         self._dist = dist
114 |         self._info_location = info_location
115 |         self._installed_location = installed_location
116 | 
117 |     @classmethod
118 |     def from_directory(cls, directory: str) -> BaseDistribution:
119 |         info_location = pathlib.Path(directory)
120 |         dist = importlib.metadata.Distribution.at(info_location)
121 |         return cls(dist, info_location, info_location.parent)
122 | 
123 |     @classmethod
124 |     def from_metadata_file_contents(
125 |         cls,
126 |         metadata_contents: bytes,
127 |         filename: str,
128 |         project_name: str,
129 |     ) -> BaseDistribution:
130 |         # Generate temp dir to contain the metadata file, and write the file contents.
131 |         temp_dir = pathlib.Path(
132 |             TempDirectory(kind="metadata", globally_managed=True).path
133 |         )
134 |         metadata_path = temp_dir / "METADATA"
135 |         metadata_path.write_bytes(metadata_contents)
136 |         # Construct dist pointing to the newly created directory.
137 |         dist = importlib.metadata.Distribution.at(metadata_path.parent)
138 |         return cls(dist, metadata_path.parent, None)
139 | 
140 |     @classmethod
141 |     def from_wheel(cls, wheel: Wheel, name: str) -> BaseDistribution:
142 |         try:
143 |             with wheel.as_zipfile() as zf:
144 |                 dist = WheelDistribution.from_zipfile(zf, name, wheel.location)
145 |         except zipfile.BadZipFile as e:
146 |             raise InvalidWheel(wheel.location, name) from e
147 |         return cls(dist, dist.info_location, pathlib.PurePosixPath(wheel.location))
148 | 
149 |     @property
150 |     def location(self) -> Optional[str]:
151 |         if self._info_location is None:
152 |             return None
153 |         return str(self._info_location.parent)
154 | 
155 |     @property
156 |     def info_location(self) -> Optional[str]:
157 |         if self._info_location is None:
158 |             return None
159 |         return str(self._info_location)
160 | 
161 |     @property
162 |     def installed_location(self) -> Optional[str]:
163 |         if self._installed_location is None:
164 |             return None
165 |         return normalize_path(str(self._installed_location))
166 | 
167 |     @property
168 |     def canonical_name(self) -> NormalizedName:
169 |         return get_dist_canonical_name(self._dist)
170 | 
171 |     @property
172 |     def version(self) -> Version:
173 |         if version := parse_name_and_version_from_info_directory(self._dist)[1]:
174 |             return parse_version(version)
175 |         return parse_version(self._dist.version)
176 | 
177 |     @property
178 |     def raw_version(self) -> str:
179 |         return self._dist.version
180 | 
181 |     def is_file(self, path: InfoPath) -> bool:
182 |         return self._dist.read_text(str(path)) is not None
183 | 
184 |     def iter_distutils_script_names(self) -> Iterator[str]:
185 |         # A distutils installation is always "flat" (not in e.g. egg form), so
186 |         # if this distribution's info location is NOT a pathlib.Path (but e.g.
187 |         # zipfile.Path), it can never contain any distutils scripts.
188 |         if not isinstance(self._info_location, pathlib.Path):
189 |             return
190 |         for child in self._info_location.joinpath("scripts").iterdir():
191 |             yield child.name
192 | 
193 |     def read_text(self, path: InfoPath) -> str:
194 |         content = self._dist.read_text(str(path))
195 |         if content is None:
196 |             raise FileNotFoundError(path)
197 |         return content
198 | 
199 |     def iter_entry_points(self) -> Iterable[BaseEntryPoint]:
200 |         # importlib.metadata's EntryPoint structure satisfies BaseEntryPoint.
201 |         return self._dist.entry_points
202 | 
203 |     def _metadata_impl(self) -> email.message.Message:
204 |         # From Python 3.10+, importlib.metadata declares PackageMetadata as the
205 |         # return type. This protocol is unfortunately a disaster now and misses
206 |         # a ton of fields that we need, including get() and get_payload(). We
207 |         # rely on the implementation that the object is actually a Message now,
208 |         # until upstream can improve the protocol. (python/cpython#94952)
209 |         return cast(email.message.Message, self._dist.metadata)
210 | 
211 |     def iter_provided_extras(self) -> Iterable[NormalizedName]:
212 |         return [
213 |             canonicalize_name(extra)
214 |             for extra in self.metadata.get_all("Provides-Extra", [])
215 |         ]
216 | 
217 |     def iter_dependencies(self, extras: Collection[str] = ()) -> Iterable[Requirement]:
218 |         contexts: Sequence[Dict[str, str]] = [{"extra": e} for e in extras]
219 |         for req_string in self.metadata.get_all("Requires-Dist", []):
220 |             # strip() because email.message.Message.get_all() may return a leading \n
221 |             # in case a long header was wrapped.
222 |             req = get_requirement(req_string.strip())
223 |             if not req.marker:
224 |                 yield req
225 |             elif not extras and req.marker.evaluate({"extra": ""}):
226 |                 yield req
227 |             elif any(req.marker.evaluate(context) for context in contexts):
228 |                 yield req
```

.venv/lib/python3.13/site-packages/pip/_internal/metadata/importlib/_envs.py
```
1 | import importlib.metadata
2 | import logging
3 | import os
4 | import pathlib
5 | import sys
6 | import zipfile
7 | from typing import Iterator, List, Optional, Sequence, Set, Tuple
8 | 
9 | from pip._vendor.packaging.utils import (
10 |     InvalidWheelFilename,
11 |     NormalizedName,
12 |     canonicalize_name,
13 |     parse_wheel_filename,
14 | )
15 | 
16 | from pip._internal.metadata.base import BaseDistribution, BaseEnvironment
17 | from pip._internal.utils.filetypes import WHEEL_EXTENSION
18 | 
19 | from ._compat import BadMetadata, BasePath, get_dist_canonical_name, get_info_location
20 | from ._dists import Distribution
21 | 
22 | logger = logging.getLogger(__name__)
23 | 
24 | 
25 | def _looks_like_wheel(location: str) -> bool:
26 |     if not location.endswith(WHEEL_EXTENSION):
27 |         return False
28 |     if not os.path.isfile(location):
29 |         return False
30 |     try:
31 |         parse_wheel_filename(os.path.basename(location))
32 |     except InvalidWheelFilename:
33 |         return False
34 |     return zipfile.is_zipfile(location)
35 | 
36 | 
37 | class _DistributionFinder:
38 |     """Finder to locate distributions.
39 | 
40 |     The main purpose of this class is to memoize found distributions' names, so
41 |     only one distribution is returned for each package name. At lot of pip code
42 |     assumes this (because it is setuptools's behavior), and not doing the same
43 |     can potentially cause a distribution in lower precedence path to override a
44 |     higher precedence one if the caller is not careful.
45 | 
46 |     Eventually we probably want to make it possible to see lower precedence
47 |     installations as well. It's useful feature, after all.
48 |     """
49 | 
50 |     FoundResult = Tuple[importlib.metadata.Distribution, Optional[BasePath]]
51 | 
52 |     def __init__(self) -> None:
53 |         self._found_names: Set[NormalizedName] = set()
54 | 
55 |     def _find_impl(self, location: str) -> Iterator[FoundResult]:
56 |         """Find distributions in a location."""
57 |         # Skip looking inside a wheel. Since a package inside a wheel is not
58 |         # always valid (due to .data directories etc.), its .dist-info entry
59 |         # should not be considered an installed distribution.
60 |         if _looks_like_wheel(location):
61 |             return
62 |         # To know exactly where we find a distribution, we have to feed in the
63 |         # paths one by one, instead of dumping the list to importlib.metadata.
64 |         for dist in importlib.metadata.distributions(path=[location]):
65 |             info_location = get_info_location(dist)
66 |             try:
67 |                 name = get_dist_canonical_name(dist)
68 |             except BadMetadata as e:
69 |                 logger.warning("Skipping %s due to %s", info_location, e.reason)
70 |                 continue
71 |             if name in self._found_names:
72 |                 continue
73 |             self._found_names.add(name)
74 |             yield dist, info_location
75 | 
76 |     def find(self, location: str) -> Iterator[BaseDistribution]:
77 |         """Find distributions in a location.
78 | 
79 |         The path can be either a directory, or a ZIP archive.
80 |         """
81 |         for dist, info_location in self._find_impl(location):
82 |             if info_location is None:
83 |                 installed_location: Optional[BasePath] = None
84 |             else:
85 |                 installed_location = info_location.parent
86 |             yield Distribution(dist, info_location, installed_location)
87 | 
88 |     def find_legacy_editables(self, location: str) -> Iterator[BaseDistribution]:
89 |         """Read location in egg-link files and return distributions in there.
90 | 
91 |         The path should be a directory; otherwise this returns nothing. This
92 |         follows how setuptools does this for compatibility. The first non-empty
93 |         line in the egg-link is read as a path (resolved against the egg-link's
94 |         containing directory if relative). Distributions found at that linked
95 |         location are returned.
96 |         """
97 |         path = pathlib.Path(location)
98 |         if not path.is_dir():
99 |             return
100 |         for child in path.iterdir():
101 |             if child.suffix != ".egg-link":
102 |                 continue
103 |             with child.open() as f:
104 |                 lines = (line.strip() for line in f)
105 |                 target_rel = next((line for line in lines if line), "")
106 |             if not target_rel:
107 |                 continue
108 |             target_location = str(path.joinpath(target_rel))
109 |             for dist, info_location in self._find_impl(target_location):
110 |                 yield Distribution(dist, info_location, path)
111 | 
112 | 
113 | class Environment(BaseEnvironment):
114 |     def __init__(self, paths: Sequence[str]) -> None:
115 |         self._paths = paths
116 | 
117 |     @classmethod
118 |     def default(cls) -> BaseEnvironment:
119 |         return cls(sys.path)
120 | 
121 |     @classmethod
122 |     def from_paths(cls, paths: Optional[List[str]]) -> BaseEnvironment:
123 |         if paths is None:
124 |             return cls(sys.path)
125 |         return cls(paths)
126 | 
127 |     def _iter_distributions(self) -> Iterator[BaseDistribution]:
128 |         finder = _DistributionFinder()
129 |         for location in self._paths:
130 |             yield from finder.find(location)
131 |             yield from finder.find_legacy_editables(location)
132 | 
133 |     def get_distribution(self, name: str) -> Optional[BaseDistribution]:
134 |         canonical_name = canonicalize_name(name)
135 |         matches = (
136 |             distribution
137 |             for distribution in self.iter_all_distributions()
138 |             if distribution.canonical_name == canonical_name
139 |         )
140 |         return next(matches, None)
```

.venv/lib/python3.13/site-packages/pip/_internal/resolution/legacy/__init__.py
```
```

.venv/lib/python3.13/site-packages/pip/_internal/resolution/legacy/resolver.py
```
1 | """Dependency Resolution
2 | 
3 | The dependency resolution in pip is performed as follows:
4 | 
5 | for top-level requirements:
6 |     a. only one spec allowed per project, regardless of conflicts or not.
7 |        otherwise a "double requirement" exception is raised
8 |     b. they override sub-dependency requirements.
9 | for sub-dependencies
10 |     a. "first found, wins" (where the order is breadth first)
11 | """
12 | 
13 | import logging
14 | import sys
15 | from collections import defaultdict
16 | from itertools import chain
17 | from typing import DefaultDict, Iterable, List, Optional, Set, Tuple
18 | 
19 | from pip._vendor.packaging import specifiers
20 | from pip._vendor.packaging.requirements import Requirement
21 | 
22 | from pip._internal.cache import WheelCache
23 | from pip._internal.exceptions import (
24 |     BestVersionAlreadyInstalled,
25 |     DistributionNotFound,
26 |     HashError,
27 |     HashErrors,
28 |     InstallationError,
29 |     NoneMetadataError,
30 |     UnsupportedPythonVersion,
31 | )
32 | from pip._internal.index.package_finder import PackageFinder
33 | from pip._internal.metadata import BaseDistribution
34 | from pip._internal.models.link import Link
35 | from pip._internal.models.wheel import Wheel
36 | from pip._internal.operations.prepare import RequirementPreparer
37 | from pip._internal.req.req_install import (
38 |     InstallRequirement,
39 |     check_invalid_constraint_type,
40 | )
41 | from pip._internal.req.req_set import RequirementSet
42 | from pip._internal.resolution.base import BaseResolver, InstallRequirementProvider
43 | from pip._internal.utils import compatibility_tags
44 | from pip._internal.utils.compatibility_tags import get_supported
45 | from pip._internal.utils.direct_url_helpers import direct_url_from_link
46 | from pip._internal.utils.logging import indent_log
47 | from pip._internal.utils.misc import normalize_version_info
48 | from pip._internal.utils.packaging import check_requires_python
49 | 
50 | logger = logging.getLogger(__name__)
51 | 
52 | DiscoveredDependencies = DefaultDict[Optional[str], List[InstallRequirement]]
53 | 
54 | 
55 | def _check_dist_requires_python(
56 |     dist: BaseDistribution,
57 |     version_info: Tuple[int, int, int],
58 |     ignore_requires_python: bool = False,
59 | ) -> None:
60 |     """
61 |     Check whether the given Python version is compatible with a distribution's
62 |     "Requires-Python" value.
63 | 
64 |     :param version_info: A 3-tuple of ints representing the Python
65 |         major-minor-micro version to check.
66 |     :param ignore_requires_python: Whether to ignore the "Requires-Python"
67 |         value if the given Python version isn't compatible.
68 | 
69 |     :raises UnsupportedPythonVersion: When the given Python version isn't
70 |         compatible.
71 |     """
72 |     # This idiosyncratically converts the SpecifierSet to str and let
73 |     # check_requires_python then parse it again into SpecifierSet. But this
74 |     # is the legacy resolver so I'm just not going to bother refactoring.
75 |     try:
76 |         requires_python = str(dist.requires_python)
77 |     except FileNotFoundError as e:
78 |         raise NoneMetadataError(dist, str(e))
79 |     try:
80 |         is_compatible = check_requires_python(
81 |             requires_python,
82 |             version_info=version_info,
83 |         )
84 |     except specifiers.InvalidSpecifier as exc:
85 |         logger.warning(
86 |             "Package %r has an invalid Requires-Python: %s", dist.raw_name, exc
87 |         )
88 |         return
89 | 
90 |     if is_compatible:
91 |         return
92 | 
93 |     version = ".".join(map(str, version_info))
94 |     if ignore_requires_python:
95 |         logger.debug(
96 |             "Ignoring failed Requires-Python check for package %r: %s not in %r",
97 |             dist.raw_name,
98 |             version,
99 |             requires_python,
100 |         )
101 |         return
102 | 
103 |     raise UnsupportedPythonVersion(
104 |         f"Package {dist.raw_name!r} requires a different Python: "
105 |         f"{version} not in {requires_python!r}"
106 |     )
107 | 
108 | 
109 | class Resolver(BaseResolver):
110 |     """Resolves which packages need to be installed/uninstalled to perform \
111 |     the requested operation without breaking the requirements of any package.
112 |     """
113 | 
114 |     _allowed_strategies = {"eager", "only-if-needed", "to-satisfy-only"}
115 | 
116 |     def __init__(
117 |         self,
118 |         preparer: RequirementPreparer,
119 |         finder: PackageFinder,
120 |         wheel_cache: Optional[WheelCache],
121 |         make_install_req: InstallRequirementProvider,
122 |         use_user_site: bool,
123 |         ignore_dependencies: bool,
124 |         ignore_installed: bool,
125 |         ignore_requires_python: bool,
126 |         force_reinstall: bool,
127 |         upgrade_strategy: str,
128 |         py_version_info: Optional[Tuple[int, ...]] = None,
129 |     ) -> None:
130 |         super().__init__()
131 |         assert upgrade_strategy in self._allowed_strategies
132 | 
133 |         if py_version_info is None:
134 |             py_version_info = sys.version_info[:3]
135 |         else:
136 |             py_version_info = normalize_version_info(py_version_info)
137 | 
138 |         self._py_version_info = py_version_info
139 | 
140 |         self.preparer = preparer
141 |         self.finder = finder
142 |         self.wheel_cache = wheel_cache
143 | 
144 |         self.upgrade_strategy = upgrade_strategy
145 |         self.force_reinstall = force_reinstall
146 |         self.ignore_dependencies = ignore_dependencies
147 |         self.ignore_installed = ignore_installed
148 |         self.ignore_requires_python = ignore_requires_python
149 |         self.use_user_site = use_user_site
150 |         self._make_install_req = make_install_req
151 | 
152 |         self._discovered_dependencies: DiscoveredDependencies = defaultdict(list)
153 | 
154 |     def resolve(
155 |         self, root_reqs: List[InstallRequirement], check_supported_wheels: bool
156 |     ) -> RequirementSet:
157 |         """Resolve what operations need to be done
158 | 
159 |         As a side-effect of this method, the packages (and their dependencies)
160 |         are downloaded, unpacked and prepared for installation. This
161 |         preparation is done by ``pip.operations.prepare``.
162 | 
163 |         Once PyPI has static dependency metadata available, it would be
164 |         possible to move the preparation to become a step separated from
165 |         dependency resolution.
166 |         """
167 |         requirement_set = RequirementSet(check_supported_wheels=check_supported_wheels)
168 |         for req in root_reqs:
169 |             if req.constraint:
170 |                 check_invalid_constraint_type(req)
171 |             self._add_requirement_to_set(requirement_set, req)
172 | 
173 |         # Actually prepare the files, and collect any exceptions. Most hash
174 |         # exceptions cannot be checked ahead of time, because
175 |         # _populate_link() needs to be called before we can make decisions
176 |         # based on link type.
177 |         discovered_reqs: List[InstallRequirement] = []
178 |         hash_errors = HashErrors()
179 |         for req in chain(requirement_set.all_requirements, discovered_reqs):
180 |             try:
181 |                 discovered_reqs.extend(self._resolve_one(requirement_set, req))
182 |             except HashError as exc:
183 |                 exc.req = req
184 |                 hash_errors.append(exc)
185 | 
186 |         if hash_errors:
187 |             raise hash_errors
188 | 
189 |         return requirement_set
190 | 
191 |     def _add_requirement_to_set(
192 |         self,
193 |         requirement_set: RequirementSet,
194 |         install_req: InstallRequirement,
195 |         parent_req_name: Optional[str] = None,
196 |         extras_requested: Optional[Iterable[str]] = None,
197 |     ) -> Tuple[List[InstallRequirement], Optional[InstallRequirement]]:
198 |         """Add install_req as a requirement to install.
199 | 
200 |         :param parent_req_name: The name of the requirement that needed this
201 |             added. The name is used because when multiple unnamed requirements
202 |             resolve to the same name, we could otherwise end up with dependency
203 |             links that point outside the Requirements set. parent_req must
204 |             already be added. Note that None implies that this is a user
205 |             supplied requirement, vs an inferred one.
206 |         :param extras_requested: an iterable of extras used to evaluate the
207 |             environment markers.
208 |         :return: Additional requirements to scan. That is either [] if
209 |             the requirement is not applicable, or [install_req] if the
210 |             requirement is applicable and has just been added.
211 |         """
212 |         # If the markers do not match, ignore this requirement.
213 |         if not install_req.match_markers(extras_requested):
214 |             logger.info(
215 |                 "Ignoring %s: markers '%s' don't match your environment",
216 |                 install_req.name,
217 |                 install_req.markers,
218 |             )
219 |             return [], None
220 | 
221 |         # If the wheel is not supported, raise an error.
222 |         # Should check this after filtering out based on environment markers to
223 |         # allow specifying different wheels based on the environment/OS, in a
224 |         # single requirements file.
225 |         if install_req.link and install_req.link.is_wheel:
226 |             wheel = Wheel(install_req.link.filename)
227 |             tags = compatibility_tags.get_supported()
228 |             if requirement_set.check_supported_wheels and not wheel.supported(tags):
229 |                 raise InstallationError(
230 |                     f"{wheel.filename} is not a supported wheel on this platform."
231 |                 )
232 | 
233 |         # This next bit is really a sanity check.
234 |         assert (
235 |             not install_req.user_supplied or parent_req_name is None
236 |         ), "a user supplied req shouldn't have a parent"
237 | 
238 |         # Unnamed requirements are scanned again and the requirement won't be
239 |         # added as a dependency until after scanning.
240 |         if not install_req.name:
241 |             requirement_set.add_unnamed_requirement(install_req)
242 |             return [install_req], None
243 | 
244 |         try:
245 |             existing_req: Optional[InstallRequirement] = (
246 |                 requirement_set.get_requirement(install_req.name)
247 |             )
248 |         except KeyError:
249 |             existing_req = None
250 | 
251 |         has_conflicting_requirement = (
252 |             parent_req_name is None
253 |             and existing_req
254 |             and not existing_req.constraint
255 |             and existing_req.extras == install_req.extras
256 |             and existing_req.req
257 |             and install_req.req
258 |             and existing_req.req.specifier != install_req.req.specifier
259 |         )
260 |         if has_conflicting_requirement:
261 |             raise InstallationError(
262 |                 f"Double requirement given: {install_req} "
263 |                 f"(already in {existing_req}, name={install_req.name!r})"
264 |             )
265 | 
266 |         # When no existing requirement exists, add the requirement as a
267 |         # dependency and it will be scanned again after.
268 |         if not existing_req:
269 |             requirement_set.add_named_requirement(install_req)
270 |             # We'd want to rescan this requirement later
271 |             return [install_req], install_req
272 | 
273 |         # Assume there's no need to scan, and that we've already
274 |         # encountered this for scanning.
275 |         if install_req.constraint or not existing_req.constraint:
276 |             return [], existing_req
277 | 
278 |         does_not_satisfy_constraint = install_req.link and not (
279 |             existing_req.link and install_req.link.path == existing_req.link.path
280 |         )
281 |         if does_not_satisfy_constraint:
282 |             raise InstallationError(
283 |                 f"Could not satisfy constraints for '{install_req.name}': "
284 |                 "installation from path or url cannot be "
285 |                 "constrained to a version"
286 |             )
287 |         # If we're now installing a constraint, mark the existing
288 |         # object for real installation.
289 |         existing_req.constraint = False
290 |         # If we're now installing a user supplied requirement,
291 |         # mark the existing object as such.
292 |         if install_req.user_supplied:
293 |             existing_req.user_supplied = True
294 |         existing_req.extras = tuple(
295 |             sorted(set(existing_req.extras) | set(install_req.extras))
296 |         )
297 |         logger.debug(
298 |             "Setting %s extras to: %s",
299 |             existing_req,
300 |             existing_req.extras,
301 |         )
302 |         # Return the existing requirement for addition to the parent and
303 |         # scanning again.
304 |         return [existing_req], existing_req
305 | 
306 |     def _is_upgrade_allowed(self, req: InstallRequirement) -> bool:
307 |         if self.upgrade_strategy == "to-satisfy-only":
308 |             return False
309 |         elif self.upgrade_strategy == "eager":
310 |             return True
311 |         else:
312 |             assert self.upgrade_strategy == "only-if-needed"
313 |             return req.user_supplied or req.constraint
314 | 
315 |     def _set_req_to_reinstall(self, req: InstallRequirement) -> None:
316 |         """
317 |         Set a requirement to be installed.
318 |         """
319 |         # Don't uninstall the conflict if doing a user install and the
320 |         # conflict is not a user install.
321 |         assert req.satisfied_by is not None
322 |         if not self.use_user_site or req.satisfied_by.in_usersite:
323 |             req.should_reinstall = True
324 |         req.satisfied_by = None
325 | 
326 |     def _check_skip_installed(
327 |         self, req_to_install: InstallRequirement
328 |     ) -> Optional[str]:
329 |         """Check if req_to_install should be skipped.
330 | 
331 |         This will check if the req is installed, and whether we should upgrade
[TRUNCATED]
```

.venv/lib/python3.13/site-packages/pip/_internal/operations/install/__init__.py
```
1 | """For modules related to installing packages."""
```

.venv/lib/python3.13/site-packages/pip/_internal/operations/install/editable_legacy.py
```
1 | """Legacy editable installation process, i.e. `setup.py develop`."""
2 | 
3 | import logging
4 | from typing import Optional, Sequence
5 | 
6 | from pip._internal.build_env import BuildEnvironment
7 | from pip._internal.utils.logging import indent_log
8 | from pip._internal.utils.setuptools_build import make_setuptools_develop_args
9 | from pip._internal.utils.subprocess import call_subprocess
10 | 
11 | logger = logging.getLogger(__name__)
12 | 
13 | 
14 | def install_editable(
15 |     *,
16 |     global_options: Sequence[str],
17 |     prefix: Optional[str],
18 |     home: Optional[str],
19 |     use_user_site: bool,
20 |     name: str,
21 |     setup_py_path: str,
22 |     isolated: bool,
23 |     build_env: BuildEnvironment,
24 |     unpacked_source_directory: str,
25 | ) -> None:
26 |     """Install a package in editable mode. Most arguments are pass-through
27 |     to setuptools.
28 |     """
29 |     logger.info("Running setup.py develop for %s", name)
30 | 
31 |     args = make_setuptools_develop_args(
32 |         setup_py_path,
33 |         global_options=global_options,
34 |         no_user_config=isolated,
35 |         prefix=prefix,
36 |         home=home,
37 |         use_user_site=use_user_site,
38 |     )
39 | 
40 |     with indent_log():
41 |         with build_env:
42 |             call_subprocess(
43 |                 args,
44 |                 command_desc="python setup.py develop",
45 |                 cwd=unpacked_source_directory,
46 |             )
```

.venv/lib/python3.13/site-packages/pip/_internal/operations/install/wheel.py
```
1 | """Support for installing and building the "wheel" binary package format."""
2 | 
3 | import collections
4 | import compileall
5 | import contextlib
6 | import csv
7 | import importlib
8 | import logging
9 | import os.path
10 | import re
11 | import shutil
12 | import sys
13 | import warnings
14 | from base64 import urlsafe_b64encode
15 | from email.message import Message
16 | from itertools import chain, filterfalse, starmap
17 | from typing import (
18 |     IO,
19 |     Any,
20 |     BinaryIO,
21 |     Callable,
22 |     Dict,
23 |     Generator,
24 |     Iterable,
25 |     Iterator,
26 |     List,
27 |     NewType,
28 |     Optional,
29 |     Protocol,
30 |     Sequence,
31 |     Set,
32 |     Tuple,
33 |     Union,
34 |     cast,
35 | )
36 | from zipfile import ZipFile, ZipInfo
37 | 
38 | from pip._vendor.distlib.scripts import ScriptMaker
39 | from pip._vendor.distlib.util import get_export_entry
40 | from pip._vendor.packaging.utils import canonicalize_name
41 | 
42 | from pip._internal.exceptions import InstallationError
43 | from pip._internal.locations import get_major_minor_version
44 | from pip._internal.metadata import (
45 |     BaseDistribution,
46 |     FilesystemWheel,
47 |     get_wheel_distribution,
48 | )
49 | from pip._internal.models.direct_url import DIRECT_URL_METADATA_NAME, DirectUrl
50 | from pip._internal.models.scheme import SCHEME_KEYS, Scheme
51 | from pip._internal.utils.filesystem import adjacent_tmp_file, replace
52 | from pip._internal.utils.misc import StreamWrapper, ensure_dir, hash_file, partition
53 | from pip._internal.utils.unpacking import (
54 |     current_umask,
55 |     is_within_directory,
56 |     set_extracted_file_to_default_mode_plus_executable,
57 |     zip_item_is_executable,
58 | )
59 | from pip._internal.utils.wheel import parse_wheel
60 | 
61 | 
62 | class File(Protocol):
63 |     src_record_path: "RecordPath"
64 |     dest_path: str
65 |     changed: bool
66 | 
67 |     def save(self) -> None:
68 |         pass
69 | 
70 | 
71 | logger = logging.getLogger(__name__)
72 | 
73 | RecordPath = NewType("RecordPath", str)
74 | InstalledCSVRow = Tuple[RecordPath, str, Union[int, str]]
75 | 
76 | 
77 | def rehash(path: str, blocksize: int = 1 << 20) -> Tuple[str, str]:
78 |     """Return (encoded_digest, length) for path using hashlib.sha256()"""
79 |     h, length = hash_file(path, blocksize)
80 |     digest = "sha256=" + urlsafe_b64encode(h.digest()).decode("latin1").rstrip("=")
81 |     return (digest, str(length))
82 | 
83 | 
84 | def csv_io_kwargs(mode: str) -> Dict[str, Any]:
85 |     """Return keyword arguments to properly open a CSV file
86 |     in the given mode.
87 |     """
88 |     return {"mode": mode, "newline": "", "encoding": "utf-8"}
89 | 
90 | 
91 | def fix_script(path: str) -> bool:
92 |     """Replace #!python with #!/path/to/python
93 |     Return True if file was changed.
94 |     """
95 |     # XXX RECORD hashes will need to be updated
96 |     assert os.path.isfile(path)
97 | 
98 |     with open(path, "rb") as script:
99 |         firstline = script.readline()
100 |         if not firstline.startswith(b"#!python"):
101 |             return False
102 |         exename = sys.executable.encode(sys.getfilesystemencoding())
103 |         firstline = b"#!" + exename + os.linesep.encode("ascii")
104 |         rest = script.read()
105 |     with open(path, "wb") as script:
106 |         script.write(firstline)
107 |         script.write(rest)
108 |     return True
109 | 
110 | 
111 | def wheel_root_is_purelib(metadata: Message) -> bool:
112 |     return metadata.get("Root-Is-Purelib", "").lower() == "true"
113 | 
114 | 
115 | def get_entrypoints(dist: BaseDistribution) -> Tuple[Dict[str, str], Dict[str, str]]:
116 |     console_scripts = {}
117 |     gui_scripts = {}
118 |     for entry_point in dist.iter_entry_points():
119 |         if entry_point.group == "console_scripts":
120 |             console_scripts[entry_point.name] = entry_point.value
121 |         elif entry_point.group == "gui_scripts":
122 |             gui_scripts[entry_point.name] = entry_point.value
123 |     return console_scripts, gui_scripts
124 | 
125 | 
126 | def message_about_scripts_not_on_PATH(scripts: Sequence[str]) -> Optional[str]:
127 |     """Determine if any scripts are not on PATH and format a warning.
128 |     Returns a warning message if one or more scripts are not on PATH,
129 |     otherwise None.
130 |     """
131 |     if not scripts:
132 |         return None
133 | 
134 |     # Group scripts by the path they were installed in
135 |     grouped_by_dir: Dict[str, Set[str]] = collections.defaultdict(set)
136 |     for destfile in scripts:
137 |         parent_dir = os.path.dirname(destfile)
138 |         script_name = os.path.basename(destfile)
139 |         grouped_by_dir[parent_dir].add(script_name)
140 | 
141 |     # We don't want to warn for directories that are on PATH.
142 |     not_warn_dirs = [
143 |         os.path.normcase(os.path.normpath(i)).rstrip(os.sep)
144 |         for i in os.environ.get("PATH", "").split(os.pathsep)
145 |     ]
146 |     # If an executable sits with sys.executable, we don't warn for it.
147 |     #     This covers the case of venv invocations without activating the venv.
148 |     not_warn_dirs.append(
149 |         os.path.normcase(os.path.normpath(os.path.dirname(sys.executable)))
150 |     )
151 |     warn_for: Dict[str, Set[str]] = {
152 |         parent_dir: scripts
153 |         for parent_dir, scripts in grouped_by_dir.items()
154 |         if os.path.normcase(os.path.normpath(parent_dir)) not in not_warn_dirs
155 |     }
156 |     if not warn_for:
157 |         return None
158 | 
159 |     # Format a message
160 |     msg_lines = []
161 |     for parent_dir, dir_scripts in warn_for.items():
162 |         sorted_scripts: List[str] = sorted(dir_scripts)
163 |         if len(sorted_scripts) == 1:
164 |             start_text = f"script {sorted_scripts[0]} is"
165 |         else:
166 |             start_text = "scripts {} are".format(
167 |                 ", ".join(sorted_scripts[:-1]) + " and " + sorted_scripts[-1]
168 |             )
169 | 
170 |         msg_lines.append(
171 |             f"The {start_text} installed in '{parent_dir}' which is not on PATH."
172 |         )
173 | 
174 |     last_line_fmt = (
175 |         "Consider adding {} to PATH or, if you prefer "
176 |         "to suppress this warning, use --no-warn-script-location."
177 |     )
178 |     if len(msg_lines) == 1:
179 |         msg_lines.append(last_line_fmt.format("this directory"))
180 |     else:
181 |         msg_lines.append(last_line_fmt.format("these directories"))
182 | 
183 |     # Add a note if any directory starts with ~
184 |     warn_for_tilde = any(
185 |         i[0] == "~" for i in os.environ.get("PATH", "").split(os.pathsep) if i
186 |     )
187 |     if warn_for_tilde:
188 |         tilde_warning_msg = (
189 |             "NOTE: The current PATH contains path(s) starting with `~`, "
190 |             "which may not be expanded by all applications."
191 |         )
192 |         msg_lines.append(tilde_warning_msg)
193 | 
194 |     # Returns the formatted multiline message
195 |     return "\n".join(msg_lines)
196 | 
197 | 
198 | def _normalized_outrows(
199 |     outrows: Iterable[InstalledCSVRow],
200 | ) -> List[Tuple[str, str, str]]:
201 |     """Normalize the given rows of a RECORD file.
202 | 
203 |     Items in each row are converted into str. Rows are then sorted to make
204 |     the value more predictable for tests.
205 | 
206 |     Each row is a 3-tuple (path, hash, size) and corresponds to a record of
207 |     a RECORD file (see PEP 376 and PEP 427 for details).  For the rows
208 |     passed to this function, the size can be an integer as an int or string,
209 |     or the empty string.
210 |     """
211 |     # Normally, there should only be one row per path, in which case the
212 |     # second and third elements don't come into play when sorting.
213 |     # However, in cases in the wild where a path might happen to occur twice,
214 |     # we don't want the sort operation to trigger an error (but still want
215 |     # determinism).  Since the third element can be an int or string, we
216 |     # coerce each element to a string to avoid a TypeError in this case.
217 |     # For additional background, see--
218 |     # https://github.com/pypa/pip/issues/5868
219 |     return sorted(
220 |         (record_path, hash_, str(size)) for record_path, hash_, size in outrows
221 |     )
222 | 
223 | 
224 | def _record_to_fs_path(record_path: RecordPath, lib_dir: str) -> str:
225 |     return os.path.join(lib_dir, record_path)
226 | 
227 | 
228 | def _fs_to_record_path(path: str, lib_dir: str) -> RecordPath:
229 |     # On Windows, do not handle relative paths if they belong to different
230 |     # logical disks
231 |     if os.path.splitdrive(path)[0].lower() == os.path.splitdrive(lib_dir)[0].lower():
232 |         path = os.path.relpath(path, lib_dir)
233 | 
234 |     path = path.replace(os.path.sep, "/")
235 |     return cast("RecordPath", path)
236 | 
237 | 
238 | def get_csv_rows_for_installed(
239 |     old_csv_rows: List[List[str]],
240 |     installed: Dict[RecordPath, RecordPath],
241 |     changed: Set[RecordPath],
242 |     generated: List[str],
243 |     lib_dir: str,
244 | ) -> List[InstalledCSVRow]:
245 |     """
246 |     :param installed: A map from archive RECORD path to installation RECORD
247 |         path.
248 |     """
249 |     installed_rows: List[InstalledCSVRow] = []
250 |     for row in old_csv_rows:
251 |         if len(row) > 3:
252 |             logger.warning("RECORD line has more than three elements: %s", row)
253 |         old_record_path = cast("RecordPath", row[0])
254 |         new_record_path = installed.pop(old_record_path, old_record_path)
255 |         if new_record_path in changed:
256 |             digest, length = rehash(_record_to_fs_path(new_record_path, lib_dir))
257 |         else:
258 |             digest = row[1] if len(row) > 1 else ""
259 |             length = row[2] if len(row) > 2 else ""
260 |         installed_rows.append((new_record_path, digest, length))
261 |     for f in generated:
262 |         path = _fs_to_record_path(f, lib_dir)
263 |         digest, length = rehash(f)
264 |         installed_rows.append((path, digest, length))
265 |     return installed_rows + [
266 |         (installed_record_path, "", "") for installed_record_path in installed.values()
267 |     ]
268 | 
269 | 
270 | def get_console_script_specs(console: Dict[str, str]) -> List[str]:
271 |     """
272 |     Given the mapping from entrypoint name to callable, return the relevant
273 |     console script specs.
274 |     """
275 |     # Don't mutate caller's version
276 |     console = console.copy()
277 | 
278 |     scripts_to_generate = []
279 | 
280 |     # Special case pip and setuptools to generate versioned wrappers
281 |     #
282 |     # The issue is that some projects (specifically, pip and setuptools) use
283 |     # code in setup.py to create "versioned" entry points - pip2.7 on Python
284 |     # 2.7, pip3.3 on Python 3.3, etc. But these entry points are baked into
285 |     # the wheel metadata at build time, and so if the wheel is installed with
286 |     # a *different* version of Python the entry points will be wrong. The
287 |     # correct fix for this is to enhance the metadata to be able to describe
288 |     # such versioned entry points.
289 |     # Currently, projects using versioned entry points will either have
290 |     # incorrect versioned entry points, or they will not be able to distribute
291 |     # "universal" wheels (i.e., they will need a wheel per Python version).
292 |     #
293 |     # Because setuptools and pip are bundled with _ensurepip and virtualenv,
294 |     # we need to use universal wheels. As a workaround, we
295 |     # override the versioned entry points in the wheel and generate the
296 |     # correct ones.
297 |     #
298 |     # To add the level of hack in this section of code, in order to support
299 |     # ensurepip this code will look for an ``ENSUREPIP_OPTIONS`` environment
300 |     # variable which will control which version scripts get installed.
301 |     #
302 |     # ENSUREPIP_OPTIONS=altinstall
303 |     #   - Only pipX.Y and easy_install-X.Y will be generated and installed
304 |     # ENSUREPIP_OPTIONS=install
305 |     #   - pipX.Y, pipX, easy_install-X.Y will be generated and installed. Note
306 |     #     that this option is technically if ENSUREPIP_OPTIONS is set and is
307 |     #     not altinstall
308 |     # DEFAULT
309 |     #   - The default behavior is to install pip, pipX, pipX.Y, easy_install
310 |     #     and easy_install-X.Y.
311 |     pip_script = console.pop("pip", None)
312 |     if pip_script:
[TRUNCATED]
```

.venv/lib/python3.13/site-packages/pip/_internal/resolution/resolvelib/__init__.py
```
```

.venv/lib/python3.13/site-packages/pip/_internal/resolution/resolvelib/base.py
```
1 | from dataclasses import dataclass
2 | from typing import FrozenSet, Iterable, Optional, Tuple
3 | 
4 | from pip._vendor.packaging.specifiers import SpecifierSet
5 | from pip._vendor.packaging.utils import NormalizedName
6 | from pip._vendor.packaging.version import Version
7 | 
8 | from pip._internal.models.link import Link, links_equivalent
9 | from pip._internal.req.req_install import InstallRequirement
10 | from pip._internal.utils.hashes import Hashes
11 | 
12 | CandidateLookup = Tuple[Optional["Candidate"], Optional[InstallRequirement]]
13 | 
14 | 
15 | def format_name(project: NormalizedName, extras: FrozenSet[NormalizedName]) -> str:
16 |     if not extras:
17 |         return project
18 |     extras_expr = ",".join(sorted(extras))
19 |     return f"{project}[{extras_expr}]"
20 | 
21 | 
22 | @dataclass(frozen=True)
23 | class Constraint:
24 |     specifier: SpecifierSet
25 |     hashes: Hashes
26 |     links: FrozenSet[Link]
27 | 
28 |     @classmethod
29 |     def empty(cls) -> "Constraint":
30 |         return Constraint(SpecifierSet(), Hashes(), frozenset())
31 | 
32 |     @classmethod
33 |     def from_ireq(cls, ireq: InstallRequirement) -> "Constraint":
34 |         links = frozenset([ireq.link]) if ireq.link else frozenset()
35 |         return Constraint(ireq.specifier, ireq.hashes(trust_internet=False), links)
36 | 
37 |     def __bool__(self) -> bool:
38 |         return bool(self.specifier) or bool(self.hashes) or bool(self.links)
39 | 
40 |     def __and__(self, other: InstallRequirement) -> "Constraint":
41 |         if not isinstance(other, InstallRequirement):
42 |             return NotImplemented
43 |         specifier = self.specifier & other.specifier
44 |         hashes = self.hashes & other.hashes(trust_internet=False)
45 |         links = self.links
46 |         if other.link:
47 |             links = links.union([other.link])
48 |         return Constraint(specifier, hashes, links)
49 | 
50 |     def is_satisfied_by(self, candidate: "Candidate") -> bool:
51 |         # Reject if there are any mismatched URL constraints on this package.
52 |         if self.links and not all(_match_link(link, candidate) for link in self.links):
53 |             return False
54 |         # We can safely always allow prereleases here since PackageFinder
55 |         # already implements the prerelease logic, and would have filtered out
56 |         # prerelease candidates if the user does not expect them.
57 |         return self.specifier.contains(candidate.version, prereleases=True)
58 | 
59 | 
60 | class Requirement:
61 |     @property
62 |     def project_name(self) -> NormalizedName:
63 |         """The "project name" of a requirement.
64 | 
65 |         This is different from ``name`` if this requirement contains extras,
66 |         in which case ``name`` would contain the ``[...]`` part, while this
67 |         refers to the name of the project.
68 |         """
69 |         raise NotImplementedError("Subclass should override")
70 | 
71 |     @property
72 |     def name(self) -> str:
73 |         """The name identifying this requirement in the resolver.
74 | 
75 |         This is different from ``project_name`` if this requirement contains
76 |         extras, where ``project_name`` would not contain the ``[...]`` part.
77 |         """
78 |         raise NotImplementedError("Subclass should override")
79 | 
80 |     def is_satisfied_by(self, candidate: "Candidate") -> bool:
81 |         return False
82 | 
83 |     def get_candidate_lookup(self) -> CandidateLookup:
84 |         raise NotImplementedError("Subclass should override")
85 | 
86 |     def format_for_error(self) -> str:
87 |         raise NotImplementedError("Subclass should override")
88 | 
89 | 
90 | def _match_link(link: Link, candidate: "Candidate") -> bool:
91 |     if candidate.source_link:
92 |         return links_equivalent(link, candidate.source_link)
93 |     return False
94 | 
95 | 
96 | class Candidate:
97 |     @property
98 |     def project_name(self) -> NormalizedName:
99 |         """The "project name" of the candidate.
100 | 
101 |         This is different from ``name`` if this candidate contains extras,
102 |         in which case ``name`` would contain the ``[...]`` part, while this
103 |         refers to the name of the project.
104 |         """
105 |         raise NotImplementedError("Override in subclass")
106 | 
107 |     @property
108 |     def name(self) -> str:
109 |         """The name identifying this candidate in the resolver.
110 | 
111 |         This is different from ``project_name`` if this candidate contains
112 |         extras, where ``project_name`` would not contain the ``[...]`` part.
113 |         """
114 |         raise NotImplementedError("Override in subclass")
115 | 
116 |     @property
117 |     def version(self) -> Version:
118 |         raise NotImplementedError("Override in subclass")
119 | 
120 |     @property
121 |     def is_installed(self) -> bool:
122 |         raise NotImplementedError("Override in subclass")
123 | 
124 |     @property
125 |     def is_editable(self) -> bool:
126 |         raise NotImplementedError("Override in subclass")
127 | 
128 |     @property
129 |     def source_link(self) -> Optional[Link]:
130 |         raise NotImplementedError("Override in subclass")
131 | 
132 |     def iter_dependencies(self, with_requires: bool) -> Iterable[Optional[Requirement]]:
133 |         raise NotImplementedError("Override in subclass")
134 | 
135 |     def get_install_requirement(self) -> Optional[InstallRequirement]:
136 |         raise NotImplementedError("Override in subclass")
137 | 
138 |     def format_for_error(self) -> str:
139 |         raise NotImplementedError("Subclass should override")
```

.venv/lib/python3.13/site-packages/pip/_internal/resolution/resolvelib/candidates.py
```
1 | import logging
2 | import sys
3 | from typing import TYPE_CHECKING, Any, FrozenSet, Iterable, Optional, Tuple, Union, cast
4 | 
5 | from pip._vendor.packaging.requirements import InvalidRequirement
6 | from pip._vendor.packaging.utils import NormalizedName, canonicalize_name
7 | from pip._vendor.packaging.version import Version
8 | 
9 | from pip._internal.exceptions import (
10 |     HashError,
11 |     InstallationSubprocessError,
12 |     InvalidInstalledPackage,
13 |     MetadataInconsistent,
14 |     MetadataInvalid,
15 | )
16 | from pip._internal.metadata import BaseDistribution
17 | from pip._internal.models.link import Link, links_equivalent
18 | from pip._internal.models.wheel import Wheel
19 | from pip._internal.req.constructors import (
20 |     install_req_from_editable,
21 |     install_req_from_line,
22 | )
23 | from pip._internal.req.req_install import InstallRequirement
24 | from pip._internal.utils.direct_url_helpers import direct_url_from_link
25 | from pip._internal.utils.misc import normalize_version_info
26 | 
27 | from .base import Candidate, Requirement, format_name
28 | 
29 | if TYPE_CHECKING:
30 |     from .factory import Factory
31 | 
32 | logger = logging.getLogger(__name__)
33 | 
34 | BaseCandidate = Union[
35 |     "AlreadyInstalledCandidate",
36 |     "EditableCandidate",
37 |     "LinkCandidate",
38 | ]
39 | 
40 | # Avoid conflicting with the PyPI package "Python".
41 | REQUIRES_PYTHON_IDENTIFIER = cast(NormalizedName, "<Python from Requires-Python>")
42 | 
43 | 
44 | def as_base_candidate(candidate: Candidate) -> Optional[BaseCandidate]:
45 |     """The runtime version of BaseCandidate."""
46 |     base_candidate_classes = (
47 |         AlreadyInstalledCandidate,
48 |         EditableCandidate,
49 |         LinkCandidate,
50 |     )
51 |     if isinstance(candidate, base_candidate_classes):
52 |         return candidate
53 |     return None
54 | 
55 | 
56 | def make_install_req_from_link(
57 |     link: Link, template: InstallRequirement
58 | ) -> InstallRequirement:
59 |     assert not template.editable, "template is editable"
60 |     if template.req:
61 |         line = str(template.req)
62 |     else:
63 |         line = link.url
64 |     ireq = install_req_from_line(
65 |         line,
66 |         user_supplied=template.user_supplied,
67 |         comes_from=template.comes_from,
68 |         use_pep517=template.use_pep517,
69 |         isolated=template.isolated,
70 |         constraint=template.constraint,
71 |         global_options=template.global_options,
72 |         hash_options=template.hash_options,
73 |         config_settings=template.config_settings,
74 |     )
75 |     ireq.original_link = template.original_link
76 |     ireq.link = link
77 |     ireq.extras = template.extras
78 |     return ireq
79 | 
80 | 
81 | def make_install_req_from_editable(
82 |     link: Link, template: InstallRequirement
83 | ) -> InstallRequirement:
84 |     assert template.editable, "template not editable"
85 |     ireq = install_req_from_editable(
86 |         link.url,
87 |         user_supplied=template.user_supplied,
88 |         comes_from=template.comes_from,
89 |         use_pep517=template.use_pep517,
90 |         isolated=template.isolated,
91 |         constraint=template.constraint,
92 |         permit_editable_wheels=template.permit_editable_wheels,
93 |         global_options=template.global_options,
94 |         hash_options=template.hash_options,
95 |         config_settings=template.config_settings,
96 |     )
97 |     ireq.extras = template.extras
98 |     return ireq
99 | 
100 | 
101 | def _make_install_req_from_dist(
102 |     dist: BaseDistribution, template: InstallRequirement
103 | ) -> InstallRequirement:
104 |     if template.req:
105 |         line = str(template.req)
106 |     elif template.link:
107 |         line = f"{dist.canonical_name} @ {template.link.url}"
108 |     else:
109 |         line = f"{dist.canonical_name}=={dist.version}"
110 |     ireq = install_req_from_line(
111 |         line,
112 |         user_supplied=template.user_supplied,
113 |         comes_from=template.comes_from,
114 |         use_pep517=template.use_pep517,
115 |         isolated=template.isolated,
116 |         constraint=template.constraint,
117 |         global_options=template.global_options,
118 |         hash_options=template.hash_options,
119 |         config_settings=template.config_settings,
120 |     )
121 |     ireq.satisfied_by = dist
122 |     return ireq
123 | 
124 | 
125 | class _InstallRequirementBackedCandidate(Candidate):
126 |     """A candidate backed by an ``InstallRequirement``.
127 | 
128 |     This represents a package request with the target not being already
129 |     in the environment, and needs to be fetched and installed. The backing
130 |     ``InstallRequirement`` is responsible for most of the leg work; this
131 |     class exposes appropriate information to the resolver.
132 | 
133 |     :param link: The link passed to the ``InstallRequirement``. The backing
134 |         ``InstallRequirement`` will use this link to fetch the distribution.
135 |     :param source_link: The link this candidate "originates" from. This is
136 |         different from ``link`` when the link is found in the wheel cache.
137 |         ``link`` would point to the wheel cache, while this points to the
138 |         found remote link (e.g. from pypi.org).
139 |     """
140 | 
141 |     dist: BaseDistribution
142 |     is_installed = False
143 | 
144 |     def __init__(
145 |         self,
146 |         link: Link,
147 |         source_link: Link,
148 |         ireq: InstallRequirement,
149 |         factory: "Factory",
150 |         name: Optional[NormalizedName] = None,
151 |         version: Optional[Version] = None,
152 |     ) -> None:
153 |         self._link = link
154 |         self._source_link = source_link
155 |         self._factory = factory
156 |         self._ireq = ireq
157 |         self._name = name
158 |         self._version = version
159 |         self.dist = self._prepare()
160 |         self._hash: Optional[int] = None
161 | 
162 |     def __str__(self) -> str:
163 |         return f"{self.name} {self.version}"
164 | 
165 |     def __repr__(self) -> str:
166 |         return f"{self.__class__.__name__}({str(self._link)!r})"
167 | 
168 |     def __hash__(self) -> int:
169 |         if self._hash is not None:
170 |             return self._hash
171 | 
172 |         self._hash = hash((self.__class__, self._link))
173 |         return self._hash
174 | 
175 |     def __eq__(self, other: Any) -> bool:
176 |         if isinstance(other, self.__class__):
177 |             return links_equivalent(self._link, other._link)
178 |         return False
179 | 
180 |     @property
181 |     def source_link(self) -> Optional[Link]:
182 |         return self._source_link
183 | 
184 |     @property
185 |     def project_name(self) -> NormalizedName:
186 |         """The normalised name of the project the candidate refers to"""
187 |         if self._name is None:
188 |             self._name = self.dist.canonical_name
189 |         return self._name
190 | 
191 |     @property
192 |     def name(self) -> str:
193 |         return self.project_name
194 | 
195 |     @property
196 |     def version(self) -> Version:
197 |         if self._version is None:
198 |             self._version = self.dist.version
199 |         return self._version
200 | 
201 |     def format_for_error(self) -> str:
202 |         return (
203 |             f"{self.name} {self.version} "
204 |             f"(from {self._link.file_path if self._link.is_file else self._link})"
205 |         )
206 | 
207 |     def _prepare_distribution(self) -> BaseDistribution:
208 |         raise NotImplementedError("Override in subclass")
209 | 
210 |     def _check_metadata_consistency(self, dist: BaseDistribution) -> None:
211 |         """Check for consistency of project name and version of dist."""
212 |         if self._name is not None and self._name != dist.canonical_name:
213 |             raise MetadataInconsistent(
214 |                 self._ireq,
215 |                 "name",
216 |                 self._name,
217 |                 dist.canonical_name,
218 |             )
219 |         if self._version is not None and self._version != dist.version:
220 |             raise MetadataInconsistent(
221 |                 self._ireq,
222 |                 "version",
223 |                 str(self._version),
224 |                 str(dist.version),
225 |             )
226 |         # check dependencies are valid
227 |         # TODO performance: this means we iterate the dependencies at least twice,
228 |         # we may want to cache parsed Requires-Dist
229 |         try:
230 |             list(dist.iter_dependencies(list(dist.iter_provided_extras())))
231 |         except InvalidRequirement as e:
232 |             raise MetadataInvalid(self._ireq, str(e))
233 | 
234 |     def _prepare(self) -> BaseDistribution:
235 |         try:
236 |             dist = self._prepare_distribution()
237 |         except HashError as e:
238 |             # Provide HashError the underlying ireq that caused it. This
239 |             # provides context for the resulting error message to show the
240 |             # offending line to the user.
241 |             e.req = self._ireq
242 |             raise
243 |         except InstallationSubprocessError as exc:
244 |             # The output has been presented already, so don't duplicate it.
245 |             exc.context = "See above for output."
246 |             raise
247 | 
248 |         self._check_metadata_consistency(dist)
249 |         return dist
250 | 
251 |     def iter_dependencies(self, with_requires: bool) -> Iterable[Optional[Requirement]]:
252 |         # Emit the Requires-Python requirement first to fail fast on
253 |         # unsupported candidates and avoid pointless downloads/preparation.
254 |         yield self._factory.make_requires_python_requirement(self.dist.requires_python)
255 |         requires = self.dist.iter_dependencies() if with_requires else ()
256 |         for r in requires:
257 |             yield from self._factory.make_requirements_from_spec(str(r), self._ireq)
258 | 
259 |     def get_install_requirement(self) -> Optional[InstallRequirement]:
260 |         return self._ireq
261 | 
262 | 
263 | class LinkCandidate(_InstallRequirementBackedCandidate):
264 |     is_editable = False
265 | 
266 |     def __init__(
267 |         self,
268 |         link: Link,
269 |         template: InstallRequirement,
270 |         factory: "Factory",
271 |         name: Optional[NormalizedName] = None,
272 |         version: Optional[Version] = None,
273 |     ) -> None:
274 |         source_link = link
275 |         cache_entry = factory.get_wheel_cache_entry(source_link, name)
276 |         if cache_entry is not None:
277 |             logger.debug("Using cached wheel link: %s", cache_entry.link)
278 |             link = cache_entry.link
279 |         ireq = make_install_req_from_link(link, template)
280 |         assert ireq.link == link
281 |         if ireq.link.is_wheel and not ireq.link.is_file:
282 |             wheel = Wheel(ireq.link.filename)
283 |             wheel_name = canonicalize_name(wheel.name)
284 |             assert name == wheel_name, f"{name!r} != {wheel_name!r} for wheel"
285 |             # Version may not be present for PEP 508 direct URLs
286 |             if version is not None:
287 |                 wheel_version = Version(wheel.version)
288 |                 assert (
289 |                     version == wheel_version
290 |                 ), f"{version!r} != {wheel_version!r} for wheel {name}"
291 | 
292 |         if cache_entry is not None:
293 |             assert ireq.link.is_wheel
294 |             assert ireq.link.is_file
295 |             if cache_entry.persistent and template.link is template.original_link:
296 |                 ireq.cached_wheel_source_link = source_link
297 |             if cache_entry.origin is not None:
298 |                 ireq.download_info = cache_entry.origin
299 |             else:
300 |                 # Legacy cache entry that does not have origin.json.
301 |                 # download_info may miss the archive_info.hashes field.
302 |                 ireq.download_info = direct_url_from_link(
303 |                     source_link, link_is_in_wheel_cache=cache_entry.persistent
304 |                 )
305 | 
306 |         super().__init__(
307 |             link=link,
308 |             source_link=source_link,
309 |             ireq=ireq,
310 |             factory=factory,
311 |             name=name,
312 |             version=version,
313 |         )
314 | 
315 |     def _prepare_distribution(self) -> BaseDistribution:
316 |         preparer = self._factory.preparer
317 |         return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True)
318 | 
319 | 
320 | class EditableCandidate(_InstallRequirementBackedCandidate):
321 |     is_editable = True
322 | 
323 |     def __init__(
324 |         self,
325 |         link: Link,
326 |         template: InstallRequirement,
327 |         factory: "Factory",
328 |         name: Optional[NormalizedName] = None,
329 |         version: Optional[Version] = None,
330 |     ) -> None:
331 |         super().__init__(
332 |             link=link,
333 |             source_link=link,
334 |             ireq=make_install_req_from_editable(link, template),
335 |             factory=factory,
336 |             name=name,
337 |             version=version,
338 |         )
339 | 
340 |     def _prepare_distribution(self) -> BaseDistribution:
341 |         return self._factory.preparer.prepare_editable_requirement(self._ireq)
342 | 
343 | 
344 | class AlreadyInstalledCandidate(Candidate):
345 |     is_installed = True
346 |     source_link = None
347 | 
348 |     def __init__(
349 |         self,
350 |         dist: BaseDistribution,
351 |         template: InstallRequirement,
352 |         factory: "Factory",
353 |     ) -> None:
354 |         self.dist = dist
355 |         self._ireq = _make_install_req_from_dist(dist, template)
356 |         self._factory = factory
357 |         self._version = None
358 | 
359 |         # This is just logging some messages, so we can do it eagerly.
360 |         # The returned dist would be exactly the same as self.dist because we
361 |         # set satisfied_by in _make_install_req_from_dist.
362 |         # TODO: Supply reason based on force_reinstall and upgrade_strategy.
363 |         skip_reason = "already satisfied"
364 |         factory.preparer.prepare_installed_requirement(self._ireq, skip_reason)
365 | 
366 |     def __str__(self) -> str:
367 |         return str(self.dist)
368 | 
369 |     def __repr__(self) -> str:
370 |         return f"{self.__class__.__name__}({self.dist!r})"
371 | 
372 |     def __eq__(self, other: object) -> bool:
[TRUNCATED]
```

.venv/lib/python3.13/site-packages/pip/_internal/resolution/resolvelib/factory.py
```
1 | import contextlib
2 | import functools
3 | import logging
4 | from typing import (
5 |     TYPE_CHECKING,
6 |     Callable,
7 |     Dict,
8 |     FrozenSet,
9 |     Iterable,
10 |     Iterator,
11 |     List,
12 |     Mapping,
13 |     NamedTuple,
14 |     Optional,
15 |     Protocol,
16 |     Sequence,
17 |     Set,
18 |     Tuple,
19 |     TypeVar,
20 |     cast,
21 | )
22 | 
23 | from pip._vendor.packaging.requirements import InvalidRequirement
24 | from pip._vendor.packaging.specifiers import SpecifierSet
25 | from pip._vendor.packaging.utils import NormalizedName, canonicalize_name
26 | from pip._vendor.packaging.version import InvalidVersion, Version
27 | from pip._vendor.resolvelib import ResolutionImpossible
28 | 
29 | from pip._internal.cache import CacheEntry, WheelCache
30 | from pip._internal.exceptions import (
31 |     DistributionNotFound,
32 |     InstallationError,
33 |     InvalidInstalledPackage,
34 |     MetadataInconsistent,
35 |     MetadataInvalid,
36 |     UnsupportedPythonVersion,
37 |     UnsupportedWheel,
38 | )
39 | from pip._internal.index.package_finder import PackageFinder
40 | from pip._internal.metadata import BaseDistribution, get_default_environment
41 | from pip._internal.models.link import Link
42 | from pip._internal.models.wheel import Wheel
43 | from pip._internal.operations.prepare import RequirementPreparer
44 | from pip._internal.req.constructors import (
45 |     install_req_drop_extras,
46 |     install_req_from_link_and_ireq,
47 | )
48 | from pip._internal.req.req_install import (
49 |     InstallRequirement,
50 |     check_invalid_constraint_type,
51 | )
52 | from pip._internal.resolution.base import InstallRequirementProvider
53 | from pip._internal.utils.compatibility_tags import get_supported
54 | from pip._internal.utils.hashes import Hashes
55 | from pip._internal.utils.packaging import get_requirement
56 | from pip._internal.utils.virtualenv import running_under_virtualenv
57 | 
58 | from .base import Candidate, Constraint, Requirement
59 | from .candidates import (
60 |     AlreadyInstalledCandidate,
61 |     BaseCandidate,
62 |     EditableCandidate,
63 |     ExtrasCandidate,
64 |     LinkCandidate,
65 |     RequiresPythonCandidate,
66 |     as_base_candidate,
67 | )
68 | from .found_candidates import FoundCandidates, IndexCandidateInfo
69 | from .requirements import (
70 |     ExplicitRequirement,
71 |     RequiresPythonRequirement,
72 |     SpecifierRequirement,
73 |     SpecifierWithoutExtrasRequirement,
74 |     UnsatisfiableRequirement,
75 | )
76 | 
77 | if TYPE_CHECKING:
78 | 
79 |     class ConflictCause(Protocol):
80 |         requirement: RequiresPythonRequirement
81 |         parent: Candidate
82 | 
83 | 
84 | logger = logging.getLogger(__name__)
85 | 
86 | C = TypeVar("C")
87 | Cache = Dict[Link, C]
88 | 
89 | 
90 | class CollectedRootRequirements(NamedTuple):
91 |     requirements: List[Requirement]
92 |     constraints: Dict[str, Constraint]
93 |     user_requested: Dict[str, int]
94 | 
95 | 
96 | class Factory:
97 |     def __init__(
98 |         self,
99 |         finder: PackageFinder,
100 |         preparer: RequirementPreparer,
101 |         make_install_req: InstallRequirementProvider,
102 |         wheel_cache: Optional[WheelCache],
103 |         use_user_site: bool,
104 |         force_reinstall: bool,
105 |         ignore_installed: bool,
106 |         ignore_requires_python: bool,
107 |         py_version_info: Optional[Tuple[int, ...]] = None,
108 |     ) -> None:
109 |         self._finder = finder
110 |         self.preparer = preparer
111 |         self._wheel_cache = wheel_cache
112 |         self._python_candidate = RequiresPythonCandidate(py_version_info)
113 |         self._make_install_req_from_spec = make_install_req
114 |         self._use_user_site = use_user_site
115 |         self._force_reinstall = force_reinstall
116 |         self._ignore_requires_python = ignore_requires_python
117 | 
118 |         self._build_failures: Cache[InstallationError] = {}
119 |         self._link_candidate_cache: Cache[LinkCandidate] = {}
120 |         self._editable_candidate_cache: Cache[EditableCandidate] = {}
121 |         self._installed_candidate_cache: Dict[str, AlreadyInstalledCandidate] = {}
122 |         self._extras_candidate_cache: Dict[
123 |             Tuple[int, FrozenSet[NormalizedName]], ExtrasCandidate
124 |         ] = {}
125 |         self._supported_tags_cache = get_supported()
126 | 
127 |         if not ignore_installed:
128 |             env = get_default_environment()
129 |             self._installed_dists = {
130 |                 dist.canonical_name: dist
131 |                 for dist in env.iter_installed_distributions(local_only=False)
132 |             }
133 |         else:
134 |             self._installed_dists = {}
135 | 
136 |     @property
137 |     def force_reinstall(self) -> bool:
138 |         return self._force_reinstall
139 | 
140 |     def _fail_if_link_is_unsupported_wheel(self, link: Link) -> None:
141 |         if not link.is_wheel:
142 |             return
143 |         wheel = Wheel(link.filename)
144 |         if wheel.supported(self._finder.target_python.get_unsorted_tags()):
145 |             return
146 |         msg = f"{link.filename} is not a supported wheel on this platform."
147 |         raise UnsupportedWheel(msg)
148 | 
149 |     def _make_extras_candidate(
150 |         self,
151 |         base: BaseCandidate,
152 |         extras: FrozenSet[str],
153 |         *,
154 |         comes_from: Optional[InstallRequirement] = None,
155 |     ) -> ExtrasCandidate:
156 |         cache_key = (id(base), frozenset(canonicalize_name(e) for e in extras))
157 |         try:
158 |             candidate = self._extras_candidate_cache[cache_key]
159 |         except KeyError:
160 |             candidate = ExtrasCandidate(base, extras, comes_from=comes_from)
161 |             self._extras_candidate_cache[cache_key] = candidate
162 |         return candidate
163 | 
164 |     def _make_candidate_from_dist(
165 |         self,
166 |         dist: BaseDistribution,
167 |         extras: FrozenSet[str],
168 |         template: InstallRequirement,
169 |     ) -> Candidate:
170 |         try:
171 |             base = self._installed_candidate_cache[dist.canonical_name]
172 |         except KeyError:
173 |             base = AlreadyInstalledCandidate(dist, template, factory=self)
174 |             self._installed_candidate_cache[dist.canonical_name] = base
175 |         if not extras:
176 |             return base
177 |         return self._make_extras_candidate(base, extras, comes_from=template)
178 | 
179 |     def _make_candidate_from_link(
180 |         self,
181 |         link: Link,
182 |         extras: FrozenSet[str],
183 |         template: InstallRequirement,
184 |         name: Optional[NormalizedName],
185 |         version: Optional[Version],
186 |     ) -> Optional[Candidate]:
187 |         base: Optional[BaseCandidate] = self._make_base_candidate_from_link(
188 |             link, template, name, version
189 |         )
190 |         if not extras or base is None:
191 |             return base
192 |         return self._make_extras_candidate(base, extras, comes_from=template)
193 | 
194 |     def _make_base_candidate_from_link(
195 |         self,
196 |         link: Link,
197 |         template: InstallRequirement,
198 |         name: Optional[NormalizedName],
199 |         version: Optional[Version],
200 |     ) -> Optional[BaseCandidate]:
201 |         # TODO: Check already installed candidate, and use it if the link and
202 |         # editable flag match.
203 | 
204 |         if link in self._build_failures:
205 |             # We already tried this candidate before, and it does not build.
206 |             # Don't bother trying again.
207 |             return None
208 | 
209 |         if template.editable:
210 |             if link not in self._editable_candidate_cache:
211 |                 try:
212 |                     self._editable_candidate_cache[link] = EditableCandidate(
213 |                         link,
214 |                         template,
215 |                         factory=self,
216 |                         name=name,
217 |                         version=version,
218 |                     )
219 |                 except (MetadataInconsistent, MetadataInvalid) as e:
220 |                     logger.info(
221 |                         "Discarding [blue underline]%s[/]: [yellow]%s[reset]",
222 |                         link,
223 |                         e,
224 |                         extra={"markup": True},
225 |                     )
226 |                     self._build_failures[link] = e
227 |                     return None
228 | 
229 |             return self._editable_candidate_cache[link]
230 |         else:
231 |             if link not in self._link_candidate_cache:
232 |                 try:
233 |                     self._link_candidate_cache[link] = LinkCandidate(
234 |                         link,
235 |                         template,
236 |                         factory=self,
237 |                         name=name,
238 |                         version=version,
239 |                     )
240 |                 except MetadataInconsistent as e:
241 |                     logger.info(
242 |                         "Discarding [blue underline]%s[/]: [yellow]%s[reset]",
243 |                         link,
244 |                         e,
245 |                         extra={"markup": True},
246 |                     )
247 |                     self._build_failures[link] = e
248 |                     return None
249 |             return self._link_candidate_cache[link]
250 | 
251 |     def _iter_found_candidates(
252 |         self,
253 |         ireqs: Sequence[InstallRequirement],
254 |         specifier: SpecifierSet,
255 |         hashes: Hashes,
256 |         prefers_installed: bool,
257 |         incompatible_ids: Set[int],
258 |     ) -> Iterable[Candidate]:
259 |         if not ireqs:
260 |             return ()
261 | 
262 |         # The InstallRequirement implementation requires us to give it a
263 |         # "template". Here we just choose the first requirement to represent
264 |         # all of them.
265 |         # Hopefully the Project model can correct this mismatch in the future.
266 |         template = ireqs[0]
267 |         assert template.req, "Candidates found on index must be PEP 508"
268 |         name = canonicalize_name(template.req.name)
269 | 
270 |         extras: FrozenSet[str] = frozenset()
271 |         for ireq in ireqs:
272 |             assert ireq.req, "Candidates found on index must be PEP 508"
273 |             specifier &= ireq.req.specifier
274 |             hashes &= ireq.hashes(trust_internet=False)
275 |             extras |= frozenset(ireq.extras)
276 | 
277 |         def _get_installed_candidate() -> Optional[Candidate]:
278 |             """Get the candidate for the currently-installed version."""
279 |             # If --force-reinstall is set, we want the version from the index
280 |             # instead, so we "pretend" there is nothing installed.
281 |             if self._force_reinstall:
282 |                 return None
283 |             try:
284 |                 installed_dist = self._installed_dists[name]
285 |             except KeyError:
286 |                 return None
287 | 
288 |             try:
289 |                 # Don't use the installed distribution if its version
290 |                 # does not fit the current dependency graph.
291 |                 if not specifier.contains(installed_dist.version, prereleases=True):
292 |                     return None
293 |             except InvalidVersion as e:
294 |                 raise InvalidInstalledPackage(dist=installed_dist, invalid_exc=e)
295 | 
296 |             candidate = self._make_candidate_from_dist(
297 |                 dist=installed_dist,
298 |                 extras=extras,
299 |                 template=template,
300 |             )
301 |             # The candidate is a known incompatibility. Don't use it.
302 |             if id(candidate) in incompatible_ids:
303 |                 return None
304 |             return candidate
305 | 
306 |         def iter_index_candidate_infos() -> Iterator[IndexCandidateInfo]:
307 |             result = self._finder.find_best_candidate(
308 |                 project_name=name,
309 |                 specifier=specifier,
310 |                 hashes=hashes,
311 |             )
312 |             icans = result.applicable_candidates
313 | 
314 |             # PEP 592: Yanked releases are ignored unless the specifier
315 |             # explicitly pins a version (via '==' or '===') that can be
316 |             # solely satisfied by a yanked release.
317 |             all_yanked = all(ican.link.is_yanked for ican in icans)
318 | 
319 |             def is_pinned(specifier: SpecifierSet) -> bool:
320 |                 for sp in specifier:
321 |                     if sp.operator == "===":
322 |                         return True
323 |                     if sp.operator != "==":
324 |                         continue
325 |                     if sp.version.endswith(".*"):
326 |                         continue
327 |                     return True
328 |                 return False
329 | 
330 |             pinned = is_pinned(specifier)
331 | 
332 |             # PackageFinder returns earlier versions first, so we reverse.
333 |             for ican in reversed(icans):
334 |                 if not (all_yanked and pinned) and ican.link.is_yanked:
335 |                     continue
336 |                 func = functools.partial(
337 |                     self._make_candidate_from_link,
338 |                     link=ican.link,
339 |                     extras=extras,
340 |                     template=template,
341 |                     name=name,
342 |                     version=ican.version,
343 |                 )
344 |                 yield ican.version, func
345 | 
346 |         return FoundCandidates(
347 |             iter_index_candidate_infos,
348 |             _get_installed_candidate(),
349 |             prefers_installed,
350 |             incompatible_ids,
351 |         )
352 | 
353 |     def _iter_explicit_candidates_from_base(
354 |         self,
355 |         base_requirements: Iterable[Requirement],
356 |         extras: FrozenSet[str],
357 |     ) -> Iterator[Candidate]:
358 |         """Produce explicit candidates from the base given an extra-ed package.
359 | 
360 |         :param base_requirements: Requirements known to the resolver. The
361 |             requirements are guaranteed to not have extras.
362 |         :param extras: The extras to inject into the explicit requirements'
363 |             candidates.
364 |         """
365 |         for req in base_requirements:
366 |             lookup_cand, _ = req.get_candidate_lookup()
367 |             if lookup_cand is None:  # Not explicit.
368 |                 continue
369 |             # We've stripped extras from the identifier, and should always
370 |             # get a BaseCandidate here, unless there's a bug elsewhere.
371 |             base_cand = as_base_candidate(lookup_cand)
372 |             assert base_cand is not None, "no extras here"
373 |             yield self._make_extras_candidate(base_cand, extras)
374 | 
375 |     def _iter_candidates_from_constraints(
376 |         self,
377 |         identifier: str,
378 |         constraint: Constraint,
379 |         template: InstallRequirement,
380 |     ) -> Iterator[Candidate]:
381 |         """Produce explicit candidates from constraints.
382 | 
383 |         This creates "fake" InstallRequirement objects that are basically clones
384 |         of what "should" be the template, but with original_link set to link.
385 |         """
386 |         for link in constraint.links:
387 |             self._fail_if_link_is_unsupported_wheel(link)
388 |             candidate = self._make_base_candidate_from_link(
389 |                 link,
390 |                 template=install_req_from_link_and_ireq(link, template),
391 |                 name=canonicalize_name(identifier),
392 |                 version=None,
393 |             )
394 |             if candidate:
395 |                 yield candidate
396 | 
397 |     def find_candidates(
398 |         self,
399 |         identifier: str,
400 |         requirements: Mapping[str, Iterable[Requirement]],
[TRUNCATED]
```

.venv/lib/python3.13/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py
```
1 | """Utilities to lazily create and visit candidates found.
2 | 
3 | Creating and visiting a candidate is a *very* costly operation. It involves
4 | fetching, extracting, potentially building modules from source, and verifying
5 | distribution metadata. It is therefore crucial for performance to keep
6 | everything here lazy all the way down, so we only touch candidates that we
7 | absolutely need, and not "download the world" when we only need one version of
8 | something.
9 | """
10 | 
11 | import logging
12 | from collections.abc import Sequence
13 | from typing import Any, Callable, Iterator, Optional, Set, Tuple
14 | 
15 | from pip._vendor.packaging.version import _BaseVersion
16 | 
17 | from pip._internal.exceptions import MetadataInvalid
18 | 
19 | from .base import Candidate
20 | 
21 | logger = logging.getLogger(__name__)
22 | 
23 | IndexCandidateInfo = Tuple[_BaseVersion, Callable[[], Optional[Candidate]]]
24 | 
25 | 
26 | def _iter_built(infos: Iterator[IndexCandidateInfo]) -> Iterator[Candidate]:
27 |     """Iterator for ``FoundCandidates``.
28 | 
29 |     This iterator is used when the package is not already installed. Candidates
30 |     from index come later in their normal ordering.
31 |     """
32 |     versions_found: Set[_BaseVersion] = set()
33 |     for version, func in infos:
34 |         if version in versions_found:
35 |             continue
36 |         try:
37 |             candidate = func()
38 |         except MetadataInvalid as e:
39 |             logger.warning(
40 |                 "Ignoring version %s of %s since it has invalid metadata:\n"
41 |                 "%s\n"
42 |                 "Please use pip<24.1 if you need to use this version.",
43 |                 version,
44 |                 e.ireq.name,
45 |                 e,
46 |             )
47 |             # Mark version as found to avoid trying other candidates with the same
48 |             # version, since they most likely have invalid metadata as well.
49 |             versions_found.add(version)
50 |         else:
51 |             if candidate is None:
52 |                 continue
53 |             yield candidate
54 |             versions_found.add(version)
55 | 
56 | 
57 | def _iter_built_with_prepended(
58 |     installed: Candidate, infos: Iterator[IndexCandidateInfo]
59 | ) -> Iterator[Candidate]:
60 |     """Iterator for ``FoundCandidates``.
61 | 
62 |     This iterator is used when the resolver prefers the already-installed
63 |     candidate and NOT to upgrade. The installed candidate is therefore
64 |     always yielded first, and candidates from index come later in their
65 |     normal ordering, except skipped when the version is already installed.
66 |     """
67 |     yield installed
68 |     versions_found: Set[_BaseVersion] = {installed.version}
69 |     for version, func in infos:
70 |         if version in versions_found:
71 |             continue
72 |         candidate = func()
73 |         if candidate is None:
74 |             continue
75 |         yield candidate
76 |         versions_found.add(version)
77 | 
78 | 
79 | def _iter_built_with_inserted(
80 |     installed: Candidate, infos: Iterator[IndexCandidateInfo]
81 | ) -> Iterator[Candidate]:
82 |     """Iterator for ``FoundCandidates``.
83 | 
84 |     This iterator is used when the resolver prefers to upgrade an
85 |     already-installed package. Candidates from index are returned in their
86 |     normal ordering, except replaced when the version is already installed.
87 | 
88 |     The implementation iterates through and yields other candidates, inserting
89 |     the installed candidate exactly once before we start yielding older or
90 |     equivalent candidates, or after all other candidates if they are all newer.
91 |     """
92 |     versions_found: Set[_BaseVersion] = set()
93 |     for version, func in infos:
94 |         if version in versions_found:
95 |             continue
96 |         # If the installed candidate is better, yield it first.
97 |         if installed.version >= version:
98 |             yield installed
99 |             versions_found.add(installed.version)
100 |         candidate = func()
101 |         if candidate is None:
102 |             continue
103 |         yield candidate
104 |         versions_found.add(version)
105 | 
106 |     # If the installed candidate is older than all other candidates.
107 |     if installed.version not in versions_found:
108 |         yield installed
109 | 
110 | 
111 | class FoundCandidates(Sequence[Candidate]):
112 |     """A lazy sequence to provide candidates to the resolver.
113 | 
114 |     The intended usage is to return this from `find_matches()` so the resolver
115 |     can iterate through the sequence multiple times, but only access the index
116 |     page when remote packages are actually needed. This improve performances
117 |     when suitable candidates are already installed on disk.
118 |     """
119 | 
120 |     def __init__(
121 |         self,
122 |         get_infos: Callable[[], Iterator[IndexCandidateInfo]],
123 |         installed: Optional[Candidate],
124 |         prefers_installed: bool,
125 |         incompatible_ids: Set[int],
126 |     ):
127 |         self._get_infos = get_infos
128 |         self._installed = installed
129 |         self._prefers_installed = prefers_installed
130 |         self._incompatible_ids = incompatible_ids
131 |         self._bool: Optional[bool] = None
132 | 
133 |     def __getitem__(self, index: Any) -> Any:
134 |         # Implemented to satisfy the ABC check. This is not needed by the
135 |         # resolver, and should not be used by the provider either (for
136 |         # performance reasons).
137 |         raise NotImplementedError("don't do this")
138 | 
139 |     def __iter__(self) -> Iterator[Candidate]:
140 |         infos = self._get_infos()
141 |         if not self._installed:
142 |             iterator = _iter_built(infos)
143 |         elif self._prefers_installed:
144 |             iterator = _iter_built_with_prepended(self._installed, infos)
145 |         else:
146 |             iterator = _iter_built_with_inserted(self._installed, infos)
147 |         return (c for c in iterator if id(c) not in self._incompatible_ids)
148 | 
149 |     def __len__(self) -> int:
150 |         # Implemented to satisfy the ABC check. This is not needed by the
151 |         # resolver, and should not be used by the provider either (for
152 |         # performance reasons).
153 |         raise NotImplementedError("don't do this")
154 | 
155 |     def __bool__(self) -> bool:
156 |         if self._bool is not None:
157 |             return self._bool
158 | 
159 |         if self._prefers_installed and self._installed:
160 |             self._bool = True
161 |             return True
162 | 
163 |         self._bool = any(self)
164 |         return self._bool
```

.venv/lib/python3.13/site-packages/pip/_internal/resolution/resolvelib/provider.py
```
1 | import math
2 | from functools import lru_cache
3 | from typing import (
4 |     TYPE_CHECKING,
5 |     Dict,
6 |     Iterable,
7 |     Iterator,
8 |     Mapping,
9 |     Optional,
10 |     Sequence,
11 |     Tuple,
12 |     TypeVar,
13 |     Union,
14 | )
15 | 
16 | from pip._vendor.resolvelib.providers import AbstractProvider
17 | 
18 | from pip._internal.req.req_install import InstallRequirement
19 | 
20 | from .base import Candidate, Constraint, Requirement
21 | from .candidates import REQUIRES_PYTHON_IDENTIFIER
22 | from .factory import Factory
23 | from .requirements import ExplicitRequirement
24 | 
25 | if TYPE_CHECKING:
26 |     from pip._vendor.resolvelib.providers import Preference
27 |     from pip._vendor.resolvelib.resolvers import RequirementInformation
28 | 
29 |     PreferenceInformation = RequirementInformation[Requirement, Candidate]
30 | 
31 |     _ProviderBase = AbstractProvider[Requirement, Candidate, str]
32 | else:
33 |     _ProviderBase = AbstractProvider
34 | 
35 | # Notes on the relationship between the provider, the factory, and the
36 | # candidate and requirement classes.
37 | #
38 | # The provider is a direct implementation of the resolvelib class. Its role
39 | # is to deliver the API that resolvelib expects.
40 | #
41 | # Rather than work with completely abstract "requirement" and "candidate"
42 | # concepts as resolvelib does, pip has concrete classes implementing these two
43 | # ideas. The API of Requirement and Candidate objects are defined in the base
44 | # classes, but essentially map fairly directly to the equivalent provider
45 | # methods. In particular, `find_matches` and `is_satisfied_by` are
46 | # requirement methods, and `get_dependencies` is a candidate method.
47 | #
48 | # The factory is the interface to pip's internal mechanisms. It is stateless,
49 | # and is created by the resolver and held as a property of the provider. It is
50 | # responsible for creating Requirement and Candidate objects, and provides
51 | # services to those objects (access to pip's finder and preparer).
52 | 
53 | 
54 | D = TypeVar("D")
55 | V = TypeVar("V")
56 | 
57 | 
58 | def _get_with_identifier(
59 |     mapping: Mapping[str, V],
60 |     identifier: str,
61 |     default: D,
62 | ) -> Union[D, V]:
63 |     """Get item from a package name lookup mapping with a resolver identifier.
64 | 
65 |     This extra logic is needed when the target mapping is keyed by package
66 |     name, which cannot be directly looked up with an identifier (which may
67 |     contain requested extras). Additional logic is added to also look up a value
68 |     by "cleaning up" the extras from the identifier.
69 |     """
70 |     if identifier in mapping:
71 |         return mapping[identifier]
72 |     # HACK: Theoretically we should check whether this identifier is a valid
73 |     # "NAME[EXTRAS]" format, and parse out the name part with packaging or
74 |     # some regular expression. But since pip's resolver only spits out three
75 |     # kinds of identifiers: normalized PEP 503 names, normalized names plus
76 |     # extras, and Requires-Python, we can cheat a bit here.
77 |     name, open_bracket, _ = identifier.partition("[")
78 |     if open_bracket and name in mapping:
79 |         return mapping[name]
80 |     return default
81 | 
82 | 
83 | class PipProvider(_ProviderBase):
84 |     """Pip's provider implementation for resolvelib.
85 | 
86 |     :params constraints: A mapping of constraints specified by the user. Keys
87 |         are canonicalized project names.
88 |     :params ignore_dependencies: Whether the user specified ``--no-deps``.
89 |     :params upgrade_strategy: The user-specified upgrade strategy.
90 |     :params user_requested: A set of canonicalized package names that the user
91 |         supplied for pip to install/upgrade.
92 |     """
93 | 
94 |     def __init__(
95 |         self,
96 |         factory: Factory,
97 |         constraints: Dict[str, Constraint],
98 |         ignore_dependencies: bool,
99 |         upgrade_strategy: str,
100 |         user_requested: Dict[str, int],
101 |     ) -> None:
102 |         self._factory = factory
103 |         self._constraints = constraints
104 |         self._ignore_dependencies = ignore_dependencies
105 |         self._upgrade_strategy = upgrade_strategy
106 |         self._user_requested = user_requested
107 | 
108 |     def identify(self, requirement_or_candidate: Union[Requirement, Candidate]) -> str:
109 |         return requirement_or_candidate.name
110 | 
111 |     def narrow_requirement_selection(
112 |         self,
113 |         identifiers: Iterable[str],
114 |         resolutions: Mapping[str, Candidate],
115 |         candidates: Mapping[str, Iterator[Candidate]],
116 |         information: Mapping[str, Iterator["PreferenceInformation"]],
117 |         backtrack_causes: Sequence["PreferenceInformation"],
118 |     ) -> Iterable[str]:
119 |         """Produce a subset of identifiers that should be considered before others.
120 | 
121 |         Currently pip narrows the following selection:
122 |             * Requires-Python, if present is always returned by itself
123 |             * Backtrack causes are considered next because they can be identified
124 |               in linear time here, whereas because get_preference() is called
125 |               for each identifier, it would be quadratic to check for them there.
126 |               Further, the current backtrack causes likely need to be resolved
127 |               before other requirements as a resolution can't be found while
128 |               there is a conflict.
129 |         """
130 |         backtrack_identifiers = set()
131 |         for info in backtrack_causes:
132 |             backtrack_identifiers.add(info.requirement.name)
133 |             if info.parent is not None:
134 |                 backtrack_identifiers.add(info.parent.name)
135 | 
136 |         current_backtrack_causes = []
137 |         for identifier in identifiers:
138 |             # Requires-Python has only one candidate and the check is basically
139 |             # free, so we always do it first to avoid needless work if it fails.
140 |             # This skips calling get_preference() for all other identifiers.
141 |             if identifier == REQUIRES_PYTHON_IDENTIFIER:
142 |                 return [identifier]
143 | 
144 |             # Check if this identifier is a backtrack cause
145 |             if identifier in backtrack_identifiers:
146 |                 current_backtrack_causes.append(identifier)
147 |                 continue
148 | 
149 |         if current_backtrack_causes:
150 |             return current_backtrack_causes
151 | 
152 |         return identifiers
153 | 
154 |     def get_preference(
155 |         self,
156 |         identifier: str,
157 |         resolutions: Mapping[str, Candidate],
158 |         candidates: Mapping[str, Iterator[Candidate]],
159 |         information: Mapping[str, Iterable["PreferenceInformation"]],
160 |         backtrack_causes: Sequence["PreferenceInformation"],
161 |     ) -> "Preference":
162 |         """Produce a sort key for given requirement based on preference.
163 | 
164 |         The lower the return value is, the more preferred this group of
165 |         arguments is.
166 | 
167 |         Currently pip considers the following in order:
168 | 
169 |         * Any requirement that is "direct", e.g., points to an explicit URL.
170 |         * Any requirement that is "pinned", i.e., contains the operator ``===``
171 |           or ``==`` without a wildcard.
172 |         * Any requirement that imposes an upper version limit, i.e., contains the
173 |           operator ``<``, ``<=``, ``~=``, or ``==`` with a wildcard. Because
174 |           pip prioritizes the latest version, preferring explicit upper bounds
175 |           can rule out infeasible candidates sooner. This does not imply that
176 |           upper bounds are good practice; they can make dependency management
177 |           and resolution harder.
178 |         * Order user-specified requirements as they are specified, placing
179 |           other requirements afterward.
180 |         * Any "non-free" requirement, i.e., one that contains at least one
181 |           operator, such as ``>=`` or ``!=``.
182 |         * Alphabetical order for consistency (aids debuggability).
183 |         """
184 |         try:
185 |             next(iter(information[identifier]))
186 |         except StopIteration:
187 |             # There is no information for this identifier, so there's no known
188 |             # candidates.
189 |             has_information = False
190 |         else:
191 |             has_information = True
192 | 
193 |         if not has_information:
194 |             direct = False
195 |             ireqs: Tuple[Optional[InstallRequirement], ...] = ()
196 |         else:
197 |             # Go through the information and for each requirement,
198 |             # check if it's explicit (e.g., a direct link) and get the
199 |             # InstallRequirement (the second element) from get_candidate_lookup()
200 |             directs, ireqs = zip(
201 |                 *(
202 |                     (isinstance(r, ExplicitRequirement), r.get_candidate_lookup()[1])
203 |                     for r, _ in information[identifier]
204 |                 )
205 |             )
206 |             direct = any(directs)
207 | 
208 |         operators: list[tuple[str, str]] = [
209 |             (specifier.operator, specifier.version)
210 |             for specifier_set in (ireq.specifier for ireq in ireqs if ireq)
211 |             for specifier in specifier_set
212 |         ]
213 | 
214 |         pinned = any(((op[:2] == "==") and ("*" not in ver)) for op, ver in operators)
215 |         upper_bounded = any(
216 |             ((op in ("<", "<=", "~=")) or (op == "==" and "*" in ver))
217 |             for op, ver in operators
218 |         )
219 |         unfree = bool(operators)
220 |         requested_order = self._user_requested.get(identifier, math.inf)
221 | 
222 |         return (
223 |             not direct,
224 |             not pinned,
225 |             not upper_bounded,
226 |             requested_order,
227 |             not unfree,
228 |             identifier,
229 |         )
230 | 
231 |     def find_matches(
232 |         self,
233 |         identifier: str,
234 |         requirements: Mapping[str, Iterator[Requirement]],
235 |         incompatibilities: Mapping[str, Iterator[Candidate]],
236 |     ) -> Iterable[Candidate]:
237 |         def _eligible_for_upgrade(identifier: str) -> bool:
238 |             """Are upgrades allowed for this project?
239 | 
240 |             This checks the upgrade strategy, and whether the project was one
241 |             that the user specified in the command line, in order to decide
242 |             whether we should upgrade if there's a newer version available.
243 | 
244 |             (Note that we don't need access to the `--upgrade` flag, because
245 |             an upgrade strategy of "to-satisfy-only" means that `--upgrade`
246 |             was not specified).
247 |             """
248 |             if self._upgrade_strategy == "eager":
249 |                 return True
250 |             elif self._upgrade_strategy == "only-if-needed":
251 |                 user_order = _get_with_identifier(
252 |                     self._user_requested,
253 |                     identifier,
254 |                     default=None,
255 |                 )
256 |                 return user_order is not None
257 |             return False
258 | 
259 |         constraint = _get_with_identifier(
260 |             self._constraints,
261 |             identifier,
262 |             default=Constraint.empty(),
263 |         )
264 |         return self._factory.find_candidates(
265 |             identifier=identifier,
266 |             requirements=requirements,
267 |             constraint=constraint,
268 |             prefers_installed=(not _eligible_for_upgrade(identifier)),
269 |             incompatibilities=incompatibilities,
270 |             is_satisfied_by=self.is_satisfied_by,
271 |         )
272 | 
273 |     @staticmethod
274 |     @lru_cache(maxsize=None)
275 |     def is_satisfied_by(requirement: Requirement, candidate: Candidate) -> bool:
276 |         return requirement.is_satisfied_by(candidate)
277 | 
278 |     def get_dependencies(self, candidate: Candidate) -> Iterable[Requirement]:
279 |         with_requires = not self._ignore_dependencies
280 |         # iter_dependencies() can perform nontrivial work so delay until needed.
281 |         return (r for r in candidate.iter_dependencies(with_requires) if r is not None)
```

.venv/lib/python3.13/site-packages/pip/_internal/resolution/resolvelib/reporter.py
```
1 | from collections import defaultdict
2 | from logging import getLogger
3 | from typing import Any, DefaultDict, Optional
4 | 
5 | from pip._vendor.resolvelib.reporters import BaseReporter
6 | 
7 | from .base import Candidate, Requirement
8 | 
9 | logger = getLogger(__name__)
10 | 
11 | 
12 | class PipReporter(BaseReporter[Requirement, Candidate, str]):
13 |     def __init__(self) -> None:
14 |         self.reject_count_by_package: DefaultDict[str, int] = defaultdict(int)
15 | 
16 |         self._messages_at_reject_count = {
17 |             1: (
18 |                 "pip is looking at multiple versions of {package_name} to "
19 |                 "determine which version is compatible with other "
20 |                 "requirements. This could take a while."
21 |             ),
22 |             8: (
23 |                 "pip is still looking at multiple versions of {package_name} to "
24 |                 "determine which version is compatible with other "
25 |                 "requirements. This could take a while."
26 |             ),
27 |             13: (
28 |                 "This is taking longer than usual. You might need to provide "
29 |                 "the dependency resolver with stricter constraints to reduce "
30 |                 "runtime. See https://pip.pypa.io/warnings/backtracking for "
31 |                 "guidance. If you want to abort this run, press Ctrl + C."
32 |             ),
33 |         }
34 | 
35 |     def rejecting_candidate(self, criterion: Any, candidate: Candidate) -> None:
36 |         self.reject_count_by_package[candidate.name] += 1
37 | 
38 |         count = self.reject_count_by_package[candidate.name]
39 |         if count not in self._messages_at_reject_count:
40 |             return
41 | 
42 |         message = self._messages_at_reject_count[count]
43 |         logger.info("INFO: %s", message.format(package_name=candidate.name))
44 | 
45 |         msg = "Will try a different candidate, due to conflict:"
46 |         for req_info in criterion.information:
47 |             req, parent = req_info.requirement, req_info.parent
48 |             # Inspired by Factory.get_installation_error
49 |             msg += "\n    "
50 |             if parent:
51 |                 msg += f"{parent.name} {parent.version} depends on "
52 |             else:
53 |                 msg += "The user requested "
54 |             msg += req.format_for_error()
55 |         logger.debug(msg)
56 | 
57 | 
58 | class PipDebuggingReporter(BaseReporter[Requirement, Candidate, str]):
59 |     """A reporter that does an info log for every event it sees."""
60 | 
61 |     def starting(self) -> None:
62 |         logger.info("Reporter.starting()")
63 | 
64 |     def starting_round(self, index: int) -> None:
65 |         logger.info("Reporter.starting_round(%r)", index)
66 | 
67 |     def ending_round(self, index: int, state: Any) -> None:
68 |         logger.info("Reporter.ending_round(%r, state)", index)
69 |         logger.debug("Reporter.ending_round(%r, %r)", index, state)
70 | 
71 |     def ending(self, state: Any) -> None:
72 |         logger.info("Reporter.ending(%r)", state)
73 | 
74 |     def adding_requirement(
75 |         self, requirement: Requirement, parent: Optional[Candidate]
76 |     ) -> None:
77 |         logger.info("Reporter.adding_requirement(%r, %r)", requirement, parent)
78 | 
79 |     def rejecting_candidate(self, criterion: Any, candidate: Candidate) -> None:
80 |         logger.info("Reporter.rejecting_candidate(%r, %r)", criterion, candidate)
81 | 
82 |     def pinning(self, candidate: Candidate) -> None:
83 |         logger.info("Reporter.pinning(%r)", candidate)
```

.venv/lib/python3.13/site-packages/pip/_internal/resolution/resolvelib/requirements.py
```
1 | from typing import Any, Optional
2 | 
3 | from pip._vendor.packaging.specifiers import SpecifierSet
4 | from pip._vendor.packaging.utils import NormalizedName, canonicalize_name
5 | 
6 | from pip._internal.req.constructors import install_req_drop_extras
7 | from pip._internal.req.req_install import InstallRequirement
8 | 
9 | from .base import Candidate, CandidateLookup, Requirement, format_name
10 | 
11 | 
12 | class ExplicitRequirement(Requirement):
13 |     def __init__(self, candidate: Candidate) -> None:
14 |         self.candidate = candidate
15 | 
16 |     def __str__(self) -> str:
17 |         return str(self.candidate)
18 | 
19 |     def __repr__(self) -> str:
20 |         return f"{self.__class__.__name__}({self.candidate!r})"
21 | 
22 |     def __hash__(self) -> int:
23 |         return hash(self.candidate)
24 | 
25 |     def __eq__(self, other: Any) -> bool:
26 |         if not isinstance(other, ExplicitRequirement):
27 |             return False
28 |         return self.candidate == other.candidate
29 | 
30 |     @property
31 |     def project_name(self) -> NormalizedName:
32 |         # No need to canonicalize - the candidate did this
33 |         return self.candidate.project_name
34 | 
35 |     @property
36 |     def name(self) -> str:
37 |         # No need to canonicalize - the candidate did this
38 |         return self.candidate.name
39 | 
40 |     def format_for_error(self) -> str:
41 |         return self.candidate.format_for_error()
42 | 
43 |     def get_candidate_lookup(self) -> CandidateLookup:
44 |         return self.candidate, None
45 | 
46 |     def is_satisfied_by(self, candidate: Candidate) -> bool:
47 |         return candidate == self.candidate
48 | 
49 | 
50 | class SpecifierRequirement(Requirement):
51 |     def __init__(self, ireq: InstallRequirement) -> None:
52 |         assert ireq.link is None, "This is a link, not a specifier"
53 |         self._ireq = ireq
54 |         self._equal_cache: Optional[str] = None
55 |         self._hash: Optional[int] = None
56 |         self._extras = frozenset(canonicalize_name(e) for e in self._ireq.extras)
57 | 
58 |     @property
59 |     def _equal(self) -> str:
60 |         if self._equal_cache is not None:
61 |             return self._equal_cache
62 | 
63 |         self._equal_cache = str(self._ireq)
64 |         return self._equal_cache
65 | 
66 |     def __str__(self) -> str:
67 |         return str(self._ireq.req)
68 | 
69 |     def __repr__(self) -> str:
70 |         return f"{self.__class__.__name__}({str(self._ireq.req)!r})"
71 | 
72 |     def __eq__(self, other: object) -> bool:
73 |         if not isinstance(other, SpecifierRequirement):
74 |             return NotImplemented
75 |         return self._equal == other._equal
76 | 
77 |     def __hash__(self) -> int:
78 |         if self._hash is not None:
79 |             return self._hash
80 | 
81 |         self._hash = hash(self._equal)
82 |         return self._hash
83 | 
84 |     @property
85 |     def project_name(self) -> NormalizedName:
86 |         assert self._ireq.req, "Specifier-backed ireq is always PEP 508"
87 |         return canonicalize_name(self._ireq.req.name)
88 | 
89 |     @property
90 |     def name(self) -> str:
91 |         return format_name(self.project_name, self._extras)
92 | 
93 |     def format_for_error(self) -> str:
94 |         # Convert comma-separated specifiers into "A, B, ..., F and G"
95 |         # This makes the specifier a bit more "human readable", without
96 |         # risking a change in meaning. (Hopefully! Not all edge cases have
97 |         # been checked)
98 |         parts = [s.strip() for s in str(self).split(",")]
99 |         if len(parts) == 0:
100 |             return ""
101 |         elif len(parts) == 1:
102 |             return parts[0]
103 | 
104 |         return ", ".join(parts[:-1]) + " and " + parts[-1]
105 | 
106 |     def get_candidate_lookup(self) -> CandidateLookup:
107 |         return None, self._ireq
108 | 
109 |     def is_satisfied_by(self, candidate: Candidate) -> bool:
110 |         assert candidate.name == self.name, (
111 |             f"Internal issue: Candidate is not for this requirement "
112 |             f"{candidate.name} vs {self.name}"
113 |         )
114 |         # We can safely always allow prereleases here since PackageFinder
115 |         # already implements the prerelease logic, and would have filtered out
116 |         # prerelease candidates if the user does not expect them.
117 |         assert self._ireq.req, "Specifier-backed ireq is always PEP 508"
118 |         spec = self._ireq.req.specifier
119 |         return spec.contains(candidate.version, prereleases=True)
120 | 
121 | 
122 | class SpecifierWithoutExtrasRequirement(SpecifierRequirement):
123 |     """
124 |     Requirement backed by an install requirement on a base package.
125 |     Trims extras from its install requirement if there are any.
126 |     """
127 | 
128 |     def __init__(self, ireq: InstallRequirement) -> None:
129 |         assert ireq.link is None, "This is a link, not a specifier"
130 |         self._ireq = install_req_drop_extras(ireq)
131 |         self._equal_cache: Optional[str] = None
132 |         self._hash: Optional[int] = None
133 |         self._extras = frozenset(canonicalize_name(e) for e in self._ireq.extras)
134 | 
135 |     @property
136 |     def _equal(self) -> str:
137 |         if self._equal_cache is not None:
138 |             return self._equal_cache
139 | 
140 |         self._equal_cache = str(self._ireq)
141 |         return self._equal_cache
142 | 
143 |     def __eq__(self, other: object) -> bool:
144 |         if not isinstance(other, SpecifierWithoutExtrasRequirement):
145 |             return NotImplemented
146 |         return self._equal == other._equal
147 | 
148 |     def __hash__(self) -> int:
149 |         if self._hash is not None:
150 |             return self._hash
151 | 
152 |         self._hash = hash(self._equal)
153 |         return self._hash
154 | 
155 | 
156 | class RequiresPythonRequirement(Requirement):
157 |     """A requirement representing Requires-Python metadata."""
158 | 
159 |     def __init__(self, specifier: SpecifierSet, match: Candidate) -> None:
160 |         self.specifier = specifier
161 |         self._specifier_string = str(specifier)  # for faster __eq__
162 |         self._hash: Optional[int] = None
163 |         self._candidate = match
164 | 
165 |     def __str__(self) -> str:
166 |         return f"Python {self.specifier}"
167 | 
168 |     def __repr__(self) -> str:
169 |         return f"{self.__class__.__name__}({str(self.specifier)!r})"
170 | 
171 |     def __hash__(self) -> int:
172 |         if self._hash is not None:
173 |             return self._hash
174 | 
175 |         self._hash = hash((self._specifier_string, self._candidate))
176 |         return self._hash
177 | 
178 |     def __eq__(self, other: Any) -> bool:
179 |         if not isinstance(other, RequiresPythonRequirement):
180 |             return False
181 |         return (
182 |             self._specifier_string == other._specifier_string
183 |             and self._candidate == other._candidate
184 |         )
185 | 
186 |     @property
187 |     def project_name(self) -> NormalizedName:
188 |         return self._candidate.project_name
189 | 
190 |     @property
191 |     def name(self) -> str:
192 |         return self._candidate.name
193 | 
194 |     def format_for_error(self) -> str:
195 |         return str(self)
196 | 
197 |     def get_candidate_lookup(self) -> CandidateLookup:
198 |         if self.specifier.contains(self._candidate.version, prereleases=True):
199 |             return self._candidate, None
200 |         return None, None
201 | 
202 |     def is_satisfied_by(self, candidate: Candidate) -> bool:
203 |         assert candidate.name == self._candidate.name, "Not Python candidate"
204 |         # We can safely always allow prereleases here since PackageFinder
205 |         # already implements the prerelease logic, and would have filtered out
206 |         # prerelease candidates if the user does not expect them.
207 |         return self.specifier.contains(candidate.version, prereleases=True)
208 | 
209 | 
210 | class UnsatisfiableRequirement(Requirement):
211 |     """A requirement that cannot be satisfied."""
212 | 
213 |     def __init__(self, name: NormalizedName) -> None:
214 |         self._name = name
215 | 
216 |     def __str__(self) -> str:
217 |         return f"{self._name} (unavailable)"
218 | 
219 |     def __repr__(self) -> str:
220 |         return f"{self.__class__.__name__}({str(self._name)!r})"
221 | 
222 |     def __eq__(self, other: object) -> bool:
223 |         if not isinstance(other, UnsatisfiableRequirement):
224 |             return NotImplemented
225 |         return self._name == other._name
226 | 
227 |     def __hash__(self) -> int:
228 |         return hash(self._name)
229 | 
230 |     @property
231 |     def project_name(self) -> NormalizedName:
232 |         return self._name
233 | 
234 |     @property
235 |     def name(self) -> str:
236 |         return self._name
237 | 
238 |     def format_for_error(self) -> str:
239 |         return str(self)
240 | 
241 |     def get_candidate_lookup(self) -> CandidateLookup:
242 |         return None, None
243 | 
244 |     def is_satisfied_by(self, candidate: Candidate) -> bool:
245 |         return False
```

.venv/lib/python3.13/site-packages/pip/_internal/resolution/resolvelib/resolver.py
```
1 | import contextlib
2 | import functools
3 | import logging
4 | import os
5 | from typing import TYPE_CHECKING, Dict, List, Optional, Set, Tuple, cast
6 | 
7 | from pip._vendor.packaging.utils import canonicalize_name
8 | from pip._vendor.resolvelib import BaseReporter, ResolutionImpossible, ResolutionTooDeep
9 | from pip._vendor.resolvelib import Resolver as RLResolver
10 | from pip._vendor.resolvelib.structs import DirectedGraph
11 | 
12 | from pip._internal.cache import WheelCache
13 | from pip._internal.exceptions import ResolutionTooDeepError
14 | from pip._internal.index.package_finder import PackageFinder
15 | from pip._internal.operations.prepare import RequirementPreparer
16 | from pip._internal.req.constructors import install_req_extend_extras
17 | from pip._internal.req.req_install import InstallRequirement
18 | from pip._internal.req.req_set import RequirementSet
19 | from pip._internal.resolution.base import BaseResolver, InstallRequirementProvider
20 | from pip._internal.resolution.resolvelib.provider import PipProvider
21 | from pip._internal.resolution.resolvelib.reporter import (
22 |     PipDebuggingReporter,
23 |     PipReporter,
24 | )
25 | from pip._internal.utils.packaging import get_requirement
26 | 
27 | from .base import Candidate, Requirement
28 | from .factory import Factory
29 | 
30 | if TYPE_CHECKING:
31 |     from pip._vendor.resolvelib.resolvers import Result as RLResult
32 | 
33 |     Result = RLResult[Requirement, Candidate, str]
34 | 
35 | 
36 | logger = logging.getLogger(__name__)
37 | 
38 | 
39 | class Resolver(BaseResolver):
40 |     _allowed_strategies = {"eager", "only-if-needed", "to-satisfy-only"}
41 | 
42 |     def __init__(
43 |         self,
44 |         preparer: RequirementPreparer,
45 |         finder: PackageFinder,
46 |         wheel_cache: Optional[WheelCache],
47 |         make_install_req: InstallRequirementProvider,
48 |         use_user_site: bool,
49 |         ignore_dependencies: bool,
50 |         ignore_installed: bool,
51 |         ignore_requires_python: bool,
52 |         force_reinstall: bool,
53 |         upgrade_strategy: str,
54 |         py_version_info: Optional[Tuple[int, ...]] = None,
55 |     ):
56 |         super().__init__()
57 |         assert upgrade_strategy in self._allowed_strategies
58 | 
59 |         self.factory = Factory(
60 |             finder=finder,
61 |             preparer=preparer,
62 |             make_install_req=make_install_req,
63 |             wheel_cache=wheel_cache,
64 |             use_user_site=use_user_site,
65 |             force_reinstall=force_reinstall,
66 |             ignore_installed=ignore_installed,
67 |             ignore_requires_python=ignore_requires_python,
68 |             py_version_info=py_version_info,
69 |         )
70 |         self.ignore_dependencies = ignore_dependencies
71 |         self.upgrade_strategy = upgrade_strategy
72 |         self._result: Optional[Result] = None
73 | 
74 |     def resolve(
75 |         self, root_reqs: List[InstallRequirement], check_supported_wheels: bool
76 |     ) -> RequirementSet:
77 |         collected = self.factory.collect_root_requirements(root_reqs)
78 |         provider = PipProvider(
79 |             factory=self.factory,
80 |             constraints=collected.constraints,
81 |             ignore_dependencies=self.ignore_dependencies,
82 |             upgrade_strategy=self.upgrade_strategy,
83 |             user_requested=collected.user_requested,
84 |         )
85 |         if "PIP_RESOLVER_DEBUG" in os.environ:
86 |             reporter: BaseReporter[Requirement, Candidate, str] = PipDebuggingReporter()
87 |         else:
88 |             reporter = PipReporter()
89 |         resolver: RLResolver[Requirement, Candidate, str] = RLResolver(
90 |             provider,
91 |             reporter,
92 |         )
93 | 
94 |         try:
95 |             limit_how_complex_resolution_can_be = 200000
96 |             result = self._result = resolver.resolve(
97 |                 collected.requirements, max_rounds=limit_how_complex_resolution_can_be
98 |             )
99 | 
100 |         except ResolutionImpossible as e:
101 |             error = self.factory.get_installation_error(
102 |                 cast("ResolutionImpossible[Requirement, Candidate]", e),
103 |                 collected.constraints,
104 |             )
105 |             raise error from e
106 |         except ResolutionTooDeep:
107 |             raise ResolutionTooDeepError from None
108 | 
109 |         req_set = RequirementSet(check_supported_wheels=check_supported_wheels)
110 |         # process candidates with extras last to ensure their base equivalent is
111 |         # already in the req_set if appropriate.
112 |         # Python's sort is stable so using a binary key function keeps relative order
113 |         # within both subsets.
114 |         for candidate in sorted(
115 |             result.mapping.values(), key=lambda c: c.name != c.project_name
116 |         ):
117 |             ireq = candidate.get_install_requirement()
118 |             if ireq is None:
119 |                 if candidate.name != candidate.project_name:
120 |                     # extend existing req's extras
121 |                     with contextlib.suppress(KeyError):
122 |                         req = req_set.get_requirement(candidate.project_name)
123 |                         req_set.add_named_requirement(
124 |                             install_req_extend_extras(
125 |                                 req, get_requirement(candidate.name).extras
126 |                             )
127 |                         )
128 |                 continue
129 | 
130 |             # Check if there is already an installation under the same name,
131 |             # and set a flag for later stages to uninstall it, if needed.
132 |             installed_dist = self.factory.get_dist_to_uninstall(candidate)
133 |             if installed_dist is None:
134 |                 # There is no existing installation -- nothing to uninstall.
135 |                 ireq.should_reinstall = False
136 |             elif self.factory.force_reinstall:
137 |                 # The --force-reinstall flag is set -- reinstall.
138 |                 ireq.should_reinstall = True
139 |             elif installed_dist.version != candidate.version:
140 |                 # The installation is different in version -- reinstall.
141 |                 ireq.should_reinstall = True
142 |             elif candidate.is_editable or installed_dist.editable:
143 |                 # The incoming distribution is editable, or different in
144 |                 # editable-ness to installation -- reinstall.
145 |                 ireq.should_reinstall = True
146 |             elif candidate.source_link and candidate.source_link.is_file:
147 |                 # The incoming distribution is under file://
148 |                 if candidate.source_link.is_wheel:
149 |                     # is a local wheel -- do nothing.
150 |                     logger.info(
151 |                         "%s is already installed with the same version as the "
152 |                         "provided wheel. Use --force-reinstall to force an "
153 |                         "installation of the wheel.",
154 |                         ireq.name,
155 |                     )
156 |                     continue
157 | 
158 |                 # is a local sdist or path -- reinstall
159 |                 ireq.should_reinstall = True
160 |             else:
161 |                 continue
162 | 
163 |             link = candidate.source_link
164 |             if link and link.is_yanked:
165 |                 # The reason can contain non-ASCII characters, Unicode
166 |                 # is required for Python 2.
167 |                 msg = (
168 |                     "The candidate selected for download or install is a "
169 |                     "yanked version: {name!r} candidate (version {version} "
170 |                     "at {link})\nReason for being yanked: {reason}"
171 |                 ).format(
172 |                     name=candidate.name,
173 |                     version=candidate.version,
174 |                     link=link,
175 |                     reason=link.yanked_reason or "<none given>",
176 |                 )
177 |                 logger.warning(msg)
178 | 
179 |             req_set.add_named_requirement(ireq)
180 | 
181 |         reqs = req_set.all_requirements
182 |         self.factory.preparer.prepare_linked_requirements_more(reqs)
183 |         for req in reqs:
184 |             req.prepared = True
185 |             req.needs_more_preparation = False
186 |         return req_set
187 | 
188 |     def get_installation_order(
189 |         self, req_set: RequirementSet
190 |     ) -> List[InstallRequirement]:
191 |         """Get order for installation of requirements in RequirementSet.
192 | 
193 |         The returned list contains a requirement before another that depends on
194 |         it. This helps ensure that the environment is kept consistent as they
195 |         get installed one-by-one.
196 | 
197 |         The current implementation creates a topological ordering of the
198 |         dependency graph, giving more weight to packages with less
199 |         or no dependencies, while breaking any cycles in the graph at
200 |         arbitrary points. We make no guarantees about where the cycle
201 |         would be broken, other than it *would* be broken.
202 |         """
203 |         assert self._result is not None, "must call resolve() first"
204 | 
205 |         if not req_set.requirements:
206 |             # Nothing is left to install, so we do not need an order.
207 |             return []
208 | 
209 |         graph = self._result.graph
210 |         weights = get_topological_weights(graph, set(req_set.requirements.keys()))
211 | 
212 |         sorted_items = sorted(
213 |             req_set.requirements.items(),
214 |             key=functools.partial(_req_set_item_sorter, weights=weights),
215 |             reverse=True,
216 |         )
217 |         return [ireq for _, ireq in sorted_items]
218 | 
219 | 
220 | def get_topological_weights(
221 |     graph: "DirectedGraph[Optional[str]]", requirement_keys: Set[str]
222 | ) -> Dict[Optional[str], int]:
223 |     """Assign weights to each node based on how "deep" they are.
224 | 
225 |     This implementation may change at any point in the future without prior
226 |     notice.
227 | 
228 |     We first simplify the dependency graph by pruning any leaves and giving them
229 |     the highest weight: a package without any dependencies should be installed
230 |     first. This is done again and again in the same way, giving ever less weight
231 |     to the newly found leaves. The loop stops when no leaves are left: all
232 |     remaining packages have at least one dependency left in the graph.
233 | 
234 |     Then we continue with the remaining graph, by taking the length for the
235 |     longest path to any node from root, ignoring any paths that contain a single
236 |     node twice (i.e. cycles). This is done through a depth-first search through
237 |     the graph, while keeping track of the path to the node.
238 | 
239 |     Cycles in the graph result would result in node being revisited while also
240 |     being on its own path. In this case, take no action. This helps ensure we
241 |     don't get stuck in a cycle.
242 | 
243 |     When assigning weight, the longer path (i.e. larger length) is preferred.
244 | 
245 |     We are only interested in the weights of packages that are in the
246 |     requirement_keys.
247 |     """
248 |     path: Set[Optional[str]] = set()
249 |     weights: Dict[Optional[str], int] = {}
250 | 
251 |     def visit(node: Optional[str]) -> None:
252 |         if node in path:
253 |             # We hit a cycle, so we'll break it here.
254 |             return
255 | 
256 |         # Time to visit the children!
257 |         path.add(node)
258 |         for child in graph.iter_children(node):
259 |             visit(child)
260 |         path.remove(node)
261 | 
262 |         if node not in requirement_keys:
263 |             return
264 | 
265 |         last_known_parent_count = weights.get(node, 0)
266 |         weights[node] = max(last_known_parent_count, len(path))
267 | 
268 |     # Simplify the graph, pruning leaves that have no dependencies.
269 |     # This is needed for large graphs (say over 200 packages) because the
270 |     # `visit` function is exponentially slower then, taking minutes.
271 |     # See https://github.com/pypa/pip/issues/10557
272 |     # We will loop until we explicitly break the loop.
273 |     while True:
274 |         leaves = set()
275 |         for key in graph:
276 |             if key is None:
277 |                 continue
278 |             for _child in graph.iter_children(key):
279 |                 # This means we have at least one child
280 |                 break
281 |             else:
282 |                 # No child.
283 |                 leaves.add(key)
284 |         if not leaves:
285 |             # We are done simplifying.
286 |             break
287 |         # Calculate the weight for the leaves.
288 |         weight = len(graph) - 1
289 |         for leaf in leaves:
290 |             if leaf not in requirement_keys:
291 |                 continue
292 |             weights[leaf] = weight
293 |         # Remove the leaves from the graph, making it simpler.
294 |         for leaf in leaves:
295 |             graph.remove(leaf)
296 | 
297 |     # Visit the remaining graph.
298 |     # `None` is guaranteed to be the root node by resolvelib.
299 |     visit(None)
300 | 
301 |     # Sanity check: all requirement keys should be in the weights,
302 |     # and no other keys should be in the weights.
303 |     difference = set(weights.keys()).difference(requirement_keys)
304 |     assert not difference, difference
305 | 
306 |     return weights
307 | 
308 | 
309 | def _req_set_item_sorter(
310 |     item: Tuple[str, InstallRequirement],
311 |     weights: Dict[Optional[str], int],
312 | ) -> Tuple[int, str]:
313 |     """Key function used to sort install requirements for installation.
314 | 
315 |     Based on the "weight" mapping calculated in ``get_installation_order()``.
316 |     The canonical package name is returned as the second member as a tie-
317 |     breaker to ensure the result is predictable, which is useful in tests.
318 |     """
319 |     name = canonicalize_name(item[0])
320 |     return weights[name], name
```

.venv/lib/python3.13/site-packages/pip/_vendor/cachecontrol/caches/__init__.py
```
1 | # SPDX-FileCopyrightText: 2015 Eric Larson
2 | #
3 | # SPDX-License-Identifier: Apache-2.0
4 | 
5 | from pip._vendor.cachecontrol.caches.file_cache import FileCache, SeparateBodyFileCache
6 | from pip._vendor.cachecontrol.caches.redis_cache import RedisCache
7 | 
8 | __all__ = ["FileCache", "SeparateBodyFileCache", "RedisCache"]
```

.venv/lib/python3.13/site-packages/pip/_vendor/cachecontrol/caches/file_cache.py
```
1 | # SPDX-FileCopyrightText: 2015 Eric Larson
2 | #
3 | # SPDX-License-Identifier: Apache-2.0
4 | from __future__ import annotations
5 | 
6 | import hashlib
7 | import os
8 | import tempfile
9 | from textwrap import dedent
10 | from typing import IO, TYPE_CHECKING
11 | from pathlib import Path
12 | 
13 | from pip._vendor.cachecontrol.cache import BaseCache, SeparateBodyBaseCache
14 | from pip._vendor.cachecontrol.controller import CacheController
15 | 
16 | if TYPE_CHECKING:
17 |     from datetime import datetime
18 | 
19 |     from filelock import BaseFileLock
20 | 
21 | 
22 | class _FileCacheMixin:
23 |     """Shared implementation for both FileCache variants."""
24 | 
25 |     def __init__(
26 |         self,
27 |         directory: str | Path,
28 |         forever: bool = False,
29 |         filemode: int = 0o0600,
30 |         dirmode: int = 0o0700,
31 |         lock_class: type[BaseFileLock] | None = None,
32 |     ) -> None:
33 |         try:
34 |             if lock_class is None:
35 |                 from filelock import FileLock
36 | 
37 |                 lock_class = FileLock
38 |         except ImportError:
39 |             notice = dedent(
40 |                 """
41 |             NOTE: In order to use the FileCache you must have
42 |             filelock installed. You can install it via pip:
43 |               pip install cachecontrol[filecache]
44 |             """
45 |             )
46 |             raise ImportError(notice)
47 | 
48 |         self.directory = directory
49 |         self.forever = forever
50 |         self.filemode = filemode
51 |         self.dirmode = dirmode
52 |         self.lock_class = lock_class
53 | 
54 |     @staticmethod
55 |     def encode(x: str) -> str:
56 |         return hashlib.sha224(x.encode()).hexdigest()
57 | 
58 |     def _fn(self, name: str) -> str:
59 |         # NOTE: This method should not change as some may depend on it.
60 |         #       See: https://github.com/ionrock/cachecontrol/issues/63
61 |         hashed = self.encode(name)
62 |         parts = list(hashed[:5]) + [hashed]
63 |         return os.path.join(self.directory, *parts)
64 | 
65 |     def get(self, key: str) -> bytes | None:
66 |         name = self._fn(key)
67 |         try:
68 |             with open(name, "rb") as fh:
69 |                 return fh.read()
70 | 
71 |         except FileNotFoundError:
72 |             return None
73 | 
74 |     def set(
75 |         self, key: str, value: bytes, expires: int | datetime | None = None
76 |     ) -> None:
77 |         name = self._fn(key)
78 |         self._write(name, value)
79 | 
80 |     def _write(self, path: str, data: bytes) -> None:
81 |         """
82 |         Safely write the data to the given path.
83 |         """
84 |         # Make sure the directory exists
85 |         dirname = os.path.dirname(path)
86 |         os.makedirs(dirname, self.dirmode, exist_ok=True)
87 | 
88 |         with self.lock_class(path + ".lock"):
89 |             # Write our actual file
90 |             (fd, name) = tempfile.mkstemp(dir=dirname)
91 |             try:
92 |                 os.write(fd, data)
93 |             finally:
94 |                 os.close(fd)
95 |             os.chmod(name, self.filemode)
96 |             os.replace(name, path)
97 | 
98 |     def _delete(self, key: str, suffix: str) -> None:
99 |         name = self._fn(key) + suffix
100 |         if not self.forever:
101 |             try:
102 |                 os.remove(name)
103 |             except FileNotFoundError:
104 |                 pass
105 | 
106 | 
107 | class FileCache(_FileCacheMixin, BaseCache):
108 |     """
109 |     Traditional FileCache: body is stored in memory, so not suitable for large
110 |     downloads.
111 |     """
112 | 
113 |     def delete(self, key: str) -> None:
114 |         self._delete(key, "")
115 | 
116 | 
117 | class SeparateBodyFileCache(_FileCacheMixin, SeparateBodyBaseCache):
118 |     """
119 |     Memory-efficient FileCache: body is stored in a separate file, reducing
120 |     peak memory usage.
121 |     """
122 | 
123 |     def get_body(self, key: str) -> IO[bytes] | None:
124 |         name = self._fn(key) + ".body"
125 |         try:
126 |             return open(name, "rb")
127 |         except FileNotFoundError:
128 |             return None
129 | 
130 |     def set_body(self, key: str, body: bytes) -> None:
131 |         name = self._fn(key) + ".body"
132 |         self._write(name, body)
133 | 
134 |     def delete(self, key: str) -> None:
135 |         self._delete(key, "")
136 |         self._delete(key, ".body")
137 | 
138 | 
139 | def url_to_file_path(url: str, filecache: FileCache) -> str:
140 |     """Return the file cache path based on the URL.
141 | 
142 |     This does not ensure the file exists!
143 |     """
144 |     key = CacheController.cache_url(url)
145 |     return filecache._fn(key)
```

.venv/lib/python3.13/site-packages/pip/_vendor/cachecontrol/caches/redis_cache.py
```
1 | # SPDX-FileCopyrightText: 2015 Eric Larson
2 | #
3 | # SPDX-License-Identifier: Apache-2.0
4 | from __future__ import annotations
5 | 
6 | 
7 | from datetime import datetime, timezone
8 | from typing import TYPE_CHECKING
9 | 
10 | from pip._vendor.cachecontrol.cache import BaseCache
11 | 
12 | if TYPE_CHECKING:
13 |     from redis import Redis
14 | 
15 | 
16 | class RedisCache(BaseCache):
17 |     def __init__(self, conn: Redis[bytes]) -> None:
18 |         self.conn = conn
19 | 
20 |     def get(self, key: str) -> bytes | None:
21 |         return self.conn.get(key)
22 | 
23 |     def set(
24 |         self, key: str, value: bytes, expires: int | datetime | None = None
25 |     ) -> None:
26 |         if not expires:
27 |             self.conn.set(key, value)
28 |         elif isinstance(expires, datetime):
29 |             now_utc = datetime.now(timezone.utc)
30 |             if expires.tzinfo is None:
31 |                 now_utc = now_utc.replace(tzinfo=None)
32 |             delta = expires - now_utc
33 |             self.conn.setex(key, int(delta.total_seconds()), value)
34 |         else:
35 |             self.conn.setex(key, expires, value)
36 | 
37 |     def delete(self, key: str) -> None:
38 |         self.conn.delete(key)
39 | 
40 |     def clear(self) -> None:
41 |         """Helper for clearing all the keys in a database. Use with
42 |         caution!"""
43 |         for key in self.conn.keys():
44 |             self.conn.delete(key)
45 | 
46 |     def close(self) -> None:
47 |         """Redis uses connection pooling, no need to close the connection."""
48 |         pass
```

.venv/lib/python3.13/site-packages/pip/_vendor/pyproject_hooks/_in_process/__init__.py
```
1 | """This is a subpackage because the directory is on sys.path for _in_process.py
2 | 
3 | The subpackage should stay as empty as possible to avoid shadowing modules that
4 | the backend might import.
5 | """
6 | 
7 | import importlib.resources as resources
8 | 
9 | try:
10 |     resources.files
11 | except AttributeError:
12 |     # Python 3.8 compatibility
13 |     def _in_proc_script_path():
14 |         return resources.path(__package__, "_in_process.py")
15 | 
16 | else:
17 | 
18 |     def _in_proc_script_path():
19 |         return resources.as_file(
20 |             resources.files(__package__).joinpath("_in_process.py")
21 |         )
```

.venv/lib/python3.13/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py
```
1 | """This is invoked in a subprocess to call the build backend hooks.
2 | 
3 | It expects:
4 | - Command line args: hook_name, control_dir
5 | - Environment variables:
6 |       _PYPROJECT_HOOKS_BUILD_BACKEND=entry.point:spec
7 |       _PYPROJECT_HOOKS_BACKEND_PATH=paths (separated with os.pathsep)
8 | - control_dir/input.json:
9 |   - {"kwargs": {...}}
10 | 
11 | Results:
12 | - control_dir/output.json
13 |   - {"return_val": ...}
14 | """
15 | import json
16 | import os
17 | import os.path
18 | import re
19 | import shutil
20 | import sys
21 | import traceback
22 | from glob import glob
23 | from importlib import import_module
24 | from importlib.machinery import PathFinder
25 | from os.path import join as pjoin
26 | 
27 | # This file is run as a script, and `import wrappers` is not zip-safe, so we
28 | # include write_json() and read_json() from wrappers.py.
29 | 
30 | 
31 | def write_json(obj, path, **kwargs):
32 |     with open(path, "w", encoding="utf-8") as f:
33 |         json.dump(obj, f, **kwargs)
34 | 
35 | 
36 | def read_json(path):
37 |     with open(path, encoding="utf-8") as f:
38 |         return json.load(f)
39 | 
40 | 
41 | class BackendUnavailable(Exception):
42 |     """Raised if we cannot import the backend"""
43 | 
44 |     def __init__(self, message, traceback=None):
45 |         super().__init__(message)
46 |         self.message = message
47 |         self.traceback = traceback
48 | 
49 | 
50 | class HookMissing(Exception):
51 |     """Raised if a hook is missing and we are not executing the fallback"""
52 | 
53 |     def __init__(self, hook_name=None):
54 |         super().__init__(hook_name)
55 |         self.hook_name = hook_name
56 | 
57 | 
58 | def _build_backend():
59 |     """Find and load the build backend"""
60 |     backend_path = os.environ.get("_PYPROJECT_HOOKS_BACKEND_PATH")
61 |     ep = os.environ["_PYPROJECT_HOOKS_BUILD_BACKEND"]
62 |     mod_path, _, obj_path = ep.partition(":")
63 | 
64 |     if backend_path:
65 |         # Ensure in-tree backend directories have the highest priority when importing.
66 |         extra_pathitems = backend_path.split(os.pathsep)
67 |         sys.meta_path.insert(0, _BackendPathFinder(extra_pathitems, mod_path))
68 | 
69 |     try:
70 |         obj = import_module(mod_path)
71 |     except ImportError:
72 |         msg = f"Cannot import {mod_path!r}"
73 |         raise BackendUnavailable(msg, traceback.format_exc())
74 | 
75 |     if obj_path:
76 |         for path_part in obj_path.split("."):
77 |             obj = getattr(obj, path_part)
78 |     return obj
79 | 
80 | 
81 | class _BackendPathFinder:
82 |     """Implements the MetaPathFinder interface to locate modules in ``backend-path``.
83 | 
84 |     Since the environment provided by the frontend can contain all sorts of
85 |     MetaPathFinders, the only way to ensure the backend is loaded from the
86 |     right place is to prepend our own.
87 |     """
88 | 
89 |     def __init__(self, backend_path, backend_module):
90 |         self.backend_path = backend_path
91 |         self.backend_module = backend_module
92 |         self.backend_parent, _, _ = backend_module.partition(".")
93 | 
94 |     def find_spec(self, fullname, _path, _target=None):
95 |         if "." in fullname:
96 |             # Rely on importlib to find nested modules based on parent's path
97 |             return None
98 | 
99 |         # Ignore other items in _path or sys.path and use backend_path instead:
100 |         spec = PathFinder.find_spec(fullname, path=self.backend_path)
101 |         if spec is None and fullname == self.backend_parent:
102 |             # According to the spec, the backend MUST be loaded from backend-path.
103 |             # Therefore, we can halt the import machinery and raise a clean error.
104 |             msg = f"Cannot find module {self.backend_module!r} in {self.backend_path!r}"
105 |             raise BackendUnavailable(msg)
106 | 
107 |         return spec
108 | 
109 |     if sys.version_info >= (3, 8):
110 | 
111 |         def find_distributions(self, context=None):
112 |             # Delayed import: Python 3.7 does not contain importlib.metadata
113 |             from importlib.metadata import DistributionFinder, MetadataPathFinder
114 | 
115 |             context = DistributionFinder.Context(path=self.backend_path)
116 |             return MetadataPathFinder.find_distributions(context=context)
117 | 
118 | 
119 | def _supported_features():
120 |     """Return the list of options features supported by the backend.
121 | 
122 |     Returns a list of strings.
123 |     The only possible value is 'build_editable'.
124 |     """
125 |     backend = _build_backend()
126 |     features = []
127 |     if hasattr(backend, "build_editable"):
128 |         features.append("build_editable")
129 |     return features
130 | 
131 | 
132 | def get_requires_for_build_wheel(config_settings):
133 |     """Invoke the optional get_requires_for_build_wheel hook
134 | 
135 |     Returns [] if the hook is not defined.
136 |     """
137 |     backend = _build_backend()
138 |     try:
139 |         hook = backend.get_requires_for_build_wheel
140 |     except AttributeError:
141 |         return []
142 |     else:
143 |         return hook(config_settings)
144 | 
145 | 
146 | def get_requires_for_build_editable(config_settings):
147 |     """Invoke the optional get_requires_for_build_editable hook
148 | 
149 |     Returns [] if the hook is not defined.
150 |     """
151 |     backend = _build_backend()
152 |     try:
153 |         hook = backend.get_requires_for_build_editable
154 |     except AttributeError:
155 |         return []
156 |     else:
157 |         return hook(config_settings)
158 | 
159 | 
160 | def prepare_metadata_for_build_wheel(
161 |     metadata_directory, config_settings, _allow_fallback
162 | ):
163 |     """Invoke optional prepare_metadata_for_build_wheel
164 | 
165 |     Implements a fallback by building a wheel if the hook isn't defined,
166 |     unless _allow_fallback is False in which case HookMissing is raised.
167 |     """
168 |     backend = _build_backend()
169 |     try:
170 |         hook = backend.prepare_metadata_for_build_wheel
171 |     except AttributeError:
172 |         if not _allow_fallback:
173 |             raise HookMissing()
174 |     else:
175 |         return hook(metadata_directory, config_settings)
176 |     # fallback to build_wheel outside the try block to avoid exception chaining
177 |     # which can be confusing to users and is not relevant
178 |     whl_basename = backend.build_wheel(metadata_directory, config_settings)
179 |     return _get_wheel_metadata_from_wheel(
180 |         whl_basename, metadata_directory, config_settings
181 |     )
182 | 
183 | 
184 | def prepare_metadata_for_build_editable(
185 |     metadata_directory, config_settings, _allow_fallback
186 | ):
187 |     """Invoke optional prepare_metadata_for_build_editable
188 | 
189 |     Implements a fallback by building an editable wheel if the hook isn't
190 |     defined, unless _allow_fallback is False in which case HookMissing is
191 |     raised.
192 |     """
193 |     backend = _build_backend()
194 |     try:
195 |         hook = backend.prepare_metadata_for_build_editable
196 |     except AttributeError:
197 |         if not _allow_fallback:
198 |             raise HookMissing()
199 |         try:
200 |             build_hook = backend.build_editable
201 |         except AttributeError:
202 |             raise HookMissing(hook_name="build_editable")
203 |         else:
204 |             whl_basename = build_hook(metadata_directory, config_settings)
205 |             return _get_wheel_metadata_from_wheel(
206 |                 whl_basename, metadata_directory, config_settings
207 |             )
208 |     else:
209 |         return hook(metadata_directory, config_settings)
210 | 
211 | 
212 | WHEEL_BUILT_MARKER = "PYPROJECT_HOOKS_ALREADY_BUILT_WHEEL"
213 | 
214 | 
215 | def _dist_info_files(whl_zip):
216 |     """Identify the .dist-info folder inside a wheel ZipFile."""
217 |     res = []
218 |     for path in whl_zip.namelist():
219 |         m = re.match(r"[^/\\]+-[^/\\]+\.dist-info/", path)
220 |         if m:
221 |             res.append(path)
222 |     if res:
223 |         return res
224 |     raise Exception("No .dist-info folder found in wheel")
225 | 
226 | 
227 | def _get_wheel_metadata_from_wheel(whl_basename, metadata_directory, config_settings):
228 |     """Extract the metadata from a wheel.
229 | 
230 |     Fallback for when the build backend does not
231 |     define the 'get_wheel_metadata' hook.
232 |     """
233 |     from zipfile import ZipFile
234 | 
235 |     with open(os.path.join(metadata_directory, WHEEL_BUILT_MARKER), "wb"):
236 |         pass  # Touch marker file
237 | 
238 |     whl_file = os.path.join(metadata_directory, whl_basename)
239 |     with ZipFile(whl_file) as zipf:
240 |         dist_info = _dist_info_files(zipf)
241 |         zipf.extractall(path=metadata_directory, members=dist_info)
242 |     return dist_info[0].split("/")[0]
243 | 
244 | 
245 | def _find_already_built_wheel(metadata_directory):
246 |     """Check for a wheel already built during the get_wheel_metadata hook."""
247 |     if not metadata_directory:
248 |         return None
249 |     metadata_parent = os.path.dirname(metadata_directory)
250 |     if not os.path.isfile(pjoin(metadata_parent, WHEEL_BUILT_MARKER)):
251 |         return None
252 | 
253 |     whl_files = glob(os.path.join(metadata_parent, "*.whl"))
254 |     if not whl_files:
255 |         print("Found wheel built marker, but no .whl files")
256 |         return None
257 |     if len(whl_files) > 1:
258 |         print(
259 |             "Found multiple .whl files; unspecified behaviour. "
260 |             "Will call build_wheel."
261 |         )
262 |         return None
263 | 
264 |     # Exactly one .whl file
265 |     return whl_files[0]
266 | 
267 | 
268 | def build_wheel(wheel_directory, config_settings, metadata_directory=None):
269 |     """Invoke the mandatory build_wheel hook.
270 | 
271 |     If a wheel was already built in the
272 |     prepare_metadata_for_build_wheel fallback, this
273 |     will copy it rather than rebuilding the wheel.
274 |     """
275 |     prebuilt_whl = _find_already_built_wheel(metadata_directory)
276 |     if prebuilt_whl:
277 |         shutil.copy2(prebuilt_whl, wheel_directory)
278 |         return os.path.basename(prebuilt_whl)
279 | 
280 |     return _build_backend().build_wheel(
281 |         wheel_directory, config_settings, metadata_directory
282 |     )
283 | 
284 | 
285 | def build_editable(wheel_directory, config_settings, metadata_directory=None):
286 |     """Invoke the optional build_editable hook.
287 | 
288 |     If a wheel was already built in the
289 |     prepare_metadata_for_build_editable fallback, this
290 |     will copy it rather than rebuilding the wheel.
291 |     """
292 |     backend = _build_backend()
293 |     try:
294 |         hook = backend.build_editable
295 |     except AttributeError:
296 |         raise HookMissing()
297 |     else:
298 |         prebuilt_whl = _find_already_built_wheel(metadata_directory)
299 |         if prebuilt_whl:
300 |             shutil.copy2(prebuilt_whl, wheel_directory)
301 |             return os.path.basename(prebuilt_whl)
302 | 
303 |         return hook(wheel_directory, config_settings, metadata_directory)
304 | 
305 | 
306 | def get_requires_for_build_sdist(config_settings):
307 |     """Invoke the optional get_requires_for_build_wheel hook
308 | 
309 |     Returns [] if the hook is not defined.
310 |     """
311 |     backend = _build_backend()
312 |     try:
313 |         hook = backend.get_requires_for_build_sdist
314 |     except AttributeError:
315 |         return []
316 |     else:
317 |         return hook(config_settings)
318 | 
319 | 
320 | class _DummyException(Exception):
321 |     """Nothing should ever raise this exception"""
322 | 
323 | 
324 | class GotUnsupportedOperation(Exception):
325 |     """For internal use when backend raises UnsupportedOperation"""
326 | 
327 |     def __init__(self, traceback):
328 |         self.traceback = traceback
329 | 
330 | 
331 | def build_sdist(sdist_directory, config_settings):
332 |     """Invoke the mandatory build_sdist hook."""
333 |     backend = _build_backend()
334 |     try:
335 |         return backend.build_sdist(sdist_directory, config_settings)
336 |     except getattr(backend, "UnsupportedOperation", _DummyException):
337 |         raise GotUnsupportedOperation(traceback.format_exc())
338 | 
339 | 
340 | HOOK_NAMES = {
341 |     "get_requires_for_build_wheel",
342 |     "prepare_metadata_for_build_wheel",
343 |     "build_wheel",
344 |     "get_requires_for_build_editable",
345 |     "prepare_metadata_for_build_editable",
346 |     "build_editable",
347 |     "get_requires_for_build_sdist",
348 |     "build_sdist",
349 |     "_supported_features",
350 | }
351 | 
352 | 
353 | def main():
354 |     if len(sys.argv) < 3:
355 |         sys.exit("Needs args: hook_name, control_dir")
356 |     hook_name = sys.argv[1]
357 |     control_dir = sys.argv[2]
358 |     if hook_name not in HOOK_NAMES:
359 |         sys.exit("Unknown hook: %s" % hook_name)
360 | 
361 |     # Remove the parent directory from sys.path to avoid polluting the backend
362 |     # import namespace with this directory.
363 |     here = os.path.dirname(__file__)
364 |     if here in sys.path:
365 |         sys.path.remove(here)
366 | 
367 |     hook = globals()[hook_name]
368 | 
[TRUNCATED]
```

.venv/lib/python3.13/site-packages/pip/_vendor/resolvelib/resolvers/__init__.py
```
1 | from ..structs import RequirementInformation
2 | from .abstract import AbstractResolver, Result
3 | from .criterion import Criterion
4 | from .exceptions import (
5 |     InconsistentCandidate,
6 |     RequirementsConflicted,
7 |     ResolutionError,
8 |     ResolutionImpossible,
9 |     ResolutionTooDeep,
10 |     ResolverException,
11 | )
12 | from .resolution import Resolution, Resolver
13 | 
14 | __all__ = [
15 |     "AbstractResolver",
16 |     "InconsistentCandidate",
17 |     "Resolver",
18 |     "Resolution",
19 |     "RequirementsConflicted",
20 |     "ResolutionError",
21 |     "ResolutionImpossible",
22 |     "ResolutionTooDeep",
23 |     "RequirementInformation",
24 |     "ResolverException",
25 |     "Result",
26 |     "Criterion",
27 | ]
```

.venv/lib/python3.13/site-packages/pip/_vendor/resolvelib/resolvers/abstract.py
```
1 | from __future__ import annotations
2 | 
3 | import collections
4 | from typing import TYPE_CHECKING, Any, Generic, Iterable, Mapping, NamedTuple
5 | 
6 | from ..structs import CT, KT, RT, DirectedGraph
7 | 
8 | if TYPE_CHECKING:
9 |     from ..providers import AbstractProvider
10 |     from ..reporters import BaseReporter
11 |     from .criterion import Criterion
12 | 
13 |     class Result(NamedTuple, Generic[RT, CT, KT]):
14 |         mapping: Mapping[KT, CT]
15 |         graph: DirectedGraph[KT | None]
16 |         criteria: Mapping[KT, Criterion[RT, CT]]
17 | 
18 | else:
19 |     Result = collections.namedtuple("Result", ["mapping", "graph", "criteria"])
20 | 
21 | 
22 | class AbstractResolver(Generic[RT, CT, KT]):
23 |     """The thing that performs the actual resolution work."""
24 | 
25 |     base_exception = Exception
26 | 
27 |     def __init__(
28 |         self,
29 |         provider: AbstractProvider[RT, CT, KT],
30 |         reporter: BaseReporter[RT, CT, KT],
31 |     ) -> None:
32 |         self.provider = provider
33 |         self.reporter = reporter
34 | 
35 |     def resolve(self, requirements: Iterable[RT], **kwargs: Any) -> Result[RT, CT, KT]:
36 |         """Take a collection of constraints, spit out the resolution result.
37 | 
38 |         This returns a representation of the final resolution state, with one
39 |         guarenteed attribute ``mapping`` that contains resolved candidates as
40 |         values. The keys are their respective identifiers.
41 | 
42 |         :param requirements: A collection of constraints.
43 |         :param kwargs: Additional keyword arguments that subclasses may accept.
44 | 
45 |         :raises: ``self.base_exception`` or its subclass.
46 |         """
47 |         raise NotImplementedError
```

.venv/lib/python3.13/site-packages/pip/_vendor/resolvelib/resolvers/criterion.py
```
1 | from __future__ import annotations
2 | 
3 | from typing import Collection, Generic, Iterable, Iterator
4 | 
5 | from ..structs import CT, RT, RequirementInformation
6 | 
7 | 
8 | class Criterion(Generic[RT, CT]):
9 |     """Representation of possible resolution results of a package.
10 | 
11 |     This holds three attributes:
12 | 
13 |     * `information` is a collection of `RequirementInformation` pairs.
14 |       Each pair is a requirement contributing to this criterion, and the
15 |       candidate that provides the requirement.
16 |     * `incompatibilities` is a collection of all known not-to-work candidates
17 |       to exclude from consideration.
18 |     * `candidates` is a collection containing all possible candidates deducted
19 |       from the union of contributing requirements and known incompatibilities.
20 |       It should never be empty, except when the criterion is an attribute of a
21 |       raised `RequirementsConflicted` (in which case it is always empty).
22 | 
23 |     .. note::
24 |         This class is intended to be externally immutable. **Do not** mutate
25 |         any of its attribute containers.
26 |     """
27 | 
28 |     def __init__(
29 |         self,
30 |         candidates: Iterable[CT],
31 |         information: Collection[RequirementInformation[RT, CT]],
32 |         incompatibilities: Collection[CT],
33 |     ) -> None:
34 |         self.candidates = candidates
35 |         self.information = information
36 |         self.incompatibilities = incompatibilities
37 | 
38 |     def __repr__(self) -> str:
39 |         requirements = ", ".join(
40 |             f"({req!r}, via={parent!r})" for req, parent in self.information
41 |         )
42 |         return f"Criterion({requirements})"
43 | 
44 |     def iter_requirement(self) -> Iterator[RT]:
45 |         return (i.requirement for i in self.information)
46 | 
47 |     def iter_parent(self) -> Iterator[CT | None]:
48 |         return (i.parent for i in self.information)
```

.venv/lib/python3.13/site-packages/pip/_vendor/resolvelib/resolvers/exceptions.py
```
1 | from __future__ import annotations
2 | 
3 | from typing import TYPE_CHECKING, Collection, Generic
4 | 
5 | from ..structs import CT, RT, RequirementInformation
6 | 
7 | if TYPE_CHECKING:
8 |     from .criterion import Criterion
9 | 
10 | 
11 | class ResolverException(Exception):
12 |     """A base class for all exceptions raised by this module.
13 | 
14 |     Exceptions derived by this class should all be handled in this module. Any
15 |     bubbling pass the resolver should be treated as a bug.
16 |     """
17 | 
18 | 
19 | class RequirementsConflicted(ResolverException, Generic[RT, CT]):
20 |     def __init__(self, criterion: Criterion[RT, CT]) -> None:
21 |         super().__init__(criterion)
22 |         self.criterion = criterion
23 | 
24 |     def __str__(self) -> str:
25 |         return "Requirements conflict: {}".format(
26 |             ", ".join(repr(r) for r in self.criterion.iter_requirement()),
27 |         )
28 | 
29 | 
30 | class InconsistentCandidate(ResolverException, Generic[RT, CT]):
31 |     def __init__(self, candidate: CT, criterion: Criterion[RT, CT]):
32 |         super().__init__(candidate, criterion)
33 |         self.candidate = candidate
34 |         self.criterion = criterion
35 | 
36 |     def __str__(self) -> str:
37 |         return "Provided candidate {!r} does not satisfy {}".format(
38 |             self.candidate,
39 |             ", ".join(repr(r) for r in self.criterion.iter_requirement()),
40 |         )
41 | 
42 | 
43 | class ResolutionError(ResolverException):
44 |     pass
45 | 
46 | 
47 | class ResolutionImpossible(ResolutionError, Generic[RT, CT]):
48 |     def __init__(self, causes: Collection[RequirementInformation[RT, CT]]):
49 |         super().__init__(causes)
50 |         # causes is a list of RequirementInformation objects
51 |         self.causes = causes
52 | 
53 | 
54 | class ResolutionTooDeep(ResolutionError):
55 |     def __init__(self, round_count: int) -> None:
56 |         super().__init__(round_count)
57 |         self.round_count = round_count
```

.venv/lib/python3.13/site-packages/pip/_vendor/resolvelib/resolvers/resolution.py
```
1 | from __future__ import annotations
2 | 
3 | import collections
4 | import itertools
5 | import operator
6 | from typing import TYPE_CHECKING, Collection, Generic, Iterable, Mapping
7 | 
8 | from ..structs import (
9 |     CT,
10 |     KT,
11 |     RT,
12 |     DirectedGraph,
13 |     IterableView,
14 |     IteratorMapping,
15 |     RequirementInformation,
16 |     State,
17 |     build_iter_view,
18 | )
19 | from .abstract import AbstractResolver, Result
20 | from .criterion import Criterion
21 | from .exceptions import (
22 |     InconsistentCandidate,
23 |     RequirementsConflicted,
24 |     ResolutionImpossible,
25 |     ResolutionTooDeep,
26 |     ResolverException,
27 | )
28 | 
29 | if TYPE_CHECKING:
30 |     from ..providers import AbstractProvider, Preference
31 |     from ..reporters import BaseReporter
32 | 
33 | 
34 | def _build_result(state: State[RT, CT, KT]) -> Result[RT, CT, KT]:
35 |     mapping = state.mapping
36 |     all_keys: dict[int, KT | None] = {id(v): k for k, v in mapping.items()}
37 |     all_keys[id(None)] = None
38 | 
39 |     graph: DirectedGraph[KT | None] = DirectedGraph()
40 |     graph.add(None)  # Sentinel as root dependencies' parent.
41 | 
42 |     connected: set[KT | None] = {None}
43 |     for key, criterion in state.criteria.items():
44 |         if not _has_route_to_root(state.criteria, key, all_keys, connected):
45 |             continue
46 |         if key not in graph:
47 |             graph.add(key)
48 |         for p in criterion.iter_parent():
49 |             try:
50 |                 pkey = all_keys[id(p)]
51 |             except KeyError:
52 |                 continue
53 |             if pkey not in graph:
54 |                 graph.add(pkey)
55 |             graph.connect(pkey, key)
56 | 
57 |     return Result(
58 |         mapping={k: v for k, v in mapping.items() if k in connected},
59 |         graph=graph,
60 |         criteria=state.criteria,
61 |     )
62 | 
63 | 
64 | class Resolution(Generic[RT, CT, KT]):
65 |     """Stateful resolution object.
66 | 
67 |     This is designed as a one-off object that holds information to kick start
68 |     the resolution process, and holds the results afterwards.
69 |     """
70 | 
71 |     def __init__(
72 |         self,
73 |         provider: AbstractProvider[RT, CT, KT],
74 |         reporter: BaseReporter[RT, CT, KT],
75 |     ) -> None:
76 |         self._p = provider
77 |         self._r = reporter
78 |         self._states: list[State[RT, CT, KT]] = []
79 | 
80 |     @property
81 |     def state(self) -> State[RT, CT, KT]:
82 |         try:
83 |             return self._states[-1]
84 |         except IndexError as e:
85 |             raise AttributeError("state") from e
86 | 
87 |     def _push_new_state(self) -> None:
88 |         """Push a new state into history.
89 | 
90 |         This new state will be used to hold resolution results of the next
91 |         coming round.
92 |         """
93 |         base = self._states[-1]
94 |         state = State(
95 |             mapping=base.mapping.copy(),
96 |             criteria=base.criteria.copy(),
97 |             backtrack_causes=base.backtrack_causes[:],
98 |         )
99 |         self._states.append(state)
100 | 
101 |     def _add_to_criteria(
102 |         self,
103 |         criteria: dict[KT, Criterion[RT, CT]],
104 |         requirement: RT,
105 |         parent: CT | None,
106 |     ) -> None:
107 |         self._r.adding_requirement(requirement=requirement, parent=parent)
108 | 
109 |         identifier = self._p.identify(requirement_or_candidate=requirement)
110 |         criterion = criteria.get(identifier)
111 |         if criterion:
112 |             incompatibilities = list(criterion.incompatibilities)
113 |         else:
114 |             incompatibilities = []
115 | 
116 |         matches = self._p.find_matches(
117 |             identifier=identifier,
118 |             requirements=IteratorMapping(
119 |                 criteria,
120 |                 operator.methodcaller("iter_requirement"),
121 |                 {identifier: [requirement]},
122 |             ),
123 |             incompatibilities=IteratorMapping(
124 |                 criteria,
125 |                 operator.attrgetter("incompatibilities"),
126 |                 {identifier: incompatibilities},
127 |             ),
128 |         )
129 | 
130 |         if criterion:
131 |             information = list(criterion.information)
132 |             information.append(RequirementInformation(requirement, parent))
133 |         else:
134 |             information = [RequirementInformation(requirement, parent)]
135 | 
136 |         criterion = Criterion(
137 |             candidates=build_iter_view(matches),
138 |             information=information,
139 |             incompatibilities=incompatibilities,
140 |         )
141 |         if not criterion.candidates:
142 |             raise RequirementsConflicted(criterion)
143 |         criteria[identifier] = criterion
144 | 
145 |     def _remove_information_from_criteria(
146 |         self, criteria: dict[KT, Criterion[RT, CT]], parents: Collection[KT]
147 |     ) -> None:
148 |         """Remove information from parents of criteria.
149 | 
150 |         Concretely, removes all values from each criterion's ``information``
151 |         field that have one of ``parents`` as provider of the requirement.
152 | 
153 |         :param criteria: The criteria to update.
154 |         :param parents: Identifiers for which to remove information from all criteria.
155 |         """
156 |         if not parents:
157 |             return
158 |         for key, criterion in criteria.items():
159 |             criteria[key] = Criterion(
160 |                 criterion.candidates,
161 |                 [
162 |                     information
163 |                     for information in criterion.information
164 |                     if (
165 |                         information.parent is None
166 |                         or self._p.identify(information.parent) not in parents
167 |                     )
168 |                 ],
169 |                 criterion.incompatibilities,
170 |             )
171 | 
172 |     def _get_preference(self, name: KT) -> Preference:
173 |         return self._p.get_preference(
174 |             identifier=name,
175 |             resolutions=self.state.mapping,
176 |             candidates=IteratorMapping(
177 |                 self.state.criteria,
178 |                 operator.attrgetter("candidates"),
179 |             ),
180 |             information=IteratorMapping(
181 |                 self.state.criteria,
182 |                 operator.attrgetter("information"),
183 |             ),
184 |             backtrack_causes=self.state.backtrack_causes,
185 |         )
186 | 
187 |     def _is_current_pin_satisfying(
188 |         self, name: KT, criterion: Criterion[RT, CT]
189 |     ) -> bool:
190 |         try:
191 |             current_pin = self.state.mapping[name]
192 |         except KeyError:
193 |             return False
194 |         return all(
195 |             self._p.is_satisfied_by(requirement=r, candidate=current_pin)
196 |             for r in criterion.iter_requirement()
197 |         )
198 | 
199 |     def _get_updated_criteria(self, candidate: CT) -> dict[KT, Criterion[RT, CT]]:
200 |         criteria = self.state.criteria.copy()
201 |         for requirement in self._p.get_dependencies(candidate=candidate):
202 |             self._add_to_criteria(criteria, requirement, parent=candidate)
203 |         return criteria
204 | 
205 |     def _attempt_to_pin_criterion(self, name: KT) -> list[Criterion[RT, CT]]:
206 |         criterion = self.state.criteria[name]
207 | 
208 |         causes: list[Criterion[RT, CT]] = []
209 |         for candidate in criterion.candidates:
210 |             try:
211 |                 criteria = self._get_updated_criteria(candidate)
212 |             except RequirementsConflicted as e:
213 |                 self._r.rejecting_candidate(e.criterion, candidate)
214 |                 causes.append(e.criterion)
215 |                 continue
216 | 
217 |             # Check the newly-pinned candidate actually works. This should
218 |             # always pass under normal circumstances, but in the case of a
219 |             # faulty provider, we will raise an error to notify the implementer
220 |             # to fix find_matches() and/or is_satisfied_by().
221 |             satisfied = all(
222 |                 self._p.is_satisfied_by(requirement=r, candidate=candidate)
223 |                 for r in criterion.iter_requirement()
224 |             )
225 |             if not satisfied:
226 |                 raise InconsistentCandidate(candidate, criterion)
227 | 
228 |             self._r.pinning(candidate=candidate)
229 |             self.state.criteria.update(criteria)
230 | 
231 |             # Put newly-pinned candidate at the end. This is essential because
232 |             # backtracking looks at this mapping to get the last pin.
233 |             self.state.mapping.pop(name, None)
234 |             self.state.mapping[name] = candidate
235 | 
236 |             return []
237 | 
238 |         # All candidates tried, nothing works. This criterion is a dead
239 |         # end, signal for backtracking.
240 |         return causes
241 | 
242 |     def _patch_criteria(
243 |         self, incompatibilities_from_broken: list[tuple[KT, list[CT]]]
244 |     ) -> bool:
245 |         # Create a new state from the last known-to-work one, and apply
246 |         # the previously gathered incompatibility information.
247 |         for k, incompatibilities in incompatibilities_from_broken:
248 |             if not incompatibilities:
249 |                 continue
250 |             try:
251 |                 criterion = self.state.criteria[k]
252 |             except KeyError:
253 |                 continue
254 |             matches = self._p.find_matches(
255 |                 identifier=k,
256 |                 requirements=IteratorMapping(
257 |                     self.state.criteria,
258 |                     operator.methodcaller("iter_requirement"),
259 |                 ),
260 |                 incompatibilities=IteratorMapping(
261 |                     self.state.criteria,
262 |                     operator.attrgetter("incompatibilities"),
263 |                     {k: incompatibilities},
264 |                 ),
265 |             )
266 |             candidates: IterableView[CT] = build_iter_view(matches)
267 |             if not candidates:
268 |                 return False
269 |             incompatibilities.extend(criterion.incompatibilities)
270 |             self.state.criteria[k] = Criterion(
271 |                 candidates=candidates,
272 |                 information=list(criterion.information),
273 |                 incompatibilities=incompatibilities,
274 |             )
275 |         return True
276 | 
277 |     def _backjump(self, causes: list[RequirementInformation[RT, CT]]) -> bool:
278 |         """Perform backjumping.
279 | 
280 |         When we enter here, the stack is like this::
281 | 
282 |             [ state Z ]
283 |             [ state Y ]
284 |             [ state X ]
285 |             .... earlier states are irrelevant.
286 | 
287 |         1. No pins worked for Z, so it does not have a pin.
288 |         2. We want to reset state Y to unpinned, and pin another candidate.
289 |         3. State X holds what state Y was before the pin, but does not
290 |            have the incompatibility information gathered in state Y.
291 | 
292 |         Each iteration of the loop will:
293 | 
294 |         1.  Identify Z. The incompatibility is not always caused by the latest
295 |             state. For example, given three requirements A, B and C, with
296 |             dependencies A1, B1 and C1, where A1 and B1 are incompatible: the
297 |             last state might be related to C, so we want to discard the
298 |             previous state.
299 |         2.  Discard Z.
300 |         3.  Discard Y but remember its incompatibility information gathered
301 |             previously, and the failure we're dealing with right now.
302 |         4.  Push a new state Y' based on X, and apply the incompatibility
303 |             information from Y to Y'.
304 |         5a. If this causes Y' to conflict, we need to backtrack again. Make Y'
305 |             the new Z and go back to step 2.
306 |         5b. If the incompatibilities apply cleanly, end backtracking.
307 |         """
308 |         incompatible_reqs: Iterable[CT | RT] = itertools.chain(
309 |             (c.parent for c in causes if c.parent is not None),
310 |             (c.requirement for c in causes),
311 |         )
312 |         incompatible_deps = {self._p.identify(r) for r in incompatible_reqs}
313 |         while len(self._states) >= 3:
314 |             # Remove the state that triggered backtracking.
315 |             del self._states[-1]
316 | 
317 |             # Optimistically backtrack to a state that caused the incompatibility
318 |             broken_state = self.state
319 |             while True:
320 |                 # Retrieve the last candidate pin and known incompatibilities.
321 |                 try:
322 |                     broken_state = self._states.pop()
323 |                     name, candidate = broken_state.mapping.popitem()
324 |                 except (IndexError, KeyError):
325 |                     raise ResolutionImpossible(causes) from None
326 | 
327 |                 # Only backjump if the current broken state is
328 |                 # an incompatible dependency
329 |                 if name not in incompatible_deps:
330 |                     break
331 | 
332 |                 # If the current dependencies and the incompatible dependencies
333 |                 # are overlapping then we have found a cause of the incompatibility
334 |                 current_dependencies = {
335 |                     self._p.identify(d) for d in self._p.get_dependencies(candidate)
336 |                 }
337 |                 if not current_dependencies.isdisjoint(incompatible_deps):
338 |                     break
339 | 
340 |                 # Fallback: We should not backtrack to the point where
341 |                 # broken_state.mapping is empty, so stop backtracking for
342 |                 # a chance for the resolution to recover
343 |                 if not broken_state.mapping:
344 |                     break
345 | 
346 |             incompatibilities_from_broken = [
347 |                 (k, list(v.incompatibilities)) for k, v in broken_state.criteria.items()
348 |             ]
349 | 
350 |             # Also mark the newly known incompatibility.
351 |             incompatibilities_from_broken.append((name, [candidate]))
352 | 
353 |             self._push_new_state()
354 |             success = self._patch_criteria(incompatibilities_from_broken)
355 | 
356 |             # It works! Let's work on this new state.
357 |             if success:
358 |                 return True
359 | 
360 |             # State does not work after applying known incompatibilities.
361 |             # Try the still previous state.
362 | 
363 |         # No way to backtrack anymore.
364 |         return False
365 | 
366 |     def _extract_causes(
367 |         self, criteron: list[Criterion[RT, CT]]
368 |     ) -> list[RequirementInformation[RT, CT]]:
369 |         """Extract causes from list of criterion and deduplicate"""
370 |         return list({id(i): i for c in criteron for i in c.information}.values())
371 | 
372 |     def resolve(self, requirements: Iterable[RT], max_rounds: int) -> State[RT, CT, KT]:
373 |         if self._states:
374 |             raise RuntimeError("already resolved")
375 | 
376 |         self._r.starting()
377 | 
378 |         # Initialize the root state.
379 |         self._states = [
380 |             State(
381 |                 mapping=collections.OrderedDict(),
382 |                 criteria={},
[TRUNCATED]
```

.venv/lib/python3.13/site-packages/pip/_vendor/pygments/filters/__init__.py
```
1 | """
2 |     pygments.filters
3 |     ~~~~~~~~~~~~~~~~
4 | 
5 |     Module containing filter lookup functions and default
6 |     filters.
7 | 
8 |     :copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
9 |     :license: BSD, see LICENSE for details.
10 | """
11 | 
12 | import re
13 | 
14 | from pip._vendor.pygments.token import String, Comment, Keyword, Name, Error, Whitespace, \
15 |     string_to_tokentype
16 | from pip._vendor.pygments.filter import Filter
17 | from pip._vendor.pygments.util import get_list_opt, get_int_opt, get_bool_opt, \
18 |     get_choice_opt, ClassNotFound, OptionError
19 | from pip._vendor.pygments.plugin import find_plugin_filters
20 | 
21 | 
22 | def find_filter_class(filtername):
23 |     """Lookup a filter by name. Return None if not found."""
24 |     if filtername in FILTERS:
25 |         return FILTERS[filtername]
26 |     for name, cls in find_plugin_filters():
27 |         if name == filtername:
28 |             return cls
29 |     return None
30 | 
31 | 
32 | def get_filter_by_name(filtername, **options):
33 |     """Return an instantiated filter.
34 | 
35 |     Options are passed to the filter initializer if wanted.
36 |     Raise a ClassNotFound if not found.
37 |     """
38 |     cls = find_filter_class(filtername)
39 |     if cls:
40 |         return cls(**options)
41 |     else:
42 |         raise ClassNotFound(f'filter {filtername!r} not found')
43 | 
44 | 
45 | def get_all_filters():
46 |     """Return a generator of all filter names."""
47 |     yield from FILTERS
48 |     for name, _ in find_plugin_filters():
49 |         yield name
50 | 
51 | 
52 | def _replace_special(ttype, value, regex, specialttype,
53 |                      replacefunc=lambda x: x):
54 |     last = 0
55 |     for match in regex.finditer(value):
56 |         start, end = match.start(), match.end()
57 |         if start != last:
58 |             yield ttype, value[last:start]
59 |         yield specialttype, replacefunc(value[start:end])
60 |         last = end
61 |     if last != len(value):
62 |         yield ttype, value[last:]
63 | 
64 | 
65 | class CodeTagFilter(Filter):
66 |     """Highlight special code tags in comments and docstrings.
67 | 
68 |     Options accepted:
69 | 
70 |     `codetags` : list of strings
71 |        A list of strings that are flagged as code tags.  The default is to
72 |        highlight ``XXX``, ``TODO``, ``FIXME``, ``BUG`` and ``NOTE``.
73 | 
74 |     .. versionchanged:: 2.13
75 |        Now recognizes ``FIXME`` by default.
76 |     """
77 | 
78 |     def __init__(self, **options):
79 |         Filter.__init__(self, **options)
80 |         tags = get_list_opt(options, 'codetags',
81 |                             ['XXX', 'TODO', 'FIXME', 'BUG', 'NOTE'])
82 |         self.tag_re = re.compile(r'\b({})\b'.format('|'.join([
83 |             re.escape(tag) for tag in tags if tag
84 |         ])))
85 | 
86 |     def filter(self, lexer, stream):
87 |         regex = self.tag_re
88 |         for ttype, value in stream:
89 |             if ttype in String.Doc or \
90 |                ttype in Comment and \
91 |                ttype not in Comment.Preproc:
92 |                 yield from _replace_special(ttype, value, regex, Comment.Special)
93 |             else:
94 |                 yield ttype, value
95 | 
96 | 
97 | class SymbolFilter(Filter):
98 |     """Convert mathematical symbols such as \\<longrightarrow> in Isabelle
99 |     or \\longrightarrow in LaTeX into Unicode characters.
100 | 
101 |     This is mostly useful for HTML or console output when you want to
102 |     approximate the source rendering you'd see in an IDE.
103 | 
104 |     Options accepted:
105 | 
106 |     `lang` : string
107 |        The symbol language. Must be one of ``'isabelle'`` or
108 |        ``'latex'``.  The default is ``'isabelle'``.
109 |     """
110 | 
111 |     latex_symbols = {
112 |         '\\alpha'                : '\U000003b1',
113 |         '\\beta'                 : '\U000003b2',
114 |         '\\gamma'                : '\U000003b3',
115 |         '\\delta'                : '\U000003b4',
116 |         '\\varepsilon'           : '\U000003b5',
117 |         '\\zeta'                 : '\U000003b6',
118 |         '\\eta'                  : '\U000003b7',
119 |         '\\vartheta'             : '\U000003b8',
120 |         '\\iota'                 : '\U000003b9',
121 |         '\\kappa'                : '\U000003ba',
122 |         '\\lambda'               : '\U000003bb',
123 |         '\\mu'                   : '\U000003bc',
124 |         '\\nu'                   : '\U000003bd',
125 |         '\\xi'                   : '\U000003be',
126 |         '\\pi'                   : '\U000003c0',
127 |         '\\varrho'               : '\U000003c1',
128 |         '\\sigma'                : '\U000003c3',
129 |         '\\tau'                  : '\U000003c4',
130 |         '\\upsilon'              : '\U000003c5',
131 |         '\\varphi'               : '\U000003c6',
132 |         '\\chi'                  : '\U000003c7',
133 |         '\\psi'                  : '\U000003c8',
134 |         '\\omega'                : '\U000003c9',
135 |         '\\Gamma'                : '\U00000393',
136 |         '\\Delta'                : '\U00000394',
137 |         '\\Theta'                : '\U00000398',
138 |         '\\Lambda'               : '\U0000039b',
139 |         '\\Xi'                   : '\U0000039e',
140 |         '\\Pi'                   : '\U000003a0',
141 |         '\\Sigma'                : '\U000003a3',
142 |         '\\Upsilon'              : '\U000003a5',
143 |         '\\Phi'                  : '\U000003a6',
144 |         '\\Psi'                  : '\U000003a8',
145 |         '\\Omega'                : '\U000003a9',
146 |         '\\leftarrow'            : '\U00002190',
147 |         '\\longleftarrow'        : '\U000027f5',
148 |         '\\rightarrow'           : '\U00002192',
149 |         '\\longrightarrow'       : '\U000027f6',
150 |         '\\Leftarrow'            : '\U000021d0',
151 |         '\\Longleftarrow'        : '\U000027f8',
152 |         '\\Rightarrow'           : '\U000021d2',
153 |         '\\Longrightarrow'       : '\U000027f9',
154 |         '\\leftrightarrow'       : '\U00002194',
155 |         '\\longleftrightarrow'   : '\U000027f7',
156 |         '\\Leftrightarrow'       : '\U000021d4',
157 |         '\\Longleftrightarrow'   : '\U000027fa',
158 |         '\\mapsto'               : '\U000021a6',
159 |         '\\longmapsto'           : '\U000027fc',
160 |         '\\relbar'               : '\U00002500',
161 |         '\\Relbar'               : '\U00002550',
162 |         '\\hookleftarrow'        : '\U000021a9',
163 |         '\\hookrightarrow'       : '\U000021aa',
164 |         '\\leftharpoondown'      : '\U000021bd',
165 |         '\\rightharpoondown'     : '\U000021c1',
166 |         '\\leftharpoonup'        : '\U000021bc',
167 |         '\\rightharpoonup'       : '\U000021c0',
168 |         '\\rightleftharpoons'    : '\U000021cc',
169 |         '\\leadsto'              : '\U0000219d',
170 |         '\\downharpoonleft'      : '\U000021c3',
171 |         '\\downharpoonright'     : '\U000021c2',
172 |         '\\upharpoonleft'        : '\U000021bf',
173 |         '\\upharpoonright'       : '\U000021be',
174 |         '\\restriction'          : '\U000021be',
175 |         '\\uparrow'              : '\U00002191',
176 |         '\\Uparrow'              : '\U000021d1',
177 |         '\\downarrow'            : '\U00002193',
178 |         '\\Downarrow'            : '\U000021d3',
179 |         '\\updownarrow'          : '\U00002195',
180 |         '\\Updownarrow'          : '\U000021d5',
181 |         '\\langle'               : '\U000027e8',
182 |         '\\rangle'               : '\U000027e9',
183 |         '\\lceil'                : '\U00002308',
184 |         '\\rceil'                : '\U00002309',
185 |         '\\lfloor'               : '\U0000230a',
186 |         '\\rfloor'               : '\U0000230b',
187 |         '\\flqq'                 : '\U000000ab',
188 |         '\\frqq'                 : '\U000000bb',
189 |         '\\bot'                  : '\U000022a5',
190 |         '\\top'                  : '\U000022a4',
191 |         '\\wedge'                : '\U00002227',
192 |         '\\bigwedge'             : '\U000022c0',
193 |         '\\vee'                  : '\U00002228',
194 |         '\\bigvee'               : '\U000022c1',
195 |         '\\forall'               : '\U00002200',
196 |         '\\exists'               : '\U00002203',
197 |         '\\nexists'              : '\U00002204',
198 |         '\\neg'                  : '\U000000ac',
199 |         '\\Box'                  : '\U000025a1',
200 |         '\\Diamond'              : '\U000025c7',
201 |         '\\vdash'                : '\U000022a2',
202 |         '\\models'               : '\U000022a8',
203 |         '\\dashv'                : '\U000022a3',
204 |         '\\surd'                 : '\U0000221a',
205 |         '\\le'                   : '\U00002264',
206 |         '\\ge'                   : '\U00002265',
207 |         '\\ll'                   : '\U0000226a',
208 |         '\\gg'                   : '\U0000226b',
209 |         '\\lesssim'              : '\U00002272',
210 |         '\\gtrsim'               : '\U00002273',
211 |         '\\lessapprox'           : '\U00002a85',
212 |         '\\gtrapprox'            : '\U00002a86',
213 |         '\\in'                   : '\U00002208',
214 |         '\\notin'                : '\U00002209',
215 |         '\\subset'               : '\U00002282',
216 |         '\\supset'               : '\U00002283',
217 |         '\\subseteq'             : '\U00002286',
218 |         '\\supseteq'             : '\U00002287',
219 |         '\\sqsubset'             : '\U0000228f',
220 |         '\\sqsupset'             : '\U00002290',
221 |         '\\sqsubseteq'           : '\U00002291',
222 |         '\\sqsupseteq'           : '\U00002292',
223 |         '\\cap'                  : '\U00002229',
224 |         '\\bigcap'               : '\U000022c2',
225 |         '\\cup'                  : '\U0000222a',
226 |         '\\bigcup'               : '\U000022c3',
227 |         '\\sqcup'                : '\U00002294',
228 |         '\\bigsqcup'             : '\U00002a06',
229 |         '\\sqcap'                : '\U00002293',
230 |         '\\Bigsqcap'             : '\U00002a05',
231 |         '\\setminus'             : '\U00002216',
232 |         '\\propto'               : '\U0000221d',
233 |         '\\uplus'                : '\U0000228e',
234 |         '\\bigplus'              : '\U00002a04',
235 |         '\\sim'                  : '\U0000223c',
236 |         '\\doteq'                : '\U00002250',
237 |         '\\simeq'                : '\U00002243',
238 |         '\\approx'               : '\U00002248',
239 |         '\\asymp'                : '\U0000224d',
240 |         '\\cong'                 : '\U00002245',
241 |         '\\equiv'                : '\U00002261',
242 |         '\\Join'                 : '\U000022c8',
243 |         '\\bowtie'               : '\U00002a1d',
244 |         '\\prec'                 : '\U0000227a',
245 |         '\\succ'                 : '\U0000227b',
246 |         '\\preceq'               : '\U0000227c',
247 |         '\\succeq'               : '\U0000227d',
248 |         '\\parallel'             : '\U00002225',
249 |         '\\mid'                  : '\U000000a6',
250 |         '\\pm'                   : '\U000000b1',
251 |         '\\mp'                   : '\U00002213',
252 |         '\\times'                : '\U000000d7',
253 |         '\\div'                  : '\U000000f7',
254 |         '\\cdot'                 : '\U000022c5',
255 |         '\\star'                 : '\U000022c6',
256 |         '\\circ'                 : '\U00002218',
257 |         '\\dagger'               : '\U00002020',
258 |         '\\ddagger'              : '\U00002021',
259 |         '\\lhd'                  : '\U000022b2',
260 |         '\\rhd'                  : '\U000022b3',
261 |         '\\unlhd'                : '\U000022b4',
262 |         '\\unrhd'                : '\U000022b5',
263 |         '\\triangleleft'         : '\U000025c3',
264 |         '\\triangleright'        : '\U000025b9',
265 |         '\\triangle'             : '\U000025b3',
266 |         '\\triangleq'            : '\U0000225c',
267 |         '\\oplus'                : '\U00002295',
268 |         '\\bigoplus'             : '\U00002a01',
269 |         '\\otimes'               : '\U00002297',
270 |         '\\bigotimes'            : '\U00002a02',
271 |         '\\odot'                 : '\U00002299',
272 |         '\\bigodot'              : '\U00002a00',
273 |         '\\ominus'               : '\U00002296',
274 |         '\\oslash'               : '\U00002298',
275 |         '\\dots'                 : '\U00002026',
276 |         '\\cdots'                : '\U000022ef',
277 |         '\\sum'                  : '\U00002211',
278 |         '\\prod'                 : '\U0000220f',
279 |         '\\coprod'               : '\U00002210',
280 |         '\\infty'                : '\U0000221e',
281 |         '\\int'                  : '\U0000222b',
282 |         '\\oint'                 : '\U0000222e',
283 |         '\\clubsuit'             : '\U00002663',
284 |         '\\diamondsuit'          : '\U00002662',
285 |         '\\heartsuit'            : '\U00002661',
286 |         '\\spadesuit'            : '\U00002660',
287 |         '\\aleph'                : '\U00002135',
288 |         '\\emptyset'             : '\U00002205',
289 |         '\\nabla'                : '\U00002207',
290 |         '\\partial'              : '\U00002202',
291 |         '\\flat'                 : '\U0000266d',
292 |         '\\natural'              : '\U0000266e',
293 |         '\\sharp'                : '\U0000266f',
294 |         '\\angle'                : '\U00002220',
295 |         '\\copyright'            : '\U000000a9',
296 |         '\\textregistered'       : '\U000000ae',
297 |         '\\textonequarter'       : '\U000000bc',
298 |         '\\textonehalf'          : '\U000000bd',
299 |         '\\textthreequarters'    : '\U000000be',
300 |         '\\textordfeminine'      : '\U000000aa',
301 |         '\\textordmasculine'     : '\U000000ba',
302 |         '\\euro'                 : '\U000020ac',
303 |         '\\pounds'               : '\U000000a3',
304 |         '\\yen'                  : '\U000000a5',
305 |         '\\textcent'             : '\U000000a2',
306 |         '\\textcurrency'         : '\U000000a4',
307 |         '\\textdegree'           : '\U000000b0',
308 |     }
309 | 
310 |     isabelle_symbols = {
311 |         '\\<zero>'                 : '\U0001d7ec',
312 |         '\\<one>'                  : '\U0001d7ed',
313 |         '\\<two>'                  : '\U0001d7ee',
314 |         '\\<three>'                : '\U0001d7ef',
315 |         '\\<four>'                 : '\U0001d7f0',
316 |         '\\<five>'                 : '\U0001d7f1',
317 |         '\\<six>'                  : '\U0001d7f2',
318 |         '\\<seven>'                : '\U0001d7f3',
319 |         '\\<eight>'                : '\U0001d7f4',
320 |         '\\<nine>'                 : '\U0001d7f5',
321 |         '\\<A>'                    : '\U0001d49c',
322 |         '\\<B>'                    : '\U0000212c',
323 |         '\\<C>'                    : '\U0001d49e',
324 |         '\\<D>'                    : '\U0001d49f',
325 |         '\\<E>'                    : '\U00002130',
326 |         '\\<F>'                    : '\U00002131',
327 |         '\\<G>'                    : '\U0001d4a2',
328 |         '\\<H>'                    : '\U0000210b',
329 |         '\\<I>'                    : '\U00002110',
330 |         '\\<J>'                    : '\U0001d4a5',
331 |         '\\<K>'                    : '\U0001d4a6',
332 |         '\\<L>'                    : '\U00002112',
333 |         '\\<M>'                    : '\U00002133',
334 |         '\\<N>'                    : '\U0001d4a9',
335 |         '\\<O>'                    : '\U0001d4aa',
336 |         '\\<P>'                    : '\U0001d4ab',
337 |         '\\<Q>'                    : '\U0001d4ac',
338 |         '\\<R>'                    : '\U0000211b',
339 |         '\\<S>'                    : '\U0001d4ae',
340 |         '\\<T>'                    : '\U0001d4af',
341 |         '\\<U>'                    : '\U0001d4b0',
342 |         '\\<V>'                    : '\U0001d4b1',
343 |         '\\<W>'                    : '\U0001d4b2',
344 |         '\\<X>'                    : '\U0001d4b3',
345 |         '\\<Y>'                    : '\U0001d4b4',
346 |         '\\<Z>'                    : '\U0001d4b5',
347 |         '\\<a>'                    : '\U0001d5ba',
348 |         '\\<b>'                    : '\U0001d5bb',
349 |         '\\<c>'                    : '\U0001d5bc',
350 |         '\\<d>'                    : '\U0001d5bd',
351 |         '\\<e>'                    : '\U0001d5be',
352 |         '\\<f>'                    : '\U0001d5bf',
353 |         '\\<g>'                    : '\U0001d5c0',
354 |         '\\<h>'                    : '\U0001d5c1',
355 |         '\\<i>'                    : '\U0001d5c2',
356 |         '\\<j>'                    : '\U0001d5c3',
357 |         '\\<k>'                    : '\U0001d5c4',
358 |         '\\<l>'                    : '\U0001d5c5',
359 |         '\\<m>'                    : '\U0001d5c6',
360 |         '\\<n>'                    : '\U0001d5c7',
361 |         '\\<o>'                    : '\U0001d5c8',
362 |         '\\<p>'                    : '\U0001d5c9',
363 |         '\\<q>'                    : '\U0001d5ca',
364 |         '\\<r>'                    : '\U0001d5cb',
365 |         '\\<s>'                    : '\U0001d5cc',
366 |         '\\<t>'                    : '\U0001d5cd',
367 |         '\\<u>'                    : '\U0001d5ce',
368 |         '\\<v>'                    : '\U0001d5cf',
369 |         '\\<w>'                    : '\U0001d5d0',
370 |         '\\<x>'                    : '\U0001d5d1',
371 |         '\\<y>'                    : '\U0001d5d2',
372 |         '\\<z>'                    : '\U0001d5d3',
373 |         '\\<AA>'                   : '\U0001d504',
374 |         '\\<BB>'                   : '\U0001d505',
375 |         '\\<CC>'                   : '\U0000212d',
376 |         '\\<DD>'                   : '\U0001d507',
377 |         '\\<EE>'                   : '\U0001d508',
378 |         '\\<FF>'                   : '\U0001d509',
379 |         '\\<GG>'                   : '\U0001d50a',
380 |         '\\<HH>'                   : '\U0000210c',
381 |         '\\<II>'                   : '\U00002111',
382 |         '\\<JJ>'                   : '\U0001d50d',
383 |         '\\<KK>'                   : '\U0001d50e',
384 |         '\\<LL>'                   : '\U0001d50f',
385 |         '\\<MM>'                   : '\U0001d510',
386 |         '\\<NN>'                   : '\U0001d511',
387 |         '\\<OO>'                   : '\U0001d512',
388 |         '\\<PP>'                   : '\U0001d513',
389 |         '\\<QQ>'                   : '\U0001d514',
390 |         '\\<RR>'                   : '\U0000211c',
391 |         '\\<SS>'                   : '\U0001d516',
392 |         '\\<TT>'                   : '\U0001d517',
393 |         '\\<UU>'                   : '\U0001d518',
394 |         '\\<VV>'                   : '\U0001d519',
395 |         '\\<WW>'                   : '\U0001d51a',
396 |         '\\<XX>'                   : '\U0001d51b',
397 |         '\\<YY>'                   : '\U0001d51c',
398 |         '\\<ZZ>'                   : '\U00002128',
399 |         '\\<aa>'                   : '\U0001d51e',
400 |         '\\<bb>'                   : '\U0001d51f',
401 |         '\\<cc>'                   : '\U0001d520',
402 |         '\\<dd>'                   : '\U0001d521',
403 |         '\\<ee>'                   : '\U0001d522',
404 |         '\\<ff>'                   : '\U0001d523',
405 |         '\\<gg>'                   : '\U0001d524',
406 |         '\\<hh>'                   : '\U0001d525',
407 |         '\\<ii>'                   : '\U0001d526',
408 |         '\\<jj>'                   : '\U0001d527',
409 |         '\\<kk>'                   : '\U0001d528',
410 |         '\\<ll>'                   : '\U0001d529',
411 |         '\\<mm>'                   : '\U0001d52a',
412 |         '\\<nn>'                   : '\U0001d52b',
413 |         '\\<oo>'                   : '\U0001d52c',
414 |         '\\<pp>'                   : '\U0001d52d',
415 |         '\\<qq>'                   : '\U0001d52e',
416 |         '\\<rr>'                   : '\U0001d52f',
417 |         '\\<ss>'                   : '\U0001d530',
418 |         '\\<tt>'                   : '\U0001d531',
419 |         '\\<uu>'                   : '\U0001d532',
420 |         '\\<vv>'                   : '\U0001d533',
421 |         '\\<ww>'                   : '\U0001d534',
422 |         '\\<xx>'                   : '\U0001d535',
423 |         '\\<yy>'                   : '\U0001d536',
424 |         '\\<zz>'                   : '\U0001d537',
425 |         '\\<alpha>'                : '\U000003b1',
426 |         '\\<beta>'                 : '\U000003b2',
427 |         '\\<gamma>'                : '\U000003b3',
428 |         '\\<delta>'                : '\U000003b4',
429 |         '\\<epsilon>'              : '\U000003b5',
430 |         '\\<zeta>'                 : '\U000003b6',
431 |         '\\<eta>'                  : '\U000003b7',
432 |         '\\<theta>'                : '\U000003b8',
433 |         '\\<iota>'                 : '\U000003b9',
434 |         '\\<kappa>'                : '\U000003ba',
435 |         '\\<lambda>'               : '\U000003bb',
436 |         '\\<mu>'                   : '\U000003bc',
437 |         '\\<nu>'                   : '\U000003bd',
438 |         '\\<xi>'                   : '\U000003be',
439 |         '\\<pi>'                   : '\U000003c0',
440 |         '\\<rho>'                  : '\U000003c1',
441 |         '\\<sigma>'                : '\U000003c3',
442 |         '\\<tau>'                  : '\U000003c4',
443 |         '\\<upsilon>'              : '\U000003c5',
444 |         '\\<phi>'                  : '\U000003c6',
445 |         '\\<chi>'                  : '\U000003c7',
446 |         '\\<psi>'                  : '\U000003c8',
447 |         '\\<omega>'                : '\U000003c9',
448 |         '\\<Gamma>'                : '\U00000393',
449 |         '\\<Delta>'                : '\U00000394',
450 |         '\\<Theta>'                : '\U00000398',
451 |         '\\<Lambda>'               : '\U0000039b',
452 |         '\\<Xi>'                   : '\U0000039e',
453 |         '\\<Pi>'                   : '\U000003a0',
454 |         '\\<Sigma>'                : '\U000003a3',
455 |         '\\<Upsilon>'              : '\U000003a5',
456 |         '\\<Phi>'                  : '\U000003a6',
457 |         '\\<Psi>'                  : '\U000003a8',
458 |         '\\<Omega>'                : '\U000003a9',
459 |         '\\<bool>'                 : '\U0001d539',
460 |         '\\<complex>'              : '\U00002102',
461 |         '\\<nat>'                  : '\U00002115',
462 |         '\\<rat>'                  : '\U0000211a',
463 |         '\\<real>'                 : '\U0000211d',
464 |         '\\<int>'                  : '\U00002124',
465 |         '\\<leftarrow>'            : '\U00002190',
466 |         '\\<longleftarrow>'        : '\U000027f5',
467 |         '\\<rightarrow>'           : '\U00002192',
468 |         '\\<longrightarrow>'       : '\U000027f6',
469 |         '\\<Leftarrow>'            : '\U000021d0',
470 |         '\\<Longleftarrow>'        : '\U000027f8',
471 |         '\\<Rightarrow>'           : '\U000021d2',
472 |         '\\<Longrightarrow>'       : '\U000027f9',
473 |         '\\<leftrightarrow>'       : '\U00002194',
474 |         '\\<longleftrightarrow>'   : '\U000027f7',
475 |         '\\<Leftrightarrow>'       : '\U000021d4',
476 |         '\\<Longleftrightarrow>'   : '\U000027fa',
477 |         '\\<mapsto>'               : '\U000021a6',
478 |         '\\<longmapsto>'           : '\U000027fc',
479 |         '\\<midarrow>'             : '\U00002500',
480 |         '\\<Midarrow>'             : '\U00002550',
481 |         '\\<hookleftarrow>'        : '\U000021a9',
482 |         '\\<hookrightarrow>'       : '\U000021aa',
483 |         '\\<leftharpoondown>'      : '\U000021bd',
484 |         '\\<rightharpoondown>'     : '\U000021c1',
485 |         '\\<leftharpoonup>'        : '\U000021bc',
486 |         '\\<rightharpoonup>'       : '\U000021c0',
487 |         '\\<rightleftharpoons>'    : '\U000021cc',
488 |         '\\<leadsto>'              : '\U0000219d',
489 |         '\\<downharpoonleft>'      : '\U000021c3',
490 |         '\\<downharpoonright>'     : '\U000021c2',
491 |         '\\<upharpoonleft>'        : '\U000021bf',
492 |         '\\<upharpoonright>'       : '\U000021be',
493 |         '\\<restriction>'          : '\U000021be',
494 |         '\\<Colon>'                : '\U00002237',
495 |         '\\<up>'                   : '\U00002191',
496 |         '\\<Up>'                   : '\U000021d1',
497 |         '\\<down>'                 : '\U00002193',
498 |         '\\<Down>'                 : '\U000021d3',
499 |         '\\<updown>'               : '\U00002195',
500 |         '\\<Updown>'               : '\U000021d5',
501 |         '\\<langle>'               : '\U000027e8',
502 |         '\\<rangle>'               : '\U000027e9',
503 |         '\\<lceil>'                : '\U00002308',
504 |         '\\<rceil>'                : '\U00002309',
505 |         '\\<lfloor>'               : '\U0000230a',
506 |         '\\<rfloor>'               : '\U0000230b',
507 |         '\\<lparr>'                : '\U00002987',
508 |         '\\<rparr>'                : '\U00002988',
[TRUNCATED]
```

.venv/lib/python3.13/site-packages/pip/_vendor/pygments/formatters/__init__.py
```
1 | """
2 |     pygments.formatters
3 |     ~~~~~~~~~~~~~~~~~~~
4 | 
5 |     Pygments formatters.
6 | 
7 |     :copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
8 |     :license: BSD, see LICENSE for details.
9 | """
10 | 
11 | import re
12 | import sys
13 | import types
14 | import fnmatch
15 | from os.path import basename
16 | 
17 | from pip._vendor.pygments.formatters._mapping import FORMATTERS
18 | from pip._vendor.pygments.plugin import find_plugin_formatters
19 | from pip._vendor.pygments.util import ClassNotFound
20 | 
21 | __all__ = ['get_formatter_by_name', 'get_formatter_for_filename',
22 |            'get_all_formatters', 'load_formatter_from_file'] + list(FORMATTERS)
23 | 
24 | _formatter_cache = {}  # classes by name
25 | _pattern_cache = {}
26 | 
27 | 
28 | def _fn_matches(fn, glob):
29 |     """Return whether the supplied file name fn matches pattern filename."""
30 |     if glob not in _pattern_cache:
31 |         pattern = _pattern_cache[glob] = re.compile(fnmatch.translate(glob))
32 |         return pattern.match(fn)
33 |     return _pattern_cache[glob].match(fn)
34 | 
35 | 
36 | def _load_formatters(module_name):
37 |     """Load a formatter (and all others in the module too)."""
38 |     mod = __import__(module_name, None, None, ['__all__'])
39 |     for formatter_name in mod.__all__:
40 |         cls = getattr(mod, formatter_name)
41 |         _formatter_cache[cls.name] = cls
42 | 
43 | 
44 | def get_all_formatters():
45 |     """Return a generator for all formatter classes."""
46 |     # NB: this returns formatter classes, not info like get_all_lexers().
47 |     for info in FORMATTERS.values():
48 |         if info[1] not in _formatter_cache:
49 |             _load_formatters(info[0])
50 |         yield _formatter_cache[info[1]]
51 |     for _, formatter in find_plugin_formatters():
52 |         yield formatter
53 | 
54 | 
55 | def find_formatter_class(alias):
56 |     """Lookup a formatter by alias.
57 | 
58 |     Returns None if not found.
59 |     """
60 |     for module_name, name, aliases, _, _ in FORMATTERS.values():
61 |         if alias in aliases:
62 |             if name not in _formatter_cache:
63 |                 _load_formatters(module_name)
64 |             return _formatter_cache[name]
65 |     for _, cls in find_plugin_formatters():
66 |         if alias in cls.aliases:
67 |             return cls
68 | 
69 | 
70 | def get_formatter_by_name(_alias, **options):
71 |     """
72 |     Return an instance of a :class:`.Formatter` subclass that has `alias` in its
73 |     aliases list. The formatter is given the `options` at its instantiation.
74 | 
75 |     Will raise :exc:`pygments.util.ClassNotFound` if no formatter with that
76 |     alias is found.
77 |     """
78 |     cls = find_formatter_class(_alias)
79 |     if cls is None:
80 |         raise ClassNotFound(f"no formatter found for name {_alias!r}")
81 |     return cls(**options)
82 | 
83 | 
84 | def load_formatter_from_file(filename, formattername="CustomFormatter", **options):
85 |     """
86 |     Return a `Formatter` subclass instance loaded from the provided file, relative
87 |     to the current directory.
88 | 
89 |     The file is expected to contain a Formatter class named ``formattername``
90 |     (by default, CustomFormatter). Users should be very careful with the input, because
91 |     this method is equivalent to running ``eval()`` on the input file. The formatter is
92 |     given the `options` at its instantiation.
93 | 
94 |     :exc:`pygments.util.ClassNotFound` is raised if there are any errors loading
95 |     the formatter.
96 | 
97 |     .. versionadded:: 2.2
98 |     """
99 |     try:
100 |         # This empty dict will contain the namespace for the exec'd file
101 |         custom_namespace = {}
102 |         with open(filename, 'rb') as f:
103 |             exec(f.read(), custom_namespace)
104 |         # Retrieve the class `formattername` from that namespace
105 |         if formattername not in custom_namespace:
106 |             raise ClassNotFound(f'no valid {formattername} class found in {filename}')
107 |         formatter_class = custom_namespace[formattername]
108 |         # And finally instantiate it with the options
109 |         return formatter_class(**options)
110 |     except OSError as err:
111 |         raise ClassNotFound(f'cannot read {filename}: {err}')
112 |     except ClassNotFound:
113 |         raise
114 |     except Exception as err:
115 |         raise ClassNotFound(f'error when loading custom formatter: {err}')
116 | 
117 | 
118 | def get_formatter_for_filename(fn, **options):
119 |     """
120 |     Return a :class:`.Formatter` subclass instance that has a filename pattern
121 |     matching `fn`. The formatter is given the `options` at its instantiation.
122 | 
123 |     Will raise :exc:`pygments.util.ClassNotFound` if no formatter for that filename
124 |     is found.
125 |     """
126 |     fn = basename(fn)
127 |     for modname, name, _, filenames, _ in FORMATTERS.values():
128 |         for filename in filenames:
129 |             if _fn_matches(fn, filename):
130 |                 if name not in _formatter_cache:
131 |                     _load_formatters(modname)
132 |                 return _formatter_cache[name](**options)
133 |     for _name, cls in find_plugin_formatters():
134 |         for filename in cls.filenames:
135 |             if _fn_matches(fn, filename):
136 |                 return cls(**options)
137 |     raise ClassNotFound(f"no formatter found for file name {fn!r}")
138 | 
139 | 
140 | class _automodule(types.ModuleType):
141 |     """Automatically import formatters."""
142 | 
143 |     def __getattr__(self, name):
144 |         info = FORMATTERS.get(name)
145 |         if info:
146 |             _load_formatters(info[0])
147 |             cls = _formatter_cache[info[1]]
148 |             setattr(self, name, cls)
149 |             return cls
150 |         raise AttributeError(name)
151 | 
152 | 
153 | oldmod = sys.modules[__name__]
154 | newmod = _automodule(__name__)
155 | newmod.__dict__.update(oldmod.__dict__)
156 | sys.modules[__name__] = newmod
157 | del newmod.newmod, newmod.oldmod, newmod.sys, newmod.types
```

.venv/lib/python3.13/site-packages/pip/_vendor/pygments/formatters/_mapping.py
```
1 | # Automatically generated by scripts/gen_mapfiles.py.
2 | # DO NOT EDIT BY HAND; run `tox -e mapfiles` instead.
3 | 
4 | FORMATTERS = {
5 |     'BBCodeFormatter': ('pygments.formatters.bbcode', 'BBCode', ('bbcode', 'bb'), (), 'Format tokens with BBcodes. These formatting codes are used by many bulletin boards, so you can highlight your sourcecode with pygments before posting it there.'),
6 |     'BmpImageFormatter': ('pygments.formatters.img', 'img_bmp', ('bmp', 'bitmap'), ('*.bmp',), 'Create a bitmap image from source code. This uses the Python Imaging Library to generate a pixmap from the source code.'),
7 |     'GifImageFormatter': ('pygments.formatters.img', 'img_gif', ('gif',), ('*.gif',), 'Create a GIF image from source code. This uses the Python Imaging Library to generate a pixmap from the source code.'),
8 |     'GroffFormatter': ('pygments.formatters.groff', 'groff', ('groff', 'troff', 'roff'), (), 'Format tokens with groff escapes to change their color and font style.'),
9 |     'HtmlFormatter': ('pygments.formatters.html', 'HTML', ('html',), ('*.html', '*.htm'), "Format tokens as HTML 4 ``<span>`` tags. By default, the content is enclosed in a ``<pre>`` tag, itself wrapped in a ``<div>`` tag (but see the `nowrap` option). The ``<div>``'s CSS class can be set by the `cssclass` option."),
10 |     'IRCFormatter': ('pygments.formatters.irc', 'IRC', ('irc', 'IRC'), (), 'Format tokens with IRC color sequences'),
11 |     'ImageFormatter': ('pygments.formatters.img', 'img', ('img', 'IMG', 'png'), ('*.png',), 'Create a PNG image from source code. This uses the Python Imaging Library to generate a pixmap from the source code.'),
12 |     'JpgImageFormatter': ('pygments.formatters.img', 'img_jpg', ('jpg', 'jpeg'), ('*.jpg',), 'Create a JPEG image from source code. This uses the Python Imaging Library to generate a pixmap from the source code.'),
13 |     'LatexFormatter': ('pygments.formatters.latex', 'LaTeX', ('latex', 'tex'), ('*.tex',), 'Format tokens as LaTeX code. This needs the `fancyvrb` and `color` standard packages.'),
14 |     'NullFormatter': ('pygments.formatters.other', 'Text only', ('text', 'null'), ('*.txt',), 'Output the text unchanged without any formatting.'),
15 |     'PangoMarkupFormatter': ('pygments.formatters.pangomarkup', 'Pango Markup', ('pango', 'pangomarkup'), (), 'Format tokens as Pango Markup code. It can then be rendered to an SVG.'),
16 |     'RawTokenFormatter': ('pygments.formatters.other', 'Raw tokens', ('raw', 'tokens'), ('*.raw',), 'Format tokens as a raw representation for storing token streams.'),
17 |     'RtfFormatter': ('pygments.formatters.rtf', 'RTF', ('rtf',), ('*.rtf',), 'Format tokens as RTF markup. This formatter automatically outputs full RTF documents with color information and other useful stuff. Perfect for Copy and Paste into Microsoft(R) Word(R) documents.'),
18 |     'SvgFormatter': ('pygments.formatters.svg', 'SVG', ('svg',), ('*.svg',), 'Format tokens as an SVG graphics file.  This formatter is still experimental. Each line of code is a ``<text>`` element with explicit ``x`` and ``y`` coordinates containing ``<tspan>`` elements with the individual token styles.'),
19 |     'Terminal256Formatter': ('pygments.formatters.terminal256', 'Terminal256', ('terminal256', 'console256', '256'), (), 'Format tokens with ANSI color sequences, for output in a 256-color terminal or console.  Like in `TerminalFormatter` color sequences are terminated at newlines, so that paging the output works correctly.'),
20 |     'TerminalFormatter': ('pygments.formatters.terminal', 'Terminal', ('terminal', 'console'), (), 'Format tokens with ANSI color sequences, for output in a text console. Color sequences are terminated at newlines, so that paging the output works correctly.'),
21 |     'TerminalTrueColorFormatter': ('pygments.formatters.terminal256', 'TerminalTrueColor', ('terminal16m', 'console16m', '16m'), (), 'Format tokens with ANSI color sequences, for output in a true-color terminal or console.  Like in `TerminalFormatter` color sequences are terminated at newlines, so that paging the output works correctly.'),
22 |     'TestcaseFormatter': ('pygments.formatters.other', 'Testcase', ('testcase',), (), 'Format tokens as appropriate for a new testcase.'),
23 | }
```

.venv/lib/python3.13/site-packages/pip/_vendor/pygments/styles/__init__.py
```
1 | """
2 |     pygments.styles
3 |     ~~~~~~~~~~~~~~~
4 | 
5 |     Contains built-in styles.
6 | 
7 |     :copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
8 |     :license: BSD, see LICENSE for details.
9 | """
10 | 
11 | from pip._vendor.pygments.plugin import find_plugin_styles
12 | from pip._vendor.pygments.util import ClassNotFound
13 | from pip._vendor.pygments.styles._mapping import STYLES
14 | 
15 | #: A dictionary of built-in styles, mapping style names to
16 | #: ``'submodule::classname'`` strings.
17 | #: This list is deprecated. Use `pygments.styles.STYLES` instead
18 | STYLE_MAP = {v[1]: v[0].split('.')[-1] + '::' + k for k, v in STYLES.items()}
19 | 
20 | #: Internal reverse mapping to make `get_style_by_name` more efficient
21 | _STYLE_NAME_TO_MODULE_MAP = {v[1]: (v[0], k) for k, v in STYLES.items()}
22 | 
23 | 
24 | def get_style_by_name(name):
25 |     """
26 |     Return a style class by its short name. The names of the builtin styles
27 |     are listed in :data:`pygments.styles.STYLE_MAP`.
28 | 
29 |     Will raise :exc:`pygments.util.ClassNotFound` if no style of that name is
30 |     found.
31 |     """
32 |     if name in _STYLE_NAME_TO_MODULE_MAP:
33 |         mod, cls = _STYLE_NAME_TO_MODULE_MAP[name]
34 |         builtin = "yes"
35 |     else:
36 |         for found_name, style in find_plugin_styles():
37 |             if name == found_name:
38 |                 return style
39 |         # perhaps it got dropped into our styles package
40 |         builtin = ""
41 |         mod = 'pygments.styles.' + name
42 |         cls = name.title() + "Style"
43 | 
44 |     try:
45 |         mod = __import__(mod, None, None, [cls])
46 |     except ImportError:
47 |         raise ClassNotFound(f"Could not find style module {mod!r}" +
48 |                             (builtin and ", though it should be builtin")
49 |                             + ".")
50 |     try:
51 |         return getattr(mod, cls)
52 |     except AttributeError:
53 |         raise ClassNotFound(f"Could not find style class {cls!r} in style module.")
54 | 
55 | 
56 | def get_all_styles():
57 |     """Return a generator for all styles by name, both builtin and plugin."""
58 |     for v in STYLES.values():
59 |         yield v[1]
60 |     for name, _ in find_plugin_styles():
61 |         yield name
```

.venv/lib/python3.13/site-packages/pip/_vendor/pygments/styles/_mapping.py
```
1 | # Automatically generated by scripts/gen_mapfiles.py.
2 | # DO NOT EDIT BY HAND; run `tox -e mapfiles` instead.
3 | 
4 | STYLES = {
5 |     'AbapStyle': ('pygments.styles.abap', 'abap', ()),
6 |     'AlgolStyle': ('pygments.styles.algol', 'algol', ()),
7 |     'Algol_NuStyle': ('pygments.styles.algol_nu', 'algol_nu', ()),
8 |     'ArduinoStyle': ('pygments.styles.arduino', 'arduino', ()),
9 |     'AutumnStyle': ('pygments.styles.autumn', 'autumn', ()),
10 |     'BlackWhiteStyle': ('pygments.styles.bw', 'bw', ()),
11 |     'BorlandStyle': ('pygments.styles.borland', 'borland', ()),
12 |     'CoffeeStyle': ('pygments.styles.coffee', 'coffee', ()),
13 |     'ColorfulStyle': ('pygments.styles.colorful', 'colorful', ()),
14 |     'DefaultStyle': ('pygments.styles.default', 'default', ()),
15 |     'DraculaStyle': ('pygments.styles.dracula', 'dracula', ()),
16 |     'EmacsStyle': ('pygments.styles.emacs', 'emacs', ()),
17 |     'FriendlyGrayscaleStyle': ('pygments.styles.friendly_grayscale', 'friendly_grayscale', ()),
18 |     'FriendlyStyle': ('pygments.styles.friendly', 'friendly', ()),
19 |     'FruityStyle': ('pygments.styles.fruity', 'fruity', ()),
20 |     'GhDarkStyle': ('pygments.styles.gh_dark', 'github-dark', ()),
21 |     'GruvboxDarkStyle': ('pygments.styles.gruvbox', 'gruvbox-dark', ()),
22 |     'GruvboxLightStyle': ('pygments.styles.gruvbox', 'gruvbox-light', ()),
23 |     'IgorStyle': ('pygments.styles.igor', 'igor', ()),
24 |     'InkPotStyle': ('pygments.styles.inkpot', 'inkpot', ()),
25 |     'LightbulbStyle': ('pygments.styles.lightbulb', 'lightbulb', ()),
26 |     'LilyPondStyle': ('pygments.styles.lilypond', 'lilypond', ()),
27 |     'LovelaceStyle': ('pygments.styles.lovelace', 'lovelace', ()),
28 |     'ManniStyle': ('pygments.styles.manni', 'manni', ()),
29 |     'MaterialStyle': ('pygments.styles.material', 'material', ()),
30 |     'MonokaiStyle': ('pygments.styles.monokai', 'monokai', ()),
31 |     'MurphyStyle': ('pygments.styles.murphy', 'murphy', ()),
32 |     'NativeStyle': ('pygments.styles.native', 'native', ()),
33 |     'NordDarkerStyle': ('pygments.styles.nord', 'nord-darker', ()),
34 |     'NordStyle': ('pygments.styles.nord', 'nord', ()),
35 |     'OneDarkStyle': ('pygments.styles.onedark', 'one-dark', ()),
36 |     'ParaisoDarkStyle': ('pygments.styles.paraiso_dark', 'paraiso-dark', ()),
37 |     'ParaisoLightStyle': ('pygments.styles.paraiso_light', 'paraiso-light', ()),
38 |     'PastieStyle': ('pygments.styles.pastie', 'pastie', ()),
39 |     'PerldocStyle': ('pygments.styles.perldoc', 'perldoc', ()),
40 |     'RainbowDashStyle': ('pygments.styles.rainbow_dash', 'rainbow_dash', ()),
41 |     'RrtStyle': ('pygments.styles.rrt', 'rrt', ()),
42 |     'SasStyle': ('pygments.styles.sas', 'sas', ()),
43 |     'SolarizedDarkStyle': ('pygments.styles.solarized', 'solarized-dark', ()),
44 |     'SolarizedLightStyle': ('pygments.styles.solarized', 'solarized-light', ()),
45 |     'StarofficeStyle': ('pygments.styles.staroffice', 'staroffice', ()),
46 |     'StataDarkStyle': ('pygments.styles.stata_dark', 'stata-dark', ()),
47 |     'StataLightStyle': ('pygments.styles.stata_light', 'stata-light', ()),
48 |     'TangoStyle': ('pygments.styles.tango', 'tango', ()),
49 |     'TracStyle': ('pygments.styles.trac', 'trac', ()),
50 |     'VimStyle': ('pygments.styles.vim', 'vim', ()),
51 |     'VisualStudioStyle': ('pygments.styles.vs', 'vs', ()),
52 |     'XcodeStyle': ('pygments.styles.xcode', 'xcode', ()),
53 |     'ZenburnStyle': ('pygments.styles.zenburn', 'zenburn', ()),
54 | }
```

.venv/lib/python3.13/site-packages/pip/_vendor/pygments/lexers/__init__.py
```
1 | """
2 |     pygments.lexers
3 |     ~~~~~~~~~~~~~~~
4 | 
5 |     Pygments lexers.
6 | 
7 |     :copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
8 |     :license: BSD, see LICENSE for details.
9 | """
10 | 
11 | import re
12 | import sys
13 | import types
14 | import fnmatch
15 | from os.path import basename
16 | 
17 | from pip._vendor.pygments.lexers._mapping import LEXERS
18 | from pip._vendor.pygments.modeline import get_filetype_from_buffer
19 | from pip._vendor.pygments.plugin import find_plugin_lexers
20 | from pip._vendor.pygments.util import ClassNotFound, guess_decode
21 | 
22 | COMPAT = {
23 |     'Python3Lexer': 'PythonLexer',
24 |     'Python3TracebackLexer': 'PythonTracebackLexer',
25 |     'LeanLexer': 'Lean3Lexer',
26 | }
27 | 
28 | __all__ = ['get_lexer_by_name', 'get_lexer_for_filename', 'find_lexer_class',
29 |            'guess_lexer', 'load_lexer_from_file'] + list(LEXERS) + list(COMPAT)
30 | 
31 | _lexer_cache = {}
32 | _pattern_cache = {}
33 | 
34 | 
35 | def _fn_matches(fn, glob):
36 |     """Return whether the supplied file name fn matches pattern filename."""
37 |     if glob not in _pattern_cache:
38 |         pattern = _pattern_cache[glob] = re.compile(fnmatch.translate(glob))
39 |         return pattern.match(fn)
40 |     return _pattern_cache[glob].match(fn)
41 | 
42 | 
43 | def _load_lexers(module_name):
44 |     """Load a lexer (and all others in the module too)."""
45 |     mod = __import__(module_name, None, None, ['__all__'])
46 |     for lexer_name in mod.__all__:
47 |         cls = getattr(mod, lexer_name)
48 |         _lexer_cache[cls.name] = cls
49 | 
50 | 
51 | def get_all_lexers(plugins=True):
52 |     """Return a generator of tuples in the form ``(name, aliases,
53 |     filenames, mimetypes)`` of all know lexers.
54 | 
55 |     If *plugins* is true (the default), plugin lexers supplied by entrypoints
56 |     are also returned.  Otherwise, only builtin ones are considered.
57 |     """
58 |     for item in LEXERS.values():
59 |         yield item[1:]
60 |     if plugins:
61 |         for lexer in find_plugin_lexers():
62 |             yield lexer.name, lexer.aliases, lexer.filenames, lexer.mimetypes
63 | 
64 | 
65 | def find_lexer_class(name):
66 |     """
67 |     Return the `Lexer` subclass that with the *name* attribute as given by
68 |     the *name* argument.
69 |     """
70 |     if name in _lexer_cache:
71 |         return _lexer_cache[name]
72 |     # lookup builtin lexers
73 |     for module_name, lname, aliases, _, _ in LEXERS.values():
74 |         if name == lname:
75 |             _load_lexers(module_name)
76 |             return _lexer_cache[name]
77 |     # continue with lexers from setuptools entrypoints
78 |     for cls in find_plugin_lexers():
79 |         if cls.name == name:
80 |             return cls
81 | 
82 | 
83 | def find_lexer_class_by_name(_alias):
84 |     """
85 |     Return the `Lexer` subclass that has `alias` in its aliases list, without
86 |     instantiating it.
87 | 
88 |     Like `get_lexer_by_name`, but does not instantiate the class.
89 | 
90 |     Will raise :exc:`pygments.util.ClassNotFound` if no lexer with that alias is
91 |     found.
92 | 
93 |     .. versionadded:: 2.2
94 |     """
95 |     if not _alias:
96 |         raise ClassNotFound(f'no lexer for alias {_alias!r} found')
97 |     # lookup builtin lexers
98 |     for module_name, name, aliases, _, _ in LEXERS.values():
99 |         if _alias.lower() in aliases:
100 |             if name not in _lexer_cache:
101 |                 _load_lexers(module_name)
102 |             return _lexer_cache[name]
103 |     # continue with lexers from setuptools entrypoints
104 |     for cls in find_plugin_lexers():
105 |         if _alias.lower() in cls.aliases:
106 |             return cls
107 |     raise ClassNotFound(f'no lexer for alias {_alias!r} found')
108 | 
109 | 
110 | def get_lexer_by_name(_alias, **options):
111 |     """
112 |     Return an instance of a `Lexer` subclass that has `alias` in its
113 |     aliases list. The lexer is given the `options` at its
114 |     instantiation.
115 | 
116 |     Will raise :exc:`pygments.util.ClassNotFound` if no lexer with that alias is
117 |     found.
118 |     """
119 |     if not _alias:
120 |         raise ClassNotFound(f'no lexer for alias {_alias!r} found')
121 | 
122 |     # lookup builtin lexers
123 |     for module_name, name, aliases, _, _ in LEXERS.values():
124 |         if _alias.lower() in aliases:
125 |             if name not in _lexer_cache:
126 |                 _load_lexers(module_name)
127 |             return _lexer_cache[name](**options)
128 |     # continue with lexers from setuptools entrypoints
129 |     for cls in find_plugin_lexers():
130 |         if _alias.lower() in cls.aliases:
131 |             return cls(**options)
132 |     raise ClassNotFound(f'no lexer for alias {_alias!r} found')
133 | 
134 | 
135 | def load_lexer_from_file(filename, lexername="CustomLexer", **options):
136 |     """Load a lexer from a file.
137 | 
138 |     This method expects a file located relative to the current working
139 |     directory, which contains a Lexer class. By default, it expects the
140 |     Lexer to be name CustomLexer; you can specify your own class name
141 |     as the second argument to this function.
142 | 
143 |     Users should be very careful with the input, because this method
144 |     is equivalent to running eval on the input file.
145 | 
146 |     Raises ClassNotFound if there are any problems importing the Lexer.
147 | 
148 |     .. versionadded:: 2.2
149 |     """
150 |     try:
151 |         # This empty dict will contain the namespace for the exec'd file
152 |         custom_namespace = {}
153 |         with open(filename, 'rb') as f:
154 |             exec(f.read(), custom_namespace)
155 |         # Retrieve the class `lexername` from that namespace
156 |         if lexername not in custom_namespace:
157 |             raise ClassNotFound(f'no valid {lexername} class found in {filename}')
158 |         lexer_class = custom_namespace[lexername]
159 |         # And finally instantiate it with the options
160 |         return lexer_class(**options)
161 |     except OSError as err:
162 |         raise ClassNotFound(f'cannot read {filename}: {err}')
163 |     except ClassNotFound:
164 |         raise
165 |     except Exception as err:
166 |         raise ClassNotFound(f'error when loading custom lexer: {err}')
167 | 
168 | 
169 | def find_lexer_class_for_filename(_fn, code=None):
170 |     """Get a lexer for a filename.
171 | 
172 |     If multiple lexers match the filename pattern, use ``analyse_text()`` to
173 |     figure out which one is more appropriate.
174 | 
175 |     Returns None if not found.
176 |     """
177 |     matches = []
178 |     fn = basename(_fn)
179 |     for modname, name, _, filenames, _ in LEXERS.values():
180 |         for filename in filenames:
181 |             if _fn_matches(fn, filename):
182 |                 if name not in _lexer_cache:
183 |                     _load_lexers(modname)
184 |                 matches.append((_lexer_cache[name], filename))
185 |     for cls in find_plugin_lexers():
186 |         for filename in cls.filenames:
187 |             if _fn_matches(fn, filename):
188 |                 matches.append((cls, filename))
189 | 
190 |     if isinstance(code, bytes):
191 |         # decode it, since all analyse_text functions expect unicode
192 |         code = guess_decode(code)
193 | 
194 |     def get_rating(info):
195 |         cls, filename = info
196 |         # explicit patterns get a bonus
197 |         bonus = '*' not in filename and 0.5 or 0
198 |         # The class _always_ defines analyse_text because it's included in
199 |         # the Lexer class.  The default implementation returns None which
200 |         # gets turned into 0.0.  Run scripts/detect_missing_analyse_text.py
201 |         # to find lexers which need it overridden.
202 |         if code:
203 |             return cls.analyse_text(code) + bonus, cls.__name__
204 |         return cls.priority + bonus, cls.__name__
205 | 
206 |     if matches:
207 |         matches.sort(key=get_rating)
208 |         # print "Possible lexers, after sort:", matches
209 |         return matches[-1][0]
210 | 
211 | 
212 | def get_lexer_for_filename(_fn, code=None, **options):
213 |     """Get a lexer for a filename.
214 | 
215 |     Return a `Lexer` subclass instance that has a filename pattern
216 |     matching `fn`. The lexer is given the `options` at its
217 |     instantiation.
218 | 
219 |     Raise :exc:`pygments.util.ClassNotFound` if no lexer for that filename
220 |     is found.
221 | 
222 |     If multiple lexers match the filename pattern, use their ``analyse_text()``
223 |     methods to figure out which one is more appropriate.
224 |     """
225 |     res = find_lexer_class_for_filename(_fn, code)
226 |     if not res:
227 |         raise ClassNotFound(f'no lexer for filename {_fn!r} found')
228 |     return res(**options)
229 | 
230 | 
231 | def get_lexer_for_mimetype(_mime, **options):
232 |     """
233 |     Return a `Lexer` subclass instance that has `mime` in its mimetype
234 |     list. The lexer is given the `options` at its instantiation.
235 | 
236 |     Will raise :exc:`pygments.util.ClassNotFound` if not lexer for that mimetype
237 |     is found.
238 |     """
239 |     for modname, name, _, _, mimetypes in LEXERS.values():
240 |         if _mime in mimetypes:
241 |             if name not in _lexer_cache:
242 |                 _load_lexers(modname)
243 |             return _lexer_cache[name](**options)
244 |     for cls in find_plugin_lexers():
245 |         if _mime in cls.mimetypes:
246 |             return cls(**options)
247 |     raise ClassNotFound(f'no lexer for mimetype {_mime!r} found')
248 | 
249 | 
250 | def _iter_lexerclasses(plugins=True):
251 |     """Return an iterator over all lexer classes."""
252 |     for key in sorted(LEXERS):
253 |         module_name, name = LEXERS[key][:2]
254 |         if name not in _lexer_cache:
255 |             _load_lexers(module_name)
256 |         yield _lexer_cache[name]
257 |     if plugins:
258 |         yield from find_plugin_lexers()
259 | 
260 | 
261 | def guess_lexer_for_filename(_fn, _text, **options):
262 |     """
263 |     As :func:`guess_lexer()`, but only lexers which have a pattern in `filenames`
264 |     or `alias_filenames` that matches `filename` are taken into consideration.
265 | 
266 |     :exc:`pygments.util.ClassNotFound` is raised if no lexer thinks it can
267 |     handle the content.
268 |     """
269 |     fn = basename(_fn)
270 |     primary = {}
271 |     matching_lexers = set()
272 |     for lexer in _iter_lexerclasses():
273 |         for filename in lexer.filenames:
274 |             if _fn_matches(fn, filename):
275 |                 matching_lexers.add(lexer)
276 |                 primary[lexer] = True
277 |         for filename in lexer.alias_filenames:
278 |             if _fn_matches(fn, filename):
279 |                 matching_lexers.add(lexer)
280 |                 primary[lexer] = False
281 |     if not matching_lexers:
282 |         raise ClassNotFound(f'no lexer for filename {fn!r} found')
283 |     if len(matching_lexers) == 1:
284 |         return matching_lexers.pop()(**options)
285 |     result = []
286 |     for lexer in matching_lexers:
287 |         rv = lexer.analyse_text(_text)
288 |         if rv == 1.0:
289 |             return lexer(**options)
290 |         result.append((rv, lexer))
291 | 
292 |     def type_sort(t):
293 |         # sort by:
294 |         # - analyse score
295 |         # - is primary filename pattern?
296 |         # - priority
297 |         # - last resort: class name
298 |         return (t[0], primary[t[1]], t[1].priority, t[1].__name__)
299 |     result.sort(key=type_sort)
300 | 
301 |     return result[-1][1](**options)
302 | 
303 | 
304 | def guess_lexer(_text, **options):
305 |     """
306 |     Return a `Lexer` subclass instance that's guessed from the text in
307 |     `text`. For that, the :meth:`.analyse_text()` method of every known lexer
308 |     class is called with the text as argument, and the lexer which returned the
309 |     highest value will be instantiated and returned.
310 | 
311 |     :exc:`pygments.util.ClassNotFound` is raised if no lexer thinks it can
312 |     handle the content.
313 |     """
314 | 
315 |     if not isinstance(_text, str):
316 |         inencoding = options.get('inencoding', options.get('encoding'))
317 |         if inencoding:
318 |             _text = _text.decode(inencoding or 'utf8')
319 |         else:
320 |             _text, _ = guess_decode(_text)
321 | 
322 |     # try to get a vim modeline first
323 |     ft = get_filetype_from_buffer(_text)
324 | 
325 |     if ft is not None:
326 |         try:
327 |             return get_lexer_by_name(ft, **options)
328 |         except ClassNotFound:
329 |             pass
330 | 
331 |     best_lexer = [0.0, None]
332 |     for lexer in _iter_lexerclasses():
333 |         rv = lexer.analyse_text(_text)
334 |         if rv == 1.0:
335 |             return lexer(**options)
336 |         if rv > best_lexer[0]:
337 |             best_lexer[:] = (rv, lexer)
338 |     if not best_lexer[0] or best_lexer[1] is None:
339 |         raise ClassNotFound('no lexer matching the text found')
340 |     return best_lexer[1](**options)
[TRUNCATED]
```

.venv/lib/python3.13/site-packages/pip/_vendor/pygments/lexers/_mapping.py
```
1 | # Automatically generated by scripts/gen_mapfiles.py.
2 | # DO NOT EDIT BY HAND; run `tox -e mapfiles` instead.
3 | 
4 | LEXERS = {
5 |     'ABAPLexer': ('pip._vendor.pygments.lexers.business', 'ABAP', ('abap',), ('*.abap', '*.ABAP'), ('text/x-abap',)),
6 |     'AMDGPULexer': ('pip._vendor.pygments.lexers.amdgpu', 'AMDGPU', ('amdgpu',), ('*.isa',), ()),
7 |     'APLLexer': ('pip._vendor.pygments.lexers.apl', 'APL', ('apl',), ('*.apl', '*.aplf', '*.aplo', '*.apln', '*.aplc', '*.apli', '*.dyalog'), ()),
8 |     'AbnfLexer': ('pip._vendor.pygments.lexers.grammar_notation', 'ABNF', ('abnf',), ('*.abnf',), ('text/x-abnf',)),
9 |     'ActionScript3Lexer': ('pip._vendor.pygments.lexers.actionscript', 'ActionScript 3', ('actionscript3', 'as3'), ('*.as',), ('application/x-actionscript3', 'text/x-actionscript3', 'text/actionscript3')),
10 |     'ActionScriptLexer': ('pip._vendor.pygments.lexers.actionscript', 'ActionScript', ('actionscript', 'as'), ('*.as',), ('application/x-actionscript', 'text/x-actionscript', 'text/actionscript')),
11 |     'AdaLexer': ('pip._vendor.pygments.lexers.ada', 'Ada', ('ada', 'ada95', 'ada2005'), ('*.adb', '*.ads', '*.ada'), ('text/x-ada',)),
12 |     'AdlLexer': ('pip._vendor.pygments.lexers.archetype', 'ADL', ('adl',), ('*.adl', '*.adls', '*.adlf', '*.adlx'), ()),
13 |     'AgdaLexer': ('pip._vendor.pygments.lexers.haskell', 'Agda', ('agda',), ('*.agda',), ('text/x-agda',)),
14 |     'AheuiLexer': ('pip._vendor.pygments.lexers.esoteric', 'Aheui', ('aheui',), ('*.aheui',), ()),
15 |     'AlloyLexer': ('pip._vendor.pygments.lexers.dsls', 'Alloy', ('alloy',), ('*.als',), ('text/x-alloy',)),
16 |     'AmbientTalkLexer': ('pip._vendor.pygments.lexers.ambient', 'AmbientTalk', ('ambienttalk', 'ambienttalk/2', 'at'), ('*.at',), ('text/x-ambienttalk',)),
17 |     'AmplLexer': ('pip._vendor.pygments.lexers.ampl', 'Ampl', ('ampl',), ('*.run',), ()),
18 |     'Angular2HtmlLexer': ('pip._vendor.pygments.lexers.templates', 'HTML + Angular2', ('html+ng2',), ('*.ng2',), ()),
19 |     'Angular2Lexer': ('pip._vendor.pygments.lexers.templates', 'Angular2', ('ng2',), (), ()),
20 |     'AntlrActionScriptLexer': ('pip._vendor.pygments.lexers.parsers', 'ANTLR With ActionScript Target', ('antlr-actionscript', 'antlr-as'), ('*.G', '*.g'), ()),
21 |     'AntlrCSharpLexer': ('pip._vendor.pygments.lexers.parsers', 'ANTLR With C# Target', ('antlr-csharp', 'antlr-c#'), ('*.G', '*.g'), ()),
22 |     'AntlrCppLexer': ('pip._vendor.pygments.lexers.parsers', 'ANTLR With CPP Target', ('antlr-cpp',), ('*.G', '*.g'), ()),
23 |     'AntlrJavaLexer': ('pip._vendor.pygments.lexers.parsers', 'ANTLR With Java Target', ('antlr-java',), ('*.G', '*.g'), ()),
24 |     'AntlrLexer': ('pip._vendor.pygments.lexers.parsers', 'ANTLR', ('antlr',), (), ()),
25 |     'AntlrObjectiveCLexer': ('pip._vendor.pygments.lexers.parsers', 'ANTLR With ObjectiveC Target', ('antlr-objc',), ('*.G', '*.g'), ()),
26 |     'AntlrPerlLexer': ('pip._vendor.pygments.lexers.parsers', 'ANTLR With Perl Target', ('antlr-perl',), ('*.G', '*.g'), ()),
27 |     'AntlrPythonLexer': ('pip._vendor.pygments.lexers.parsers', 'ANTLR With Python Target', ('antlr-python',), ('*.G', '*.g'), ()),
28 |     'AntlrRubyLexer': ('pip._vendor.pygments.lexers.parsers', 'ANTLR With Ruby Target', ('antlr-ruby', 'antlr-rb'), ('*.G', '*.g'), ()),
29 |     'ApacheConfLexer': ('pip._vendor.pygments.lexers.configs', 'ApacheConf', ('apacheconf', 'aconf', 'apache'), ('.htaccess', 'apache.conf', 'apache2.conf'), ('text/x-apacheconf',)),
30 |     'AppleScriptLexer': ('pip._vendor.pygments.lexers.scripting', 'AppleScript', ('applescript',), ('*.applescript',), ()),
31 |     'ArduinoLexer': ('pip._vendor.pygments.lexers.c_like', 'Arduino', ('arduino',), ('*.ino',), ('text/x-arduino',)),
32 |     'ArrowLexer': ('pip._vendor.pygments.lexers.arrow', 'Arrow', ('arrow',), ('*.arw',), ()),
33 |     'ArturoLexer': ('pip._vendor.pygments.lexers.arturo', 'Arturo', ('arturo', 'art'), ('*.art',), ()),
34 |     'AscLexer': ('pip._vendor.pygments.lexers.asc', 'ASCII armored', ('asc', 'pem'), ('*.asc', '*.pem', 'id_dsa', 'id_ecdsa', 'id_ecdsa_sk', 'id_ed25519', 'id_ed25519_sk', 'id_rsa'), ('application/pgp-keys', 'application/pgp-encrypted', 'application/pgp-signature', 'application/pem-certificate-chain')),
35 |     'Asn1Lexer': ('pip._vendor.pygments.lexers.asn1', 'ASN.1', ('asn1',), ('*.asn1',), ()),
36 |     'AspectJLexer': ('pip._vendor.pygments.lexers.jvm', 'AspectJ', ('aspectj',), ('*.aj',), ('text/x-aspectj',)),
37 |     'AsymptoteLexer': ('pip._vendor.pygments.lexers.graphics', 'Asymptote', ('asymptote', 'asy'), ('*.asy',), ('text/x-asymptote',)),
38 |     'AugeasLexer': ('pip._vendor.pygments.lexers.configs', 'Augeas', ('augeas',), ('*.aug',), ()),
39 |     'AutoItLexer': ('pip._vendor.pygments.lexers.automation', 'AutoIt', ('autoit',), ('*.au3',), ('text/x-autoit',)),
40 |     'AutohotkeyLexer': ('pip._vendor.pygments.lexers.automation', 'autohotkey', ('autohotkey', 'ahk'), ('*.ahk', '*.ahkl'), ('text/x-autohotkey',)),
41 |     'AwkLexer': ('pip._vendor.pygments.lexers.textedit', 'Awk', ('awk', 'gawk', 'mawk', 'nawk'), ('*.awk',), ('application/x-awk',)),
42 |     'BBCBasicLexer': ('pip._vendor.pygments.lexers.basic', 'BBC Basic', ('bbcbasic',), ('*.bbc',), ()),
43 |     'BBCodeLexer': ('pip._vendor.pygments.lexers.markup', 'BBCode', ('bbcode',), (), ('text/x-bbcode',)),
44 |     'BCLexer': ('pip._vendor.pygments.lexers.algebra', 'BC', ('bc',), ('*.bc',), ()),
45 |     'BQNLexer': ('pip._vendor.pygments.lexers.bqn', 'BQN', ('bqn',), ('*.bqn',), ()),
46 |     'BSTLexer': ('pip._vendor.pygments.lexers.bibtex', 'BST', ('bst', 'bst-pybtex'), ('*.bst',), ()),
47 |     'BareLexer': ('pip._vendor.pygments.lexers.bare', 'BARE', ('bare',), ('*.bare',), ()),
48 |     'BaseMakefileLexer': ('pip._vendor.pygments.lexers.make', 'Base Makefile', ('basemake',), (), ()),
49 |     'BashLexer': ('pip._vendor.pygments.lexers.shell', 'Bash', ('bash', 'sh', 'ksh', 'zsh', 'shell', 'openrc'), ('*.sh', '*.ksh', '*.bash', '*.ebuild', '*.eclass', '*.exheres-0', '*.exlib', '*.zsh', '.bashrc', 'bashrc', '.bash_*', 'bash_*', 'zshrc', '.zshrc', '.kshrc', 'kshrc', 'PKGBUILD'), ('application/x-sh', 'application/x-shellscript', 'text/x-shellscript')),
50 |     'BashSessionLexer': ('pip._vendor.pygments.lexers.shell', 'Bash Session', ('console', 'shell-session'), ('*.sh-session', '*.shell-session'), ('application/x-shell-session', 'application/x-sh-session')),
51 |     'BatchLexer': ('pip._vendor.pygments.lexers.shell', 'Batchfile', ('batch', 'bat', 'dosbatch', 'winbatch'), ('*.bat', '*.cmd'), ('application/x-dos-batch',)),
52 |     'BddLexer': ('pip._vendor.pygments.lexers.bdd', 'Bdd', ('bdd',), ('*.feature',), ('text/x-bdd',)),
53 |     'BefungeLexer': ('pip._vendor.pygments.lexers.esoteric', 'Befunge', ('befunge',), ('*.befunge',), ('application/x-befunge',)),
54 |     'BerryLexer': ('pip._vendor.pygments.lexers.berry', 'Berry', ('berry', 'be'), ('*.be',), ('text/x-berry', 'application/x-berry')),
55 |     'BibTeXLexer': ('pip._vendor.pygments.lexers.bibtex', 'BibTeX', ('bibtex', 'bib'), ('*.bib',), ('text/x-bibtex',)),
56 |     'BlitzBasicLexer': ('pip._vendor.pygments.lexers.basic', 'BlitzBasic', ('blitzbasic', 'b3d', 'bplus'), ('*.bb', '*.decls'), ('text/x-bb',)),
57 |     'BlitzMaxLexer': ('pip._vendor.pygments.lexers.basic', 'BlitzMax', ('blitzmax', 'bmax'), ('*.bmx',), ('text/x-bmx',)),
58 |     'BlueprintLexer': ('pip._vendor.pygments.lexers.blueprint', 'Blueprint', ('blueprint',), ('*.blp',), ('text/x-blueprint',)),
59 |     'BnfLexer': ('pip._vendor.pygments.lexers.grammar_notation', 'BNF', ('bnf',), ('*.bnf',), ('text/x-bnf',)),
60 |     'BoaLexer': ('pip._vendor.pygments.lexers.boa', 'Boa', ('boa',), ('*.boa',), ()),
61 |     'BooLexer': ('pip._vendor.pygments.lexers.dotnet', 'Boo', ('boo',), ('*.boo',), ('text/x-boo',)),
62 |     'BoogieLexer': ('pip._vendor.pygments.lexers.verification', 'Boogie', ('boogie',), ('*.bpl',), ()),
63 |     'BrainfuckLexer': ('pip._vendor.pygments.lexers.esoteric', 'Brainfuck', ('brainfuck', 'bf'), ('*.bf', '*.b'), ('application/x-brainfuck',)),
64 |     'BugsLexer': ('pip._vendor.pygments.lexers.modeling', 'BUGS', ('bugs', 'winbugs', 'openbugs'), ('*.bug',), ()),
65 |     'CAmkESLexer': ('pip._vendor.pygments.lexers.esoteric', 'CAmkES', ('camkes', 'idl4'), ('*.camkes', '*.idl4'), ()),
66 |     'CLexer': ('pip._vendor.pygments.lexers.c_cpp', 'C', ('c',), ('*.c', '*.h', '*.idc', '*.x[bp]m'), ('text/x-chdr', 'text/x-csrc', 'image/x-xbitmap', 'image/x-xpixmap')),
67 |     'CMakeLexer': ('pip._vendor.pygments.lexers.make', 'CMake', ('cmake',), ('*.cmake', 'CMakeLists.txt'), ('text/x-cmake',)),
68 |     'CObjdumpLexer': ('pip._vendor.pygments.lexers.asm', 'c-objdump', ('c-objdump',), ('*.c-objdump',), ('text/x-c-objdump',)),
69 |     'CPSALexer': ('pip._vendor.pygments.lexers.lisp', 'CPSA', ('cpsa',), ('*.cpsa',), ()),
70 |     'CSSUL4Lexer': ('pip._vendor.pygments.lexers.ul4', 'CSS+UL4', ('css+ul4',), ('*.cssul4',), ()),
71 |     'CSharpAspxLexer': ('pip._vendor.pygments.lexers.dotnet', 'aspx-cs', ('aspx-cs',), ('*.aspx', '*.asax', '*.ascx', '*.ashx', '*.asmx', '*.axd'), ()),
72 |     'CSharpLexer': ('pip._vendor.pygments.lexers.dotnet', 'C#', ('csharp', 'c#', 'cs'), ('*.cs',), ('text/x-csharp',)),
73 |     'Ca65Lexer': ('pip._vendor.pygments.lexers.asm', 'ca65 assembler', ('ca65',), ('*.s',), ()),
74 |     'CadlLexer': ('pip._vendor.pygments.lexers.archetype', 'cADL', ('cadl',), ('*.cadl',), ()),
75 |     'CapDLLexer': ('pip._vendor.pygments.lexers.esoteric', 'CapDL', ('capdl',), ('*.cdl',), ()),
76 |     'CapnProtoLexer': ('pip._vendor.pygments.lexers.capnproto', "Cap'n Proto", ('capnp',), ('*.capnp',), ()),
77 |     'CarbonLexer': ('pip._vendor.pygments.lexers.carbon', 'Carbon', ('carbon',), ('*.carbon',), ('text/x-carbon',)),
78 |     'CbmBasicV2Lexer': ('pip._vendor.pygments.lexers.basic', 'CBM BASIC V2', ('cbmbas',), ('*.bas',), ()),
79 |     'CddlLexer': ('pip._vendor.pygments.lexers.cddl', 'CDDL', ('cddl',), ('*.cddl',), ('text/x-cddl',)),
80 |     'CeylonLexer': ('pip._vendor.pygments.lexers.jvm', 'Ceylon', ('ceylon',), ('*.ceylon',), ('text/x-ceylon',)),
81 |     'Cfengine3Lexer': ('pip._vendor.pygments.lexers.configs', 'CFEngine3', ('cfengine3', 'cf3'), ('*.cf',), ()),
82 |     'ChaiscriptLexer': ('pip._vendor.pygments.lexers.scripting', 'ChaiScript', ('chaiscript', 'chai'), ('*.chai',), ('text/x-chaiscript', 'application/x-chaiscript')),
83 |     'ChapelLexer': ('pip._vendor.pygments.lexers.chapel', 'Chapel', ('chapel', 'chpl'), ('*.chpl',), ()),
84 |     'CharmciLexer': ('pip._vendor.pygments.lexers.c_like', 'Charmci', ('charmci',), ('*.ci',), ()),
85 |     'CheetahHtmlLexer': ('pip._vendor.pygments.lexers.templates', 'HTML+Cheetah', ('html+cheetah', 'html+spitfire', 'htmlcheetah'), (), ('text/html+cheetah', 'text/html+spitfire')),
86 |     'CheetahJavascriptLexer': ('pip._vendor.pygments.lexers.templates', 'JavaScript+Cheetah', ('javascript+cheetah', 'js+cheetah', 'javascript+spitfire', 'js+spitfire'), (), ('application/x-javascript+cheetah', 'text/x-javascript+cheetah', 'text/javascript+cheetah', 'application/x-javascript+spitfire', 'text/x-javascript+spitfire', 'text/javascript+spitfire')),
87 |     'CheetahLexer': ('pip._vendor.pygments.lexers.templates', 'Cheetah', ('cheetah', 'spitfire'), ('*.tmpl', '*.spt'), ('application/x-cheetah', 'application/x-spitfire')),
88 |     'CheetahXmlLexer': ('pip._vendor.pygments.lexers.templates', 'XML+Cheetah', ('xml+cheetah', 'xml+spitfire'), (), ('application/xml+cheetah', 'application/xml+spitfire')),
89 |     'CirruLexer': ('pip._vendor.pygments.lexers.webmisc', 'Cirru', ('cirru',), ('*.cirru',), ('text/x-cirru',)),
90 |     'ClayLexer': ('pip._vendor.pygments.lexers.c_like', 'Clay', ('clay',), ('*.clay',), ('text/x-clay',)),
91 |     'CleanLexer': ('pip._vendor.pygments.lexers.clean', 'Clean', ('clean',), ('*.icl', '*.dcl'), ()),
92 |     'ClojureLexer': ('pip._vendor.pygments.lexers.jvm', 'Clojure', ('clojure', 'clj'), ('*.clj', '*.cljc'), ('text/x-clojure', 'application/x-clojure')),
93 |     'ClojureScriptLexer': ('pip._vendor.pygments.lexers.jvm', 'ClojureScript', ('clojurescript', 'cljs'), ('*.cljs',), ('text/x-clojurescript', 'application/x-clojurescript')),
94 |     'CobolFreeformatLexer': ('pip._vendor.pygments.lexers.business', 'COBOLFree', ('cobolfree',), ('*.cbl', '*.CBL'), ()),
95 |     'CobolLexer': ('pip._vendor.pygments.lexers.business', 'COBOL', ('cobol',), ('*.cob', '*.COB', '*.cpy', '*.CPY'), ('text/x-cobol',)),
96 |     'CodeQLLexer': ('pip._vendor.pygments.lexers.codeql', 'CodeQL', ('codeql', 'ql'), ('*.ql', '*.qll'), ()),
97 |     'CoffeeScriptLexer': ('pip._vendor.pygments.lexers.javascript', 'CoffeeScript', ('coffeescript', 'coffee-script', 'coffee'), ('*.coffee',), ('text/coffeescript',)),
98 |     'ColdfusionCFCLexer': ('pip._vendor.pygments.lexers.templates', 'Coldfusion CFC', ('cfc',), ('*.cfc',), ()),
99 |     'ColdfusionHtmlLexer': ('pip._vendor.pygments.lexers.templates', 'Coldfusion HTML', ('cfm',), ('*.cfm', '*.cfml'), ('application/x-coldfusion',)),
100 |     'ColdfusionLexer': ('pip._vendor.pygments.lexers.templates', 'cfstatement', ('cfs',), (), ()),
101 |     'Comal80Lexer': ('pip._vendor.pygments.lexers.comal', 'COMAL-80', ('comal', 'comal80'), ('*.cml', '*.comal'), ()),
102 |     'CommonLispLexer': ('pip._vendor.pygments.lexers.lisp', 'Common Lisp', ('common-lisp', 'cl', 'lisp'), ('*.cl', '*.lisp'), ('text/x-common-lisp',)),
103 |     'ComponentPascalLexer': ('pip._vendor.pygments.lexers.oberon', 'Component Pascal', ('componentpascal', 'cp'), ('*.cp', '*.cps'), ('text/x-component-pascal',)),
104 |     'CoqLexer': ('pip._vendor.pygments.lexers.theorem', 'Coq', ('coq',), ('*.v',), ('text/x-coq',)),
105 |     'CplintLexer': ('pip._vendor.pygments.lexers.cplint', 'cplint', ('cplint',), ('*.ecl', '*.prolog', '*.pro', '*.pl', '*.P', '*.lpad', '*.cpl'), ('text/x-cplint',)),
106 |     'CppLexer': ('pip._vendor.pygments.lexers.c_cpp', 'C++', ('cpp', 'c++'), ('*.cpp', '*.hpp', '*.c++', '*.h++', '*.cc', '*.hh', '*.cxx', '*.hxx', '*.C', '*.H', '*.cp', '*.CPP', '*.tpp'), ('text/x-c++hdr', 'text/x-c++src')),
107 |     'CppObjdumpLexer': ('pip._vendor.pygments.lexers.asm', 'cpp-objdump', ('cpp-objdump', 'c++-objdumb', 'cxx-objdump'), ('*.cpp-objdump', '*.c++-objdump', '*.cxx-objdump'), ('text/x-cpp-objdump',)),
108 |     'CrmshLexer': ('pip._vendor.pygments.lexers.dsls', 'Crmsh', ('crmsh', 'pcmk'), ('*.crmsh', '*.pcmk'), ()),
109 |     'CrocLexer': ('pip._vendor.pygments.lexers.d', 'Croc', ('croc',), ('*.croc',), ('text/x-crocsrc',)),
110 |     'CryptolLexer': ('pip._vendor.pygments.lexers.haskell', 'Cryptol', ('cryptol', 'cry'), ('*.cry',), ('text/x-cryptol',)),
111 |     'CrystalLexer': ('pip._vendor.pygments.lexers.crystal', 'Crystal', ('cr', 'crystal'), ('*.cr',), ('text/x-crystal',)),
112 |     'CsoundDocumentLexer': ('pip._vendor.pygments.lexers.csound', 'Csound Document', ('csound-document', 'csound-csd'), ('*.csd',), ()),
113 |     'CsoundOrchestraLexer': ('pip._vendor.pygments.lexers.csound', 'Csound Orchestra', ('csound', 'csound-orc'), ('*.orc', '*.udo'), ()),
114 |     'CsoundScoreLexer': ('pip._vendor.pygments.lexers.csound', 'Csound Score', ('csound-score', 'csound-sco'), ('*.sco',), ()),
115 |     'CssDjangoLexer': ('pip._vendor.pygments.lexers.templates', 'CSS+Django/Jinja', ('css+django', 'css+jinja'), ('*.css.j2', '*.css.jinja2'), ('text/css+django', 'text/css+jinja')),
116 |     'CssErbLexer': ('pip._vendor.pygments.lexers.templates', 'CSS+Ruby', ('css+ruby', 'css+erb'), (), ('text/css+ruby',)),
117 |     'CssGenshiLexer': ('pip._vendor.pygments.lexers.templates', 'CSS+Genshi Text', ('css+genshitext', 'css+genshi'), (), ('text/css+genshi',)),
118 |     'CssLexer': ('pip._vendor.pygments.lexers.css', 'CSS', ('css',), ('*.css',), ('text/css',)),
119 |     'CssPhpLexer': ('pip._vendor.pygments.lexers.templates', 'CSS+PHP', ('css+php',), (), ('text/css+php',)),
120 |     'CssSmartyLexer': ('pip._vendor.pygments.lexers.templates', 'CSS+Smarty', ('css+smarty',), (), ('text/css+smarty',)),
121 |     'CudaLexer': ('pip._vendor.pygments.lexers.c_like', 'CUDA', ('cuda', 'cu'), ('*.cu', '*.cuh'), ('text/x-cuda',)),
122 |     'CypherLexer': ('pip._vendor.pygments.lexers.graph', 'Cypher', ('cypher',), ('*.cyp', '*.cypher'), ()),
123 |     'CythonLexer': ('pip._vendor.pygments.lexers.python', 'Cython', ('cython', 'pyx', 'pyrex'), ('*.pyx', '*.pxd', '*.pxi'), ('text/x-cython', 'application/x-cython')),
124 |     'DLexer': ('pip._vendor.pygments.lexers.d', 'D', ('d',), ('*.d', '*.di'), ('text/x-dsrc',)),
125 |     'DObjdumpLexer': ('pip._vendor.pygments.lexers.asm', 'd-objdump', ('d-objdump',), ('*.d-objdump',), ('text/x-d-objdump',)),
126 |     'DarcsPatchLexer': ('pip._vendor.pygments.lexers.diff', 'Darcs Patch', ('dpatch',), ('*.dpatch', '*.darcspatch'), ()),
127 |     'DartLexer': ('pip._vendor.pygments.lexers.javascript', 'Dart', ('dart',), ('*.dart',), ('text/x-dart',)),
128 |     'Dasm16Lexer': ('pip._vendor.pygments.lexers.asm', 'DASM16', ('dasm16',), ('*.dasm16', '*.dasm'), ('text/x-dasm16',)),
129 |     'DaxLexer': ('pip._vendor.pygments.lexers.dax', 'Dax', ('dax',), ('*.dax',), ()),
130 |     'DebianControlLexer': ('pip._vendor.pygments.lexers.installers', 'Debian Control file', ('debcontrol', 'control'), ('control',), ()),
131 |     'DebianSourcesLexer': ('pip._vendor.pygments.lexers.installers', 'Debian Sources file', ('debian.sources',), ('*.sources',), ()),
132 |     'DelphiLexer': ('pip._vendor.pygments.lexers.pascal', 'Delphi', ('delphi', 'pas', 'pascal', 'objectpascal'), ('*.pas', '*.dpr'), ('text/x-pascal',)),
133 |     'DesktopLexer': ('pip._vendor.pygments.lexers.configs', 'Desktop file', ('desktop',), ('*.desktop',), ('application/x-desktop',)),
134 |     'DevicetreeLexer': ('pip._vendor.pygments.lexers.devicetree', 'Devicetree', ('devicetree', 'dts'), ('*.dts', '*.dtsi'), ('text/x-c',)),
135 |     'DgLexer': ('pip._vendor.pygments.lexers.python', 'dg', ('dg',), ('*.dg',), ('text/x-dg',)),
136 |     'DiffLexer': ('pip._vendor.pygments.lexers.diff', 'Diff', ('diff', 'udiff'), ('*.diff', '*.patch'), ('text/x-diff', 'text/x-patch')),
137 |     'DjangoLexer': ('pip._vendor.pygments.lexers.templates', 'Django/Jinja', ('django', 'jinja'), (), ('application/x-django-templating', 'application/x-jinja')),
138 |     'DnsZoneLexer': ('pip._vendor.pygments.lexers.dns', 'Zone', ('zone',), ('*.zone',), ('text/dns',)),
139 |     'DockerLexer': ('pip._vendor.pygments.lexers.configs', 'Docker', ('docker', 'dockerfile'), ('Dockerfile', '*.docker'), ('text/x-dockerfile-config',)),
140 |     'DtdLexer': ('pip._vendor.pygments.lexers.html', 'DTD', ('dtd',), ('*.dtd',), ('application/xml-dtd',)),
141 |     'DuelLexer': ('pip._vendor.pygments.lexers.webmisc', 'Duel', ('duel', 'jbst', 'jsonml+bst'), ('*.duel', '*.jbst'), ('text/x-duel', 'text/x-jbst')),
142 |     'DylanConsoleLexer': ('pip._vendor.pygments.lexers.dylan', 'Dylan session', ('dylan-console', 'dylan-repl'), ('*.dylan-console',), ('text/x-dylan-console',)),
143 |     'DylanLexer': ('pip._vendor.pygments.lexers.dylan', 'Dylan', ('dylan',), ('*.dylan', '*.dyl', '*.intr'), ('text/x-dylan',)),
144 |     'DylanLidLexer': ('pip._vendor.pygments.lexers.dylan', 'DylanLID', ('dylan-lid', 'lid'), ('*.lid', '*.hdp'), ('text/x-dylan-lid',)),
145 |     'ECLLexer': ('pip._vendor.pygments.lexers.ecl', 'ECL', ('ecl',), ('*.ecl',), ('application/x-ecl',)),
146 |     'ECLexer': ('pip._vendor.pygments.lexers.c_like', 'eC', ('ec',), ('*.ec', '*.eh'), ('text/x-echdr', 'text/x-ecsrc')),
[TRUNCATED]
```

.venv/lib/python3.13/site-packages/pip/_vendor/pygments/lexers/python.py
```
1 | """
2 |     pygments.lexers.python
3 |     ~~~~~~~~~~~~~~~~~~~~~~
4 | 
5 |     Lexers for Python and related languages.
6 | 
7 |     :copyright: Copyright 2006-2025 by the Pygments team, see AUTHORS.
8 |     :license: BSD, see LICENSE for details.
9 | """
10 | 
11 | import keyword
12 | 
13 | from pip._vendor.pygments.lexer import DelegatingLexer, RegexLexer, include, \
14 |     bygroups, using, default, words, combined, this
15 | from pip._vendor.pygments.util import get_bool_opt, shebang_matches
16 | from pip._vendor.pygments.token import Text, Comment, Operator, Keyword, Name, String, \
17 |     Number, Punctuation, Generic, Other, Error, Whitespace
18 | from pip._vendor.pygments import unistring as uni
19 | 
20 | __all__ = ['PythonLexer', 'PythonConsoleLexer', 'PythonTracebackLexer',
21 |            'Python2Lexer', 'Python2TracebackLexer',
22 |            'CythonLexer', 'DgLexer', 'NumPyLexer']
23 | 
24 | 
25 | class PythonLexer(RegexLexer):
26 |     """
27 |     For Python source code (version 3.x).
28 | 
29 |     .. versionchanged:: 2.5
30 |        This is now the default ``PythonLexer``.  It is still available as the
31 |        alias ``Python3Lexer``.
32 |     """
33 | 
34 |     name = 'Python'
35 |     url = 'https://www.python.org'
36 |     aliases = ['python', 'py', 'sage', 'python3', 'py3', 'bazel', 'starlark', 'pyi']
37 |     filenames = [
38 |         '*.py',
39 |         '*.pyw',
40 |         # Type stubs
41 |         '*.pyi',
42 |         # Jython
43 |         '*.jy',
44 |         # Sage
45 |         '*.sage',
46 |         # SCons
47 |         '*.sc',
48 |         'SConstruct',
49 |         'SConscript',
50 |         # Skylark/Starlark (used by Bazel, Buck, and Pants)
51 |         '*.bzl',
52 |         'BUCK',
53 |         'BUILD',
54 |         'BUILD.bazel',
55 |         'WORKSPACE',
56 |         # Twisted Application infrastructure
57 |         '*.tac',
58 |     ]
59 |     mimetypes = ['text/x-python', 'application/x-python',
60 |                  'text/x-python3', 'application/x-python3']
61 |     version_added = '0.10'
62 | 
63 |     uni_name = f"[{uni.xid_start}][{uni.xid_continue}]*"
64 | 
65 |     def innerstring_rules(ttype):
66 |         return [
67 |             # the old style '%s' % (...) string formatting (still valid in Py3)
68 |             (r'%(\(\w+\))?[-#0 +]*([0-9]+|[*])?(\.([0-9]+|[*]))?'
69 |              '[hlL]?[E-GXc-giorsaux%]', String.Interpol),
70 |             # the new style '{}'.format(...) string formatting
71 |             (r'\{'
72 |              r'((\w+)((\.\w+)|(\[[^\]]+\]))*)?'  # field name
73 |              r'(\![sra])?'                       # conversion
74 |              r'(\:(.?[<>=\^])?[-+ ]?#?0?(\d+)?,?(\.\d+)?[E-GXb-gnosx%]?)?'
75 |              r'\}', String.Interpol),
76 | 
77 |             # backslashes, quotes and formatting signs must be parsed one at a time
78 |             (r'[^\\\'"%{\n]+', ttype),
79 |             (r'[\'"\\]', ttype),
80 |             # unhandled string formatting sign
81 |             (r'%|(\{{1,2})', ttype)
82 |             # newlines are an error (use "nl" state)
83 |         ]
84 | 
85 |     def fstring_rules(ttype):
86 |         return [
87 |             # Assuming that a '}' is the closing brace after format specifier.
88 |             # Sadly, this means that we won't detect syntax error. But it's
89 |             # more important to parse correct syntax correctly, than to
90 |             # highlight invalid syntax.
91 |             (r'\}', String.Interpol),
92 |             (r'\{', String.Interpol, 'expr-inside-fstring'),
93 |             # backslashes, quotes and formatting signs must be parsed one at a time
94 |             (r'[^\\\'"{}\n]+', ttype),
95 |             (r'[\'"\\]', ttype),
96 |             # newlines are an error (use "nl" state)
97 |         ]
98 | 
99 |     tokens = {
100 |         'root': [
101 |             (r'\n', Whitespace),
102 |             (r'^(\s*)([rRuUbB]{,2})("""(?:.|\n)*?""")',
103 |              bygroups(Whitespace, String.Affix, String.Doc)),
104 |             (r"^(\s*)([rRuUbB]{,2})('''(?:.|\n)*?''')",
105 |              bygroups(Whitespace, String.Affix, String.Doc)),
106 |             (r'\A#!.+$', Comment.Hashbang),
107 |             (r'#.*$', Comment.Single),
108 |             (r'\\\n', Text),
109 |             (r'\\', Text),
110 |             include('keywords'),
111 |             include('soft-keywords'),
112 |             (r'(def)((?:\s|\\\s)+)', bygroups(Keyword, Whitespace), 'funcname'),
113 |             (r'(class)((?:\s|\\\s)+)', bygroups(Keyword, Whitespace), 'classname'),
114 |             (r'(from)((?:\s|\\\s)+)', bygroups(Keyword.Namespace, Whitespace),
115 |              'fromimport'),
116 |             (r'(import)((?:\s|\\\s)+)', bygroups(Keyword.Namespace, Whitespace),
117 |              'import'),
118 |             include('expr'),
119 |         ],
120 |         'expr': [
121 |             # raw f-strings
122 |             ('(?i)(rf|fr)(""")',
123 |              bygroups(String.Affix, String.Double),
124 |              combined('rfstringescape', 'tdqf')),
125 |             ("(?i)(rf|fr)(''')",
126 |              bygroups(String.Affix, String.Single),
127 |              combined('rfstringescape', 'tsqf')),
128 |             ('(?i)(rf|fr)(")',
129 |              bygroups(String.Affix, String.Double),
130 |              combined('rfstringescape', 'dqf')),
131 |             ("(?i)(rf|fr)(')",
132 |              bygroups(String.Affix, String.Single),
133 |              combined('rfstringescape', 'sqf')),
134 |             # non-raw f-strings
135 |             ('([fF])(""")', bygroups(String.Affix, String.Double),
136 |              combined('fstringescape', 'tdqf')),
137 |             ("([fF])(''')", bygroups(String.Affix, String.Single),
138 |              combined('fstringescape', 'tsqf')),
139 |             ('([fF])(")', bygroups(String.Affix, String.Double),
140 |              combined('fstringescape', 'dqf')),
141 |             ("([fF])(')", bygroups(String.Affix, String.Single),
142 |              combined('fstringescape', 'sqf')),
143 |             # raw bytes and strings
144 |             ('(?i)(rb|br|r)(""")',
145 |              bygroups(String.Affix, String.Double), 'tdqs'),
146 |             ("(?i)(rb|br|r)(''')",
147 |              bygroups(String.Affix, String.Single), 'tsqs'),
148 |             ('(?i)(rb|br|r)(")',
149 |              bygroups(String.Affix, String.Double), 'dqs'),
150 |             ("(?i)(rb|br|r)(')",
151 |              bygroups(String.Affix, String.Single), 'sqs'),
152 |             # non-raw strings
153 |             ('([uU]?)(""")', bygroups(String.Affix, String.Double),
154 |              combined('stringescape', 'tdqs')),
155 |             ("([uU]?)(''')", bygroups(String.Affix, String.Single),
156 |              combined('stringescape', 'tsqs')),
157 |             ('([uU]?)(")', bygroups(String.Affix, String.Double),
158 |              combined('stringescape', 'dqs')),
159 |             ("([uU]?)(')", bygroups(String.Affix, String.Single),
160 |              combined('stringescape', 'sqs')),
161 |             # non-raw bytes
162 |             ('([bB])(""")', bygroups(String.Affix, String.Double),
163 |              combined('bytesescape', 'tdqs')),
164 |             ("([bB])(''')", bygroups(String.Affix, String.Single),
165 |              combined('bytesescape', 'tsqs')),
166 |             ('([bB])(")', bygroups(String.Affix, String.Double),
167 |              combined('bytesescape', 'dqs')),
168 |             ("([bB])(')", bygroups(String.Affix, String.Single),
169 |              combined('bytesescape', 'sqs')),
170 | 
171 |             (r'[^\S\n]+', Text),
172 |             include('numbers'),
173 |             (r'!=|==|<<|>>|:=|[-~+/*%=<>&^|.]', Operator),
174 |             (r'[]{}:(),;[]', Punctuation),
175 |             (r'(in|is|and|or|not)\b', Operator.Word),
176 |             include('expr-keywords'),
177 |             include('builtins'),
178 |             include('magicfuncs'),
179 |             include('magicvars'),
180 |             include('name'),
181 |         ],
182 |         'expr-inside-fstring': [
183 |             (r'[{([]', Punctuation, 'expr-inside-fstring-inner'),
184 |             # without format specifier
185 |             (r'(=\s*)?'         # debug (https://bugs.python.org/issue36817)
186 |              r'(\![sraf])?'     # conversion
187 |              r'\}', String.Interpol, '#pop'),
188 |             # with format specifier
189 |             # we'll catch the remaining '}' in the outer scope
190 |             (r'(=\s*)?'         # debug (https://bugs.python.org/issue36817)
191 |              r'(\![sraf])?'     # conversion
192 |              r':', String.Interpol, '#pop'),
193 |             (r'\s+', Whitespace),  # allow new lines
194 |             include('expr'),
195 |         ],
196 |         'expr-inside-fstring-inner': [
197 |             (r'[{([]', Punctuation, 'expr-inside-fstring-inner'),
198 |             (r'[])}]', Punctuation, '#pop'),
199 |             (r'\s+', Whitespace),  # allow new lines
200 |             include('expr'),
201 |         ],
202 |         'expr-keywords': [
203 |             # Based on https://docs.python.org/3/reference/expressions.html
204 |             (words((
205 |                 'async for', 'await', 'else', 'for', 'if', 'lambda',
206 |                 'yield', 'yield from'), suffix=r'\b'),
207 |              Keyword),
208 |             (words(('True', 'False', 'None'), suffix=r'\b'), Keyword.Constant),
209 |         ],
210 |         'keywords': [
211 |             (words((
212 |                 'assert', 'async', 'await', 'break', 'continue', 'del', 'elif',
213 |                 'else', 'except', 'finally', 'for', 'global', 'if', 'lambda',
214 |                 'pass', 'raise', 'nonlocal', 'return', 'try', 'while', 'yield',
215 |                 'yield from', 'as', 'with'), suffix=r'\b'),
216 |              Keyword),
217 |             (words(('True', 'False', 'None'), suffix=r'\b'), Keyword.Constant),
218 |         ],
219 |         'soft-keywords': [
220 |             # `match`, `case` and `_` soft keywords
221 |             (r'(^[ \t]*)'              # at beginning of line + possible indentation
222 |              r'(match|case)\b'         # a possible keyword
223 |              r'(?![ \t]*(?:'           # not followed by...
224 |              r'[:,;=^&|@~)\]}]|(?:' +  # characters and keywords that mean this isn't
225 |                                        # pattern matching (but None/True/False is ok)
226 |              r'|'.join(k for k in keyword.kwlist if k[0].islower()) + r')\b))',
227 |              bygroups(Text, Keyword), 'soft-keywords-inner'),
228 |         ],
229 |         'soft-keywords-inner': [
230 |             # optional `_` keyword
231 |             (r'(\s+)([^\n_]*)(_\b)', bygroups(Whitespace, using(this), Keyword)),
232 |             default('#pop')
233 |         ],
234 |         'builtins': [
235 |             (words((
236 |                 '__import__', 'abs', 'aiter', 'all', 'any', 'bin', 'bool', 'bytearray',
237 |                 'breakpoint', 'bytes', 'callable', 'chr', 'classmethod', 'compile',
238 |                 'complex', 'delattr', 'dict', 'dir', 'divmod', 'enumerate', 'eval',
239 |                 'filter', 'float', 'format', 'frozenset', 'getattr', 'globals',
240 |                 'hasattr', 'hash', 'hex', 'id', 'input', 'int', 'isinstance',
241 |                 'issubclass', 'iter', 'len', 'list', 'locals', 'map', 'max',
242 |                 'memoryview', 'min', 'next', 'object', 'oct', 'open', 'ord', 'pow',
243 |                 'print', 'property', 'range', 'repr', 'reversed', 'round', 'set',
244 |                 'setattr', 'slice', 'sorted', 'staticmethod', 'str', 'sum', 'super',
245 |                 'tuple', 'type', 'vars', 'zip'), prefix=r'(?<!\.)', suffix=r'\b'),
246 |              Name.Builtin),
247 |             (r'(?<!\.)(self|Ellipsis|NotImplemented|cls)\b', Name.Builtin.Pseudo),
248 |             (words((
249 |                 'ArithmeticError', 'AssertionError', 'AttributeError',
250 |                 'BaseException', 'BufferError', 'BytesWarning', 'DeprecationWarning',
251 |                 'EOFError', 'EnvironmentError', 'Exception', 'FloatingPointError',
252 |                 'FutureWarning', 'GeneratorExit', 'IOError', 'ImportError',
253 |                 'ImportWarning', 'IndentationError', 'IndexError', 'KeyError',
254 |                 'KeyboardInterrupt', 'LookupError', 'MemoryError', 'NameError',
255 |                 'NotImplementedError', 'OSError', 'OverflowError',
256 |                 'PendingDeprecationWarning', 'ReferenceError', 'ResourceWarning',
257 |                 'RuntimeError', 'RuntimeWarning', 'StopIteration',
258 |                 'SyntaxError', 'SyntaxWarning', 'SystemError', 'SystemExit',
259 |                 'TabError', 'TypeError', 'UnboundLocalError', 'UnicodeDecodeError',
260 |                 'UnicodeEncodeError', 'UnicodeError', 'UnicodeTranslateError',
261 |                 'UnicodeWarning', 'UserWarning', 'ValueError', 'VMSError',
262 |                 'Warning', 'WindowsError', 'ZeroDivisionError',
263 |                 # new builtin exceptions from PEP 3151
264 |                 'BlockingIOError', 'ChildProcessError', 'ConnectionError',
265 |                 'BrokenPipeError', 'ConnectionAbortedError', 'ConnectionRefusedError',
266 |                 'ConnectionResetError', 'FileExistsError', 'FileNotFoundError',
267 |                 'InterruptedError', 'IsADirectoryError', 'NotADirectoryError',
268 |                 'PermissionError', 'ProcessLookupError', 'TimeoutError',
269 |                 # others new in Python 3
270 |                 'StopAsyncIteration', 'ModuleNotFoundError', 'RecursionError',
271 |                 'EncodingWarning'),
272 |                 prefix=r'(?<!\.)', suffix=r'\b'),
273 |              Name.Exception),
274 |         ],
275 |         'magicfuncs': [
276 |             (words((
277 |                 '__abs__', '__add__', '__aenter__', '__aexit__', '__aiter__',
278 |                 '__and__', '__anext__', '__await__', '__bool__', '__bytes__',
279 |                 '__call__', '__complex__', '__contains__', '__del__', '__delattr__',
280 |                 '__delete__', '__delitem__', '__dir__', '__divmod__', '__enter__',
281 |                 '__eq__', '__exit__', '__float__', '__floordiv__', '__format__',
282 |                 '__ge__', '__get__', '__getattr__', '__getattribute__',
283 |                 '__getitem__', '__gt__', '__hash__', '__iadd__', '__iand__',
284 |                 '__ifloordiv__', '__ilshift__', '__imatmul__', '__imod__',
285 |                 '__imul__', '__index__', '__init__', '__instancecheck__',
286 |                 '__int__', '__invert__', '__ior__', '__ipow__', '__irshift__',
287 |                 '__isub__', '__iter__', '__itruediv__', '__ixor__', '__le__',
288 |                 '__len__', '__length_hint__', '__lshift__', '__lt__', '__matmul__',
289 |                 '__missing__', '__mod__', '__mul__', '__ne__', '__neg__',
290 |                 '__new__', '__next__', '__or__', '__pos__', '__pow__',
291 |                 '__prepare__', '__radd__', '__rand__', '__rdivmod__', '__repr__',
292 |                 '__reversed__', '__rfloordiv__', '__rlshift__', '__rmatmul__',
293 |                 '__rmod__', '__rmul__', '__ror__', '__round__', '__rpow__',
294 |                 '__rrshift__', '__rshift__', '__rsub__', '__rtruediv__',
295 |                 '__rxor__', '__set__', '__setattr__', '__setitem__', '__str__',
296 |                 '__sub__', '__subclasscheck__', '__truediv__',
297 |                 '__xor__'), suffix=r'\b'),
298 |              Name.Function.Magic),
299 |         ],
300 |         'magicvars': [
301 |             (words((
302 |                 '__annotations__', '__bases__', '__class__', '__closure__',
303 |                 '__code__', '__defaults__', '__dict__', '__doc__', '__file__',
304 |                 '__func__', '__globals__', '__kwdefaults__', '__module__',
305 |                 '__mro__', '__name__', '__objclass__', '__qualname__',
306 |                 '__self__', '__slots__', '__weakref__'), suffix=r'\b'),
307 |              Name.Variable.Magic),
308 |         ],
309 |         'numbers': [
310 |             (r'(\d(?:_?\d)*\.(?:\d(?:_?\d)*)?|(?:\d(?:_?\d)*)?\.\d(?:_?\d)*)'
311 |              r'([eE][+-]?\d(?:_?\d)*)?', Number.Float),
312 |             (r'\d(?:_?\d)*[eE][+-]?\d(?:_?\d)*j?', Number.Float),
313 |             (r'0[oO](?:_?[0-7])+', Number.Oct),
314 |             (r'0[bB](?:_?[01])+', Number.Bin),
315 |             (r'0[xX](?:_?[a-fA-F0-9])+', Number.Hex),
316 |             (r'\d(?:_?\d)*', Number.Integer),
317 |         ],
318 |         'name': [
319 |             (r'@' + uni_name, Name.Decorator),
320 |             (r'@', Operator),  # new matrix multiplication operator
321 |             (uni_name, Name),
322 |         ],
323 |         'funcname': [
324 |             include('magicfuncs'),
325 |             (uni_name, Name.Function, '#pop'),
326 |             default('#pop'),
327 |         ],
328 |         'classname': [
329 |             (uni_name, Name.Class, '#pop'),
330 |         ],
331 |         'import': [
332 |             (r'(\s+)(as)(\s+)', bygroups(Whitespace, Keyword, Whitespace)),
333 |             (r'\.', Name.Namespace),
334 |             (uni_name, Name.Namespace),
335 |             (r'(\s*)(,)(\s*)', bygroups(Whitespace, Operator, Whitespace)),
336 |             default('#pop')  # all else: go back
337 |         ],
338 |         'fromimport': [
339 |             (r'(\s+)(import)\b', bygroups(Whitespace, Keyword.Namespace), '#pop'),
340 |             (r'\.', Name.Namespace),
341 |             # if None occurs here, it's "raise x from None", since None can
342 |             # never be a module name
343 |             (r'None\b', Keyword.Constant, '#pop'),
344 |             (uni_name, Name.Namespace),
345 |             default('#pop'),
346 |         ],
347 |         'rfstringescape': [
348 |             (r'\{\{', String.Escape),
349 |             (r'\}\}', String.Escape),
350 |         ],
351 |         'fstringescape': [
352 |             include('rfstringescape'),
353 |             include('stringescape'),
354 |         ],
355 |         'bytesescape': [
356 |             (r'\\([\\abfnrtv"\']|\n|x[a-fA-F0-9]{2}|[0-7]{1,3})', String.Escape)
357 |         ],
358 |         'stringescape': [
359 |             (r'\\(N\{.*?\}|u[a-fA-F0-9]{4}|U[a-fA-F0-9]{8})', String.Escape),
360 |             include('bytesescape')
361 |         ],
362 |         'fstrings-single': fstring_rules(String.Single),
363 |         'fstrings-double': fstring_rules(String.Double),
364 |         'strings-single': innerstring_rules(String.Single),
365 |         'strings-double': innerstring_rules(String.Double),
366 |         'dqf': [
367 |             (r'"', String.Double, '#pop'),
368 |             (r'\\\\|\\"|\\\n', String.Escape),  # included here for raw strings
369 |             include('fstrings-double')
370 |         ],
371 |         'sqf': [
372 |             (r"'", String.Single, '#pop'),
[TRUNCATED]
```

.venv/lib/python3.13/site-packages/pip/_vendor/urllib3/packages/__init__.py
```
```

.venv/lib/python3.13/site-packages/pip/_vendor/urllib3/packages/six.py
```
1 | # Copyright (c) 2010-2020 Benjamin Peterson
2 | #
3 | # Permission is hereby granted, free of charge, to any person obtaining a copy
4 | # of this software and associated documentation files (the "Software"), to deal
5 | # in the Software without restriction, including without limitation the rights
6 | # to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
7 | # copies of the Software, and to permit persons to whom the Software is
8 | # furnished to do so, subject to the following conditions:
9 | #
10 | # The above copyright notice and this permission notice shall be included in all
11 | # copies or substantial portions of the Software.
12 | #
13 | # THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
14 | # IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
15 | # FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
16 | # AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
17 | # LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
18 | # OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
19 | # SOFTWARE.
20 | 
21 | """Utilities for writing code that runs on Python 2 and 3"""
22 | 
23 | from __future__ import absolute_import
24 | 
25 | import functools
26 | import itertools
27 | import operator
28 | import sys
29 | import types
30 | 
31 | __author__ = "Benjamin Peterson <benjamin@python.org>"
32 | __version__ = "1.16.0"
33 | 
34 | 
35 | # Useful for very coarse version differentiation.
36 | PY2 = sys.version_info[0] == 2
37 | PY3 = sys.version_info[0] == 3
38 | PY34 = sys.version_info[0:2] >= (3, 4)
39 | 
40 | if PY3:
41 |     string_types = (str,)
42 |     integer_types = (int,)
43 |     class_types = (type,)
44 |     text_type = str
45 |     binary_type = bytes
46 | 
47 |     MAXSIZE = sys.maxsize
48 | else:
49 |     string_types = (basestring,)
50 |     integer_types = (int, long)
51 |     class_types = (type, types.ClassType)
52 |     text_type = unicode
53 |     binary_type = str
54 | 
55 |     if sys.platform.startswith("java"):
56 |         # Jython always uses 32 bits.
57 |         MAXSIZE = int((1 << 31) - 1)
58 |     else:
59 |         # It's possible to have sizeof(long) != sizeof(Py_ssize_t).
60 |         class X(object):
61 |             def __len__(self):
62 |                 return 1 << 31
63 | 
64 |         try:
65 |             len(X())
66 |         except OverflowError:
67 |             # 32-bit
68 |             MAXSIZE = int((1 << 31) - 1)
69 |         else:
70 |             # 64-bit
71 |             MAXSIZE = int((1 << 63) - 1)
72 |         del X
73 | 
74 | if PY34:
75 |     from importlib.util import spec_from_loader
76 | else:
77 |     spec_from_loader = None
78 | 
79 | 
80 | def _add_doc(func, doc):
81 |     """Add documentation to a function."""
82 |     func.__doc__ = doc
83 | 
84 | 
85 | def _import_module(name):
86 |     """Import module, returning the module after the last dot."""
87 |     __import__(name)
88 |     return sys.modules[name]
89 | 
90 | 
91 | class _LazyDescr(object):
92 |     def __init__(self, name):
93 |         self.name = name
94 | 
95 |     def __get__(self, obj, tp):
96 |         result = self._resolve()
97 |         setattr(obj, self.name, result)  # Invokes __set__.
98 |         try:
99 |             # This is a bit ugly, but it avoids running this again by
100 |             # removing this descriptor.
101 |             delattr(obj.__class__, self.name)
102 |         except AttributeError:
103 |             pass
104 |         return result
105 | 
106 | 
107 | class MovedModule(_LazyDescr):
108 |     def __init__(self, name, old, new=None):
109 |         super(MovedModule, self).__init__(name)
110 |         if PY3:
111 |             if new is None:
112 |                 new = name
113 |             self.mod = new
114 |         else:
115 |             self.mod = old
116 | 
117 |     def _resolve(self):
118 |         return _import_module(self.mod)
119 | 
120 |     def __getattr__(self, attr):
121 |         _module = self._resolve()
122 |         value = getattr(_module, attr)
123 |         setattr(self, attr, value)
124 |         return value
125 | 
126 | 
127 | class _LazyModule(types.ModuleType):
128 |     def __init__(self, name):
129 |         super(_LazyModule, self).__init__(name)
130 |         self.__doc__ = self.__class__.__doc__
131 | 
132 |     def __dir__(self):
133 |         attrs = ["__doc__", "__name__"]
134 |         attrs += [attr.name for attr in self._moved_attributes]
135 |         return attrs
136 | 
137 |     # Subclasses should override this
138 |     _moved_attributes = []
139 | 
140 | 
141 | class MovedAttribute(_LazyDescr):
142 |     def __init__(self, name, old_mod, new_mod, old_attr=None, new_attr=None):
143 |         super(MovedAttribute, self).__init__(name)
144 |         if PY3:
145 |             if new_mod is None:
146 |                 new_mod = name
147 |             self.mod = new_mod
148 |             if new_attr is None:
149 |                 if old_attr is None:
150 |                     new_attr = name
151 |                 else:
152 |                     new_attr = old_attr
153 |             self.attr = new_attr
154 |         else:
155 |             self.mod = old_mod
156 |             if old_attr is None:
157 |                 old_attr = name
158 |             self.attr = old_attr
159 | 
160 |     def _resolve(self):
161 |         module = _import_module(self.mod)
162 |         return getattr(module, self.attr)
163 | 
164 | 
165 | class _SixMetaPathImporter(object):
166 | 
167 |     """
168 |     A meta path importer to import six.moves and its submodules.
169 | 
170 |     This class implements a PEP302 finder and loader. It should be compatible
171 |     with Python 2.5 and all existing versions of Python3
172 |     """
173 | 
174 |     def __init__(self, six_module_name):
175 |         self.name = six_module_name
176 |         self.known_modules = {}
177 | 
178 |     def _add_module(self, mod, *fullnames):
179 |         for fullname in fullnames:
180 |             self.known_modules[self.name + "." + fullname] = mod
181 | 
182 |     def _get_module(self, fullname):
183 |         return self.known_modules[self.name + "." + fullname]
184 | 
185 |     def find_module(self, fullname, path=None):
186 |         if fullname in self.known_modules:
187 |             return self
188 |         return None
189 | 
190 |     def find_spec(self, fullname, path, target=None):
191 |         if fullname in self.known_modules:
192 |             return spec_from_loader(fullname, self)
193 |         return None
194 | 
195 |     def __get_module(self, fullname):
196 |         try:
197 |             return self.known_modules[fullname]
198 |         except KeyError:
199 |             raise ImportError("This loader does not know module " + fullname)
200 | 
201 |     def load_module(self, fullname):
202 |         try:
203 |             # in case of a reload
204 |             return sys.modules[fullname]
205 |         except KeyError:
206 |             pass
207 |         mod = self.__get_module(fullname)
208 |         if isinstance(mod, MovedModule):
209 |             mod = mod._resolve()
210 |         else:
211 |             mod.__loader__ = self
212 |         sys.modules[fullname] = mod
213 |         return mod
214 | 
215 |     def is_package(self, fullname):
216 |         """
217 |         Return true, if the named module is a package.
218 | 
219 |         We need this method to get correct spec objects with
220 |         Python 3.4 (see PEP451)
221 |         """
222 |         return hasattr(self.__get_module(fullname), "__path__")
223 | 
224 |     def get_code(self, fullname):
225 |         """Return None
226 | 
227 |         Required, if is_package is implemented"""
228 |         self.__get_module(fullname)  # eventually raises ImportError
229 |         return None
230 | 
231 |     get_source = get_code  # same as get_code
232 | 
233 |     def create_module(self, spec):
234 |         return self.load_module(spec.name)
235 | 
236 |     def exec_module(self, module):
237 |         pass
238 | 
239 | 
240 | _importer = _SixMetaPathImporter(__name__)
241 | 
242 | 
243 | class _MovedItems(_LazyModule):
244 | 
245 |     """Lazy loading of moved objects"""
246 | 
247 |     __path__ = []  # mark as package
248 | 
249 | 
250 | _moved_attributes = [
251 |     MovedAttribute("cStringIO", "cStringIO", "io", "StringIO"),
252 |     MovedAttribute("filter", "itertools", "builtins", "ifilter", "filter"),
253 |     MovedAttribute(
254 |         "filterfalse", "itertools", "itertools", "ifilterfalse", "filterfalse"
255 |     ),
256 |     MovedAttribute("input", "__builtin__", "builtins", "raw_input", "input"),
257 |     MovedAttribute("intern", "__builtin__", "sys"),
258 |     MovedAttribute("map", "itertools", "builtins", "imap", "map"),
259 |     MovedAttribute("getcwd", "os", "os", "getcwdu", "getcwd"),
260 |     MovedAttribute("getcwdb", "os", "os", "getcwd", "getcwdb"),
261 |     MovedAttribute("getoutput", "commands", "subprocess"),
262 |     MovedAttribute("range", "__builtin__", "builtins", "xrange", "range"),
263 |     MovedAttribute(
264 |         "reload_module", "__builtin__", "importlib" if PY34 else "imp", "reload"
265 |     ),
266 |     MovedAttribute("reduce", "__builtin__", "functools"),
267 |     MovedAttribute("shlex_quote", "pipes", "shlex", "quote"),
268 |     MovedAttribute("StringIO", "StringIO", "io"),
269 |     MovedAttribute("UserDict", "UserDict", "collections"),
270 |     MovedAttribute("UserList", "UserList", "collections"),
271 |     MovedAttribute("UserString", "UserString", "collections"),
272 |     MovedAttribute("xrange", "__builtin__", "builtins", "xrange", "range"),
273 |     MovedAttribute("zip", "itertools", "builtins", "izip", "zip"),
274 |     MovedAttribute(
275 |         "zip_longest", "itertools", "itertools", "izip_longest", "zip_longest"
276 |     ),
277 |     MovedModule("builtins", "__builtin__"),
278 |     MovedModule("configparser", "ConfigParser"),
279 |     MovedModule(
280 |         "collections_abc",
281 |         "collections",
282 |         "collections.abc" if sys.version_info >= (3, 3) else "collections",
283 |     ),
284 |     MovedModule("copyreg", "copy_reg"),
285 |     MovedModule("dbm_gnu", "gdbm", "dbm.gnu"),
286 |     MovedModule("dbm_ndbm", "dbm", "dbm.ndbm"),
287 |     MovedModule(
288 |         "_dummy_thread",
289 |         "dummy_thread",
290 |         "_dummy_thread" if sys.version_info < (3, 9) else "_thread",
291 |     ),
292 |     MovedModule("http_cookiejar", "cookielib", "http.cookiejar"),
293 |     MovedModule("http_cookies", "Cookie", "http.cookies"),
294 |     MovedModule("html_entities", "htmlentitydefs", "html.entities"),
295 |     MovedModule("html_parser", "HTMLParser", "html.parser"),
296 |     MovedModule("http_client", "httplib", "http.client"),
297 |     MovedModule("email_mime_base", "email.MIMEBase", "email.mime.base"),
298 |     MovedModule("email_mime_image", "email.MIMEImage", "email.mime.image"),
299 |     MovedModule("email_mime_multipart", "email.MIMEMultipart", "email.mime.multipart"),
300 |     MovedModule(
301 |         "email_mime_nonmultipart", "email.MIMENonMultipart", "email.mime.nonmultipart"
302 |     ),
303 |     MovedModule("email_mime_text", "email.MIMEText", "email.mime.text"),
304 |     MovedModule("BaseHTTPServer", "BaseHTTPServer", "http.server"),
305 |     MovedModule("CGIHTTPServer", "CGIHTTPServer", "http.server"),
306 |     MovedModule("SimpleHTTPServer", "SimpleHTTPServer", "http.server"),
307 |     MovedModule("cPickle", "cPickle", "pickle"),
308 |     MovedModule("queue", "Queue"),
309 |     MovedModule("reprlib", "repr"),
310 |     MovedModule("socketserver", "SocketServer"),
311 |     MovedModule("_thread", "thread", "_thread"),
312 |     MovedModule("tkinter", "Tkinter"),
313 |     MovedModule("tkinter_dialog", "Dialog", "tkinter.dialog"),
314 |     MovedModule("tkinter_filedialog", "FileDialog", "tkinter.filedialog"),
315 |     MovedModule("tkinter_scrolledtext", "ScrolledText", "tkinter.scrolledtext"),
316 |     MovedModule("tkinter_simpledialog", "SimpleDialog", "tkinter.simpledialog"),
317 |     MovedModule("tkinter_tix", "Tix", "tkinter.tix"),
318 |     MovedModule("tkinter_ttk", "ttk", "tkinter.ttk"),
319 |     MovedModule("tkinter_constants", "Tkconstants", "tkinter.constants"),
320 |     MovedModule("tkinter_dnd", "Tkdnd", "tkinter.dnd"),
321 |     MovedModule("tkinter_colorchooser", "tkColorChooser", "tkinter.colorchooser"),
322 |     MovedModule("tkinter_commondialog", "tkCommonDialog", "tkinter.commondialog"),
323 |     MovedModule("tkinter_tkfiledialog", "tkFileDialog", "tkinter.filedialog"),
324 |     MovedModule("tkinter_font", "tkFont", "tkinter.font"),
325 |     MovedModule("tkinter_messagebox", "tkMessageBox", "tkinter.messagebox"),
326 |     MovedModule("tkinter_tksimpledialog", "tkSimpleDialog", "tkinter.simpledialog"),
327 |     MovedModule("urllib_parse", __name__ + ".moves.urllib_parse", "urllib.parse"),
328 |     MovedModule("urllib_error", __name__ + ".moves.urllib_error", "urllib.error"),
329 |     MovedModule("urllib", __name__ + ".moves.urllib", __name__ + ".moves.urllib"),
330 |     MovedModule("urllib_robotparser", "robotparser", "urllib.robotparser"),
331 |     MovedModule("xmlrpc_client", "xmlrpclib", "xmlrpc.client"),
332 |     MovedModule("xmlrpc_server", "SimpleXMLRPCServer", "xmlrpc.server"),
333 | ]
334 | # Add windows specific modules.
335 | if sys.platform == "win32":
336 |     _moved_attributes += [
337 |         MovedModule("winreg", "_winreg"),
338 |     ]
339 | 
340 | for attr in _moved_attributes:
341 |     setattr(_MovedItems, attr.name, attr)
342 |     if isinstance(attr, MovedModule):
343 |         _importer._add_module(attr, "moves." + attr.name)
344 | del attr
345 | 
346 | _MovedItems._moved_attributes = _moved_attributes
347 | 
348 | moves = _MovedItems(__name__ + ".moves")
349 | _importer._add_module(moves, "moves")
350 | 
351 | 
352 | class Module_six_moves_urllib_parse(_LazyModule):
353 | 
354 |     """Lazy loading of moved objects in six.moves.urllib_parse"""
355 | 
356 | 
357 | _urllib_parse_moved_attributes = [
358 |     MovedAttribute("ParseResult", "urlparse", "urllib.parse"),
359 |     MovedAttribute("SplitResult", "urlparse", "urllib.parse"),
360 |     MovedAttribute("parse_qs", "urlparse", "urllib.parse"),
361 |     MovedAttribute("parse_qsl", "urlparse", "urllib.parse"),
362 |     MovedAttribute("urldefrag", "urlparse", "urllib.parse"),
363 |     MovedAttribute("urljoin", "urlparse", "urllib.parse"),
364 |     MovedAttribute("urlparse", "urlparse", "urllib.parse"),
365 |     MovedAttribute("urlsplit", "urlparse", "urllib.parse"),
366 |     MovedAttribute("urlunparse", "urlparse", "urllib.parse"),
367 |     MovedAttribute("urlunsplit", "urlparse", "urllib.parse"),
368 |     MovedAttribute("quote", "urllib", "urllib.parse"),
369 |     MovedAttribute("quote_plus", "urllib", "urllib.parse"),
370 |     MovedAttribute("unquote", "urllib", "urllib.parse"),
[TRUNCATED]
```

.venv/lib/python3.13/site-packages/pip/_vendor/urllib3/contrib/__init__.py
```
```

.venv/lib/python3.13/site-packages/pip/_vendor/urllib3/contrib/_appengine_environ.py
```
1 | """
2 | This module provides means to detect the App Engine environment.
3 | """
4 | 
5 | import os
6 | 
7 | 
8 | def is_appengine():
9 |     return is_local_appengine() or is_prod_appengine()
10 | 
11 | 
12 | def is_appengine_sandbox():
13 |     """Reports if the app is running in the first generation sandbox.
14 | 
15 |     The second generation runtimes are technically still in a sandbox, but it
16 |     is much less restrictive, so generally you shouldn't need to check for it.
17 |     see https://cloud.google.com/appengine/docs/standard/runtimes
18 |     """
19 |     return is_appengine() and os.environ["APPENGINE_RUNTIME"] == "python27"
20 | 
21 | 
22 | def is_local_appengine():
23 |     return "APPENGINE_RUNTIME" in os.environ and os.environ.get(
24 |         "SERVER_SOFTWARE", ""
25 |     ).startswith("Development/")
26 | 
27 | 
28 | def is_prod_appengine():
29 |     return "APPENGINE_RUNTIME" in os.environ and os.environ.get(
30 |         "SERVER_SOFTWARE", ""
31 |     ).startswith("Google App Engine/")
32 | 
33 | 
34 | def is_prod_appengine_mvms():
35 |     """Deprecated."""
36 |     return False
```

.venv/lib/python3.13/site-packages/pip/_vendor/urllib3/contrib/appengine.py
```
1 | """
2 | This module provides a pool manager that uses Google App Engine's
3 | `URLFetch Service <https://cloud.google.com/appengine/docs/python/urlfetch>`_.
4 | 
5 | Example usage::
6 | 
7 |     from pip._vendor.urllib3 import PoolManager
8 |     from pip._vendor.urllib3.contrib.appengine import AppEngineManager, is_appengine_sandbox
9 | 
10 |     if is_appengine_sandbox():
11 |         # AppEngineManager uses AppEngine's URLFetch API behind the scenes
12 |         http = AppEngineManager()
13 |     else:
14 |         # PoolManager uses a socket-level API behind the scenes
15 |         http = PoolManager()
16 | 
17 |     r = http.request('GET', 'https://google.com/')
18 | 
19 | There are `limitations <https://cloud.google.com/appengine/docs/python/\
20 | urlfetch/#Python_Quotas_and_limits>`_ to the URLFetch service and it may not be
21 | the best choice for your application. There are three options for using
22 | urllib3 on Google App Engine:
23 | 
24 | 1. You can use :class:`AppEngineManager` with URLFetch. URLFetch is
25 |    cost-effective in many circumstances as long as your usage is within the
26 |    limitations.
27 | 2. You can use a normal :class:`~urllib3.PoolManager` by enabling sockets.
28 |    Sockets also have `limitations and restrictions
29 |    <https://cloud.google.com/appengine/docs/python/sockets/\
30 |    #limitations-and-restrictions>`_ and have a lower free quota than URLFetch.
31 |    To use sockets, be sure to specify the following in your ``app.yaml``::
32 | 
33 |         env_variables:
34 |             GAE_USE_SOCKETS_HTTPLIB : 'true'
35 | 
36 | 3. If you are using `App Engine Flexible
37 | <https://cloud.google.com/appengine/docs/flexible/>`_, you can use the standard
38 | :class:`PoolManager` without any configuration or special environment variables.
39 | """
40 | 
41 | from __future__ import absolute_import
42 | 
43 | import io
44 | import logging
45 | import warnings
46 | 
47 | from ..exceptions import (
48 |     HTTPError,
49 |     HTTPWarning,
50 |     MaxRetryError,
51 |     ProtocolError,
52 |     SSLError,
53 |     TimeoutError,
54 | )
55 | from ..packages.six.moves.urllib.parse import urljoin
56 | from ..request import RequestMethods
57 | from ..response import HTTPResponse
58 | from ..util.retry import Retry
59 | from ..util.timeout import Timeout
60 | from . import _appengine_environ
61 | 
62 | try:
63 |     from google.appengine.api import urlfetch
64 | except ImportError:
65 |     urlfetch = None
66 | 
67 | 
68 | log = logging.getLogger(__name__)
69 | 
70 | 
71 | class AppEnginePlatformWarning(HTTPWarning):
72 |     pass
73 | 
74 | 
75 | class AppEnginePlatformError(HTTPError):
76 |     pass
77 | 
78 | 
79 | class AppEngineManager(RequestMethods):
80 |     """
81 |     Connection manager for Google App Engine sandbox applications.
82 | 
83 |     This manager uses the URLFetch service directly instead of using the
84 |     emulated httplib, and is subject to URLFetch limitations as described in
85 |     the App Engine documentation `here
86 |     <https://cloud.google.com/appengine/docs/python/urlfetch>`_.
87 | 
88 |     Notably it will raise an :class:`AppEnginePlatformError` if:
89 |         * URLFetch is not available.
90 |         * If you attempt to use this on App Engine Flexible, as full socket
91 |           support is available.
92 |         * If a request size is more than 10 megabytes.
93 |         * If a response size is more than 32 megabytes.
94 |         * If you use an unsupported request method such as OPTIONS.
95 | 
96 |     Beyond those cases, it will raise normal urllib3 errors.
97 |     """
98 | 
99 |     def __init__(
100 |         self,
101 |         headers=None,
102 |         retries=None,
103 |         validate_certificate=True,
104 |         urlfetch_retries=True,
105 |     ):
106 |         if not urlfetch:
107 |             raise AppEnginePlatformError(
108 |                 "URLFetch is not available in this environment."
109 |             )
110 | 
111 |         warnings.warn(
112 |             "urllib3 is using URLFetch on Google App Engine sandbox instead "
113 |             "of sockets. To use sockets directly instead of URLFetch see "
114 |             "https://urllib3.readthedocs.io/en/1.26.x/reference/urllib3.contrib.html.",
115 |             AppEnginePlatformWarning,
116 |         )
117 | 
118 |         RequestMethods.__init__(self, headers)
119 |         self.validate_certificate = validate_certificate
120 |         self.urlfetch_retries = urlfetch_retries
121 | 
122 |         self.retries = retries or Retry.DEFAULT
123 | 
124 |     def __enter__(self):
125 |         return self
126 | 
127 |     def __exit__(self, exc_type, exc_val, exc_tb):
128 |         # Return False to re-raise any potential exceptions
129 |         return False
130 | 
131 |     def urlopen(
132 |         self,
133 |         method,
134 |         url,
135 |         body=None,
136 |         headers=None,
137 |         retries=None,
138 |         redirect=True,
139 |         timeout=Timeout.DEFAULT_TIMEOUT,
140 |         **response_kw
141 |     ):
142 | 
143 |         retries = self._get_retries(retries, redirect)
144 | 
145 |         try:
146 |             follow_redirects = redirect and retries.redirect != 0 and retries.total
147 |             response = urlfetch.fetch(
148 |                 url,
149 |                 payload=body,
150 |                 method=method,
151 |                 headers=headers or {},
152 |                 allow_truncated=False,
153 |                 follow_redirects=self.urlfetch_retries and follow_redirects,
154 |                 deadline=self._get_absolute_timeout(timeout),
155 |                 validate_certificate=self.validate_certificate,
156 |             )
157 |         except urlfetch.DeadlineExceededError as e:
158 |             raise TimeoutError(self, e)
159 | 
160 |         except urlfetch.InvalidURLError as e:
161 |             if "too large" in str(e):
162 |                 raise AppEnginePlatformError(
163 |                     "URLFetch request too large, URLFetch only "
164 |                     "supports requests up to 10mb in size.",
165 |                     e,
166 |                 )
167 |             raise ProtocolError(e)
168 | 
169 |         except urlfetch.DownloadError as e:
170 |             if "Too many redirects" in str(e):
171 |                 raise MaxRetryError(self, url, reason=e)
172 |             raise ProtocolError(e)
173 | 
174 |         except urlfetch.ResponseTooLargeError as e:
175 |             raise AppEnginePlatformError(
176 |                 "URLFetch response too large, URLFetch only supports"
177 |                 "responses up to 32mb in size.",
178 |                 e,
179 |             )
180 | 
181 |         except urlfetch.SSLCertificateError as e:
182 |             raise SSLError(e)
183 | 
184 |         except urlfetch.InvalidMethodError as e:
185 |             raise AppEnginePlatformError(
186 |                 "URLFetch does not support method: %s" % method, e
187 |             )
188 | 
189 |         http_response = self._urlfetch_response_to_http_response(
190 |             response, retries=retries, **response_kw
191 |         )
192 | 
193 |         # Handle redirect?
194 |         redirect_location = redirect and http_response.get_redirect_location()
195 |         if redirect_location:
196 |             # Check for redirect response
197 |             if self.urlfetch_retries and retries.raise_on_redirect:
198 |                 raise MaxRetryError(self, url, "too many redirects")
199 |             else:
200 |                 if http_response.status == 303:
201 |                     method = "GET"
202 | 
203 |                 try:
204 |                     retries = retries.increment(
205 |                         method, url, response=http_response, _pool=self
206 |                     )
207 |                 except MaxRetryError:
208 |                     if retries.raise_on_redirect:
209 |                         raise MaxRetryError(self, url, "too many redirects")
210 |                     return http_response
211 | 
212 |                 retries.sleep_for_retry(http_response)
213 |                 log.debug("Redirecting %s -> %s", url, redirect_location)
214 |                 redirect_url = urljoin(url, redirect_location)
215 |                 return self.urlopen(
216 |                     method,
217 |                     redirect_url,
218 |                     body,
219 |                     headers,
220 |                     retries=retries,
221 |                     redirect=redirect,
222 |                     timeout=timeout,
223 |                     **response_kw
224 |                 )
225 | 
226 |         # Check if we should retry the HTTP response.
227 |         has_retry_after = bool(http_response.headers.get("Retry-After"))
228 |         if retries.is_retry(method, http_response.status, has_retry_after):
229 |             retries = retries.increment(method, url, response=http_response, _pool=self)
230 |             log.debug("Retry: %s", url)
231 |             retries.sleep(http_response)
232 |             return self.urlopen(
233 |                 method,
234 |                 url,
235 |                 body=body,
236 |                 headers=headers,
237 |                 retries=retries,
238 |                 redirect=redirect,
239 |                 timeout=timeout,
240 |                 **response_kw
241 |             )
242 | 
243 |         return http_response
244 | 
245 |     def _urlfetch_response_to_http_response(self, urlfetch_resp, **response_kw):
246 | 
247 |         if is_prod_appengine():
248 |             # Production GAE handles deflate encoding automatically, but does
249 |             # not remove the encoding header.
250 |             content_encoding = urlfetch_resp.headers.get("content-encoding")
251 | 
252 |             if content_encoding == "deflate":
253 |                 del urlfetch_resp.headers["content-encoding"]
254 | 
255 |         transfer_encoding = urlfetch_resp.headers.get("transfer-encoding")
256 |         # We have a full response's content,
257 |         # so let's make sure we don't report ourselves as chunked data.
258 |         if transfer_encoding == "chunked":
259 |             encodings = transfer_encoding.split(",")
260 |             encodings.remove("chunked")
261 |             urlfetch_resp.headers["transfer-encoding"] = ",".join(encodings)
262 | 
263 |         original_response = HTTPResponse(
264 |             # In order for decoding to work, we must present the content as
265 |             # a file-like object.
266 |             body=io.BytesIO(urlfetch_resp.content),
267 |             msg=urlfetch_resp.header_msg,
268 |             headers=urlfetch_resp.headers,
269 |             status=urlfetch_resp.status_code,
270 |             **response_kw
271 |         )
272 | 
273 |         return HTTPResponse(
274 |             body=io.BytesIO(urlfetch_resp.content),
275 |             headers=urlfetch_resp.headers,
276 |             status=urlfetch_resp.status_code,
277 |             original_response=original_response,
278 |             **response_kw
279 |         )
280 | 
281 |     def _get_absolute_timeout(self, timeout):
282 |         if timeout is Timeout.DEFAULT_TIMEOUT:
283 |             return None  # Defer to URLFetch's default.
284 |         if isinstance(timeout, Timeout):
285 |             if timeout._read is not None or timeout._connect is not None:
286 |                 warnings.warn(
287 |                     "URLFetch does not support granular timeout settings, "
288 |                     "reverting to total or default URLFetch timeout.",
289 |                     AppEnginePlatformWarning,
290 |                 )
291 |             return timeout.total
292 |         return timeout
293 | 
294 |     def _get_retries(self, retries, redirect):
295 |         if not isinstance(retries, Retry):
296 |             retries = Retry.from_int(retries, redirect=redirect, default=self.retries)
297 | 
298 |         if retries.connect or retries.read or retries.redirect:
299 |             warnings.warn(
300 |                 "URLFetch only supports total retries and does not "
301 |                 "recognize connect, read, or redirect retry parameters.",
302 |                 AppEnginePlatformWarning,
303 |             )
304 | 
305 |         return retries
306 | 
307 | 
308 | # Alias methods from _appengine_environ to maintain public API interface.
309 | 
310 | is_appengine = _appengine_environ.is_appengine
311 | is_appengine_sandbox = _appengine_environ.is_appengine_sandbox
312 | is_local_appengine = _appengine_environ.is_local_appengine
313 | is_prod_appengine = _appengine_environ.is_prod_appengine
314 | is_prod_appengine_mvms = _appengine_environ.is_prod_appengine_mvms
```

.venv/lib/python3.13/site-packages/pip/_vendor/urllib3/contrib/ntlmpool.py
```
1 | """
2 | NTLM authenticating pool, contributed by erikcederstran
3 | 
4 | Issue #10, see: http://code.google.com/p/urllib3/issues/detail?id=10
5 | """
6 | from __future__ import absolute_import
7 | 
8 | import warnings
9 | from logging import getLogger
10 | 
11 | from ntlm import ntlm
12 | 
13 | from .. import HTTPSConnectionPool
14 | from ..packages.six.moves.http_client import HTTPSConnection
15 | 
16 | warnings.warn(
17 |     "The 'urllib3.contrib.ntlmpool' module is deprecated and will be removed "
18 |     "in urllib3 v2.0 release, urllib3 is not able to support it properly due "
19 |     "to reasons listed in issue: https://github.com/urllib3/urllib3/issues/2282. "
20 |     "If you are a user of this module please comment in the mentioned issue.",
21 |     DeprecationWarning,
22 | )
23 | 
24 | log = getLogger(__name__)
25 | 
26 | 
27 | class NTLMConnectionPool(HTTPSConnectionPool):
28 |     """
29 |     Implements an NTLM authentication version of an urllib3 connection pool
30 |     """
31 | 
32 |     scheme = "https"
33 | 
34 |     def __init__(self, user, pw, authurl, *args, **kwargs):
35 |         """
36 |         authurl is a random URL on the server that is protected by NTLM.
37 |         user is the Windows user, probably in the DOMAIN\\username format.
38 |         pw is the password for the user.
39 |         """
40 |         super(NTLMConnectionPool, self).__init__(*args, **kwargs)
41 |         self.authurl = authurl
42 |         self.rawuser = user
43 |         user_parts = user.split("\\", 1)
44 |         self.domain = user_parts[0].upper()
45 |         self.user = user_parts[1]
46 |         self.pw = pw
47 | 
48 |     def _new_conn(self):
49 |         # Performs the NTLM handshake that secures the connection. The socket
50 |         # must be kept open while requests are performed.
51 |         self.num_connections += 1
52 |         log.debug(
53 |             "Starting NTLM HTTPS connection no. %d: https://%s%s",
54 |             self.num_connections,
55 |             self.host,
56 |             self.authurl,
57 |         )
58 | 
59 |         headers = {"Connection": "Keep-Alive"}
60 |         req_header = "Authorization"
61 |         resp_header = "www-authenticate"
62 | 
63 |         conn = HTTPSConnection(host=self.host, port=self.port)
64 | 
65 |         # Send negotiation message
66 |         headers[req_header] = "NTLM %s" % ntlm.create_NTLM_NEGOTIATE_MESSAGE(
67 |             self.rawuser
68 |         )
69 |         log.debug("Request headers: %s", headers)
70 |         conn.request("GET", self.authurl, None, headers)
71 |         res = conn.getresponse()
72 |         reshdr = dict(res.headers)
73 |         log.debug("Response status: %s %s", res.status, res.reason)
74 |         log.debug("Response headers: %s", reshdr)
75 |         log.debug("Response data: %s [...]", res.read(100))
76 | 
77 |         # Remove the reference to the socket, so that it can not be closed by
78 |         # the response object (we want to keep the socket open)
79 |         res.fp = None
80 | 
81 |         # Server should respond with a challenge message
82 |         auth_header_values = reshdr[resp_header].split(", ")
83 |         auth_header_value = None
84 |         for s in auth_header_values:
85 |             if s[:5] == "NTLM ":
86 |                 auth_header_value = s[5:]
87 |         if auth_header_value is None:
88 |             raise Exception(
89 |                 "Unexpected %s response header: %s" % (resp_header, reshdr[resp_header])
90 |             )
91 | 
92 |         # Send authentication message
93 |         ServerChallenge, NegotiateFlags = ntlm.parse_NTLM_CHALLENGE_MESSAGE(
94 |             auth_header_value
95 |         )
96 |         auth_msg = ntlm.create_NTLM_AUTHENTICATE_MESSAGE(
97 |             ServerChallenge, self.user, self.domain, self.pw, NegotiateFlags
98 |         )
99 |         headers[req_header] = "NTLM %s" % auth_msg
100 |         log.debug("Request headers: %s", headers)
101 |         conn.request("GET", self.authurl, None, headers)
102 |         res = conn.getresponse()
103 |         log.debug("Response status: %s %s", res.status, res.reason)
104 |         log.debug("Response headers: %s", dict(res.headers))
105 |         log.debug("Response data: %s [...]", res.read()[:100])
106 |         if res.status != 200:
107 |             if res.status == 401:
108 |                 raise Exception("Server rejected request: wrong username or password")
109 |             raise Exception("Wrong server response: %s %s" % (res.status, res.reason))
110 | 
111 |         res.fp = None
112 |         log.debug("Connection established")
113 |         return conn
114 | 
115 |     def urlopen(
116 |         self,
117 |         method,
118 |         url,
119 |         body=None,
120 |         headers=None,
121 |         retries=3,
122 |         redirect=True,
123 |         assert_same_host=True,
124 |     ):
125 |         if headers is None:
126 |             headers = {}
127 |         headers["Connection"] = "Keep-Alive"
128 |         return super(NTLMConnectionPool, self).urlopen(
129 |             method, url, body, headers, retries, redirect, assert_same_host
130 |         )
```

.venv/lib/python3.13/site-packages/pip/_vendor/urllib3/contrib/pyopenssl.py
```
1 | """
2 | TLS with SNI_-support for Python 2. Follow these instructions if you would
3 | like to verify TLS certificates in Python 2. Note, the default libraries do
4 | *not* do certificate checking; you need to do additional work to validate
5 | certificates yourself.
6 | 
7 | This needs the following packages installed:
8 | 
9 | * `pyOpenSSL`_ (tested with 16.0.0)
10 | * `cryptography`_ (minimum 1.3.4, from pyopenssl)
11 | * `idna`_ (minimum 2.0, from cryptography)
12 | 
13 | However, pyopenssl depends on cryptography, which depends on idna, so while we
14 | use all three directly here we end up having relatively few packages required.
15 | 
16 | You can install them with the following command:
17 | 
18 | .. code-block:: bash
19 | 
20 |     $ python -m pip install pyopenssl cryptography idna
21 | 
22 | To activate certificate checking, call
23 | :func:`~urllib3.contrib.pyopenssl.inject_into_urllib3` from your Python code
24 | before you begin making HTTP requests. This can be done in a ``sitecustomize``
25 | module, or at any other time before your application begins using ``urllib3``,
26 | like this:
27 | 
28 | .. code-block:: python
29 | 
30 |     try:
31 |         import pip._vendor.urllib3.contrib.pyopenssl as pyopenssl
32 |         pyopenssl.inject_into_urllib3()
33 |     except ImportError:
34 |         pass
35 | 
36 | Now you can use :mod:`urllib3` as you normally would, and it will support SNI
37 | when the required modules are installed.
38 | 
39 | Activating this module also has the positive side effect of disabling SSL/TLS
40 | compression in Python 2 (see `CRIME attack`_).
41 | 
42 | .. _sni: https://en.wikipedia.org/wiki/Server_Name_Indication
43 | .. _crime attack: https://en.wikipedia.org/wiki/CRIME_(security_exploit)
44 | .. _pyopenssl: https://www.pyopenssl.org
45 | .. _cryptography: https://cryptography.io
46 | .. _idna: https://github.com/kjd/idna
47 | """
48 | from __future__ import absolute_import
49 | 
50 | import OpenSSL.crypto
51 | import OpenSSL.SSL
52 | from cryptography import x509
53 | from cryptography.hazmat.backends.openssl import backend as openssl_backend
54 | 
55 | try:
56 |     from cryptography.x509 import UnsupportedExtension
57 | except ImportError:
58 |     # UnsupportedExtension is gone in cryptography >= 2.1.0
59 |     class UnsupportedExtension(Exception):
60 |         pass
61 | 
62 | 
63 | from io import BytesIO
64 | from socket import error as SocketError
65 | from socket import timeout
66 | 
67 | try:  # Platform-specific: Python 2
68 |     from socket import _fileobject
69 | except ImportError:  # Platform-specific: Python 3
70 |     _fileobject = None
71 |     from ..packages.backports.makefile import backport_makefile
72 | 
73 | import logging
74 | import ssl
75 | import sys
76 | import warnings
77 | 
78 | from .. import util
79 | from ..packages import six
80 | from ..util.ssl_ import PROTOCOL_TLS_CLIENT
81 | 
82 | warnings.warn(
83 |     "'urllib3.contrib.pyopenssl' module is deprecated and will be removed "
84 |     "in a future release of urllib3 2.x. Read more in this issue: "
85 |     "https://github.com/urllib3/urllib3/issues/2680",
86 |     category=DeprecationWarning,
87 |     stacklevel=2,
88 | )
89 | 
90 | __all__ = ["inject_into_urllib3", "extract_from_urllib3"]
91 | 
92 | # SNI always works.
93 | HAS_SNI = True
94 | 
95 | # Map from urllib3 to PyOpenSSL compatible parameter-values.
96 | _openssl_versions = {
97 |     util.PROTOCOL_TLS: OpenSSL.SSL.SSLv23_METHOD,
98 |     PROTOCOL_TLS_CLIENT: OpenSSL.SSL.SSLv23_METHOD,
99 |     ssl.PROTOCOL_TLSv1: OpenSSL.SSL.TLSv1_METHOD,
100 | }
101 | 
102 | if hasattr(ssl, "PROTOCOL_SSLv3") and hasattr(OpenSSL.SSL, "SSLv3_METHOD"):
103 |     _openssl_versions[ssl.PROTOCOL_SSLv3] = OpenSSL.SSL.SSLv3_METHOD
104 | 
105 | if hasattr(ssl, "PROTOCOL_TLSv1_1") and hasattr(OpenSSL.SSL, "TLSv1_1_METHOD"):
106 |     _openssl_versions[ssl.PROTOCOL_TLSv1_1] = OpenSSL.SSL.TLSv1_1_METHOD
107 | 
108 | if hasattr(ssl, "PROTOCOL_TLSv1_2") and hasattr(OpenSSL.SSL, "TLSv1_2_METHOD"):
109 |     _openssl_versions[ssl.PROTOCOL_TLSv1_2] = OpenSSL.SSL.TLSv1_2_METHOD
110 | 
111 | 
112 | _stdlib_to_openssl_verify = {
113 |     ssl.CERT_NONE: OpenSSL.SSL.VERIFY_NONE,
114 |     ssl.CERT_OPTIONAL: OpenSSL.SSL.VERIFY_PEER,
115 |     ssl.CERT_REQUIRED: OpenSSL.SSL.VERIFY_PEER
116 |     + OpenSSL.SSL.VERIFY_FAIL_IF_NO_PEER_CERT,
117 | }
118 | _openssl_to_stdlib_verify = dict((v, k) for k, v in _stdlib_to_openssl_verify.items())
119 | 
120 | # OpenSSL will only write 16K at a time
121 | SSL_WRITE_BLOCKSIZE = 16384
122 | 
123 | orig_util_HAS_SNI = util.HAS_SNI
124 | orig_util_SSLContext = util.ssl_.SSLContext
125 | 
126 | 
127 | log = logging.getLogger(__name__)
128 | 
129 | 
130 | def inject_into_urllib3():
131 |     "Monkey-patch urllib3 with PyOpenSSL-backed SSL-support."
132 | 
133 |     _validate_dependencies_met()
134 | 
135 |     util.SSLContext = PyOpenSSLContext
136 |     util.ssl_.SSLContext = PyOpenSSLContext
137 |     util.HAS_SNI = HAS_SNI
138 |     util.ssl_.HAS_SNI = HAS_SNI
139 |     util.IS_PYOPENSSL = True
140 |     util.ssl_.IS_PYOPENSSL = True
141 | 
142 | 
143 | def extract_from_urllib3():
144 |     "Undo monkey-patching by :func:`inject_into_urllib3`."
145 | 
146 |     util.SSLContext = orig_util_SSLContext
147 |     util.ssl_.SSLContext = orig_util_SSLContext
148 |     util.HAS_SNI = orig_util_HAS_SNI
149 |     util.ssl_.HAS_SNI = orig_util_HAS_SNI
150 |     util.IS_PYOPENSSL = False
151 |     util.ssl_.IS_PYOPENSSL = False
152 | 
153 | 
154 | def _validate_dependencies_met():
155 |     """
156 |     Verifies that PyOpenSSL's package-level dependencies have been met.
157 |     Throws `ImportError` if they are not met.
158 |     """
159 |     # Method added in `cryptography==1.1`; not available in older versions
160 |     from cryptography.x509.extensions import Extensions
161 | 
162 |     if getattr(Extensions, "get_extension_for_class", None) is None:
163 |         raise ImportError(
164 |             "'cryptography' module missing required functionality.  "
165 |             "Try upgrading to v1.3.4 or newer."
166 |         )
167 | 
168 |     # pyOpenSSL 0.14 and above use cryptography for OpenSSL bindings. The _x509
169 |     # attribute is only present on those versions.
170 |     from OpenSSL.crypto import X509
171 | 
172 |     x509 = X509()
173 |     if getattr(x509, "_x509", None) is None:
174 |         raise ImportError(
175 |             "'pyOpenSSL' module missing required functionality. "
176 |             "Try upgrading to v0.14 or newer."
177 |         )
178 | 
179 | 
180 | def _dnsname_to_stdlib(name):
181 |     """
182 |     Converts a dNSName SubjectAlternativeName field to the form used by the
183 |     standard library on the given Python version.
184 | 
185 |     Cryptography produces a dNSName as a unicode string that was idna-decoded
186 |     from ASCII bytes. We need to idna-encode that string to get it back, and
187 |     then on Python 3 we also need to convert to unicode via UTF-8 (the stdlib
188 |     uses PyUnicode_FromStringAndSize on it, which decodes via UTF-8).
189 | 
190 |     If the name cannot be idna-encoded then we return None signalling that
191 |     the name given should be skipped.
192 |     """
193 | 
194 |     def idna_encode(name):
195 |         """
196 |         Borrowed wholesale from the Python Cryptography Project. It turns out
197 |         that we can't just safely call `idna.encode`: it can explode for
198 |         wildcard names. This avoids that problem.
199 |         """
200 |         from pip._vendor import idna
201 | 
202 |         try:
203 |             for prefix in [u"*.", u"."]:
204 |                 if name.startswith(prefix):
205 |                     name = name[len(prefix) :]
206 |                     return prefix.encode("ascii") + idna.encode(name)
207 |             return idna.encode(name)
208 |         except idna.core.IDNAError:
209 |             return None
210 | 
211 |     # Don't send IPv6 addresses through the IDNA encoder.
212 |     if ":" in name:
213 |         return name
214 | 
215 |     name = idna_encode(name)
216 |     if name is None:
217 |         return None
218 |     elif sys.version_info >= (3, 0):
219 |         name = name.decode("utf-8")
220 |     return name
221 | 
222 | 
223 | def get_subj_alt_name(peer_cert):
224 |     """
225 |     Given an PyOpenSSL certificate, provides all the subject alternative names.
226 |     """
227 |     # Pass the cert to cryptography, which has much better APIs for this.
228 |     if hasattr(peer_cert, "to_cryptography"):
229 |         cert = peer_cert.to_cryptography()
230 |     else:
231 |         der = OpenSSL.crypto.dump_certificate(OpenSSL.crypto.FILETYPE_ASN1, peer_cert)
232 |         cert = x509.load_der_x509_certificate(der, openssl_backend)
233 | 
234 |     # We want to find the SAN extension. Ask Cryptography to locate it (it's
235 |     # faster than looping in Python)
236 |     try:
237 |         ext = cert.extensions.get_extension_for_class(x509.SubjectAlternativeName).value
238 |     except x509.ExtensionNotFound:
239 |         # No such extension, return the empty list.
240 |         return []
241 |     except (
242 |         x509.DuplicateExtension,
243 |         UnsupportedExtension,
244 |         x509.UnsupportedGeneralNameType,
245 |         UnicodeError,
246 |     ) as e:
247 |         # A problem has been found with the quality of the certificate. Assume
248 |         # no SAN field is present.
249 |         log.warning(
250 |             "A problem was encountered with the certificate that prevented "
251 |             "urllib3 from finding the SubjectAlternativeName field. This can "
252 |             "affect certificate validation. The error was %s",
253 |             e,
254 |         )
255 |         return []
256 | 
257 |     # We want to return dNSName and iPAddress fields. We need to cast the IPs
258 |     # back to strings because the match_hostname function wants them as
259 |     # strings.
260 |     # Sadly the DNS names need to be idna encoded and then, on Python 3, UTF-8
261 |     # decoded. This is pretty frustrating, but that's what the standard library
262 |     # does with certificates, and so we need to attempt to do the same.
263 |     # We also want to skip over names which cannot be idna encoded.
264 |     names = [
265 |         ("DNS", name)
266 |         for name in map(_dnsname_to_stdlib, ext.get_values_for_type(x509.DNSName))
267 |         if name is not None
268 |     ]
269 |     names.extend(
270 |         ("IP Address", str(name)) for name in ext.get_values_for_type(x509.IPAddress)
271 |     )
272 | 
273 |     return names
274 | 
275 | 
276 | class WrappedSocket(object):
277 |     """API-compatibility wrapper for Python OpenSSL's Connection-class.
278 | 
279 |     Note: _makefile_refs, _drop() and _reuse() are needed for the garbage
280 |     collector of pypy.
281 |     """
282 | 
283 |     def __init__(self, connection, socket, suppress_ragged_eofs=True):
284 |         self.connection = connection
285 |         self.socket = socket
286 |         self.suppress_ragged_eofs = suppress_ragged_eofs
287 |         self._makefile_refs = 0
288 |         self._closed = False
289 | 
290 |     def fileno(self):
291 |         return self.socket.fileno()
292 | 
293 |     # Copy-pasted from Python 3.5 source code
294 |     def _decref_socketios(self):
295 |         if self._makefile_refs > 0:
296 |             self._makefile_refs -= 1
297 |         if self._closed:
298 |             self.close()
299 | 
300 |     def recv(self, *args, **kwargs):
301 |         try:
302 |             data = self.connection.recv(*args, **kwargs)
303 |         except OpenSSL.SSL.SysCallError as e:
304 |             if self.suppress_ragged_eofs and e.args == (-1, "Unexpected EOF"):
305 |                 return b""
306 |             else:
307 |                 raise SocketError(str(e))
308 |         except OpenSSL.SSL.ZeroReturnError:
309 |             if self.connection.get_shutdown() == OpenSSL.SSL.RECEIVED_SHUTDOWN:
310 |                 return b""
311 |             else:
312 |                 raise
313 |         except OpenSSL.SSL.WantReadError:
314 |             if not util.wait_for_read(self.socket, self.socket.gettimeout()):
315 |                 raise timeout("The read operation timed out")
316 |             else:
317 |                 return self.recv(*args, **kwargs)
318 | 
319 |         # TLS 1.3 post-handshake authentication
320 |         except OpenSSL.SSL.Error as e:
321 |             raise ssl.SSLError("read error: %r" % e)
322 |         else:
323 |             return data
324 | 
325 |     def recv_into(self, *args, **kwargs):
326 |         try:
327 |             return self.connection.recv_into(*args, **kwargs)
328 |         except OpenSSL.SSL.SysCallError as e:
329 |             if self.suppress_ragged_eofs and e.args == (-1, "Unexpected EOF"):
330 |                 return 0
331 |             else:
332 |                 raise SocketError(str(e))
333 |         except OpenSSL.SSL.ZeroReturnError:
334 |             if self.connection.get_shutdown() == OpenSSL.SSL.RECEIVED_SHUTDOWN:
335 |                 return 0
336 |             else:
337 |                 raise
338 |         except OpenSSL.SSL.WantReadError:
339 |             if not util.wait_for_read(self.socket, self.socket.gettimeout()):
[TRUNCATED]
```

.venv/lib/python3.13/site-packages/pip/_vendor/urllib3/contrib/securetransport.py
```
1 | """
2 | SecureTranport support for urllib3 via ctypes.
3 | 
4 | This makes platform-native TLS available to urllib3 users on macOS without the
5 | use of a compiler. This is an important feature because the Python Package
6 | Index is moving to become a TLSv1.2-or-higher server, and the default OpenSSL
7 | that ships with macOS is not capable of doing TLSv1.2. The only way to resolve
8 | this is to give macOS users an alternative solution to the problem, and that
9 | solution is to use SecureTransport.
10 | 
11 | We use ctypes here because this solution must not require a compiler. That's
12 | because pip is not allowed to require a compiler either.
13 | 
14 | This is not intended to be a seriously long-term solution to this problem.
15 | The hope is that PEP 543 will eventually solve this issue for us, at which
16 | point we can retire this contrib module. But in the short term, we need to
17 | solve the impending tire fire that is Python on Mac without this kind of
18 | contrib module. So...here we are.
19 | 
20 | To use this module, simply import and inject it::
21 | 
22 |     import pip._vendor.urllib3.contrib.securetransport as securetransport
23 |     securetransport.inject_into_urllib3()
24 | 
25 | Happy TLSing!
26 | 
27 | This code is a bastardised version of the code found in Will Bond's oscrypto
28 | library. An enormous debt is owed to him for blazing this trail for us. For
29 | that reason, this code should be considered to be covered both by urllib3's
30 | license and by oscrypto's:
31 | 
32 | .. code-block::
33 | 
34 |     Copyright (c) 2015-2016 Will Bond <will@wbond.net>
35 | 
36 |     Permission is hereby granted, free of charge, to any person obtaining a
37 |     copy of this software and associated documentation files (the "Software"),
38 |     to deal in the Software without restriction, including without limitation
39 |     the rights to use, copy, modify, merge, publish, distribute, sublicense,
40 |     and/or sell copies of the Software, and to permit persons to whom the
41 |     Software is furnished to do so, subject to the following conditions:
42 | 
43 |     The above copyright notice and this permission notice shall be included in
44 |     all copies or substantial portions of the Software.
45 | 
46 |     THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
47 |     IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
48 |     FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
49 |     AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
50 |     LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
51 |     FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
52 |     DEALINGS IN THE SOFTWARE.
53 | """
54 | from __future__ import absolute_import
55 | 
56 | import contextlib
57 | import ctypes
58 | import errno
59 | import os.path
60 | import shutil
61 | import socket
62 | import ssl
63 | import struct
64 | import threading
65 | import weakref
66 | 
67 | from .. import util
68 | from ..packages import six
69 | from ..util.ssl_ import PROTOCOL_TLS_CLIENT
70 | from ._securetransport.bindings import CoreFoundation, Security, SecurityConst
71 | from ._securetransport.low_level import (
72 |     _assert_no_error,
73 |     _build_tls_unknown_ca_alert,
74 |     _cert_array_from_pem,
75 |     _create_cfstring_array,
76 |     _load_client_cert_chain,
77 |     _temporary_keychain,
78 | )
79 | 
80 | try:  # Platform-specific: Python 2
81 |     from socket import _fileobject
82 | except ImportError:  # Platform-specific: Python 3
83 |     _fileobject = None
84 |     from ..packages.backports.makefile import backport_makefile
85 | 
86 | __all__ = ["inject_into_urllib3", "extract_from_urllib3"]
87 | 
88 | # SNI always works
89 | HAS_SNI = True
90 | 
91 | orig_util_HAS_SNI = util.HAS_SNI
92 | orig_util_SSLContext = util.ssl_.SSLContext
93 | 
94 | # This dictionary is used by the read callback to obtain a handle to the
95 | # calling wrapped socket. This is a pretty silly approach, but for now it'll
96 | # do. I feel like I should be able to smuggle a handle to the wrapped socket
97 | # directly in the SSLConnectionRef, but for now this approach will work I
98 | # guess.
99 | #
100 | # We need to lock around this structure for inserts, but we don't do it for
101 | # reads/writes in the callbacks. The reasoning here goes as follows:
102 | #
103 | #    1. It is not possible to call into the callbacks before the dictionary is
104 | #       populated, so once in the callback the id must be in the dictionary.
105 | #    2. The callbacks don't mutate the dictionary, they only read from it, and
106 | #       so cannot conflict with any of the insertions.
107 | #
108 | # This is good: if we had to lock in the callbacks we'd drastically slow down
109 | # the performance of this code.
110 | _connection_refs = weakref.WeakValueDictionary()
111 | _connection_ref_lock = threading.Lock()
112 | 
113 | # Limit writes to 16kB. This is OpenSSL's limit, but we'll cargo-cult it over
114 | # for no better reason than we need *a* limit, and this one is right there.
115 | SSL_WRITE_BLOCKSIZE = 16384
116 | 
117 | # This is our equivalent of util.ssl_.DEFAULT_CIPHERS, but expanded out to
118 | # individual cipher suites. We need to do this because this is how
119 | # SecureTransport wants them.
120 | CIPHER_SUITES = [
121 |     SecurityConst.TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,
122 |     SecurityConst.TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,
123 |     SecurityConst.TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,
124 |     SecurityConst.TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,
125 |     SecurityConst.TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,
126 |     SecurityConst.TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256,
127 |     SecurityConst.TLS_DHE_RSA_WITH_AES_256_GCM_SHA384,
128 |     SecurityConst.TLS_DHE_RSA_WITH_AES_128_GCM_SHA256,
129 |     SecurityConst.TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA384,
130 |     SecurityConst.TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA,
131 |     SecurityConst.TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,
132 |     SecurityConst.TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA,
133 |     SecurityConst.TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA384,
134 |     SecurityConst.TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA,
135 |     SecurityConst.TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256,
136 |     SecurityConst.TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA,
137 |     SecurityConst.TLS_DHE_RSA_WITH_AES_256_CBC_SHA256,
138 |     SecurityConst.TLS_DHE_RSA_WITH_AES_256_CBC_SHA,
139 |     SecurityConst.TLS_DHE_RSA_WITH_AES_128_CBC_SHA256,
140 |     SecurityConst.TLS_DHE_RSA_WITH_AES_128_CBC_SHA,
141 |     SecurityConst.TLS_AES_256_GCM_SHA384,
142 |     SecurityConst.TLS_AES_128_GCM_SHA256,
143 |     SecurityConst.TLS_RSA_WITH_AES_256_GCM_SHA384,
144 |     SecurityConst.TLS_RSA_WITH_AES_128_GCM_SHA256,
145 |     SecurityConst.TLS_AES_128_CCM_8_SHA256,
146 |     SecurityConst.TLS_AES_128_CCM_SHA256,
147 |     SecurityConst.TLS_RSA_WITH_AES_256_CBC_SHA256,
148 |     SecurityConst.TLS_RSA_WITH_AES_128_CBC_SHA256,
149 |     SecurityConst.TLS_RSA_WITH_AES_256_CBC_SHA,
150 |     SecurityConst.TLS_RSA_WITH_AES_128_CBC_SHA,
151 | ]
152 | 
153 | # Basically this is simple: for PROTOCOL_SSLv23 we turn it into a low of
154 | # TLSv1 and a high of TLSv1.2. For everything else, we pin to that version.
155 | # TLSv1 to 1.2 are supported on macOS 10.8+
156 | _protocol_to_min_max = {
157 |     util.PROTOCOL_TLS: (SecurityConst.kTLSProtocol1, SecurityConst.kTLSProtocol12),
158 |     PROTOCOL_TLS_CLIENT: (SecurityConst.kTLSProtocol1, SecurityConst.kTLSProtocol12),
159 | }
160 | 
161 | if hasattr(ssl, "PROTOCOL_SSLv2"):
162 |     _protocol_to_min_max[ssl.PROTOCOL_SSLv2] = (
163 |         SecurityConst.kSSLProtocol2,
164 |         SecurityConst.kSSLProtocol2,
165 |     )
166 | if hasattr(ssl, "PROTOCOL_SSLv3"):
167 |     _protocol_to_min_max[ssl.PROTOCOL_SSLv3] = (
168 |         SecurityConst.kSSLProtocol3,
169 |         SecurityConst.kSSLProtocol3,
170 |     )
171 | if hasattr(ssl, "PROTOCOL_TLSv1"):
172 |     _protocol_to_min_max[ssl.PROTOCOL_TLSv1] = (
173 |         SecurityConst.kTLSProtocol1,
174 |         SecurityConst.kTLSProtocol1,
175 |     )
176 | if hasattr(ssl, "PROTOCOL_TLSv1_1"):
177 |     _protocol_to_min_max[ssl.PROTOCOL_TLSv1_1] = (
178 |         SecurityConst.kTLSProtocol11,
179 |         SecurityConst.kTLSProtocol11,
180 |     )
181 | if hasattr(ssl, "PROTOCOL_TLSv1_2"):
182 |     _protocol_to_min_max[ssl.PROTOCOL_TLSv1_2] = (
183 |         SecurityConst.kTLSProtocol12,
184 |         SecurityConst.kTLSProtocol12,
185 |     )
186 | 
187 | 
188 | def inject_into_urllib3():
189 |     """
190 |     Monkey-patch urllib3 with SecureTransport-backed SSL-support.
191 |     """
192 |     util.SSLContext = SecureTransportContext
193 |     util.ssl_.SSLContext = SecureTransportContext
194 |     util.HAS_SNI = HAS_SNI
195 |     util.ssl_.HAS_SNI = HAS_SNI
196 |     util.IS_SECURETRANSPORT = True
197 |     util.ssl_.IS_SECURETRANSPORT = True
198 | 
199 | 
200 | def extract_from_urllib3():
201 |     """
202 |     Undo monkey-patching by :func:`inject_into_urllib3`.
203 |     """
204 |     util.SSLContext = orig_util_SSLContext
205 |     util.ssl_.SSLContext = orig_util_SSLContext
206 |     util.HAS_SNI = orig_util_HAS_SNI
207 |     util.ssl_.HAS_SNI = orig_util_HAS_SNI
208 |     util.IS_SECURETRANSPORT = False
209 |     util.ssl_.IS_SECURETRANSPORT = False
210 | 
211 | 
212 | def _read_callback(connection_id, data_buffer, data_length_pointer):
213 |     """
214 |     SecureTransport read callback. This is called by ST to request that data
215 |     be returned from the socket.
216 |     """
217 |     wrapped_socket = None
218 |     try:
219 |         wrapped_socket = _connection_refs.get(connection_id)
220 |         if wrapped_socket is None:
221 |             return SecurityConst.errSSLInternal
222 |         base_socket = wrapped_socket.socket
223 | 
224 |         requested_length = data_length_pointer[0]
225 | 
226 |         timeout = wrapped_socket.gettimeout()
227 |         error = None
228 |         read_count = 0
229 | 
230 |         try:
231 |             while read_count < requested_length:
232 |                 if timeout is None or timeout >= 0:
233 |                     if not util.wait_for_read(base_socket, timeout):
234 |                         raise socket.error(errno.EAGAIN, "timed out")
235 | 
236 |                 remaining = requested_length - read_count
237 |                 buffer = (ctypes.c_char * remaining).from_address(
238 |                     data_buffer + read_count
239 |                 )
240 |                 chunk_size = base_socket.recv_into(buffer, remaining)
241 |                 read_count += chunk_size
242 |                 if not chunk_size:
243 |                     if not read_count:
244 |                         return SecurityConst.errSSLClosedGraceful
245 |                     break
246 |         except (socket.error) as e:
247 |             error = e.errno
248 | 
249 |             if error is not None and error != errno.EAGAIN:
250 |                 data_length_pointer[0] = read_count
251 |                 if error == errno.ECONNRESET or error == errno.EPIPE:
252 |                     return SecurityConst.errSSLClosedAbort
253 |                 raise
254 | 
255 |         data_length_pointer[0] = read_count
256 | 
257 |         if read_count != requested_length:
258 |             return SecurityConst.errSSLWouldBlock
259 | 
260 |         return 0
261 |     except Exception as e:
262 |         if wrapped_socket is not None:
263 |             wrapped_socket._exception = e
264 |         return SecurityConst.errSSLInternal
265 | 
266 | 
267 | def _write_callback(connection_id, data_buffer, data_length_pointer):
268 |     """
269 |     SecureTransport write callback. This is called by ST to request that data
270 |     actually be sent on the network.
271 |     """
272 |     wrapped_socket = None
273 |     try:
274 |         wrapped_socket = _connection_refs.get(connection_id)
275 |         if wrapped_socket is None:
276 |             return SecurityConst.errSSLInternal
277 |         base_socket = wrapped_socket.socket
278 | 
279 |         bytes_to_write = data_length_pointer[0]
280 |         data = ctypes.string_at(data_buffer, bytes_to_write)
281 | 
282 |         timeout = wrapped_socket.gettimeout()
283 |         error = None
284 |         sent = 0
285 | 
286 |         try:
287 |             while sent < bytes_to_write:
288 |                 if timeout is None or timeout >= 0:
289 |                     if not util.wait_for_write(base_socket, timeout):
290 |                         raise socket.error(errno.EAGAIN, "timed out")
291 |                 chunk_sent = base_socket.send(data)
292 |                 sent += chunk_sent
293 | 
294 |                 # This has some needless copying here, but I'm not sure there's
295 |                 # much value in optimising this data path.
296 |                 data = data[chunk_sent:]
[TRUNCATED]
```

.venv/lib/python3.13/site-packages/pip/_vendor/urllib3/contrib/socks.py
```
1 | # -*- coding: utf-8 -*-
2 | """
3 | This module contains provisional support for SOCKS proxies from within
4 | urllib3. This module supports SOCKS4, SOCKS4A (an extension of SOCKS4), and
5 | SOCKS5. To enable its functionality, either install PySocks or install this
6 | module with the ``socks`` extra.
7 | 
8 | The SOCKS implementation supports the full range of urllib3 features. It also
9 | supports the following SOCKS features:
10 | 
11 | - SOCKS4A (``proxy_url='socks4a://...``)
12 | - SOCKS4 (``proxy_url='socks4://...``)
13 | - SOCKS5 with remote DNS (``proxy_url='socks5h://...``)
14 | - SOCKS5 with local DNS (``proxy_url='socks5://...``)
15 | - Usernames and passwords for the SOCKS proxy
16 | 
17 | .. note::
18 |    It is recommended to use ``socks5h://`` or ``socks4a://`` schemes in
19 |    your ``proxy_url`` to ensure that DNS resolution is done from the remote
20 |    server instead of client-side when connecting to a domain name.
21 | 
22 | SOCKS4 supports IPv4 and domain names with the SOCKS4A extension. SOCKS5
23 | supports IPv4, IPv6, and domain names.
24 | 
25 | When connecting to a SOCKS4 proxy the ``username`` portion of the ``proxy_url``
26 | will be sent as the ``userid`` section of the SOCKS request:
27 | 
28 | .. code-block:: python
29 | 
30 |     proxy_url="socks4a://<userid>@proxy-host"
31 | 
32 | When connecting to a SOCKS5 proxy the ``username`` and ``password`` portion
33 | of the ``proxy_url`` will be sent as the username/password to authenticate
34 | with the proxy:
35 | 
36 | .. code-block:: python
37 | 
38 |     proxy_url="socks5h://<username>:<password>@proxy-host"
39 | 
40 | """
41 | from __future__ import absolute_import
42 | 
43 | try:
44 |     import socks
45 | except ImportError:
46 |     import warnings
47 | 
48 |     from ..exceptions import DependencyWarning
49 | 
50 |     warnings.warn(
51 |         (
52 |             "SOCKS support in urllib3 requires the installation of optional "
53 |             "dependencies: specifically, PySocks.  For more information, see "
54 |             "https://urllib3.readthedocs.io/en/1.26.x/contrib.html#socks-proxies"
55 |         ),
56 |         DependencyWarning,
57 |     )
58 |     raise
59 | 
60 | from socket import error as SocketError
61 | from socket import timeout as SocketTimeout
62 | 
63 | from ..connection import HTTPConnection, HTTPSConnection
64 | from ..connectionpool import HTTPConnectionPool, HTTPSConnectionPool
65 | from ..exceptions import ConnectTimeoutError, NewConnectionError
66 | from ..poolmanager import PoolManager
67 | from ..util.url import parse_url
68 | 
69 | try:
70 |     import ssl
71 | except ImportError:
72 |     ssl = None
73 | 
74 | 
75 | class SOCKSConnection(HTTPConnection):
76 |     """
77 |     A plain-text HTTP connection that connects via a SOCKS proxy.
78 |     """
79 | 
80 |     def __init__(self, *args, **kwargs):
81 |         self._socks_options = kwargs.pop("_socks_options")
82 |         super(SOCKSConnection, self).__init__(*args, **kwargs)
83 | 
84 |     def _new_conn(self):
85 |         """
86 |         Establish a new connection via the SOCKS proxy.
87 |         """
88 |         extra_kw = {}
89 |         if self.source_address:
90 |             extra_kw["source_address"] = self.source_address
91 | 
92 |         if self.socket_options:
93 |             extra_kw["socket_options"] = self.socket_options
94 | 
95 |         try:
96 |             conn = socks.create_connection(
97 |                 (self.host, self.port),
98 |                 proxy_type=self._socks_options["socks_version"],
99 |                 proxy_addr=self._socks_options["proxy_host"],
100 |                 proxy_port=self._socks_options["proxy_port"],
101 |                 proxy_username=self._socks_options["username"],
102 |                 proxy_password=self._socks_options["password"],
103 |                 proxy_rdns=self._socks_options["rdns"],
104 |                 timeout=self.timeout,
105 |                 **extra_kw
106 |             )
107 | 
108 |         except SocketTimeout:
109 |             raise ConnectTimeoutError(
110 |                 self,
111 |                 "Connection to %s timed out. (connect timeout=%s)"
112 |                 % (self.host, self.timeout),
113 |             )
114 | 
115 |         except socks.ProxyError as e:
116 |             # This is fragile as hell, but it seems to be the only way to raise
117 |             # useful errors here.
118 |             if e.socket_err:
119 |                 error = e.socket_err
120 |                 if isinstance(error, SocketTimeout):
121 |                     raise ConnectTimeoutError(
122 |                         self,
123 |                         "Connection to %s timed out. (connect timeout=%s)"
124 |                         % (self.host, self.timeout),
125 |                     )
126 |                 else:
127 |                     raise NewConnectionError(
128 |                         self, "Failed to establish a new connection: %s" % error
129 |                     )
130 |             else:
131 |                 raise NewConnectionError(
132 |                     self, "Failed to establish a new connection: %s" % e
133 |                 )
134 | 
135 |         except SocketError as e:  # Defensive: PySocks should catch all these.
136 |             raise NewConnectionError(
137 |                 self, "Failed to establish a new connection: %s" % e
138 |             )
139 | 
140 |         return conn
141 | 
142 | 
143 | # We don't need to duplicate the Verified/Unverified distinction from
144 | # urllib3/connection.py here because the HTTPSConnection will already have been
145 | # correctly set to either the Verified or Unverified form by that module. This
146 | # means the SOCKSHTTPSConnection will automatically be the correct type.
147 | class SOCKSHTTPSConnection(SOCKSConnection, HTTPSConnection):
148 |     pass
149 | 
150 | 
151 | class SOCKSHTTPConnectionPool(HTTPConnectionPool):
152 |     ConnectionCls = SOCKSConnection
153 | 
154 | 
155 | class SOCKSHTTPSConnectionPool(HTTPSConnectionPool):
156 |     ConnectionCls = SOCKSHTTPSConnection
157 | 
158 | 
159 | class SOCKSProxyManager(PoolManager):
160 |     """
161 |     A version of the urllib3 ProxyManager that routes connections via the
162 |     defined SOCKS proxy.
163 |     """
164 | 
165 |     pool_classes_by_scheme = {
166 |         "http": SOCKSHTTPConnectionPool,
167 |         "https": SOCKSHTTPSConnectionPool,
168 |     }
169 | 
170 |     def __init__(
171 |         self,
172 |         proxy_url,
173 |         username=None,
174 |         password=None,
175 |         num_pools=10,
176 |         headers=None,
177 |         **connection_pool_kw
178 |     ):
179 |         parsed = parse_url(proxy_url)
180 | 
181 |         if username is None and password is None and parsed.auth is not None:
182 |             split = parsed.auth.split(":")
183 |             if len(split) == 2:
184 |                 username, password = split
185 |         if parsed.scheme == "socks5":
186 |             socks_version = socks.PROXY_TYPE_SOCKS5
187 |             rdns = False
188 |         elif parsed.scheme == "socks5h":
189 |             socks_version = socks.PROXY_TYPE_SOCKS5
190 |             rdns = True
191 |         elif parsed.scheme == "socks4":
192 |             socks_version = socks.PROXY_TYPE_SOCKS4
193 |             rdns = False
194 |         elif parsed.scheme == "socks4a":
195 |             socks_version = socks.PROXY_TYPE_SOCKS4
196 |             rdns = True
197 |         else:
198 |             raise ValueError("Unable to determine SOCKS version from %s" % proxy_url)
199 | 
200 |         self.proxy_url = proxy_url
201 | 
202 |         socks_options = {
203 |             "socks_version": socks_version,
204 |             "proxy_host": parsed.host,
205 |             "proxy_port": parsed.port,
206 |             "username": username,
207 |             "password": password,
208 |             "rdns": rdns,
209 |         }
210 |         connection_pool_kw["_socks_options"] = socks_options
211 | 
212 |         super(SOCKSProxyManager, self).__init__(
213 |             num_pools, headers, **connection_pool_kw
214 |         )
215 | 
216 |         self.pool_classes_by_scheme = SOCKSProxyManager.pool_classes_by_scheme
```

.venv/lib/python3.13/site-packages/pip/_vendor/urllib3/util/__init__.py
```
1 | from __future__ import absolute_import
2 | 
3 | # For backwards compatibility, provide imports that used to be here.
4 | from .connection import is_connection_dropped
5 | from .request import SKIP_HEADER, SKIPPABLE_HEADERS, make_headers
6 | from .response import is_fp_closed
7 | from .retry import Retry
8 | from .ssl_ import (
9 |     ALPN_PROTOCOLS,
10 |     HAS_SNI,
11 |     IS_PYOPENSSL,
12 |     IS_SECURETRANSPORT,
13 |     PROTOCOL_TLS,
14 |     SSLContext,
15 |     assert_fingerprint,
16 |     resolve_cert_reqs,
17 |     resolve_ssl_version,
18 |     ssl_wrap_socket,
19 | )
20 | from .timeout import Timeout, current_time
21 | from .url import Url, get_host, parse_url, split_first
22 | from .wait import wait_for_read, wait_for_write
23 | 
24 | __all__ = (
25 |     "HAS_SNI",
26 |     "IS_PYOPENSSL",
27 |     "IS_SECURETRANSPORT",
28 |     "SSLContext",
29 |     "PROTOCOL_TLS",
30 |     "ALPN_PROTOCOLS",
31 |     "Retry",
32 |     "Timeout",
33 |     "Url",
34 |     "assert_fingerprint",
35 |     "current_time",
36 |     "is_connection_dropped",
37 |     "is_fp_closed",
38 |     "get_host",
39 |     "parse_url",
40 |     "make_headers",
41 |     "resolve_cert_reqs",
42 |     "resolve_ssl_version",
43 |     "split_first",
44 |     "ssl_wrap_socket",
45 |     "wait_for_read",
46 |     "wait_for_write",
47 |     "SKIP_HEADER",
48 |     "SKIPPABLE_HEADERS",
49 | )
```

.venv/lib/python3.13/site-packages/pip/_vendor/urllib3/util/connection.py
```
1 | from __future__ import absolute_import
2 | 
3 | import socket
4 | 
5 | from ..contrib import _appengine_environ
6 | from ..exceptions import LocationParseError
7 | from ..packages import six
8 | from .wait import NoWayToWaitForSocketError, wait_for_read
9 | 
10 | 
11 | def is_connection_dropped(conn):  # Platform-specific
12 |     """
13 |     Returns True if the connection is dropped and should be closed.
14 | 
15 |     :param conn:
16 |         :class:`http.client.HTTPConnection` object.
17 | 
18 |     Note: For platforms like AppEngine, this will always return ``False`` to
19 |     let the platform handle connection recycling transparently for us.
20 |     """
21 |     sock = getattr(conn, "sock", False)
22 |     if sock is False:  # Platform-specific: AppEngine
23 |         return False
24 |     if sock is None:  # Connection already closed (such as by httplib).
25 |         return True
26 |     try:
27 |         # Returns True if readable, which here means it's been dropped
28 |         return wait_for_read(sock, timeout=0.0)
29 |     except NoWayToWaitForSocketError:  # Platform-specific: AppEngine
30 |         return False
31 | 
32 | 
33 | # This function is copied from socket.py in the Python 2.7 standard
34 | # library test suite. Added to its signature is only `socket_options`.
35 | # One additional modification is that we avoid binding to IPv6 servers
36 | # discovered in DNS if the system doesn't have IPv6 functionality.
37 | def create_connection(
38 |     address,
39 |     timeout=socket._GLOBAL_DEFAULT_TIMEOUT,
40 |     source_address=None,
41 |     socket_options=None,
42 | ):
43 |     """Connect to *address* and return the socket object.
44 | 
45 |     Convenience function.  Connect to *address* (a 2-tuple ``(host,
46 |     port)``) and return the socket object.  Passing the optional
47 |     *timeout* parameter will set the timeout on the socket instance
48 |     before attempting to connect.  If no *timeout* is supplied, the
49 |     global default timeout setting returned by :func:`socket.getdefaulttimeout`
50 |     is used.  If *source_address* is set it must be a tuple of (host, port)
51 |     for the socket to bind as a source address before making the connection.
52 |     An host of '' or port 0 tells the OS to use the default.
53 |     """
54 | 
55 |     host, port = address
56 |     if host.startswith("["):
57 |         host = host.strip("[]")
58 |     err = None
59 | 
60 |     # Using the value from allowed_gai_family() in the context of getaddrinfo lets
61 |     # us select whether to work with IPv4 DNS records, IPv6 records, or both.
62 |     # The original create_connection function always returns all records.
63 |     family = allowed_gai_family()
64 | 
65 |     try:
66 |         host.encode("idna")
67 |     except UnicodeError:
68 |         return six.raise_from(
69 |             LocationParseError(u"'%s', label empty or too long" % host), None
70 |         )
71 | 
72 |     for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
73 |         af, socktype, proto, canonname, sa = res
74 |         sock = None
75 |         try:
76 |             sock = socket.socket(af, socktype, proto)
77 | 
78 |             # If provided, set socket level options before connecting.
79 |             _set_socket_options(sock, socket_options)
80 | 
81 |             if timeout is not socket._GLOBAL_DEFAULT_TIMEOUT:
82 |                 sock.settimeout(timeout)
83 |             if source_address:
84 |                 sock.bind(source_address)
85 |             sock.connect(sa)
86 |             return sock
87 | 
88 |         except socket.error as e:
89 |             err = e
90 |             if sock is not None:
91 |                 sock.close()
92 |                 sock = None
93 | 
94 |     if err is not None:
95 |         raise err
96 | 
97 |     raise socket.error("getaddrinfo returns an empty list")
98 | 
99 | 
100 | def _set_socket_options(sock, options):
101 |     if options is None:
102 |         return
103 | 
104 |     for opt in options:
105 |         sock.setsockopt(*opt)
106 | 
107 | 
108 | def allowed_gai_family():
109 |     """This function is designed to work in the context of
110 |     getaddrinfo, where family=socket.AF_UNSPEC is the default and
111 |     will perform a DNS search for both IPv6 and IPv4 records."""
112 | 
113 |     family = socket.AF_INET
114 |     if HAS_IPV6:
115 |         family = socket.AF_UNSPEC
116 |     return family
117 | 
118 | 
119 | def _has_ipv6(host):
120 |     """Returns True if the system can bind an IPv6 address."""
121 |     sock = None
122 |     has_ipv6 = False
123 | 
124 |     # App Engine doesn't support IPV6 sockets and actually has a quota on the
125 |     # number of sockets that can be used, so just early out here instead of
126 |     # creating a socket needlessly.
127 |     # See https://github.com/urllib3/urllib3/issues/1446
128 |     if _appengine_environ.is_appengine_sandbox():
129 |         return False
130 | 
131 |     if socket.has_ipv6:
132 |         # has_ipv6 returns true if cPython was compiled with IPv6 support.
133 |         # It does not tell us if the system has IPv6 support enabled. To
134 |         # determine that we must bind to an IPv6 address.
135 |         # https://github.com/urllib3/urllib3/pull/611
136 |         # https://bugs.python.org/issue658327
137 |         try:
138 |             sock = socket.socket(socket.AF_INET6)
139 |             sock.bind((host, 0))
140 |             has_ipv6 = True
141 |         except Exception:
142 |             pass
143 | 
144 |     if sock:
145 |         sock.close()
146 |     return has_ipv6
147 | 
148 | 
149 | HAS_IPV6 = _has_ipv6("::1")
```

.venv/lib/python3.13/site-packages/pip/_vendor/urllib3/util/proxy.py
```
1 | from .ssl_ import create_urllib3_context, resolve_cert_reqs, resolve_ssl_version
2 | 
3 | 
4 | def connection_requires_http_tunnel(
5 |     proxy_url=None, proxy_config=None, destination_scheme=None
6 | ):
7 |     """
8 |     Returns True if the connection requires an HTTP CONNECT through the proxy.
9 | 
10 |     :param URL proxy_url:
11 |         URL of the proxy.
12 |     :param ProxyConfig proxy_config:
13 |         Proxy configuration from poolmanager.py
14 |     :param str destination_scheme:
15 |         The scheme of the destination. (i.e https, http, etc)
16 |     """
17 |     # If we're not using a proxy, no way to use a tunnel.
18 |     if proxy_url is None:
19 |         return False
20 | 
21 |     # HTTP destinations never require tunneling, we always forward.
22 |     if destination_scheme == "http":
23 |         return False
24 | 
25 |     # Support for forwarding with HTTPS proxies and HTTPS destinations.
26 |     if (
27 |         proxy_url.scheme == "https"
28 |         and proxy_config
29 |         and proxy_config.use_forwarding_for_https
30 |     ):
31 |         return False
32 | 
33 |     # Otherwise always use a tunnel.
34 |     return True
35 | 
36 | 
37 | def create_proxy_ssl_context(
38 |     ssl_version, cert_reqs, ca_certs=None, ca_cert_dir=None, ca_cert_data=None
39 | ):
40 |     """
41 |     Generates a default proxy ssl context if one hasn't been provided by the
42 |     user.
43 |     """
44 |     ssl_context = create_urllib3_context(
45 |         ssl_version=resolve_ssl_version(ssl_version),
46 |         cert_reqs=resolve_cert_reqs(cert_reqs),
47 |     )
48 | 
49 |     if (
50 |         not ca_certs
51 |         and not ca_cert_dir
52 |         and not ca_cert_data
53 |         and hasattr(ssl_context, "load_default_certs")
54 |     ):
55 |         ssl_context.load_default_certs()
56 | 
57 |     return ssl_context
```

.venv/lib/python3.13/site-packages/pip/_vendor/urllib3/util/queue.py
```
1 | import collections
2 | 
3 | from ..packages import six
4 | from ..packages.six.moves import queue
5 | 
6 | if six.PY2:
7 |     # Queue is imported for side effects on MS Windows. See issue #229.
8 |     import Queue as _unused_module_Queue  # noqa: F401
9 | 
10 | 
11 | class LifoQueue(queue.Queue):
12 |     def _init(self, _):
13 |         self.queue = collections.deque()
14 | 
15 |     def _qsize(self, len=len):
16 |         return len(self.queue)
17 | 
18 |     def _put(self, item):
19 |         self.queue.append(item)
20 | 
21 |     def _get(self):
22 |         return self.queue.pop()
```

.venv/lib/python3.13/site-packages/pip/_vendor/urllib3/util/request.py
```
1 | from __future__ import absolute_import
2 | 
3 | from base64 import b64encode
4 | 
5 | from ..exceptions import UnrewindableBodyError
6 | from ..packages.six import b, integer_types
7 | 
8 | # Pass as a value within ``headers`` to skip
9 | # emitting some HTTP headers that are added automatically.
10 | # The only headers that are supported are ``Accept-Encoding``,
11 | # ``Host``, and ``User-Agent``.
12 | SKIP_HEADER = "@@@SKIP_HEADER@@@"
13 | SKIPPABLE_HEADERS = frozenset(["accept-encoding", "host", "user-agent"])
14 | 
15 | ACCEPT_ENCODING = "gzip,deflate"
16 | 
17 | _FAILEDTELL = object()
18 | 
19 | 
20 | def make_headers(
21 |     keep_alive=None,
22 |     accept_encoding=None,
23 |     user_agent=None,
24 |     basic_auth=None,
25 |     proxy_basic_auth=None,
26 |     disable_cache=None,
27 | ):
28 |     """
29 |     Shortcuts for generating request headers.
30 | 
31 |     :param keep_alive:
32 |         If ``True``, adds 'connection: keep-alive' header.
33 | 
34 |     :param accept_encoding:
35 |         Can be a boolean, list, or string.
36 |         ``True`` translates to 'gzip,deflate'.
37 |         List will get joined by comma.
38 |         String will be used as provided.
39 | 
40 |     :param user_agent:
41 |         String representing the user-agent you want, such as
42 |         "python-urllib3/0.6"
43 | 
44 |     :param basic_auth:
45 |         Colon-separated username:password string for 'authorization: basic ...'
46 |         auth header.
47 | 
48 |     :param proxy_basic_auth:
49 |         Colon-separated username:password string for 'proxy-authorization: basic ...'
50 |         auth header.
51 | 
52 |     :param disable_cache:
53 |         If ``True``, adds 'cache-control: no-cache' header.
54 | 
55 |     Example::
56 | 
57 |         >>> make_headers(keep_alive=True, user_agent="Batman/1.0")
58 |         {'connection': 'keep-alive', 'user-agent': 'Batman/1.0'}
59 |         >>> make_headers(accept_encoding=True)
60 |         {'accept-encoding': 'gzip,deflate'}
61 |     """
62 |     headers = {}
63 |     if accept_encoding:
64 |         if isinstance(accept_encoding, str):
65 |             pass
66 |         elif isinstance(accept_encoding, list):
67 |             accept_encoding = ",".join(accept_encoding)
68 |         else:
69 |             accept_encoding = ACCEPT_ENCODING
70 |         headers["accept-encoding"] = accept_encoding
71 | 
72 |     if user_agent:
73 |         headers["user-agent"] = user_agent
74 | 
75 |     if keep_alive:
76 |         headers["connection"] = "keep-alive"
77 | 
78 |     if basic_auth:
79 |         headers["authorization"] = "Basic " + b64encode(b(basic_auth)).decode("utf-8")
80 | 
81 |     if proxy_basic_auth:
82 |         headers["proxy-authorization"] = "Basic " + b64encode(
83 |             b(proxy_basic_auth)
84 |         ).decode("utf-8")
85 | 
86 |     if disable_cache:
87 |         headers["cache-control"] = "no-cache"
88 | 
89 |     return headers
90 | 
91 | 
92 | def set_file_position(body, pos):
93 |     """
94 |     If a position is provided, move file to that point.
95 |     Otherwise, we'll attempt to record a position for future use.
96 |     """
97 |     if pos is not None:
98 |         rewind_body(body, pos)
99 |     elif getattr(body, "tell", None) is not None:
100 |         try:
101 |             pos = body.tell()
102 |         except (IOError, OSError):
103 |             # This differentiates from None, allowing us to catch
104 |             # a failed `tell()` later when trying to rewind the body.
105 |             pos = _FAILEDTELL
106 | 
107 |     return pos
108 | 
109 | 
110 | def rewind_body(body, body_pos):
111 |     """
112 |     Attempt to rewind body to a certain position.
113 |     Primarily used for request redirects and retries.
114 | 
115 |     :param body:
116 |         File-like object that supports seek.
117 | 
118 |     :param int pos:
119 |         Position to seek to in file.
120 |     """
121 |     body_seek = getattr(body, "seek", None)
122 |     if body_seek is not None and isinstance(body_pos, integer_types):
123 |         try:
124 |             body_seek(body_pos)
125 |         except (IOError, OSError):
126 |             raise UnrewindableBodyError(
127 |                 "An error occurred when rewinding request body for redirect/retry."
128 |             )
129 |     elif body_pos is _FAILEDTELL:
130 |         raise UnrewindableBodyError(
131 |             "Unable to record file position for rewinding "
132 |             "request body during a redirect/retry."
133 |         )
134 |     else:
135 |         raise ValueError(
136 |             "body_pos must be of type integer, instead it was %s." % type(body_pos)
137 |         )
```

.venv/lib/python3.13/site-packages/pip/_vendor/urllib3/util/response.py
```
1 | from __future__ import absolute_import
2 | 
3 | from email.errors import MultipartInvariantViolationDefect, StartBoundaryNotFoundDefect
4 | 
5 | from ..exceptions import HeaderParsingError
6 | from ..packages.six.moves import http_client as httplib
7 | 
8 | 
9 | def is_fp_closed(obj):
10 |     """
11 |     Checks whether a given file-like object is closed.
12 | 
13 |     :param obj:
14 |         The file-like object to check.
15 |     """
16 | 
17 |     try:
18 |         # Check `isclosed()` first, in case Python3 doesn't set `closed`.
19 |         # GH Issue #928
20 |         return obj.isclosed()
21 |     except AttributeError:
22 |         pass
23 | 
24 |     try:
25 |         # Check via the official file-like-object way.
26 |         return obj.closed
27 |     except AttributeError:
28 |         pass
29 | 
30 |     try:
31 |         # Check if the object is a container for another file-like object that
32 |         # gets released on exhaustion (e.g. HTTPResponse).
33 |         return obj.fp is None
34 |     except AttributeError:
35 |         pass
36 | 
37 |     raise ValueError("Unable to determine whether fp is closed.")
38 | 
39 | 
40 | def assert_header_parsing(headers):
41 |     """
42 |     Asserts whether all headers have been successfully parsed.
43 |     Extracts encountered errors from the result of parsing headers.
44 | 
45 |     Only works on Python 3.
46 | 
47 |     :param http.client.HTTPMessage headers: Headers to verify.
48 | 
49 |     :raises urllib3.exceptions.HeaderParsingError:
50 |         If parsing errors are found.
51 |     """
52 | 
53 |     # This will fail silently if we pass in the wrong kind of parameter.
54 |     # To make debugging easier add an explicit check.
55 |     if not isinstance(headers, httplib.HTTPMessage):
56 |         raise TypeError("expected httplib.Message, got {0}.".format(type(headers)))
57 | 
58 |     defects = getattr(headers, "defects", None)
59 |     get_payload = getattr(headers, "get_payload", None)
60 | 
61 |     unparsed_data = None
62 |     if get_payload:
63 |         # get_payload is actually email.message.Message.get_payload;
64 |         # we're only interested in the result if it's not a multipart message
65 |         if not headers.is_multipart():
66 |             payload = get_payload()
67 | 
68 |             if isinstance(payload, (bytes, str)):
69 |                 unparsed_data = payload
70 |     if defects:
71 |         # httplib is assuming a response body is available
72 |         # when parsing headers even when httplib only sends
73 |         # header data to parse_headers() This results in
74 |         # defects on multipart responses in particular.
75 |         # See: https://github.com/urllib3/urllib3/issues/800
76 | 
77 |         # So we ignore the following defects:
78 |         # - StartBoundaryNotFoundDefect:
79 |         #     The claimed start boundary was never found.
80 |         # - MultipartInvariantViolationDefect:
81 |         #     A message claimed to be a multipart but no subparts were found.
82 |         defects = [
83 |             defect
84 |             for defect in defects
85 |             if not isinstance(
86 |                 defect, (StartBoundaryNotFoundDefect, MultipartInvariantViolationDefect)
87 |             )
88 |         ]
89 | 
90 |     if defects or unparsed_data:
91 |         raise HeaderParsingError(defects=defects, unparsed_data=unparsed_data)
92 | 
93 | 
94 | def is_response_to_head(response):
95 |     """
96 |     Checks whether the request of a response has been a HEAD-request.
97 |     Handles the quirks of AppEngine.
98 | 
99 |     :param http.client.HTTPResponse response:
100 |         Response to check if the originating request
101 |         used 'HEAD' as a method.
102 |     """
103 |     # FIXME: Can we do this somehow without accessing private httplib _method?
104 |     method = response._method
105 |     if isinstance(method, int):  # Platform-specific: Appengine
106 |         return method == 3
107 |     return method.upper() == "HEAD"
```

.venv/lib/python3.13/site-packages/pip/_vendor/urllib3/util/retry.py
```
1 | from __future__ import absolute_import
2 | 
3 | import email
4 | import logging
5 | import re
6 | import time
7 | import warnings
8 | from collections import namedtuple
9 | from itertools import takewhile
10 | 
11 | from ..exceptions import (
12 |     ConnectTimeoutError,
13 |     InvalidHeader,
14 |     MaxRetryError,
15 |     ProtocolError,
16 |     ProxyError,
17 |     ReadTimeoutError,
18 |     ResponseError,
19 | )
20 | from ..packages import six
21 | 
22 | log = logging.getLogger(__name__)
23 | 
24 | 
25 | # Data structure for representing the metadata of requests that result in a retry.
26 | RequestHistory = namedtuple(
27 |     "RequestHistory", ["method", "url", "error", "status", "redirect_location"]
28 | )
29 | 
30 | 
31 | # TODO: In v2 we can remove this sentinel and metaclass with deprecated options.
32 | _Default = object()
33 | 
34 | 
35 | class _RetryMeta(type):
36 |     @property
37 |     def DEFAULT_METHOD_WHITELIST(cls):
38 |         warnings.warn(
39 |             "Using 'Retry.DEFAULT_METHOD_WHITELIST' is deprecated and "
40 |             "will be removed in v2.0. Use 'Retry.DEFAULT_ALLOWED_METHODS' instead",
41 |             DeprecationWarning,
42 |         )
43 |         return cls.DEFAULT_ALLOWED_METHODS
44 | 
45 |     @DEFAULT_METHOD_WHITELIST.setter
46 |     def DEFAULT_METHOD_WHITELIST(cls, value):
47 |         warnings.warn(
48 |             "Using 'Retry.DEFAULT_METHOD_WHITELIST' is deprecated and "
49 |             "will be removed in v2.0. Use 'Retry.DEFAULT_ALLOWED_METHODS' instead",
50 |             DeprecationWarning,
51 |         )
52 |         cls.DEFAULT_ALLOWED_METHODS = value
53 | 
54 |     @property
55 |     def DEFAULT_REDIRECT_HEADERS_BLACKLIST(cls):
56 |         warnings.warn(
57 |             "Using 'Retry.DEFAULT_REDIRECT_HEADERS_BLACKLIST' is deprecated and "
58 |             "will be removed in v2.0. Use 'Retry.DEFAULT_REMOVE_HEADERS_ON_REDIRECT' instead",
59 |             DeprecationWarning,
60 |         )
61 |         return cls.DEFAULT_REMOVE_HEADERS_ON_REDIRECT
62 | 
63 |     @DEFAULT_REDIRECT_HEADERS_BLACKLIST.setter
64 |     def DEFAULT_REDIRECT_HEADERS_BLACKLIST(cls, value):
65 |         warnings.warn(
66 |             "Using 'Retry.DEFAULT_REDIRECT_HEADERS_BLACKLIST' is deprecated and "
67 |             "will be removed in v2.0. Use 'Retry.DEFAULT_REMOVE_HEADERS_ON_REDIRECT' instead",
68 |             DeprecationWarning,
69 |         )
70 |         cls.DEFAULT_REMOVE_HEADERS_ON_REDIRECT = value
71 | 
72 |     @property
73 |     def BACKOFF_MAX(cls):
74 |         warnings.warn(
75 |             "Using 'Retry.BACKOFF_MAX' is deprecated and "
76 |             "will be removed in v2.0. Use 'Retry.DEFAULT_BACKOFF_MAX' instead",
77 |             DeprecationWarning,
78 |         )
79 |         return cls.DEFAULT_BACKOFF_MAX
80 | 
81 |     @BACKOFF_MAX.setter
82 |     def BACKOFF_MAX(cls, value):
83 |         warnings.warn(
84 |             "Using 'Retry.BACKOFF_MAX' is deprecated and "
85 |             "will be removed in v2.0. Use 'Retry.DEFAULT_BACKOFF_MAX' instead",
86 |             DeprecationWarning,
87 |         )
88 |         cls.DEFAULT_BACKOFF_MAX = value
89 | 
90 | 
91 | @six.add_metaclass(_RetryMeta)
92 | class Retry(object):
93 |     """Retry configuration.
94 | 
95 |     Each retry attempt will create a new Retry object with updated values, so
96 |     they can be safely reused.
97 | 
98 |     Retries can be defined as a default for a pool::
99 | 
100 |         retries = Retry(connect=5, read=2, redirect=5)
101 |         http = PoolManager(retries=retries)
102 |         response = http.request('GET', 'http://example.com/')
103 | 
104 |     Or per-request (which overrides the default for the pool)::
105 | 
106 |         response = http.request('GET', 'http://example.com/', retries=Retry(10))
107 | 
108 |     Retries can be disabled by passing ``False``::
109 | 
110 |         response = http.request('GET', 'http://example.com/', retries=False)
111 | 
112 |     Errors will be wrapped in :class:`~urllib3.exceptions.MaxRetryError` unless
113 |     retries are disabled, in which case the causing exception will be raised.
114 | 
115 |     :param int total:
116 |         Total number of retries to allow. Takes precedence over other counts.
117 | 
118 |         Set to ``None`` to remove this constraint and fall back on other
119 |         counts.
120 | 
121 |         Set to ``0`` to fail on the first retry.
122 | 
123 |         Set to ``False`` to disable and imply ``raise_on_redirect=False``.
124 | 
125 |     :param int connect:
126 |         How many connection-related errors to retry on.
127 | 
128 |         These are errors raised before the request is sent to the remote server,
129 |         which we assume has not triggered the server to process the request.
130 | 
131 |         Set to ``0`` to fail on the first retry of this type.
132 | 
133 |     :param int read:
134 |         How many times to retry on read errors.
135 | 
136 |         These errors are raised after the request was sent to the server, so the
137 |         request may have side-effects.
138 | 
139 |         Set to ``0`` to fail on the first retry of this type.
140 | 
141 |     :param int redirect:
142 |         How many redirects to perform. Limit this to avoid infinite redirect
143 |         loops.
144 | 
145 |         A redirect is a HTTP response with a status code 301, 302, 303, 307 or
146 |         308.
147 | 
148 |         Set to ``0`` to fail on the first retry of this type.
149 | 
150 |         Set to ``False`` to disable and imply ``raise_on_redirect=False``.
151 | 
152 |     :param int status:
153 |         How many times to retry on bad status codes.
154 | 
155 |         These are retries made on responses, where status code matches
156 |         ``status_forcelist``.
157 | 
158 |         Set to ``0`` to fail on the first retry of this type.
159 | 
160 |     :param int other:
161 |         How many times to retry on other errors.
162 | 
163 |         Other errors are errors that are not connect, read, redirect or status errors.
164 |         These errors might be raised after the request was sent to the server, so the
165 |         request might have side-effects.
166 | 
167 |         Set to ``0`` to fail on the first retry of this type.
168 | 
169 |         If ``total`` is not set, it's a good idea to set this to 0 to account
170 |         for unexpected edge cases and avoid infinite retry loops.
171 | 
172 |     :param iterable allowed_methods:
173 |         Set of uppercased HTTP method verbs that we should retry on.
174 | 
175 |         By default, we only retry on methods which are considered to be
176 |         idempotent (multiple requests with the same parameters end with the
177 |         same state). See :attr:`Retry.DEFAULT_ALLOWED_METHODS`.
178 | 
179 |         Set to a ``False`` value to retry on any verb.
180 | 
181 |         .. warning::
182 | 
183 |             Previously this parameter was named ``method_whitelist``, that
184 |             usage is deprecated in v1.26.0 and will be removed in v2.0.
185 | 
186 |     :param iterable status_forcelist:
187 |         A set of integer HTTP status codes that we should force a retry on.
188 |         A retry is initiated if the request method is in ``allowed_methods``
189 |         and the response status code is in ``status_forcelist``.
190 | 
191 |         By default, this is disabled with ``None``.
192 | 
193 |     :param float backoff_factor:
194 |         A backoff factor to apply between attempts after the second try
195 |         (most errors are resolved immediately by a second try without a
196 |         delay). urllib3 will sleep for::
197 | 
198 |             {backoff factor} * (2 ** ({number of total retries} - 1))
199 | 
200 |         seconds. If the backoff_factor is 0.1, then :func:`.sleep` will sleep
201 |         for [0.0s, 0.2s, 0.4s, ...] between retries. It will never be longer
202 |         than :attr:`Retry.DEFAULT_BACKOFF_MAX`.
203 | 
204 |         By default, backoff is disabled (set to 0).
205 | 
206 |     :param bool raise_on_redirect: Whether, if the number of redirects is
207 |         exhausted, to raise a MaxRetryError, or to return a response with a
208 |         response code in the 3xx range.
209 | 
210 |     :param bool raise_on_status: Similar meaning to ``raise_on_redirect``:
211 |         whether we should raise an exception, or return a response,
212 |         if status falls in ``status_forcelist`` range and retries have
213 |         been exhausted.
214 | 
215 |     :param tuple history: The history of the request encountered during
216 |         each call to :meth:`~Retry.increment`. The list is in the order
217 |         the requests occurred. Each list item is of class :class:`RequestHistory`.
218 | 
219 |     :param bool respect_retry_after_header:
220 |         Whether to respect Retry-After header on status codes defined as
221 |         :attr:`Retry.RETRY_AFTER_STATUS_CODES` or not.
222 | 
223 |     :param iterable remove_headers_on_redirect:
224 |         Sequence of headers to remove from the request when a response
225 |         indicating a redirect is returned before firing off the redirected
226 |         request.
227 |     """
228 | 
229 |     #: Default methods to be used for ``allowed_methods``
230 |     DEFAULT_ALLOWED_METHODS = frozenset(
231 |         ["HEAD", "GET", "PUT", "DELETE", "OPTIONS", "TRACE"]
232 |     )
233 | 
234 |     #: Default status codes to be used for ``status_forcelist``
235 |     RETRY_AFTER_STATUS_CODES = frozenset([413, 429, 503])
236 | 
237 |     #: Default headers to be used for ``remove_headers_on_redirect``
238 |     DEFAULT_REMOVE_HEADERS_ON_REDIRECT = frozenset(
239 |         ["Cookie", "Authorization", "Proxy-Authorization"]
240 |     )
241 | 
242 |     #: Maximum backoff time.
243 |     DEFAULT_BACKOFF_MAX = 120
244 | 
245 |     def __init__(
246 |         self,
247 |         total=10,
248 |         connect=None,
249 |         read=None,
250 |         redirect=None,
251 |         status=None,
252 |         other=None,
253 |         allowed_methods=_Default,
254 |         status_forcelist=None,
255 |         backoff_factor=0,
256 |         raise_on_redirect=True,
257 |         raise_on_status=True,
258 |         history=None,
259 |         respect_retry_after_header=True,
260 |         remove_headers_on_redirect=_Default,
261 |         # TODO: Deprecated, remove in v2.0
262 |         method_whitelist=_Default,
263 |     ):
264 | 
265 |         if method_whitelist is not _Default:
266 |             if allowed_methods is not _Default:
267 |                 raise ValueError(
268 |                     "Using both 'allowed_methods' and "
269 |                     "'method_whitelist' together is not allowed. "
270 |                     "Instead only use 'allowed_methods'"
271 |                 )
272 |             warnings.warn(
273 |                 "Using 'method_whitelist' with Retry is deprecated and "
274 |                 "will be removed in v2.0. Use 'allowed_methods' instead",
275 |                 DeprecationWarning,
276 |                 stacklevel=2,
277 |             )
278 |             allowed_methods = method_whitelist
279 |         if allowed_methods is _Default:
280 |             allowed_methods = self.DEFAULT_ALLOWED_METHODS
281 |         if remove_headers_on_redirect is _Default:
282 |             remove_headers_on_redirect = self.DEFAULT_REMOVE_HEADERS_ON_REDIRECT
283 | 
284 |         self.total = total
285 |         self.connect = connect
286 |         self.read = read
287 |         self.status = status
288 |         self.other = other
289 | 
290 |         if redirect is False or total is False:
291 |             redirect = 0
292 |             raise_on_redirect = False
293 | 
294 |         self.redirect = redirect
295 |         self.status_forcelist = status_forcelist or set()
296 |         self.allowed_methods = allowed_methods
297 |         self.backoff_factor = backoff_factor
298 |         self.raise_on_redirect = raise_on_redirect
299 |         self.raise_on_status = raise_on_status
300 |         self.history = history or tuple()
301 |         self.respect_retry_after_header = respect_retry_after_header
302 |         self.remove_headers_on_redirect = frozenset(
303 |             [h.lower() for h in remove_headers_on_redirect]
304 |         )
305 | 
306 |     def new(self, **kw):
307 |         params = dict(
308 |             total=self.total,
309 |             connect=self.connect,
310 |             read=self.read,
311 |             redirect=self.redirect,
312 |             status=self.status,
313 |             other=self.other,
314 |             status_forcelist=self.status_forcelist,
315 |             backoff_factor=self.backoff_factor,
316 |             raise_on_redirect=self.raise_on_redirect,
317 |             raise_on_status=self.raise_on_status,
318 |             history=self.history,
319 |             remove_headers_on_redirect=self.remove_headers_on_redirect,
320 |             respect_retry_after_header=self.respect_retry_after_header,
321 |         )
322 | 
323 |         # TODO: If already given in **kw we use what's given to us
324 |         # If not given we need to figure out what to pass. We decide
325 |         # based on whether our class has the 'method_whitelist' property
326 |         # and if so we pass the deprecated 'method_whitelist' otherwise
327 |         # we use 'allowed_methods'. Remove in v2.0
328 |         if "method_whitelist" not in kw and "allowed_methods" not in kw:
329 |             if "method_whitelist" in self.__dict__:
330 |                 warnings.warn(
331 |                     "Using 'method_whitelist' with Retry is deprecated and "
332 |                     "will be removed in v2.0. Use 'allowed_methods' instead",
333 |                     DeprecationWarning,
334 |                 )
335 |                 params["method_whitelist"] = self.allowed_methods
336 |             else:
337 |                 params["allowed_methods"] = self.allowed_methods
338 | 
339 |         params.update(kw)
340 |         return type(self)(**params)
341 | 
342 |     @classmethod
[TRUNCATED]
```

.venv/lib/python3.13/site-packages/pip/_vendor/urllib3/util/ssl_.py
```
1 | from __future__ import absolute_import
2 | 
3 | import hashlib
4 | import hmac
5 | import os
6 | import sys
7 | import warnings
8 | from binascii import hexlify, unhexlify
9 | 
10 | from ..exceptions import (
11 |     InsecurePlatformWarning,
12 |     ProxySchemeUnsupported,
13 |     SNIMissingWarning,
14 |     SSLError,
15 | )
16 | from ..packages import six
17 | from .url import BRACELESS_IPV6_ADDRZ_RE, IPV4_RE
18 | 
19 | SSLContext = None
20 | SSLTransport = None
21 | HAS_SNI = False
22 | IS_PYOPENSSL = False
23 | IS_SECURETRANSPORT = False
24 | ALPN_PROTOCOLS = ["http/1.1"]
25 | 
26 | # Maps the length of a digest to a possible hash function producing this digest
27 | HASHFUNC_MAP = {
28 |     length: getattr(hashlib, algorithm, None)
29 |     for length, algorithm in ((32, "md5"), (40, "sha1"), (64, "sha256"))
30 | }
31 | 
32 | 
33 | def _const_compare_digest_backport(a, b):
34 |     """
35 |     Compare two digests of equal length in constant time.
36 | 
37 |     The digests must be of type str/bytes.
38 |     Returns True if the digests match, and False otherwise.
39 |     """
40 |     result = abs(len(a) - len(b))
41 |     for left, right in zip(bytearray(a), bytearray(b)):
42 |         result |= left ^ right
43 |     return result == 0
44 | 
45 | 
46 | _const_compare_digest = getattr(hmac, "compare_digest", _const_compare_digest_backport)
47 | 
48 | try:  # Test for SSL features
49 |     import ssl
50 |     from ssl import CERT_REQUIRED, wrap_socket
51 | except ImportError:
52 |     pass
53 | 
54 | try:
55 |     from ssl import HAS_SNI  # Has SNI?
56 | except ImportError:
57 |     pass
58 | 
59 | try:
60 |     from .ssltransport import SSLTransport
61 | except ImportError:
62 |     pass
63 | 
64 | 
65 | try:  # Platform-specific: Python 3.6
66 |     from ssl import PROTOCOL_TLS
67 | 
68 |     PROTOCOL_SSLv23 = PROTOCOL_TLS
69 | except ImportError:
70 |     try:
71 |         from ssl import PROTOCOL_SSLv23 as PROTOCOL_TLS
72 | 
73 |         PROTOCOL_SSLv23 = PROTOCOL_TLS
74 |     except ImportError:
75 |         PROTOCOL_SSLv23 = PROTOCOL_TLS = 2
76 | 
77 | try:
78 |     from ssl import PROTOCOL_TLS_CLIENT
79 | except ImportError:
80 |     PROTOCOL_TLS_CLIENT = PROTOCOL_TLS
81 | 
82 | 
83 | try:
84 |     from ssl import OP_NO_COMPRESSION, OP_NO_SSLv2, OP_NO_SSLv3
85 | except ImportError:
86 |     OP_NO_SSLv2, OP_NO_SSLv3 = 0x1000000, 0x2000000
87 |     OP_NO_COMPRESSION = 0x20000
88 | 
89 | 
90 | try:  # OP_NO_TICKET was added in Python 3.6
91 |     from ssl import OP_NO_TICKET
92 | except ImportError:
93 |     OP_NO_TICKET = 0x4000
94 | 
95 | 
96 | # A secure default.
97 | # Sources for more information on TLS ciphers:
98 | #
99 | # - https://wiki.mozilla.org/Security/Server_Side_TLS
100 | # - https://www.ssllabs.com/projects/best-practices/index.html
101 | # - https://hynek.me/articles/hardening-your-web-servers-ssl-ciphers/
102 | #
103 | # The general intent is:
104 | # - prefer cipher suites that offer perfect forward secrecy (DHE/ECDHE),
105 | # - prefer ECDHE over DHE for better performance,
106 | # - prefer any AES-GCM and ChaCha20 over any AES-CBC for better performance and
107 | #   security,
108 | # - prefer AES-GCM over ChaCha20 because hardware-accelerated AES is common,
109 | # - disable NULL authentication, MD5 MACs, DSS, and other
110 | #   insecure ciphers for security reasons.
111 | # - NOTE: TLS 1.3 cipher suites are managed through a different interface
112 | #   not exposed by CPython (yet!) and are enabled by default if they're available.
113 | DEFAULT_CIPHERS = ":".join(
114 |     [
115 |         "ECDHE+AESGCM",
116 |         "ECDHE+CHACHA20",
117 |         "DHE+AESGCM",
118 |         "DHE+CHACHA20",
119 |         "ECDH+AESGCM",
120 |         "DH+AESGCM",
121 |         "ECDH+AES",
122 |         "DH+AES",
123 |         "RSA+AESGCM",
124 |         "RSA+AES",
125 |         "!aNULL",
126 |         "!eNULL",
127 |         "!MD5",
128 |         "!DSS",
129 |     ]
130 | )
131 | 
132 | try:
133 |     from ssl import SSLContext  # Modern SSL?
134 | except ImportError:
135 | 
136 |     class SSLContext(object):  # Platform-specific: Python 2
137 |         def __init__(self, protocol_version):
138 |             self.protocol = protocol_version
139 |             # Use default values from a real SSLContext
140 |             self.check_hostname = False
141 |             self.verify_mode = ssl.CERT_NONE
142 |             self.ca_certs = None
143 |             self.options = 0
144 |             self.certfile = None
145 |             self.keyfile = None
146 |             self.ciphers = None
147 | 
148 |         def load_cert_chain(self, certfile, keyfile):
149 |             self.certfile = certfile
150 |             self.keyfile = keyfile
151 | 
152 |         def load_verify_locations(self, cafile=None, capath=None, cadata=None):
153 |             self.ca_certs = cafile
154 | 
155 |             if capath is not None:
156 |                 raise SSLError("CA directories not supported in older Pythons")
157 | 
158 |             if cadata is not None:
159 |                 raise SSLError("CA data not supported in older Pythons")
160 | 
161 |         def set_ciphers(self, cipher_suite):
162 |             self.ciphers = cipher_suite
163 | 
164 |         def wrap_socket(self, socket, server_hostname=None, server_side=False):
165 |             warnings.warn(
166 |                 "A true SSLContext object is not available. This prevents "
167 |                 "urllib3 from configuring SSL appropriately and may cause "
168 |                 "certain SSL connections to fail. You can upgrade to a newer "
169 |                 "version of Python to solve this. For more information, see "
170 |                 "https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html"
171 |                 "#ssl-warnings",
172 |                 InsecurePlatformWarning,
173 |             )
174 |             kwargs = {
175 |                 "keyfile": self.keyfile,
176 |                 "certfile": self.certfile,
177 |                 "ca_certs": self.ca_certs,
178 |                 "cert_reqs": self.verify_mode,
179 |                 "ssl_version": self.protocol,
180 |                 "server_side": server_side,
181 |             }
182 |             return wrap_socket(socket, ciphers=self.ciphers, **kwargs)
183 | 
184 | 
185 | def assert_fingerprint(cert, fingerprint):
186 |     """
187 |     Checks if given fingerprint matches the supplied certificate.
188 | 
189 |     :param cert:
190 |         Certificate as bytes object.
191 |     :param fingerprint:
192 |         Fingerprint as string of hexdigits, can be interspersed by colons.
193 |     """
194 | 
195 |     fingerprint = fingerprint.replace(":", "").lower()
196 |     digest_length = len(fingerprint)
197 |     if digest_length not in HASHFUNC_MAP:
198 |         raise SSLError("Fingerprint of invalid length: {0}".format(fingerprint))
199 |     hashfunc = HASHFUNC_MAP.get(digest_length)
200 |     if hashfunc is None:
201 |         raise SSLError(
202 |             "Hash function implementation unavailable for fingerprint length: {0}".format(
203 |                 digest_length
204 |             )
205 |         )
206 | 
207 |     # We need encode() here for py32; works on py2 and p33.
208 |     fingerprint_bytes = unhexlify(fingerprint.encode())
209 | 
210 |     cert_digest = hashfunc(cert).digest()
211 | 
212 |     if not _const_compare_digest(cert_digest, fingerprint_bytes):
213 |         raise SSLError(
214 |             'Fingerprints did not match. Expected "{0}", got "{1}".'.format(
215 |                 fingerprint, hexlify(cert_digest)
216 |             )
217 |         )
218 | 
219 | 
220 | def resolve_cert_reqs(candidate):
221 |     """
222 |     Resolves the argument to a numeric constant, which can be passed to
223 |     the wrap_socket function/method from the ssl module.
224 |     Defaults to :data:`ssl.CERT_REQUIRED`.
225 |     If given a string it is assumed to be the name of the constant in the
226 |     :mod:`ssl` module or its abbreviation.
227 |     (So you can specify `REQUIRED` instead of `CERT_REQUIRED`.
228 |     If it's neither `None` nor a string we assume it is already the numeric
229 |     constant which can directly be passed to wrap_socket.
230 |     """
231 |     if candidate is None:
232 |         return CERT_REQUIRED
233 | 
234 |     if isinstance(candidate, str):
235 |         res = getattr(ssl, candidate, None)
236 |         if res is None:
237 |             res = getattr(ssl, "CERT_" + candidate)
238 |         return res
239 | 
240 |     return candidate
241 | 
242 | 
243 | def resolve_ssl_version(candidate):
244 |     """
245 |     like resolve_cert_reqs
246 |     """
247 |     if candidate is None:
248 |         return PROTOCOL_TLS
249 | 
250 |     if isinstance(candidate, str):
251 |         res = getattr(ssl, candidate, None)
252 |         if res is None:
253 |             res = getattr(ssl, "PROTOCOL_" + candidate)
254 |         return res
255 | 
256 |     return candidate
257 | 
258 | 
259 | def create_urllib3_context(
260 |     ssl_version=None, cert_reqs=None, options=None, ciphers=None
261 | ):
262 |     """All arguments have the same meaning as ``ssl_wrap_socket``.
263 | 
264 |     By default, this function does a lot of the same work that
265 |     ``ssl.create_default_context`` does on Python 3.4+. It:
266 | 
267 |     - Disables SSLv2, SSLv3, and compression
268 |     - Sets a restricted set of server ciphers
269 | 
270 |     If you wish to enable SSLv3, you can do::
271 | 
272 |         from pip._vendor.urllib3.util import ssl_
273 |         context = ssl_.create_urllib3_context()
274 |         context.options &= ~ssl_.OP_NO_SSLv3
275 | 
276 |     You can do the same to enable compression (substituting ``COMPRESSION``
277 |     for ``SSLv3`` in the last line above).
278 | 
279 |     :param ssl_version:
280 |         The desired protocol version to use. This will default to
281 |         PROTOCOL_SSLv23 which will negotiate the highest protocol that both
282 |         the server and your installation of OpenSSL support.
283 |     :param cert_reqs:
284 |         Whether to require the certificate verification. This defaults to
285 |         ``ssl.CERT_REQUIRED``.
286 |     :param options:
287 |         Specific OpenSSL options. These default to ``ssl.OP_NO_SSLv2``,
288 |         ``ssl.OP_NO_SSLv3``, ``ssl.OP_NO_COMPRESSION``, and ``ssl.OP_NO_TICKET``.
289 |     :param ciphers:
290 |         Which cipher suites to allow the server to select.
291 |     :returns:
292 |         Constructed SSLContext object with specified options
293 |     :rtype: SSLContext
294 |     """
295 |     # PROTOCOL_TLS is deprecated in Python 3.10
296 |     if not ssl_version or ssl_version == PROTOCOL_TLS:
297 |         ssl_version = PROTOCOL_TLS_CLIENT
298 | 
299 |     context = SSLContext(ssl_version)
300 | 
301 |     context.set_ciphers(ciphers or DEFAULT_CIPHERS)
302 | 
303 |     # Setting the default here, as we may have no ssl module on import
304 |     cert_reqs = ssl.CERT_REQUIRED if cert_reqs is None else cert_reqs
305 | 
306 |     if options is None:
307 |         options = 0
308 |         # SSLv2 is easily broken and is considered harmful and dangerous
309 |         options |= OP_NO_SSLv2
310 |         # SSLv3 has several problems and is now dangerous
311 |         options |= OP_NO_SSLv3
312 |         # Disable compression to prevent CRIME attacks for OpenSSL 1.0+
313 |         # (issue #309)
314 |         options |= OP_NO_COMPRESSION
315 |         # TLSv1.2 only. Unless set explicitly, do not request tickets.
316 |         # This may save some bandwidth on wire, and although the ticket is encrypted,
317 |         # there is a risk associated with it being on wire,
318 |         # if the server is not rotating its ticketing keys properly.
319 |         options |= OP_NO_TICKET
320 | 
321 |     context.options |= options
322 | 
323 |     # Enable post-handshake authentication for TLS 1.3, see GH #1634. PHA is
324 |     # necessary for conditional client cert authentication with TLS 1.3.
325 |     # The attribute is None for OpenSSL <= 1.1.0 or does not exist in older
326 |     # versions of Python.  We only enable on Python 3.7.4+ or if certificate
327 |     # verification is enabled to work around Python issue #37428
328 |     # See: https://bugs.python.org/issue37428
329 |     if (cert_reqs == ssl.CERT_REQUIRED or sys.version_info >= (3, 7, 4)) and getattr(
330 |         context, "post_handshake_auth", None
331 |     ) is not None:
332 |         context.post_handshake_auth = True
333 | 
334 |     def disable_check_hostname():
335 |         if (
336 |             getattr(context, "check_hostname", None) is not None
337 |         ):  # Platform-specific: Python 3.2
338 |             # We do our own verification, including fingerprints and alternative
339 |             # hostnames. So disable it here
340 |             context.check_hostname = False
341 | 
342 |     # The order of the below lines setting verify_mode and check_hostname
343 |     # matter due to safe-guards SSLContext has to prevent an SSLContext with
344 |     # check_hostname=True, verify_mode=NONE/OPTIONAL. This is made even more
345 |     # complex because we don't know whether PROTOCOL_TLS_CLIENT will be used
346 |     # or not so we don't know the initial state of the freshly created SSLContext.
347 |     if cert_reqs == ssl.CERT_REQUIRED:
348 |         context.verify_mode = cert_reqs
349 |         disable_check_hostname()
350 |     else:
[TRUNCATED]
```

.venv/lib/python3.13/site-packages/pip/_vendor/urllib3/util/ssl_match_hostname.py
```
1 | """The match_hostname() function from Python 3.3.3, essential when using SSL."""
2 | 
3 | # Note: This file is under the PSF license as the code comes from the python
4 | # stdlib.   http://docs.python.org/3/license.html
5 | 
6 | import re
7 | import sys
8 | 
9 | # ipaddress has been backported to 2.6+ in pypi.  If it is installed on the
10 | # system, use it to handle IPAddress ServerAltnames (this was added in
11 | # python-3.5) otherwise only do DNS matching.  This allows
12 | # util.ssl_match_hostname to continue to be used in Python 2.7.
13 | try:
14 |     import ipaddress
15 | except ImportError:
16 |     ipaddress = None
17 | 
18 | __version__ = "3.5.0.1"
19 | 
20 | 
21 | class CertificateError(ValueError):
22 |     pass
23 | 
24 | 
25 | def _dnsname_match(dn, hostname, max_wildcards=1):
26 |     """Matching according to RFC 6125, section 6.4.3
27 | 
28 |     http://tools.ietf.org/html/rfc6125#section-6.4.3
29 |     """
30 |     pats = []
31 |     if not dn:
32 |         return False
33 | 
34 |     # Ported from python3-syntax:
35 |     # leftmost, *remainder = dn.split(r'.')
36 |     parts = dn.split(r".")
37 |     leftmost = parts[0]
38 |     remainder = parts[1:]
39 | 
40 |     wildcards = leftmost.count("*")
41 |     if wildcards > max_wildcards:
42 |         # Issue #17980: avoid denials of service by refusing more
43 |         # than one wildcard per fragment.  A survey of established
44 |         # policy among SSL implementations showed it to be a
45 |         # reasonable choice.
46 |         raise CertificateError(
47 |             "too many wildcards in certificate DNS name: " + repr(dn)
48 |         )
49 | 
50 |     # speed up common case w/o wildcards
51 |     if not wildcards:
52 |         return dn.lower() == hostname.lower()
53 | 
54 |     # RFC 6125, section 6.4.3, subitem 1.
55 |     # The client SHOULD NOT attempt to match a presented identifier in which
56 |     # the wildcard character comprises a label other than the left-most label.
57 |     if leftmost == "*":
58 |         # When '*' is a fragment by itself, it matches a non-empty dotless
59 |         # fragment.
60 |         pats.append("[^.]+")
61 |     elif leftmost.startswith("xn--") or hostname.startswith("xn--"):
62 |         # RFC 6125, section 6.4.3, subitem 3.
63 |         # The client SHOULD NOT attempt to match a presented identifier
64 |         # where the wildcard character is embedded within an A-label or
65 |         # U-label of an internationalized domain name.
66 |         pats.append(re.escape(leftmost))
67 |     else:
68 |         # Otherwise, '*' matches any dotless string, e.g. www*
69 |         pats.append(re.escape(leftmost).replace(r"\*", "[^.]*"))
70 | 
71 |     # add the remaining fragments, ignore any wildcards
72 |     for frag in remainder:
73 |         pats.append(re.escape(frag))
74 | 
75 |     pat = re.compile(r"\A" + r"\.".join(pats) + r"\Z", re.IGNORECASE)
76 |     return pat.match(hostname)
77 | 
78 | 
79 | def _to_unicode(obj):
80 |     if isinstance(obj, str) and sys.version_info < (3,):
81 |         # ignored flake8 # F821 to support python 2.7 function
82 |         obj = unicode(obj, encoding="ascii", errors="strict")  # noqa: F821
83 |     return obj
84 | 
85 | 
86 | def _ipaddress_match(ipname, host_ip):
87 |     """Exact matching of IP addresses.
88 | 
89 |     RFC 6125 explicitly doesn't define an algorithm for this
90 |     (section 1.7.2 - "Out of Scope").
91 |     """
92 |     # OpenSSL may add a trailing newline to a subjectAltName's IP address
93 |     # Divergence from upstream: ipaddress can't handle byte str
94 |     ip = ipaddress.ip_address(_to_unicode(ipname).rstrip())
95 |     return ip == host_ip
96 | 
97 | 
98 | def match_hostname(cert, hostname):
99 |     """Verify that *cert* (in decoded format as returned by
100 |     SSLSocket.getpeercert()) matches the *hostname*.  RFC 2818 and RFC 6125
101 |     rules are followed, but IP addresses are not accepted for *hostname*.
102 | 
103 |     CertificateError is raised on failure. On success, the function
104 |     returns nothing.
105 |     """
106 |     if not cert:
107 |         raise ValueError(
108 |             "empty or no certificate, match_hostname needs a "
109 |             "SSL socket or SSL context with either "
110 |             "CERT_OPTIONAL or CERT_REQUIRED"
111 |         )
112 |     try:
113 |         # Divergence from upstream: ipaddress can't handle byte str
114 |         host_ip = ipaddress.ip_address(_to_unicode(hostname))
115 |     except (UnicodeError, ValueError):
116 |         # ValueError: Not an IP address (common case)
117 |         # UnicodeError: Divergence from upstream: Have to deal with ipaddress not taking
118 |         # byte strings.  addresses should be all ascii, so we consider it not
119 |         # an ipaddress in this case
120 |         host_ip = None
121 |     except AttributeError:
122 |         # Divergence from upstream: Make ipaddress library optional
123 |         if ipaddress is None:
124 |             host_ip = None
125 |         else:  # Defensive
126 |             raise
127 |     dnsnames = []
128 |     san = cert.get("subjectAltName", ())
129 |     for key, value in san:
130 |         if key == "DNS":
131 |             if host_ip is None and _dnsname_match(value, hostname):
132 |                 return
133 |             dnsnames.append(value)
134 |         elif key == "IP Address":
135 |             if host_ip is not None and _ipaddress_match(value, host_ip):
136 |                 return
137 |             dnsnames.append(value)
138 |     if not dnsnames:
139 |         # The subject is only checked when there is no dNSName entry
140 |         # in subjectAltName
141 |         for sub in cert.get("subject", ()):
142 |             for key, value in sub:
143 |                 # XXX according to RFC 2818, the most specific Common Name
144 |                 # must be used.
145 |                 if key == "commonName":
146 |                     if _dnsname_match(value, hostname):
147 |                         return
148 |                     dnsnames.append(value)
149 |     if len(dnsnames) > 1:
150 |         raise CertificateError(
151 |             "hostname %r "
152 |             "doesn't match either of %s" % (hostname, ", ".join(map(repr, dnsnames)))
153 |         )
154 |     elif len(dnsnames) == 1:
155 |         raise CertificateError("hostname %r doesn't match %r" % (hostname, dnsnames[0]))
156 |     else:
157 |         raise CertificateError(
158 |             "no appropriate commonName or subjectAltName fields were found"
159 |         )
```

.venv/lib/python3.13/site-packages/pip/_vendor/urllib3/util/ssltransport.py
```
1 | import io
2 | import socket
3 | import ssl
4 | 
5 | from ..exceptions import ProxySchemeUnsupported
6 | from ..packages import six
7 | 
8 | SSL_BLOCKSIZE = 16384
9 | 
10 | 
11 | class SSLTransport:
12 |     """
13 |     The SSLTransport wraps an existing socket and establishes an SSL connection.
14 | 
15 |     Contrary to Python's implementation of SSLSocket, it allows you to chain
16 |     multiple TLS connections together. It's particularly useful if you need to
17 |     implement TLS within TLS.
18 | 
19 |     The class supports most of the socket API operations.
20 |     """
21 | 
22 |     @staticmethod
23 |     def _validate_ssl_context_for_tls_in_tls(ssl_context):
24 |         """
25 |         Raises a ProxySchemeUnsupported if the provided ssl_context can't be used
26 |         for TLS in TLS.
27 | 
28 |         The only requirement is that the ssl_context provides the 'wrap_bio'
29 |         methods.
30 |         """
31 | 
32 |         if not hasattr(ssl_context, "wrap_bio"):
33 |             if six.PY2:
34 |                 raise ProxySchemeUnsupported(
35 |                     "TLS in TLS requires SSLContext.wrap_bio() which isn't "
36 |                     "supported on Python 2"
37 |                 )
38 |             else:
39 |                 raise ProxySchemeUnsupported(
40 |                     "TLS in TLS requires SSLContext.wrap_bio() which isn't "
41 |                     "available on non-native SSLContext"
42 |                 )
43 | 
44 |     def __init__(
45 |         self, socket, ssl_context, server_hostname=None, suppress_ragged_eofs=True
46 |     ):
47 |         """
48 |         Create an SSLTransport around socket using the provided ssl_context.
49 |         """
50 |         self.incoming = ssl.MemoryBIO()
51 |         self.outgoing = ssl.MemoryBIO()
52 | 
53 |         self.suppress_ragged_eofs = suppress_ragged_eofs
54 |         self.socket = socket
55 | 
56 |         self.sslobj = ssl_context.wrap_bio(
57 |             self.incoming, self.outgoing, server_hostname=server_hostname
58 |         )
59 | 
60 |         # Perform initial handshake.
61 |         self._ssl_io_loop(self.sslobj.do_handshake)
62 | 
63 |     def __enter__(self):
64 |         return self
65 | 
66 |     def __exit__(self, *_):
67 |         self.close()
68 | 
69 |     def fileno(self):
70 |         return self.socket.fileno()
71 | 
72 |     def read(self, len=1024, buffer=None):
73 |         return self._wrap_ssl_read(len, buffer)
74 | 
75 |     def recv(self, len=1024, flags=0):
76 |         if flags != 0:
77 |             raise ValueError("non-zero flags not allowed in calls to recv")
78 |         return self._wrap_ssl_read(len)
79 | 
80 |     def recv_into(self, buffer, nbytes=None, flags=0):
81 |         if flags != 0:
82 |             raise ValueError("non-zero flags not allowed in calls to recv_into")
83 |         if buffer and (nbytes is None):
84 |             nbytes = len(buffer)
85 |         elif nbytes is None:
86 |             nbytes = 1024
87 |         return self.read(nbytes, buffer)
88 | 
89 |     def sendall(self, data, flags=0):
90 |         if flags != 0:
91 |             raise ValueError("non-zero flags not allowed in calls to sendall")
92 |         count = 0
93 |         with memoryview(data) as view, view.cast("B") as byte_view:
94 |             amount = len(byte_view)
95 |             while count < amount:
96 |                 v = self.send(byte_view[count:])
97 |                 count += v
98 | 
99 |     def send(self, data, flags=0):
100 |         if flags != 0:
101 |             raise ValueError("non-zero flags not allowed in calls to send")
102 |         response = self._ssl_io_loop(self.sslobj.write, data)
103 |         return response
104 | 
105 |     def makefile(
106 |         self, mode="r", buffering=None, encoding=None, errors=None, newline=None
107 |     ):
108 |         """
109 |         Python's httpclient uses makefile and buffered io when reading HTTP
110 |         messages and we need to support it.
111 | 
112 |         This is unfortunately a copy and paste of socket.py makefile with small
113 |         changes to point to the socket directly.
114 |         """
115 |         if not set(mode) <= {"r", "w", "b"}:
116 |             raise ValueError("invalid mode %r (only r, w, b allowed)" % (mode,))
117 | 
118 |         writing = "w" in mode
119 |         reading = "r" in mode or not writing
120 |         assert reading or writing
121 |         binary = "b" in mode
122 |         rawmode = ""
123 |         if reading:
124 |             rawmode += "r"
125 |         if writing:
126 |             rawmode += "w"
127 |         raw = socket.SocketIO(self, rawmode)
128 |         self.socket._io_refs += 1
129 |         if buffering is None:
130 |             buffering = -1
131 |         if buffering < 0:
132 |             buffering = io.DEFAULT_BUFFER_SIZE
133 |         if buffering == 0:
134 |             if not binary:
135 |                 raise ValueError("unbuffered streams must be binary")
136 |             return raw
137 |         if reading and writing:
138 |             buffer = io.BufferedRWPair(raw, raw, buffering)
139 |         elif reading:
140 |             buffer = io.BufferedReader(raw, buffering)
141 |         else:
142 |             assert writing
143 |             buffer = io.BufferedWriter(raw, buffering)
144 |         if binary:
145 |             return buffer
146 |         text = io.TextIOWrapper(buffer, encoding, errors, newline)
147 |         text.mode = mode
148 |         return text
149 | 
150 |     def unwrap(self):
151 |         self._ssl_io_loop(self.sslobj.unwrap)
152 | 
153 |     def close(self):
154 |         self.socket.close()
155 | 
156 |     def getpeercert(self, binary_form=False):
157 |         return self.sslobj.getpeercert(binary_form)
158 | 
159 |     def version(self):
160 |         return self.sslobj.version()
161 | 
162 |     def cipher(self):
163 |         return self.sslobj.cipher()
164 | 
165 |     def selected_alpn_protocol(self):
166 |         return self.sslobj.selected_alpn_protocol()
167 | 
168 |     def selected_npn_protocol(self):
169 |         return self.sslobj.selected_npn_protocol()
170 | 
171 |     def shared_ciphers(self):
172 |         return self.sslobj.shared_ciphers()
173 | 
174 |     def compression(self):
175 |         return self.sslobj.compression()
176 | 
177 |     def settimeout(self, value):
178 |         self.socket.settimeout(value)
179 | 
180 |     def gettimeout(self):
181 |         return self.socket.gettimeout()
182 | 
183 |     def _decref_socketios(self):
184 |         self.socket._decref_socketios()
185 | 
186 |     def _wrap_ssl_read(self, len, buffer=None):
187 |         try:
188 |             return self._ssl_io_loop(self.sslobj.read, len, buffer)
189 |         except ssl.SSLError as e:
190 |             if e.errno == ssl.SSL_ERROR_EOF and self.suppress_ragged_eofs:
191 |                 return 0  # eof, return 0.
192 |             else:
193 |                 raise
194 | 
195 |     def _ssl_io_loop(self, func, *args):
196 |         """Performs an I/O loop between incoming/outgoing and the socket."""
197 |         should_loop = True
198 |         ret = None
199 | 
200 |         while should_loop:
201 |             errno = None
202 |             try:
203 |                 ret = func(*args)
204 |             except ssl.SSLError as e:
205 |                 if e.errno not in (ssl.SSL_ERROR_WANT_READ, ssl.SSL_ERROR_WANT_WRITE):
206 |                     # WANT_READ, and WANT_WRITE are expected, others are not.
207 |                     raise e
208 |                 errno = e.errno
209 | 
210 |             buf = self.outgoing.read()
211 |             self.socket.sendall(buf)
212 | 
213 |             if errno is None:
214 |                 should_loop = False
215 |             elif errno == ssl.SSL_ERROR_WANT_READ:
216 |                 buf = self.socket.recv(SSL_BLOCKSIZE)
217 |                 if buf:
218 |                     self.incoming.write(buf)
219 |                 else:
220 |                     self.incoming.write_eof()
221 |         return ret
```

.venv/lib/python3.13/site-packages/pip/_vendor/urllib3/util/timeout.py
```
1 | from __future__ import absolute_import
2 | 
3 | import time
4 | 
5 | # The default socket timeout, used by httplib to indicate that no timeout was; specified by the user
6 | from socket import _GLOBAL_DEFAULT_TIMEOUT, getdefaulttimeout
7 | 
8 | from ..exceptions import TimeoutStateError
9 | 
10 | # A sentinel value to indicate that no timeout was specified by the user in
11 | # urllib3
12 | _Default = object()
13 | 
14 | 
15 | # Use time.monotonic if available.
16 | current_time = getattr(time, "monotonic", time.time)
17 | 
18 | 
19 | class Timeout(object):
20 |     """Timeout configuration.
21 | 
22 |     Timeouts can be defined as a default for a pool:
23 | 
24 |     .. code-block:: python
25 | 
26 |        timeout = Timeout(connect=2.0, read=7.0)
27 |        http = PoolManager(timeout=timeout)
28 |        response = http.request('GET', 'http://example.com/')
29 | 
30 |     Or per-request (which overrides the default for the pool):
31 | 
32 |     .. code-block:: python
33 | 
34 |        response = http.request('GET', 'http://example.com/', timeout=Timeout(10))
35 | 
36 |     Timeouts can be disabled by setting all the parameters to ``None``:
37 | 
38 |     .. code-block:: python
39 | 
40 |        no_timeout = Timeout(connect=None, read=None)
41 |        response = http.request('GET', 'http://example.com/, timeout=no_timeout)
42 | 
43 | 
44 |     :param total:
45 |         This combines the connect and read timeouts into one; the read timeout
46 |         will be set to the time leftover from the connect attempt. In the
47 |         event that both a connect timeout and a total are specified, or a read
48 |         timeout and a total are specified, the shorter timeout will be applied.
49 | 
50 |         Defaults to None.
51 | 
52 |     :type total: int, float, or None
53 | 
54 |     :param connect:
55 |         The maximum amount of time (in seconds) to wait for a connection
56 |         attempt to a server to succeed. Omitting the parameter will default the
57 |         connect timeout to the system default, probably `the global default
58 |         timeout in socket.py
59 |         <http://hg.python.org/cpython/file/603b4d593758/Lib/socket.py#l535>`_.
60 |         None will set an infinite timeout for connection attempts.
61 | 
62 |     :type connect: int, float, or None
63 | 
64 |     :param read:
65 |         The maximum amount of time (in seconds) to wait between consecutive
66 |         read operations for a response from the server. Omitting the parameter
67 |         will default the read timeout to the system default, probably `the
68 |         global default timeout in socket.py
69 |         <http://hg.python.org/cpython/file/603b4d593758/Lib/socket.py#l535>`_.
70 |         None will set an infinite timeout.
71 | 
72 |     :type read: int, float, or None
73 | 
74 |     .. note::
75 | 
76 |         Many factors can affect the total amount of time for urllib3 to return
77 |         an HTTP response.
78 | 
79 |         For example, Python's DNS resolver does not obey the timeout specified
80 |         on the socket. Other factors that can affect total request time include
81 |         high CPU load, high swap, the program running at a low priority level,
82 |         or other behaviors.
83 | 
84 |         In addition, the read and total timeouts only measure the time between
85 |         read operations on the socket connecting the client and the server,
86 |         not the total amount of time for the request to return a complete
87 |         response. For most requests, the timeout is raised because the server
88 |         has not sent the first byte in the specified time. This is not always
89 |         the case; if a server streams one byte every fifteen seconds, a timeout
90 |         of 20 seconds will not trigger, even though the request will take
91 |         several minutes to complete.
92 | 
93 |         If your goal is to cut off any request after a set amount of wall clock
94 |         time, consider having a second "watcher" thread to cut off a slow
95 |         request.
96 |     """
97 | 
98 |     #: A sentinel object representing the default timeout value
99 |     DEFAULT_TIMEOUT = _GLOBAL_DEFAULT_TIMEOUT
100 | 
101 |     def __init__(self, total=None, connect=_Default, read=_Default):
102 |         self._connect = self._validate_timeout(connect, "connect")
103 |         self._read = self._validate_timeout(read, "read")
104 |         self.total = self._validate_timeout(total, "total")
105 |         self._start_connect = None
106 | 
107 |     def __repr__(self):
108 |         return "%s(connect=%r, read=%r, total=%r)" % (
109 |             type(self).__name__,
110 |             self._connect,
111 |             self._read,
112 |             self.total,
113 |         )
114 | 
115 |     # __str__ provided for backwards compatibility
116 |     __str__ = __repr__
117 | 
118 |     @classmethod
119 |     def resolve_default_timeout(cls, timeout):
120 |         return getdefaulttimeout() if timeout is cls.DEFAULT_TIMEOUT else timeout
121 | 
122 |     @classmethod
123 |     def _validate_timeout(cls, value, name):
124 |         """Check that a timeout attribute is valid.
125 | 
126 |         :param value: The timeout value to validate
127 |         :param name: The name of the timeout attribute to validate. This is
128 |             used to specify in error messages.
129 |         :return: The validated and casted version of the given value.
130 |         :raises ValueError: If it is a numeric value less than or equal to
131 |             zero, or the type is not an integer, float, or None.
132 |         """
133 |         if value is _Default:
134 |             return cls.DEFAULT_TIMEOUT
135 | 
136 |         if value is None or value is cls.DEFAULT_TIMEOUT:
137 |             return value
138 | 
139 |         if isinstance(value, bool):
140 |             raise ValueError(
141 |                 "Timeout cannot be a boolean value. It must "
142 |                 "be an int, float or None."
143 |             )
144 |         try:
145 |             float(value)
146 |         except (TypeError, ValueError):
147 |             raise ValueError(
148 |                 "Timeout value %s was %s, but it must be an "
149 |                 "int, float or None." % (name, value)
150 |             )
151 | 
152 |         try:
153 |             if value <= 0:
154 |                 raise ValueError(
155 |                     "Attempted to set %s timeout to %s, but the "
156 |                     "timeout cannot be set to a value less "
157 |                     "than or equal to 0." % (name, value)
158 |                 )
159 |         except TypeError:
160 |             # Python 3
161 |             raise ValueError(
162 |                 "Timeout value %s was %s, but it must be an "
163 |                 "int, float or None." % (name, value)
164 |             )
165 | 
166 |         return value
167 | 
168 |     @classmethod
169 |     def from_float(cls, timeout):
170 |         """Create a new Timeout from a legacy timeout value.
171 | 
172 |         The timeout value used by httplib.py sets the same timeout on the
173 |         connect(), and recv() socket requests. This creates a :class:`Timeout`
174 |         object that sets the individual timeouts to the ``timeout`` value
175 |         passed to this function.
176 | 
177 |         :param timeout: The legacy timeout value.
178 |         :type timeout: integer, float, sentinel default object, or None
179 |         :return: Timeout object
180 |         :rtype: :class:`Timeout`
181 |         """
182 |         return Timeout(read=timeout, connect=timeout)
183 | 
184 |     def clone(self):
185 |         """Create a copy of the timeout object
186 | 
187 |         Timeout properties are stored per-pool but each request needs a fresh
188 |         Timeout object to ensure each one has its own start/stop configured.
189 | 
190 |         :return: a copy of the timeout object
191 |         :rtype: :class:`Timeout`
192 |         """
193 |         # We can't use copy.deepcopy because that will also create a new object
194 |         # for _GLOBAL_DEFAULT_TIMEOUT, which socket.py uses as a sentinel to
195 |         # detect the user default.
196 |         return Timeout(connect=self._connect, read=self._read, total=self.total)
197 | 
198 |     def start_connect(self):
199 |         """Start the timeout clock, used during a connect() attempt
200 | 
201 |         :raises urllib3.exceptions.TimeoutStateError: if you attempt
202 |             to start a timer that has been started already.
203 |         """
204 |         if self._start_connect is not None:
205 |             raise TimeoutStateError("Timeout timer has already been started.")
206 |         self._start_connect = current_time()
207 |         return self._start_connect
208 | 
209 |     def get_connect_duration(self):
210 |         """Gets the time elapsed since the call to :meth:`start_connect`.
211 | 
212 |         :return: Elapsed time in seconds.
213 |         :rtype: float
214 |         :raises urllib3.exceptions.TimeoutStateError: if you attempt
215 |             to get duration for a timer that hasn't been started.
216 |         """
217 |         if self._start_connect is None:
218 |             raise TimeoutStateError(
219 |                 "Can't get connect duration for timer that has not started."
220 |             )
221 |         return current_time() - self._start_connect
222 | 
223 |     @property
224 |     def connect_timeout(self):
225 |         """Get the value to use when setting a connection timeout.
226 | 
227 |         This will be a positive float or integer, the value None
228 |         (never timeout), or the default system timeout.
229 | 
230 |         :return: Connect timeout.
231 |         :rtype: int, float, :attr:`Timeout.DEFAULT_TIMEOUT` or None
232 |         """
233 |         if self.total is None:
234 |             return self._connect
235 | 
236 |         if self._connect is None or self._connect is self.DEFAULT_TIMEOUT:
237 |             return self.total
238 | 
239 |         return min(self._connect, self.total)
240 | 
241 |     @property
242 |     def read_timeout(self):
243 |         """Get the value for the read timeout.
244 | 
245 |         This assumes some time has elapsed in the connection timeout and
246 |         computes the read timeout appropriately.
247 | 
248 |         If self.total is set, the read timeout is dependent on the amount of
249 |         time taken by the connect timeout. If the connection time has not been
250 |         established, a :exc:`~urllib3.exceptions.TimeoutStateError` will be
251 |         raised.
252 | 
253 |         :return: Value to use for the read timeout.
254 |         :rtype: int, float, :attr:`Timeout.DEFAULT_TIMEOUT` or None
255 |         :raises urllib3.exceptions.TimeoutStateError: If :meth:`start_connect`
256 |             has not yet been called on this object.
257 |         """
258 |         if (
259 |             self.total is not None
260 |             and self.total is not self.DEFAULT_TIMEOUT
261 |             and self._read is not None
262 |             and self._read is not self.DEFAULT_TIMEOUT
263 |         ):
264 |             # In case the connect timeout has not yet been established.
265 |             if self._start_connect is None:
266 |                 return self._read
267 |             return max(0, min(self.total - self.get_connect_duration(), self._read))
268 |         elif self.total is not None and self.total is not self.DEFAULT_TIMEOUT:
269 |             return max(0, self.total - self.get_connect_duration())
270 |         else:
271 |             return self._read
```

.venv/lib/python3.13/site-packages/pip/_vendor/urllib3/util/url.py
```
1 | from __future__ import absolute_import
2 | 
3 | import re
4 | from collections import namedtuple
5 | 
6 | from ..exceptions import LocationParseError
7 | from ..packages import six
8 | 
9 | url_attrs = ["scheme", "auth", "host", "port", "path", "query", "fragment"]
10 | 
11 | # We only want to normalize urls with an HTTP(S) scheme.
12 | # urllib3 infers URLs without a scheme (None) to be http.
13 | NORMALIZABLE_SCHEMES = ("http", "https", None)
14 | 
15 | # Almost all of these patterns were derived from the
16 | # 'rfc3986' module: https://github.com/python-hyper/rfc3986
17 | PERCENT_RE = re.compile(r"%[a-fA-F0-9]{2}")
18 | SCHEME_RE = re.compile(r"^(?:[a-zA-Z][a-zA-Z0-9+-]*:|/)")
19 | URI_RE = re.compile(
20 |     r"^(?:([a-zA-Z][a-zA-Z0-9+.-]*):)?"
21 |     r"(?://([^\\/?#]*))?"
22 |     r"([^?#]*)"
23 |     r"(?:\?([^#]*))?"
24 |     r"(?:#(.*))?$",
25 |     re.UNICODE | re.DOTALL,
26 | )
27 | 
28 | IPV4_PAT = r"(?:[0-9]{1,3}\.){3}[0-9]{1,3}"
29 | HEX_PAT = "[0-9A-Fa-f]{1,4}"
30 | LS32_PAT = "(?:{hex}:{hex}|{ipv4})".format(hex=HEX_PAT, ipv4=IPV4_PAT)
31 | _subs = {"hex": HEX_PAT, "ls32": LS32_PAT}
32 | _variations = [
33 |     #                            6( h16 ":" ) ls32
34 |     "(?:%(hex)s:){6}%(ls32)s",
35 |     #                       "::" 5( h16 ":" ) ls32
36 |     "::(?:%(hex)s:){5}%(ls32)s",
37 |     # [               h16 ] "::" 4( h16 ":" ) ls32
38 |     "(?:%(hex)s)?::(?:%(hex)s:){4}%(ls32)s",
39 |     # [ *1( h16 ":" ) h16 ] "::" 3( h16 ":" ) ls32
40 |     "(?:(?:%(hex)s:)?%(hex)s)?::(?:%(hex)s:){3}%(ls32)s",
41 |     # [ *2( h16 ":" ) h16 ] "::" 2( h16 ":" ) ls32
42 |     "(?:(?:%(hex)s:){0,2}%(hex)s)?::(?:%(hex)s:){2}%(ls32)s",
43 |     # [ *3( h16 ":" ) h16 ] "::"    h16 ":"   ls32
44 |     "(?:(?:%(hex)s:){0,3}%(hex)s)?::%(hex)s:%(ls32)s",
45 |     # [ *4( h16 ":" ) h16 ] "::"              ls32
46 |     "(?:(?:%(hex)s:){0,4}%(hex)s)?::%(ls32)s",
47 |     # [ *5( h16 ":" ) h16 ] "::"              h16
48 |     "(?:(?:%(hex)s:){0,5}%(hex)s)?::%(hex)s",
49 |     # [ *6( h16 ":" ) h16 ] "::"
50 |     "(?:(?:%(hex)s:){0,6}%(hex)s)?::",
51 | ]
52 | 
53 | UNRESERVED_PAT = r"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789._\-~"
54 | IPV6_PAT = "(?:" + "|".join([x % _subs for x in _variations]) + ")"
55 | ZONE_ID_PAT = "(?:%25|%)(?:[" + UNRESERVED_PAT + "]|%[a-fA-F0-9]{2})+"
56 | IPV6_ADDRZ_PAT = r"\[" + IPV6_PAT + r"(?:" + ZONE_ID_PAT + r")?\]"
57 | REG_NAME_PAT = r"(?:[^\[\]%:/?#]|%[a-fA-F0-9]{2})*"
58 | TARGET_RE = re.compile(r"^(/[^?#]*)(?:\?([^#]*))?(?:#.*)?$")
59 | 
60 | IPV4_RE = re.compile("^" + IPV4_PAT + "$")
61 | IPV6_RE = re.compile("^" + IPV6_PAT + "$")
62 | IPV6_ADDRZ_RE = re.compile("^" + IPV6_ADDRZ_PAT + "$")
63 | BRACELESS_IPV6_ADDRZ_RE = re.compile("^" + IPV6_ADDRZ_PAT[2:-2] + "$")
64 | ZONE_ID_RE = re.compile("(" + ZONE_ID_PAT + r")\]$")
65 | 
66 | _HOST_PORT_PAT = ("^(%s|%s|%s)(?::0*?(|0|[1-9][0-9]{0,4}))?$") % (
67 |     REG_NAME_PAT,
68 |     IPV4_PAT,
69 |     IPV6_ADDRZ_PAT,
70 | )
71 | _HOST_PORT_RE = re.compile(_HOST_PORT_PAT, re.UNICODE | re.DOTALL)
72 | 
73 | UNRESERVED_CHARS = set(
74 |     "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789._-~"
75 | )
76 | SUB_DELIM_CHARS = set("!$&'()*+,;=")
77 | USERINFO_CHARS = UNRESERVED_CHARS | SUB_DELIM_CHARS | {":"}
78 | PATH_CHARS = USERINFO_CHARS | {"@", "/"}
79 | QUERY_CHARS = FRAGMENT_CHARS = PATH_CHARS | {"?"}
80 | 
81 | 
82 | class Url(namedtuple("Url", url_attrs)):
83 |     """
84 |     Data structure for representing an HTTP URL. Used as a return value for
85 |     :func:`parse_url`. Both the scheme and host are normalized as they are
86 |     both case-insensitive according to RFC 3986.
87 |     """
88 | 
89 |     __slots__ = ()
90 | 
91 |     def __new__(
92 |         cls,
93 |         scheme=None,
94 |         auth=None,
95 |         host=None,
96 |         port=None,
97 |         path=None,
98 |         query=None,
99 |         fragment=None,
100 |     ):
101 |         if path and not path.startswith("/"):
102 |             path = "/" + path
103 |         if scheme is not None:
104 |             scheme = scheme.lower()
105 |         return super(Url, cls).__new__(
106 |             cls, scheme, auth, host, port, path, query, fragment
107 |         )
108 | 
109 |     @property
110 |     def hostname(self):
111 |         """For backwards-compatibility with urlparse. We're nice like that."""
112 |         return self.host
113 | 
114 |     @property
115 |     def request_uri(self):
116 |         """Absolute path including the query string."""
117 |         uri = self.path or "/"
118 | 
119 |         if self.query is not None:
120 |             uri += "?" + self.query
121 | 
122 |         return uri
123 | 
124 |     @property
125 |     def netloc(self):
126 |         """Network location including host and port"""
127 |         if self.port:
128 |             return "%s:%d" % (self.host, self.port)
129 |         return self.host
130 | 
131 |     @property
132 |     def url(self):
133 |         """
134 |         Convert self into a url
135 | 
136 |         This function should more or less round-trip with :func:`.parse_url`. The
137 |         returned url may not be exactly the same as the url inputted to
138 |         :func:`.parse_url`, but it should be equivalent by the RFC (e.g., urls
139 |         with a blank port will have : removed).
140 | 
141 |         Example: ::
142 | 
143 |             >>> U = parse_url('http://google.com/mail/')
144 |             >>> U.url
145 |             'http://google.com/mail/'
146 |             >>> Url('http', 'username:password', 'host.com', 80,
147 |             ... '/path', 'query', 'fragment').url
148 |             'http://username:password@host.com:80/path?query#fragment'
149 |         """
150 |         scheme, auth, host, port, path, query, fragment = self
151 |         url = u""
152 | 
153 |         # We use "is not None" we want things to happen with empty strings (or 0 port)
154 |         if scheme is not None:
155 |             url += scheme + u"://"
156 |         if auth is not None:
157 |             url += auth + u"@"
158 |         if host is not None:
159 |             url += host
160 |         if port is not None:
161 |             url += u":" + str(port)
162 |         if path is not None:
163 |             url += path
164 |         if query is not None:
165 |             url += u"?" + query
166 |         if fragment is not None:
167 |             url += u"#" + fragment
168 | 
169 |         return url
170 | 
171 |     def __str__(self):
172 |         return self.url
173 | 
174 | 
175 | def split_first(s, delims):
176 |     """
177 |     .. deprecated:: 1.25
178 | 
179 |     Given a string and an iterable of delimiters, split on the first found
180 |     delimiter. Return two split parts and the matched delimiter.
181 | 
182 |     If not found, then the first part is the full input string.
183 | 
184 |     Example::
185 | 
186 |         >>> split_first('foo/bar?baz', '?/=')
187 |         ('foo', 'bar?baz', '/')
188 |         >>> split_first('foo/bar?baz', '123')
189 |         ('foo/bar?baz', '', None)
190 | 
191 |     Scales linearly with number of delims. Not ideal for large number of delims.
192 |     """
193 |     min_idx = None
194 |     min_delim = None
195 |     for d in delims:
196 |         idx = s.find(d)
197 |         if idx < 0:
198 |             continue
199 | 
200 |         if min_idx is None or idx < min_idx:
201 |             min_idx = idx
202 |             min_delim = d
203 | 
204 |     if min_idx is None or min_idx < 0:
205 |         return s, "", None
206 | 
207 |     return s[:min_idx], s[min_idx + 1 :], min_delim
208 | 
209 | 
210 | def _encode_invalid_chars(component, allowed_chars, encoding="utf-8"):
211 |     """Percent-encodes a URI component without reapplying
212 |     onto an already percent-encoded component.
213 |     """
214 |     if component is None:
215 |         return component
216 | 
217 |     component = six.ensure_text(component)
218 | 
219 |     # Normalize existing percent-encoded bytes.
220 |     # Try to see if the component we're encoding is already percent-encoded
221 |     # so we can skip all '%' characters but still encode all others.
222 |     component, percent_encodings = PERCENT_RE.subn(
223 |         lambda match: match.group(0).upper(), component
224 |     )
225 | 
226 |     uri_bytes = component.encode("utf-8", "surrogatepass")
227 |     is_percent_encoded = percent_encodings == uri_bytes.count(b"%")
228 |     encoded_component = bytearray()
229 | 
230 |     for i in range(0, len(uri_bytes)):
231 |         # Will return a single character bytestring on both Python 2 & 3
232 |         byte = uri_bytes[i : i + 1]
233 |         byte_ord = ord(byte)
234 |         if (is_percent_encoded and byte == b"%") or (
235 |             byte_ord < 128 and byte.decode() in allowed_chars
236 |         ):
237 |             encoded_component += byte
238 |             continue
239 |         encoded_component.extend(b"%" + (hex(byte_ord)[2:].encode().zfill(2).upper()))
240 | 
241 |     return encoded_component.decode(encoding)
242 | 
243 | 
244 | def _remove_path_dot_segments(path):
245 |     # See http://tools.ietf.org/html/rfc3986#section-5.2.4 for pseudo-code
246 |     segments = path.split("/")  # Turn the path into a list of segments
247 |     output = []  # Initialize the variable to use to store output
248 | 
249 |     for segment in segments:
250 |         # '.' is the current directory, so ignore it, it is superfluous
251 |         if segment == ".":
252 |             continue
253 |         # Anything other than '..', should be appended to the output
254 |         elif segment != "..":
255 |             output.append(segment)
256 |         # In this case segment == '..', if we can, we should pop the last
257 |         # element
258 |         elif output:
259 |             output.pop()
260 | 
261 |     # If the path starts with '/' and the output is empty or the first string
262 |     # is non-empty
263 |     if path.startswith("/") and (not output or output[0]):
264 |         output.insert(0, "")
265 | 
266 |     # If the path starts with '/.' or '/..' ensure we add one more empty
267 |     # string to add a trailing '/'
268 |     if path.endswith(("/.", "/..")):
269 |         output.append("")
270 | 
271 |     return "/".join(output)
272 | 
273 | 
274 | def _normalize_host(host, scheme):
275 |     if host:
276 |         if isinstance(host, six.binary_type):
277 |             host = six.ensure_str(host)
278 | 
279 |         if scheme in NORMALIZABLE_SCHEMES:
280 |             is_ipv6 = IPV6_ADDRZ_RE.match(host)
281 |             if is_ipv6:
282 |                 # IPv6 hosts of the form 'a::b%zone' are encoded in a URL as
283 |                 # such per RFC 6874: 'a::b%25zone'. Unquote the ZoneID
284 |                 # separator as necessary to return a valid RFC 4007 scoped IP.
285 |                 match = ZONE_ID_RE.search(host)
286 |                 if match:
287 |                     start, end = match.span(1)
288 |                     zone_id = host[start:end]
289 | 
290 |                     if zone_id.startswith("%25") and zone_id != "%25":
291 |                         zone_id = zone_id[3:]
292 |                     else:
293 |                         zone_id = zone_id[1:]
294 |                     zone_id = "%" + _encode_invalid_chars(zone_id, UNRESERVED_CHARS)
295 |                     return host[:start].lower() + zone_id + host[end:]
296 |                 else:
297 |                     return host.lower()
298 |             elif not IPV4_RE.match(host):
299 |                 return six.ensure_str(
300 |                     b".".join([_idna_encode(label) for label in host.split(".")])
301 |                 )
302 |     return host
303 | 
304 | 
305 | def _idna_encode(name):
306 |     if name and any(ord(x) >= 128 for x in name):
307 |         try:
308 |             from pip._vendor import idna
309 |         except ImportError:
310 |             six.raise_from(
311 |                 LocationParseError("Unable to parse URL without the 'idna' module"),
312 |                 None,
313 |             )
314 |         try:
315 |             return idna.encode(name.lower(), strict=True, std3_rules=True)
316 |         except idna.IDNAError:
317 |             six.raise_from(
318 |                 LocationParseError(u"Name '%s' is not a valid IDNA label" % name), None
319 |             )
320 |     return name.lower().encode("ascii")
321 | 
322 | 
323 | def _encode_target(target):
324 |     """Percent-encodes a request target so that there are no invalid characters"""
325 |     path, query = TARGET_RE.match(target).groups()
326 |     target = _encode_invalid_chars(path, PATH_CHARS)
327 |     query = _encode_invalid_chars(query, QUERY_CHARS)
328 |     if query is not None:
329 |         target += "?" + query
[TRUNCATED]
```

.venv/lib/python3.13/site-packages/pip/_vendor/urllib3/util/wait.py
```
1 | import errno
2 | import select
3 | import sys
4 | from functools import partial
5 | 
6 | try:
7 |     from time import monotonic
8 | except ImportError:
9 |     from time import time as monotonic
10 | 
11 | __all__ = ["NoWayToWaitForSocketError", "wait_for_read", "wait_for_write"]
12 | 
13 | 
14 | class NoWayToWaitForSocketError(Exception):
15 |     pass
16 | 
17 | 
18 | # How should we wait on sockets?
19 | #
20 | # There are two types of APIs you can use for waiting on sockets: the fancy
21 | # modern stateful APIs like epoll/kqueue, and the older stateless APIs like
22 | # select/poll. The stateful APIs are more efficient when you have a lots of
23 | # sockets to keep track of, because you can set them up once and then use them
24 | # lots of times. But we only ever want to wait on a single socket at a time
25 | # and don't want to keep track of state, so the stateless APIs are actually
26 | # more efficient. So we want to use select() or poll().
27 | #
28 | # Now, how do we choose between select() and poll()? On traditional Unixes,
29 | # select() has a strange calling convention that makes it slow, or fail
30 | # altogether, for high-numbered file descriptors. The point of poll() is to fix
31 | # that, so on Unixes, we prefer poll().
32 | #
33 | # On Windows, there is no poll() (or at least Python doesn't provide a wrapper
34 | # for it), but that's OK, because on Windows, select() doesn't have this
35 | # strange calling convention; plain select() works fine.
36 | #
37 | # So: on Windows we use select(), and everywhere else we use poll(). We also
38 | # fall back to select() in case poll() is somehow broken or missing.
39 | 
40 | if sys.version_info >= (3, 5):
41 |     # Modern Python, that retries syscalls by default
42 |     def _retry_on_intr(fn, timeout):
43 |         return fn(timeout)
44 | 
45 | else:
46 |     # Old and broken Pythons.
47 |     def _retry_on_intr(fn, timeout):
48 |         if timeout is None:
49 |             deadline = float("inf")
50 |         else:
51 |             deadline = monotonic() + timeout
52 | 
53 |         while True:
54 |             try:
55 |                 return fn(timeout)
56 |             # OSError for 3 <= pyver < 3.5, select.error for pyver <= 2.7
57 |             except (OSError, select.error) as e:
58 |                 # 'e.args[0]' incantation works for both OSError and select.error
59 |                 if e.args[0] != errno.EINTR:
60 |                     raise
61 |                 else:
62 |                     timeout = deadline - monotonic()
63 |                     if timeout < 0:
64 |                         timeout = 0
65 |                     if timeout == float("inf"):
66 |                         timeout = None
67 |                     continue
68 | 
69 | 
70 | def select_wait_for_socket(sock, read=False, write=False, timeout=None):
71 |     if not read and not write:
72 |         raise RuntimeError("must specify at least one of read=True, write=True")
73 |     rcheck = []
74 |     wcheck = []
75 |     if read:
76 |         rcheck.append(sock)
77 |     if write:
78 |         wcheck.append(sock)
79 |     # When doing a non-blocking connect, most systems signal success by
80 |     # marking the socket writable. Windows, though, signals success by marked
81 |     # it as "exceptional". We paper over the difference by checking the write
82 |     # sockets for both conditions. (The stdlib selectors module does the same
83 |     # thing.)
84 |     fn = partial(select.select, rcheck, wcheck, wcheck)
85 |     rready, wready, xready = _retry_on_intr(fn, timeout)
86 |     return bool(rready or wready or xready)
87 | 
88 | 
89 | def poll_wait_for_socket(sock, read=False, write=False, timeout=None):
90 |     if not read and not write:
91 |         raise RuntimeError("must specify at least one of read=True, write=True")
92 |     mask = 0
93 |     if read:
94 |         mask |= select.POLLIN
95 |     if write:
96 |         mask |= select.POLLOUT
97 |     poll_obj = select.poll()
98 |     poll_obj.register(sock, mask)
99 | 
100 |     # For some reason, poll() takes timeout in milliseconds
101 |     def do_poll(t):
102 |         if t is not None:
103 |             t *= 1000
104 |         return poll_obj.poll(t)
105 | 
106 |     return bool(_retry_on_intr(do_poll, timeout))
107 | 
108 | 
109 | def null_wait_for_socket(*args, **kwargs):
110 |     raise NoWayToWaitForSocketError("no select-equivalent available")
111 | 
112 | 
113 | def _have_working_poll():
114 |     # Apparently some systems have a select.poll that fails as soon as you try
115 |     # to use it, either due to strange configuration or broken monkeypatching
116 |     # from libraries like eventlet/greenlet.
117 |     try:
118 |         poll_obj = select.poll()
119 |         _retry_on_intr(poll_obj.poll, 0)
120 |     except (AttributeError, OSError):
121 |         return False
122 |     else:
123 |         return True
124 | 
125 | 
126 | def wait_for_socket(*args, **kwargs):
127 |     # We delay choosing which implementation to use until the first time we're
128 |     # called. We could do it at import time, but then we might make the wrong
129 |     # decision if someone goes wild with monkeypatching select.poll after
130 |     # we're imported.
131 |     global wait_for_socket
132 |     if _have_working_poll():
133 |         wait_for_socket = poll_wait_for_socket
134 |     elif hasattr(select, "select"):
135 |         wait_for_socket = select_wait_for_socket
136 |     else:  # Platform-specific: Appengine.
137 |         wait_for_socket = null_wait_for_socket
138 |     return wait_for_socket(*args, **kwargs)
139 | 
140 | 
141 | def wait_for_read(sock, timeout=None):
142 |     """Waits for reading to be available on a given socket.
143 |     Returns True if the socket is readable, or False if the timeout expired.
144 |     """
145 |     return wait_for_socket(sock, read=True, timeout=timeout)
146 | 
147 | 
148 | def wait_for_write(sock, timeout=None):
149 |     """Waits for writing to be available on a given socket.
150 |     Returns True if the socket is readable, or False if the timeout expired.
151 |     """
152 |     return wait_for_socket(sock, write=True, timeout=timeout)
```

.venv/lib/python3.13/site-packages/pip/_vendor/urllib3/contrib/_securetransport/__init__.py
```
```

.venv/lib/python3.13/site-packages/pip/_vendor/urllib3/contrib/_securetransport/bindings.py
```
1 | """
2 | This module uses ctypes to bind a whole bunch of functions and constants from
3 | SecureTransport. The goal here is to provide the low-level API to
4 | SecureTransport. These are essentially the C-level functions and constants, and
5 | they're pretty gross to work with.
6 | 
7 | This code is a bastardised version of the code found in Will Bond's oscrypto
8 | library. An enormous debt is owed to him for blazing this trail for us. For
9 | that reason, this code should be considered to be covered both by urllib3's
10 | license and by oscrypto's:
11 | 
12 |     Copyright (c) 2015-2016 Will Bond <will@wbond.net>
13 | 
14 |     Permission is hereby granted, free of charge, to any person obtaining a
15 |     copy of this software and associated documentation files (the "Software"),
16 |     to deal in the Software without restriction, including without limitation
17 |     the rights to use, copy, modify, merge, publish, distribute, sublicense,
18 |     and/or sell copies of the Software, and to permit persons to whom the
19 |     Software is furnished to do so, subject to the following conditions:
20 | 
21 |     The above copyright notice and this permission notice shall be included in
22 |     all copies or substantial portions of the Software.
23 | 
24 |     THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
25 |     IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
26 |     FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
27 |     AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
28 |     LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
29 |     FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
30 |     DEALINGS IN THE SOFTWARE.
31 | """
32 | from __future__ import absolute_import
33 | 
34 | import platform
35 | from ctypes import (
36 |     CDLL,
37 |     CFUNCTYPE,
38 |     POINTER,
39 |     c_bool,
40 |     c_byte,
41 |     c_char_p,
42 |     c_int32,
43 |     c_long,
44 |     c_size_t,
45 |     c_uint32,
46 |     c_ulong,
47 |     c_void_p,
48 | )
49 | from ctypes.util import find_library
50 | 
51 | from ...packages.six import raise_from
52 | 
53 | if platform.system() != "Darwin":
54 |     raise ImportError("Only macOS is supported")
55 | 
56 | version = platform.mac_ver()[0]
57 | version_info = tuple(map(int, version.split(".")))
58 | if version_info < (10, 8):
59 |     raise OSError(
60 |         "Only OS X 10.8 and newer are supported, not %s.%s"
61 |         % (version_info[0], version_info[1])
62 |     )
63 | 
64 | 
65 | def load_cdll(name, macos10_16_path):
66 |     """Loads a CDLL by name, falling back to known path on 10.16+"""
67 |     try:
68 |         # Big Sur is technically 11 but we use 10.16 due to the Big Sur
69 |         # beta being labeled as 10.16.
70 |         if version_info >= (10, 16):
71 |             path = macos10_16_path
72 |         else:
73 |             path = find_library(name)
74 |         if not path:
75 |             raise OSError  # Caught and reraised as 'ImportError'
76 |         return CDLL(path, use_errno=True)
77 |     except OSError:
78 |         raise_from(ImportError("The library %s failed to load" % name), None)
79 | 
80 | 
81 | Security = load_cdll(
82 |     "Security", "/System/Library/Frameworks/Security.framework/Security"
83 | )
84 | CoreFoundation = load_cdll(
85 |     "CoreFoundation",
86 |     "/System/Library/Frameworks/CoreFoundation.framework/CoreFoundation",
87 | )
88 | 
89 | 
90 | Boolean = c_bool
91 | CFIndex = c_long
92 | CFStringEncoding = c_uint32
93 | CFData = c_void_p
94 | CFString = c_void_p
95 | CFArray = c_void_p
96 | CFMutableArray = c_void_p
97 | CFDictionary = c_void_p
98 | CFError = c_void_p
99 | CFType = c_void_p
100 | CFTypeID = c_ulong
101 | 
102 | CFTypeRef = POINTER(CFType)
103 | CFAllocatorRef = c_void_p
104 | 
105 | OSStatus = c_int32
106 | 
107 | CFDataRef = POINTER(CFData)
108 | CFStringRef = POINTER(CFString)
109 | CFArrayRef = POINTER(CFArray)
110 | CFMutableArrayRef = POINTER(CFMutableArray)
111 | CFDictionaryRef = POINTER(CFDictionary)
112 | CFArrayCallBacks = c_void_p
113 | CFDictionaryKeyCallBacks = c_void_p
114 | CFDictionaryValueCallBacks = c_void_p
115 | 
116 | SecCertificateRef = POINTER(c_void_p)
117 | SecExternalFormat = c_uint32
118 | SecExternalItemType = c_uint32
119 | SecIdentityRef = POINTER(c_void_p)
120 | SecItemImportExportFlags = c_uint32
121 | SecItemImportExportKeyParameters = c_void_p
122 | SecKeychainRef = POINTER(c_void_p)
123 | SSLProtocol = c_uint32
124 | SSLCipherSuite = c_uint32
125 | SSLContextRef = POINTER(c_void_p)
126 | SecTrustRef = POINTER(c_void_p)
127 | SSLConnectionRef = c_uint32
128 | SecTrustResultType = c_uint32
129 | SecTrustOptionFlags = c_uint32
130 | SSLProtocolSide = c_uint32
131 | SSLConnectionType = c_uint32
132 | SSLSessionOption = c_uint32
133 | 
134 | 
135 | try:
136 |     Security.SecItemImport.argtypes = [
137 |         CFDataRef,
138 |         CFStringRef,
139 |         POINTER(SecExternalFormat),
140 |         POINTER(SecExternalItemType),
141 |         SecItemImportExportFlags,
142 |         POINTER(SecItemImportExportKeyParameters),
143 |         SecKeychainRef,
144 |         POINTER(CFArrayRef),
145 |     ]
146 |     Security.SecItemImport.restype = OSStatus
147 | 
148 |     Security.SecCertificateGetTypeID.argtypes = []
149 |     Security.SecCertificateGetTypeID.restype = CFTypeID
150 | 
151 |     Security.SecIdentityGetTypeID.argtypes = []
152 |     Security.SecIdentityGetTypeID.restype = CFTypeID
153 | 
154 |     Security.SecKeyGetTypeID.argtypes = []
155 |     Security.SecKeyGetTypeID.restype = CFTypeID
156 | 
157 |     Security.SecCertificateCreateWithData.argtypes = [CFAllocatorRef, CFDataRef]
158 |     Security.SecCertificateCreateWithData.restype = SecCertificateRef
159 | 
160 |     Security.SecCertificateCopyData.argtypes = [SecCertificateRef]
161 |     Security.SecCertificateCopyData.restype = CFDataRef
162 | 
163 |     Security.SecCopyErrorMessageString.argtypes = [OSStatus, c_void_p]
164 |     Security.SecCopyErrorMessageString.restype = CFStringRef
165 | 
166 |     Security.SecIdentityCreateWithCertificate.argtypes = [
167 |         CFTypeRef,
168 |         SecCertificateRef,
169 |         POINTER(SecIdentityRef),
170 |     ]
171 |     Security.SecIdentityCreateWithCertificate.restype = OSStatus
172 | 
173 |     Security.SecKeychainCreate.argtypes = [
174 |         c_char_p,
175 |         c_uint32,
176 |         c_void_p,
177 |         Boolean,
178 |         c_void_p,
179 |         POINTER(SecKeychainRef),
180 |     ]
181 |     Security.SecKeychainCreate.restype = OSStatus
182 | 
183 |     Security.SecKeychainDelete.argtypes = [SecKeychainRef]
184 |     Security.SecKeychainDelete.restype = OSStatus
185 | 
186 |     Security.SecPKCS12Import.argtypes = [
187 |         CFDataRef,
188 |         CFDictionaryRef,
189 |         POINTER(CFArrayRef),
190 |     ]
191 |     Security.SecPKCS12Import.restype = OSStatus
192 | 
193 |     SSLReadFunc = CFUNCTYPE(OSStatus, SSLConnectionRef, c_void_p, POINTER(c_size_t))
194 |     SSLWriteFunc = CFUNCTYPE(
195 |         OSStatus, SSLConnectionRef, POINTER(c_byte), POINTER(c_size_t)
196 |     )
197 | 
198 |     Security.SSLSetIOFuncs.argtypes = [SSLContextRef, SSLReadFunc, SSLWriteFunc]
199 |     Security.SSLSetIOFuncs.restype = OSStatus
200 | 
201 |     Security.SSLSetPeerID.argtypes = [SSLContextRef, c_char_p, c_size_t]
202 |     Security.SSLSetPeerID.restype = OSStatus
203 | 
204 |     Security.SSLSetCertificate.argtypes = [SSLContextRef, CFArrayRef]
205 |     Security.SSLSetCertificate.restype = OSStatus
206 | 
207 |     Security.SSLSetCertificateAuthorities.argtypes = [SSLContextRef, CFTypeRef, Boolean]
208 |     Security.SSLSetCertificateAuthorities.restype = OSStatus
209 | 
210 |     Security.SSLSetConnection.argtypes = [SSLContextRef, SSLConnectionRef]
211 |     Security.SSLSetConnection.restype = OSStatus
212 | 
213 |     Security.SSLSetPeerDomainName.argtypes = [SSLContextRef, c_char_p, c_size_t]
214 |     Security.SSLSetPeerDomainName.restype = OSStatus
215 | 
216 |     Security.SSLHandshake.argtypes = [SSLContextRef]
217 |     Security.SSLHandshake.restype = OSStatus
218 | 
219 |     Security.SSLRead.argtypes = [SSLContextRef, c_char_p, c_size_t, POINTER(c_size_t)]
220 |     Security.SSLRead.restype = OSStatus
221 | 
222 |     Security.SSLWrite.argtypes = [SSLContextRef, c_char_p, c_size_t, POINTER(c_size_t)]
223 |     Security.SSLWrite.restype = OSStatus
224 | 
225 |     Security.SSLClose.argtypes = [SSLContextRef]
226 |     Security.SSLClose.restype = OSStatus
227 | 
228 |     Security.SSLGetNumberSupportedCiphers.argtypes = [SSLContextRef, POINTER(c_size_t)]
229 |     Security.SSLGetNumberSupportedCiphers.restype = OSStatus
230 | 
231 |     Security.SSLGetSupportedCiphers.argtypes = [
232 |         SSLContextRef,
233 |         POINTER(SSLCipherSuite),
234 |         POINTER(c_size_t),
235 |     ]
236 |     Security.SSLGetSupportedCiphers.restype = OSStatus
237 | 
238 |     Security.SSLSetEnabledCiphers.argtypes = [
239 |         SSLContextRef,
240 |         POINTER(SSLCipherSuite),
241 |         c_size_t,
242 |     ]
243 |     Security.SSLSetEnabledCiphers.restype = OSStatus
244 | 
245 |     Security.SSLGetNumberEnabledCiphers.argtype = [SSLContextRef, POINTER(c_size_t)]
246 |     Security.SSLGetNumberEnabledCiphers.restype = OSStatus
247 | 
248 |     Security.SSLGetEnabledCiphers.argtypes = [
249 |         SSLContextRef,
250 |         POINTER(SSLCipherSuite),
251 |         POINTER(c_size_t),
252 |     ]
253 |     Security.SSLGetEnabledCiphers.restype = OSStatus
254 | 
255 |     Security.SSLGetNegotiatedCipher.argtypes = [SSLContextRef, POINTER(SSLCipherSuite)]
256 |     Security.SSLGetNegotiatedCipher.restype = OSStatus
257 | 
258 |     Security.SSLGetNegotiatedProtocolVersion.argtypes = [
259 |         SSLContextRef,
260 |         POINTER(SSLProtocol),
261 |     ]
262 |     Security.SSLGetNegotiatedProtocolVersion.restype = OSStatus
263 | 
264 |     Security.SSLCopyPeerTrust.argtypes = [SSLContextRef, POINTER(SecTrustRef)]
265 |     Security.SSLCopyPeerTrust.restype = OSStatus
266 | 
267 |     Security.SecTrustSetAnchorCertificates.argtypes = [SecTrustRef, CFArrayRef]
268 |     Security.SecTrustSetAnchorCertificates.restype = OSStatus
269 | 
270 |     Security.SecTrustSetAnchorCertificatesOnly.argstypes = [SecTrustRef, Boolean]
271 |     Security.SecTrustSetAnchorCertificatesOnly.restype = OSStatus
272 | 
273 |     Security.SecTrustEvaluate.argtypes = [SecTrustRef, POINTER(SecTrustResultType)]
274 |     Security.SecTrustEvaluate.restype = OSStatus
275 | 
276 |     Security.SecTrustGetCertificateCount.argtypes = [SecTrustRef]
277 |     Security.SecTrustGetCertificateCount.restype = CFIndex
278 | 
279 |     Security.SecTrustGetCertificateAtIndex.argtypes = [SecTrustRef, CFIndex]
280 |     Security.SecTrustGetCertificateAtIndex.restype = SecCertificateRef
281 | 
282 |     Security.SSLCreateContext.argtypes = [
283 |         CFAllocatorRef,
284 |         SSLProtocolSide,
285 |         SSLConnectionType,
286 |     ]
287 |     Security.SSLCreateContext.restype = SSLContextRef
288 | 
289 |     Security.SSLSetSessionOption.argtypes = [SSLContextRef, SSLSessionOption, Boolean]
290 |     Security.SSLSetSessionOption.restype = OSStatus
291 | 
292 |     Security.SSLSetProtocolVersionMin.argtypes = [SSLContextRef, SSLProtocol]
293 |     Security.SSLSetProtocolVersionMin.restype = OSStatus
294 | 
295 |     Security.SSLSetProtocolVersionMax.argtypes = [SSLContextRef, SSLProtocol]
296 |     Security.SSLSetProtocolVersionMax.restype = OSStatus
297 | 
298 |     try:
299 |         Security.SSLSetALPNProtocols.argtypes = [SSLContextRef, CFArrayRef]
300 |         Security.SSLSetALPNProtocols.restype = OSStatus
301 |     except AttributeError:
302 |         # Supported only in 10.12+
303 |         pass
304 | 
305 |     Security.SecCopyErrorMessageString.argtypes = [OSStatus, c_void_p]
306 |     Security.SecCopyErrorMessageString.restype = CFStringRef
307 | 
308 |     Security.SSLReadFunc = SSLReadFunc
309 |     Security.SSLWriteFunc = SSLWriteFunc
310 |     Security.SSLContextRef = SSLContextRef
311 |     Security.SSLProtocol = SSLProtocol
312 |     Security.SSLCipherSuite = SSLCipherSuite
313 |     Security.SecIdentityRef = SecIdentityRef
314 |     Security.SecKeychainRef = SecKeychainRef
315 |     Security.SecTrustRef = SecTrustRef
316 |     Security.SecTrustResultType = SecTrustResultType
317 |     Security.SecExternalFormat = SecExternalFormat
318 |     Security.OSStatus = OSStatus
319 | 
320 |     Security.kSecImportExportPassphrase = CFStringRef.in_dll(
321 |         Security, "kSecImportExportPassphrase"
322 |     )
323 |     Security.kSecImportItemIdentity = CFStringRef.in_dll(
324 |         Security, "kSecImportItemIdentity"
325 |     )
326 | 
327 |     # CoreFoundation time!
328 |     CoreFoundation.CFRetain.argtypes = [CFTypeRef]
329 |     CoreFoundation.CFRetain.restype = CFTypeRef
330 | 
331 |     CoreFoundation.CFRelease.argtypes = [CFTypeRef]
332 |     CoreFoundation.CFRelease.restype = None
333 | 
334 |     CoreFoundation.CFGetTypeID.argtypes = [CFTypeRef]
335 |     CoreFoundation.CFGetTypeID.restype = CFTypeID
336 | 
337 |     CoreFoundation.CFStringCreateWithCString.argtypes = [
338 |         CFAllocatorRef,
339 |         c_char_p,
340 |         CFStringEncoding,
341 |     ]
342 |     CoreFoundation.CFStringCreateWithCString.restype = CFStringRef
343 | 
344 |     CoreFoundation.CFStringGetCStringPtr.argtypes = [CFStringRef, CFStringEncoding]
345 |     CoreFoundation.CFStringGetCStringPtr.restype = c_char_p
346 | 
347 |     CoreFoundation.CFStringGetCString.argtypes = [
348 |         CFStringRef,
349 |         c_char_p,
350 |         CFIndex,
351 |         CFStringEncoding,
352 |     ]
353 |     CoreFoundation.CFStringGetCString.restype = c_bool
354 | 
355 |     CoreFoundation.CFDataCreate.argtypes = [CFAllocatorRef, c_char_p, CFIndex]
356 |     CoreFoundation.CFDataCreate.restype = CFDataRef
357 | 
358 |     CoreFoundation.CFDataGetLength.argtypes = [CFDataRef]
359 |     CoreFoundation.CFDataGetLength.restype = CFIndex
360 | 
361 |     CoreFoundation.CFDataGetBytePtr.argtypes = [CFDataRef]
362 |     CoreFoundation.CFDataGetBytePtr.restype = c_void_p
363 | 
364 |     CoreFoundation.CFDictionaryCreate.argtypes = [
365 |         CFAllocatorRef,
366 |         POINTER(CFTypeRef),
367 |         POINTER(CFTypeRef),
368 |         CFIndex,
369 |         CFDictionaryKeyCallBacks,
370 |         CFDictionaryValueCallBacks,
371 |     ]
372 |     CoreFoundation.CFDictionaryCreate.restype = CFDictionaryRef
373 | 
374 |     CoreFoundation.CFDictionaryGetValue.argtypes = [CFDictionaryRef, CFTypeRef]
375 |     CoreFoundation.CFDictionaryGetValue.restype = CFTypeRef
376 | 
377 |     CoreFoundation.CFArrayCreate.argtypes = [
378 |         CFAllocatorRef,
379 |         POINTER(CFTypeRef),
380 |         CFIndex,
381 |         CFArrayCallBacks,
382 |     ]
383 |     CoreFoundation.CFArrayCreate.restype = CFArrayRef
384 | 
385 |     CoreFoundation.CFArrayCreateMutable.argtypes = [
386 |         CFAllocatorRef,
387 |         CFIndex,
388 |         CFArrayCallBacks,
389 |     ]
390 |     CoreFoundation.CFArrayCreateMutable.restype = CFMutableArrayRef
391 | 
392 |     CoreFoundation.CFArrayAppendValue.argtypes = [CFMutableArrayRef, c_void_p]
393 |     CoreFoundation.CFArrayAppendValue.restype = None
394 | 
395 |     CoreFoundation.CFArrayGetCount.argtypes = [CFArrayRef]
396 |     CoreFoundation.CFArrayGetCount.restype = CFIndex
397 | 
[TRUNCATED]
```

.venv/lib/python3.13/site-packages/pip/_vendor/urllib3/contrib/_securetransport/low_level.py
```
1 | """
2 | Low-level helpers for the SecureTransport bindings.
3 | 
4 | These are Python functions that are not directly related to the high-level APIs
5 | but are necessary to get them to work. They include a whole bunch of low-level
6 | CoreFoundation messing about and memory management. The concerns in this module
7 | are almost entirely about trying to avoid memory leaks and providing
8 | appropriate and useful assistance to the higher-level code.
9 | """
10 | import base64
11 | import ctypes
12 | import itertools
13 | import os
14 | import re
15 | import ssl
16 | import struct
17 | import tempfile
18 | 
19 | from .bindings import CFConst, CoreFoundation, Security
20 | 
21 | # This regular expression is used to grab PEM data out of a PEM bundle.
22 | _PEM_CERTS_RE = re.compile(
23 |     b"-----BEGIN CERTIFICATE-----\n(.*?)\n-----END CERTIFICATE-----", re.DOTALL
24 | )
25 | 
26 | 
27 | def _cf_data_from_bytes(bytestring):
28 |     """
29 |     Given a bytestring, create a CFData object from it. This CFData object must
30 |     be CFReleased by the caller.
31 |     """
32 |     return CoreFoundation.CFDataCreate(
33 |         CoreFoundation.kCFAllocatorDefault, bytestring, len(bytestring)
34 |     )
35 | 
36 | 
37 | def _cf_dictionary_from_tuples(tuples):
38 |     """
39 |     Given a list of Python tuples, create an associated CFDictionary.
40 |     """
41 |     dictionary_size = len(tuples)
42 | 
43 |     # We need to get the dictionary keys and values out in the same order.
44 |     keys = (t[0] for t in tuples)
45 |     values = (t[1] for t in tuples)
46 |     cf_keys = (CoreFoundation.CFTypeRef * dictionary_size)(*keys)
47 |     cf_values = (CoreFoundation.CFTypeRef * dictionary_size)(*values)
48 | 
49 |     return CoreFoundation.CFDictionaryCreate(
50 |         CoreFoundation.kCFAllocatorDefault,
51 |         cf_keys,
52 |         cf_values,
53 |         dictionary_size,
54 |         CoreFoundation.kCFTypeDictionaryKeyCallBacks,
55 |         CoreFoundation.kCFTypeDictionaryValueCallBacks,
56 |     )
57 | 
58 | 
59 | def _cfstr(py_bstr):
60 |     """
61 |     Given a Python binary data, create a CFString.
62 |     The string must be CFReleased by the caller.
63 |     """
64 |     c_str = ctypes.c_char_p(py_bstr)
65 |     cf_str = CoreFoundation.CFStringCreateWithCString(
66 |         CoreFoundation.kCFAllocatorDefault,
67 |         c_str,
68 |         CFConst.kCFStringEncodingUTF8,
69 |     )
70 |     return cf_str
71 | 
72 | 
73 | def _create_cfstring_array(lst):
74 |     """
75 |     Given a list of Python binary data, create an associated CFMutableArray.
76 |     The array must be CFReleased by the caller.
77 | 
78 |     Raises an ssl.SSLError on failure.
79 |     """
80 |     cf_arr = None
81 |     try:
82 |         cf_arr = CoreFoundation.CFArrayCreateMutable(
83 |             CoreFoundation.kCFAllocatorDefault,
84 |             0,
85 |             ctypes.byref(CoreFoundation.kCFTypeArrayCallBacks),
86 |         )
87 |         if not cf_arr:
88 |             raise MemoryError("Unable to allocate memory!")
89 |         for item in lst:
90 |             cf_str = _cfstr(item)
91 |             if not cf_str:
92 |                 raise MemoryError("Unable to allocate memory!")
93 |             try:
94 |                 CoreFoundation.CFArrayAppendValue(cf_arr, cf_str)
95 |             finally:
96 |                 CoreFoundation.CFRelease(cf_str)
97 |     except BaseException as e:
98 |         if cf_arr:
99 |             CoreFoundation.CFRelease(cf_arr)
100 |         raise ssl.SSLError("Unable to allocate array: %s" % (e,))
101 |     return cf_arr
102 | 
103 | 
104 | def _cf_string_to_unicode(value):
105 |     """
106 |     Creates a Unicode string from a CFString object. Used entirely for error
107 |     reporting.
108 | 
109 |     Yes, it annoys me quite a lot that this function is this complex.
110 |     """
111 |     value_as_void_p = ctypes.cast(value, ctypes.POINTER(ctypes.c_void_p))
112 | 
113 |     string = CoreFoundation.CFStringGetCStringPtr(
114 |         value_as_void_p, CFConst.kCFStringEncodingUTF8
115 |     )
116 |     if string is None:
117 |         buffer = ctypes.create_string_buffer(1024)
118 |         result = CoreFoundation.CFStringGetCString(
119 |             value_as_void_p, buffer, 1024, CFConst.kCFStringEncodingUTF8
120 |         )
121 |         if not result:
122 |             raise OSError("Error copying C string from CFStringRef")
123 |         string = buffer.value
124 |     if string is not None:
125 |         string = string.decode("utf-8")
126 |     return string
127 | 
128 | 
129 | def _assert_no_error(error, exception_class=None):
130 |     """
131 |     Checks the return code and throws an exception if there is an error to
132 |     report
133 |     """
134 |     if error == 0:
135 |         return
136 | 
137 |     cf_error_string = Security.SecCopyErrorMessageString(error, None)
138 |     output = _cf_string_to_unicode(cf_error_string)
139 |     CoreFoundation.CFRelease(cf_error_string)
140 | 
141 |     if output is None or output == u"":
142 |         output = u"OSStatus %s" % error
143 | 
144 |     if exception_class is None:
145 |         exception_class = ssl.SSLError
146 | 
147 |     raise exception_class(output)
148 | 
149 | 
150 | def _cert_array_from_pem(pem_bundle):
151 |     """
152 |     Given a bundle of certs in PEM format, turns them into a CFArray of certs
153 |     that can be used to validate a cert chain.
154 |     """
155 |     # Normalize the PEM bundle's line endings.
156 |     pem_bundle = pem_bundle.replace(b"\r\n", b"\n")
157 | 
158 |     der_certs = [
159 |         base64.b64decode(match.group(1)) for match in _PEM_CERTS_RE.finditer(pem_bundle)
160 |     ]
161 |     if not der_certs:
162 |         raise ssl.SSLError("No root certificates specified")
163 | 
164 |     cert_array = CoreFoundation.CFArrayCreateMutable(
165 |         CoreFoundation.kCFAllocatorDefault,
166 |         0,
167 |         ctypes.byref(CoreFoundation.kCFTypeArrayCallBacks),
168 |     )
169 |     if not cert_array:
170 |         raise ssl.SSLError("Unable to allocate memory!")
171 | 
172 |     try:
173 |         for der_bytes in der_certs:
174 |             certdata = _cf_data_from_bytes(der_bytes)
175 |             if not certdata:
176 |                 raise ssl.SSLError("Unable to allocate memory!")
177 |             cert = Security.SecCertificateCreateWithData(
178 |                 CoreFoundation.kCFAllocatorDefault, certdata
179 |             )
180 |             CoreFoundation.CFRelease(certdata)
181 |             if not cert:
182 |                 raise ssl.SSLError("Unable to build cert object!")
183 | 
184 |             CoreFoundation.CFArrayAppendValue(cert_array, cert)
185 |             CoreFoundation.CFRelease(cert)
186 |     except Exception:
187 |         # We need to free the array before the exception bubbles further.
188 |         # We only want to do that if an error occurs: otherwise, the caller
189 |         # should free.
190 |         CoreFoundation.CFRelease(cert_array)
191 |         raise
192 | 
193 |     return cert_array
194 | 
195 | 
196 | def _is_cert(item):
197 |     """
198 |     Returns True if a given CFTypeRef is a certificate.
199 |     """
200 |     expected = Security.SecCertificateGetTypeID()
201 |     return CoreFoundation.CFGetTypeID(item) == expected
202 | 
203 | 
204 | def _is_identity(item):
205 |     """
206 |     Returns True if a given CFTypeRef is an identity.
207 |     """
208 |     expected = Security.SecIdentityGetTypeID()
209 |     return CoreFoundation.CFGetTypeID(item) == expected
210 | 
211 | 
212 | def _temporary_keychain():
213 |     """
214 |     This function creates a temporary Mac keychain that we can use to work with
215 |     credentials. This keychain uses a one-time password and a temporary file to
216 |     store the data. We expect to have one keychain per socket. The returned
217 |     SecKeychainRef must be freed by the caller, including calling
218 |     SecKeychainDelete.
219 | 
220 |     Returns a tuple of the SecKeychainRef and the path to the temporary
221 |     directory that contains it.
222 |     """
223 |     # Unfortunately, SecKeychainCreate requires a path to a keychain. This
224 |     # means we cannot use mkstemp to use a generic temporary file. Instead,
225 |     # we're going to create a temporary directory and a filename to use there.
226 |     # This filename will be 8 random bytes expanded into base64. We also need
227 |     # some random bytes to password-protect the keychain we're creating, so we
228 |     # ask for 40 random bytes.
229 |     random_bytes = os.urandom(40)
230 |     filename = base64.b16encode(random_bytes[:8]).decode("utf-8")
231 |     password = base64.b16encode(random_bytes[8:])  # Must be valid UTF-8
232 |     tempdirectory = tempfile.mkdtemp()
233 | 
234 |     keychain_path = os.path.join(tempdirectory, filename).encode("utf-8")
235 | 
236 |     # We now want to create the keychain itself.
237 |     keychain = Security.SecKeychainRef()
238 |     status = Security.SecKeychainCreate(
239 |         keychain_path, len(password), password, False, None, ctypes.byref(keychain)
240 |     )
241 |     _assert_no_error(status)
242 | 
243 |     # Having created the keychain, we want to pass it off to the caller.
244 |     return keychain, tempdirectory
245 | 
246 | 
247 | def _load_items_from_file(keychain, path):
248 |     """
249 |     Given a single file, loads all the trust objects from it into arrays and
250 |     the keychain.
251 |     Returns a tuple of lists: the first list is a list of identities, the
252 |     second a list of certs.
253 |     """
254 |     certificates = []
255 |     identities = []
256 |     result_array = None
257 | 
258 |     with open(path, "rb") as f:
259 |         raw_filedata = f.read()
260 | 
261 |     try:
262 |         filedata = CoreFoundation.CFDataCreate(
263 |             CoreFoundation.kCFAllocatorDefault, raw_filedata, len(raw_filedata)
264 |         )
265 |         result_array = CoreFoundation.CFArrayRef()
266 |         result = Security.SecItemImport(
267 |             filedata,  # cert data
268 |             None,  # Filename, leaving it out for now
269 |             None,  # What the type of the file is, we don't care
270 |             None,  # what's in the file, we don't care
271 |             0,  # import flags
272 |             None,  # key params, can include passphrase in the future
273 |             keychain,  # The keychain to insert into
274 |             ctypes.byref(result_array),  # Results
275 |         )
276 |         _assert_no_error(result)
277 | 
278 |         # A CFArray is not very useful to us as an intermediary
279 |         # representation, so we are going to extract the objects we want
280 |         # and then free the array. We don't need to keep hold of keys: the
281 |         # keychain already has them!
282 |         result_count = CoreFoundation.CFArrayGetCount(result_array)
283 |         for index in range(result_count):
284 |             item = CoreFoundation.CFArrayGetValueAtIndex(result_array, index)
285 |             item = ctypes.cast(item, CoreFoundation.CFTypeRef)
286 | 
287 |             if _is_cert(item):
288 |                 CoreFoundation.CFRetain(item)
289 |                 certificates.append(item)
290 |             elif _is_identity(item):
291 |                 CoreFoundation.CFRetain(item)
292 |                 identities.append(item)
293 |     finally:
294 |         if result_array:
295 |             CoreFoundation.CFRelease(result_array)
296 | 
297 |         CoreFoundation.CFRelease(filedata)
298 | 
299 |     return (identities, certificates)
300 | 
301 | 
302 | def _load_client_cert_chain(keychain, *paths):
303 |     """
304 |     Load certificates and maybe keys from a number of files. Has the end goal
305 |     of returning a CFArray containing one SecIdentityRef, and then zero or more
306 |     SecCertificateRef objects, suitable for use as a client certificate trust
307 |     chain.
308 |     """
309 |     # Ok, the strategy.
310 |     #
311 |     # This relies on knowing that macOS will not give you a SecIdentityRef
312 |     # unless you have imported a key into a keychain. This is a somewhat
313 |     # artificial limitation of macOS (for example, it doesn't necessarily
314 |     # affect iOS), but there is nothing inside Security.framework that lets you
315 |     # get a SecIdentityRef without having a key in a keychain.
316 |     #
317 |     # So the policy here is we take all the files and iterate them in order.
318 |     # Each one will use SecItemImport to have one or more objects loaded from
319 |     # it. We will also point at a keychain that macOS can use to work with the
320 |     # private key.
321 |     #
322 |     # Once we have all the objects, we'll check what we actually have. If we
323 |     # already have a SecIdentityRef in hand, fab: we'll use that. Otherwise,
324 |     # we'll take the first certificate (which we assume to be our leaf) and
325 |     # ask the keychain to give us a SecIdentityRef with that cert's associated
326 |     # key.
327 |     #
328 |     # We'll then return a CFArray containing the trust chain: one
329 |     # SecIdentityRef and then zero-or-more SecCertificateRef objects. The
330 |     # responsibility for freeing this CFArray will be with the caller. This
331 |     # CFArray must remain alive for the entire connection, so in practice it
332 |     # will be stored with a single SSLSocket, along with the reference to the
333 |     # keychain.
334 |     certificates = []
335 |     identities = []
336 | 
337 |     # Filter out bad paths.
338 |     paths = (path for path in paths if path)
339 | 
340 |     try:
341 |         for file_path in paths:
[TRUNCATED]
```

.venv/lib/python3.13/site-packages/pip/_vendor/urllib3/packages/backports/__init__.py
```
```

.venv/lib/python3.13/site-packages/pip/_vendor/urllib3/packages/backports/makefile.py
```
1 | # -*- coding: utf-8 -*-
2 | """
3 | backports.makefile
4 | ~~~~~~~~~~~~~~~~~~
5 | 
6 | Backports the Python 3 ``socket.makefile`` method for use with anything that
7 | wants to create a "fake" socket object.
8 | """
9 | import io
10 | from socket import SocketIO
11 | 
12 | 
13 | def backport_makefile(
14 |     self, mode="r", buffering=None, encoding=None, errors=None, newline=None
15 | ):
16 |     """
17 |     Backport of ``socket.makefile`` from Python 3.5.
18 |     """
19 |     if not set(mode) <= {"r", "w", "b"}:
20 |         raise ValueError("invalid mode %r (only r, w, b allowed)" % (mode,))
21 |     writing = "w" in mode
22 |     reading = "r" in mode or not writing
23 |     assert reading or writing
24 |     binary = "b" in mode
25 |     rawmode = ""
26 |     if reading:
27 |         rawmode += "r"
28 |     if writing:
29 |         rawmode += "w"
30 |     raw = SocketIO(self, rawmode)
31 |     self._makefile_refs += 1
32 |     if buffering is None:
33 |         buffering = -1
34 |     if buffering < 0:
35 |         buffering = io.DEFAULT_BUFFER_SIZE
36 |     if buffering == 0:
37 |         if not binary:
38 |             raise ValueError("unbuffered streams must be binary")
39 |         return raw
40 |     if reading and writing:
41 |         buffer = io.BufferedRWPair(raw, raw, buffering)
42 |     elif reading:
43 |         buffer = io.BufferedReader(raw, buffering)
44 |     else:
45 |         assert writing
46 |         buffer = io.BufferedWriter(raw, buffering)
47 |     if binary:
48 |         return buffer
49 |     text = io.TextIOWrapper(buffer, encoding, errors, newline)
50 |     text.mode = mode
51 |     return text
```

.venv/lib/python3.13/site-packages/pip/_vendor/urllib3/packages/backports/weakref_finalize.py
```
1 | # -*- coding: utf-8 -*-
2 | """
3 | backports.weakref_finalize
4 | ~~~~~~~~~~~~~~~~~~
5 | 
6 | Backports the Python 3 ``weakref.finalize`` method.
7 | """
8 | from __future__ import absolute_import
9 | 
10 | import itertools
11 | import sys
12 | from weakref import ref
13 | 
14 | __all__ = ["weakref_finalize"]
15 | 
16 | 
17 | class weakref_finalize(object):
18 |     """Class for finalization of weakrefable objects
19 |     finalize(obj, func, *args, **kwargs) returns a callable finalizer
20 |     object which will be called when obj is garbage collected. The
21 |     first time the finalizer is called it evaluates func(*arg, **kwargs)
22 |     and returns the result. After this the finalizer is dead, and
23 |     calling it just returns None.
24 |     When the program exits any remaining finalizers for which the
25 |     atexit attribute is true will be run in reverse order of creation.
26 |     By default atexit is true.
27 |     """
28 | 
29 |     # Finalizer objects don't have any state of their own.  They are
30 |     # just used as keys to lookup _Info objects in the registry.  This
31 |     # ensures that they cannot be part of a ref-cycle.
32 | 
33 |     __slots__ = ()
34 |     _registry = {}
35 |     _shutdown = False
36 |     _index_iter = itertools.count()
37 |     _dirty = False
38 |     _registered_with_atexit = False
39 | 
40 |     class _Info(object):
41 |         __slots__ = ("weakref", "func", "args", "kwargs", "atexit", "index")
42 | 
43 |     def __init__(self, obj, func, *args, **kwargs):
44 |         if not self._registered_with_atexit:
45 |             # We may register the exit function more than once because
46 |             # of a thread race, but that is harmless
47 |             import atexit
48 | 
49 |             atexit.register(self._exitfunc)
50 |             weakref_finalize._registered_with_atexit = True
51 |         info = self._Info()
52 |         info.weakref = ref(obj, self)
53 |         info.func = func
54 |         info.args = args
55 |         info.kwargs = kwargs or None
56 |         info.atexit = True
57 |         info.index = next(self._index_iter)
58 |         self._registry[self] = info
59 |         weakref_finalize._dirty = True
60 | 
61 |     def __call__(self, _=None):
62 |         """If alive then mark as dead and return func(*args, **kwargs);
63 |         otherwise return None"""
64 |         info = self._registry.pop(self, None)
65 |         if info and not self._shutdown:
66 |             return info.func(*info.args, **(info.kwargs or {}))
67 | 
68 |     def detach(self):
69 |         """If alive then mark as dead and return (obj, func, args, kwargs);
70 |         otherwise return None"""
71 |         info = self._registry.get(self)
72 |         obj = info and info.weakref()
73 |         if obj is not None and self._registry.pop(self, None):
74 |             return (obj, info.func, info.args, info.kwargs or {})
75 | 
76 |     def peek(self):
77 |         """If alive then return (obj, func, args, kwargs);
78 |         otherwise return None"""
79 |         info = self._registry.get(self)
80 |         obj = info and info.weakref()
81 |         if obj is not None:
82 |             return (obj, info.func, info.args, info.kwargs or {})
83 | 
84 |     @property
85 |     def alive(self):
86 |         """Whether finalizer is alive"""
87 |         return self in self._registry
88 | 
89 |     @property
90 |     def atexit(self):
91 |         """Whether finalizer should be called at exit"""
92 |         info = self._registry.get(self)
93 |         return bool(info) and info.atexit
94 | 
95 |     @atexit.setter
96 |     def atexit(self, value):
97 |         info = self._registry.get(self)
98 |         if info:
99 |             info.atexit = bool(value)
100 | 
101 |     def __repr__(self):
102 |         info = self._registry.get(self)
103 |         obj = info and info.weakref()
104 |         if obj is None:
105 |             return "<%s object at %#x; dead>" % (type(self).__name__, id(self))
106 |         else:
107 |             return "<%s object at %#x; for %r at %#x>" % (
108 |                 type(self).__name__,
109 |                 id(self),
110 |                 type(obj).__name__,
111 |                 id(obj),
112 |             )
113 | 
114 |     @classmethod
115 |     def _select_for_exit(cls):
116 |         # Return live finalizers marked for exit, oldest first
117 |         L = [(f, i) for (f, i) in cls._registry.items() if i.atexit]
118 |         L.sort(key=lambda item: item[1].index)
119 |         return [f for (f, i) in L]
120 | 
121 |     @classmethod
122 |     def _exitfunc(cls):
123 |         # At shutdown invoke finalizers for which atexit is true.
124 |         # This is called once all other non-daemonic threads have been
125 |         # joined.
126 |         reenable_gc = False
127 |         try:
128 |             if cls._registry:
129 |                 import gc
130 | 
131 |                 if gc.isenabled():
132 |                     reenable_gc = True
133 |                     gc.disable()
134 |                 pending = None
135 |                 while True:
136 |                     if pending is None or weakref_finalize._dirty:
137 |                         pending = cls._select_for_exit()
138 |                         weakref_finalize._dirty = False
139 |                     if not pending:
140 |                         break
141 |                     f = pending.pop()
142 |                     try:
143 |                         # gc is disabled, so (assuming no daemonic
144 |                         # threads) the following is the only line in
145 |                         # this function which might trigger creation
146 |                         # of a new finalizer
147 |                         f()
148 |                     except Exception:
149 |                         sys.excepthook(*sys.exc_info())
150 |                     assert f not in cls._registry
151 |         finally:
152 |             # prevent any more finalizers from executing during shutdown
153 |             weakref_finalize._shutdown = True
154 |             if reenable_gc:
155 |                 gc.enable()
```
